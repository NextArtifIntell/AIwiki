<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIIMS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="siims---74">SIIMS - 74</h2>
<ul>
<li><details>
<summary>
(2024). Regularized CNN with geodesic active contour and edge
predictor for image segmentation. <em>SIIMS</em>, <em>17</em>(4),
2392–2417. (<a href="https://doi.org/10.1137/24M1633868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In order to exploit effectively the benefits of classical variational methods with good interpretability and high generalization performance, this paper proposes a novel regularized convolutional neural network (CNN) based on geodesic active contour (GAC) and edge predictor (EP) for image segmentation. The main idea is to establish a variational problem which integrates the Heaviside function such that the GAC prior is easily added into the problem. Furthermore, an edge predictor module is designed to predict the edges of target objects and an edge predictor function (EPF) is generated instead of the traditional edge indicator function in the GAC. Besides, an iterative convolution soft thresholding module (ICSTM) is developed to numerically solve the GAC and EPF based variational problem, and merged into an existing CNN to generate our new end-to-end network. It is also proved that the ICSTM algorithm is unconditionally stable. Finally, experimental results on synthetic, MRI and CT images show that the proposed method is quite competitive with the other state-of-the-art segmentation methods especially in segmenting noisy images with low contrast.},
  archive      = {J_SIIMS},
  author       = {Zhengmeng Jin and Hao Wang and Michael K. Ng and Lihua Min},
  doi          = {10.1137/24M1633868},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2392-2417},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Regularized CNN with geodesic active contour and edge predictor for image segmentation},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual simplex volume maximization for simplex-structured
matrix factorization. <em>SIIMS</em>, <em>17</em>(4), 2362–2391. (<a
href="https://doi.org/10.1137/24M1650600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Simplex-structured matrix factorization (SSMF), closely related to nonnegative matrix factorization, is a fundamental interpretable data analysis model and has applications in hyperspectral unmixing and topic modeling. To obtain identifiable solutions, a standard approach is to find minimum-volume solutions. By taking advantage of the duality/polarity concept for polytopes, we convert minimum-volume SSMF in the primal space to a maximum-volume problem in the dual space. We first prove the identifiability of this maximum-volume dual problem. Then, we use this dual formulation to provide a novel optimization approach which bridges the gap between two existing families of algorithms for SSMF, namely volume minimization and facet identification. Numerical experiments show that the proposed approach performs favorably compared to the state-of-the-art SSMF algorithms.},
  archive      = {J_SIIMS},
  author       = {Maryam Abdolali and Giovanni Barbarino and Nicolas Gillis},
  doi          = {10.1137/24M1650600},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2362-2391},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Dual simplex volume maximization for simplex-structured matrix factorization},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Early stopping of untrained convolutional neural networks.
<em>SIIMS</em>, <em>17</em>(4), 2331–2361. (<a
href="https://doi.org/10.1137/24M1636617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In recent years, new regularization methods based on (deep) neural networks have shown very promising empirical performance for the numerical solution of ill-posed problems, e.g., in medical imaging and imaging science. Due to the nonlinearity of neural networks, these methods often lack satisfactory theoretical justification. In this work, we rigorously discuss the convergence of a successful unsupervised approach that utilizes untrained convolutional neural networks to represent solutions to linear ill-posed problems. Untrained neural networks are particularly appealing for many applications because they do not require paired training data. The regularization property of the approach relies solely on the architecture of the neural network instead. Due to the vast overparameterization of the employed neural network, suitable early stopping is essential for the success of the method. We establish that the classical discrepancy principle is an adequate method for early stopping of two-layer untrained convolutional neural networks learned by gradient descent, and furthermore, it yields an approximation with minimax optimal convergence rates. Numerical results are also presented to illustrate the theoretical findings.},
  archive      = {J_SIIMS},
  author       = {Tim Jahn and Bangti Jin},
  doi          = {10.1137/24M1636617},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2331-2361},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Early stopping of untrained convolutional neural networks},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RDA-INR: Riemannian diffeomorphic autoencoding via implicit
neural representations. <em>SIIMS</em>, <em>17</em>(4), 2302–2330. (<a
href="https://doi.org/10.1137/24M1644730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Diffeomorphic registration frameworks such as large deformation diffeomorphic metric mapping (LDDMM) are used in computer graphics and the medical domain for atlas building, statistical latent modeling, and pairwise and groupwise registration. In recent years, researchers have developed neural network–based approaches regarding diffeomorphic registration to improve the accuracy and computational efficiency of traditional methods. In this work, we focus on a limitation of neural network–based atlas building and statistical latent modeling methods, namely that they either (i) are resolution dependent or (ii) disregard any data- or problem-specific geometry needed for proper mean-variance analysis. In particular, we overcome this limitation by designing a novel encoder based on resolution-independent implicit neural representations. The encoder achieves resolution invariance for LDDMM-based statistical latent modeling. Additionally, the encoder adds LDDMM Riemannian geometry to resolution-independent deep learning models for statistical latent modeling. We investigate how the Riemannian geometry improves latent modeling and is required for a proper mean-variance analysis. To highlight the benefit of resolution independence for LDDMM-based data variability modeling, we show that our approach outperforms current neural network–based LDDMM latent code models. Our work paves the way for more research into how Riemannian geometry; shape, respectively, image analysis; and deep learning can be combined.},
  archive      = {J_SIIMS},
  author       = {Sven Dummer and Nicola Strisciuglio and Christoph Brune},
  doi          = {10.1137/24M1644730},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2302-2330},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {RDA-INR: Riemannian diffeomorphic autoencoding via implicit neural representations},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Direct imaging of moving acoustic point sources.
<em>SIIMS</em>, <em>17</em>(4), 2277–2301. (<a
href="https://doi.org/10.1137/24M167367X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We concern with the reconstruction of trajectories for moving acoustic point sources, which is motivated by applications in moving pollution sources, gesture recognition, and underwater sonar systems. The uniqueness of trajectories is established by and when the moving sources perform uniform motion and initially generate acoustic the pressure field at the same location and time. Moreover, a direct imaging method with a novel indicator function is proposed to recover the trajectories of multiple moving sources, and the indicator function only requires the calculation of the Euclidean norm. In addition, we provide an adaptive acceleration approach to improve the computational efficiency. Finally, extensive numerical experiments exhibit that the proposed method is capable of reconstructing trajectories across various sizes, whether they are close to or far away from each other, and the method requires only a few sensors during the reconstruction.},
  archive      = {J_SIIMS},
  author       = {Jiaru Wang and Bo Chen and Keji Liu},
  doi          = {10.1137/24M167367X},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2277-2301},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Direct imaging of moving acoustic point sources},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A low-rank tensor completion method via strassen–ottaviani
flattening. <em>SIIMS</em>, <em>17</em>(4), 2242–2276. (<a
href="https://doi.org/10.1137/23M158975X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, a tensor completion method is proposed based on the Strassen–Ottaviani flattening, which can reveal the underlying tensor rank intrinsically. The resulting tensor completion optimization problem is formulated by spectral functions (convex or nonconvex) as surrogates for the rank function. An exact recovery result for the nuclear norm surrogate is given. An efficient method is proposed for this problem, and adaptive parameters for the spectral functions are allowed during the iterations. The global convergence is established under mild assumptions on the spectral functions and the adaptive parameter updates. In particular, we show that the class of weighted nuclear norms (either with nonincreasing or nondecreasing weights), the -sparsity index, and a class of weighted nuclear norms with adaptive weights, which are all widely employed in the literature, all fulfill the assumptions, and thus the global convergence is valid without any assumption. Numerical experiments on color images show that the proposed methods are promising, and always return images with better quality than some state-of-the-art methods.},
  archive      = {J_SIIMS},
  author       = {Tiantian He and Shenglong Hu and Zheng-Hai Huang},
  doi          = {10.1137/23M158975X},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2242-2276},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A low-rank tensor completion method via Strassen–Ottaviani flattening},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive heavy ball method for ill-posed inverse
problems. <em>SIIMS</em>, <em>17</em>(4), 2212–2241. (<a
href="https://doi.org/10.1137/24M1651721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we consider ill-posed inverse problems, both linear and nonlinear, by a heavy ball method in which a strongly convex regularization function is incorporated to detect the feature of the sought solution. We develop ideas on how to adaptively choose the step-sizes and the momentum coefficients to achieve acceleration over the Landweber-type method. We then analyze the method and establish its regularization property when it is terminated by the discrepancy principle. Various numerical results are reported which demonstrate the superior performance of our method over the Landweber-type method by reducing substantially the required number of iterations and the computational time.},
  archive      = {J_SIIMS},
  author       = {Qinian Jin and Qin Huang},
  doi          = {10.1137/24M1651721},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2212-2241},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {An adaptive heavy ball method for ill-posed inverse problems},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). ROM inversion of monostatic data lifted to full MIMO.
<em>SIIMS</em>, <em>17</em>(4), 2196–2211. (<a
href="https://doi.org/10.1137/24M165778X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Lippmann–Schwinger–Lanczos (LSL) algorithm has recently been shown to provide an efficient tool for imaging and direct inversion of synthetic aperture radar data in multiscattering environments [V. Druskin, S. Moskow, and M. Zaslavsky, SIAM J. Imaging Sci., 17 (2024), pp. 334–350], where the data set is limited to the monostatic, a.k.a. single input/single output (SISO), measurements. The approach is based on constructing data-driven estimates of internal fields via a reduced order model (ROM) framework and then plugging them into the Lippmann–Schwinger integral equation. However, the approximations of the internal solutions may have more error due to missing the off-diagonal elements of the multiple input/multiple output (MIMO) matrix valued transfer function. This, in turn, may result in multiple echoes in the image. Here we present a ROM-based data completion algorithm to mitigate this problem. First, we apply the LSL algorithm to the SISO data as in [V. Druskin, S. Moskow, and M. Zaslavsky, SIAM J. Imaging Sci., 17 (2024), pp. 334–350] to obtain approximate reconstructions as well as the estimate of internal field. Next, we use these estimates to calculate a forward Lippmann–Schwinger integral to populate the missing off-diagonal data (the lifting step). Finally, to update the reconstructions, we solve the Lippmann–Schwinger equation using the original SISO data, where the internal fields are constructed from the lifted MIMO data. The steps of obtaining the approximate reconstructions and internal fields and populating the missing MIMO data entries can be repeated for complex models to improve the images even further. Efficiency of the proposed approach is demonstrated on two-dimensional and 2.5-dimensional numerical examples, where we see reconstructions are improved substantially.},
  archive      = {J_SIIMS},
  author       = {V. Druskin and S. Moskow and M. Zaslavsky},
  doi          = {10.1137/24M165778X},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2196-2211},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {ROM inversion of monostatic data lifted to full MIMO},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Averaging orientations with molecular symmetry in cryo-EM.
<em>SIIMS</em>, <em>17</em>(4), 2174–2195. (<a
href="https://doi.org/10.1137/24M1639518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Cryogenic electron microscopy (cryo-EM) is an invaluable technique for determining high-resolution three-dimensional structures of biological macromolecules using transmission particle images. The inherent symmetry in these macromolecules is advantageous, as it allows each image to represent multiple perspectives. However, data processing that incorporates symmetry can inadvertently average out asymmetric features. Therefore, a key preliminary step is to visualize two-dimensional asymmetric features in the particle images, which requires estimating orientation statistics under molecular symmetry constraints. Motivated by this challenge, we introduce a novel method for estimating the mean and variance of orientations with molecular symmetry. Utilizing tools from nonunique games, we show that our proposed nonconvex formulation can be simplified as a semidefinite programming problem. Moreover, we propose a novel rounding procedure to determine the representative values. Experimental results demonstrate that the proposed approach can find the global minima and the appropriate representatives with a high degree of probability. We release the code of our method as an open-source Python package named pySymStat. Finally, we apply pySymStat to visualize an asymmetric feature in an icosahedral virus, a feat that proved unachievable using the conventional two-dimensional classification method in RELION.},
  archive      = {J_SIIMS},
  author       = {Qi Zhang and Chenglong Bao and Hai Lin and Mingxu Hu},
  doi          = {10.1137/24M1639518},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2174-2195},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Averaging orientations with molecular symmetry in cryo-EM},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The linear sampling method for data generated by small
random scatterers. <em>SIIMS</em>, <em>17</em>(4), 2142–2173. (<a
href="https://doi.org/10.1137/24M1650417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present an extension of the linear sampling method for solving the sound-soft inverse scattering problem in two dimensions with data generated by randomly distributed small scatterers. The theoretical justification of our novel sampling method is based on a rigorous asymptotic model, a modified Helmholtz–Kirchhoff identity, and our previous work on the linear sampling method for random sources. Our numerical implementation incorporates boundary elements, singular value decomposition, Tikhonov regularization, and Morozov’s discrepancy principle. We showcase the robustness and accuracy of our algorithms with a series of numerical experiments.},
  archive      = {J_SIIMS},
  author       = {Josselin Garnier and Houssem Haddar and Hadrien Montanelli},
  doi          = {10.1137/24M1650417},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2142-2173},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {The linear sampling method for data generated by small random scatterers},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spherical density-equalizing map for genus-0 closed
surfaces. <em>SIIMS</em>, <em>17</em>(4), 2110–2141. (<a
href="https://doi.org/10.1137/24M1633911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Density-equalizing maps are a class of mapping methods in which the shape deformation is driven by prescribed density information. In recent years, they have been widely used for data visualization on planar domains and planar parameterization of open surfaces. However, the theory and computation of density-equalizing maps for closed surfaces are much less explored. In this work, we develop a novel method for computing spherical density-equalizing maps for genus-0 closed surfaces. Specifically, we first compute a conformal parameterization of the given genus-0 closed surface onto the unit sphere. Then we perform density equalization on the spherical domain based on the given density information to achieve a spherical density-equalizing map. The bijectivity of the mapping is guaranteed by introducing an overlap correction scheme based on quasi-conformal theory throughout the density-equalizing iterative process. We further propose a method for incorporating the harmonic energy and landmark constraints into our formulation to achieve landmark-aligned spherical density-equalizing maps balancing different distortion measures. Using the proposed methods, a large variety of spherical parameterizations can be achieved. Applications to surface registration, remeshing, and data visualization are presented to demonstrate the effectiveness of our methods.},
  archive      = {J_SIIMS},
  author       = {Zhiyuan Lyu and Lok Ming Lui and Gary P. T. Choi},
  doi          = {10.1137/24M1633911},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2110-2141},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Spherical density-equalizing map for genus-0 closed surfaces},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Practical acceleration of the condat–vũ algorithm.
<em>SIIMS</em>, <em>17</em>(4), 2076–2109. (<a
href="https://doi.org/10.1137/23M159473X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Condat–Vũ algorithm is a widely used primal-dual method for optimizing composite objectives of three functions. Several algorithms for optimizing composite objectives of two functions are special cases of Condat–Vũ, including proximal gradient descent (PGD). It is well known that PGD exhibits suboptimal performance, and a simple adjustment to PGD can accelerate its convergence rate from to on convex objectives, and this accelerated rate is optimal. In this work, we show that a simple adjustment to the Condat–Vũ algorithm allows it to recover accelerated PGD (APGD) as a special case, instead of PGD. We prove that this accelerated Condat–Vũ algorithm achieves optimal convergence rates and significantly outperforms the traditional Condat–Vũ algorithm in regimes where the Condat–Vũ algorithm approximates the dynamics of PGD. We demonstrate the effectiveness of our approach in various applications in machine learning and computational imaging.},
  archive      = {J_SIIMS},
  author       = {Derek Driggs and Matthias J. Ehrhardt and Carola-Bibiane Schönlieb and Junqi Tang},
  doi          = {10.1137/23M159473X},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2076-2109},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Practical acceleration of the Condat–Vũ algorithm},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regularization of linear inverse problems with irregular
noise using embedding operators. <em>SIIMS</em>, <em>17</em>(4),
2053–2075. (<a href="https://doi.org/10.1137/24M1636307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we investigate regularization of linear inverse problems with irregular noise. In particular, we consider the case that the noise can be preprocessed by certain adjoint embedding operators. By introducing the consequent preprocessed problem, we provide convergence analysis for general regularization schemes under standard assumptions. Furthermore, for a special case of Tikhonov regularization in computerized tomography, we show that our approach leads to a novel (Fourier-based) filtered backprojection algorithm. Numerical examples with different parameter choice rules verify the efficiency of our proposed algorithm.},
  archive      = {J_SIIMS},
  author       = {Xinyan Li and Simon Hubmer and Shuai Lu and Ronny Ramlau},
  doi          = {10.1137/24M1636307},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {12},
  number       = {4},
  pages        = {2053-2075},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Regularization of linear inverse problems with irregular noise using embedding operators},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary weighted laplace equations with applications in
signal decomposition. <em>SIIMS</em>, <em>17</em>(3), 2015–2052. (<a
href="https://doi.org/10.1137/24M1630980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Evolutionary weighted Laplace equations with convex constant coefficients and variable coefficients consisting of power functions are employed to improve signal decomposition. We show the existence of solutions by the Faedo–Galerkin method. We also investigate the asymptotical behavior of solutions to the equations and find that time-separated solutions are deeply related to eigenfunctions of the weighted Laplace operator. We accomplish signal decomposition based on different smoothness via solutions to those equations through the transform and inverse transform that depend on fractional order derivatives. Our methods are extremely time efficient and have better quality. Discrete solutions to those equations and signal decomposition are obtained with numerical methods in MATLAB.},
  archive      = {J_SIIMS},
  author       = {Zhen Shuang and Jie Xiao},
  doi          = {10.1137/24M1630980},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {2015-2052},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Evolutionary weighted laplace equations with applications in signal decomposition},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Background removal for ptychography via wigner distribution
deconvolution. <em>SIIMS</em>, <em>17</em>(3), 1978–2014. (<a
href="https://doi.org/10.1137/24M1642433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Ptychography is a computational imaging technique that aims to reconstruct the object of interest from a set of diffraction patterns. Each of these is obtained by a localized illumination of the object, which is shifted after each illumination to cover its whole domain. Because in the resulting measurements the phase information is lost, ptychography gives rise to solving a phase retrieval problem. In this work, we consider ptychographic measurements contaminated by a background signal. Such a background is caused by imperfections in the experimental setup and appears as a signal that is added to the diffraction patterns. The background is assumed to be independent of the shift of the object, i.e., it is the same for all diffraction patterns. Two algorithms are provided, for arbitrary objects and for so-called phase objects that do not absorb the light but only scatter it. For the second type, a uniqueness of reconstruction is established for almost every object. Our approach is based on the Wigner distribution deconvolution, which lifts the object to a higher-dimensional matrix space where the recovery can be reformulated as a linear problem. The background only affects a few equations of the linear system that are therefore discarded. The lost information is then restored using redundancy in the higher-dimensional space.},
  archive      = {J_SIIMS},
  author       = {Oleh Melnyk and Patricia Römer},
  doi          = {10.1137/24M1642433},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1978-2014},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Background removal for ptychography via wigner distribution deconvolution},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uniform recovery guarantees for quantized corrupted sensing
using structured or generative priors. <em>SIIMS</em>, <em>17</em>(3),
1909–1977. (<a href="https://doi.org/10.1137/23M1578358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies quantized corrupted sensing where the measurements are contaminated by unknown corruption and then quantized by a dithered uniform quantizer. We establish uniform guarantees for Lasso that ensure the accurate recovery of all signals and corruptions using a single draw of the sub-Gaussian sensing matrix and uniform dither. For signal and corruption with structured priors (e.g., sparsity, low-rankness), our uniform error rate for constrained Lasso typically coincides with the nonuniform one up to logarithmic factors, indicating that the uniformity costs very little. By contrast, our uniform error rate for unconstrained Lasso exhibits worse dependence on the structured parameters due to regularization parameters larger than the ones for nonuniform recovery. These results complement the nonuniform ones recently obtained in Sun, Cui, and Liu [IEEE Trans. Signal Process., 70 (2022), pp. 600–615] and provide more insights for understanding actual applications where the sensing ensemble is typically fixed and the corruption may be adversarial. For signal and corruption living in the ranges of some Lipschitz continuous generative models (referred to as generative priors), we achieve uniform recovery via constrained Lasso with a measurement number proportional to the latent dimensions of the generative models. We present experimental results to corroborate our theories. From the technical side, our treatments to the two kinds of priors are (nearly) unified and share the common key ingredients of a (global) quantized product embedding (QPE) property, which states that the dithered uniform quantization (universally) preserves the inner product. As a by-product, our QPE result refines the one in Xu and Jacques [Inf. Inference, 9 (2020), pp. 543–586] under the sub-Gaussian random matrix, and in this specific instance, we are able to sharpen the uniform error decaying rate (for the projected back-projection estimator with signals in some convex symmetric set) presented therein from to .},
  archive      = {J_SIIMS},
  author       = {Junren Chen and Zhaoqiang Liu and Meng Ding and Michael K. Ng},
  doi          = {10.1137/23M1578358},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1909-1977},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Uniform recovery guarantees for quantized corrupted sensing using structured or generative priors},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Restoration guarantee of image inpainting via low rank patch
matrix completion. <em>SIIMS</em>, <em>17</em>(3), 1879–1908. (<a
href="https://doi.org/10.1137/23M1614456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In recent years, patch-based image restoration approaches have demonstrated superior performance compared to conventional variational methods. This paper delves into the mathematical foundations underlying patch-based image restoration methods, with a specific focus on establishing restoration guarantees for patch-based image inpainting, leveraging the assumption of self-similarity among patches. To accomplish this, we present a reformulation of the image inpainting problem as structured low-rank matrix completion, accomplished by grouping image patches with potential overlaps. By making certain incoherence assumptions, we establish a restoration guarantee, given that the number of samples exceeds the order of , where denotes the size of the image and represents the sum of ranks for each group of image patches. Through our rigorous mathematical analysis, we provide valuable insights into the theoretical foundations of patch-based image restoration methods, shedding light on their efficacy and offering guidelines for practical implementation.},
  archive      = {J_SIIMS},
  author       = {Jian-Feng Cai and Jae Kyu Choi and Jingyang Li and Guojian Yin},
  doi          = {10.1137/23M1614456},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1879-1908},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Restoration guarantee of image inpainting via low rank patch matrix completion},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inclusion and estimates for the jumps of minimizers in
variational denoising. <em>SIIMS</em>, <em>17</em>(3), 1844–1878. (<a
href="https://doi.org/10.1137/23M1627948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study stability and inclusion of the jump set of minimizers of convex denoising functionals, such as the celebrated “Rudin–Osher–Fatemi” functional, for scalar or vectorial signals. We show that under mild regularity assumptions on the data fidelity term and the regularizer, the jump set of the minimizer is essentially a subset of the original jump set. Moreover, we give an estimate on the magnitude of the jumps in terms of the data. This extends old results, in particular of the first author (with Caselles and Novaga) and of Valkonen, to much more general cases. We also consider the case where the original datum has unbounded variation, and we define a notion of its jump set which, again, must contain the jump set of the solution.},
  archive      = {J_SIIMS},
  author       = {Antonin Chambolle and Michał Łasica},
  doi          = {10.1137/23M1627948},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1844-1878},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Inclusion and estimates for the jumps of minimizers in variational denoising},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Removing the mask—reconstructing a real-valued field on the
sphere from a masked field by spherical fourier analysis.
<em>SIIMS</em>, <em>17</em>(3), 1820–1843. (<a
href="https://doi.org/10.1137/23M1603157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The paper analyzes a spectral approach to reconstructing a scalar field on the sphere, given only information about a masked version of the field, together with precise information about the (smooth) mask. The theory is developed for a general mask and later specialized to the case of an axially symmetric mask. Numerical experiments are given for the case of an axial mask motivated by the cosmic microwave background, assuming that the underlying field is a realization of a Gaussian random field with an artificial angular power spectrum of moderate degree . The recovery is highly satisfactory in the absence of noise and even in the presence of moderate noise.},
  archive      = {J_SIIMS},
  author       = {Jan Hamann and Quoc T. Le Gia and Ian H. Sloan and Robert S. Womersley},
  doi          = {10.1137/23M1603157},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1820-1843},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Removing the Mask—Reconstructing a real-valued field on the sphere from a masked field by spherical fourier analysis},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An inexact majorized proximal alternating direction method
of multipliers for diffusion tensors. <em>SIIMS</em>, <em>17</em>(3),
1795–1819. (<a href="https://doi.org/10.1137/23M1607015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper focuses on studying the denoising problem for positive semidefinite fourth-order tensor field estimation from noisy observations. The positive semidefiniteness of the tensor is preserved by mapping the tensor to a 6-by-6 symmetric positive semidefinite matrix where its matrix rank is less than or equal to three. For denoising, we propose to use an anisotropic discrete total variation function over the tensor field as the regularization term. We propose an inexact majorized proximal alternating direction method of multipliers for such a nonconvex and nonsmooth optimization problem. We show that an -stationary solution of the resulting optimization problem can be found in no more than iterations. The effectiveness of the proposed model and algorithm is tested using multifiber diffusion weighted imaging data, and our numerical results demonstrate that our method outperforms existing methods in terms of denoising performance.},
  archive      = {J_SIIMS},
  author       = {Hong Zhu and Michael K. Ng},
  doi          = {10.1137/23M1607015},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1795-1819},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {An inexact majorized proximal alternating direction method of multipliers for diffusion tensors},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TILT: Topological interface recovery in limited-angle
tomography. <em>SIIMS</em>, <em>17</em>(3), 1761–1794. (<a
href="https://doi.org/10.1137/23M1611567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A novel reconstruction method is introduced for the severely ill-posed inverse problem of limited-angle tomography. It is well known that, depending on the available measurement, angles specify a subset of the wavefront set of the unknown target, while some oriented singularities remain invisible in the data. Topological Interface recovery for Limited-angle Tomography, or TILT, is based on lifting the visible part of the wavefront set under a universal covering map. In the space provided, it is possible to connect the appropriate pieces of the lifted wavefront set correctly using dual-tree complex wavelets, a dedicated metric, and persistent homology. The result is not only a suggested invisible boundary but also a computational representation for all interfaces in the target.},
  archive      = {J_SIIMS},
  author       = {Elli Karvonen and Matti Lassas and Pekka Pankka and Samuli Siltanen},
  doi          = {10.1137/23M1611567},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1761-1794},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {TILT: Topological interface recovery in limited-angle tomography},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proximal langevin sampling with inexact proximal mapping.
<em>SIIMS</em>, <em>17</em>(3), 1729–1760. (<a
href="https://doi.org/10.1137/23M1593565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In order to solve tasks like uncertainty quantification or hypothesis tests in Bayesian imaging inverse problems, we often have to draw samples from the arising posterior distribution. For the usually log-concave but high-dimensional posteriors, Markov chain Monte Carlo methods based on time discretizations of Langevin diffusion are a popular tool. If the potential defining the distribution is nonsmooth, these discretizations are usually of an implicit form leading to Langevin sampling algorithms that require the evaluation of proximal operators. For some of the potentials relevant in imaging problems this is only possible approximately using an iterative scheme. We investigate the behavior of a proximal Langevin algorithm under the presence of errors in the evaluation of proximal mappings. We generalize existing nonasymptotic and asymptotic convergence results of the exact algorithm to our inexact setting and quantify the bias between the target and the algorithm’s stationary distribution due to the errors. We show that the additional bias stays bounded for bounded errors and converges to zero for decaying errors in a strongly convex setting. We apply the inexact algorithm to sample numerically from the posterior of typical imaging inverse problems in which we can only approximate the proximal operator by an iterative scheme and validate our theoretical convergence results.},
  archive      = {J_SIIMS},
  author       = {Matthias J. Ehrhardt and Lorenz Kuger and Carola-Bibiane Schönlieb},
  doi          = {10.1137/23M1593565},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1729-1760},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Proximal langevin sampling with inexact proximal mapping},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-stage approach for 2D/3D diffeomorphic multimodality
image registration with textural control. <em>SIIMS</em>,
<em>17</em>(3), 1690–1728. (<a
href="https://doi.org/10.1137/23M1583971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Intensity inhomogeneity is a challenging task in image registration. Few past works have addressed the case of intensity inhomogeneity due to texture noise. To address this difficulty, we propose a novel three-stage approach for 2D/3D diffeomorphic multimodality image registration. The proposed approach contains three stages: (1) decomposition which decomposes the image pairs into texture, noise, and smooth component; (2) Blake–Zisserman homogenization which transforms the geometric features from different modalities into approximately the same modality in terms of the first-order and second-order edge information; (3) image registration which combines the homogenized geometric features and mutual information. Based on the proposed approach, the greedy matching for multimodality image registration is discussed and a coarse-to-fine algorithm is also proposed. Furthermore, several numerical tests are performed to validate the efficiency of the proposed approach.},
  archive      = {J_SIIMS},
  author       = {Ke Chen and Huan Han},
  doi          = {10.1137/23M1583971},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1690-1728},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Three-stage approach for 2D/3D diffeomorphic multimodality image registration with textural control},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discrete morphological neural networks. <em>SIIMS</em>,
<em>17</em>(3), 1650–1689. (<a
href="https://doi.org/10.1137/23M1598477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A classical approach to designing binary image operators is mathematical morphology (MM). We propose the Discrete Morphological Neural Networks (DMNN) for binary image analysis to represent W-operators and estimate them via machine learning. A DMNN architecture, which is represented by a morphological computational graph, is designed as in the classical heuristic design of morphological operators, in which the designer should combine a set of MM operators and Boolean operations based on prior information and theoretical knowledge. Then, once the architecture is fixed, instead of adjusting its parameters (i.e., structuring elements or maximal intervals) by hand, we propose a lattice descent algorithm (LDA) to train these parameters based on a sample of input and output images under the usual machine learning approach. We also propose a stochastic version of the LDA that is more efficient, is scalable, and can obtain small error in practical problems. The class represented by a DMNN can be quite general or specialized according to expected properties of the target operator, i.e., prior information, and the semantic expressed by algebraic properties of classes of operators is a differential relative to other methods. The main contribution of this paper is the merger of the two main paradigms for designing morphological operators: classical heuristic design and automatic design via machine learning. As a proof-of-concept, we apply the DMNN to recognize the boundary of digits with noise, and we discuss many topics for future research.},
  archive      = {J_SIIMS},
  author       = {Diego Marcondes and Junior Barrera},
  doi          = {10.1137/23M1598477},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1650-1689},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Discrete morphological neural networks},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Localization of point scatterers via sparse optimization on
measures. <em>SIIMS</em>, <em>17</em>(3), 1619–1649. (<a
href="https://doi.org/10.1137/24M1636265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the inverse scattering problem for time-harmonic acoustic waves in a medium with pointwise inhomogeneities. In the Foldy–Lax model, the estimation of the scatterers’ locations and intensities from far field measurements can be recast as the recovery of a discrete measure from nonlinear observations. We propose a “linearize and locally optimize” approach to perform this reconstruction. We first solve a convex program in the space of measures (known as the Beurling LASSO), which involves a linearization of the forward operator (the far field pattern in the Born approximation). Then, we locally minimize a second functional involving the nonlinear forward map, using the output of the first step as initialization. We provide guarantees that the output of the first step is close to the sought-after measure when the scatterers have small intensities and are sufficiently separated. We also provide numerical evidence that the second step still allows for accurate recovery in settings that are more involved.},
  archive      = {J_SIIMS},
  author       = {Giovanni S. Alberti and Romain Petit and Matteo Santacesaria},
  doi          = {10.1137/24M1636265},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1619-1649},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Localization of point scatterers via sparse optimization on measures},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tight-frame-like analysis-sparse recovery using nontight
sensing matrices. <em>SIIMS</em>, <em>17</em>(3), 1587–1618. (<a
href="https://doi.org/10.1137/23M1625846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The choice of the sensing matrix is crucial in compressed sensing. Random Gaussian sensing matrices satisfy the restricted isometry property, which is crucial for solving the sparse recovery problem using convex optimization techniques. However, tight-frame sensing matrices result in minimum mean-squared-error recovery given oracle knowledge of the support of the sparse vector. If the sensing matrix is not tight, could one achieve the recovery performance assured by a tight frame by suitably designing the recovery strategy?  This is the key question addressed in this paper. We consider the analysis-sparse -minimization problem with a generalized -norm-based data-fidelity and show that it effectively corresponds to using a tight-frame sensing matrix. The new formulation offers improved performance bounds when the number of nonzeros is large. One could develop a tight-frame variant of a known sparse recovery algorithm using the proposed formalism. We solve the analysis-sparse recovery problem in an unconstrained setting using proximal methods. Within the tight-frame sensing framework, we rescale the gradients of the data-fidelity loss in the iterative updates to further improve the accuracy of analysis-sparse recovery. Experimental results show that the proposed algorithms offer superior analysis-sparse recovery performance. Proceeding further, we also develop deep-unfolded variants, with a convolutional neural network as the sparsifying operator. On the application front, we consider compressed sensing image recovery. Experimental results on Set11, BSD68, Urban100, and DIV2K datasets show that the proposed techniques outperform the state-of-the-art techniques, with performance measured in terms of peak signal-to-noise ratio and structural similarity index metric.},
  archive      = {J_SIIMS},
  author       = {Kartheek Kumar Reddy Nareddy and Abijith Jagannath Kamath and Chandra Sekhar Seelamantula},
  doi          = {10.1137/23M1625846},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1587-1618},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Tight-frame-like analysis-sparse recovery using nontight sensing matrices},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic image reconstruction with motion priors in
application to three dimensional magnetic particle imaging.
<em>SIIMS</em>, <em>17</em>(3), 1539–1586. (<a
href="https://doi.org/10.1137/23M1580401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Various imaging modalities allow for time-dependent image reconstructions from measurements where its acquisition also has a time-dependent nature. Magnetic particle imaging (MPI) falls into this class of imaging modalities and it thus also provides a dynamic inverse problem. Without proper consideration of the dynamic behavior, motion artifacts in the reconstruction become an issue. More sophisticated methods need to be developed and applied to the reconstruction of the time-dependent sequences of images. In this context, we investigate the incorporation of motion priors in terms of certain flow-parameter-dependent PDEs in the reconstruction process of time-dependent three dimensional (3D) images in magnetic particle imaging. The present work comprises the method development for a general 3D+time setting for time-dependent linear forward operators, analytical investigation of necessary properties in the MPI forward operator, modeling aspects in dynamic MPI, and extensive numerical experiments on 3D+time imaging including simulated data as well as measurements from a rotation phantom and in vivo data from a mouse.},
  archive      = {J_SIIMS},
  author       = {Christina Brandt and Tobias Kluth and Tobias Knopp and Lena Westen},
  doi          = {10.1137/23M1580401},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1539-1586},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Dynamic image reconstruction with motion priors in application to three dimensional magnetic particle imaging},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PhaseNet: A deep learning based phase reconstruction method
for ground-based astronomy. <em>SIIMS</em>, <em>17</em>(3), 1511–1538.
(<a href="https://doi.org/10.1137/23M1592377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Ground-based astronomy utilizes modern telescopes to obtain information on the universe by analyzing recorded signals. Due to atmospheric turbulence, the reconstruction process requires solving a deconvolution problem with an unknown point spread function (PSF). The crucial step in PSF estimation is to obtain a high-resolution phase from low-resolution phase gradients, which is a challenging problem. In this paper, when multiple frames of low-resolution phase gradients are available, we introduce PhaseNet, a deep learning approach based on the Taylor frozen flow hypothesis. Our approach incorporates a data-driven residual regularization term, of which the gradient is parameterized by a network, into the Laplacian regularization based model. To solve the model, we unroll the Nesterov accelerated gradient algorithm so that the network can be efficiently and effectively trained. Finally, we evaluate the performance of PhaseNet under various atmospheric conditions and demonstrate its superiority over TV and Laplacian regularization based methods.},
  archive      = {J_SIIMS},
  author       = {Dihan Zheng and Shiqi Tang and Roland Wagner and Ronny Ramlau and Chenglong Bao and Raymond H. Chan},
  doi          = {10.1137/23M1592377},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1511-1538},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {PhaseNet: A deep learning based phase reconstruction method for ground-based astronomy},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imaging of atmospheric dispersion processes with
differential absorption lidar. <em>SIIMS</em>, <em>17</em>(3),
1467–1510. (<a href="https://doi.org/10.1137/23M1598404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the inverse problem of fitting atmospheric dispersion parameters based on time-resolved back-scattered differential absorption Lidar (DIAL) measurements. The obvious advantage of light-based remote sensing modalities is their extended spatial range which makes them less sensitive to strictly local perturbations/modelling errors or the distance to the plume source. In contrast to other state-of-the-art DIAL methods, we do not make a single scattering assumption but rather propose a new type modality which includes the collection of multiply scattered photons from wider/multiple fields-of-view and argue that this data, paired with a time dependent radiative transfer model, is beneficial for the reconstruction of certain image features. The resulting inverse problem is solved by means of a semiparametric approach in which the image is reduced to a small number of dispersion related parameters and high-dimensional but computationally convenient nuisance component. This not only allows us to effectively avoid a high-dimensional inverse problem but simultaneously provides a natural regularization mechanism along with parameters which are directly related to the dispersion model. These can be associated with meaningful physical units while spatial concentration profiles can be obtained by means of forward evaluation of the dispersion process.},
  archive      = {J_SIIMS},
  author       = {Robert Lung and Nick Polydorides},
  doi          = {10.1137/23M1598404},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1467-1510},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Imaging of atmospheric dispersion processes with differential absorption lidar},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A wasserstein-type distance for gaussian mixtures on vector
bundles with applications to shape analysis. <em>SIIMS</em>,
<em>17</em>(3), 1433–1466. (<a
href="https://doi.org/10.1137/23M1620363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper uses sample data to study the problem of comparing populations on finite-dimensional parallelizable Riemannian manifolds and more general trivial vector bundles. Utilizing triviality, our framework represents populations as mixtures of Gaussians on vector bundles and estimates the population parameters using a mode-based clustering algorithm. We derive a Wasserstein-type metric between Gaussian mixtures, adapted to the manifold geometry, in order to compare estimated distributions. Our contributions include an identifiability result for Gaussian mixtures on manifold domains and a convenient characterization of optimal couplings of Gaussian mixtures under the derived metric. We demonstrate these tools on some example domains, including the preshape space of planar closed curves, with applications to the shape space of triangles and populations of nanoparticles. In the nanoparticle application, we consider a sequence of populations of particle shapes arising from a manufacturing process and utilize the Wasserstein-type distance to perform change-point detection.},
  archive      = {J_SIIMS},
  author       = {Michael Wilson and Tom Needham and Chiwoo Park and Suparteek Kundu and Anuj Srivastava},
  doi          = {10.1137/23M1620363},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1433-1466},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A wasserstein-type distance for gaussian mixtures on vector bundles with applications to shape analysis},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast certifiable algorithm for the absolute pose estimation
of a camera. <em>SIIMS</em>, <em>17</em>(3), 1415–1432. (<a
href="https://doi.org/10.1137/23M159994X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Estimating the absolute pose of a camera given a set of points and their observations is known as the resectioning or Perspective-n-Point (PnP) problem. It is at the core of most computer vision applications and it can be stated as an instance of three-dimensional registration with point-line distances, making the error quadratic in the unknown pose. The PnP problem, though, is nonconvex due to the constraints associated with the rotation, and iterative algorithms may get trapped into any suboptimal solutions without notice. This work proposes an efficient certification algorithm for central and noncentral cameras that either confirms the optimality of a solution or is inconclusive. We exploit different sets of constraints for the rotation to assess their performance in terms of certification. Two of the formulations lack the Linear Independence Constraint Qualification (LICQ) while one of them has more constraints than variables. This hinders the usage of the “standard” procedure which estimates the Lagrange multipliers in closed-form. To overcome that, we formulate the certification as an eigenvalue optimization and solve it through a line-search method. Our evaluation on synthetic and real data shows that minimal formulations certify most solutions (more than on real data) whereas redundant formulations are able to certify all of them and even random problem instances. The proposed algorithm runs in microseconds for all these formulations.},
  archive      = {J_SIIMS},
  author       = {Mercedes Garcia-Salguero and Elijs Dima and André Mateus and Javier Gonzalez-Jimenez},
  doi          = {10.1137/23M159994X},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1415-1432},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Fast certifiable algorithm for the absolute pose estimation of a camera},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imaging a moving point source from multifrequency data
measured at one and sparse observation points (part II): Near-field case
in 3D. <em>SIIMS</em>, <em>17</em>(3), 1377–1414. (<a
href="https://doi.org/10.1137/23M162260X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we introduce a frequency-domain approach to extract information on the trajectory of a moving point source. The method hinges on the analysis of multifrequency near-field data recorded at one and sparse observation points in three dimensions. The radiating period of the moving point source is supposed to be supported on the real axis and a priori known. In contrast to inverse stationary source problems, one needs to classify observable and non-observable measurement positions. The analogues of these concepts in the far-field regime were first proposed in the authors’ previous paper [SIAM J. Imaging Sci., 16 (2023), pp. 1535–1571]. In this paper we shall derive the observable and non-observable measurement positions for straight and circular motions in . In the near-field case, we verify that the smallest annular region centered at an observable position that contains the trajectory can be imaged for an admissible class of orbit functions. Using the data from sparse observable positions, it is possible to reconstruct the -convex domain of the trajectory. Intensive 3D numerical tests with synthetic data are performed to show effectiveness and feasibility of this new algorithm.},
  archive      = {J_SIIMS},
  author       = {Guanqiu Ma and Hongxia Guo and Guanghui Hu},
  doi          = {10.1137/23M162260X},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1377-1414},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Imaging a moving point source from multifrequency data measured at one and sparse observation points (Part II): Near-field case in 3D},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IML FISTA: A multilevel framework for inexact and inertial
forward-backward. Application to image restoration. <em>SIIMS</em>,
<em>17</em>(3), 1347–1376. (<a
href="https://doi.org/10.1137/23M1582345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper presents a multilevel framework for inertial and inexact proximal algorithms that encompasses multilevel versions of classical algorithms such as forward-backward and FISTA. The methods are supported by strong theoretical guarantees: we prove both the rate of convergence and the convergence of the iterates to a minimum in the convex case, an important result for ill-posed problems. We propose a particular instance of IML (Inexact MultiLevel) FISTA, based on the use of the Moreau envelope to build efficient and useful coarse corrections, fully adapted to solve problems in image restoration. Such a construction is derived for a broad class of composite optimization problems with proximable functions. We evaluate our approach on several image reconstruction problems, and we show that it considerably accelerates the convergence of the corresponding one-level (i.e., standard) version of the methods for large-scale images.},
  archive      = {J_SIIMS},
  author       = {Guillaume Lauga and Elisa Riccietti and Nelly Pustelnik and Paulo Gonçalves},
  doi          = {10.1137/23M1582345},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {9},
  number       = {3},
  pages        = {1347-1376},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {IML FISTA: A multilevel framework for inexact and inertial forward-backward. application to image restoration},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Training adaptive reconstruction networks for blind inverse
problems. <em>SIIMS</em>, <em>17</em>(2), 1314–1346. (<a
href="https://doi.org/10.1137/23M1545628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Neural networks allow solving many ill-posed inverse problems with unprecedented performance. Physics informed approaches already progressively replace carefully hand-crafted reconstruction algorithms in real applications. However, these networks suffer from a major defect: when trained on a given forward operator, they do not generalize well to a different one. The aim of this paper is twofold. First, we show through various applications that training the network with a family of forward operators allows solving the adaptivity problem without compromising the reconstruction quality significantly. Second, we illustrate that this training procedure allows tackling challenging blind inverse problems. Our experiments include partial Fourier sampling problems arising in magnetic resonance imaging with sensitivity estimation and off-resonance effects, computerized tomography with a tilted geometry, and image deblurring with Fresnel diffraction kernels.},
  archive      = {J_SIIMS},
  author       = {Alban Gossard and Pierre Weiss},
  doi          = {10.1137/23M1545628},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {1314-1346},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Training adaptive reconstruction networks for blind inverse problems},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Riesz feature representation: Scale equivariant scattering
network for classification tasks. <em>SIIMS</em>, <em>17</em>(2),
1284–1313. (<a href="https://doi.org/10.1137/23M1584836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Scattering networks yield powerful and robust hierarchical image descriptors which do not require lengthy training and which work well with very few training data. However, they rely on sampling the scale dimension. Hence, they become sensitive to scale variations and are unable to generalize to unseen scales. In this work, we define an alternative feature representation based on the Riesz transform. We detail and analyze the mathematical foundations behind this representation. In particular, it inherits scale equivariance from the Riesz transform and completely avoids sampling of the scale dimension. Additionally, the number of features in the representation is reduced by a factor four compared to scattering networks. Nevertheless, our representation performs comparably well for texture classification with an interesting addition: scale equivariance. Our method yields very good performance when dealing with scales outside of those covered by the training dataset. The usefulness of the equivariance property is demonstrated on the digit classification task, where accuracy remains stable even for scales four times larger than the one chosen for training. As a second example, we consider classification of textures. Finally, we show how this representation can be used to build hybrid deep learning methods that are more stable to scale variations than standard deep networks.},
  archive      = {J_SIIMS},
  author       = {Tin Barisin and Jesus Angulo and Katja Schladitz and Claudia Redenbach},
  doi          = {10.1137/23M1584836},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {1284-1313},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Riesz feature representation: Scale equivariant scattering network for classification tasks},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-lipschitz variational models and their iteratively
reweighted least squares algorithms for image denoising on surfaces.
<em>SIIMS</em>, <em>17</em>(2), 1255–1283. (<a
href="https://doi.org/10.1137/23M159439X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Image processing on surfaces has gotten increasing interest in recent years, and denoising is a basic problem in image processing. In this paper, we extend non-Lipschitz variational methods for 2D image denoising, including TV, to image denoising on surfaces. We establish a lower bound for nonzero gradients of the recovered image, implying the advantage of the models in recovering piecewise constant images. A new iteratively reweighted least squares algorithm with the thresholding and support shrinking strategy is proposed. The global convergence of the algorithm is established under the assumption that the object function is a Kurdyka–Łojasiewicz function. Numerical examples are given to show good performance of the algorithm.},
  archive      = {J_SIIMS},
  author       = {Yuan Liu and Chunlin Wu and Chao Zeng},
  doi          = {10.1137/23M159439X},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {1255-1283},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Non-lipschitz variational models and their iteratively reweighted least squares algorithms for image denoising on surfaces},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Marginal likelihood estimation in semiblind image
deconvolution: A stochastic approximation approach. <em>SIIMS</em>,
<em>17</em>(2), 1206–1254. (<a
href="https://doi.org/10.1137/23M1584496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper presents a novel stochastic optimization methodology to perform empirical Bayesian inference in semi-blind image deconvolution problems. Given a blurred image and a parametric class of possible operators, the proposed optimization approach automatically calibrates the parameters of the blur model by maximum marginal likelihood estimation, followed by (non-blind) image deconvolution by maximum a posteriori estimation conditionally to the estimated model parameters. In addition to the blur model, the proposed approach also automatically calibrates the noise level as well as any regularization parameters. The marginal likelihood of the blur, noise, and regularization parameters is generally computationally intractable, as it requires calculating several integrals over the entire solution space. Our approach addresses this difficulty by using a stochastic approximation proximal gradient optimization scheme, which iteratively solves such integrals by using a Moreau–Yosida regularized unadjusted Langevin Markov chain Monte Carlo algorithm. This optimization strategy can be easily and efficiently applied to any model that is log-concave and by using the same gradient and proximal operators that are required to compute the maximum a posteriori solution by convex optimization. We provide convergence guarantees for the proposed optimization scheme under realistic and easily verifiable conditions and subsequently demonstrate the effectiveness of the approach with a series of deconvolution experiments and comparisons with alternative strategies from the state of the art},
  archive      = {J_SIIMS},
  author       = {Charlesquin Kemajou Mbakam and Marcelo Pereyra and Jean-François Giovannelli},
  doi          = {10.1137/23M1584496},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {1206-1254},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Marginal likelihood estimation in semiblind image deconvolution: A stochastic approximation approach},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stable local-smooth principal component pursuit.
<em>SIIMS</em>, <em>17</em>(2), 1182–1205. (<a
href="https://doi.org/10.1137/23M1580164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Recently, the CTV-RPCA model proposed the first recoverable theory for separating low-rank and local-smooth matrices and sparse matrices based on the correlated total variation (CTV) regularizer. However, the CTV-RPCA model ignores the influence of noise, which makes the model unable to effectively extract low-rank and local-smooth principal components under noisy circumstances. To alleviate this issue, this article extends the CTV-RPCA model by considering the influence of noise and proposes two robust models with parameter adaptive adjustment, i.e., Stable Principal Component Pursuit based on CTV (CTV-SPCP) and Square Root Principal Component Pursuit based on CTV (CTV-). Furthermore, we present a statistical recoverable error bound for the proposed models, which allows us to know the relationship between the solution of the proposed models and the ground-truth. It is worth mentioning that, in the absence of noise, our theory degenerates back to the exact recoverable theory of the CTV-RPCA model. Finally, we develop the effective algorithms with the strict convergence guarantees. Extensive experiments adequately validate the theoretical assertions and also demonstrate the superiority of the proposed models over many state-of-the-art methods on various typical applications, including video foreground extraction, multispectral image denoising, and hyperspectral image denoising. The source code is released at https://github.com/andrew-pengjj/CTV-SPCP.},
  archive      = {J_SIIMS},
  author       = {Jiangjun Peng and Hailin Wang and Xiangyong Cao and Xixi Jia and Hongying Zhang and Deyu Meng},
  doi          = {10.1137/23M1580164},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {1182-1205},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Stable local-smooth principal component pursuit},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extrapolated plug-and-play three-operator splitting methods
for nonconvex optimization with applications to image restoration.
<em>SIIMS</em>, <em>17</em>(2), 1145–1181. (<a
href="https://doi.org/10.1137/23M1611166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper investigates the convergence properties and applications of the three-operator splitting method, also known as the Davis–Yin splitting (DYS) method, integrated with extrapolation and plug-and-play (PnP) denoiser within a nonconvex framework. We first propose an extrapolated DYS method to effectively solve a class of structural nonconvex optimization problems that involve minimizing the sum of three possibly nonconvex functions. Our approach provides an algorithmic framework that encompasses both extrapolated forward–backward splitting and extrapolated Douglas–Rachford splitting methods. To establish the convergence of the proposed method, we rigorously analyze its behavior based on the Kurdyka–Łojasiewicz property, subject to some tight parameter conditions. Moreover, we introduce two extrapolated PnP-DYS methods with convergence guarantee, where the traditional regularization step is replaced by a gradient step–based denoiser. This denoiser is designed using a differentiable neural network and can be reformulated as the proximal operator of a specific nonconvex functional. We conduct extensive experiments on image deblurring and image superresolution problems, where our numerical results showcase the advantage of the extrapolation strategy and the superior performance of the learning-based model that incorporates the PnP denoiser in terms of achieving high-quality recovery images.},
  archive      = {J_SIIMS},
  author       = {Zhongming Wu and Chaoyan Huang and Tieyong Zeng},
  doi          = {10.1137/23M1611166},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {1145-1181},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Extrapolated plug-and-play three-operator splitting methods for nonconvex optimization with applications to image restoration},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic variance reduced gradient for affine rank
minimization problem. <em>SIIMS</em>, <em>17</em>(2), 1118–1144. (<a
href="https://doi.org/10.1137/23M1555387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we develop an efficient stochastic variance reduced gradient descent algorithm to solve the affine rank minimization problem consisting of finding a matrix of minimum rank from linear measurements. The proposed algorithm as a stochastic gradient descent strategy enjoys a more favorable complexity than that using full gradients. It also reduces the variance of the stochastic gradient at each iteration and accelerates the rate of convergence. We prove that the proposed algorithm converges linearly in expectation to the solution under a restricted isometry condition. Numerical experimental results demonstrate that the proposed algorithm has a clear advantageous balance of efficiency, adaptivity, and accuracy compared with other state-of-the-art algorithms.},
  archive      = {J_SIIMS},
  author       = {Ningning Han and Juan Nie and Jian Lu and Michael K. Ng},
  doi          = {10.1137/23M1555387},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {1118-1144},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Stochastic variance reduced gradient for affine rank minimization problem},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerated bayesian imaging by relaxed proximal-point
langevin sampling. <em>SIIMS</em>, <em>17</em>(2), 1078–1117. (<a
href="https://doi.org/10.1137/23M1594832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper presents a new accelerated proximal Markov chain Monte Carlo methodology to perform Bayesian inference in imaging inverse problems with an underlying convex geometry. The proposed strategy takes the form of a stochastic relaxed proximal-point iteration that admits two complementary interpretations. For models that are smooth or regularized by Moreau–Yosida smoothing, the algorithm is equivalent to an implicit midpoint discretization of an overdamped Langevin diffusion targeting the posterior distribution of interest. This discretization is asymptotically unbiased for Gaussian targets and shown to converge in an accelerated manner for any target that is -strongly log-concave (i.e., requiring in the order of iterations to converge, similar to accelerated optimization schemes), comparing favorably to Pereyra, Vargas Mieles, and Zygalakis [SIAM J. Imaging Sci., 13 (2020), pp. 905–935], which is only provably accelerated for Gaussian targets and has bias. For models that are not smooth, the algorithm is equivalent to a Leimkuhler–Matthews discretization of a Langevin diffusion targeting a Moreau–Yosida approximation of the posterior distribution of interest and hence achieves a significantly lower bias than conventional unadjusted Langevin strategies based on the Euler–Maruyama discretization. For targets that are -strongly log-concave, the provided nonasymptotic convergence analysis also identifies the optimal time step, which maximizes the convergence speed. The proposed methodology is demonstrated through a range of experiments related to image deconvolution with Gaussian and Poisson noise with assumption-driven and data-driven convex priors. Source codes for the numerical experiments of this paper are available from https://github.com/MI2G/accelerated-langevin-imla.},
  archive      = {J_SIIMS},
  author       = {Teresa Klatzer and Paul Dobson and Yoann Altmann and Marcelo Pereyra and Jesus Maria Sanz-Serna and Konstantinos C. Zygalakis},
  doi          = {10.1137/23M1594832},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {1078-1117},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Accelerated bayesian imaging by relaxed proximal-point langevin sampling},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Total generalized variation on a tree. <em>SIIMS</em>,
<em>17</em>(2), 1040–1077. (<a
href="https://doi.org/10.1137/23M1556915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a class of optimization problems defined over trees with unary cost terms and shifted pairwise cost terms. These problems arise when considering block coordinate descent (BCD) approaches for solving inverse problems with total generalized variation (TGV) regularizers or their nonconvex generalizations. We introduce a linear-time reduction that transforms the shifted problems into their nonshifted counterparts. However, combining existing continuous dynamic programming (DP) algorithms with the reduction does not lead to BCD iterations that compute TGV-like solutions. This problem can be overcome by considering a box-constrained modification of the subproblems or smoothing the cost terms of the TGV regularized problem. The former leads to shifted and box-constrained subproblems, for which we propose a linear-time reduction to their unconstrained counterpart. The latter naturally leads to problems with smooth unary and pairwise cost terms. With this in mind, we propose two novel continuous DP algorithms that can solve (convex and nonconvex) problems with piecewise quadratic unary and pairwise cost terms. We prove that the algorithm for the convex case has quadratic worst-case time and memory complexity, while the algorithm for the nonconvex case has exponential time and memory complexity, but works well in practice for smooth truncated total variation pairwise costs. Finally, we demonstrate the applicability of the proposed algorithms for solving inverse problems with first-order and higher-order regularizers.},
  archive      = {J_SIIMS},
  author       = {Muhamed Kuric and Jan Ahmetspahic and Thomas Pock},
  doi          = {10.1137/23M1556915},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {1040-1077},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Total generalized variation on a tree},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assembling a learnable mumford–shah type model with
multigrid technique for image segmentation. <em>SIIMS</em>,
<em>17</em>(2), 1007–1039. (<a
href="https://doi.org/10.1137/23M1577663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The classical Mumford–Shah (MS) model has been successful in some medical image segmentation tasks, providing segmentation results with smooth boundaries of objects. However, the MS model, which operates at the pixel level of the images, faces challenges when dealing with medical images with low contrast or unclear edges. In this paper, we begin by using a feature extractor to capture high-dimensional deep features that contain more comprehensive semantic information than pixel-level data alone. Inspired by the MS model, we develop a variational model that incorporates threshold dynamics (TD) regularization for segmenting each feature. We obtain the final segmentation result for the original image by assembling segmentation results of all the features. This process results in MS-MGNet, a lightweight trainable segmentation network with a similar architecture to many encoder–decoder networks. The intermediate layers of MS-MGNet are designed by unrolling the numerical scheme based on the multigrid method for solving the variational model. We provide interpretability for the encoder–decoder architecture by elucidating the roles of each layer and offering explanations of the underlying mathematical models. By incorporating the TD regularizer, we integrate spatial priors from the variational models into the network architecture, resulting in better segmentation results with smoother edges and a certain robustness to noise. Compared to some relevant methods, experimental results on the selected data sets with low contrast or unclear edges show that the proposed method can achieve better segmentation performance with fewer parameters, even when trained on smaller data sets.},
  archive      = {J_SIIMS},
  author       = {Junying Meng and Weihong Guo and Jun Liu and Mingrui Yang},
  doi          = {10.1137/23M1577663},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {1007-1039},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Assembling a learnable Mumford–Shah type model with multigrid technique for image segmentation},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imaging with thermal noise induced currents. <em>SIIMS</em>,
<em>17</em>(2), 984–1006. (<a
href="https://doi.org/10.1137/23M1571630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We use thermal noise induced currents to image the real and imaginary parts of the conductivity of a body. Covariances of the thermal noise currents measured at a few electrodes are shown to be related to a deterministic problem. We use the covariances obtained while selectively heating the body to recover the real power density in the body under known boundary conditions and at a known frequency. The resulting inverse problem is related to acousto-electric tomography, but where the conductivity is complex and only the real power is measured. We study the local solvability of this problem by determining where its linearization is elliptic. Numerical experiments illustrating this inverse problem are included.},
  archive      = {J_SIIMS},
  author       = {Trent DeGiovanni and Fernando Guevara Vasquez and China Mauck},
  doi          = {10.1137/23M1571630},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {984-1006},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Imaging with thermal noise induced currents},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weighted spectral filters for kernel interpolation on
spheres: Estimates of prediction accuracy for noisy data.
<em>SIIMS</em>, <em>17</em>(2), 951–983. (<a
href="https://doi.org/10.1137/23M1585350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Spherical radial-basis-based kernel interpolation abounds in image sciences, including geophysical image reconstruction, climate trends description, and image rendering, due to its excellent spatial localization property and perfect approximation performance. However, in dealing with noisy data, kernel interpolation frequently behaves not so well due to the large condition number of the kernel matrix and instability of the interpolation process. In this paper, we introduce a weighted spectral filter approach to reduce the condition number of the kernel matrix and then stabilize kernel interpolation. The main building blocks of the proposed method are the well-developed spherical positive quadrature rules and high-pass spectral filters. Using a recently developed integral operator approach for spherical data analysis, we theoretically demonstrate that the proposed weighted spectral filter approach succeeds in breaking through the bottleneck of kernel interpolation, especially in fitting noisy data. We provide optimal approximation rates of the new method to show that our approach does not compromise the predicting accuracy. Furthermore, we conduct both toy simulations and two real-world data experiments with synthetically added noise in geophysical image reconstruction and climate image processing to verify our theoretical assertions and show the feasibility of the weighted spectral filter approach.},
  archive      = {J_SIIMS},
  author       = {Xiaotong Liu and Jinxin Wang and Di Wang and Shao-Bo Lin},
  doi          = {10.1137/23M1585350},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {951-983},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Weighted spectral filters for kernel interpolation on spheres: Estimates of prediction accuracy for noisy data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized nonconvex hyperspectral anomaly detection via
background representation learning with dictionary constraint.
<em>SIIMS</em>, <em>17</em>(2), 917–950. (<a
href="https://doi.org/10.1137/23M157363X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Anomaly detection in the hyperspectral images, which aims to separate interesting sparse anomalies from backgrounds, is a significant topic in remote sensing. In this paper, we propose a generalized nonconvex background representation learning with dictionary constraint (GNBRL) model for hyperspectral anomaly detection. Unlike existing methods that use a specific nonconvex function for a low rank term, GNBRL uses a class of nonconvex functions for both low rank and sparse terms simultaneously, which can better capture the low rank structure of the background and the sparsity of the anomaly. In addition, GNBRL simultaneously learns the dictionary and anomaly tensor in a unified framework by imposing a three-dimensional correlated total variation constraint on the dictionary tensor to enhance the quality of representation. An extrapolated linearized alternating direction method of multipliers (ELADMM) algorithm is then developed to solve the proposed GNBRL model. Finally, a novel coarse to fine two-stage framework is proposed to enhance the GNBRL model by exploiting the nonlocal similarity of the hyperspectral data. Theoretically, we establish an error bound for the GNBRL model and show that this error bound can be superior to those of similar models based on Tucker rank. We prove that the sequence generated by the proposed ELADMM algorithm converges to a Karush–Kuhn–Tucker point of the GNBRL model. This is a challenging task due to the nonconvexity of the objective function. Experiments on hyperspectral image datasets demonstrate that our proposed method outperforms several state-of-the-art methods in terms of detection accuracy.},
  archive      = {J_SIIMS},
  author       = {Quan Yu and Minru Bai},
  doi          = {10.1137/23M157363X},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {917-950},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Generalized nonconvex hyperspectral anomaly detection via background representation learning with dictionary constraint},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring structural sparsity of coil images from
3-dimensional directional tight framelets for SENSE reconstruction.
<em>SIIMS</em>, <em>17</em>(2), 888–916. (<a
href="https://doi.org/10.1137/23M1571150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Each coil image in a parallel magnetic resonance imaging (pMRI) system is an imaging slice modulated by the corresponding coil sensitivity. These coil images, structurally similar to each other, are stacked together as 3-dimensional (3D) image data, and their sparsity property can be explored via 3D directional Haar tight framelets. The features of the 3D image data from the 3D framelet systems are utilized to regularize sensitivity encoding (SENSE) pMRI reconstruction. Accordingly, a so-called SENSE3d algorithm is proposed to reconstruct images of high quality from the sampled -space data with a high acceleration rate by decoupling effects of the desired image (slice) and sensitivity maps. Since both the imaging slice and sensitivity maps are unknown, this algorithm repeatedly performs a slice step followed by a sensitivity step by using updated estimations of the desired image and the sensitivity maps. In the slice step, for the given sensitivity maps, the estimation of the desired image is viewed as the solution to a convex optimization problem regularized by the sparsity of its 3D framelet coefficients of coil images. This optimization problem, involving data from the complex field, is solved by a primal-dual three-operator splitting (PD3O) method. In the sensitivity step, the estimation of sensitivity maps is modeled as the solution to a Tikhonov-type optimization problem that favors the smoothness of the sensitivity maps. This corresponding problem is nonconvex and could be solved by a forward-backward splitting method. Experiments on real phantoms and in vivo data show that the proposed SENSE3d algorithm can explore the sparsity property of the imaging slices and efficiently produce reconstructed images of high quality with reduced aliasing artifacts caused by high acceleration rate, additive noise, and the inaccurate estimation of each coil sensitivity. To provide a comprehensive picture of the overall performance of our SENSE3d model, we provide the quantitative index (HaarPSI) and comparisons to some deep learning methods such as VarNet and fastMRI-UNet.},
  archive      = {J_SIIMS},
  author       = {Yanran Li and Raymond H. Chan and Lixin Shen and Xiaosheng Zhuang and Risheng Wu and Yijun Huang and Junwei Liu},
  doi          = {10.1137/23M1571150},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {888-916},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Exploring structural sparsity of coil images from 3-dimensional directional tight framelets for SENSE reconstruction},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sliding at first-order: Higher-order momentum distributions
for discontinuous image registration. <em>SIIMS</em>, <em>17</em>(2),
861–887. (<a href="https://doi.org/10.1137/23M1558665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose a new approach to deformable image registration that captures sliding motions. The large deformation diffeomorphic metric mapping (LDDMM) registration method faces challenges in representing sliding motion since it per construction generates smooth warps. To address this issue, we extend LDDMM by incorporating both zeroth- and first-order momenta with a nondifferentiable kernel. This allows us to represent both discontinuous deformation at switching boundaries and diffeomorphic deformation in homogeneous regions. We provide a mathematical analysis of the proposed deformation model from the viewpoint of discontinuous systems. To evaluate our approach, we conduct experiments on both artificial images and the publicly available DIR-Lab 4DCT dataset. Results show the effectiveness of our approach in capturing plausible sliding motion.},
  archive      = {J_SIIMS},
  author       = {Lili Bao and Jiahao Lu and Shihui Ying and Stefan Sommer},
  doi          = {10.1137/23M1558665},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {861-887},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Sliding at first-order: Higher-order momentum distributions for discontinuous image registration},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NF-ULA: Normalizing flow-based unadjusted langevin algorithm
for imaging inverse problems. <em>SIIMS</em>, <em>17</em>(2), 820–860.
(<a href="https://doi.org/10.1137/23M1581807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Bayesian methods for solving inverse problems are a powerful alternative to classical methods since the Bayesian approach offers the ability to quantify the uncertainty in the solution. In recent years, data-driven techniques for solving inverse problems have also been remarkably successful, due to their superior representation ability. In this work, we incorporate data-based models into a class of Langevin-based sampling algorithms for Bayesian inference in imaging inverse problems. In particular, we introduce NF-ULA (normalizing flow-based unadjusted Langevin algorithm), which involves learning a normalizing flow (NF) as the image prior. We use NF to learn the prior because a tractable closed-form expression for the log prior enables the differentiation of it using autograd libraries. Our algorithm only requires a normalizing flow-based generative network, which can be pretrained independently of the considered inverse problem and the forward operator. We perform theoretical analysis by investigating the well-posedness and nonasymptotic convergence of the resulting NF-ULA algorithm. The efficacy of the proposed NF-ULA algorithm is demonstrated in various image restoration problems such as image deblurring, image inpainting, and limited-angle X-ray computed tomography reconstruction. NF-ULA is found to perform better than competing methods for severely ill-posed inverse problems.},
  archive      = {J_SIIMS},
  author       = {Ziruo Cai and Junqi Tang and Subhadip Mukherjee and Jinglai Li and Carola-Bibiane Schönlieb and Xiaoqun Zhang},
  doi          = {10.1137/23M1581807},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {820-860},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {NF-ULA: Normalizing flow-based unadjusted langevin algorithm for imaging inverse problems},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Provably convergent plug-and-play quasi-newton methods.
<em>SIIMS</em>, <em>17</em>(2), 785–819. (<a
href="https://doi.org/10.1137/23M157185X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Plug-and-Play (PnP) methods are a class of efficient iterative methods that aim to combine data fidelity terms and deep denoisers using classical optimization algorithms, such as ISTA or ADMM, with applications in inverse problems and imaging. Provable PnP methods are a subclass of PnP methods with convergence guarantees, such as fixed point convergence or convergence to critical points of some energy function. Many existing provable PnP methods impose heavy restrictions on the denoiser or fidelity function, such as nonexpansiveness or strict convexity, respectively. In this work, we propose a novel algorithmic approach incorporating quasi-Newton steps into a provable PnP framework based on proximal denoisers, resulting in greatly accelerated convergence while retaining light assumptions on the denoiser. By characterizing the denoiser as the proximal operator of a weakly convex function, we show that the fixed points of the proposed quasi-Newton PnP algorithm are critical points of a weakly convex function. Numerical experiments on image deblurring and super-resolution demonstrate 2–8x faster convergence as compared to other provable PnP methods with similar reconstruction quality.},
  archive      = {J_SIIMS},
  author       = {Hong Ye Tan and Subhadip Mukherjee and Junqi Tang and Carola-Bibiane Schönlieb},
  doi          = {10.1137/23M157185X},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {6},
  number       = {2},
  pages        = {785-819},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Provably convergent plug-and-play quasi-newton methods},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A scale-invariant relaxation in low-rank tensor recovery
with an application to tensor completion. <em>SIIMS</em>,
<em>17</em>(1), 756–783. (<a
href="https://doi.org/10.1137/23M1560847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we consider a low-rank tensor recovery problem. Based on the tensor singular value decomposition (t-SVD), we propose the ratio of the tensor nuclear norm and the tensor Frobenius norm (TNF) as a novel nonconvex surrogate of tensor’s tubal rank. The rationale of the proposed model for enforcing a low-rank structure is analyzed as its theoretical properties. Specifically, we introduce a null space property (NSP) type condition, under which a low-rank tensor is a local minimum for the proposed TNF recovery model. Numerically, we consider a low-rank tensor completion problem as a specific application of tensor recovery and employ the alternating direction method of multipliers (ADMM) to secure a model solution with guaranteed subsequential convergence under mild conditions. Extensive experiments demonstrate the superiority of our proposed model over state-of-the-art methods.},
  archive      = {J_SIIMS},
  author       = {Huiwen Zheng and Yifei Lou and Guoliang Tian and Chao Wang},
  doi          = {10.1137/23M1560847},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {756-783},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A scale-invariant relaxation in low-rank tensor recovery with an application to tensor completion},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bijective density-equalizing quasiconformal map for multiply
connected open surfaces. <em>SIIMS</em>, <em>17</em>(1), 706–755. (<a
href="https://doi.org/10.1137/23M1594376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper proposes a novel method for computing bijective density-equalizing quasiconformal flattening maps for multiply connected open surfaces. In conventional density-equalizing maps, shape deformations are solely driven by prescribed constraints on the density distribution, defined as the population per unit area, while the bijectivity and local geometric distortions of the mappings are uncontrolled. Also, prior methods have primarily focused on simply connected open surfaces but not surfaces with more complicated topologies. Our proposed method overcomes these issues by formulating the density diffusion process as a quasiconformal flow, which allows us to effectively control the local geometric distortion and guarantee the bijectivity of the mapping by solving an energy minimization problem involving the Beltrami coefficient of the mapping. To achieve an optimal parameterization of multiply connected surfaces, we develop an iterative scheme that optimizes both the shape of the target planar circular domain and the density-equalizing quasiconformal map onto it. In addition, landmark constraints can be incorporated into our proposed method for consistent feature alignment. The method can also be naturally applied to simply connected open surfaces. By changing the prescribed population, a large variety of surface flattening maps with different desired properties can be achieved. The method is tested on both synthetic and real examples, demonstrating its efficacy in various applications in computer graphics and medical imaging.},
  archive      = {J_SIIMS},
  author       = {Zhiyuan Lyu and Gary P. T. Choi and Lok Ming Lui},
  doi          = {10.1137/23M1594376},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {706-755},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Bijective density-equalizing quasiconformal map for multiply connected open surfaces},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A boundary integral equation method for the complete
electrode model in electrical impedance tomography with tests on
experimental data. <em>SIIMS</em>, <em>17</em>(1), 672–705. (<a
href="https://doi.org/10.1137/23M1585696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop a boundary integral equation–based numerical method to solve for the electrostatic potential in two dimensions, inside a medium with piecewise constant conductivity, where the boundary condition is given by the complete electrode model (CEM). The CEM is seen as the most accurate model of the physical setting where electrodes are placed on the surface of an electrically conductive body, currents are injected through the electrodes, and the resulting voltages are measured again on these same electrodes. The integral equation formulation is based on expressing the electrostatic potential as the solution to a finite number of Laplace equations which are coupled through boundary matching conditions. This allows us to re-express the solution in terms of single-layer potentials; the problem is thus recast as a system of integral equations on a finite number of smooth curves. We discuss an adaptive method for the solution of the resulting system of mildly singular integral equations. This forward solver is both fast and accurate. We then present a numerical inverse solver for electrical impedance tomography which uses our forward solver at its core. To demonstrate the applicability of our results we test our numerical methods on an open electrical impedance tomography data set provided by the Finnish Inverse Problems Society.},
  archive      = {J_SIIMS},
  author       = {Teemu Tyni and Adam R. Stinchcombe and Spyros Alexakis},
  doi          = {10.1137/23M1585696},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {672-705},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A boundary integral equation method for the complete electrode model in electrical impedance tomography with tests on experimental data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polarimetric fourier phase retrieval. <em>SIIMS</em>,
<em>17</em>(1), 632–671. (<a
href="https://doi.org/10.1137/23M1570971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work introduces polarimetric Fourier phase retrieval (PPR), a physically inspired model to leverage polarization of light information in Fourier phase retrieval problems. We provide a complete characterization of its uniqueness properties by unraveling equivalencies with two related problems, namely, bivariate phase retrieval and a polynomial autocorrelation factorization problem. In particular, we show that the problem admits a unique solution, which can be formulated as a greatest common divisor (GCD) of measurement polynomials. As a result, we propose algebraic solutions for PPR based on approximate GCD computations using the null-space properties of Sylvester matrices. Alternatively, existing iterative algorithms for phase retrieval, semidefinite positive relaxation and Wirtinger flow, are carefully adapted to solve the PPR problem. Finally, a set of numerical experiments permits a detailed assessment of the numerical behavior and relative performances of each proposed reconstruction strategy. They further demonstrate the fruitful combination of algebraic and iterative approaches toward a scalable, computationally efficient, and robust to noise reconstruction strategy for PPR.},
  archive      = {J_SIIMS},
  author       = {Julien Flamant and Konstantin Usevich and Marianne Clausel and David Brie},
  doi          = {10.1137/23M1570971},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {632-671},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Polarimetric fourier phase retrieval},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Numerical implementation of generalized v-line transforms on
2D vector fields and their inversions. <em>SIIMS</em>, <em>17</em>(1),
595–631. (<a href="https://doi.org/10.1137/23M1573112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The paper discusses numerical implementations of various inversion schemes for generalized V-line transforms on vector fields introduced in [G. Ambartsoumian, M. J. Latifi, and R. K. Mishra, Inverse Problems, 36 (2020), 104002]. It demonstrates the possibility of efficient recovery of an unknown vector field from five different types of data sets, with and without noise. We examine the performance of the proposed algorithms in a variety of setups, and illustrate our results with numerical simulations on different phantoms.},
  archive      = {J_SIIMS},
  author       = {Gaik Ambartsoumian and Mohammad J. Latifi Jebelli and Rohit K. Mishra},
  doi          = {10.1137/23M1573112},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {595-631},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Numerical implementation of generalized V-line transforms on 2D vector fields and their inversions},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PottsMGNet: A mathematical explanation of encoder-decoder
based neural networks. <em>SIIMS</em>, <em>17</em>(1), 540–594. (<a
href="https://doi.org/10.1137/23M1586355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. For problems in image processing and many other fields, a large class of effective neural networks has encoder-decoder-based architectures. Although these networks have shown impressive performance, mathematical explanations of their architectures are still underdeveloped. In this paper, we study the encoder-decoder-based network architecture from the algorithmic perspective and provide a mathematical explanation. We use the two-phase Potts model for image segmentation as an example for our explanations. We associate the segmentation problem with a control problem in the continuous setting. Then, the continuous control model is time discretized by an operator-splitting scheme, the PottsMGNet, and space discretized by the multigrid method. We show that the resulting discrete PottsMGNet is equivalent to an encoder-decoder-based network. With minor modifications, it is shown that a number of the popular encoder-decoder-based neural networks are just instances of the proposed PottsMGNet. By incorporating the soft-threshold-dynamics into the PottsMGNet as a regularizer, the PottsMGNet has shown to be robust with the network parameters such as network width and depth and has achieved remarkable performance on datasets with very large noise. In nearly all our experiments, the new network always performs better than or as well as on accuracy and dice score compared to existing networks for image segmentation.},
  archive      = {J_SIIMS},
  author       = {Xue-Cheng Tai and Hao Liu and Raymond Chan},
  doi          = {10.1137/23M1586355},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {540-594},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {PottsMGNet: A mathematical explanation of encoder-decoder based neural networks},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning framework for diffeomorphic mapping problems
via quasi-conformal geometry applied to imaging. <em>SIIMS</em>,
<em>17</em>(1), 501–539. (<a
href="https://doi.org/10.1137/22M1516099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Many imaging problems can be formulated as mapping problems. A general mapping problem aims to obtain an optimal mapping that minimizes an energy functional subject to the given constraints. Existing methods to solve the mapping problems are often inefficient and can sometimes get trapped in local minima. An extra challenge arises when the optimal mapping is required to be diffeomorphic. In this work, we address the problem by proposing a deep-learning framework based on the Quasiconformal (QC) Teichmüller theories. The main strategy is to learn the Beltrami coefficient (BC) that represents a mapping as the latent feature vector in the deep neural network. The BC measures the local geometric distortion under the mapping, with which the interpretability of the deep neural network can be enhanced. Under this framework, the diffeomorphic property of the mapping can be controlled via a simple activation function within the network. The optimal mapping can also be easily regularized by integrating the BC into the loss function. A crucial advantage of the proposed framework is that once the network is successfully trained, the optimized mapping corresponding to each input data information can be obtained in real time. To examine the efficacy of the proposed framework, we apply the method to the diffeomorphic image registration problem. Experimental results outperform other state-of-the-art registration algorithms in both efficiency and accuracy, which demonstrate the effectiveness of our proposed framework to solve the mapping problem.},
  archive      = {J_SIIMS},
  author       = {Qiguang Chen and Zhiwen Li and Lok Ming Lui},
  doi          = {10.1137/22M1516099},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {501-539},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A deep learning framework for diffeomorphic mapping problems via quasi-conformal geometry applied to imaging},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fractional fourier transforms meet riesz potentials and
image processing. <em>SIIMS</em>, <em>17</em>(1), 476–500. (<a
href="https://doi.org/10.1137/23M1555442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Via chirp functions from fractional Fourier transforms, we introduce fractional Riesz potentials related to chirp functions, which are further used to give a new image encryption method with double phase coding. In a comparison with the image encryption method based on fractional Fourier transforms, via a series of image encryption and decryption experiments, we demonstrate that the symbols of fractional Riesz potentials related to chirp functions and the order of fractional Fourier transforms essentially provide greater flexibility and information security. We also establish the relations of fractional Riesz potentials related to chirp functions with fractional Fourier transforms, fractional Laplace operators, and fractional Riesz transforms, and we obtain their boundedness on rotation invariant spaces.},
  archive      = {J_SIIMS},
  author       = {Zunwei Fu and Yan Lin and Dachun Yang and Shuhui Yang},
  doi          = {10.1137/23M1555442},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {476-500},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Fractional fourier transforms meet riesz potentials and image processing},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learnable nonlocal self-similarity of deep features for
image denoising. <em>SIIMS</em>, <em>17</em>(1), 441–475. (<a
href="https://doi.org/10.1137/22M1536996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. High-dimensional deep features extracted by convolutional neural networks have nonlocal self-similarity. However, incorporating this nonlocal prior of deep features into deep network architectures with an interpretable variational framework is rarely explored. In this paper, we propose a learnable nonlocal self-similarity deep feature network for image denoising. Our method is motivated by the fact that the high-dimensional deep features obey a mixture probability distribution based on the Parzen–Rosenblatt window method. Then a regularizer with learnable nonlocal weights is proposed by considering the dual representation of the log-probability prior of the deep features. Specifically, the nonlocal weights are introduced as dual variables that can be learned by unrolling the associated numerical scheme. This leads to nonlocal modules (NLMs) in newly designed networks. Our method provides a statistical and variational interpretation for the nonlocal self-attention mechanism widely used in various networks. By adopting nonoverlapping window and region decomposition techniques, we can significantly reduce the computational complexity of nonlocal self-similarity, thus enabling parallel computation of the NLM. The solution to the proposed variational problem can be formulated as a learnable nonlocal self-similarity network for image denoising. This work offers a novel approach for constructing network structures that consider self-similarity and nonlocality. The improvements achieved by this method are predictable and partially controllable. Compared with several closely related denoising methods, the experimental results show the effectiveness of the proposed method in image denoising.},
  archive      = {J_SIIMS},
  author       = {Junying Meng and Faqiang Wang and Jun Liu},
  doi          = {10.1137/22M1536996},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {441-475},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Learnable nonlocal self-similarity of deep features for image denoising},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of view aliasing for the generalized radon
transform in <span
class="math inline">𝕣<sup><strong>2</strong></sup></span>.
<em>SIIMS</em>, <em>17</em>(1), 415–440. (<a
href="https://doi.org/10.1137/23M1554746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we consider the generalized Radon transform in the plane. Let be a piecewise smooth function, which has a jump across a smooth curve . We obtain a formula, which accurately describes view aliasing artifacts away from when is reconstructed from the data discretized in the view direction. The formula is asymptotic, it is established in the limit as the sampling rate . The proposed approach does not require that be band-limited. Numerical experiments with the classical Radon transform and generalized Radon transform (which integrates over circles) demonstrate the accuracy of the formula.},
  archive      = {J_SIIMS},
  author       = {Alexander Katsevich},
  doi          = {10.1137/23M1554746},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {415-440},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Analysis of view aliasing for the generalized radon transform in \({\mathbb r}^{\textbf{2}}\)},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The cortical v1 transform as a heterogeneous poisson
problem. <em>SIIMS</em>, <em>17</em>(1), 389–414. (<a
href="https://doi.org/10.1137/23M1555958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Receptive profiles of the primary visual cortex (V1) cortical cells are very heterogeneous and act by differentiating the stimulus image as operators changing from point to point. In this paper we aim to show that the distribution of cells in V1, although not complete to reconstruct the original image, is sufficient to reconstruct the perceived image with subjective constancy. We show that a color constancy image can be reconstructed as the solution of the associated inverse problem, which is a Poisson equation with heterogeneous differential operators. At the neural level the weights of short-range connectivity constitute the fundamental solution of the Poisson problem adapted point by point. A first demonstration of convergence of the result towards homogeneous reconstructions is proposed by means of homogenization techniques.},
  archive      = {J_SIIMS},
  author       = {Alessandro Sarti and Mattia Galeotti and Giovanna Citti},
  doi          = {10.1137/23M1555958},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {389-414},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {The cortical v1 transform as a heterogeneous poisson problem},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The <span
class="math inline"><strong>p</strong><sub><strong>0</strong></sub></span>-laplace
“signature” for quasilinear inverse problems. <em>SIIMS</em>,
<em>17</em>(1), 351–388. (<a
href="https://doi.org/10.1137/22M1527192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper refers to an imaging problem in the presence of nonlinear materials. Specifically, the problem we address falls within the framework of Electrical Resistance Tomography and involves two different materials, one or both of which are nonlinear. Tomography with nonlinear materials is in the early stages of development, although breakthroughs are expected in the not-too-distant future. The original contribution this work makes is that the nonlinear problem can be approximated by a weighted -Laplace problem. From the perspective of tomography, this is a significant result because it highlights the central role played by the -Laplacian in inverse problems with nonlinear materials. Moreover, when , this result allows all the imaging methods and algorithms developed for linear materials to be brought into the arena of problems with nonlinear materials. The main result of this work is that for “small” Dirichlet data, (i) one material can be replaced by a perfect electric conductor and (ii) the other material can be replaced by a material giving rise to a weighted -Laplace problem.},
  archive      = {J_SIIMS},
  author       = {Antonio Corbo Esposito and Luisa Faella and Gianpaolo Piscitelli and Vincenzo Mottola and Ravi Prakash and Antonello Tamburrino},
  doi          = {10.1137/22M1527192},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {351-388},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {The \(\boldsymbol{{p}_0}\)-laplace “Signature” for quasilinear inverse problems},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Reduced order modeling inversion of monostatic data in a
multi-scattering environment. <em>SIIMS</em>, <em>17</em>(1), 334–350.
(<a href="https://doi.org/10.1137/23M1564365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Data-driven reduced order models (ROMs) have recently emerged as an efficient tool for the solution of inverse scattering problems with applications to seismic and sonar imaging. One requirement of this approach is that it uses the full square multiple-input/multiple-output (MIMO) matrix-valued transfer function as the data for multidimensional problems. The synthetic aperture radar (SAR), however, is limited to the single-input/single-output (SISO) measurements corresponding to the diagonal of the matrix transfer function. Here we present a ROM-based Lippmann–Schwinger approach overcoming this drawback. The ROMs are constructed to match the data for each source-receiver pair separately, and these are used to construct internal solutions for the corresponding source using only the data-driven Gramian. Efficiency of the proposed approach is demonstrated on 2D and 2.5D (3D propagation and 2D reflectors) numerical examples. The new algorithm not only suppresses multiple echoes seen in the Born imaging but also takes advantage of their illumination of some back sides of the reflectors, improving the quality of their mapping.},
  archive      = {J_SIIMS},
  author       = {Vladimir Druskin and Shari Moskow and Mikhail Zaslavsky},
  doi          = {10.1137/23M1564365},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {334-350},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Reduced order modeling inversion of monostatic data in a multi-scattering environment},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Posterior-variance–based error quantification for inverse
problems in imaging. <em>SIIMS</em>, <em>17</em>(1), 301–333. (<a
href="https://doi.org/10.1137/23M1546129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, a method for obtaining pixelwise error bounds in Bayesian regularization of inverse imaging problems is introduced. The proposed method employs estimates of the posterior variance together with techniques from conformal prediction in order to obtain coverage guarantees for the error bounds, without making any assumption on the underlying data distribution. It is generally applicable to Bayesian regularization approaches, independent, e.g., of the concrete choice of the prior. Furthermore, the coverage guarantees can also be obtained in case only approximate sampling from the posterior is possible. With this in particular, the proposed framework is able to incorporate any learned prior in a black-box manner. Guaranteed coverage without assumptions on the underlying distributions is only achievable since the magnitude of the error bounds is, in general, unknown in advance. Nevertheless, experiments with multiple regularization approaches presented in the paper confirm that, in practice, the obtained error bounds are rather tight. For realizing the numerical experiments, a novel primal-dual Langevin algorithm for sampling from nonsmooth distributions is also introduced in this work, showing promising results in practice. While a proof of convergence for this primal-dual algorithm is still open, the theoretical guarantees of the proposed method do not require a guaranteed convergence of the sampling algorithm.},
  archive      = {J_SIIMS},
  author       = {Dominik Narnhofer and Andreas Habring and Martin Holler and Thomas Pock},
  doi          = {10.1137/23M1546129},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {301-333},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Posterior-Variance–Based error quantification for inverse problems in imaging},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A majorization-minimization algorithm for neuroimage
registration. <em>SIIMS</em>, <em>17</em>(1), 273–300. (<a
href="https://doi.org/10.1137/22M1516907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Intensity-based image registration is critical for neuroimaging tasks, such as 3D reconstruction, times-series alignment, and common coordinate mapping. The gradient-based optimization methods commonly used to solve this problem require a careful selection of step-length. This limitation imposes substantial time and computational costs. Here we propose a gradient-independent rigid-motion registration algorithm based on the majorization-minimization (MM) principle. Each iteration of our intensity-based MM algorithm reduces to a simple point-set rigid registration problem with a closed form solution that avoids the step-length issue altogether. The details of the algorithm are presented, and an error bound for its more practical truncated form is derived. The performance of the MM algorithm is shown to be more effective than gradient descent on simulated images and Nissl stained coronal slices of mouse brain. We also compare and contrast the similarities and differences between the MM algorithm and another gradient-free registration algorithm called the block-matching method. Finally, extensions of this algorithm to more complex problems are discussed.},
  archive      = {J_SIIMS},
  author       = {Gaiting Zhou and Daniel Tward and Kenneth Lange},
  doi          = {10.1137/22M1516907},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {273-300},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A majorization-minimization algorithm for neuroimage registration},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image segmentation using bayesian inference for convex
variant mumford–shah variational model. <em>SIIMS</em>, <em>17</em>(1),
248–272. (<a href="https://doi.org/10.1137/23M1545379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Mumford–Shah model is a classical segmentation model, but its objective function is nonconvex. The smoothing and thresholding (SaT) approach is a convex variant of the Mumford–Shah model, which seeks a smoothed approximation solution to the Mumford–Shah model. The SaT approach separates the segmentation into two stages: first, a convex energy function is minimized to obtain a smoothed image; then, a thresholding technique is applied to segment the smoothed image. The energy function consists of three weighted terms and the weights are called the regularization parameters. Selecting appropriate regularization parameters is crucial to achieving effective segmentation results. Traditionally, the regularization parameters are chosen by trial-and-error, which is a very time-consuming procedure and is not practical in real applications. In this paper, we apply a Bayesian inference approach to infer the regularization parameters and estimate the smoothed image. We analyze the convex variant Mumford–Shah variational model from a statistical perspective and then construct a hierarchical Bayesian model. A mean field variational family is used to approximate the posterior distribution. The variational density of the smoothed image is assumed to have a Gaussian density, and the hyperparameters are assumed to have Gamma variational densities. All the parameters in the Gaussian density and Gamma densities are iteratively updated. Experimental results show that the proposed approach is capable of generating high-quality segmentation results. Although the proposed approach contains an inference step to estimate the regularization parameters, it requires less CPU running time to obtain the smoothed image than previous methods.},
  archive      = {J_SIIMS},
  author       = {Xu Xiao and Youwei Wen and Raymond Chan and Tieyong Zeng},
  doi          = {10.1137/23M1545379},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {248-272},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Image segmentation using bayesian inference for convex variant Mumford–Shah variational model},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust tensor CUR decompositions: Rapid low-tucker-rank
tensor recovery with sparse corruptions. <em>SIIMS</em>, <em>17</em>(1),
225–247. (<a href="https://doi.org/10.1137/23M1574282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the tensor robust principal component analysis (TRPCA) problem, a tensorial extension of matrix robust principal component analysis, which aims to split the given tensor into an underlying low-rank component and a sparse outlier component. This work proposes a fast algorithm, called robust tensor CUR decompositions (RTCUR), for large-scale nonconvex TRPCA problems under the Tucker rank setting. RTCUR is developed within a framework of alternating projections that projects between the set of low-rank tensors and the set of sparse tensors. We utilize the recently developed tensor CUR decomposition to substantially reduce the computational complexity in each projection. In addition, we develop four variants of RTCUR for different application settings. We demonstrate the effectiveness and computational advantages of RTCUR against state-of-the-art methods on both synthetic and real-world datasets.},
  archive      = {J_SIIMS},
  author       = {HanQin Cai and Zehan Chao and Longxiu Huang and Deanna Needell},
  doi          = {10.1137/23M1574282},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {225-247},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Robust tensor CUR decompositions: Rapid low-tucker-rank tensor recovery with sparse corruptions},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Direct imaging methods for reconstructing a locally rough
interface from phaseless total-field data or phased far-field data.
<em>SIIMS</em>, <em>17</em>(1), 188–224. (<a
href="https://doi.org/10.1137/23M1571393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is concerned with the problem of inverse scattering of time-harmonic acoustic plane waves by a two-layered medium with a locally rough interface in two dimensions. A direct imaging method is proposed to reconstruct the locally rough interface from the phaseless total-field data measured on the upper half of the circle with a large radius at a fixed frequency or from the phased far-field data measured on the upper half of the unit circle at a fixed frequency. The presence of the locally rough interface poses challenges in the theoretical analysis of the imaging methods. To address these challenges, a technically involved asymptotic analysis is provided for the relevant oscillatory integrals involved in the imaging methods, based mainly on the techniques and results in our recent work [L. Li, J. Yang, B. Zhang, and H. Zhang, arXiv:2208.00456, 2022] on the uniform far-field asymptotics of the scattered field for acoustic scattering in a two-layered medium. Finally, extensive numerical experiments are conducted to demonstrate the feasibility and robustness of our imaging algorithms.},
  archive      = {J_SIIMS},
  author       = {Long Li and Jiansheng Yang and Bo Zhang and Haiwen Zhang},
  doi          = {10.1137/23M1571393},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {188-224},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Direct imaging methods for reconstructing a locally rough interface from phaseless total-field data or phased far-field data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conductivity imaging from internal measurements with mixed
least-squares deep neural networks. <em>SIIMS</em>, <em>17</em>(1),
147–187. (<a href="https://doi.org/10.1137/23M1562536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we develop a novel approach using deep neural networks (DNNs) to reconstruct the conductivity distribution in elliptic problems from one measurement of the solution over the whole domain. The approach is based on a mixed reformulation of the governing equation and utilizes the standard least-squares objective, with DNNs as ansatz functions to approximate the conductivity and flux simultaneously. We provide a thorough analysis of the DNN approximations of the conductivity for both continuous and empirical losses, including rigorous error estimates that are explicit in terms of the noise level, various penalty parameters, and neural network architectural parameters (depth, width, and parameter bounds). We also provide multiple numerical experiments in two dimensions and multidimensions to illustrate distinct features of the approach, e.g., excellent stability with respect to data noise and capability of solving high-dimensional problems.},
  archive      = {J_SIIMS},
  author       = {Bangti Jin and Xiyao Li and Qimeng Quan and Zhi Zhou},
  doi          = {10.1137/23M1562536},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {147-187},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Conductivity imaging from internal measurements with mixed least-squares deep neural networks},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polynomial preconditioners for regularized linear inverse
problems. <em>SIIMS</em>, <em>17</em>(1), 116–146. (<a
href="https://doi.org/10.1137/22M1530355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work aims to accelerate the convergence of proximal gradient methods used to solve regularized linear inverse problems. This is achieved by designing a polynomial-based preconditioner that targets the eigenvalue spectrum of the normal operator derived from the linear operator. The preconditioner does not assume any explicit structure on the linear function and thus can be deployed in diverse applications of interest. The efficacy of the preconditioner is validated on three different Magnetic Resonance Imaging applications, where it is seen to achieve faster iterative convergence (around faster, depending on the application of interest) while achieving similar reconstruction quality.},
  archive      = {J_SIIMS},
  author       = {Siddharth S. Iyer and Frank Ong and Xiaozhi Cao and Congyu Liao and Luca Daniel and Jonathan I. Tamir and Kawin Setsompop},
  doi          = {10.1137/22M1530355},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {116-146},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Polynomial preconditioners for regularized linear inverse problems},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning weakly convex regularizers for convergent
image-reconstruction algorithms. <em>SIIMS</em>, <em>17</em>(1), 91–115.
(<a href="https://doi.org/10.1137/23M1565243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose to learn non-convex regularizers with a prescribed upper bound on their weak-convexity modulus. Such regularizers give rise to variational denoisers that minimize a convex energy. They rely on few parameters (less than 15,000) and offer a signal-processing interpretation as they mimic handcrafted sparsity-promoting regularizers. Through numerical experiments, we show that such denoisers outperform convex-regularization methods as well as the popular BM3D denoiser. Additionally, the learned regularizer can be deployed to solve inverse problems with iterative schemes that provably converge. For both CT and MRI reconstruction, the regularizer generalizes well and offers an excellent tradeoff between performance, number of parameters, guarantees, and interpretability when compared to other data-driven approaches.},
  archive      = {J_SIIMS},
  author       = {Alexis Goujon and Sebastian Neumayer and Michael Unser},
  doi          = {10.1137/23M1565243},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {91-115},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Learning weakly convex regularizers for convergent image-reconstruction algorithms},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identification of sparsely representable diffusion
parameters in elliptic problems. <em>SIIMS</em>, <em>17</em>(1), 61–90.
(<a href="https://doi.org/10.1137/23M1565346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the task of estimating the unknown diffusion parameter in an elliptic PDE as a model problem to develop and test the effectiveness and robustness to noise of reconstruction schemes with sparsity regularization. To this end, the model problem is recast as a nonlinear infinite dimensional optimization problem, where the logarithm of the unknown diffusion parameter is modeled using a linear combination of the elements of a dictionary, i.e., a known bounded sequence of functions, with unknown coefficients that form a sequence in . We show that the regularization of this nonlinear optimization problem using a weighted -norm has minimizers that are finitely supported. We then propose modifications of well-known algorithms (ISTA and FISTA) to find a minimizer of this weighted -norm regularized nonlinear optimization problem that accounts for the fact that in general the smooth part of the functional being optimized is a functional only defined over . We also introduce semismooth methods (ASISTA and FASISTA) for finding a minimizer, which locally uses Gauss–Newton type surrogate models that additionally are stabilized by means of a Levenberg–Marquardt type approach. Our numerical examples show that the regularization with the weighted -norm indeed does make the estimation more robust with respect to noise. Moreover, the numerical examples also demonstrate that the ASISTA and FASISTA methods are quite efficient, outperforming both ISTA and FISTA.},
  archive      = {J_SIIMS},
  author       = {Luzia N. Felber and Helmut Harbrecht and Marc Schmidlin},
  doi          = {10.1137/23M1565346},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {61-90},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Identification of sparsely representable diffusion parameters in elliptic problems},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning sparsity-promoting regularizers using bilevel
optimization. <em>SIIMS</em>, <em>17</em>(1), 31–60. (<a
href="https://doi.org/10.1137/22M1506547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a gradient-based heuristic method for supervised learning of sparsity-promoting regularizers for denoising signals and images. Sparsity-promoting regularization is a key ingredient in solving modern signal reconstruction problems; however, the operators underlying these regularizers are usually either designed by hand or learned from data in an unsupervised way. The recent success of supervised learning (e.g., with convolutional neural networks) in solving image reconstruction problems suggests that it could be a fruitful approach to designing regularizers. Towards this end, we propose to denoise signals using a variational formulation with a parametric, sparsity-promoting regularizer, where the parameters of the regularizer are learned to minimize the mean squared error of reconstructions on a training set of ground truth image and measurement pairs. Training involves solving a challenging bilevel optimization problem; we derive an expression for the gradient of the training loss using the closed-form solution of the denoising problem and provide an accompanying gradient descent algorithm to minimize it. Our experiments with structured 1D signals and natural images indicate that the proposed method can learn an operator that outperforms well-known regularizers (total variation, DCT-sparsity, and unsupervised dictionary learning) and collaborative filtering for denoising.},
  archive      = {J_SIIMS},
  author       = {Avrajit Ghosh and Michael McCann and Madeline Mitchell and Saiprasad Ravishankar},
  doi          = {10.1137/22M1506547},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {31-60},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {Learning sparsity-promoting regularizers using bilevel optimization},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A variational model for nonuniform low-light image
enhancement. <em>SIIMS</em>, <em>17</em>(1), 1–30. (<a
href="https://doi.org/10.1137/22M1543161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Low-light image enhancement plays an important role in computer vision applications, which is a fundamental low-level task and can affect high-level computer vision tasks. To solve this ill-posed problem, a lot of methods have been proposed to enhance low-light images. However, their performance degrades significantly under nonuniform lighting conditions. Due to the rapid variation of illuminance in different regions in natural images, it is challenging to enhance low-light parts and retain normal-light parts simultaneously in the same image. Commonly, either the low-light parts are underenhanced or the normal-light parts are overenhanced, accompanied by color distortion and artifacts. To overcome this problem, we propose a simple and effective Retinex-based model with reflectance map reweighting for images under nonuniform lighting conditions. An alternating proximal gradient (APG) algorithm is proposed to solve the proposed model, in which the illumination map, the reflectance map, and the weighting map are updated iteratively. To make our model applicable to a wide range of light conditions, we design an initialization scheme for the weighting map. A theoretical analysis of the existence of the solution to our model and the convergence of the APG algorithm are also established. A series of experiments on real-world low-light images are conducted, which demonstrate the effectiveness of our method.},
  archive      = {J_SIIMS},
  author       = {Fan Jia and Shen Mao and Xue-Cheng Tai and Tieyong Zeng},
  doi          = {10.1137/22M1543161},
  journal      = {SIAM Journal on Imaging Sciences},
  month        = {3},
  number       = {1},
  pages        = {1-30},
  shortjournal = {SIAM J. Imaging Sci.},
  title        = {A variational model for nonuniform low-light image enhancement},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
