<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SIOPT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="siopt---138">SIOPT - 138</h2>
<ul>
<li><details>
<summary>
(2024). Convergence rate of random scan coordinate ascent
variational inference under log-concavity. <em>SIOPT</em>,
<em>34</em>(4), 3750–3761. (<a
href="https://doi.org/10.1137/24M1670627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Coordinate Ascent Variational Inference scheme is a popular algorithm used to compute the mean-field approximation of a probability distribution of interest. We analyze its random scan version, under log-concavity assumptions on the target density. Our approach builds on the recent work of Arnese and Lacker, [M. Arnese and D. Lacker, Convergence of Coordinate Ascent Variational Inference for Log-Concave Measures via Optimal Transport, preprint, arXiv:2404.08792, 2024], which studies the deterministic scan version of the algorithm, phrasing it as a block-coordinate descent algorithm in the space of probability distributions endowed with the geometry of optimal transport. We obtain tight rates for the random scan version, which imply that the total number of factor updates required to converge scales linearly with the condition number and the number of blocks of the target distribution. By contrast, available bounds for the deterministic scan case scale quadratically in the same quantities, which is analogous to what happens for optimization of convex functions in Euclidean spaces.},
  archive      = {J_SIOPT},
  author       = {Hugo Lavenant and Giacomo Zanella},
  doi          = {10.1137/24M1670627},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3750-3761},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence rate of random scan coordinate ascent variational inference under log-concavity},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The computation of approximate feedback stackelberg
equilibria in multiplayer nonlinear constrained dynamic games.
<em>SIOPT</em>, <em>34</em>(4), 3723–3749. (<a
href="https://doi.org/10.1137/24M1634709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Solving feedback Stackelberg games with nonlinear dynamics and coupled constraints, a common scenario in practice, presents significant challenges. This work introduces an efficient method for computing approximate local feedback Stackelberg equilibria in multiplayer general-sum dynamic games, with continuous state and action spaces. Different from existing (approximate) dynamic programming solutions that are primarily designed for unconstrained problems, our approach involves reformulating a feedback Stackelberg dynamic game into a sequence of nested optimization problems, enabling the derivation of Karush–Kuhn–Tucker (KKT) conditions and the establishment of a second-order sufficient condition for local feedback Stackelberg equilibria. We propose a Newton-style primal-dual interior point method for solving constrained linear quadratic (LQ) feedback Stackelberg games, offering provable convergence guarantees. Our method is further extended to compute local feedback Stackelberg equilibria for more general nonlinear games by iteratively approximating them using LQ games, ensuring that their KKT conditions are locally aligned with those of the original nonlinear games. We prove the exponential convergence of our algorithm in constrained nonlinear games. In a feedback Stackelberg game with nonlinear dynamics and (nonconvex) coupled costs and constraints, our experimental results reveal the algorithm’s ability to handle infeasible initial conditions and achieve exponential convergence toward an approximate local feedback Stackelberg equilibrium.},
  archive      = {J_SIOPT},
  author       = {Jingqi Li and Somayeh Sojoudi and Claire J. Tomlin and David Fridovich-Keil},
  doi          = {10.1137/24M1634709},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3723-3749},
  shortjournal = {SIAM J. Optim.},
  title        = {The computation of approximate feedback stackelberg equilibria in multiplayer nonlinear constrained dynamic games},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uniform weak sharp minima for multiobjective optimization
problems. <em>SIOPT</em>, <em>34</em>(4), 3699–3722. (<a
href="https://doi.org/10.1137/23M1628012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Noting that there exist abnormal phenomena in the existing weak sharp minima for multiobjective optimization problems, this paper introduces and studies uniform weak sharp minima for the multiobjective optimization problem. We first provide several characterizations for a piecewise linear multiobjective optimization problem with respect to the natural vector partial order induced by to have uniform weak sharp minima. Under a mild assumption, a piecewise linear multiobjective optimization problem with respect to an arbitrary vector partial order is proved to be equivalent to a piecewise linear multiobjective optimization problem with respect to the natural vector partial order. Based on such an interesting equivalence, this paper mainly establishes the uniform bounded and global weak sharp minima for a general piecewise linear multiobjective optimization problem with respect to any vector partial order.},
  archive      = {J_SIOPT},
  author       = {Chunhai Hu and Xiaoqi Yang and Xi Yin Zheng},
  doi          = {10.1137/23M1628012},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3699-3722},
  shortjournal = {SIAM J. Optim.},
  title        = {Uniform weak sharp minima for multiobjective optimization problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Superlinear convergence of a semismooth newton method for
some optimization problems with applications to control theory.
<em>SIOPT</em>, <em>34</em>(4), 3681–3698. (<a
href="https://doi.org/10.1137/24M1644286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we formulate a semismooth Newton method for an abstract optimization problem and prove its superlinear convergence by assuming that the no-gap second order sufficient optimality condition and the strict complementarity condition are fulfilled at the local minimizer. Many control problems fit this abstract formulation. In particular, we apply this abstract result to distributed control problems of a semilinear elliptic equation, to boundary bilinear control problems associated with a semilinear elliptic equation, and to distributed control of a semilinear parabolic equation.},
  archive      = {J_SIOPT},
  author       = {Eduardo Casas},
  doi          = {10.1137/24M1644286},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3681-3698},
  shortjournal = {SIAM J. Optim.},
  title        = {Superlinear convergence of a semismooth newton method for some optimization problems with applications to control theory},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive consensus: A network pruning approach for
decentralized optimization. <em>SIOPT</em>, <em>34</em>(4), 3653–3680.
(<a href="https://doi.org/10.1137/23M1599379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider network-based decentralized optimization problems, where each node in the network possesses a local function and the objective is to collectively attain a consensus solution that minimizes the sum of all the local functions. A major challenge in decentralized optimization is the reliance on communication, which remains a considerable bottleneck in many applications. To address this challenge, we propose an adaptive randomized communication-efficient algorithmic framework that reduces the volume of communication by periodically tracking the disagreement error and judiciously selecting the most influential and effective edges at each node for communication. Within this framework, we present two algorithms: adaptive consensus (AC) to solve the consensus problem and adaptive consensus-based gradient tracking (AC-GT) to solve smooth strongly convex decentralized optimization problems. We establish strong theoretical convergence guarantees for the proposed algorithms and quantify their performance in terms of various algorithmic parameters under standard assumptions. Finally, numerical experiments showcase the effectiveness of the framework in significantly reducing the information exchange required to achieve a consensus solution.},
  archive      = {J_SIOPT},
  author       = {Suhail M. Shah and Albert S. Berahas and Raghu Bollapragada},
  doi          = {10.1137/23M1599379},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3653-3680},
  shortjournal = {SIAM J. Optim.},
  title        = {Adaptive consensus: A network pruning approach for decentralized optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An exact method for nonlinear network flow interdiction
problems. <em>SIOPT</em>, <em>34</em>(4), 3623–3652. (<a
href="https://doi.org/10.1137/22M152983X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study network flow interdiction problems with nonlinear and nonconvex flow models. The resulting model is a max-min bilevel optimization problem in which the follower’s problem is nonlinear and nonconvex. In this game, the leader attacks a limited number of arcs with the goal of maximizing the load shed, and the follower aims at minimizing the load shed by solving a transport problem in the interdicted network. We develop an exact algorithm consisting of lower and upper bounding schemes that computes an optimal interdiction under the assumption that the interdicted network remains weakly connected. The main challenge consists of computing valid upper bounds for the maximal load shed, whereas lower bounds can directly be derived from the follower’s problem. To compute an upper bound, we propose solving a specific bilevel problem, which is derived from restricting the flexibility of the follower when adjusting the load flow. This bilevel problem still has a nonlinear and nonconvex follower’s problem, for which we then prove necessary and sufficient optimality conditions. Consequently, we obtain equivalent single-level reformulations of the specific bilevel model to compute upper bounds. Our numerical results show the applicability of this exact approach using the example of gas networks.},
  archive      = {J_SIOPT},
  author       = {Martin Schmidt and Johannes Thürauf},
  doi          = {10.1137/22M152983X},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3623-3652},
  shortjournal = {SIAM J. Optim.},
  title        = {An exact method for nonlinear network flow interdiction problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sequential quadratic optimization for stochastic
optimization with deterministic nonlinear inequality and equality
constraints. <em>SIOPT</em>, <em>34</em>(4), 3592–3622. (<a
href="https://doi.org/10.1137/23M1556149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A sequential quadratic optimization algorithm for minimizing an objective function defined by an expectation subject to nonlinear inequality and equality constraints is proposed, analyzed, and tested. The context of interest is when it is tractable to evaluate constraint function and derivative values in each iteration, but it is intractable to evaluate the objective function or its derivatives in any iteration, and instead, an algorithm can only make use of stochastic objective gradient estimates. Under loose assumptions, including that the gradient estimates are unbiased, the algorithm is proved to possess convergence guarantees in expectation. The results of numerical experiments are presented to demonstrate that the proposed algorithm can outperform an alternative approach that relies on the ability to compute more accurate gradient estimates and can outperform a stochastic algorithm that employs a penalty method to enforce the constraints.},
  archive      = {J_SIOPT},
  author       = {Frank E. Curtis and Daniel P. Robinson and Baoyu Zhou},
  doi          = {10.1137/23M1556149},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3592-3622},
  shortjournal = {SIAM J. Optim.},
  title        = {Sequential quadratic optimization for stochastic optimization with deterministic nonlinear inequality and equality constraints},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solution of mismatched monotone+lipschitz inclusion
problems. <em>SIOPT</em>, <em>34</em>(4), 3564–3591. (<a
href="https://doi.org/10.1137/23M1609166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this article, we study the convergence of algorithms for solving monotone inclusions in the presence of adjoint mismatch. The adjoint mismatch arises when the adjoint of a linear operator is replaced by an approximation, due to computational or physical issues. This occurs in inverse problems, particularly in computed tomography. In real Hilbert spaces, monotone inclusion problems involving a maximally -monotone operator, a cocoercive operator, and a Lipschitzian operator can be solved by the forward-backward-half-forward and the forward-Douglas–Rachford-forward methods. We investigate the case of a mismatched Lipschitzian operator. We propose variants of the two aforementioned methods to cope with the mismatch, and establish conditions under which the weak convergence to a solution is guaranteed for these variants. The proposed algorithms hence enable each iteration to be implemented with a possibly iteration-dependent approximation to the mismatch operator, thus allowing this operator to be modified at each iteration. Finally, we present numerical experiments on a computed tomography example in material science, showing the applicability of our theoretical findings.},
  archive      = {J_SIOPT},
  author       = {Emilie Chouzenoux and Jean-Christophe Pesquet and Fernando Roldán},
  doi          = {10.1137/23M1609166},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3564-3591},
  shortjournal = {SIAM J. Optim.},
  title        = {Solution of mismatched Monotone+Lipschitz inclusion problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PolyCD: Optimization via cycling through the vertices of a
polytope. <em>SIOPT</em>, <em>34</em>(4), 3534–3563. (<a
href="https://doi.org/10.1137/23M1558975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the minimization of a convex function over a bounded polyhedral constraint set where the number of vertices of the polyhedron is not too large such as the -ball and the standard simplex. We propose an algorithm that cycles through the vertices of the polyhedron—for every vertex, it minimizes the function along a line connecting the current iterate and that vertex. Loosely speaking, viewing the extreme points as “coordinates” of the polytope, our algorithm has some similarities with cyclic coordinate descent, and the Frank–Wolfe algorithm. We prove that our algorithm has an convergence rate for smooth convex objectives, where denotes the number of iterations. Inspired by the away-step Frank–Wolfe method, we propose a variant of our algorithm with away steps having a linear convergence rate when the loss function is smooth and strongly convex. Empirical studies demonstrate that our algorithm achieves strong computational performance for various common problems including -constrained linear regression, -constrained logistic regression, and kernel density estimation.},
  archive      = {J_SIOPT},
  author       = {Rahul Mazumder and Haoyue Wang},
  doi          = {10.1137/23M1558975},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3534-3563},
  shortjournal = {SIAM J. Optim.},
  title        = {PolyCD: Optimization via cycling through the vertices of a polytope},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sample average approximation for stochastic programming with
equality constraints. <em>SIOPT</em>, <em>34</em>(4), 3506–3533. (<a
href="https://doi.org/10.1137/23M1573227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We revisit the sample average approximation (SAA) approach for nonconvex stochastic programming. We show that applying the SAA approach to problems with expected value equality constraints does not necessarily result in asymptotic optimality guarantees as the sample size increases. To address this issue, we relax the equality constraints. Then, we prove the asymptotic optimality of the modified SAA approach under mild smoothness and boundedness conditions on the equality constraint functions. Our analysis uses random set theory and concentration inequalities to characterize the approximation error from the sampling procedure. We apply our approach and analysis to the problem of stochastic optimal control for nonlinear dynamical systems under external disturbances modeled by a Wiener process. Numerical results on relevant stochastic programs show the reliability of the proposed approach. Results on a rocket-powered descent problem show that our computed solutions allow for significant uncertainty reduction compared to a deterministic baseline.},
  archive      = {J_SIOPT},
  author       = {Thomas Lew and Riccardo Bonalli and Marco Pavone},
  doi          = {10.1137/23M1573227},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3506-3533},
  shortjournal = {SIAM J. Optim.},
  title        = {Sample average approximation for stochastic programming with equality constraints},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards global solutions for nonconvex two-stage stochastic
programs: A polynomial lower approximation approach. <em>SIOPT</em>,
<em>34</em>(4), 3477–3505. (<a
href="https://doi.org/10.1137/23M1615516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper tackles the challenging problem of finding global optimal solutions for two-stage stochastic programs with continuous decision variables and nonconvex recourse functions. We introduce a two-phase approach. The first phase involves the construction of a polynomial lower bound for the recourse function through a linear optimization problem over a nonnegative polynomial cone. Given the complex structure of this cone, we employ semidefinite relaxations with quadratic modules to facilitate our computations. In the second phase, we solve a surrogate first-stage problem by substituting the original recourse function with the polynomial lower approximation obtained in the first phase. Our method is particularly advantageous for two reasons: it not only generates global lower bounds for the nonconvex stochastic program, aiding in the certificate of global optimality for prospective solutions like stationary solutions computed from other methods, but it also yields an explicit polynomial approximation for the recourse function through the solution of a linear conic optimization problem, where the number of variables is independent of the support of the underlying random vector. Therefore, our approach is particularly suitable for the case where the random vector follows a continuous distribution or when dealing with a large number of scenarios. Numerical experiments are conducted to demonstrate the effectiveness of our proposed approach.},
  archive      = {J_SIOPT},
  author       = {Suhan Zhong and Ying Cui and Jiawang Nie},
  doi          = {10.1137/23M1615516},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3477-3505},
  shortjournal = {SIAM J. Optim.},
  title        = {Towards global solutions for nonconvex two-stage stochastic programs: A polynomial lower approximation approach},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Face relative interior of convex sets in topological vector
spaces. <em>SIOPT</em>, <em>34</em>(4), 3456–3476. (<a
href="https://doi.org/10.1137/23M1602814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A new notion of face relative interior for convex sets in topological real vector spaces is introduced in this work. Face relative interior is grounded in the facial structure and may capture the geometry of convex sets in topological vector spaces better than other generalizations of relative interior. We show that the face relative interior partitions convex sets into face relative interiors of their closure-equivalent faces (different from the partition generated by intrinsic cores), establishes the conditions for nonemptiness of this new notion, compares the face relative interior with other concepts of convex interior, and proves basic calculus rules.},
  archive      = {J_SIOPT},
  author       = {R. Díaz Millán and Vera Roshchina},
  doi          = {10.1137/23M1602814},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3456-3476},
  shortjournal = {SIAM J. Optim.},
  title        = {Face relative interior of convex sets in topological vector spaces},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving the global convergence of inexact restoration
methods for constrained optimization problems. <em>SIOPT</em>,
<em>34</em>(4), 3429–3455. (<a
href="https://doi.org/10.1137/22M1493811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Inexact restoration (IR) methods are an important family of numerical methods for solving constrained optimization problems with applications to electronic structures and bilevel programming, among others areas. In these methods, the minimization is divided in two phases: decreasing infeasibility (feasibility phase) and improving optimality (optimality phase). The feasibility phase does not require the generated points to be feasible, so it has a practical appeal. In turn, the optimization phase involves minimizing a simplified model of the problem over a linearization of the feasible set. In this paper, we introduce a new optimization phase through a novel linearization that carries more information about complementarity than that employed in previous IR strategies. We then prove that the resulting algorithmic scheme is able to converge globally to the so-called complementary approximate KKT (CAKKT) points. This global convergence result improves upon all previous results for this class of methods. In particular, convergence to KKT points is established with the very weak CAKKT-regularity condition. Furthermore, to the best of our knowledge, this is the first time that a method for general nonlinear programming has reached CAKKT points without exogenous assumptions. From the practical point of view, the new optimization phase does not require significant additional computational effort compared to the usual one. Our theory also provides new insights, even for the classical IR method, for cases where it is reasonable to compute exact feasible points in the feasibility phase. We present numerical experiments on CUTEst problems to support our findings.},
  archive      = {J_SIOPT},
  author       = {Roberto Andreani and Alberto Ramos and Leonardo D. Secchin},
  doi          = {10.1137/22M1493811},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3429-3455},
  shortjournal = {SIAM J. Optim.},
  title        = {Improving the global convergence of inexact restoration methods for constrained optimization problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite convergence of moment-SOS relaxations with nonreal
radical ideals. <em>SIOPT</em>, <em>34</em>(4), 3399–3428. (<a
href="https://doi.org/10.1137/23M1605430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the linear conic optimization problem with the cone of nonnegative polynomials. Its dual optimization problem is the generalized moment problem. Moment-sum of squares (SOS) relaxations are powerful for solving them. This paper studies finite convergence of the Moment-SOS hierarchy when the constraining set is defined by equations whose ideal may not be real radical. Under the archimedeanness, we show that the Moment-SOS hierarchy has finite convergence if some classical optimality conditions hold at every minimizer of the optimal nonnegative polynomial for the linear conic optimization problem. When the archimedeanness fails (this is the case for unbounded sets), we propose a homogenized Moment-SOS hierarchy and prove its finite convergence under similar assumptions. Furthermore, we also prove the finite convergence of the Moment-SOS hierarchy with denominators. In particular, this paper resolves a conjecture posed in the earlier work.},
  archive      = {J_SIOPT},
  author       = {Lei Huang and Jiawang Nie and Ya-Xiang Yuan},
  doi          = {10.1137/23M1605430},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3399-3428},
  shortjournal = {SIAM J. Optim.},
  title        = {Finite convergence of moment-SOS relaxations with nonreal radical ideals},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A branch-and-bound algorithm for nonconvex nash equilibrium
problems. <em>SIOPT</em>, <em>34</em>(4), 3371–3398. (<a
href="https://doi.org/10.1137/23M1548189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper introduces a spatial branch-and-bound method for the computation of the set of all -Nash equilibria of continuous box-constrained nonconvex Nash equilibrium problems with an approximation guarantee. Thereby, the existence of -Nash equilibria is not assumed, but the algorithm is also able to detect their absence. We explain appropriate discarding and fathoming techniques, provide a termination proof for a prescribed approximation tolerance, and report our computational experience.},
  archive      = {J_SIOPT},
  author       = {Peter Kirst and Stefan Schwarze and Oliver Stein},
  doi          = {10.1137/23M1548189},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3371-3398},
  shortjournal = {SIAM J. Optim.},
  title        = {A branch-and-bound algorithm for nonconvex nash equilibrium problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient first order method for saddle point problems with
higher order smoothness. <em>SIOPT</em>, <em>34</em>(4), 3342–3370. (<a
href="https://doi.org/10.1137/23M1566972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies the complexity of finding approximate stationary points for the smooth nonconvex-strongly-concave (NC-SC) saddle point problem: . Under the standard first-order smoothness conditions where is -smooth in both arguments and -strongly concave in , existing literature shows that the optimal complexity for first-order methods to obtain an -stationary point is , where is the condition number. However, when has -Lipschitz continuous Hessian in addition, we derive a first-order algorithm with an complexity by designing an accelerated proximal point algorithm enhanced with the “Convex Until Proven Guilty” technique. Moreover, an improved lower bound for first-order method is also derived for sufficiently small . As a result, given the second-order smoothness of the problem, the complexity of our method improves the state-of-the-art result by a factor of , while almost matching the lower bound except for a small factor.},
  archive      = {J_SIOPT},
  author       = {Nuozhou Wang and Junyu Zhang and Shuzhong Zhang},
  doi          = {10.1137/23M1566972},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3342-3370},
  shortjournal = {SIAM J. Optim.},
  title        = {Efficient first order method for saddle point problems with higher order smoothness},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zeroth-order riemannian averaging stochastic approximation
algorithms. <em>SIOPT</em>, <em>34</em>(4), 3314–3341. (<a
href="https://doi.org/10.1137/23M1605405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present Zeroth-order Riemannian Averaging Stochastic Approximation (Zo-RASA) algorithms for stochastic optimization on Riemannian manifolds. We show that Zo-RASA achieves optimal sample complexities for generating -approximation first-order stationary solutions using only one-sample or constant-order batches in each iteration. Our approach employs Riemannian moving-average stochastic gradient estimators and a novel Riemannian–Lyapunov analysis technique for convergence analysis. We provably improve the algorithm’s practicality by using retractions and vector transport, instead of exponential mappings and parallel transports, thereby reducing per-iteration complexity. To do so, we introduce a novel geometric condition, satisfied by manifolds with bounded second fundamental form, which enables new error bounds for approximating parallel transport with vector transport.},
  archive      = {J_SIOPT},
  author       = {Jiaxiang Li and Krishnakumar Balasubramanian and Shiqian Ma},
  doi          = {10.1137/23M1605405},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3314-3341},
  shortjournal = {SIAM J. Optim.},
  title        = {Zeroth-order riemannian averaging stochastic approximation algorithms},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A disjunctive cutting plane algorithm for bilinear
programming. <em>SIOPT</em>, <em>34</em>(4), 3286–3313. (<a
href="https://doi.org/10.1137/22M1515562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we present and analyze a finitely convergent disjunctive cutting plane algorithm to obtain an -optimal solution or detect the infeasibility of a general nonconvex continuous bilinear program. While the cutting planes are obtained like Saxena, Bonami, and Lee [Math. Prog., 130 (2011), pp. 359–413] and Fampa and Lee [J. Global Optim., 80 (2021), pp. 287–305], a feature of the algorithm that guarantees finite convergence is exploring near-optimal extreme point solutions to a current relaxation at each iteration. In this sense, the presented algorithm and its analysis extend the work Owen and Mehrotra [Math. Prog., 89 (2001), pp. 437–448] for solving mixed-integer linear programs to the general bilinear programs.},
  archive      = {J_SIOPT},
  author       = {Hamed Rahimian and Sanjay Mehrotra},
  doi          = {10.1137/22M1515562},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3286-3313},
  shortjournal = {SIAM J. Optim.},
  title        = {A disjunctive cutting plane algorithm for bilinear programming},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameter-free FISTA by adaptive restart and backtracking.
<em>SIOPT</em>, <em>34</em>(4), 3259–3285. (<a
href="https://doi.org/10.1137/23M158961X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a combined restarting and adaptive backtracking strategy for the popular fast iterative shrinking-thresholding algorithm (FISTA) frequently employed for accelerating the convergence speed of large-scale structured convex optimization problems. Several variants of FISTA enjoy a provable linear convergence rate for the function values of the form under the prior knowledge of problem conditioning, i.e., of the ratio between the (Łojasiewicz) parameter determining the growth of the objective function and the Lipschitz constant of its smooth component. These parameters are nonetheless hard to estimate in many practical cases. Recent works address the problem by estimating either parameter via suitable adaptive strategies. In our work both parameters can be estimated at the same time by means of an algorithmic restarting scheme where, at each restart, a nonmonotone estimation of is performed. For this scheme, theoretical convergence results are proved, showing that an convergence speed can still be achieved along with quantitative estimates of the conditioning. The resulting free-FISTA is therefore parameter-free. Several numerical results are reported to confirm the practical interest of its use in many example problems.},
  archive      = {J_SIOPT},
  author       = {Jean-François Aujol and Luca Calatroni and Charles Dossal and Hippolyte Labarrière and Aude Rondepierre},
  doi          = {10.1137/23M158961X},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3259-3285},
  shortjournal = {SIAM J. Optim.},
  title        = {Parameter-free FISTA by adaptive restart and backtracking},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A search-free <span
class="math inline"><em>O</em>(1/<em>k</em><sup>3/2</sup>)</span>
homotopy inexact proximal-newton extragradient algorithm for monotone
variational inequalities. <em>SIOPT</em>, <em>34</em>(4), 3235–3258. (<a
href="https://doi.org/10.1137/23M1593000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present and study the iteration-complexity of a relative-error inexact proximal-Newton extragradient algorithm for solving smooth monotone variational inequality problems in real Hilbert spaces. We removed a search procedure from Monteiro and Svaiter (2012) by introducing a novel approach based on homotopy, which requires the resolution (at each iteration) of a single strongly monotone linear variational inequality. For a given tolerance , our main algorithm exhibits pointwise and ergodic iteration-complexities. From a practical perspective, preliminary numerical experiments indicate that our main algorithm outperforms some previous proximal-Newton schemes.},
  archive      = {J_SIOPT},
  author       = {M. Marques Alves and J. M. Pereira and B. F. Svaiter},
  doi          = {10.1137/23M1593000},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3235-3258},
  shortjournal = {SIAM J. Optim.},
  title        = {A search-free \({O(1/{k}^{3/2})}\) homotopy inexact proximal-newton extragradient algorithm for monotone variational inequalities},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proximity operators of perspective functions with nonlinear
scaling. <em>SIOPT</em>, <em>34</em>(4), 3212–3234. (<a
href="https://doi.org/10.1137/23M1583430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A perspective function is a construction which combines a base function defined on a given space with a nonlinear scaling function defined on another space and which yields a lower semicontinuous convex function on the product space. Since perspective functions are typically nonsmooth, their use in first-order algorithms necessitates the computation of their proximity operator. This paper establishes closed-form expressions for the proximity operator of a perspective function defined on a Hilbert space in terms of a proximity operator involving its base function and one involving its scaling function.},
  archive      = {J_SIOPT},
  author       = {Luis M. Briceño-Arias and Patrick L. Combettes and Francisco J. Silva},
  doi          = {10.1137/23M1583430},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3212-3234},
  shortjournal = {SIAM J. Optim.},
  title        = {Proximity operators of perspective functions with nonlinear scaling},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Further development in convex conic reformulation of
geometric nonconvex conic optimization problems. <em>SIOPT</em>,
<em>34</em>(4), 3194–3211. (<a
href="https://doi.org/10.1137/23M1593346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A geometric nonconvex conic optimization problem (COP) was recently proposed by Kim, Kojima, and Toh (SIAM J. Optim., 30 (2020), pp. 1251–1273) as a unified framework for convex conic reformulation of a class of quadratic optimization problems and polynomial optimization problems. The nonconvex COP minimizes a linear function over the intersection of a nonconvex cone , a convex subcone of the convex hull co of , and an affine hyperplane with a normal vector . Under the assumption co, the original nonconvex COP in their paper was shown to be equivalently formulated as a convex conic program by replacing the constraint set with the intersection of and the affine hyperplane. This paper further studies the key assumption co in their framework and provides three sets of necessary-sufficient conditions for the assumption. Based on the conditions, we propose a new wide class of quadratically constrained quadratic programs with multiple nonconvex equality and inequality constraints, which can be solved exactly by their semidefinite relaxation.},
  archive      = {J_SIOPT},
  author       = {Naohiko Arima and Sunyoung Kim and Masakazu Kojima},
  doi          = {10.1137/23M1593346},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3194-3211},
  shortjournal = {SIAM J. Optim.},
  title        = {Further development in convex conic reformulation of geometric nonconvex conic optimization problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Piecewise polyhedral relaxations of multilinear
optimization. <em>SIOPT</em>, <em>34</em>(4), 3167–3193. (<a
href="https://doi.org/10.1137/22M1507486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we consider piecewise polyhedral relaxations (PPRs) of multilinear optimization problems over axis-parallel hyperrectangular partitions of their domain. We improve formulations for PPRs by linking components that are commonly modeled independently in the literature. Numerical experiments with ALPINE, an open-source software for global optimization that relies on piecewise approximations of functions, show that the resulting formulations speed up the solver by an order of magnitude when compared to its default settings. If given the same time, the new formulation can solve more than twice as many instances from our test-set. Most results on piecewise functions in the literature assume that the partition is regular. Regular partitions arise when the domain of each individual input variable is divided into nonoverlapping intervals and when the partition of the overall domain is composed of all Cartesian products of these intervals. We provide the first locally ideal formulation for general (nonregular) hyperrectangular partitions. We also perform experiments that show that, for a variant of tree ensemble optimization, our formulations based on nonregular partitions outperform an existing formulation for piecewise linear functions commonly used in the literature and also outperform by an order of magnitude formulations over regular partitions.},
  archive      = {J_SIOPT},
  author       = {Jongeun Kim and Jean-Philippe P. Richard and Mohit Tawarmalani},
  doi          = {10.1137/22M1507486},
  journal      = {SIAM Journal on Optimization},
  month        = {12},
  number       = {4},
  pages        = {3167-3193},
  shortjournal = {SIAM J. Optim.},
  title        = {Piecewise polyhedral relaxations of multilinear optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Corrigendum and addendum: Newton differentiability of convex
functions in normed spaces and of a class of operators. <em>SIOPT</em>,
<em>34</em>(3), 3163–3166. (<a
href="https://doi.org/10.1137/24M1669542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. As it is formulated, Proposition 3.12 of [M. Brokate and M. Ulbrich, SIAM J. Optim., 32 (2022), pp. 1265–1287] contains an error. But this can be corrected in the way described below. The results of [M. Brokate and M. Ulbrich, SIAM J. Optim., 32 (2022), pp. 1265–1287] based on Proposition 3.12 are not affected. We also use the opportunity to add a further illustrating example and to rectify some inaccuracies which may be confusing.},
  archive      = {J_SIOPT},
  author       = {Martin Brokate and Michael Ulbrich},
  doi          = {10.1137/24M1669542},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {3163-3166},
  shortjournal = {SIAM J. Optim.},
  title        = {Corrigendum and addendum: Newton differentiability of convex functions in normed spaces and of a class of operators},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Newton-based alternating methods for the ground state of a
class of multicomponent bose–einstein condensates. <em>SIOPT</em>,
<em>34</em>(3), 3136–3162. (<a
href="https://doi.org/10.1137/23M1580346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The computation of the ground state of special multicomponent Bose–Einstein condensates (BECs) can be formulated as an energy functional minimization problem with spherical constraints. It leads to a nonconvex quartic-quadratic optimization problem after suitable discretizations. First, we generalize the Newton-based methods for single-component BECs to the alternating minimization scheme for multicomponent BECs. Second, the global convergent alternating Newton-Noda iteration (ANNI) is proposed. In particular, we prove the positivity preserving property of ANNI under mild conditions. Finally, our analysis is applied to a class of more general “multiblock” optimization problems with spherical constraints. Numerical experiments are performed to evaluate the performance of proposed methods for different multicomponent BECs, including pseudo spin-1/2, antiferromagnetic spin-1 and spin-2 BECs. These results support our theory and demonstrate the efficiency of our algorithms.},
  archive      = {J_SIOPT},
  author       = {Pengfei Huang and Qingzhi Yang},
  doi          = {10.1137/23M1580346},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {3136-3162},
  shortjournal = {SIAM J. Optim.},
  title        = {Newton-based alternating methods for the ground state of a class of multicomponent Bose–Einstein condensates},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimum spanning trees in infinite graphs: Theory and
algorithms. <em>SIOPT</em>, <em>34</em>(3), 3112–3135. (<a
href="https://doi.org/10.1137/23M157627X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We discuss finding minimum spanning trees (MSTs) on connected graphs with countably many nodes of finite degree. When edge costs are summable and an MST exists (which is not guaranteed in general), we show that an algorithm that finds MSTs on finite subgraphs (called layers) converges in objective value to the cost of an MST of the whole graph as the sizes of the layers grow to infinity. We call this the layered greedy algorithm since a greedy algorithm is used to find MSTs on each finite layer. We stress that the overall algorithm is not greedy since edges can enter and leave iterate spanning trees as larger layers are considered. However, in the setting where the underlying graph has the finite cycle (FC) property (meaning that every edge is contained in at most finitely many cycles) and distinct edge costs, we show that a unique MST exists and the layered greedy algorithm produces iterates that converge to by eventually “locking in&quot; edges after finitely many iterations. Applications to network deployment are discussed.},
  archive      = {J_SIOPT},
  author       = {Christopher T. Ryan and Robert L. Smith and Marina A. Epelman},
  doi          = {10.1137/23M157627X},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {3112-3135},
  shortjournal = {SIAM J. Optim.},
  title        = {Minimum spanning trees in infinite graphs: Theory and algorithms},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On minimal extended representations of generalized power
cones. <em>SIOPT</em>, <em>34</em>(3), 3088–3111. (<a
href="https://doi.org/10.1137/23M1617205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we analyze minimal representations of -power cones as simpler cones. We derive some new results on the complexity of the representations, and we provide a procedure to construct a minimal representation by means of second order cones in case and are rational. The construction is based on the identification of the cones with a graph, the mediated graph. Then, we develop a mixed integer linear optimization formulation to obtain the optimal mediated graph, and then the minimal representation. We present the results of a series of computational experiments in order to analyze the computational performance of the approach, both to obtain the representation and its incorporation into a practical conic optimization model that arises in facility location.},
  archive      = {J_SIOPT},
  author       = {Víctor Blanco and Miguel Martínez-Antón},
  doi          = {10.1137/23M1617205},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {3088-3111},
  shortjournal = {SIAM J. Optim.},
  title        = {On minimal extended representations of generalized power cones},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A functional model method for nonconvex nonsmooth
conditional stochastic optimization. <em>SIOPT</em>, <em>34</em>(3),
3064–3087. (<a href="https://doi.org/10.1137/23M1617965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider stochastic optimization problems involving an expected value of a nonlinear function of a base random vector and a conditional expectation of another function depending on the base random vector, a dependent random vector, and the decision variables. We call such problems conditional stochastic optimization problems. They arise in many applications, such as uplift modeling, reinforcement learning, and contextual optimization. We propose a specialized single time-scale stochastic method for nonconvex constrained conditional stochastic optimization problems with a Lipschitz smooth outer function and a generalized differentiable inner function. In the method, we approximate the inner conditional expectation with a rich parametric model whose mean squared error satisfies a stochastic version of a Łojasiewicz condition. The model is used by an inner learning algorithm. The main feature of our approach is that unbiased stochastic estimates of the directions used by the method can be generated with one observation from the joint distribution per iteration, which makes it applicable to real-time learning. The directions, however, are not gradients or subgradients of any overall objective function. We prove the convergence of the method with probability one, using the method of differential inclusions and a specially designed Lyapunov function, involving a stochastic generalization of the Bregman distance. Finally, a numerical illustration demonstrates the viability of our approach.},
  archive      = {J_SIOPT},
  author       = {Andrzej Ruszczyński and Shangzhe Yang},
  doi          = {10.1137/23M1617965},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {3064-3087},
  shortjournal = {SIAM J. Optim.},
  title        = {A functional model method for nonconvex nonsmooth conditional stochastic optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpolation conditions for linear operators and
applications to performance estimation problems. <em>SIOPT</em>,
<em>34</em>(3), 3033–3063. (<a
href="https://doi.org/10.1137/23M1575391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The performance estimation problem methodology makes it possible to determine the exact worst-case performance of an optimization method. In this work, we generalize this framework to first-order methods involving linear operators. This extension requires an explicit formulation of interpolation conditions for those linear operators. We consider the class of linear operators , where matrix has bounded singular values, and the class of linear operators, where is symmetric and has bounded eigenvalues. We describe interpolation conditions for these classes, i.e., necessary and sufficient conditions that, given a list of pairs , characterize the existence of a linear operator mapping to for all . Using these conditions, we first identify the exact worst-case behavior of the gradient method applied to the composed objective , and observe that it always corresponds to being a scaling operator. We then investigate the Chambolle–Pock method applied to , and improve the existing analysis to obtain a proof of the exact convergence rate of the primal-dual gap. In addition, we study how this method behaves on Lipschitz convex functions, and obtain a numerical convergence rate for the primal accuracy of the last iterate. We also show numerically that averaging iterates is beneficial in this setting.},
  archive      = {J_SIOPT},
  author       = {Nizar Bousselmi and Julien M. Hendrickx and François Glineur},
  doi          = {10.1137/23M1575391},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {3033-3063},
  shortjournal = {SIAM J. Optim.},
  title        = {Interpolation conditions for linear operators and applications to performance estimation problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complexity-optimal and parameter-free first-order methods
for finding stationary points of composite optimization problems.
<em>SIOPT</em>, <em>34</em>(3), 3005–3032. (<a
href="https://doi.org/10.1137/22M1498826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper develops and analyzes an accelerated proximal descent method for finding stationary points of nonconvex composite optimization problems. The objective function is of the form , where is a proper closed convex function, is a differentiable function on the domain of , and is Lipschitz continuous on the domain of . The main advantage of this method is that it is “parameter-free” in the sense that it does not require knowledge of the Lipschitz constant of or of any global topological properties of . It is shown that the proposed method can obtain an -approximate stationary point with iteration complexity bounds that are optimal, up to logarithmic terms over , in both the convex and nonconvex settings. Some discussion is also given about how the proposed method can be leveraged in other existing optimization frameworks, such as min-max smoothing and penalty frameworks for constrained programming, to create more specialized parameter-free methods. Finally, numerical experiments are presented to support the practical viability of the method.},
  archive      = {J_SIOPT},
  author       = {Weiwei Kong},
  doi          = {10.1137/22M1498826},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {3005-3032},
  shortjournal = {SIAM J. Optim.},
  title        = {Complexity-optimal and parameter-free first-order methods for finding stationary points of composite optimization problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consensus-based optimization methods converge globally.
<em>SIOPT</em>, <em>34</em>(3), 2973–3004. (<a
href="https://doi.org/10.1137/22M1527805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we study consensus-based optimization (CBO), which is a multiagent metaheuristic derivative-free optimization method that can globally minimize nonconvex nonsmooth functions and is amenable to theoretical analysis. Based on an experimentally supported intuition that, on average, CBO performs a gradient descent of the squared Euclidean distance to the global minimizer, we devise a novel technique for proving the convergence to the global minimizer in mean-field law for a rich class of objective functions. The result unveils internal mechanisms of CBO that are responsible for the success of the method. In particular, we prove that CBO performs a convexification of a large class of optimization problems as the number of optimizing agents goes to infinity. Furthermore, we improve prior analyses by requiring mild assumptions about the initialization of the method and by covering objectives that are merely locally Lipschitz continuous. As a core component of this analysis, we establish a quantitative nonasymptotic Laplace principle, which may be of independent interest. From the result of CBO convergence in mean-field law, it becomes apparent that the hardness of any global optimization problem is necessarily encoded in the rate of the mean-field approximation, for which we provide a novel probabilistic quantitative estimate. The combination of these results allows us to obtain probabilistic global convergence guarantees of the numerical CBO method.},
  archive      = {J_SIOPT},
  author       = {Massimo Fornasier and Timo Klock and Konstantin Riedl},
  doi          = {10.1137/22M1527805},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2973-3004},
  shortjournal = {SIAM J. Optim.},
  title        = {Consensus-based optimization methods converge globally},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A quadratically convergent sequential programming method for
second-order cone programs capable of warm starts. <em>SIOPT</em>,
<em>34</em>(3), 2943–2972. (<a
href="https://doi.org/10.1137/22M1507681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a new method for linear second-order cone programs. It is based on the sequential quadratic programming framework for nonlinear programming. In contrast to interior point methods, it can capitalize on the warm-start capabilities of active-set quadratic programming subproblem solvers and achieve a local quadratic rate of convergence. In order to overcome the nondifferentiability or singularity observed in nonlinear formulations of the conic constraints, the subproblems approximate the cones with polyhedral outer approximations that are refined throughout the iterations. For nondegenerate instances, the algorithm implicitly identifies the set of cones for which the optimal solution lies at the extreme points. As a consequence, the final steps are identical to regular sequential quadratic programming steps for a differentiable nonlinear optimization problem, yielding local quadratic convergence. We prove the global and local convergence guarantees of the method and present numerical experiments that confirm that the method can take advantage of good starting points and can achieve higher accuracy compared to a state-of-the-art interior point solver.},
  archive      = {J_SIOPT},
  author       = {Xinyi Luo and Andreas Wächter},
  doi          = {10.1137/22M1507681},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2943-2972},
  shortjournal = {SIAM J. Optim.},
  title        = {A quadratically convergent sequential programming method for second-order cone programs capable of warm starts},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven distributionally robust multiproduct pricing
problems under pure characteristics demand models. <em>SIOPT</em>,
<em>34</em>(3), 2917–2942. (<a
href="https://doi.org/10.1137/23M1585131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper considers a multiproduct pricing problem under pure characteristics demand models when the probability distribution of the random parameter in the problem is uncertain. We formulate this problem as a distributionally robust optimization (DRO) problem based on a constructive approach to estimating pure characteristics demand models with pricing by Pang, Su, and Lee. In this model, the consumers’ purchase decision is to maximize their utility. We show that the DRO problem is well-defined, and the objective function is upper semicontinuous by using an equivalent hierarchical form. We also use the data-driven approach to analyze the DRO problem when the ambiguity set, i.e., a set of probability distributions that contains some exact information of the underlying probability distribution, is given by a general moment-based case. We give convergence results as the data size tends to infinity and analyze the quantitative statistical robustness in view of the possible contamination of driven data. Furthermore, we use the Lagrange duality to reformulate the DRO problem as a mathematical program with complementarity constraints, and give a numerical procedure for finding a global solution of the DRO problem under certain specific settings. Finally, we report numerical results that validate the effectiveness and scalability of our approach for the distributionally robust multiproduct pricing problem.},
  archive      = {J_SIOPT},
  author       = {Jie Jiang and Hailin Sun and Xiaojun Chen},
  doi          = {10.1137/23M1585131},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2917-2942},
  shortjournal = {SIAM J. Optim.},
  title        = {Data-driven distributionally robust multiproduct pricing problems under pure characteristics demand models},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimality conditions and numerical algorithms for a class
of linearly constrained minimax optimization problems. <em>SIOPT</em>,
<em>34</em>(3), 2883–2916. (<a
href="https://doi.org/10.1137/22M1535243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. It is well known that there have been many numerical algorithms for solving nonsmooth minimax problems; however, numerical algorithms for nonsmooth minimax problems with joint linear constraints are very rare. This paper aims to discuss optimality conditions and develop practical numerical algorithms for minimax problems with joint linear constraints. First, we use the properties of proximal mapping and the KKT system to establish optimality conditions. Second, we propose a framework of an alternating coordinate algorithm for the minimax problem and analyze its convergence properties. Third, we develop a proximal gradient multistep ascent descent method (PGmsAD) as a numerical algorithm and demonstrate that the method can find an -stationary point for this kind of nonsmooth problem in iterations. Finally, we apply PGmsAD to generalized absolute value equations, generalized linear projection equations, and linear regression problems, and we report the efficiency of PGmsAD on large-scale optimization.},
  archive      = {J_SIOPT},
  author       = {Yu-Hong Dai and Jiani Wang and Liwei Zhang},
  doi          = {10.1137/22M1535243},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2883-2916},
  shortjournal = {SIAM J. Optim.},
  title        = {Optimality conditions and numerical algorithms for a class of linearly constrained minimax optimization problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MIP relaxations in factorable programming. <em>SIOPT</em>,
<em>34</em>(3), 2856–2882. (<a
href="https://doi.org/10.1137/22M1515537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we develop new discrete relaxations for nonlinear expressions in factorable programming. We utilize specialized convexification results as well as composite relaxations to develop mixed-integer programming relaxations. Our relaxations rely on ideal formulations of convex hulls of outer-functions over a combinatorial structure that captures local inner-function structure. The resulting relaxations often require fewer variables and are tighter than currently prevalent ones. Finally, we provide computational evidence to demonstrate that our relaxations close approximately 60%–70% of the gap relative to McCormick relaxations and significantly improve the relaxations used in a state-of-the-art solver on various instances involving polynomial functions.},
  archive      = {J_SIOPT},
  author       = {Taotao He and Mohit Tawarmalani},
  doi          = {10.1137/22M1515537},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2856-2882},
  shortjournal = {SIAM J. Optim.},
  title        = {MIP relaxations in factorable programming},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On a differential generalized nash equilibrium problem with
mean field interaction. <em>SIOPT</em>, <em>34</em>(3), 2821–2855. (<a
href="https://doi.org/10.1137/22M1489952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a class of -player linear quadratic differential generalized Nash equilibrium problems (GNEPs) with bound constraints on the individual control and state variables. In addition, we assume the individual players’ optimal control problems are coupled through their dynamics and objectives via a time-dependent mean field interaction term. This assumption allows us to model the realistic setting that strategic players in large games cannot observe the individual states of their competitors. We observe that the GNEPs require a constraint qualification, which necessitates sufficient robustness of the individuals, in order to prove the existence of an open-loop pure strategy Nash equilibrium and to derive optimality conditions. In order to gain qualitative insight into the -player game, we assume that players are identical and pass to the limit in to derive a type of first-order constrained mean field game (MFG). We prove that the mean field interaction terms converge to an absolutely continuous curve of probability measures on the set of possible state trajectories. Using variational convergence methods, we show that the optimal control problems converge to a representative agent problem. Under additional regularity assumptions, we provide an explicit form for the mean field term as the solution of a continuity equation and demonstrate the link back to the -player GNEP.},
  archive      = {J_SIOPT},
  author       = {Michael Hintermüller and Thomas M. Surowiec and Mike Theiß},
  doi          = {10.1137/22M1489952},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2821-2855},
  shortjournal = {SIAM J. Optim.},
  title        = {On a differential generalized nash equilibrium problem with mean field interaction},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MGProx: A nonsmooth multigrid proximal gradient method with
adaptive restriction for strongly convex optimization. <em>SIOPT</em>,
<em>34</em>(3), 2788–2820. (<a
href="https://doi.org/10.1137/23M1552140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the combination of proximal gradient descent with multigrid for solving a class of possibly nonsmooth strongly convex optimization problems. We propose a multigrid proximal gradient method called MGProx, which accelerates the proximal gradient method by multigrid, based on using hierarchical information of the optimization problem. MGProx applies a newly introduced adaptive restriction operator to simplify the Minkowski sum of subdifferentials of the nondifferentiable objective function across different levels. We provide a theoretical characterization of MGProx. First we show that the MGProx update operator exhibits a fixed-point property. Next, we show that the coarse correction is a descent direction for the fine variable of the original fine level problem in the general nonsmooth case. Last, under some assumptions we provide the convergence rate for the algorithm. In the numerical tests on the elastic obstacle problem, which is an example of a nonsmooth convex optimization problem where the multigrid method can be applied, we show that MGProx has a faster convergence speed than competing methods.},
  archive      = {J_SIOPT},
  author       = {Andersen Ang and Hans De Sterck and Stephen Vavasis},
  doi          = {10.1137/23M1552140},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2788-2820},
  shortjournal = {SIAM J. Optim.},
  title        = {MGProx: A nonsmooth multigrid proximal gradient method with adaptive restriction for strongly convex optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variational and strong variational convexity in
infinite-dimensional variational analysis. <em>SIOPT</em>,
<em>34</em>(3), 2756–2787. (<a
href="https://doi.org/10.1137/23M1604667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is devoted to a systematic study and characterizations of the fundamental notions of variational and strong variational convexity for lower semicontinuous functions. While these notions have been quite recently introduced by Rockafellar, the importance of them has already been recognized and documented in finite-dimensional variational analysis and optimization. Here we address general infinite-dimensional settings and derive comprehensive characterizations of both variational and strong variational convexity notions by developing novel techniques, which are essentially different from finite-dimensional counterparts. As a consequence of the obtained characterizations, we establish new quantitative and qualitative relationships between strong variational convexity and tilt stability of local minimizers in appropriate frameworks of Banach spaces.},
  archive      = {J_SIOPT},
  author       = {P. D. Khanh and V. V. H. Khoa and B. S. Mordukhovich and V. T. Phat},
  doi          = {10.1137/23M1604667},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2756-2787},
  shortjournal = {SIAM J. Optim.},
  title        = {Variational and strong variational convexity in infinite-dimensional variational analysis},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence of entropy-regularized natural policy gradient
with linear function approximation. <em>SIOPT</em>, <em>34</em>(3),
2729–2755. (<a href="https://doi.org/10.1137/22M1540156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Natural policy gradient (NPG) methods, equipped with function approximation and entropy regularization, achieve impressive empirical success in reinforcement learning problems with large state-action spaces. However, their convergence properties and the impact of entropy regularization remain elusive in the function approximation regime. In this paper, we establish finite-time convergence analyses of entropy-regularized NPG with linear function approximation under softmax parameterization. In particular, we prove that entropy-regularized NPG with averaging satisfies the persistence of excitation condition, and achieves a fast convergence rate of up to a function approximation error in regularized Markov decision processes. This convergence result does not require any a priori assumptions on the policies. Furthermore, under mild regularity conditions on the concentrability coefficient and basis vectors, we prove that entropy-regularized NPG exhibits linear convergence up to the compatible function approximation error. Finally, we provide sample complexity results for sample-based NPG with entropy regularization.},
  archive      = {J_SIOPT},
  author       = {Semih Cayci and Niao He and R. Srikant},
  doi          = {10.1137/22M1540156},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2729-2755},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence of entropy-regularized natural policy gradient with linear function approximation},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence analysis of a norm minimization-based convex
vector optimization algorithm. <em>SIOPT</em>, <em>34</em>(3),
2700–2728. (<a href="https://doi.org/10.1137/23M1574580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we propose an outer approximation algorithm for solving bounded convex vector optimization problems (CVOPs). The scalarization model solved iteratively within the algorithm is a modification of the norm-minimizing scalarization proposed in [Ç. Ararat, F. Ulus, and M. Umer, J. Optim. Theory Appl., 194 (2022), pp. 681–712]. For a predetermined tolerance , we prove that the algorithm terminates after finitely many iterations, and it returns a polyhedral outer approximation to the upper image of the CVOP such that the Hausdorff distance between the two is less than . We show that for an arbitrary norm used in the scalarization models, the approximation error after iterations decreases by the order of , where is the dimension of the objective space. An improved convergence rate of is proved for the special case of using the Euclidean norm.},
  archive      = {J_SIOPT},
  author       = {Çağin Ararat and Firdevs Ulus and Muhammad Umer},
  doi          = {10.1137/23M1574580},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2700-2728},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence analysis of a norm minimization-based convex vector optimization algorithm},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic trust-region algorithm in random subspaces with
convergence and expected complexity analyses. <em>SIOPT</em>,
<em>34</em>(3), 2671–2699. (<a
href="https://doi.org/10.1137/22M1524072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work proposes a framework for large-scale stochastic derivative-free optimization (DFO) by introducing STARS, a trust-region method based on iterative minimization in random subspaces. This framework is both an algorithmic and theoretical extension of a random subspace derivative-free optimization (RSDFO) framework, and an algorithm for stochastic optimization with random models (STORM). Moreover, like RSDFO, STARS achieves scalability by minimizing interpolation models that approximate the objective in low-dimensional affine subspaces, thus significantly reducing per-iteration costs in terms of function evaluations and yielding strong performance on large-scale stochastic DFO problems. The user-determined dimension of these subspaces, when the latter are defined, for example, by the columns of so-called Johnson–Lindenstrauss transforms, turns out to be independent of the dimension of the problem. For convergence purposes, inspired by the analyses of RSDFO and STORM, both a particular quality of the subspace and the accuracies of random function estimates and models are required to hold with sufficiently high, but fixed, probabilities. Using martingale theory under the latter assumptions, an almost sure global convergence of STARS to a first-order stationary point is shown, and the expected number of iterations required to reach a desired first-order accuracy is proved to be similar to that of STORM and other stochastic DFO algorithms, up to constants.},
  archive      = {J_SIOPT},
  author       = {K. J. Dzahini and S. M. Wild},
  doi          = {10.1137/22M1524072},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2671-2699},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic trust-region algorithm in random subspaces with convergence and expected complexity analyses},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Small errors in random zeroth-order optimization are
imaginary. <em>SIOPT</em>, <em>34</em>(3), 2638–2670. (<a
href="https://doi.org/10.1137/22M1510261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Most zeroth-order optimization algorithms mimic a first-order algorithm but replace the gradient of the objective function with some gradient estimator that can be computed from a small number of function evaluations. This estimator is constructed randomly, and its expectation matches the gradient of a smooth approximation of the objective function whose quality improves as the underlying smoothing parameter is reduced. Gradient estimators requiring a smaller number of function evaluations are preferable from a computational point of view. While estimators based on a single function evaluation can be obtained by use of the divergence theorem from vector calculus, their variance explodes as tends to 0. Estimators based on multiple function evaluations, on the other hand, suffer from numerical cancellation when tends to 0. To combat both effects simultaneously, we extend the objective function to the complex domain and construct a gradient estimator that evaluates the objective at a complex point whose coordinates have small imaginary parts of the order . As this estimator requires only one function evaluation, it is immune to cancellation. In addition, its variance remains bounded as tends to 0. We prove that zeroth-order algorithms that use our estimator offer the same theoretical convergence guarantees as the state-of-the-art methods. Numerical experiments suggest, however, that they often converge faster in practice.},
  archive      = {J_SIOPT},
  author       = {Wouter Jongeneel and Man-Chung Yue and Daniel Kuhn},
  doi          = {10.1137/22M1510261},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2638-2670},
  shortjournal = {SIAM J. Optim.},
  title        = {Small errors in random zeroth-order optimization are imaginary},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Square root LASSO: Well-posedness, lipschitz stability, and
the tuning trade-off. <em>SIOPT</em>, <em>34</em>(3), 2609–2637. (<a
href="https://doi.org/10.1137/23M1561968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies well-posedness and parameter sensitivity of the square root LASSO (SR-LASSO), an optimization model for recovering sparse solutions to linear inverse problems in finite dimension. An advantage of the SR-LASSO (e.g., over the standard LASSO) is that the optimal tuning of the regularization parameter is robust with respect to measurement noise. This paper provides three point-based regularity conditions at a solution of the SR-LASSO: the weak, intermediate, and strong assumptions. It is shown that the weak assumption implies uniqueness of the solution in question. The intermediate assumption yields a directionally differentiable and locally Lipschitz solution map (with explicit Lipschitz bounds), whereas the strong assumption gives continuous differentiability of said map around the point in question. Our analysis leads to new theoretical insights on the comparison between SR-LASSO and LASSO from the viewpoint of tuning parameter sensitivity: noise-robust optimal parameter choice for SR-LASSO comes at the “price” of elevated tuning parameter sensitivity. Numerical results support and showcase the theoretical findings.},
  archive      = {J_SIOPT},
  author       = {Aaron Berk and Simone Brugiapaglia and Tim Hoheisel},
  doi          = {10.1137/23M1561968},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2609-2637},
  shortjournal = {SIAM J. Optim.},
  title        = {Square root LASSO: Well-posedness, lipschitz stability, and the tuning trade-off},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Provably faster gradient descent via long steps.
<em>SIOPT</em>, <em>34</em>(3), 2588–2608. (<a
href="https://doi.org/10.1137/23M1588408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work establishes new convergence guarantees for gradient descent in smooth convex optimization via a computer-assisted analysis technique. Our theory allows nonconstant stepsize policies with frequent long steps potentially violating descent by analyzing the overall effect of many iterations at once rather than the typical one-iteration inductions used in most first-order method analyses. We show that long steps, which may increase the objective value in the short term, lead to provably faster convergence in the long term. A conjecture towards proving a faster rate for gradient descent is also motivated along with simple numerical validation.},
  archive      = {J_SIOPT},
  author       = {Benjamin Grimmer},
  doi          = {10.1137/23M1588408},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2588-2608},
  shortjournal = {SIAM J. Optim.},
  title        = {Provably faster gradient descent via long steps},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast gradient algorithm with dry-like friction and
nonmonotone line search for nonconvex optimization problems.
<em>SIOPT</em>, <em>34</em>(3), 2557–2587. (<a
href="https://doi.org/10.1137/22M1532354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose a fast gradient algorithm for the problem of minimizing a differentiable (possibly nonconvex) function in Hilbert spaces. We first extend the dry friction property for convex functions to what we call the dry-like friction property in a nonconvex setting, and then employ a line search technique to adaptively update parameters at each iteration. Depending on the choice of parameters, the proposed algorithm exhibits subsequential convergence to a critical point or full sequential convergence to an “approximate” critical point of the objective function. We also establish the full sequential convergence to a critical point under the Kurdyka–Łojasiewicz (KL) property of a merit function. Thanks to the parameters’ flexibility, our algorithm can reduce to a number of existing inertial gradient algorithms with Hessian damping and dry friction. By exploiting variational properties of the Moreau envelope, the proposed algorithm is adapted to address weakly convex nonsmooth optimization problems. In particular, we extend the result on KL exponent for the Moreau envelope of a convex KL function to a broad class of KL functions that are not necessarily convex nor continuous. Simulation results illustrate the efficiency of our algorithm and demonstrate the potential advantages of combining dry-like friction with extrapolation and line search techniques.},
  archive      = {J_SIOPT},
  author       = {Lien T. Nguyen and Andrew Eberhard and Xinghuo Yu and Chaojie Li},
  doi          = {10.1137/22M1532354},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2557-2587},
  shortjournal = {SIAM J. Optim.},
  title        = {Fast gradient algorithm with dry-like friction and nonmonotone line search for nonconvex optimization problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A finitely convergent circumcenter method for the convex
feasibility problem. <em>SIOPT</em>, <em>34</em>(3), 2535–2556. (<a
href="https://doi.org/10.1137/23M1595412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we present a variant of the circumcenter method for the convex feasibility problem (CFP), ensuring finite convergence under a Slater assumption. The method replaces exact projections onto the convex sets with projections onto separating half-spaces, perturbed by positive exogenous parameters that decrease to zero along the iterations. If the perturbation parameters decrease slowly enough, such as the terms of a diverging series, finite convergence is achieved. To the best of our knowledge, this is the first circumcenter method for CFP that guarantees finite convergence.},
  archive      = {J_SIOPT},
  author       = {Roger Behling and Yunier Bello-Cruz and Alfredo N. Iusem and Di Liu and Luiz-Rafael Santos},
  doi          = {10.1137/23M1595412},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2535-2556},
  shortjournal = {SIAM J. Optim.},
  title        = {A finitely convergent circumcenter method for the convex feasibility problem},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using taylor-approximated gradients to improve the
frank–wolfe method for empirical risk minimization. <em>SIOPT</em>,
<em>34</em>(3), 2503–2534. (<a
href="https://doi.org/10.1137/22M1519286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Frank–Wolfe method has become increasingly useful in statistical and machine learning applications due to the structure-inducing properties of the iterates and especially in settings where linear minimization over the feasible set is more computationally efficient than projection. In the setting of empirical risk minimization—one of the fundamental optimization problems in statistical and machine learning—the computational effectiveness of Frank–Wolfe methods typically grows linearly in the number of data observations . This is in stark contrast to the case for typical stochastic projection methods. In order to reduce this dependence on , we look to second-order smoothness of typical smooth loss functions (least squares loss and logistic loss, for example), and we propose amending the Frank–Wolfe method with Taylor series–approximated gradients, including variants for both deterministic and stochastic settings. Compared with current state-of-the-art methods in the regime where the optimality tolerance is sufficiently small, our methods are able to simultaneously reduce the dependence on large while obtaining optimal convergence rates of Frank–Wolfe methods in both convex and nonconvex settings. We also propose a novel adaptive step-size approach for which we have computational guarantees. Finally, we present computational experiments which show that our methods exhibit very significant speedups over existing methods on real-world datasets for both convex and nonconvex binary classification problems.},
  archive      = {J_SIOPT},
  author       = {Zikai Xiong and Robert M. Freund},
  doi          = {10.1137/22M1519286},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2503-2534},
  shortjournal = {SIAM J. Optim.},
  title        = {Using taylor-approximated gradients to improve the Frank–Wolfe method for empirical risk minimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complexity of finite-sum optimization with nonsmooth
composite functions and non-lipschitz regularization. <em>SIOPT</em>,
<em>34</em>(3), 2472–2502. (<a
href="https://doi.org/10.1137/23M1546701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we present complexity analysis of proximal inexact gradient methods for finite-sum optimization with a nonconvex nonsmooth composite function and non-Lipschitz regularization. By getting access to a convex approximation to the Lipschitz function and a Lipschitz continuous approximation to the non-Lipschitz regularizer, we construct a proximal subproblem at each iteration without using exact function values and gradients. With certain accuracy control on inexact gradients and subproblem solutions, we show that the oracle complexity in terms of total number of inexact gradient evaluations is in order to find an -approximate first-order stationary point, ensuring that within a -ball centered at this point the maximum reduction of an approximation model does not exceed . This shows that we can have the same worst-case evaluation complexity order as in [C. Cartis, N. I. M. Gould, and P. L. Toint, SIAM J. Optim., 21 (2011), pp. 1721–1739, X. Chen, Ph. L. Toint, and H. Wang, SIAM J. Optim., 29 (2019), pp. 874–903], even if we introduce the non-Lipschitz singularity and the nonconvex nonsmooth composite function in the objective function. Moreover, we establish that the oracle complexity regarding the total number of stochastic oracles is in order with high probability for stochastic proximal inexact gradient methods. We further extend the algorithm to adjust to solving stochastic problems with expectation form and derive the associated oracle complexity in order with high probability.},
  archive      = {J_SIOPT},
  author       = {Xiao Wang and Xiaojun Chen},
  doi          = {10.1137/23M1546701},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2472-2502},
  shortjournal = {SIAM J. Optim.},
  title        = {Complexity of finite-sum optimization with nonsmooth composite functions and non-lipschitz regularization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The rate of convergence of bregman proximal methods: Local
geometry versus regularity versus sharpness. <em>SIOPT</em>,
<em>34</em>(3), 2440–2471. (<a
href="https://doi.org/10.1137/23M1580218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We examine the last-iterate convergence rate of Bregman proximal methods—from mirror descent to mirror-prox and its optimistic variants—as a function of the local geometry induced by the prox-mapping defining the method. For generality, we focus on local solutions of constrained, nonmonotone variational inequalities, and we show that the convergence rate of a given method depends sharply on its associated Legendre exponent, a notion that measures the growth rate of the underlying Bregman function (Euclidean, entropic, or other) near a solution. In particular, we show that boundary solutions exhibit a stark separation of regimes between methods with a zero and nonzero Legendre exponent: The former converge at a linear rate, while the latter converge, in general, sublinearly. This dichotomy becomes even more pronounced in linearly constrained problems where methods with entropic regularization achieve a linear convergence rate along sharp directions, compared to convergence in a finite number of steps under Euclidean regularization.},
  archive      = {J_SIOPT},
  author       = {Waïss Azizian and Franck Iutzeler and Jérôme Malick and Panayotis Mertikopoulos},
  doi          = {10.1137/23M1580218},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2440-2471},
  shortjournal = {SIAM J. Optim.},
  title        = {The rate of convergence of bregman proximal methods: Local geometry versus regularity versus sharpness},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). High probability complexity bounds for adaptive step search
based on stochastic oracles. <em>SIOPT</em>, <em>34</em>(3), 2411–2439.
(<a href="https://doi.org/10.1137/22M1512764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a step search method for continuous optimization under a stochastic setting where the function values and gradients are available only through inexact probabilistic zeroth- and first-order oracles. (We introduce the term step search for a class of methods, similar to line search, but where step direction can change during the back-tracking procedure.) Unlike the stochastic gradient method and its many variants, the algorithm does not use a prespecified sequence of step sizes but increases or decreases the step size adaptively according to the estimated progress of the algorithm. These oracles capture multiple standard settings including expected loss minimization and zeroth-order optimization. Moreover, our framework is very general and allows the function and gradient estimates to be biased. The proposed algorithm is simple to describe and easy to implement. Under fairly general conditions on the oracles, we derive a high probability tail bound on the iteration complexity of the algorithm when it is applied to nonconvex, convex, and strongly convex (more generally, those satisfying the Polyak-Łojasiewicz (PL) condition) functions. Our analysis strengthens and extends prior results for stochastic step and line search methods.},
  archive      = {J_SIOPT},
  author       = {Billy Jin and Katya Scheinberg and Miaolan Xie},
  doi          = {10.1137/22M1512764},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2411-2439},
  shortjournal = {SIAM J. Optim.},
  title        = {High probability complexity bounds for adaptive step search based on stochastic oracles},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel nonconvex relaxation approach to low-rank matrix
completion of inexact observed data. <em>SIOPT</em>, <em>34</em>(3),
2378–2410. (<a href="https://doi.org/10.1137/22M1543653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In recent years, matrix completion has become one of the main concepts in data science. In the process of data acquisition in real applications, in addition to missing data, observed data may be inaccurate. This paper is concerned with such matrix completion of inexact observed data which can be modeled as a rank minimization problem. We adopt the difference of the nuclear norm and the Frobenius norm as an approximation of the rank function, employ Tikhonov-type regularization to preserve the inherent characteristics of original data and control oscillation arising from inexact observations, and then establish a new nonsmooth and nonconvex relaxation model for such low-rank matrix completion. We propose a new accelerated proximal gradient–type algorithm to solve the nonsmooth and nonconvex minimization problem and show that the generated sequence is bounded and globally converges to a critical point of our model. Furthermore, the rate of convergence is given via the Kurdyka–Łojasiewicz property. We evaluate our model and method on visual images and received signal strength fingerprint data in an indoor positioning system. Numerical experiments illustrate that our approach outperforms some state-of-the-art methods, and also verify the efficacy of the Tikhonov-type regularization.},
  archive      = {J_SIOPT},
  author       = {Yan Li and Liping Zhang},
  doi          = {10.1137/22M1543653},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2378-2410},
  shortjournal = {SIAM J. Optim.},
  title        = {A novel nonconvex relaxation approach to low-rank matrix completion of inexact observed data},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Subgradient regularized multivariate convex regression at
scale. <em>SIOPT</em>, <em>34</em>(3), 2350–2377. (<a
href="https://doi.org/10.1137/21M1413134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present new large-scale algorithms for fitting a subgradient regularized multivariate convex regression function to samples in dimensions—a key problem in shape constrained nonparametric regression with applications in statistics, engineering, and the applied sciences. The infinite-dimensional learning task can be expressed via a convex quadratic program (QP) with decision variables and constraints. While instances with in the lower thousands can be addressed with current algorithms within reasonable runtimes, solving larger problems (e.g., or ) is computationally challenging. To this end, we present an active set type algorithm on the dual QP. For computational scalability, we allow for approximate optimization of the reduced subproblems and propose randomized augmentation rules for expanding the active set. We derive novel computational guarantees for our algorithms. We demonstrate that our framework can approximately solve instances of the subgradient regularized convex regression problem with and within minutes and shows strong computational performance compared to earlier approaches.},
  archive      = {J_SIOPT},
  author       = {Wenyu Chen and Rahul Mazumder},
  doi          = {10.1137/21M1413134},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2350-2377},
  shortjournal = {SIAM J. Optim.},
  title        = {Subgradient regularized multivariate convex regression at scale},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A descent algorithm for the optimal control of ReLU neural
network informed PDEs based on approximate directional derivatives.
<em>SIOPT</em>, <em>34</em>(3), 2314–2349. (<a
href="https://doi.org/10.1137/22M1534420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose and analyze a numerical algorithm for solving a class of optimal control problems for learning-informed semilinear partial differential equations (PDEs). Such PDEs contain constituents that are in principle unknown and are approximated by nonsmooth ReLU neural networks. We first show that direct smoothing of the ReLU network with the aim of using classical numerical solvers can have disadvantages, such as potentially introducing multiple solutions for the corresponding PDE. This motivates us to devise a numerical algorithm that treats directly the nonsmooth optimal control problem, by employing a descent algorithm inspired by a bundle-free method. Several numerical examples are provided and the efficiency of the algorithm is shown.},
  archive      = {J_SIOPT},
  author       = {Guozhi Dong and Michael Hintermüller and Kostas Papafitsoros},
  doi          = {10.1137/22M1534420},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2314-2349},
  shortjournal = {SIAM J. Optim.},
  title        = {A descent algorithm for the optimal control of ReLU neural network informed PDEs based on approximate directional derivatives},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast optimization of charged particle dynamics with damping.
<em>SIOPT</em>, <em>34</em>(3), 2287–2313. (<a
href="https://doi.org/10.1137/23M1599045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, the convergence analysis of accelerated second-order methods for convex optimization problems is developed from the point of view of autonomous dissipative inertial continuous dynamics in the magnetic field. Different from the classical heavy ball model with damping, we consider the motion of a charged particle in a magnetic field model involving the linear asymptotic vanishing damping. It is a coupled ordinary differential system by adding the magnetic coupled term to the heavy ball system with . In order to develop fast optimization methods, our first contribution is to prove the global existence and uniqueness of a smooth solution under certain regularity conditions of this system via the Banach fixed point theorem. Our second contribution is to establish the convergence rate of corresponding algorithms involving inertial features via discrete time versions of inertial dynamics under the magnetic field. Meanwhile, the connection of algorithms between the heavy ball model and the motion of a charged particle in a magnetic field model is established.},
  archive      = {J_SIOPT},
  author       = {Weiping Yan and Yu Tang and Gonglin Yuan},
  doi          = {10.1137/23M1599045},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2287-2313},
  shortjournal = {SIAM J. Optim.},
  title        = {Fast optimization of charged particle dynamics with damping},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast convergence of inertial multiobjective gradient-like
systems with asymptotic vanishing damping. <em>SIOPT</em>,
<em>34</em>(3), 2259–2286. (<a
href="https://doi.org/10.1137/23M1588512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a new gradient-like dynamical system related to unconstrained convex smooth multiobjective optimization which involves inertial effects and asymptotic vanishing damping. To the best of our knowledge, this system is the first inertial gradient-like system for multiobjective optimization problems including asymptotic vanishing damping, expanding the ideas previously laid out in [H. Attouch and G. Garrigos, Multiobjective Optimization: An Inertial Dynamical Approach to Pareto Optima, preprint, arXiv:1506.02823, 2015]. We prove existence of solutions to this system in finite dimensions and further prove that its bounded solutions converge weakly to weakly Pareto optimal points. In addition, we obtain a convergence rate of order for the function values measured with a merit function. This approach presents a good basis for the development of fast gradient methods for multiobjective optimization.},
  archive      = {J_SIOPT},
  author       = {Konstantin Sonntag and Sebastian Peitz},
  doi          = {10.1137/23M1588512},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2259-2286},
  shortjournal = {SIAM J. Optim.},
  title        = {Fast convergence of inertial multiobjective gradient-like systems with asymptotic vanishing damping},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable frank–wolfe on generalized self-concordant
functions via simple steps. <em>SIOPT</em>, <em>34</em>(3), 2231–2258.
(<a href="https://doi.org/10.1137/23M1616789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Generalized self-concordance is a key property present in the objective function of many important learning problems. We establish the convergence rate of a simple Frank–Wolfe variant that uses the open-loop step size strategy , obtaining an convergence rate for this class of functions in terms of primal gap and Frank–Wolfe gap, where is the iteration count. This avoids the use of second-order information or the need to estimate local smoothness parameters of previous work. We also show improved convergence rates for various common cases, e.g., when the feasible region under consideration is uniformly convex or polyhedral.},
  archive      = {J_SIOPT},
  author       = {Alejandro Carderera and Mathieu Besançon and Sebastian Pokutta},
  doi          = {10.1137/23M1616789},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2231-2258},
  shortjournal = {SIAM J. Optim.},
  title        = {Scalable Frank–Wolfe on generalized self-concordant functions via simple steps},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Path-following methods for maximum a posteriori estimators
in bayesian hierarchical models: How estimates depend on
hyperparameters. <em>SIOPT</em>, <em>34</em>(3), 2201–2230. (<a
href="https://doi.org/10.1137/22M153330X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Maximum a posteriori (MAP) estimation, like all Bayesian methods, depends on prior assumptions. These assumptions are often chosen to promote specific features in the recovered estimate. The form of the chosen prior determines the shape of the posterior distribution, thus the behavior of the estimator and complexity of the associated optimization problem. Here, we consider a family of Gaussian hierarchical models with generalized gamma hyperpriors designed to promote sparsity in linear inverse problems. By varying the hyperparameters, we move continuously between priors that act as smoothed penalties with flexible , smoothing, and scale. We then introduce a predictor-corrector method that tracks MAP solution paths as the hyperparameters vary. Path following allows a user to explore the space of possible MAP solutions and to test the sensitivity of solutions to changes in the prior assumptions. By tracing paths from a convex region to a nonconvex region, the user could find local minimizers in strongly sparsity promoting regimes that are consistent with a convex relaxation derived using related prior assumptions. We show experimentally that these solutions are less error prone than direct optimization of the nonconvex problem.},
  archive      = {J_SIOPT},
  author       = {Zilai Si and Yucong Liu and Alexander Strang},
  doi          = {10.1137/22M153330X},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2201-2230},
  shortjournal = {SIAM J. Optim.},
  title        = {Path-following methods for maximum a posteriori estimators in bayesian hierarchical models: How estimates depend on hyperparameters},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A feasible method for general convex low-rank SDP problems.
<em>SIOPT</em>, <em>34</em>(3), 2169–2200. (<a
href="https://doi.org/10.1137/23M1561464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we consider the low-rank decomposition (SDPR) of general convex semidefinite programming (SDP) problems that contain both a positive semidefinite matrix and a nonnegative vector as variables. We develop a rank-support-adaptive feasible method to solve (SDPR) based on Riemannian optimization. The method is able to escape from a saddle point to ensure its convergence to a global optimal solution for generic constraint vectors. We prove its global convergence and local linear convergence without assuming that the objective function is twice differentiable. Due to the special structure of the low-rank SDP problem, our algorithm can achieve better iteration complexity than existing results for more general smooth nonconvex problems. In order to overcome the degeneracy issues of SDP problems, we develop two strategies based on random perturbation and dual refinement. These techniques enable us to solve some primal degenerate SDP problems efficiently, for example, Lovász theta SDPs. Our work is a step forward in extending the application range of Riemannian optimization approaches for solving SDP problems. Numerical experiments are conducted to verify the efficiency and robustness of our method.},
  archive      = {J_SIOPT},
  author       = {Tianyun Tang and Kim-Chuan Toh},
  doi          = {10.1137/23M1561464},
  journal      = {SIAM Journal on Optimization},
  month        = {9},
  number       = {3},
  pages        = {2169-2200},
  shortjournal = {SIAM J. Optim.},
  title        = {A feasible method for general convex low-rank SDP problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear convergence of forward-backward accelerated
algorithms without knowledge of the modulus of strong convexity.
<em>SIOPT</em>, <em>34</em>(2), 2150–2168. (<a
href="https://doi.org/10.1137/23M158111X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A significant milestone in modern gradient-based optimization was achieved with the development of Nesterov’s accelerated gradient descent (NAG) method. This forward-backward technique has been further advanced with the introduction of its proximal generalization, commonly known as the fast iterative shrinkage-thresholding algorithm (FISTA), which enjoys widespread application in image science and engineering. Nonetheless, it remains unclear whether both NAG and FISTA exhibit linear convergence for strongly convex functions. Remarkably, these algorithms demonstrate convergence without requiring any prior knowledge of strongly convex modulus, and this intriguing characteristic has been acknowledged as an open problem in the comprehensive review [A. Chambolle and T. Pock, Acta Numer., 25 (2016), pp. 161–319]. In this paper, we address this question by utilizing the high-resolution ordinary differential equation (ODE) framework. Expanding upon the established phase-space representation, we emphasize the distinctive approach employed in crafting the Lyapunov function, which involves a dynamically adapting coefficient of kinetic energy that evolves throughout the iterations. Furthermore, we highlight that the linear convergence of both NAG and FISTA is independent of the parameter . Additionally, we demonstrate that the square of the proximal subgradient norm likewise advances toward linear convergence.},
  archive      = {J_SIOPT},
  author       = {Bowen Li and Bin Shi and Ya-xiang Yuan},
  doi          = {10.1137/23M158111X},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {2150-2168},
  shortjournal = {SIAM J. Optim.},
  title        = {Linear convergence of forward-backward accelerated algorithms without knowledge of the modulus of strong convexity},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximation guarantees for min-max-min robust optimization
and <span class="math inline"><strong>k</strong></span>-adaptability
under objective uncertainty. <em>SIOPT</em>, <em>34</em>(2), 2121–2149.
(<a href="https://doi.org/10.1137/23M1595084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work we investigate the min-max-min robust optimization problem and the k-adaptability robust optimization problem for binary problems with uncertain costs. The idea of the first approach is to calculate a set of k feasible solutions which are worst-case optimal if in each possible scenario the best of the k solutions is implemented. It is known that the min-max-min robust problem can be solved efficiently if k is at least the dimension of the problem, while it is theoretically and computationally hard if k is small. However, nothing is known about the intermediate case, i.e., k lies between one and the dimension of the problem. We approach this open question and present an approximation algorithm which achieves good problem-specific approximation guarantees for the cases where k is close to or a fraction of the dimension. The derived bounds can be used to show that the min-max-min robust problem is solvable in oracle-polynomial time under certain conditions even if k is smaller than the dimension. We extend the previous results to the robust k-adaptability problem. As a consequence we can provide bounds on the number of necessary second-stage policies to approximate the exact two-stage robust problem. We derive an approximation algorithm for the k-adaptability problem which has similar guarantees as for the min-max-min problem. Finally, we test both algorithms on knapsack and shortest path problems. The experiments show that both algorithms calculate solutions with relatively small optimality gap in seconds.},
  archive      = {J_SIOPT},
  author       = {Jannis Kurtz},
  doi          = {10.1137/23M1595084},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {2121-2149},
  shortjournal = {SIAM J. Optim.},
  title        = {Approximation guarantees for min-max-min robust optimization and \({\boldsymbol{k}}\)-adaptability under objective uncertainty},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameter-free accelerated gradient descent for nonconvex
minimization. <em>SIOPT</em>, <em>34</em>(2), 2093–2120. (<a
href="https://doi.org/10.1137/22M1540934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a new first-order method for minimizing nonconvex functions with a Lipschitz continuous gradient and Hessian. The proposed method is an accelerated gradient descent with two restart mechanisms and finds a solution where the gradient norm is less than in function and gradient evaluations. Unlike existing first-order methods with similar complexity bounds, our algorithm is parameter-free because it requires no prior knowledge of problem-dependent parameters, e.g., the Lipschitz constants and the target accuracy . The main challenge in achieving this advantage is estimating the Lipschitz constant of the Hessian using only first-order information. To this end, we develop a new Hessian-free analysis based on two technical inequalities: a Jensen-type inequality for gradients and an error bound for the trapezoidal rule. Several numerical results illustrate that the proposed method performs comparably to existing algorithms with similar complexity bounds, even without parameter tuning.},
  archive      = {J_SIOPT},
  author       = {Naoki Marumo and Akiko Takeda},
  doi          = {10.1137/22M1540934},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {2093-2120},
  shortjournal = {SIAM J. Optim.},
  title        = {Parameter-free accelerated gradient descent for nonconvex minimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic trust-region and direct-search methods: A weak
tail bound condition and reduced sample sizing. <em>SIOPT</em>,
<em>34</em>(2), 2067–2092. (<a
href="https://doi.org/10.1137/22M1543446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Using tail bounds, we introduce a new probabilistic condition for function estimation in stochastic derivative-free optimization (SDFO) which leads to a reduction in the number of samples and eases algorithmic analyses. Moreover, we develop simple stochastic direct-search and trust-region methods for the optimization of a potentially nonsmooth function whose values can only be estimated via stochastic observations. For trial points to be accepted, these algorithms require the estimated function values to yield a sufficient decrease measured in terms of a power larger than 1 of the algoritmic stepsize. Our new tail bound condition is precisely imposed on the reduction estimate used to achieve such a sufficient decrease. This condition allows us to select the stepsize power used for sufficient decrease in such a way that the number of samples needed per iteration is reduced. In previous works, the number of samples necessary for global convergence at every iteration of this type of algorithm was , where is the stepsize or trust-region radius. However, using the new tail bound condition, and under mild assumptions on the noise, one can prove that such a number of samples is only , where can be made arbitrarily small by selecting the power of the stepsize in the sufficient decrease test arbitrarily close to 1. In the common random number generator setting, a further improvement by a factor of can be obtained. The global convergence properties of the stochastic direct-search and trust-region algorithms are established under the new tail bound condition.},
  archive      = {J_SIOPT},
  author       = {F. Rinaldi and L. N. Vicente and D. Zeffiro},
  doi          = {10.1137/22M1543446},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {2067-2092},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic trust-region and direct-search methods: A weak tail bound condition and reduced sample sizing},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient sieving-based secant method for sparse
optimization problems with least-squares constraints. <em>SIOPT</em>,
<em>34</em>(2), 2038–2066. (<a
href="https://doi.org/10.1137/23M1594443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose an efficient sieving-based secant method to address the computational challenges of solving sparse optimization problems with least-squares constraints. A level-set method has been introduced in [X. Li, D. F. Sun, and K.-C. Toh, SIAM J. Optim., 28 (2018), pp. 1842–1866] that solves these problems by using the bisection method to find a root of a univariate nonsmooth equation for some , where is the value function computed by a solution of the corresponding regularized least-squares optimization problem. When the objective function in the constrained problem is a polyhedral gauge function, we prove that (i) for any positive integer , is piecewise in an open interval containing the solution to the equation and that (ii) the Clarke Jacobian of is always positive. These results allow us to establish the essential ingredients of the fast convergence rates of the secant method. Moreover, an adaptive sieving technique is incorporated into the secant method to effectively reduce the dimension of the level-set subproblems for computing the value of . The high efficiency of the proposed algorithm is demonstrated by extensive numerical results.},
  archive      = {J_SIOPT},
  author       = {Qian Li and Defeng Sun and Yancheng Yuan},
  doi          = {10.1137/23M1594443},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {2038-2066},
  shortjournal = {SIAM J. Optim.},
  title        = {An efficient sieving-based secant method for sparse optimization problems with least-squares constraints},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fully stochastic trust-region sequential quadratic
programming for equality-constrained optimization problems.
<em>SIOPT</em>, <em>34</em>(2), 2007–2037. (<a
href="https://doi.org/10.1137/22M1537862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a trust-region stochastic sequential quadratic programming algorithm (TR-StoSQP) to solve nonlinear optimization problems with stochastic objectives and deterministic equality constraints. We consider a fully stochastic setting, where at each step a single sample is generated to estimate the objective gradient. The algorithm adaptively selects the trust-region radius and, compared to the existing line-search StoSQP schemes, allows us to utilize indefinite Hessian matrices (i.e., Hessians without modification) in SQP subproblems. As a trust-region method for constrained optimization, our algorithm must address an infeasibility issue—the linearized equality constraints and trust-region constraints may lead to infeasible SQP subproblems. In this regard, we propose an adaptive relaxation technique to compute the trial step, consisting of a normal step and a tangential step. To control the lengths of these two steps while ensuring a scale-invariant property, we adaptively decompose the trust-region radius into two segments, based on the proportions of the rescaled feasibility and optimality residuals to the rescaled full KKT residual. The normal step has a closed form, while the tangential step is obtained by solving a trust-region subproblem, to which a solution ensuring the Cauchy reduction is sufficient for our study. We establish a global almost sure convergence guarantee for TR-StoSQP and illustrate its empirical performance on both a subset of problems in the CUTEst test set and constrained logistic regression problems using data from the LIBSVM collection.},
  archive      = {J_SIOPT},
  author       = {Yuchen Fang and Sen Na and Michael W. Mahoney and Mladen Kolar},
  doi          = {10.1137/22M1537862},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {2007-2037},
  shortjournal = {SIAM J. Optim.},
  title        = {Fully stochastic trust-region sequential quadratic programming for equality-constrained optimization problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reducing nonnegativity over general semialgebraic sets to
nonnegativity over simple sets. <em>SIOPT</em>, <em>34</em>(2),
1970–2006. (<a href="https://doi.org/10.1137/22M1501027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A nonnegativity certificate (NNC) is a way to write a polynomial so that its nonnegativity on a semialgebraic set becomes evident. Positivstellensätze (Psätze) guarantee the existence of NNCs. Both NNCs and Psätze underlie powerful algorithmic techniques for optimization. This paper proposes a universal approach to derive new Psätze for general semialgebraic sets from ones developed for simpler sets, such as a box, a simplex, or the nonnegative orthant. We provide several results illustrating the approach. First, by considering Handelman’s Positivstellensatz (Psatz) over a box, we construct non-SOS Schmüdgen-type Psätze over any compact semialgebraic set, that is, a family of Psätze that follow the structure of the fundamental Schmüdgen’s Psatz but where instead of SOS polynomials, any class of polynomials containing the nonnegative constants can be used, such as SONC, DSOS/SDSOS, hyperbolic, or sums of AM/GM polynomials. Second, by considering the simplex as the simple set, we derive a sparse Psatz over general compact sets which does not rely on any structural assumptions of the set. Finally, by considering Pólya’s Psatz over the nonnegative orthant, we derive a new non-SOS Psatz over unbounded sets which satisfy some generic conditions. All these results contribute to the literature regarding the use of non-SOS polynomials and sparse NNCs to derive Psätze over compact and unbounded sets. Throughout the article, we illustrate our results with relevant examples and numerical experiments.},
  archive      = {J_SIOPT},
  author       = {Olga Kuryatnikova and Juan C. Vera and Luis F. Zuluaga},
  doi          = {10.1137/22M1501027},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1970-2006},
  shortjournal = {SIAM J. Optim.},
  title        = {Reducing nonnegativity over general semialgebraic sets to nonnegativity over simple sets},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). First-order penalty methods for bilevel optimization.
<em>SIOPT</em>, <em>34</em>(2), 1937–1969. (<a
href="https://doi.org/10.1137/23M1566753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we study a class of unconstrained and constrained bilevel optimization problems in which the lower level is a possibly nonsmooth convex optimization problem, while the upper level is a possibly nonconvex optimization problem. We introduce a notion of -KKT solution for them and show that an -KKT solution leads to an - or -hypergradient–based stationary point under suitable assumptions. We also propose first-order penalty methods for finding an -KKT solution of them, whose subproblems turn out to be a structured minimax problem and can be suitably solved by a first-order method recently developed by the authors. Under suitable assumptions, an operation complexity of and , measured by their fundamental operations, is established for the proposed penalty methods for finding an -KKT solution of the unconstrained and constrained bilevel optimization problems, respectively. Preliminary numerical results are presented to illustrate the performance of our proposed methods. To the best of our knowledge, this paper is the first work to demonstrate that bilevel optimization can be approximately solved as minimax optimization, and moreover, it provides the first implementable method with complexity guarantees for such sophisticated bilevel optimization.},
  archive      = {J_SIOPT},
  author       = {Zhaosong Lu and Sanyou Mei},
  doi          = {10.1137/23M1566753},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1937-1969},
  shortjournal = {SIAM J. Optim.},
  title        = {First-order penalty methods for bilevel optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time consistency for multistage stochastic optimization
problems under constraints in expectation. <em>SIOPT</em>,
<em>34</em>(2), 1909–1936. (<a
href="https://doi.org/10.1137/22M151830X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider sequences—indexed by time (discrete stages)—of parametric families of multistage stochastic optimization problems; thus, at each time, the optimization problems in a family are parameterized by some quantities (initial states, constraint levels, and so on). In this framework, we introduce an adapted notion of parametric time-consistent optimal solutions: They are solutions that remain optimal after truncation of the past and that are optimal for any values of the parameters. We link this time consistency notion with the concept of state variable in Markov decision processes for a class of multistage stochastic optimization problems incorporating state constraints at the final time, formulated in expectation. For such problems, when the primitive noise random process is stagewise independent and takes a finite number of values, we show that time-consistent solutions can be obtained by considering a finite-dimensional state variable. We illustrate our results on a simple dam management problem.},
  archive      = {J_SIOPT},
  author       = {Pierre Carpentier and Jean-Philippe Chancelier and Michel De Lara},
  doi          = {10.1137/22M151830X},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1909-1936},
  shortjournal = {SIAM J. Optim.},
  title        = {Time consistency for multistage stochastic optimization problems under constraints in expectation},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Derivative-free alternating projection algorithms for
general nonconvex-concave minimax problems. <em>SIOPT</em>,
<em>34</em>(2), 1879–1908. (<a
href="https://doi.org/10.1137/23M1568168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we study zeroth-order algorithms for nonconvex-concave minimax problems, which have attracted much attention in machine learning, signal processing, and many other fields in recent years. We propose a zeroth-order alternating randomized gradient projection (ZO-AGP) algorithm for smooth nonconvex-concave minimax problems; its iteration complexity to obtain an -stationary point is bounded by , and the number of function value estimates is bounded by per iteration. Moreover, we propose a zeroth-order block alternating randomized proximal gradient algorithm (ZO-BAPG) for solving blockwise nonsmooth nonconvex-concave minimax optimization problems; its iteration complexity to obtain an -stationary point is bounded by , and the number of function value estimates per iteration is bounded by . To the best of our knowledge, this is the first time zeroth-order algorithms with iteration complexity guarantee are developed for solving both general smooth and blockwise nonsmooth nonconvex-concave minimax problems. Numerical results on the data poisoning attack problem and the distributed nonconvex sparse principal component analysis problem validate the efficiency of the proposed algorithms.},
  archive      = {J_SIOPT},
  author       = {Zi Xu and Ziqi Wang and Jingjing Shen and Yuhong Dai},
  doi          = {10.1137/23M1568168},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1879-1908},
  shortjournal = {SIAM J. Optim.},
  title        = {Derivative-free alternating projection algorithms for general nonconvex-concave minimax problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On difference-of-SOS and difference-of-convex-SOS
decompositions for polynomials. <em>SIOPT</em>, <em>34</em>(2),
1852–1878. (<a href="https://doi.org/10.1137/22M1495524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this article, we are interested in developing polynomial decomposition techniques based on sums-of-squares (SOS), namely the difference-of-sums-of-squares (D-SOS) and the difference-of-convex-sums-of-squares (DC-SOS). In particular, the DC-SOS decomposition is very useful for difference-of-convex (DC) programming formulation of polynomial optimization problems. First, we introduce the cone of convex-sums-of-squares (CSOS) polynomials and discuss its relationship to the sums-of-squares (SOS) polynomials, the non-negative polynomials, and the SOS-convex polynomials. Then we propose the set of D-SOS and DC-SOS polynomials and prove that any polynomial can be formulated as D-SOS and DC-SOS. The problem of finding D-SOS and DC-SOS decompositions can be formulated as a semi-definite program and solved for any desired precision in polynomial time using interior point methods. Some algebraic properties of CSOS, D-SOS, and DC-SOS are established. Second, we focus on establishing several practical algorithms for exact D-SOS and DC-SOS polynomial decompositions without solving any SDP. The numerical performance of the proposed D-SOS and DC-SOS decomposition algorithms and their parallel versions, tested on a dataset of 1750 randomly generated polynomials, is reported.},
  archive      = {J_SIOPT},
  author       = {Yi-Shuai Niu and Hoai An Le Thi and Dinh Tao Pham},
  doi          = {10.1137/22M1495524},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1852-1878},
  shortjournal = {SIAM J. Optim.},
  title        = {On difference-of-SOS and difference-of-convex-SOS decompositions for polynomials},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vector asymptotic functions and their application to
multiobjective optimization problems. <em>SIOPT</em>, <em>34</em>(2),
1826–1851. (<a href="https://doi.org/10.1137/23M158098X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce two notions of vector asymptotic functions for vector functions with their image space ordered by the nonnegative orthant. To do this, a suitable extended-valued framework is used. We establish properties and formulas for these notions. The asymptotic notions are used to study multiobjective optimization problems. We obtain (outer/inner) estimates for the asymptotic and recession cones of level, colevel, and weakly efficient solution sets. With this information, we establish coercivity properties, coercive and noncoercive existence results for solutions of multiobjective optimization problems.},
  archive      = {J_SIOPT},
  author       = {Fabián Flores-Bazán and Rubén López and Cristian Vera},
  doi          = {10.1137/23M158098X},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1826-1851},
  shortjournal = {SIAM J. Optim.},
  title        = {Vector asymptotic functions and their application to multiobjective optimization problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constraint qualifications and strong global convergence
properties of an augmented lagrangian method on riemannian manifolds.
<em>SIOPT</em>, <em>34</em>(2), 1799–1825. (<a
href="https://doi.org/10.1137/23M1582382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In the past several years, augmented Lagrangian methods have been successfully applied to several classes of nonconvex optimization problems, inspiring new developments in both theory and practice. In this paper we bring most of these recent developments from nonlinear programming to the context of optimization on Riemannian manifolds, including equality and inequality constraints. Many research have been conducted on optimization problems on manifolds, however only recently the treatment of the constrained case has been considered. In this paper we propose to bridge this gap with respect to the most recent developments in nonlinear programming. In particular, we formulate several well-known constraint qualifications from the Euclidean context which are sufficient for guaranteeing global convergence of augmented Lagrangian methods, without requiring boundedness of the set of Lagrange multipliers. Convergence of the dual sequence can also be assured under a weak constraint qualification. The theory presented is based on so-called sequential optimality conditions, which is a powerful tool used in this context. The paper can also be read with the Euclidean context in mind, serving as a review of the most relevant constraint qualifications and global convergence theory of state-of-the-art augmented Lagrangian methods for nonlinear programming.},
  archive      = {J_SIOPT},
  author       = {Roberto Andreani and Kelvin R. Couto and Orizon P. Ferreira and Gabriel Haeser},
  doi          = {10.1137/23M1582382},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1799-1825},
  shortjournal = {SIAM J. Optim.},
  title        = {Constraint qualifications and strong global convergence properties of an augmented lagrangian method on riemannian manifolds},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extending the rademacher theorem to set-valued maps.
<em>SIOPT</em>, <em>34</em>(2), 1784–1798. (<a
href="https://doi.org/10.1137/22M1538831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Rademacher theorem asserts that Lipschitz continuous functions between Euclidean spaces are differentiable almost everywhere. In this work we extend this result to set-valued maps using an adequate notion of set-valued differentiability relating to convex processes. Our approach uses the Rademacher theorem but also recovers it as a special case.},
  archive      = {J_SIOPT},
  author       = {Aris Daniilidis and Marc Quincampoix},
  doi          = {10.1137/22M1538831},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1784-1798},
  shortjournal = {SIAM J. Optim.},
  title        = {Extending the rademacher theorem to set-valued maps},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pragmatic distributionally robust optimization for simple
integer recourse models. <em>SIOPT</em>, <em>34</em>(2), 1755–1783. (<a
href="https://doi.org/10.1137/22M1523509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Inspired by its success for their continuous counterparts, the standard approach to deal with mixed-integer recourse (MIR) models under distributional uncertainty is to use distributionally robust optimization (DRO). We argue, however, that this modeling choice is not always justified since DRO techniques are generally computationally challenging when integer decision variables are involved. That is why we propose an alternative approach for dealing with distributional uncertainty for the special case of simple integer recourse (SIR) models, which is aimed at obtaining models with improved computational tractability. We show that such models can be obtained by pragmatically selecting the uncertainty set. Here, we consider uncertainty sets based on the Wasserstein distance and also on generalized moment conditions. We compare our approach with standard DRO both numerically and theoretically. An important side result of our analysis is the derivation of performance guarantees for convex approximations of SIR models. In contrast to the literature, these error bounds are not only valid for a continuous distribution but hold for any distribution.},
  archive      = {J_SIOPT},
  author       = {E. Ruben van Beesten and Ward Romeijnders and David P. Morton},
  doi          = {10.1137/22M1523509},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1755-1783},
  shortjournal = {SIAM J. Optim.},
  title        = {Pragmatic distributionally robust optimization for simple integer recourse models},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clarke’s tangent cones, subgradients, optimality conditions,
and the lipschitzness at infinity. <em>SIOPT</em>, <em>34</em>(2),
1732–1754. (<a href="https://doi.org/10.1137/23M1545367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We first study Clarke’s tangent cones at infinity to unbounded subsets of . We prove that these cones are closed convex and show a characterization of their interiors. We then study subgradients at infinity for extended real value functions on and derive necessary optimality conditions at infinity for optimization problems. We also give a number of rules for the computing of subgradients at infinity and provide some characterizations of the Lipschitz continuity at infinity for lower semicontinuous functions.},
  archive      = {J_SIOPT},
  author       = {Minh Tùng Nguyễn and Tiến-Sơn Phạm},
  doi          = {10.1137/23M1545367},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1732-1754},
  shortjournal = {SIAM J. Optim.},
  title        = {Clarke’s tangent cones, subgradients, optimality conditions, and the lipschitzness at infinity},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Occupation measure relaxations in variational problems: The
role of convexity. <em>SIOPT</em>, <em>34</em>(2), 1708–1731. (<a
href="https://doi.org/10.1137/23M1557088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work addresses the occupation measure relaxation of calculus of variations problems, which is an infinite-dimensional linear programming reformulation amenable to numerical approximation by a hierarchy of semidefinite optimization problems. We address the problem of equivalence of this relaxation to the original problem. Our main result provides sufficient conditions for this equivalence. These conditions, revolving around the convexity of the data, are simple and apply in very general settings that may be of arbitrary dimensions and may include pointwise and integral constraints, thereby considerably strengthening the existing results. Our conditions are also extended to optimal control problems. In addition, we demonstrate how these results can be applied in nonconvex settings, showing that the occupation measure relaxation is at least as strong as the convexification using the convex envelope; in doing so, we prove that a certain weakening of the occupation measure relaxation is equivalent to the convex envelope. This opens the way to application of the occupation measure relaxation in situations where the convex envelope relaxation is known to be equivalent to the original problem, which includes problems in magnetism and elasticity.},
  archive      = {J_SIOPT},
  author       = {Didier Henrion and Milan Korda and Martin Kruzik and Rodolfo Rios-Zertuche},
  doi          = {10.1137/23M1557088},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1708-1731},
  shortjournal = {SIAM J. Optim.},
  title        = {Occupation measure relaxations in variational problems: The role of convexity},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual descent augmented lagrangian method and alternating
direction method of multipliers. <em>SIOPT</em>, <em>34</em>(2),
1679–1707. (<a href="https://doi.org/10.1137/21M1449099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Classical primal-dual algorithms attempt to solve by alternately minimizing over the primal variable through primal descent and maximizing the dual variable through dual ascent. However, when is highly nonconvex with complex constraints in , the minimization over may not achieve global optimality and, hence, the dual ascent step loses its valid intuition. This observation motivates us to propose a new class of primal-dual algorithms for nonconvex constrained optimization with the key feature to reverse dual ascent to a conceptually new dual descent, in a sense, elevating the dual variable to the same status as the primal variable. Surprisingly, this new dual scheme achieves some best iteration complexities for solving nonconvex optimization problems. In particular, when the dual descent step is scaled by a fractional constant, we name it scaled dual descent (SDD), otherwise, unscaled dual descent (UDD). For nonconvex multiblock optimization with nonlinear equality constraints, we propose SDD-alternating direction method of multipliers (SDD-ADMM) and show that it finds an -stationary solution in iterations. The complexity is further improved to and under proper conditions. We also propose UDD-augmented Lagrangian method (UDD-ALM), combining UDD with ALM, for weakly convex minimization over affine constraints. We show that UDD-ALM finds an -stationary solution in iterations. These complexity bounds for both algorithms either achieve or improve the best-known results in the ADMM and ALM literature. Moreover, SDD-ADMM addresses a long-standing limitation of existing ADMM frameworks.},
  archive      = {J_SIOPT},
  author       = {Kaizhao Sun and Xu Andy Sun},
  doi          = {10.1137/21M1449099},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1679-1707},
  shortjournal = {SIAM J. Optim.},
  title        = {Dual descent augmented lagrangian method and alternating direction method of multipliers},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single-projection procedure for infinite dimensional convex
optimization problems. <em>SIOPT</em>, <em>34</em>(2), 1646–1678. (<a
href="https://doi.org/10.1137/22M1530173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a class of convex optimization problems in a Hilbert space that can be solved by performing a single projection, i.e., by projecting an infeasible point onto the feasible set. Our results improve those established for the linear programming setting in Nurminski (2015) by considering problems that (i) may have multiple solutions, (ii) do not satisfy strict complementarity conditions, and (iii) possess nonlinear convex constraints. As a by-product of our analysis, we provide a quantitative estimate on the required distance between the infeasible point and the feasible set in order for its projection to be a solution of the problem. Our analysis relies on a “sharpness” property of the constraint set, a new property we introduce here.},
  archive      = {J_SIOPT},
  author       = {Hoa T. Bui and Regina S. Burachik and Evgeni A. Nurminski and Matthew K. Tam},
  doi          = {10.1137/22M1530173},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1646-1678},
  shortjournal = {SIAM J. Optim.},
  title        = {Single-projection procedure for infinite dimensional convex optimization problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact augmented lagrangian duality for mixed integer convex
optimization. <em>SIOPT</em>, <em>34</em>(2), 1622–1645. (<a
href="https://doi.org/10.1137/22M1526204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Augmented Lagrangian dual augments the classical Lagrangian dual with a nonnegative nonlinear penalty function of the violation of the relaxed/dualized constraints in order to reduce the duality gap. We investigate the cases in which mixed integer convex optimization problems have an exact penalty representation using sharp augmenting functions (norms as augmenting penalty functions). We present a generalizable constructive proof technique for proving existence of exact penalty representations for mixed integer convex programs under specific conditions using the associated value functions. This generalizes the recent results for mixed integer linear programming [M. J. Feizollahi, S. Ahmed, and A. Sun, Math. Program., 161 (2017), pp. 365–387] and mixed integer quadratic progamming [X. Gu, S. Ahmed, and S. S. Dey, SIAM J. Optim., 30 (2020), pp. 781–797] while also providing an alternative proof for the aforementioned along with quantification of the finite penalty parameter in these cases.},
  archive      = {J_SIOPT},
  author       = {Avinash Bhardwaj and Vishnu Narayanan and Abhishek Pathapati},
  doi          = {10.1137/22M1526204},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1622-1645},
  shortjournal = {SIAM J. Optim.},
  title        = {Exact augmented lagrangian duality for mixed integer convex optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Frugal splitting operators: Representation, minimal lifting,
and convergence. <em>SIOPT</em>, <em>34</em>(2), 1595–1621. (<a
href="https://doi.org/10.1137/22M1531105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We investigate frugal splitting operators for finite sum monotone inclusion problems. These operators utilize exactly one direct or resolvent evaluation of each operator of the sum, and the splitting operator’s output is dictated by linear combinations of these evaluations’ inputs and outputs. To facilitate analysis, we introduce a novel representation of frugal splitting operators via a generalized primal-dual resolvent. The representation is characterized by an index and four matrices, and we provide conditions on these that ensure equivalence between the classes of frugal splitting operators and generalized primal-dual resolvents. Our representation paves the way for new results regarding lifting numbers and the development of a unified convergence analysis for frugal splitting operator methods, contingent on the directly evaluated operators being cocoercive. The minimal lifting number is where is the number of monotone operators and is the number of direct evaluations in the splitting. Notably, this lifting number is achievable only if the first and last operator evaluations are resolvent evaluations. These results generalize the minimal lifting results by Ryu and by Malitsky and Tam that consider frugal resolvent splittings. Building on our representation, we delineate a constructive method to design frugal splitting operators, exemplified in the design of a novel, convergent, and parallelizable frugal splitting operator with minimal lifting.},
  archive      = {J_SIOPT},
  author       = {Martin Morin and Sebastian Banert and Pontus Giselsson},
  doi          = {10.1137/22M1531105},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1595-1621},
  shortjournal = {SIAM J. Optim.},
  title        = {Frugal splitting operators: Representation, minimal lifting, and convergence},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph and distributed extensions of the douglas–rachford
method. <em>SIOPT</em>, <em>34</em>(2), 1569–1594. (<a
href="https://doi.org/10.1137/22M1535097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose several graph-based extensions of the Douglas–Rachford splitting (DRS) method to solve monotone inclusion problems involving the sum of maximal monotone operators. Our construction is based on the choice of two nested graphs, to which we associate a generalization of the DRS algorithm that presents a prescribed structure. The resulting schemes can be understood as unconditionally stable frugal resolvent splitting methods with minimal lifting in the sense of Ryu [Math. Program., 182 (2020), pp. 233–273] as well as instances of the (degenerate) preconditioned proximal point method, which provides robust convergence guarantees. We further describe how the graph-based extensions of the DRS method can be leveraged to design new fully distributed protocols. Applications to a congested optimal transport problem and to distributed support vector machines show interesting connections with the underlying graph topology and highly competitive performances with state-of-the-art distributed optimization approaches.},
  archive      = {J_SIOPT},
  author       = {Kristian Bredies and Enis Chenchene and Emanuele Naldi},
  doi          = {10.1137/22M1535097},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1569-1594},
  shortjournal = {SIAM J. Optim.},
  title        = {Graph and distributed extensions of the Douglas–Rachford method},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A family of <span
class="math inline"><strong>s</strong></span>-rectangular robust MDPs:
Relative conservativeness, asymptotic analyses, and finite-sample
properties. <em>SIOPT</em>, <em>34</em>(2), 1540–1568. (<a
href="https://doi.org/10.1137/23M1559920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce a family of -rectangular robust Markov decision processes (-RMDPs) indexed with . In each state, the ambiguity set of transition probability mass functions (pmfs) across actions equals a sublevel set of the -norm of a vector of distances from reference pmfs. Setting recovers -RMDPs. For any -RMDP from this family, there is an -RMDP whose robust optimal value is at least as good, and vice versa. This occurs because - and -RMDPs can employ different ambiguity set radii, casting doubt on the belief that -RMDPs are more conservative than -RMDPs. If the distance is lower semicontinuous and convex, then, for any -RMDP, there exists an -RMDP with an identical robust optimal value. We also study data-driven -RMDPs, where the reference pmf is constructed from state transition samples. If the distance satisfies a Pinsker-type inequality, the robust optimal and out-of-sample values both converge with sample-size to the true optimal. We derive rates of convergence and sample complexity when the distance satisfies a concentration inequality. Under this concentration inequality, the robust optimal value provides a probabilistic lower bound on the out-of-sample value. An artifact of the analyses behind these guarantees is the surprising conclusion that -RMDPs might be the least conservative among all -RMDPs within our family. The asymptotic and finite sample properties also extend for a class of nonrectangular RMDPs.},
  archive      = {J_SIOPT},
  author       = {Sivaramakrishnan Ramani and Archis Ghate},
  doi          = {10.1137/23M1559920},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1540-1568},
  shortjournal = {SIAM J. Optim.},
  title        = {A family of \(\boldsymbol{s}\)-rectangular robust MDPs: Relative conservativeness, asymptotic analyses, and finite-sample properties},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On enhanced KKT optimality conditions for smooth nonlinear
optimization. <em>SIOPT</em>, <em>34</em>(2), 1515–1539. (<a
href="https://doi.org/10.1137/22M1539678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Fritz John (FJ) and Karush–Kuhn–Tucker (KKT) conditions are fundamental tools for characterizing minimizers and form the basis of almost all methods for constrained optimization. Since the seminal works of Fritz John, Karush, Kuhn, and Tucker, FJ/KKT conditions have been enhanced by adding extra necessary conditions. Such an extension was initially proposed by Hestenes in the 1970s and later extensively studied by Bertsekas and collaborators. In this work, we revisit enhanced KKT stationarity for standard (smooth) nonlinear programming. We argue that every KKT point satisfies the usual enhanced versions found in the literature. Therefore, enhanced KKT stationarity only concerns the Lagrange multipliers. We then analyze some properties of the corresponding multipliers under the quasi-normality constraint qualification (QNCQ), showing in particular that the set of so-called quasinormal multipliers is compact under QNCQ. Also, we report some consequences of introducing an extra abstract constraint to the problem. Given that enhanced FJ/KKT concepts are obtained by aggregating sequential conditions to FJ/KKT, we discuss the relevance of our findings with respect to the well-known sequential optimality conditions, which have been crucial in generalizing the global convergence of a well-established safeguarded augmented Lagrangian method. Finally, we apply our theory to mathematical programs with complementarity constraints and multiobjective problems, improving and elucidating previous results in the literature.},
  archive      = {J_SIOPT},
  author       = {Roberto Andreani and María L. Schuverdt and Leonardo D. Secchin},
  doi          = {10.1137/22M1539678},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1515-1539},
  shortjournal = {SIAM J. Optim.},
  title        = {On enhanced KKT optimality conditions for smooth nonlinear optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weighted geometric mean, minimum mediated set, and optimal
simple second-order cone representation. <em>SIOPT</em>, <em>34</em>(2),
1490–1514. (<a href="https://doi.org/10.1137/22M1531257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study optimal simple second-order cone representations (a particular subclass of second-order cone representations) for weighted geometric means, which turns out to be closely related to minimum mediated sets. Several lower bounds and upper bounds on the size of optimal simple second-order cone representations are proved. In the case of bivariate weighted geometric means (equivalently, one-dimensional mediated sets), we are able to prove the exact size of an optimal simple second-order cone representation and give an algorithm to compute one. In the genenal case, fast heuristic algorithms and traversal algorithms are proposed to compute an approximately optimal simple second-order cone representation. Finally, applications to polynomial optimization, matrix optimization, and quantum information are provided.},
  archive      = {J_SIOPT},
  author       = {Jie Wang},
  doi          = {10.1137/22M1531257},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1490-1514},
  shortjournal = {SIAM J. Optim.},
  title        = {Weighted geometric mean, minimum mediated set, and optimal simple second-order cone representation},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A copositive framework for analysis of hybrid
ising-classical algorithms. <em>SIOPT</em>, <em>34</em>(2), 1455–1489.
(<a href="https://doi.org/10.1137/22M1514581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Recent years have seen significant advances in quantum/quantum-inspired technologies capable of approximately searching for the ground state of Ising spin Hamiltonians. The promise of leveraging such technologies to accelerate the solution of difficult optimization problems has spurred an increased interest in exploring methods to integrate Ising problems as part of their solution process, with existing approaches ranging from direct transcription to hybrid quantum-classical approaches rooted in existing optimization algorithms. While it is widely acknowledged that quantum computers should augment classical computers, rather than replace them entirely, comparatively little attention has been directed toward deriving analytical characterizations of their interactions. In this paper, we present a formal analysis of hybrid algorithms in the context of solving mixed-binary quadratic programs (MBQP) via Ising solvers. By leveraging an existing completely positive reformulation of MBQPs, as well as a new strong-duality result, we show the exactness of the dual problem over the cone of copositive matrices, thus allowing the resulting reformulation to inherit the straightforward analysis of convex optimization. We propose to solve this reformulation with a hybrid quantum-classical cutting-plane algorithm. Using existing complexity results for convex cutting-plane algorithms, we deduce that the classical portion of this hybrid framework is guaranteed to be polynomial time. This suggests that when applied to NP-hard problems, the complexity of the solution is shifted onto the subroutine handled by the Ising solver.},
  archive      = {J_SIOPT},
  author       = {Robin Brown and David E. Bernal Neira and Davide Venturelli and Marco Pavone},
  doi          = {10.1137/22M1514581},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1455-1489},
  shortjournal = {SIAM J. Optim.},
  title        = {A copositive framework for analysis of hybrid ising-classical algorithms},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Benign landscapes of low-dimensional relaxations for
orthogonal synchronization on general graphs. <em>SIOPT</em>,
<em>34</em>(2), 1427–1454. (<a
href="https://doi.org/10.1137/23M1584642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Orthogonal group synchronization is the problem of estimating elements from the orthogonal group given some relative measurements . The least-squares formulation is nonconvex. To avoid its local minima, a Shor-type convex relaxation squares the dimension of the optimization problem from to . Alternatively, Burer–Monteiro-type nonconvex relaxations have generic landscape guarantees at dimension . For smaller relaxations, the problem structure matters. It has been observed in the robotics literature that, for simultaneous localization and mapping problems, it seems sufficient to increase the dimension by a small constant multiple over the original. We partially explain this. This also has implications for Kuramoto oscillators. Specifically, we minimize the least-squares cost function in terms of estimators . For , each is relaxed to the Stiefel manifold of matrices with orthonormal rows. The available measurements implicitly define a (connected) graph on vertices. In the noiseless case, we show that, for all connected graphs , second-order critical points are globally optimal as soon as . (This implies that Kuramoto oscillators on synchronize for all .) This result is the best possible for general graphs; the previous best known result requires . For , our result is robust to modest amounts of noise (depending on and ). Our proof uses a novel randomized choice of tangent direction to prove (near-)optimality of second-order critical points. Finally, we partially extend our noiseless landscape results to the complex case (unitary group); we show that there are no spurious local minima when .},
  archive      = {J_SIOPT},
  author       = {Andrew D. McRae and Nicolas Boumal},
  doi          = {10.1137/23M1584642},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1427-1454},
  shortjournal = {SIAM J. Optim.},
  title        = {Benign landscapes of low-dimensional relaxations for orthogonal synchronization on general graphs},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic differential equations for modeling first order
optimization methods. <em>SIOPT</em>, <em>34</em>(2), 1402–1426. (<a
href="https://doi.org/10.1137/21M1435665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this article, a family of SDEs are derived as a tool to understand the behavior of numerical optimization methods under random evaluations of the gradient. Our objective is to transpose the introduction of continuous versions through ODEs to understand the asymptotic behavior of a discrete optimization scheme to the stochastic setting. We consider a continuous version of the stochastic gradient scheme and of a stochastic inertial system. This article first studies the quality of the approximation of the discrete scheme by an SDE when the step size tends to 0. Then, it presents new asymptotic bounds on the values , where is a solution of the SDE and , when is convex and under integrability conditions on the noise. Results are provided under two sets of hypotheses: first considering and convex functions and then adding some geometrical properties of . All of these results provide insight on the behavior of these inertial and perturbed algorithms in the setting of stochastic algorithms.},
  archive      = {J_SIOPT},
  author       = {M. Dambrine and Ch. Dossal and B. Puig and A. Rondepierre},
  doi          = {10.1137/21M1435665},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1402-1426},
  shortjournal = {SIAM J. Optim.},
  title        = {Stochastic differential equations for modeling first order optimization methods},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A gradient complexity analysis for minimizing the sum of
strongly convex functions with varying condition numbers.
<em>SIOPT</em>, <em>34</em>(2), 1374–1401. (<a
href="https://doi.org/10.1137/22M1503646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A popular approach to minimizing a finite sum of smooth convex functions is stochastic gradient descent (SGD) and its variants. Fundamental research questions associated with SGD include (i) how to find a lower bound on the number of times that the gradient oracle of each individual function must be assessed in order to find an -minimizer of the overall objective; (ii) how to design algorithms which guarantee finding an -minimizer of the overall objective in expectation no more than a certain number of times (in terms of ) that the gradient oracle of each function needs to be assessed (i.e., upper bound). If these two bounds are at the same order of magnitude, then the algorithms may be called optimal. Most existing results along this line of research typically assume that the functions in the objective share the same condition number. In this paper, the first model we study is the problem of minimizing the sum of finitely many strongly convex functions whose condition numbers are all different. We propose an SGD-based method for this model and show that it is optimal in gradient computations, up to a logarithmic factor. We then consider a constrained separate block optimization model and present lower and upper bounds for its gradient computation complexity. Next, we propose solving the Fenchel dual of the constrained block optimization model via generalized SSNM, which we introduce earlier, and show that it yields a lower iteration complexity than solving the original model by the ADMM-type approach. Finally, we extend the analysis to the general composite convex optimization model and obtain gradient-computation complexity results under certain conditions.},
  archive      = {J_SIOPT},
  author       = {Nuozhou Wang and Shuzhong Zhang},
  doi          = {10.1137/22M1503646},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1374-1401},
  shortjournal = {SIAM J. Optim.},
  title        = {A gradient complexity analysis for minimizing the sum of strongly convex functions with varying condition numbers},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Certifying optimality of bell inequality violations:
Noncommutative polynomial optimization through semidefinite programming
and local optimization. <em>SIOPT</em>, <em>34</em>(2), 1341–1373. (<a
href="https://doi.org/10.1137/22M1473340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Bell inequalities are pillars of quantum physics in that their violations imply that certain properties of quantum physics (e.g., entanglement) cannot be represented by any classical picture of physics. In this article Bell inequalities and their violations are considered through the lens of noncommutative polynomial optimization. Optimality of these violations is certified for a large majority of a set of standard Bell inequalities, denoted A2–A89 in the literature. The main techniques used in the paper include the NPA hierarchy, i.e., the noncommutative version of the Lasserre semidefinite programming (SDP) hierarchies based on the Helton–McCullough Positivstellensatz, the Gelfand–Naimark–Segal (GNS) construction with a novel use of the Artin–Wedderburn theory for rounding and projecting, and nonlinear programming (NLP). A new “Newton chip”-like technique for reducing sizes of SDPs arising in the constructed polynomial optimization problems is presented. This technique is based on conditional expectations. Finally, noncommutative Gröbner bases are exploited to certify when an optimizer (a solution yielding optimum violation) cannot be extracted from a dual SDP solution.},
  archive      = {J_SIOPT},
  author       = {Timotej Hrga and Igor Klep and Janez Povh},
  doi          = {10.1137/22M1473340},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1341-1373},
  shortjournal = {SIAM J. Optim.},
  title        = {Certifying optimality of bell inequality violations: Noncommutative polynomial optimization through semidefinite programming and local optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized power cones: Optimal error bounds and
automorphisms. <em>SIOPT</em>, <em>34</em>(2), 1316–1340. (<a
href="https://doi.org/10.1137/22M1542921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Error bounds are a requisite for trusting or distrusting solutions in an informed way. Until recently, provable error bounds in the absence of constraint qualifications were unattainable for many classes of cones that do not admit projections with known succinct expressions. We build such error bounds for the generalized power cones, using the recently developed framework of one-step facial residual functions. We also show that our error bounds are tight in the sense of that framework. Besides their utility for understanding solution reliability, the error bounds we discover have additional applications to the algebraic structure of the underlying cone, which we describe. In particular we use the error bounds to compute the automorphisms of the generalized power cones, and to identify a set of generalized power cones that are self-dual, irreducible, nonhomogeneous, and perfect.},
  archive      = {J_SIOPT},
  author       = {Ying Lin and Scott B. Lindstrom and Bruno F. Lourenço and Ting Kei Pong},
  doi          = {10.1137/22M1542921},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1316-1340},
  shortjournal = {SIAM J. Optim.},
  title        = {Generalized power cones: Optimal error bounds and automorphisms},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Parabolic optimal control problems with combinatorial
switching constraints, part II: Outer approximation algorithm.
<em>SIOPT</em>, <em>34</em>(2), 1295–1315. (<a
href="https://doi.org/10.1137/22M1490284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider optimal control problems for partial differential equations where the controls take binary values but vary over the time horizon; they can thus be seen as dynamic switches. The switching patterns may be subject to combinatorial constraints such as, e.g., an upper bound on the total number of switchings or a lower bound on the time between two switchings. In a companion paper [C. Buchheim, A. Grütering, and C. Meyer, SIAM J. Optim., arXiv:2203.07121, 2024], we describe the -closure of the convex hull of feasible switching patterns as the intersection of convex sets derived from finite-dimensional projections. In this paper, the resulting outer description is used for the construction of an outer approximation algorithm in function space, whose iterates are proven to converge strongly in to the global minimizer of the convexified optimal control problem. The linear-quadratic subproblems arising in each iteration of the outer approximation algorithm are solved by means of a semismooth Newton method. A numerical example in two spatial dimensions illustrates the efficiency of the overall algorithm.},
  archive      = {J_SIOPT},
  author       = {Christoph Buchheim and Alexandra Grütering and Christian Meyer},
  doi          = {10.1137/22M1490284},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1295-1315},
  shortjournal = {SIAM J. Optim.},
  title        = {Parabolic optimal control problems with combinatorial switching constraints, part II: Outer approximation algorithm},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonasymptotic upper estimates for errors of the sample
average approximation method to solve risk-averse stochastic programs.
<em>SIOPT</em>, <em>34</em>(2), 1264–1294. (<a
href="https://doi.org/10.1137/22M1535425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study statistical properties of the optimal value of the sample average approximation (SAA). The focus is on the tail function of the absolute error induced by the SAA, deriving upper estimates of its outcomes dependent on the sample size. The estimates allow to conclude immediately convergence rates for the optimal value of the SAA. As a crucial point, the investigations are based on new types of conditions from the theory of empirical processes which do not rely on pathwise analytical properties of the goal functions. In particular, continuity in the parameter is not imposed in advance as often in the literature on the SAA method. It is also shown that the new condition is satisfied if the paths of the goal functions are Hölder continuous so that the main results carry over in this case. Moreover, the main results are applied to goal functions whose paths are piecewise Hölder continuous as, e.g., in two-stage mixed-integer programs. The main results are shown for classical risk-neutral stochastic programs, but we also demonstrate how to apply them to the sample average approximation of risk-averse stochastic programs. In this respect, we consider stochastic programs expressed in terms of mean upper semideviations and divergence risk measures.},
  archive      = {J_SIOPT},
  author       = {Volker Krätschmer},
  doi          = {10.1137/22M1535425},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1264-1294},
  shortjournal = {SIAM J. Optim.},
  title        = {Nonasymptotic upper estimates for errors of the sample average approximation method to solve risk-averse stochastic programs},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerated forward-backward optimization using deep
learning. <em>SIOPT</em>, <em>34</em>(2), 1236–1263. (<a
href="https://doi.org/10.1137/22M1532548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose several deep-learning accelerated optimization solvers with convergence guarantees. We use ideas from the analysis of accelerated forward-backward schemes like FISTA, but instead of the classical approach of proving convergence for a choice of parameters, such as a step-size, we show convergence whenever the update is chosen in a specific set. Rather than picking a point in this set using some predefined method, we train a deep neural network to pick the best update within a given space. Finally, we show that the method is applicable to several cases of smooth and nonsmooth optimization and show superior results to established accelerated solvers.},
  archive      = {J_SIOPT},
  author       = {Sebastian Banert and Jevgenija Rudzusika and Ozan Öktem and Jonas Adler},
  doi          = {10.1137/22M1532548},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1236-1263},
  shortjournal = {SIAM J. Optim.},
  title        = {Accelerated forward-backward optimization using deep learning},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decomposition methods for global solution of mixed-integer
linear programs. <em>SIOPT</em>, <em>34</em>(2), 1206–1235. (<a
href="https://doi.org/10.1137/22M1487321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper introduces two decomposition-based methods for two-block mixed-integer linear programs (MILPs), which aim to take advantage of separable structures of the original problem by solving a sequence of lower-dimensional MILPs. The first method is based on the -augmented Lagrangian method, and the second one is based on a modified alternating direction method of multipliers. In the presence of certain block-angular structures, both methods create parallel subproblems in one block of variables and add nonconvex cuts to update the other block; they converge to globally optimal solutions of the original MILP under proper conditions. Numerical experiments on three classes of MILPs demonstrate the advantages of the proposed methods on structured problems over the state-of-the-art MILP solvers.},
  archive      = {J_SIOPT},
  author       = {Kaizhao Sun and Mou Sun and Wotao Yin},
  doi          = {10.1137/22M1487321},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1206-1235},
  shortjournal = {SIAM J. Optim.},
  title        = {Decomposition methods for global solution of mixed-integer linear programs},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Parabolic optimal control problems with combinatorial
switching constraints, part i: Convex relaxations. <em>SIOPT</em>,
<em>34</em>(2), 1187–1205. (<a
href="https://doi.org/10.1137/22M1490260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider optimal control problems for partial differential equations where the controls take binary values but vary over the time horizon; they can thus be seen as dynamic switches. The switching patterns may be subject to combinatorial constraints such as, e.g., an upper bound on the total number of switchings or a lower bound on the time between two switchings. While such combinatorial constraints are often seen as an additional complication that is treated in a heuristic postprocessing, the core of our approach is to investigate the convex hull of all feasible switching patterns in order to define a tight convex relaxation of the control problem. The convex relaxation is built by cutting planes derived from finite-dimensional projections, which can be studied by means of polyhedral combinatorics. A numerical example for the case of a bounded number of switchings shows that our approach can significantly improve the dual bounds given by the straightforward continuous relaxation, which is obtained by relaxing binarity constraints.},
  archive      = {J_SIOPT},
  author       = {Christoph Buchheim and Alexandra Grütering and Christian Meyer},
  doi          = {10.1137/22M1490260},
  journal      = {SIAM Journal on Optimization},
  month        = {6},
  number       = {2},
  pages        = {1187-1205},
  shortjournal = {SIAM J. Optim.},
  title        = {Parabolic optimal control problems with combinatorial switching constraints, part i: Convex relaxations},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semismooth newton stochastic proximal point algorithm with
variance reduction. <em>SIOPT</em>, <em>34</em>(1), 1157–1185. (<a
href="https://doi.org/10.1137/22M1488181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop an implementable stochastic proximal point (SPP) method for a class of weakly convex, composite optimization problems. The proposed stochastic proximal point algorithm incorporates a variance reduction mechanism and the resulting SPP updates are solved using an inexact semismooth Newton framework. We establish detailed convergence results that take the inexactness of the SPP steps into account and that are in accordance with existing convergence guarantees of (proximal) stochastic variance-reduced gradient methods. Numerical experiments show that the proposed algorithm competes favorably with other state-of-the-art methods and achieves higher robustness with respect to the step size selection.},
  archive      = {J_SIOPT},
  author       = {Andre Milzarek and Fabian Schaipp and Michael Ulbrich},
  doi          = {10.1137/22M1488181},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {1157-1185},
  shortjournal = {SIAM J. Optim.},
  title        = {A semismooth newton stochastic proximal point algorithm with variance reduction},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Provably accelerated decentralized gradient methods over
unbalanced directed graphs. <em>SIOPT</em>, <em>34</em>(1), 1131–1156.
(<a href="https://doi.org/10.1137/22M148570X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the decentralized optimization problem, where a network of agents aims to collaboratively minimize the average of their individual smooth and convex objective functions through peer-to-peer communication in a directed graph. To tackle this problem, we propose two accelerated gradient tracking methods, namely Accelerated Push-DIGing (APD) and APD-SC, for non-strongly convex and strongly convex objective functions, respectively. We show that APD and APD-SC converge at the rates and , respectively, up to constant factors depending only on the mixing matrix. APD and APD-SC are the first decentralized methods over unbalanced directed graphs that achieve the same provable acceleration as centralized methods. Numerical experiments demonstrate the effectiveness of both methods.},
  archive      = {J_SIOPT},
  author       = {Zhuoqing Song and Lei Shi and Shi Pu and Ming Yan},
  doi          = {10.1137/22M148570X},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {1131-1156},
  shortjournal = {SIAM J. Optim.},
  title        = {Provably accelerated decentralized gradient methods over unbalanced directed graphs},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust accelerated primal-dual methods for computing saddle
points. <em>SIOPT</em>, <em>34</em>(1), 1097–1130. (<a
href="https://doi.org/10.1137/21M1462775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider strongly-convex-strongly-concave saddle point problems assuming we have access to unbiased stochastic estimates of the gradients. We propose a stochastic accelerated primal-dual (SAPD) algorithm and show that the SAPD sequence, generated using constant primal-dual step sizes, linearly converges to a neighborhood of the unique saddle point. Interpreting the size of the neighborhood as a measure of robustness to gradient noise, we obtain explicit characterizations of robustness in terms of SAPD parameters and problem constants. Based on these characterizations, we develop computationally tractable techniques for optimizing the SAPD parameters, i.e., the primal and dual step sizes, and the momentum parameter, to achieve a desired trade-off between the convergence rate and robustness on the Pareto curve. This allows SAPD to enjoy fast convergence properties while being robust to noise as an accelerated method. SAPD admits convergence guarantees for the distance metric with a variance term optimal up to a logarithmic factor, which can be removed by employing a restarting strategy. We also discuss how convergence and robustness results extend to the merely-convex-merely-concave setting. Finally, we illustrate our framework on a distributionally robust logistic regression problem.},
  archive      = {J_SIOPT},
  author       = {Xuan Zhang and Necdet Serhat Aybat and Mert Gürbüzbalaban},
  doi          = {10.1137/21M1462775},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {1097-1130},
  shortjournal = {SIAM J. Optim.},
  title        = {Robust accelerated primal-dual methods for computing saddle points},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On integrality in semidefinite programming for discrete
optimization. <em>SIOPT</em>, <em>34</em>(1), 1071–1096. (<a
href="https://doi.org/10.1137/23M1580905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. It is well known that by adding integrality constraints to the semidefinite programming (SDP) relaxation of the max-cut problem, the resulting integer semidefinite program is an exact formulation of the problem. In this paper we show similar results for a wide variety of discrete optimization problems for which SDP relaxations have been derived. Based on a comprehensive study on discrete positive semidefinite matrices, we introduce a generic approach to derive mixed-integer SDP (MISDP) formulations of binary quadratically constrained quadratic programs and binary quadratic matrix programs. Applying a problem-specific approach, we derive more compact MISDP formulations of several problems, such as the quadratic assignment problem, the graph partition problem, and the integer matrix completion problem. We also show that several structured problems allow for novel compact MISDP formulations through the notion of association schemes. Complementary to the recent advances on algorithmic aspects related to MISDP, this work opens new perspectives on solution approaches for the here considered problems.},
  archive      = {J_SIOPT},
  author       = {Frank de Meijer and Renata Sotirov},
  doi          = {10.1137/23M1580905},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {1071-1096},
  shortjournal = {SIAM J. Optim.},
  title        = {On integrality in semidefinite programming for discrete optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Randomized douglas–rachford methods for linear systems:
Improved accuracy and efficiency. <em>SIOPT</em>, <em>34</em>(1),
1045–1070. (<a href="https://doi.org/10.1137/23M1567503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Douglas–Rachford (DR) method is a widely used method for finding a point in the intersection of two closed convex sets (feasibility problem). However, the method converges weakly, and the associated rate of convergence is hard to analyze in general. In addition, the direct extension of the DR method for solving more-than-two-sets feasibility problems, called the -sets-DR method, is not necessarily convergent. To improve the efficiency of the optimization algorithms, the introduction of randomization and the momentum technique has attracted increasing attention. In this paper, we propose the randomized -sets-DR (RrDR) method for solving the feasibility problem derived from linear systems, showing the benefit of the randomization as it brings linear convergence in expectation to the otherwise divergent -sets-DR method. Furthermore, the convergence rate does not depend on the dimension of the coefficient matrix. We also study RrDR with heavy ball momentum and establish its accelerated rate. Numerical experiments are provided to confirm our results and demonstrate the notable improvements in accuracy and efficiency of the DR method brought by the randomization and the momentum technique.},
  archive      = {J_SIOPT},
  author       = {Deren Han and Yansheng Su and Jiaxin Xie},
  doi          = {10.1137/23M1567503},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {1045-1070},
  shortjournal = {SIAM J. Optim.},
  title        = {Randomized Douglas–Rachford methods for linear systems: Improved accuracy and efficiency},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decentralized gradient descent maximization method for
composite nonconvex strongly-concave minimax problems. <em>SIOPT</em>,
<em>34</em>(1), 1006–1044. (<a
href="https://doi.org/10.1137/23M1558677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Minimax problems have recently attracted a lot of research interests. A few efforts have been made to solve decentralized nonconvex strongly-concave (NCSC) minimax-structured optimization; however, all of them focus on smooth problems with at most a constraint on the maximization variable. In this paper, we make the first attempt on solving composite NCSC minimax problems that can have convex nonsmooth terms on both minimization and maximization variables. Our algorithm is designed based on a novel reformulation of the decentralized minimax problem that introduces a multiplier to absorb the dual consensus constraint. The removal of dual consensus constraint enables the most aggressive (i.e., local maximization instead of a gradient ascent step) dual update that leads to the benefit of taking a larger primal stepsize and better complexity results. In addition, the decoupling of the nonsmoothness and consensus on the dual variable eases the analysis of a decentralized algorithm; thus our reformulation creates a new way for interested researchers to design new (and possibly more efficient) decentralized methods on solving NCSC minimax problems. We show a global convergence result of the proposed algorithm and an iteration complexity result to produce a (near) stationary point of the reformulation. Moreover, a relation is established between the (near) stationarities of the reformulation and the original formulation. With this relation, we show that when the dual regularizer is smooth, our algorithm can have lower complexity results (with reduced dependence on a condition number) than existing ones to produce a near-stationary point of the original formulation. Numerical experiments are conducted on a distributionally robust logistic regression to demonstrate the performance of the proposed algorithm.},
  archive      = {J_SIOPT},
  author       = {Yangyang Xu},
  doi          = {10.1137/23M1558677},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {1006-1044},
  shortjournal = {SIAM J. Optim.},
  title        = {Decentralized gradient descent maximization method for composite nonconvex strongly-concave minimax problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How do exponential size solutions arise in semidefinite
programming? <em>SIOPT</em>, <em>34</em>(1), 977–1005. (<a
href="https://doi.org/10.1137/21M1434945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A striking pathology of semidefinite programs (SDPs) is illustrated by a classical example of Khachiyan: feasible solutions in SDPs may need exponential space even to write down. Such exponential size solutions are the main obstacle to solving a long standing, fundamental open problem: can we decide feasibility of SDPs in polynomial time? The consensus seems that SDPs with large size solutions are rare. However, here we prove that they are actually quite common: a linear change of variables transforms every strictly feasible SDP into a Khachiyan type SDP, in which the leading variables are large. As to “how large,” that depends on the singularity degree of a dual problem. Further, we present some SDPs coming from sum-of-squares proofs, in which large solutions appear naturally, without any change of variables. We also partially answer the question how do we represent such large solutions in polynomial space?},
  archive      = {J_SIOPT},
  author       = {Gábor Pataki and Aleksandr Touzov},
  doi          = {10.1137/21M1434945},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {977-1005},
  shortjournal = {SIAM J. Optim.},
  title        = {How do exponential size solutions arise in semidefinite programming?},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-time-scale stochastic optimization framework with
applications in control and reinforcement learning. <em>SIOPT</em>,
<em>34</em>(1), 946–976. (<a
href="https://doi.org/10.1137/22M150277X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study a new two-time-scale stochastic gradient method for solving optimization problems, where the gradients are computed with the aid of an auxiliary variable under samples generated by time-varying Markov random processes controlled by the underlying optimization variable. These time-varying samples make gradient directions in our update biased and dependent, which can potentially lead to the divergence of the iterates. In our two-time-scale approach, one scale is to estimate the true gradient from these samples, which is then used to update the estimate of the optimal solution. While these two iterates are implemented simultaneously, the former is updated “faster” (using bigger step sizes) than the latter (using smaller step sizes). Our first contribution is to characterize the finite-time complexity of the proposed two-time-scale stochastic gradient method. In particular, we provide explicit formulas for the convergence rates of this method under different structural assumptions, namely, strong convexity, the Polyak–Łojasiewicz condition, and general nonconvexity. We apply our framework to policy optimization problems in control and reinforcement learning. First, we look at the infinite-horizon average-reward Markov decision process with finite state and action spaces and derive a convergence rate of for the online actor-critic algorithm under function approximation, which recovers the best known rate derived specifically for this problem. Second, we study the linear-quadratic regulator and show that an online actor-critic method converges with rate . Third, we use the actor-critic algorithm to solve the policy optimization problem in an entropy regularized Markov decision process, where we also establish a convergence of . The results we derive for both the second and third problems are novel and previously unknown in the literature. Finally, we briefly present the application of our framework to gradient-based policy evaluation algorithms in reinforcement learning.},
  archive      = {J_SIOPT},
  author       = {Sihan Zeng and Thinh T. Doan and Justin Romberg},
  doi          = {10.1137/22M150277X},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {946-976},
  shortjournal = {SIAM J. Optim.},
  title        = {A two-time-scale stochastic optimization framework with applications in control and reinforcement learning},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A chain rule for strict twice epi-differentiability and its
applications. <em>SIOPT</em>, <em>34</em>(1), 918–945. (<a
href="https://doi.org/10.1137/22M1520025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The presence of second-order smoothness for objective functions of optimization problems can provide valuable information about their stability properties and help us design efficient numerical algorithms for solving these problems. Such second-order information, however, cannot be expected in various constrained and composite optimization problems since we often have to express their objective functions in terms of extended-real-valued functions for which the classical second derivative may not exist. One powerful geometrical tool to use for dealing with such functions is the concept of twice epi-differentiability. In this paper, we study a stronger version of this concept, called strict twice epi-differentiability. We characterize this concept for certain composite functions and use it to establish the equivalence of metric regularity and strong metric regularity for a class of generalized equations at their nondegenerate solutions. Finally, we present a characterization of continuous differentiability of the proximal mapping of our composite functions.},
  archive      = {J_SIOPT},
  author       = {Nguyen T. V. Hang and M. Ebrahim Sarabi},
  doi          = {10.1137/22M1520025},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {918-945},
  shortjournal = {SIAM J. Optim.},
  title        = {A chain rule for strict twice epi-differentiability and its applications},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximating higher-order derivative tensors using secant
updates. <em>SIOPT</em>, <em>34</em>(1), 893–917. (<a
href="https://doi.org/10.1137/23M1549687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Quasi-Newton methods employ an update rule that gradually improves the Hessian approximation using the already available gradient evaluations. We propose higher-order secant updates which generalize this idea to higher-order derivatives, approximating, for example, third derivatives (which are tensors) from given Hessian evaluations. Our generalization is based on the observation that quasi-Newton updates are least-change updates satisfying the secant equation, with different methods using different norms to measure the size of the change. We present a full characterization for least-change updates in weighted Frobenius norms (satisfying an analogue of the secant equation) for derivatives of arbitrary order. Moreover, we establish convergence of the approximations to the true derivative under standard assumptions and explore the quality of the generated approximations in numerical experiments.},
  archive      = {J_SIOPT},
  author       = {Karl Welzel and Raphael A. Hauser},
  doi          = {10.1137/23M1549687},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {893-917},
  shortjournal = {SIAM J. Optim.},
  title        = {Approximating higher-order derivative tensors using secant updates},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continuous selections of solutions to parametric variational
inequalities. <em>SIOPT</em>, <em>34</em>(1), 870–892. (<a
href="https://doi.org/10.1137/22M1514982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies the existence of a (Lipschitz) continuous (single-valued) solution function of parametric variational inequalities under functional and constraint perturbations. At the most elementary level, this issue can be explained from classical parametric linear programming and its resolution by the parametric simplex method, which computes a solution trajectory of the problem when the objective coefficients and the right-hand sides of the constraints are parameterized by a single scalar parameter. The computed optimal solution vector (and not the optimal objective value) is a continuous piecewise affine function in the parameter when the objective coefficients are kept constant, whereas the computed solution vector can be discontinuous when the right-hand constraint coefficients are kept fixed and there is a basis change at a critical value of the parameter in the objective. We investigate this issue more broadly first in the context of an affine variational inequality (AVI) and obtain results that go beyond those pertaining to the lower semicontinuity of the solution map with joint vector perturbations; the latter property is closely tied to a stability theory of a parametric AVI and in particular to Robinson’s seminal concept of strong regularity. Extensions to nonlinear variational inequalities is also investigated without requiring solution uniqueness (and therefore applicable to nonstrongly regular problems). The role of solution uniqueness in this issue of continuous single-valued solution selection is further clarified.},
  archive      = {J_SIOPT},
  author       = {Shaoning Han and Jong-Shi Pang},
  doi          = {10.1137/22M1514982},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {870-892},
  shortjournal = {SIAM J. Optim.},
  title        = {Continuous selections of solutions to parametric variational inequalities},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sample size estimates for risk-neutral semilinear
PDE-constrained optimization. <em>SIOPT</em>, <em>34</em>(1), 844–869.
(<a href="https://doi.org/10.1137/22M1512636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The sample average approximation (SAA) approach is applied to risk-neutral optimization problems governed by semilinear elliptic partial differential equations with random inputs. After constructing a compact set that contains the SAA critical points, we derive nonasymptotic sample size estimates for SAA critical points using the covering number approach. Thereby, we derive upper bounds on the number of samples needed to obtain accurate critical points of the risk-neutral PDE-constrained optimization problem through SAA critical points. We quantify accuracy using expectation and exponential tail bounds. Numerical illustrations are presented.},
  archive      = {J_SIOPT},
  author       = {Johannes Milz and Michael Ulbrich},
  doi          = {10.1137/22M1512636},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {844-869},
  shortjournal = {SIAM J. Optim.},
  title        = {Sample size estimates for risk-neutral semilinear PDE-constrained optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Subset selection and the cone of factor-width-k matrices.
<em>SIOPT</em>, <em>34</em>(1), 817–843. (<a
href="https://doi.org/10.1137/23M1549444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the cone of factor-width- matrices, where the factor width of a positive semidefinite matrix is defined as the smallest number allowing it to be expressed as a sum of positive semidefinite matrices that are nonzero only on a single principal submatrix. Two hierarchies of approximations are proposed for this cone. Some theoretical bounds to assess the quality of the new approximations are derived. We also use these approximations to build convex conic relaxations for the subset selection problem where one has to minimize under the constraint that has at most nonzero components. Several numerical experiments are performed showing that some of these relaxations provide a good compromise between tightness and computational complexity and rank well compared to perspective-type relaxations.},
  archive      = {J_SIOPT},
  author       = {Walid Ben-Ameur},
  doi          = {10.1137/23M1549444},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {817-843},
  shortjournal = {SIAM J. Optim.},
  title        = {Subset selection and the cone of factor-width-k matrices},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A path-based approach to constrained sparse optimization.
<em>SIOPT</em>, <em>34</em>(1), 790–816. (<a
href="https://doi.org/10.1137/22M1535498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper proposes a path-based approach for the minimization of a continuously differentiable function over sparse symmetric sets, which is a hard problem that exhibits a restrictiveness-hierarchy of necessary optimality conditions. To achieve the more restrictive conditions in the hierarchy, state-of-the-art algorithms require a support optimization oracle that must exactly solve the problem in smaller dimensions. The path-based approach developed in this study produces a path-based optimality condition, which is placed well in the restrictiveness-hierarchy, and a method to achieve it that does not require a support optimization oracle and, moreover, is projection-free. In the development process, new results are derived for the regularized linear minimization problem over sparse symmetric sets, which give additional means to identify optimal solutions for convex and concave objective functions. We complement our results with numerical examples.},
  archive      = {J_SIOPT},
  author       = {Nadav Hallak},
  doi          = {10.1137/22M1535498},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {790-816},
  shortjournal = {SIAM J. Optim.},
  title        = {A path-based approach to constrained sparse optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerating primal-dual methods for regularized markov
decision processes. <em>SIOPT</em>, <em>34</em>(1), 764–789. (<a
href="https://doi.org/10.1137/21M1468851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Entropy regularized Markov decision processes have been widely used in reinforcement learning. This paper is concerned with the primal-dual formulation of the entropy regularized problems. Standard first-order methods suffer from slow convergence due to the lack of strict convexity and concavity. To address this issue, we first introduce a new quadratically convexified primal-dual formulation. The natural gradient ascent descent of the new formulation enjoys global convergence guarantee and exponential convergence rate. We also propose a new interpolating metric that further accelerates the convergence significantly. Numerical results are provided to demonstrate the performance of the proposed methods under multiple settings.},
  archive      = {J_SIOPT},
  author       = {Haoya Li and Hsiang-Fu Yu and Lexing Ying and Inderjit S. Dhillon},
  doi          = {10.1137/21M1468851},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {764-789},
  shortjournal = {SIAM J. Optim.},
  title        = {Accelerating primal-dual methods for regularized markov decision processes},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Safe and verified gomory mixed-integer cuts in a rational
mixed-integer program framework. <em>SIOPT</em>, <em>34</em>(1),
742–763. (<a href="https://doi.org/10.1137/23M156046X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is concerned with the exact solution of mixed-integer programs (MIPs) over the rational numbers, i.e., without any roundoff errors and error tolerances. Here, one computational bottleneck that should be avoided whenever possible is to employ large-scale symbolic computations. Instead it is often possible to use safe directed rounding methods, e.g., to generate provably correct dual bounds. In this work, we continue to leverage this paradigm and extend an exact branch-and-bound framework by separation routines for safe cutting planes, based on the approach first introduced by Cook, Dash, Fukasawa, and Goycoolea in 2009 [INFORMS J. Comput., 21 (2009), pp. 641–649]. Constraints are aggregated safely using approximate dual multipliers from an LP solve, followed by mixed-integer rounding to generate provably valid, although slightly weaker inequalities. We generalize this approach to problem data that is not representable in floating-point arithmetic, add routines for controlling the encoding length of the resulting cutting planes, and show how these cutting planes can be verified according to the VIPR certificate standard. Furthermore, we analyze the performance impact of these cutting planes in the context of an exact MIP framework, showing that we can solve 21.5% more instances to exact optimality and reduce solving times by 26.8% on the MIPLIB 2017 benchmark test set.},
  archive      = {J_SIOPT},
  author       = {Leon Eifler and Ambros Gleixner},
  doi          = {10.1137/23M156046X},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {742-763},
  shortjournal = {SIAM J. Optim.},
  title        = {Safe and verified gomory mixed-integer cuts in a rational mixed-integer program framework},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear programming on the stiefel manifold. <em>SIOPT</em>,
<em>34</em>(1), 718–741. (<a
href="https://doi.org/10.1137/23M1552243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Linear programming on the Stiefel manifold (LPS) is studied for the first time. It aims at minimizing a linear objective function over the set of all -tuples of orthonormal vectors in satisfying additional linear constraints. Despite the classical polynomial-time solvable case , general (LPS) is NP-hard. According to the Shapiro–Barvinok–Pataki theorem, (LPS) admits an exact semidefinite programming relaxation when , which is tight when . Surprisingly, we can greatly strengthen this sufficient exactness condition to , which covers the classical case and . Regarding (LPS) as a smooth nonlinear programming problem, we reveal a nice property that under the linear independence constraint qualification, the standard first- and second-order local necessary optimality conditions are sufficient for global optimality when .},
  archive      = {J_SIOPT},
  author       = {Mengmeng Song and Yong Xia},
  doi          = {10.1137/23M1552243},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {718-741},
  shortjournal = {SIAM J. Optim.},
  title        = {Linear programming on the stiefel manifold},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bounds for multistage mixed-integer distributionally robust
optimization. <em>SIOPT</em>, <em>34</em>(1), 682–717. (<a
href="https://doi.org/10.1137/22M147178X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Multistage mixed-integer distributionally robust optimization (DRO) forms a class of extremely challenging problems since their size grows exponentially with the number of stages. One way to model the uncertainty in multistage DRO is by creating sets of conditional distributions (the so-called conditional ambiguity sets) on a finite scenario tree and requiring that such distributions remain close to nominal conditional distributions according to some measure of similarity/distance (e.g., -divergences or Wasserstein distance). In this paper, new bounding criteria for this class of difficult decision problems are provided through scenario grouping using the ambiguity sets associated with various commonly used -divergences and the Wasserstein distance. Our approach does not require any special problem structure such as linearity, convexity, stagewise independence, and so forth. Therefore, while we focus on multistage mixed-integer DRO, our bounds can be applied to a wide range of DRO problems including two-stage and multistage, with or without integer variables, convex or nonconvex, and nested or nonnested formulations. Numerical results on a multistage mixed-integer production problem show the efficiency of the proposed approach through different choices of partition strategies, ambiguity sets, and levels of robustness.},
  archive      = {J_SIOPT},
  author       = {Güzin Bayraksan and Francesca Maggioni and Daniel Faccini and Ming Yang},
  doi          = {10.1137/22M147178X},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {682-717},
  shortjournal = {SIAM J. Optim.},
  title        = {Bounds for multistage mixed-integer distributionally robust optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A riemannian proximal newton method. <em>SIOPT</em>,
<em>34</em>(1), 654–681. (<a
href="https://doi.org/10.1137/23M1565097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In recent years, the proximal gradient method and its variants have been generalized to Riemannian manifolds for solving optimization problems with an additively separable structure, i.e., where is continuously differentiable, and may be nonsmooth but convex with computationally reasonable proximal mapping. In this paper, we generalize the proximal Newton method to embedded submanifolds for solving the type of problem with . The generalization relies on the Weingarten and semismooth analysis. It is shown that the Riemannian proximal Newton method has a local superlinear convergence rate under certain reasonable assumptions. Moreover, a hybrid version is given by concatenating a Riemannian proximal gradient method and the Riemannian proximal Newton method. It is shown that if the switch parameter is chosen appropriately, then the hybrid method converges globally and also has a local superlinear convergence rate. Numerical experiments on random and synthetic data are used to demonstrate the performance of the proposed methods.},
  archive      = {J_SIOPT},
  author       = {Wutao Si and P.-A. Absil and Wen Huang and Rujun Jiang and Simon Vary},
  doi          = {10.1137/23M1565097},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {654-681},
  shortjournal = {SIAM J. Optim.},
  title        = {A riemannian proximal newton method},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Various notions of nonexpansiveness coincide for proximal
mappings of functions. <em>SIOPT</em>, <em>34</em>(1), 642–653. (<a
href="https://doi.org/10.1137/23M1597009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Proximal mappings are essential in splitting algorithms for both convex and nonconvex optimization. In this paper, we show that proximal mappings of every prox-bounded function are nonexpansive if and only if they are firmly nonexpansive if and only if they are averaged if and only if the function is convex. Lipschitz proximal mappings of prox-bounded functions are also characterized via hypoconvex or strongly convex functions. Our results generalize a recent result due to Rockafellar.},
  archive      = {J_SIOPT},
  author       = {Honglin Luo and Xianfu Wang and Xinmin Yang},
  doi          = {10.1137/23M1597009},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {642-653},
  shortjournal = {SIAM J. Optim.},
  title        = {Various notions of nonexpansiveness coincide for proximal mappings of functions},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Second order conditions to decompose smooth functions as
sums of squares. <em>SIOPT</em>, <em>34</em>(1), 616–641. (<a
href="https://doi.org/10.1137/22M1480914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the problem of decomposing a regular nonnegative function as a sum of squares of functions which preserve some form of regularity. In the same way as decomposing nonnegative polynomials as sum of squares of polynomials allows one to derive methods in order to solve global optimization problems on polynomials, decomposing a regular function as a sum of squares allows one to derive methods to solve global optimization problems on more general functions. As the regularity of the functions in the sum of squares decomposition is a key indicator in analyzing the convergence and speed of convergence of optimization methods, it is important to have theoretical results guaranteeing such a regularity. In this work, we show second order sufficient conditions in order for a times continuously differentiable nonnegative function to be a sum of squares of differentiable functions. The main hypothesis is that, locally, the function grows quadratically in directions which are orthogonal to its set of zeros. The novelty of this result, compared to previous works is that it allows sets of zeros which are continuous as opposed to discrete, and also applies to manifolds as opposed to open sets of . This has applications in problems where manifolds of minimizers or zeros typically appear, such as in optimal transport, and for minimizing functions defined on manifolds.},
  archive      = {J_SIOPT},
  author       = {Ulysse Marteau-Ferey and Francis Bach and Alessandro Rudi},
  doi          = {10.1137/22M1480914},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {616-641},
  shortjournal = {SIAM J. Optim.},
  title        = {Second order conditions to decompose smooth functions as sums of squares},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Harmonic hierarchies for polynomial optimization.
<em>SIOPT</em>, <em>34</em>(1), 590–615. (<a
href="https://doi.org/10.1137/22M1484511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce novel polyhedral approximation hierarchies for the cone of nonnegative forms on the unit sphere in and for its (dual) cone of moments. We prove computable quantitative bounds on the speed of convergence of such hierarchies. We also introduce a novel optimization-free algorithm for building converging sequences of lower bounds for polynomial minimization problems on spheres. Finally, some computational results are discussed, showcasing our implementation of these hierarchies in the programming language Julia.},
  archive      = {J_SIOPT},
  author       = {Sergio Cristancho and Mauricio Velasco},
  doi          = {10.1137/22M1484511},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {590-615},
  shortjournal = {SIAM J. Optim.},
  title        = {Harmonic hierarchies for polynomial optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence rate analysis of a dykstra-type projection
algorithm. <em>SIOPT</em>, <em>34</em>(1), 563–589. (<a
href="https://doi.org/10.1137/23M1545781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Given closed convex sets , and some nonzero linear maps , of suitable dimensions, the multiset split feasibility problem aims at finding a point in based on computing projections onto and multiplications by and . In this paper, we consider the associated best approximation problem, i.e., the problem of computing projections onto ; we refer to this problem as the best approximation problem in multiset split feasibility settings (BA-MSF). We adapt the Dykstra’s projection algorithm, which is classical for solving the BA-MSF in the special case when all , to solve the general BA-MSF. Our Dykstra-type projection algorithm is derived by applying (proximal) coordinate gradient descent to the Lagrange dual problem, and it only requires computing projections onto and multiplications by and in each iteration. Under a standard relative interior condition and a genericity assumption on the point we need to project, we show that the dual objective satisfies the Kurdyka-Łojasiewicz property with an explicitly computable exponent on a neighborhood of the (typically unbounded) dual solution set when each is -cone reducible for some : this class of sets covers the class of -cone reducible sets, which include all polyhedrons, second-order cone, and the cone of positive semidefinite matrices as special cases. Using this, explicit convergence rate (linear or sublinear) of the sequence generated by the Dykstra-type projection algorithm is derived. Concrete examples are constructed to illustrate the necessity of some of our assumptions.},
  archive      = {J_SIOPT},
  author       = {Xiaozhou Wang and Ting Kei Pong},
  doi          = {10.1137/23M1545781},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {563-589},
  shortjournal = {SIAM J. Optim.},
  title        = {Convergence rate analysis of a dykstra-type projection algorithm},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact quantization of multistage stochastic linear problems.
<em>SIOPT</em>, <em>34</em>(1), 533–562. (<a
href="https://doi.org/10.1137/22M1508005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We show that the multistage stochastic linear problem (MSLP) with an arbitrary cost distribution is equivalent to an MSLP on a finite scenario tree. We establish this exact quantization result by analyzing the polyhedral structure of MSLPs. In particular, we show that the expected cost-to-go functions are polyhedral and affine on the cells of a chamber complex, which is independent of the cost distribution. This leads to new complexity results, showing that MSLP becomes polynomial when certain parameters are fixed.},
  archive      = {J_SIOPT},
  author       = {Maël Forcier and Stéphane Gaubert and Vincent Leclère},
  doi          = {10.1137/22M1508005},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {533-562},
  shortjournal = {SIAM J. Optim.},
  title        = {Exact quantization of multistage stochastic linear problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shortest paths in graphs of convex sets. <em>SIOPT</em>,
<em>34</em>(1), 507–532. (<a
href="https://doi.org/10.1137/22M1523790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Given a graph, the shortest-path problem requires finding a sequence of edges with minimum cumulative length that connects a source vertex to a target vertex. We consider a variant of this classical problem in which the position of each vertex in the graph is a continuous decision variable constrained in a convex set, and the length of an edge is a convex function of the position of its endpoints. Problems of this form arise naturally in many areas, from motion planning of autonomous vehicles to optimal control of hybrid systems. The price for such a wide applicability is the complexity of this problem, which is easily seen to be NP-hard. Our main contribution is a strong and lightweight mixed-integer convex formulation based on perspective operators, that makes it possible to efficiently find globally optimal paths in large graphs and in high-dimensional spaces.},
  archive      = {J_SIOPT},
  author       = {Tobia Marcucci and Jack Umenberger and Pablo Parrilo and Russ Tedrake},
  doi          = {10.1137/22M1523790},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {507-532},
  shortjournal = {SIAM J. Optim.},
  title        = {Shortest paths in graphs of convex sets},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid algorithms for finding a d-stationary point of a
class of structured nonsmooth DC minimization. <em>SIOPT</em>,
<em>34</em>(1), 485–506. (<a
href="https://doi.org/10.1137/21M1457709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we consider a class of structured nonsmooth difference-of-convex (DC) minimization in which the first convex component is the sum of a smooth and a nonsmooth function, while the second convex component is the supremum of finitely many convex smooth functions. The existing methods for this problem usually have weak convergence guarantees or need to solve lots of subproblems per iteration. Due to this, we propose hybrid algorithms for solving this problem in which we first compute approximate critical points and then check whether these points are approximate D-stationary points. Under suitable conditions, we prove that there exists a subsequence of iterates of which every accumulation point is a D-stationary point. Some preliminary numerical experiments are conducted to demonstrate the efficiency of the proposed algorithms.},
  archive      = {J_SIOPT},
  author       = {Zhe Sun and Lei Wu},
  doi          = {10.1137/21M1457709},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {485-506},
  shortjournal = {SIAM J. Optim.},
  title        = {Hybrid algorithms for finding a D-stationary point of a class of structured nonsmooth DC minimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Infeasibility detection with primal-dual hybrid gradient for
large-scale linear programming. <em>SIOPT</em>, <em>34</em>(1), 459–484.
(<a href="https://doi.org/10.1137/22M1510467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the problem of detecting infeasibility of large-scale linear programming problems using the primal-dual hybrid gradient (PDHG) method of Chambolle and Pock [J. Math. Imaging Vision, 40 (2011), pp. 120–145]. The literature on PDHG has focused chiefly on problems with at least one optimal solution. We show that when the problem is infeasible or unbounded, the iterates diverge at a controlled rate toward a well-defined ray. In turn, the direction of such a ray recovers infeasibility certificates. Based on this fact, we propose a simple way to extract approximate infeasibility certificates from the iterates of PDHG. We study three sequences that converge to certificates: the difference of iterates, the normalized iterates, and the normalized average. All of them are easy to compute and suitable for large-scale problems. We show that the normalized iterates and normalized averages achieve a convergence rate of . This rate is general and applies to any fixed-point iteration of a nonexpansive operator. Thus, it is a result of independent interest that goes well beyond our setting. Finally, we show that, under nondegeneracy assumptions, the iterates of PDHG identify the active set of an auxiliary feasible problem in finite time, which ensures that the difference of iterates exhibits eventual linear convergence. These results provide a theoretical justification for infeasibility detection in the newly developed linear programming solver PDLP.},
  archive      = {J_SIOPT},
  author       = {David Applegate and Mateo Díaz and Haihao Lu and Miles Lubin},
  doi          = {10.1137/22M1510467},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {459-484},
  shortjournal = {SIAM J. Optim.},
  title        = {Infeasibility detection with primal-dual hybrid gradient for large-scale linear programming},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributionally favorable optimization: A framework for
data-driven decision-making with endogenous outliers. <em>SIOPT</em>,
<em>34</em>(1), 419–458. (<a
href="https://doi.org/10.1137/22M1528094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A typical data-driven stochastic program seeks the best decision that minimizes the sum of a deterministic cost function and an expected recourse function under a given distribution. Recently, much success has been witnessed in the development of distributionally robust optimization (DRO), which considers the worst-case expected recourse function under the least favorable probability distribution from a distributional family. However, in the presence of endogenous outliers such that their corresponding recourse function values are very large or even infinite, the commonly used DRO framework alone tends to overemphasize these endogenous outliers and cause undesirable or even infeasible decisions. On the contrary, distributionally favorable optimization (DFO), concerning the best-case expected recourse function under the most favorable distribution from the distributional family, can serve as a proper measure of the stochastic recourse function and mitigate the effect of endogenous outliers. We show that DFO recovers many robust statistics, suggesting that the DFO framework might be appropriate for the stochastic recourse function in the presence of endogenous outliers. A notion of decision outlier robustness is proposed for selecting a DFO framework for data-driven optimization with outliers. We also provide a unified way to integrate DRO with DFO, where DRO addresses the out-of-sample performance, and DFO properly handles the stochastic recourse function under endogenous outliers. We further extend the proposed DFO framework to solve two-stage stochastic programs without relatively complete recourse. The numerical study demonstrates that the framework is promising.},
  archive      = {J_SIOPT},
  author       = {Nan Jiang and Weijun Xie},
  doi          = {10.1137/22M1528094},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {419-458},
  shortjournal = {SIAM J. Optim.},
  title        = {Distributionally favorable optimization: A framework for data-driven decision-making with endogenous outliers},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian stochastic gradient descent for stochastic
optimization with streaming input data. <em>SIOPT</em>, <em>34</em>(1),
389–418. (<a href="https://doi.org/10.1137/22M1478951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider stochastic optimization under distributional uncertainty, where the unknown distributional parameter is estimated from streaming data that arrive sequentially over time. Moreover, data may depend on the decision at the time when they are generated. For both decision-independent and decision-dependent uncertainties, we propose an approach to jointly estimate the distributional parameter via Bayesian posterior distribution and update the decision by applying stochastic gradient descent (SGD) on the Bayesian average of the objective function. Our approach converges asymptotically over time and achieves the convergence rates of classical SGD in the decision-independent case. We demonstrate the empirical performance of our approach on both synthetic test problems and a classical newsvendor problem.},
  archive      = {J_SIOPT},
  author       = {Tianyi Liu and Yifan Lin and Enlu Zhou},
  doi          = {10.1137/22M1478951},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {389-418},
  shortjournal = {SIAM J. Optim.},
  title        = {Bayesian stochastic gradient descent for stochastic optimization with streaming input data},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Basic convex analysis in metric spaces with bounded
curvature. <em>SIOPT</em>, <em>34</em>(1), 366–388. (<a
href="https://doi.org/10.1137/23M1551389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Differentiable structure ensures that many of the basics of classical convex analysis extend naturally from Euclidean space to Riemannian manifolds. Without such structure, however, extensions are more challenging. Nonetheless, in Alexandrov spaces with curvature bounded above (but possibly positive), we develop several basic building blocks. We define subgradients via projection and the normal cone, prove their existence, and relate them to the classical affine minorant property. Then, in what amounts to a simple calculus or duality result, we develop a necessary optimality condition for minimizing the sum of two convex functions.},
  archive      = {J_SIOPT},
  author       = {Adrian S. Lewis and Genaro López-Acedo and Adriana Nicolae},
  doi          = {10.1137/23M1551389},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {366-388},
  shortjournal = {SIAM J. Optim.},
  title        = {Basic convex analysis in metric spaces with bounded curvature},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Descent properties of an anderson accelerated gradient
method with restarting. <em>SIOPT</em>, <em>34</em>(1), 336–365. (<a
href="https://doi.org/10.1137/22M151460X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Anderson acceleration is a popular acceleration technique to enhance the convergence of fixed-point schemes. The analysis of approaches often focuses on the convergence behavior of a corresponding fixed-point residual, while the behavior of the underlying objective function values along the accelerated iterates is currently not well understood. In this paper, we investigate local properties of with restarting applied to a basic gradient scheme in terms of function values. Specifically, we show that is a local descent method and that it can decrease the objective function at a rate no slower than the gradient method up to higher-order error terms. These new results theoretically support the good numerical performance of when heuristic descent conditions are used for globalization and they provide a novel perspective on the convergence analysis of that is more amenable to nonconvex optimization problems. Numerical experiments are conducted to illustrate our theoretical findings.},
  archive      = {J_SIOPT},
  author       = {Wenqing Ouyang and Yang Liu and Andre Milzarek},
  doi          = {10.1137/22M151460X},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {336-365},
  shortjournal = {SIAM J. Optim.},
  title        = {Descent properties of an anderson accelerated gradient method with restarting},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A decomposition algorithm for two-stage stochastic programs
with nonconvex recourse functions. <em>SIOPT</em>, <em>34</em>(1),
306–335. (<a href="https://doi.org/10.1137/22M1488533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we have studied a decomposition method for solving a class of nonconvex two-stage stochastic programs, where both the objective and constraints of the second-stage problem are nonlinearly parameterized by the first-stage variables. Due to the failure of the Clarke regularity of the resulting nonconvex recourse function, classical decomposition approaches such as Benders decomposition and (augmented) Lagrangian-based algorithms cannot be directly generalized to solve such models. By exploring an implicitly convex-concave structure of the recourse function, we introduce a novel decomposition framework based on the so-called partial Moreau envelope. The algorithm successively generates strongly convex quadratic approximations of the recourse function based on the solutions of the second-stage convex subproblems and adds them to the first-stage master problem. Convergence has been established for both a fixed number of scenarios and a sequential internal sampling strategy. Numerical experiments are conducted to demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_SIOPT},
  author       = {Hanyang Li and Ying Cui},
  doi          = {10.1137/22M1488533},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {306-335},
  shortjournal = {SIAM J. Optim.},
  title        = {A decomposition algorithm for two-stage stochastic programs with nonconvex recourse functions},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sharper bounds for proximal gradient algorithms with errors.
<em>SIOPT</em>, <em>34</em>(1), 278–305. (<a
href="https://doi.org/10.1137/22M1480161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We analyze the convergence of the proximal gradient algorithm for convex composite problems in the presence of gradient and proximal computational inaccuracies. We generalize the deterministic analysis to the quasi-Fejér case and quantify the uncertainty incurred from approximate computing and early termination errors. We propose new probabilistic tighter bounds that we use to verify a simulated Model Predictive Control (MPC) with sparse controls problem solved with early termination, reduced precision, and proximal errors. We also show how the probabilistic bounds are more suitable than the deterministic ones for algorithm verification and more accurate for application performance guarantees. Under mild statistical assumptions, we also prove that some cumulative error terms follow a martingale property. And conforming to observations, e.g., in [M. Schmidt, N. L. Roux, and F. R. Bach, Convergence rates of inexact proximal-gradient methods for convex optimization, in Advances in Neural Information Processing Systems, 2011, pp. 1458–1466], we also show how the acceleration of the algorithm amplifies the gradient and proximal computational errors.},
  archive      = {J_SIOPT},
  author       = {Anis Hamadouche and Yun Wu and Andrew M. Wallace and João F. C. Mota},
  doi          = {10.1137/22M1480161},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {278-305},
  shortjournal = {SIAM J. Optim.},
  title        = {Sharper bounds for proximal gradient algorithms with errors},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continuous newton-like methods featuring inertia and
variable mass. <em>SIOPT</em>, <em>34</em>(1), 251–277. (<a
href="https://doi.org/10.1137/23M1549675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce a new dynamical system at the interface between second-order dynamics with inertia and Newton’s method. This system extends the class of inertial Newton-like dynamics by featuring a time-dependent parameter in front of the acceleration, called variable mass. For strongly convex optimization, we provide guarantees on how the Newtonian and inertial behaviors of the system can be nonasymptotically controlled by means of this variable mass. A connection with the Levenberg–Marquardt (or regularized Newton) method is also made. We then show the effect of the variable mass on the asymptotic rate of convergence of the dynamics and, in particular, how it can turn the latter into an accelerated Newton method. We provide numerical experiments supporting our findings. This work represents a significant step toward designing new algorithms that benefit from the best of both first- and second-order optimization methods.},
  archive      = {J_SIOPT},
  author       = {Camille Castera and Hedy Attouch and Jalal Fadili and Peter Ochs},
  doi          = {10.1137/23M1549675},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {251-277},
  shortjournal = {SIAM J. Optim.},
  title        = {Continuous newton-like methods featuring inertia and variable mass},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonlinear cone separation theorems in real topological
linear spaces. <em>SIOPT</em>, <em>34</em>(1), 225–250. (<a
href="https://doi.org/10.1137/22M1542003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The separation of two sets (or more specific of two cones) plays an important role in different fields of mathematics such as variational analysis, convex analysis, convex geometry, and optimization. In the paper, we derive some new results for the separation of two not necessarily convex cones by a (convex) cone/conical surface in real (topological) linear spaces. Basically, we follow the separation approach by Kasimbeyli [SIAM J. Optim., 20 (2010), pp. 1591–1619] based on augmented dual cones and Bishop–Phelps type (normlinear) separating functions. Classical separation theorems for convex sets are the key tool for proving our main nonlinear cone separation theorems.},
  archive      = {J_SIOPT},
  author       = {Christian Günther and Bahareh Khazayel and Christiane Tammer},
  doi          = {10.1137/22M1542003},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {225-250},
  shortjournal = {SIAM J. Optim.},
  title        = {Nonlinear cone separation theorems in real topological linear spaces},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global complexity bound of a proximal ADMM for linearly
constrained nonseparable nonconvex composite programming.
<em>SIOPT</em>, <em>34</em>(1), 201–224. (<a
href="https://doi.org/10.1137/22M1503129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper proposes and analyzes a dampened proximal alternating direction method of multipliers (DP.ADMM) for solving linearly constrained nonconvex optimization problems where the smooth part of the objective function is nonseparable. Each iteration of DP.ADMM consists of (i) a sequence of partial proximal augmented Lagrangian (AL) updates, (ii) an under-relaxed Lagrange multiplier update, and (iii) a novel test to check whether the penalty parameter of the AL function should be updated. Under a basic Slater point condition and some requirements on the dampening factor and under-relaxation parameter, it is shown that DP.ADMM obtains an approximate first-order stationary point of the constrained problem in iterations for a given numerical tolerance . One of the main novelties of the paper is that convergence of the method is obtained without requiring any rank assumptions on the constraint matrices.},
  archive      = {J_SIOPT},
  author       = {Weiwei Kong and Renato D. C. Monteiro},
  doi          = {10.1137/22M1503129},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {201-224},
  shortjournal = {SIAM J. Optim.},
  title        = {Global complexity bound of a proximal ADMM for linearly constrained nonseparable nonconvex composite programming},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New bounds for the integer carathéodory rank.
<em>SIOPT</em>, <em>34</em>(1), 190–200. (<a
href="https://doi.org/10.1137/23M1561312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Given a rational pointed -dimensional cone , we study the integer Carathéodory rank and its asymptotic form , where we consider “most” integer vectors in the cone. The main result significantly improves the previously known upper bound for . We also study bounds on in terms of , the maximal absolute minor of the matrix given in an integral polyhedral representation of . If , we show that , and prove upper bounds for simplicial cones, improving the best known upper bound on for .},
  archive      = {J_SIOPT},
  author       = {Iskander Aliev and Martin Henk and Mark Hogan and Stefan Kuhlmann and Timm Oertel},
  doi          = {10.1137/23M1561312},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {190-200},
  shortjournal = {SIAM J. Optim.},
  title        = {New bounds for the integer carathéodory rank},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal algorithms for stochastic complementary composite
minimization. <em>SIOPT</em>, <em>34</em>(1), 163–189. (<a
href="https://doi.org/10.1137/22M1530884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Inspired by regularization techniques in statistics and machine learning, we study complementary composite minimization in the stochastic setting. This problem corresponds to the minimization of the sum of a (weakly) smooth function endowed with a stochastic first-order oracle and a structured uniformly convex (possibly nonsmooth and non-Lipschitz) regularization term. Despite intensive work on closely related settings, prior to our work no complexity bounds for this problem were known. We close this gap by providing novel excess risk bounds, both in expectation and with high probability. Our algorithms are nearly optimal, which we prove via novel lower complexity bounds for this class of problems. We conclude by providing numerical results comparing our methods to the state of the art.},
  archive      = {J_SIOPT},
  author       = {Alexandre d’Aspremont and Cristóbal Guzmán and Clément Lezane},
  doi          = {10.1137/22M1530884},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {163-189},
  shortjournal = {SIAM J. Optim.},
  title        = {Optimal algorithms for stochastic complementary composite minimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A correlatively sparse lagrange multiplier expression
relaxation for polynomial optimization. <em>SIOPT</em>, <em>34</em>(1),
127–162. (<a href="https://doi.org/10.1137/22M1515689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we consider polynomial optimization with correlative sparsity. We construct correlatively sparse Lagrange multiplier expressions (CS-LMEs) and propose CS-LME reformulations for polynomial optimization problems using the Karush–Kuhn–Tucker optimality conditions. Correlatively sparse sum-of-squares (CS-SOS) relaxations are applied to solve the CS-LME reformulation. We show that the CS-LME reformulation inherits the original correlative sparsity pattern, and the CS-SOS relaxation provides sharper lower bounds when applied to the CS-LME reformulation, compared with when it is applied to the original problem. Moreover, the convergence of our approach is guaranteed under mild conditions. In numerical experiments, our new approach usually finds the global optimal value (up to a negligible error) with a low relaxation order for cases where directly solving the problem fails to get an accurate approximation. Also, by properly exploiting the correlative sparsity, our CS-LME approach requires less computational time than the original LME approach to reach the same accuracy level.},
  archive      = {J_SIOPT},
  author       = {Zheng Qu and Xindong Tang},
  doi          = {10.1137/22M1515689},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {127-162},
  shortjournal = {SIAM J. Optim.},
  title        = {A correlatively sparse lagrange multiplier expression relaxation for polynomial optimization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aggregations of quadratic inequalities and hidden hyperplane
convexity. <em>SIOPT</em>, <em>34</em>(1), 98–126. (<a
href="https://doi.org/10.1137/22M1528215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study properties of the convex hull of a set described by quadratic inequalities. A simple way of generating inequalities valid on is to take nonnegative linear combinations of the defining inequalities of . We call such inequalities aggregations. Special aggregations naturally contain the convex hull of , and we give sufficient conditions for intersection of such aggregations to define the convex hull. We introduce the notion of hidden hyperplane convexity (HHC), which is related to the classical notion of hidden convexity of quadratic maps. We show that if the quadratic map associated with satisfies HHC, then the convex hull of is defined by special aggregations. To the best of our knowledge, this result generalizes all known results regarding aggregations defining convex hulls. Using this sufficient condition, we are able to recognize previously unknown classes of sets where aggregations lead to convex hull. We show that the condition known as the positive definite linear combination for every triple of inequalities, together with HHC, is sufficient for finitely many aggregations to define the convex hull, answering a question raised in [S. S. Dey, G. Munoz, and F. Serrano, On Obtaining the Convex Hull of Quadratic Inequalities via Aggregations, arXiv:2106.12629, 2021]. All the above results are for sets defined using open quadratic inequalities. For closed quadratic inequalities, we prove a new result regarding aggregations giving the convex hull, without topological assumptions on , which were needed in [S. Modaresi and J. P. Vielma, Math. Program., 164 (2017), pp. 383–409; S. S. Dey, G. Munoz, and F. Serrano, On Obtaining the Convex Hull of Quadratic Inequalities via Aggregations, arXiv:2106.12629, 2021].},
  archive      = {J_SIOPT},
  author       = {Grigoriy Blekherman and Santanu S. Dey and Shengding Sun},
  doi          = {10.1137/22M1528215},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {98-126},
  shortjournal = {SIAM J. Optim.},
  title        = {Aggregations of quadratic inequalities and hidden hyperplane convexity},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentiating nonsmooth solutions to parametric monotone
inclusion problems. <em>SIOPT</em>, <em>34</em>(1), 71–97. (<a
href="https://doi.org/10.1137/22M1541630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We leverage path differentiability and a recent result on nonsmooth implicit differentiation calculus to give sufficient conditions ensuring that the solution to a monotone inclusion problem will be path differentiable, with formulas for computing its generalized gradient. A direct consequence of our result is that these solutions happen to be differentiable almost everywhere. Our approach is fully compatible with automatic differentiation and comes with the following assumptions which are easy to check (roughly speaking): semialgebraicity and strong monotonicity. We illustrate the scope of our results by considering the following three fundamental composite problem settings: strongly convex problems, dual solutions to convex minimization problems, and primal-dual solutions to min-max problems.},
  archive      = {J_SIOPT},
  author       = {Jérôme Bolte and Edouard Pauwels and Antonio Silveti-Falls},
  doi          = {10.1137/22M1541630},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {71-97},
  shortjournal = {SIAM J. Optim.},
  title        = {Differentiating nonsmooth solutions to parametric monotone inclusion problems},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sufficient conditions for instability of the subgradient
method with constant step size. <em>SIOPT</em>, <em>34</em>(1), 57–70.
(<a href="https://doi.org/10.1137/22M1535723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We provide sufficient conditions for instability of the subgradient method with constant step size around a local minimum of a locally Lipschitz semialgebraic function. They are satisfied by several spurious local minima arising in robust principal component analysis and neural networks.},
  archive      = {J_SIOPT},
  author       = {Cédric Josz and Lexiao Lai},
  doi          = {10.1137/22M1535723},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {57-70},
  shortjournal = {SIAM J. Optim.},
  title        = {Sufficient conditions for instability of the subgradient method with constant step size},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Super-universal regularized newton method. <em>SIOPT</em>,
<em>34</em>(1), 27–56. (<a
href="https://doi.org/10.1137/22M1519444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We analyze the performance of a variant of the Newton method with quadratic regularization for solving composite convex minimization problems. At each step of our method, we choose a regularization parameter proportional to a certain power of the gradient norm at the current point. We introduce a family of problem classes characterized by the Hölder continuity of either the second or third derivative. Then we present the method with a simple adaptive search procedure allowing an automatic adjustment to the problem class with the best global complexity bounds, without knowing specific parameters of the problem. In particular, for the class of functions with a Lipschitz continuous third derivative, we get the global rate, which was previously attributed to third-order tensor methods. When the objective function is uniformly convex, we justify an automatic acceleration of our scheme, resulting in a faster global rate and local superlinear convergence. The switching between the different rates (sublinear, linear, and superlinear) is automatic. Again, for that, no a priori knowledge of parameters is needed.},
  archive      = {J_SIOPT},
  author       = {Nikita Doikov and Konstantin Mishchenko and Yurii Nesterov},
  doi          = {10.1137/22M1519444},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {27-56},
  shortjournal = {SIAM J. Optim.},
  title        = {Super-universal regularized newton method},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time-varying semidefinite programming: Path following a
burer–monteiro factorization. <em>SIOPT</em>, <em>34</em>(1), 1–26. (<a
href="https://doi.org/10.1137/22M1529762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present an online algorithm for time-varying semidefinite programs (TV-SDPs), based on the tracking of the solution trajectory of a low-rank matrix factorization, also known as the Burer–Monteiro factorization, in a path-following procedure. There, a predictor-corrector algorithm solves a sequence of linearized systems. This requires the introduction of a horizontal space constraint to ensure the local injectivity of the low-rank factorization. The method produces a sequence of approximate solutions for the original TV-SDP problem, for which we show that they stay close to the optimal solution path if properly initialized. Numerical experiments for a time-varying max-cut SDP relaxation demonstrate the computational advantages of the proposed method for tracking TV-SDPs in terms of runtime compared to off-the-shelf interior-point methods.},
  archive      = {J_SIOPT},
  author       = {Antonio Bellon and Mareike Dressler and Vyacheslav Kungurtsev and Jakub Mareček and André Uschmajew},
  doi          = {10.1137/22M1529762},
  journal      = {SIAM Journal on Optimization},
  month        = {3},
  number       = {1},
  pages        = {1-26},
  shortjournal = {SIAM J. Optim.},
  title        = {Time-varying semidefinite programming: Path following a Burer–Monteiro factorization},
  volume       = {34},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
