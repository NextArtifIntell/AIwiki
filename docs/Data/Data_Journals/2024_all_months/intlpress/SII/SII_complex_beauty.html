<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SII_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="sii---55">SII - 55</h2>
<ul>
<li><details>
<summary>
(2024). Composite quantile regression based robust empirical
likelihood for partially linear spatial autoregressive models.
<em>SII</em>, <em>17</em>(4), 749–761. (<a
href="https://doi.org/10.4310/22-SII764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the robust estimation for a class of partially linear spatial autoregressive models. By combining empirical likelihood and composite quantile regression methods, we propose a robust empirical likelihood estimation procedure. Under some regularity conditions, the proposed empirical log-likelihood ratio is proved to be asymptotically chi-squared, and the convergence rate of the estimator for nonparametric component is also derived. Some simulation analyses are conducted for further illustrating the performance of the proposed method, and simulation results show that the proposed method is more robust.},
  archive      = {J_SII},
  author       = {Zhao, Peixin and Cheng, Suli and Zhou, Xiaoshuang},
  doi          = {10.4310/22-SII764},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {749-761},
  shortjournal = {Stat. Interface},
  title        = {Composite quantile regression based robust empirical likelihood for partially linear spatial autoregressive models},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling and identifiability of non-homogenous poisson
process cure rate model. <em>SII</em>, <em>17</em>(4), 733–747. (<a
href="https://doi.org/10.4310/22-SII763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The promotion time cure models or bounded cumulative hazards model (BCH) was proposed as an alternative to the mixture cure models. In the present paper, this model is modified to provide a class of cure rate models based on a non-homogeneous Poisson process (NHPP). The properties of this class are studied. Also, when censored observations are present, distinguishing censored individuals from the cured group lead to identifiability issues in the members of this class. These identifiability issues are investigated and finally few members of this class are provided. Simulation results using an example of the NHPP cure rate model with exponentiated intensity and exponential baseline is supplemented. The application of the model is illustrated using E1684 real data from a study that included 284 patients from the Eastern Cooperative Oncology Group (ECOG) phase III clinical trial.},
  archive      = {J_SII},
  author       = {Surendren, Soorya and Gopalakrishnan, Asha and Dewanji, Anup},
  doi          = {10.4310/22-SII763},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {733-747},
  shortjournal = {Stat. Interface},
  title        = {Modeling and identifiability of non-homogenous poisson process cure rate model},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Flexible quasi-beta prime regression models for dependent
continuous positive data. <em>SII</em>, <em>17</em>(4), 715–731. (<a
href="https://doi.org/10.4310/22-SII762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many situations of interest, it is common to observe positive responses measured along several assessment conditions, within the same subjects. Usually, such a scenario implies a positive skewness on the response distributions, along with the existence of within-subject dependency. It is known that neglecting these features can lead to a misleading inference. In this paper we extend the beta prime regression model for modeling asymmetric positive data, while taking into account the dependence structure. We consider a useful predictor for modeling a suitable transformation of the mean, along with homogeneous covariance structure. The proposed model is an interesting competitor of the flexible Tweedie regression models, which include distributions such as Gamma and Inverse Gaussian. Furthermore, residual analysis and influence diagnostic tools are proposed. A Monte Carlo experiment is conducted to evaluate the performance of the proposed methodology, under small and moderate sample sizes, along with suitable discussions. The methodology is illustrated with the analysis of a real longitudinal dataset. An R package was developed to allow the practitioners to use the methodology described in this paper.},
  archive      = {J_SII},
  author       = {Freitas, João and Nobre, Juvêncio and Azevedo, Caio},
  doi          = {10.4310/22-SII762},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {715-731},
  shortjournal = {Stat. Interface},
  title        = {Flexible quasi-beta prime regression models for dependent continuous positive data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Empirical likelihood-based weighted estimation of average
treatment effects in randomized clinical trials with missing outcomes.
<em>SII</em>, <em>17</em>(4), 699–714. (<a
href="https://doi.org/10.4310/SII.2024.v17.n4.a7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been growing attention on covariate adjustment for treatment effect estimation in an objective and efficient manner in randomized clinical trials. In this paper, we propose a weighting approach to extract covariate information based on the empirical likelihood method for the randomized clinical trials with possible missingness in the outcomes. Multiple regression models are imposed to delineate the missing data mechanism and the covariate-outcome relationship, respectively. We demonstrate that the proposed estimator is suitable for objective inference of treatment effects. Theoretically, we prove that the proposed approach is multiply robust and semiparametrically efficient. We conduct simulations and a real data study to make comparisons with other existing methods.},
  archive      = {J_SII},
  author       = {Tan, Yuanyao and Wen, Xialing and Liang, Wei and Yan, Ying},
  doi          = {10.4310/SII.2024.v17.n4.a7},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {699-714},
  shortjournal = {Stat. Interface},
  title        = {Empirical likelihood-based weighted estimation of average treatment effects in randomized clinical trials with missing outcomes},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variable selection and estimation for high-dimensional
partially linear spatial autoregressive models with measurement errors.
<em>SII</em>, <em>17</em>(4), 681–697. (<a
href="https://doi.org/10.4310/22-SII758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a class of corrected post-model selection estimation method to identify important explanatory variables in parametric component of high-dimensional partially linear spatial autoregressive model with measurement errors. Compared with existing methods, the proposed method adds a new process of re-estimating the selected model parameters after model selection. We show that the post-model selection estimator performs at least as well as the Lasso penalty estimator by establishing some theorems of model selection and estimation properties. Extensive simulation studies not only evaluate the finite sample performance of the proposed method, but also show the superiority of the proposed method over other methods. As an empirical illustration, we apply the proposed model and method to two real data sets.},
  archive      = {J_SII},
  author       = {Huang, Zhensheng and Meng, Shuyu and Zhang, Linlin},
  doi          = {10.4310/22-SII758},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {681-697},
  shortjournal = {Stat. Interface},
  title        = {Variable selection and estimation for high-dimensional partially linear spatial autoregressive models with measurement errors},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A double regression method for graphical modeling of
high-dimensional nonlinear and non-gaussian data. <em>SII</em>,
<em>17</em>(4), 669–680. (<a
href="https://doi.org/10.4310/22-SII756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphical models have long been studied in statistics as a tool for inferring conditional independence relationships among a large set of random variables. The most existing works in graphical modeling focus on the cases that the data are Gaussian or mixed and the variables are linearly dependent. In this paper, we propose a double regression method for learning graphical models under the high-dimensional nonlinear and non-Gaussian setting, and prove that the proposed method is consistent under mild conditions. The proposed method works by performing a series of nonparametric conditional independence tests. The conditioning set of each test is reduced via a double regression procedure where a model-free sure independence screening procedure or a sparse deep neural network can be employed. The numerical results indicate that the proposed method works well for high-dimensional nonlinear and non-Gaussian data.},
  archive      = {J_SII},
  author       = {Liang, Siqi and Liang, Faming},
  doi          = {10.4310/22-SII756},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {669-680},
  shortjournal = {Stat. Interface},
  title        = {A double regression method for graphical modeling of high-dimensional nonlinear and non-gaussian data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A consistent specification test for functional linear
quantile regression models. <em>SII</em>, <em>17</em>(4), 649–667. (<a
href="https://doi.org/10.4310/22-SII754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is focused on the specification test of functional linear quantile regression models. A nonparametric test statistic is proposed based on the orthogonality of residual and its conditional expectation. It is proved with mild assumptions that the proposed statistic follows asymptotically the standard normal distribution under the null hypothesis, but tends to infinity under alternative hypothesis. The asymptotic power of the test is also presented for some local alternative hypotheses. The test is easy to implement, and is shown by simulations powerful even for small sample sizes. A real data example with the Capital Bikeshare data is presented for illustration.},
  archive      = {J_SII},
  author       = {Xia, Lili and Zhang, Zhongzhan and Shi, Gongming},
  doi          = {10.4310/22-SII754},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {649-667},
  shortjournal = {Stat. Interface},
  title        = {A consistent specification test for functional linear quantile regression models},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A latent class selection model for categorical response
variables with nonignorably missing data. <em>SII</em>, <em>17</em>(4),
635–648. (<a href="https://doi.org/10.4310/22-SII753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a new selection model for nonignorable missing values in multivariate categorical response variables by assuming that the response variables and their missingness can be summarized into categorical latent variables. Our proposed model contains two categorical latent variables. One latent variable summarizes the response patterns while the other describes the response variables’ missingness. Our selection model is an alternative method to other incomplete data methods when the incomplete data mechanism is nonignorable. We implement simulation studies to evaluate the performance of the proposed method and analyze the General Social Survey 2018 data to demonstrate its performance.},
  archive      = {J_SII},
  author       = {Lee, Jung Wun and Harel, Ofer},
  doi          = {10.4310/22-SII753},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {635-648},
  shortjournal = {Stat. Interface},
  title        = {A latent class selection model for categorical response variables with nonignorably missing data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Default bayesian testing for the zero-inflated poisson
distribution. <em>SII</em>, <em>17</em>(4), 623–634. (<a
href="https://doi.org/10.4310/22-SII750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a Bayesian model selection and hypothesis testing, users should be cautious when choosing suitable prior distributions, as it is an important problem. More often than not, objective Bayesian analyses utilize noninformative priors such as Jeffreys priors. However, since these noninformative priors are often improper, the Bayes factor associated with these improper priors is not well-defined. To circumvent this indeterminate issue, the Bayes factor can be corrected by intrinsic and fractional methods. These adjusted Bayes factors are asymptotically equivalent to the ordinary Bayes factors calculated with proper priors, called intrinsic priors. In this article, we derive intrinsic priors for testing the point null hypothesis under a zero-inflated Poisson distribution. Extensive simulation studies are performed to support the theoretical results on asymptotic equivalence, and two real datasets are analyzed to illustrate the methodology developed in this paper.},
  archive      = {J_SII},
  author       = {Han, Yewon and Hwang, Haewon and Ng, Hon Keung and Kim, Seong},
  doi          = {10.4310/22-SII750},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {623-634},
  shortjournal = {Stat. Interface},
  title        = {Default bayesian testing for the zero-inflated poisson distribution},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating extreme value index by subsampling for massive
datasets with heavy-tailed distributions. <em>SII</em>, <em>17</em>(4),
605–622. (<a href="https://doi.org/10.4310/22-SII749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern statistical analyses often encounter datasets with massive sizes and heavy-tailed distributions. For datasets with massive sizes, traditional estimation methods can hardly be used to estimate the extreme value index directly. To address the issue, we propose here a subsampling-based method. Specifically, multiple subsamples are drawn from the whole dataset by using the technique of simple random subsampling with replacement. Based on each subsample, an approximate maximum likelihood estimator can be computed. The resulting estimators are then averaged to form a more accurate one. Under appropriate regularity conditions, we show theoretically that the proposed estimator is consistent and asymptotically normal. With the help of the estimated extreme value index, we can estimate high-level quantiles and tail probabilities of a heavy-tailed random variable consistently. Extensive simulation experiments are provided to demonstrate the promising performance of our method. A real data analysis is also presented for illustration purpose.},
  archive      = {J_SII},
  author       = {Li, Yongxin and Chen, Liujun and Li, Deyuan and Wang, Hansheng},
  doi          = {10.4310/22-SII749},
  journal      = {Statistics and Its Interface},
  number       = {4},
  pages        = {605-622},
  shortjournal = {Stat. Interface},
  title        = {Estimating extreme value index by subsampling for massive datasets with heavy-tailed distributions},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An asymptotically normal representation for the minimal
clinically important difference under a nonconvex surrogate loss.
<em>SII</em>, <em>17</em>(3), 591–603. (<a
href="https://doi.org/10.4310/23-SII831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In clinical research, the effect of a treatment or intervention is widely assessed through clinical importance, instead of statistical significance. In this paper, we study an asymptotically normal representation for the minimal clinically important difference (MCID), a vital concept in assessing clinical importance. We formulate the scientific question into a statistical learning problem, develop an efficient algorithm for parameter estimation, and establish the asymptotic theory for the proposed estimator. We conduct comprehensive simulation studies to examine the finite sample performance of the proposed method. We also re-analyze the ChAMP (Chondral Lesions And Meniscus Procedures) trial with the patient-reported pain score change as the primary outcome. The ultimate goal of this trial is to determine whether there exists a significant difference in post-operative knee pain between patients undergoing debridement versus observation of chondral lesions during the surgery. Some previous analysis of this trial exhibited that the effect of debriding the chondral lesions does not reach a statistical significance. Our analysis reinforces this conclusion in that the effect of debriding the chondral lesions is not only statistically nonsignificant, but also clinically un-important.},
  archive      = {J_SII},
  author       = {Zhao, Jiwei and Zhou, Zehua and Bisson, Leslie},
  doi          = {10.4310/23-SII831},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {591-603},
  shortjournal = {Stat. Interface},
  title        = {An asymptotically normal representation for the minimal clinically important difference under a nonconvex surrogate loss},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved strategy for predicting alzheimer’s disease
progression in patients with mild cognitive impairment by clustering
hippocampal shape data. <em>SII</em>, <em>17</em>(3), 573–590. (<a
href="https://doi.org/10.4310/23-SII823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD), a neurodegenerative disorder leading to dementia and cognitive deficits, is influenced by various risk factors. Precise prognoses of AD are crucial to developing effective treatments, and recognizing potential heterogeneity within the population aids prognoses by detecting possible risk factors of each subgroup. Hippocampal structure changes have been connected to Alzheimer’s disease and are hypothesized to occur early in the illness’s development. In our work, we propose a universal clustering method for metric spaces that combines energy distance and a decision tree to detect the underlying heterogeneity in hippocampal structure. We are able to show that our method helps highlight the importance of utilizing hippocampus information for diagnosis and treatment and improves the prediction accuracy in a case study. The effectiveness of our approach is further backed up by the conducted simulations on widely-used metric spaces.},
  archive      = {J_SII},
  author       = {Wang, Tingyin and Gao, Zhe and Wang, Xueqin},
  doi          = {10.4310/23-SII823},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {573-590},
  shortjournal = {Stat. Interface},
  title        = {An improved strategy for predicting alzheimer&#39;s disease progression in patients with mild cognitive impairment by clustering hippocampal shape data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint model-based distance embedding of multi-track hi-c
data for chromosomal conformation learning. <em>SII</em>,
<em>17</em>(3), 565–571. (<a
href="https://doi.org/10.4310/SII.2024.v17.n3.a19">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the problem of reconstructing chromatin conformation from multi-track Hi-C data, we develop a data-integration method named Joint Model-based Distance Embedding (JMDE). JMDE enables probabilistic modeling for data from multiple sources, and learns the underlying shared Euclidean distance embedding in a unified framework. The practical merits of JMDE is demonstrated by simulations and real applications for reconstructing chromatin conformations of human chromosomes 14 and 22 in human lymphoblastoid cell line using two tracks of Hi-C data where the assays were performed with two restriction enzymes HindIII and NcoI, respectively. The proposed JMDE method can be applied to other fields to learn low-dimensional manifold latent structures from multiple related high-dimensional data where pairwise distances are not directly observed.},
  archive      = {J_SII},
  author       = {Zhang, Yuping and Ouyang, Zhengqing},
  doi          = {10.4310/SII.2024.v17.n3.a19},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {565-571},
  shortjournal = {Stat. Interface},
  title        = {Joint model-based distance embedding of multi-track hi-C data for chromosomal conformation learning},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A selective review on conditional density estimation.
<em>SII</em>, <em>17</em>(3), 549–564. (<a
href="https://doi.org/10.4310/23-SII821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional density estimation is a fundamental research problem in data science, naturally arising in a variety of applications such as semiparametric statistics, causal inference and machine learning. However, methodology development for conditional density estimation has received rather limited attention, in particular in comparison with conditional expectation estimation. In this review paper, we survey available nonparametric methods, as well as their corresponding software, in the literature for conditional density estimation. Specifically, we focus on nonparametric methods based on kernel smoothing, orthogonal basis expansion, and a highly adaptive lasso estimation strategy. We compare numerical performance of these methods in a comprehensive simulation study as well as in three benchmark data sets.},
  archive      = {J_SII},
  author       = {Ghosh, Trinetri and Yu, Menggang and Zhao, Jiwei},
  doi          = {10.4310/23-SII821},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {549-564},
  shortjournal = {Stat. Interface},
  title        = {A selective review on conditional density estimation},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imaging mediation analysis for longitudinal outcomes: A case
study of childhood brain tumor survivorship. <em>SII</em>,
<em>17</em>(3), 533–548. (<a
href="https://doi.org/10.4310/23-SII815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggressive cancer treatments that affect the central nervous system are associated with an increased risk of cognitive deficits. As treatment for pediatric brain tumors has become more effective, there has been a heightened focus on improving cognitive outcomes, which can significantly affect the quality of life for pediatric cancer survivors. This paper is motivated by and applied to a clinical trial for medulloblastoma, the most common malignant brain tumor in children. The trial collects comprehensive data including treatment-related clinical information, neuroimaging, and longitudinal neurocognitive outcomes to enhance our understanding of the responses to treatment and the enduring impacts of radiation therapy on the survivors of medulloblastoma. To this end, we have developed a new mediation model tailored for longitudinal outcomes with high-dimensional imaging mediators. Specifically, we adopt a joint binary Ising-Gaussian Markov random field prior distribution to account for spatial dependency and smoothness of ultra-high-dimensional neuroimaging mediators for enhancing detection power of informative voxels. By exploiting the proposed approach, we identify causal pathways and the corresponding white matter microstructures mediating the negative impact of irradiation on neurodevelopment. The results provide guidance on sparing the brain regions and improving long-term neurodevelopment for pediatric cancer survivors. Simulation studies also confirm the validity of the proposed method.},
  archive      = {J_SII},
  author       = {Li, Yimei and Wang, Xiaoqing and Zhou, Chen and Conklin, Heather and Onar-Thomas, Arzu and Gajjar, Amar and Reddick, Wilburn and Li, Cai},
  doi          = {10.4310/23-SII815},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {533-548},
  shortjournal = {Stat. Interface},
  title        = {Imaging mediation analysis for longitudinal outcomes: A case study of childhood brain tumor survivorship},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data integration of multiple genome-wide association studies
under group homogeneous structure. <em>SII</em>, <em>17</em>(3),
517–532. (<a href="https://doi.org/10.4310/23-SII810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, it’s common to have a large collection of datasets from similar scientific studies, with the famous example of multiple genome-wide association studies that are investigating the same human disease. To take advantage of these datasets, statisticians have developed data integration methods to combine datasets from multiple studies in order to increase statistical power. Most data integration methods to date can only combine compatible studies with the same explanatory variables; they also tend to ignore the grouping structure of the explanatory variables. However, incompatible studies with grouped explanatory variables arise frequently from multiple genome-wide association studies that employ different genotyping platforms. Therefore, we propose a new method called “gMeta” that can integrate incompatible datasets under a new group homogeneous structure by utilizing group regularization principles. gMeta not only promotes statistical powers by assuming homogeneity among group-level signals but also allows heterogeneous individual-level signals from different studies. Simulation studies illustrate the advantage of gMeta over separate analysis in terms of its homogeneity and enhanced statistical power for detecting weak signals. Finally, an integrative analysis of multiple genetic datasets on schizophrenia shows the applicability and efficacy of gMeta when it is applied to genome-wide association studies.},
  archive      = {J_SII},
  author       = {Li, Kai and Song, Chi and Jiang, Yuan},
  doi          = {10.4310/23-SII810},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {517-532},
  shortjournal = {Stat. Interface},
  title        = {Data integration of multiple genome-wide association studies under group homogeneous structure},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised learning in unbalanced networks with
heterogeneous degree. <em>SII</em>, <em>17</em>(3), 501–516. (<a
href="https://doi.org/10.4310/23-SII809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is a well-established area of research in network analysis. However, there has been limited discussion on how to improve prediction accuracy when some community labels are already known. In this paper, we introduce a novel algorithm called the weighted inverse Laplacian (WIL) for predicting labels in partially labeled undirected networks. Our algorithm is founded on the concept of the first hitting time of a random walk and is supported by information propagation and regularization frameworks. By combining two different normalization techniques, WIL is highly adaptable and can handle community imbalance and degree heterogeneity. Additionally, we propose a partially labeled degree-corrected block model (pDCBM) to describe the generation of partially labeled networks. Under this model, we prove that WIL guarantees a misclassification rate going to zero as the number of nodes goes to infinity, and it can handle greater imbalances than traditional Laplacian methods. Our simulations and empirical studies demonstrate that WIL outperforms other state-of-the-art methods, particularly in unbalanced and heterogeneous networks.},
  archive      = {J_SII},
  author       = {Ting, Li and Ying, Ningchen and Yu, Xianshi and Jing, Bing-Yi},
  doi          = {10.4310/23-SII809},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {501-516},
  shortjournal = {Stat. Interface},
  title        = {Semi-supervised learning in unbalanced networks with heterogeneous degree},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simultaneous change-point detection and curve estimation.
<em>SII</em>, <em>17</em>(3), 493–500. (<a
href="https://doi.org/10.4310/23-SII807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we focus on a nonparametric regression model that accounts for discontinuities. We propose a method called Simultaneous CHange-point detection And Curve Estimation (SCHACE) for effectively detecting jumps in a data sequence and accurately capturing nonlinear trends between these jumps in the mean curve. The SCHACE is a unified regularization framework that incorporates two statistical tools: the normalized fused Lasso for change-point detection and B-splines for curve estimation. Notably, this approach is a single-step method that does not require iteration and is straightforward to implement. We demonstrate the advantages of the SCHACE by simulated and real-world data examples.},
  archive      = {J_SII},
  author       = {Lu, Zhaoying and Hao, Ning and Zhang, Hao},
  doi          = {10.4310/23-SII807},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {493-500},
  shortjournal = {Stat. Interface},
  title        = {Simultaneous change-point detection and curve estimation},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable and globally convergent algorithm for sufficient
dimension reduction. <em>SII</em>, <em>17</em>(3), 479–491. (<a
href="https://doi.org/10.4310/23-SII798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sufficient Dimension Reduction (SDR) is a powerful approach for analyzing high-dimensional data, where the goal is to represent covariates by a minimal set of their linear projections that still capture the necessary information for regression analysis of the response. However, many existing SDR methods employ a generalized eigen decomposition of a method-specific kernel matrix, which is a non-convex optimization problem and requires significant computation involving large matrix products and decomposition. In this paper, we propose an iterative least squares formulation for SDR, which solves each least squares problem approximately. We combine this formulation with state-of-the-art stochastic gradient descent methods to propose a scalable and globally convergent algorithm for SDR. To the best of our knowledge, this is the first stochastic algorithm proposed for SDR. Through extensive simulations, we demonstrate that our method achieves competitive empirical performance.},
  archive      = {J_SII},
  author       = {Chen, Canyi},
  doi          = {10.4310/23-SII798},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {479-491},
  shortjournal = {Stat. Interface},
  title        = {Scalable and globally convergent algorithm for sufficient dimension reduction},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The use of parental genotypes in mendelian randomization.
<em>SII</em>, <em>17</em>(3), 469–478. (<a
href="https://doi.org/10.4310/23-SII795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mendelian randomization method has been used in genetic epidemiological studies to estimate the causal effect of a biomarker on clinical outcomes. Genotypes are used as instrumental variables (IV) to remove the bias due to unmeasured confounding in observational data. A valid inference relies on the assumption that IV is not correlated with unmeasured confounders. While this assumption may be violated in many scenarios, it can be difficult to assess potential violations. To relax this assumption, we proposed a framework of 2-stage least square method stratified on parental genotypes when available. This method can effectively reduce confounding and provide an unbiased estimate of the causal effect, even when unmeasured confounders are correlated with the IV. We extended the method for scenarios when only partial parental genotypes are available. As a demonstration, we applied the method to a study of triglyceride response to drug and diet. The result was consistent with the known negative effect of high-density lipoprotein on insulin resistance.},
  archive      = {J_SII},
  author       = {Feng, Rui and Arnett, Donna and Yang, Wei},
  doi          = {10.4310/23-SII795},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {469-478},
  shortjournal = {Stat. Interface},
  title        = {The use of parental genotypes in mendelian randomization},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatially robust adaptive ensemble average propagator
reconstruction via spherical polar fourier imaging. <em>SII</em>,
<em>17</em>(3), 451–468. (<a
href="https://doi.org/10.4310/23-SII791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to propose a robust multi-scale adaptive and sequential smoothing (MASS) method framework to spatially and adaptively infer the ensemble average propagator (EAP) of water diffusion in brain regions with complex fiber configurations. We consider Spherical Polar Fourier Imaging (SPFI), which is a model-free and fast analytical high angular resolution diffusion imaging (HARDI) technique, for EAP reconstruction. SPFI uses the combination of angular and radial elementary functions expressed in a spherical coordinate system, making it less reliant on data assumptions and sampling requirements than other HARDI techniques. We reformulate the EAP reconstruction as a robust regression problem using Huber’s loss function with Spherical Polar Fourier (SPF) basis as covariates. Similarity and distance weights are introduced to account for spatial smoothness of HARDI, while preserving the unknown discontinuities (e.g., edges between white matter and grey matter). Experimental results indicate that MASS can reduce the angle detection errors in fiber crossing area and provides more accurate reconstructions than standard voxel-wise methods under the presence of outliers.},
  archive      = {J_SII},
  author       = {Wang, Xifeng and Rao, Shangbang and Cheng, Jian and Wu, Ye and Yap, Pew-Thian and Ibrahim, Joseph and Zhu, Hongtu},
  doi          = {10.4310/23-SII791},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {451-468},
  shortjournal = {Stat. Interface},
  title        = {Spatially robust adaptive ensemble average propagator reconstruction via spherical polar fourier imaging},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel update and propagation-based dynamic graph neural
network and its application to consumer finance data. <em>SII</em>,
<em>17</em>(3), 439–450. (<a
href="https://doi.org/10.4310/23-SII788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel dynamic graph neural network, the UP-DGNN, which combines the DGNNs and the update-propagation framework. The main contributions of the proposed method are two-fold. On one hand, in the update phase, the model updates the embedding vector of interacting nodes using a T-GRU to extract temporal features, and on the other hand, in the propagation phase, the self-attention mechanism is introduced to update the embedding vector of the affected nodes. Compared with GRU and LSTM models, the proposed model can update node information more efficiently. Further, the performance of the model is demonstrated in public datasets on tasks of link prediction, edge classification and node classification, and we apply the proposed method on the prediction of peer to peer credit default, taking into account the social relationships, and achieve better prediction performance than SOTA methods in consumer finance area.},
  archive      = {J_SII},
  author       = {Liu, Xin and Zhang, Zhen and Guo, Shujun and Wang, Shaoli},
  doi          = {10.4310/23-SII788},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {439-450},
  shortjournal = {Stat. Interface},
  title        = {A novel update and propagation-based dynamic graph neural network and its application to consumer finance data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards better clinical prediction and interpretation via a
new imputation strategy from national health and nutrition examination
survey. <em>SII</em>, <em>17</em>(3), 425–437. (<a
href="https://doi.org/10.4310/23-SII783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart failure, the most prevalent reason for hospitalization and readmission among the elderly, is a common, expensive, and potentially fatal condition brought on by impairment of the heart’s function to pump blood. Finding the underlying causes is essential to diagnosis and treatment because heart failure is a syndrome and the potential final stage of all heart illnesses. In the observational study, missing values are frequent and challenging. We propose an efficient and interpretable framework to analyze missing data based on the matrix completion method and logistic regression model. A simple rank estimation procedure is also proposed in our approach to determine hyperparameters in matrix completion and provide interpretability for the number of important variables or risk factors. We conduct a case study with the National Health and Nutrition Examination Survey data on heart failure (2007–2014) to explore new risk factors. Each participant had variables with missing values, resulting in the total missing rate being 47.73%. Our method has been shown to improve AUC in a case study. Even more, total spine bone mineral content (BMC) is identified as a potential risk factor associated with heart failure.},
  archive      = {J_SII},
  author       = {Gao, Zhe and Xu, Yanfang and Wu, Wangwei and Wang, Xueqin and Kong, YinYing and Tian, Ting},
  doi          = {10.4310/23-SII783},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {425-437},
  shortjournal = {Stat. Interface},
  title        = {Towards better clinical prediction and interpretation via a new imputation strategy from national health and nutrition examination survey},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable inference for individual treatment effect.
<em>SII</em>, <em>17</em>(3), 413–423. (<a
href="https://doi.org/10.4310/23-SII781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovery of the discrepant treatment effect across each individual is important for precision decision making. Different from the conditional average treatment effect (CATE) which is sensitive to the uncertain environments, the developed individual treatment effect (ITE) is more scalable in term of generating average treatment effect, group-specific treatment effects or CATE and more robust to the model uncertainty, because the proposed heterogeneous model includes partially linear and high-dimensional regression, etc. Under the potential outcome framework, we use multiple imputation techniques first to recover the conditional expectation of unobserved potential outcome. Ridge fused penalty-based quadratic loss function is developed to estimate all population and individual parameters and we deduce the explicit expression for individual estimators, avoiding the computational burden caused by the massive data. Theoretical results argue the asymptotic distribution of individual parameters for statistical inference of individual treatment effect. Simulation studies pose supportive evidence that the proposed unified structure of individual analysis including estimation, inference and prediction performs well with finite samples, and a real data example is provided for illustrating the flexibility of ITE in finding the individual information and forming all sorts of treatment effects.},
  archive      = {J_SII},
  author       = {Yan, Xiaodong and Xie, Jinhan and Tu, Wei and Jiang, Bei and Kong, Linglong},
  doi          = {10.4310/23-SII781},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {413-423},
  shortjournal = {Stat. Interface},
  title        = {Scalable inference for individual treatment effect},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Associations between EEG-defined subgroups and
antidepressant response: A joint mixture of probabilistic multilinear
principal component analysis modeling approach. <em>SII</em>,
<em>17</em>(3), 397–411. (<a
href="https://doi.org/10.4310/23-SII780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint mixture models have become popular tools to uncover distinct latent subgroups in some manifest variables and to simultaneously relate such heterogeneity to an outcome of interest, while explicitly taking into account the uncertainty of latent class memberships. In this paper, we extend existing latent mixture models to incorporate matrix-variate data built on a mixture model for probabilistic multilinear principle component analysis. The work is motivated by a depression study to investigate the patient heterogeneity based on baseline electroencephalograph (EEG) and the association of such EEG defined subgroups and the antidepressant response. Specifically, there are three levels of structure in our proposed model. First, the uncertainty of latent class membership in the matrix-variate EEG data is specified through a multinomial logistic model. Second, the class-specific EEG data is assumed to follow a probabilistic multilinear principle component analysis model. Third, under the assumption of conditional independence given the latent class membership, the association of the baseline EEG and the antidepressant response is established through the latent classes of baseline EEG. Applying the proposed model to our motivating depression study, four distinct patient subpopulations are identified that differ with respect to their baseline EEG patterns and the risk for positively responding to antidepressant treatment. In contrast, other existing clustering methods cannot lead to findings of such patient subpopulations.},
  archive      = {J_SII},
  author       = {Yu, Peng and Zhao, Kaiqiong and Jiang, Bei and Petkova, Eva and Tarpey, Thaddeus and Ogden, R. Todd},
  doi          = {10.4310/23-SII780},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {397-411},
  shortjournal = {Stat. Interface},
  title        = {Associations between EEG-defined subgroups and antidepressant response: A joint mixture of probabilistic multilinear principal component analysis modeling approach},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Welfare and fairness dynamics in federated learning: A
client selection perspective. <em>SII</em>, <em>17</em>(3), 383–395. (<a
href="https://doi.org/10.4310/23-SII779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a privacy-preserving learning technique that enables distributed computing devices to train shared learning models across data silos collaboratively. Existing FL works mostly focus on designing advanced FL algorithms to improve the model performance. However, the economic considerations of the clients, such as fairness and incentive, are yet to be fully explored. Without such considerations, self-motivated clients may lose interest and leave the federation. To address this problem, we designed a novel incentive mechanism that involves a client selection process to remove low-quality clients and a money transfer process to ensure a fair reward distribution. Our experimental results strongly demonstrate that the proposed incentive mechanism can effectively improve the duration and fairness of the federation.},
  archive      = {J_SII},
  author       = {Travadi, Yash and Peng, Le and Bi, Xuan and Sun, Ju and Yang, Mochen},
  doi          = {10.4310/23-SII779},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {383-395},
  shortjournal = {Stat. Interface},
  title        = {Welfare and fairness dynamics in federated learning: A client selection perspective},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimation of partially linear varying coefficient spatial
autoregressive models. <em>SII</em>, <em>17</em>(3), 371–382. (<a
href="https://doi.org/10.4310/23-SII775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partially linear varying coefficient spatial autoregressive (PLVCSAR) models are powerful tools for analyzing data with complex features such as non-linearity, interactions between predictors, and spatial dependence. This paper studies the estimation of the PLVCSAR model by combining the profile quasi-maximum likelihood method and the spline approximation technique. Estimations of the constant coefficients, function coefficients, variance of the error term, and the spatial lag parameter are proposed. Under mild conditions, the asymptotic properties of the proposed estimators are established. Simulation studies and real data analysis of Boston housing data illustrate the finite sample performances of the proposed estimators.},
  archive      = {J_SII},
  author       = {Wang, Xiaoying and Sun, Xiaoqian and Du, Jiang and Liu, Kaiyuan},
  doi          = {10.4310/23-SII775},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {371-382},
  shortjournal = {Stat. Interface},
  title        = {Estimation of partially linear varying coefficient spatial autoregressive models},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust subgroup analysis for network-linked data.
<em>SII</em>, <em>17</em>(3), 357–370. (<a
href="https://doi.org/10.4310/23-SII774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern applications often collect data with individuals connected by a network to effectively record relationship information between individuals. In this paper, we use both covariates and the network to identify subgroup structures from a heterogeneous population, where heterogeneity arises from unknown or unobserved latent factors. We propose a penalization based method for subgroup analysis based on the median regression model, which can automatically divide the samples into subgroups by penalizing pairwise difference of intercepts for individuals connected by an edge in the network. The proposed method can also be used to predict response variables for new subjects with only covariates by taking advantage of the network reconstructed after adding these new subjects. We suggest an implementation algorithm based on the local linear approximation to the nondifferentiable and nonconvex penalty function and establish the oracle properties of the proposed estimator under some regularity conditions. Our simulation studies show that the proposed method can effectively identify heterogeneous subgroups even when the network has errors or misspecified edges. Finally, the advantages of the proposed method are further illustrated by the analysis on a housing price data set from real estate transactions.},
  archive      = {J_SII},
  author       = {Xing, Yu and Zhu, Wensheng and Jon, Kyongson},
  doi          = {10.4310/23-SII774},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {357-370},
  shortjournal = {Stat. Interface},
  title        = {Robust subgroup analysis for network-linked data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). <span
class="math inline"><em>L</em><sub>1</sub></span>-regularized functional
support vector machine. <em>SII</em>, <em>17</em>(3), 349–356. (<a
href="https://doi.org/10.4310/22-SII773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In functional data analysis, binary classification with one functional covariate has been extensively studied. We aim to fill in the gap of considering multivariate functional covariates in classification. In particular, we propose an $L_1$-regularized functional support vector machine for binary classification. An accompanying algorithm is developed to fit the classifier. By imposing an $L_1$ penalty, the algorithm enables us to identify relevant functional covariates of the binary response. Numerical results from simulations and one real-world application demonstrate that the proposed classifier enjoys good performance in both prediction and feature selection.},
  archive      = {J_SII},
  author       = {Liu, Bingfan and Sang, Peijun},
  doi          = {10.4310/22-SII773},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {349-356},
  shortjournal = {Stat. Interface},
  title        = {$L_1$-regularized functional support vector machine},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Debiased distributed quantile regression in high dimensions.
<em>SII</em>, <em>17</em>(3), 337–347. (<a
href="https://doi.org/10.4310/22-SII759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the debiased distributed estimation for the linear model in high dimensions with arbitrary noise distribution. Quantile regression (QR) is adopted to safeguard potential heavy-tailed noises. To tackle the computational challenges accompanied by the non-smooth QR loss, we cast the QR loss into a least-squares loss by constructing new pseudo responses. We further equip the new least-squares loss with the $\ell_1$ penalty to accomplish tasks of coefficient estimation and variable selection. To eliminate the bias brought by the $\ell_1$ penalty, we correct the bias of nonzero coefficient estimation for each local machine and aggregate all the local debiased estimators through averaging. Our distributed algorithm is guaranteed to converge in a finite number of iterations. Theoretically, we show that the resulting estimator can consistently recover the sparsity pattern and achieve a near-oracle convergence rate. We conduct extensive numerical studies to demonstrate the competitive finite sample performance of our method.},
  archive      = {J_SII},
  author       = {He, Yiran and Chen, Canyi and Xu, Wangli},
  doi          = {10.4310/22-SII759},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {337-347},
  shortjournal = {Stat. Interface},
  title        = {Debiased distributed quantile regression in high dimensions},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved naive bayes with mislabeled data. <em>SII</em>,
<em>17</em>(3), 323–336. (<a
href="https://doi.org/10.4310/22-SII757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Labeling mistakes are frequently encountered in real-world applications. If not treated well, the labeling mistakes can deteriorate the classification performances of a model seriously. To address this issue, we propose an improved Naive Bayes method for text classification. It is analytically simple and free of subjective judgments on the correct and incorrect labels. By specifying the generating mechanism of incorrect labels, we optimize the corresponding log-likelihood function iteratively by using an EM algorithm. Our simulation and experiment results show that the improved Naive Bayes method greatly improves the performances of the Naive Bayes method with mislabeled data.},
  archive      = {J_SII},
  author       = {Zeng, Qianhan and Zhu, Yingqiu and Zhu, Xuening and Wang, Feifei and Zhao, Weichen and Sun, Shuning and Su, Meng and Wang, Hansheng},
  doi          = {10.4310/22-SII757},
  journal      = {Statistics and Its Interface},
  number       = {3},
  pages        = {323-336},
  shortjournal = {Stat. Interface},
  title        = {Improved naive bayes with mislabeled data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-based statistical depth for matrix data. <em>SII</em>,
<em>17</em>(2), 305–316. (<a
href="https://doi.org/10.4310/23-SII829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of matrix data learning has witnessed significant advancements in recent years, encompassing diverse datasets such as medical images, social networks, and personalized recommendation systems. These advancements have found widespread application in various domains, including medicine, biology, public health, engineering, finance, economics, sports analytics, and environmental sciences. While extensive research has been conducted on estimation, inference, prediction, and computation for matrix data, the ranking problem has not received adequate attention. Statistical depth, a measure providing a centeroutward rank for different data types, has been introduced in the past few decades. However, its exploration has been limited due to the complexity of the second and higher orderstatistics. In this paper, we propose an approach to rank matrix data by employing a model-based depth framework. Our methodology involves estimating the eigen-decomposition of a 4th-order covariance tensor. To enable this process using conventional matrix operations, we specify the tensor product operator between matrices and 4th-order tensors. Furthermore, we introduce a Kronecker product form on the covariance to enhance the robustness and efficiency of the estimation process, effectively reducing the number of parameters in the model. Based on this new framework, we develop an efficient algorithm to estimate the model-based statistical depth. To validate the effectiveness of our proposed method, we conduct simulations and apply it to two real-world applications: field goal attempts of NBA players and global temperature anomalies.},
  archive      = {J_SII},
  author       = {Mu, Yue and Hu, Guanyu and Wu, Wei},
  doi          = {10.4310/23-SII829},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {305-316},
  shortjournal = {Stat. Interface},
  title        = {Model-based statistical depth for matrix data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust and covariance-assisted tensor response regression.
<em>SII</em>, <em>17</em>(2), 291–303. (<a
href="https://doi.org/10.4310/SII.2024.v17.n2.a10">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor data analysis is gaining increasing popularity in modern multivariate statistics. When analyzing real-world tensor data, many existing tensor estimation approaches are sensitive to heavy-tailed data and outliers, in addition to the apparent high-dimensionality. In this article, we develop a robust and covariance-assisted tensor response regression model based on a recently proposed tensor t‑distribution to address these issues in tensor data. This model assumes that the tensor regression coefficient has a low-rank structure that can be learned more effectively using the additional covariance information. This enables a fast and robust decomposition-based estimation method. Theoretical analysis and numerical experiments demonstrate the superior performance of our approach. By addressing the heavy-tail, high-order, and high-dimensional issues, our work contributes to robust and effective estimation methods for tensor response regression, with broad applicability in various domains.},
  archive      = {J_SII},
  author       = {Wang, Ning and Zhang, Xin},
  doi          = {10.4310/SII.2024.v17.n2.a10},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {291-303},
  shortjournal = {Stat. Interface},
  title        = {Robust and covariance-assisted tensor response regression},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rank-r matrix autoregressive models for modeling
spatio-temporal data. <em>SII</em>, <em>17</em>(2), 275–290. (<a
href="https://doi.org/10.4310/23-SII812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a matrix-variate autoregressive (MAR) model to analyze spatio-temporal data organized on a regular grid in space. The model is an extension of the bilinear MAR spatial model of Hsu, Huang and Tsay $\href{ https://doi.org/10.1080/10618600.2021.1938587 }{[10]}$ by increasing its flexibility and applicability in empirical applications. Specifically, we propose to model each autoregressive (AR) coefficient matrix of the MAR model by $R$ bilinear terms, thereby establishing a rank‑R model. The extension can be interpreted as decomposing the AR dynamics of the data into $R$ bilinear MAR components. We further incorporate a banded neighborhood structure for AR coefficient matrices and utilize a flexible nonstationary low-rank covariance model for the spatial innovation process, leading to a parsimonious model without sacrificing its flexibility. We estimate all parameters of the model by the maximum likelihood method and develop a computationally efficient alternating direction method of multipliers algorithm, involving only closed-form expressions in all steps. Applications to a wind-speed dataset and an employment dataset, as well as two simulation experiments, demonstrate the effectiveness of the proposed method in estimation, model selection, and prediction.},
  archive      = {J_SII},
  author       = {Hsu, Nan-Jung and Huang, Hsin-Cheng and Tsay, Ruey S. and Kao, Tzu-Chieh},
  doi          = {10.4310/23-SII812},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {275-290},
  shortjournal = {Stat. Interface},
  title        = {Rank-R matrix autoregressive models for modeling spatio-temporal data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian methods in tensor analysis. <em>SII</em>,
<em>17</em>(2), 249–274. (<a
href="https://doi.org/10.4310/23-SII802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensors, also known as multidimensional arrays, are useful data structures in machine learning and statistics. In recent years, Bayesian methods have emerged as a popular direction for analyzing tensor-valued data since they provide a convenient way to introduce sparsity into the model and conduct uncertainty quantification. In this article, we provide an overview of frequentist and Bayesian methods for solving tensor completion and regression problems, with a focus on Bayesian methods. We review common Bayesian tensor approaches including model formulation, prior assignment, posterior computation, and theoretical properties.We also discuss potential future directions in this field.},
  archive      = {J_SII},
  author       = {Yiyao, Shi and Weining, Shen},
  doi          = {10.4310/23-SII802},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {249-274},
  shortjournal = {Stat. Interface},
  title        = {Bayesian methods in tensor analysis},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Density-convoluted tensor support vector machines.
<em>SII</em>, <em>17</em>(2), 231–247. (<a
href="https://doi.org/10.4310/23-SII796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of tensor data (also known as multi-dimensional arrays) in many modern applications such as image processing and digital marketing, tensor classification is gaining increasing attention. Although there is a rich toolbox of classification methods for vector-based data, these traditional methods may not be adequate for tensor data classification. In this paper, we propose a new classifier called density-convoluted tensor support vector machine (DCT‑SVM). This method is motivated by applying a kernel density convolution method on the SVM loss to induce a new family of classification loss functions. To establish the theoretical foundation of DCT‑SVM, the probabilistic order of magnitude for its excess risk is systematically studied. For efficiently computing DCT‑SVM, we develop a fast monotone accelerated proximal gradient descent algorithm and show the convergence of the algorithm. With simulation studies, we demonstrate the superior performance of DCT‑SVM over many popular classification methods. We further demonstrate the real potential of DCT‑SVM using a modern data application for online advertising.},
  archive      = {J_SII},
  author       = {Wang, Boxiang and Zhou, Le and Yang, Jian and Mai, Qing},
  doi          = {10.4310/23-SII796},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {231-247},
  shortjournal = {Stat. Interface},
  title        = {Density-convoluted tensor support vector machines},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-way overlapping clustering by bayesian tensor
decomposition. <em>SII</em>, <em>17</em>(2), 219–230. (<a
href="https://doi.org/10.4310/23-SII790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of modern sequencing technologies provides great opportunities to measure gene expression of multiple tissues from different individuals. The three-way variation across genes, tissues, and individuals makes statistical inference a challenging task. In this paper, we propose a Bayesian multi-way clustering approach to cluster genes, tissues, and individuals simultaneously. The proposed model adaptively trichotomizes the observed data into three latent categories and uses a Bayesian hierarchical construction to further decompose the latent variables into lower-dimensional features, which can be interpreted as overlapping clusters. With a Bayesian nonparametric prior, i.e., the Indian buffet process, our method determines the cluster number automatically. The utility of our approach is demonstrated through simulation studies and an application to the Genotype-Tissue Expression (GTEx) RNA-seq data. The clustering result reveals some interesting findings about depression-related genes in human brain, which are also consistent with biological domain knowledge. The detailed algorithm and some numerical results are available in the online Supplementary Material, available at $\href{https://intlpress.com/site/pub/files/supp/sii/2024/0017/0002/sii-2024-0017-0002-s001.pdf}{ https://intlpress.com/site/pub/files/supp/sii/2024/0017/0002/sii-2024-0017-0002-s001.pdf}.},
  archive      = {J_SII},
  author       = {Wang, Zhuofan and Zhou, Fangting and He, Kejun and Ni, Yang},
  doi          = {10.4310/23-SII790},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {219-230},
  shortjournal = {Stat. Interface},
  title        = {Multi-way overlapping clustering by bayesian tensor decomposition},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian tensor-on-tensor regression with efficient
computation. <em>SII</em>, <em>17</em>(2), 199–217. (<a
href="https://doi.org/10.4310/23-SII786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a Bayesian tensor-on-tensor regression approach to predict a multidimensional array (tensor) of arbitrary dimensions from another tensor of arbitrary dimensions, building upon the Tucker decomposition of the regression coefficient tensor. Traditional tensor regression methods making use of the Tucker decomposition either assume the dimension of the core tensor to be known or estimate it via cross-validation or some model selection criteria. However, no existing method can simultaneously estimate the model dimension (the dimension of the core tensor) and other model parameters. To fill this gap, we develop an efficient Markov Chain Monte Carlo (MCMC) algorithm to estimate both the model dimension and parameters for posterior inference. Besides the MCMC sampler, we also develop an ultra-fast optimization-based computing algorithm wherein the maximum a posteriori estimators for parameters are computed, and the model dimension is optimized via a simulated annealing algorithm. The proposed Bayesian framework provides a natural way for uncertainty quantification. Through extensive simulation studies, we evaluate the proposed Bayesian tensor-on-tensor regression model and show its superior performance compared to alternative methods. We also demonstrate its practical effectiveness by applying it to two real-world datasets, including facial imaging data and 3D motion data.},
  archive      = {J_SII},
  author       = {Wang, Kunbo and Xu, Yanxun},
  doi          = {10.4310/23-SII786},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {199-217},
  shortjournal = {Stat. Interface},
  title        = {Bayesian tensor-on-tensor regression with efficient computation},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning conditional dependence graph for concepts via
matrix normal graphical model. <em>SII</em>, <em>17</em>(2), 187–198.
(<a href="https://doi.org/10.4310/23-SII784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional dependence relationships for random vectors are extensively studied and broadly applied. But it is not very clear how to construct the dependence graph for unstructured data like concept words or phrases in text corpus, where the variables(concepts) are not jointly observed with i.i.d. assumption. Using the global embedding methods like GloVe, we get the ‘structured’ representation vectors for concepts. Then we assume that all the concept vectors jointly follow a matrix normal distribution with sparse precision matrices. With the observation of the word-word co-occurrence matrix and the GloVe construction procedure, we can test this assumption empirically. The asymptotic distribution for the test statistics is derived. Another advantage of this matrix-normal distributional assumption is that the linearly additive property in word analogy tasks is natural and straightforward. Different from knowledge graph methods, the conditional dependence graph describes the conditional dependence structure between concepts given all other concepts, which means that the concepts(nodes) linked by edges cannot be separated by other concepts. It represents an essential semantic relationship. There is no need to enumerate all related pairs as head and tail elements of a triplet in knowledge graph regime. And the relation type in this graph is solely the conditional dependence between concepts. A penalized matrix normal graphical model (MNGM) is then employed to learn the conditional dependence graph for both the concepts and the embedding ‘dimensions’. Since the concept words are nodes in our graph with huge dimensions, we employ the MDMC optimization method to speed up the glasso algorithm. Also, the algorithm is adaptive to incremental accumulation of new concepts in text corpus. On the other hand, we propose a sentence granularity bootstrap to get ‘independent’ repeats of samples to enhance the penalized MNGM algorithm.We name the proposed method as Matrix-GloVe. In simulation studies, we check that the graph learned by Matrix-GloVe is more suitable for Graph Convolutional Networks(GCN) than a correlation graph, i.e. a graph determined from the k-NN method. We employ the proposed method in two scenarios from real data. The first scenario is concept graph learning for concepts in textbook corpus. Under this scenario, two tasks are studied. One is comparing the vectors output by GloVe and other word2vec methods, i.e. CBOW and Skip-Gram, then the vectors are used by penalized MNGM. Another task is link prediction among the concepts. On both tasks, Matrix-GloVe achieves better. In the second scenario, Matrix-GloVe is applied to a downstream method i.e. GCN. For node classification tasks on the BBC and BBCSport datasets, both GCN with Matrix- GloVe and GCN with Matrix-GloVe plus Deepwalk outperform GCN with k-NN.},
  archive      = {J_SII},
  author       = {Lai, Jizheng and Yin, Jianxin},
  doi          = {10.4310/23-SII784},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {187-198},
  shortjournal = {Stat. Interface},
  title        = {Learning conditional dependence graph for concepts via matrix normal graphical model},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correlated wishart matrices classification via an
expectation-maximization composite likelihood-based algorithm.
<em>SII</em>, <em>17</em>(2), 173–185. (<a
href="https://doi.org/10.4310/22-SII770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Positive-definite matrix-variate data is becoming popular in computer vision. The computer vision data descriptors in the form of Region Covariance Descriptors (RCD) are positive definite matrices, which extract the key features of the images. The RCDs are extensively used in image set classification. Some classification methods treating RCDs as Wishart distributed random matrices are being proposed. However, the majority of the current methods preclude the potential correlation among the RCDs caused by the so-called auxiliary information (e.g., subjects’ ages and nose widths, etc). Modeling correlated Wishart matrices is difficult since the joint density function of correlated Wishart matrices is difficult to be obtained. In this paper, we propose an Expectation-Maximization composite likelihoodbased algorithm of Wishart matrices to tackle this issue. Given the numerical studies based on the synthetic data and the real data (Chicago face data-set), our proposed algorithm performs better than the alternative methods which do not consider the correlation caused by the so-called auxiliary information.},
  archive      = {J_SII},
  author       = {Lan, Zhou},
  doi          = {10.4310/22-SII770},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {173-185},
  shortjournal = {Stat. Interface},
  title        = {Correlated wishart matrices classification via an expectation-maximization composite likelihood-based algorithm},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A random projection method for large-scale community
detection. <em>SII</em>, <em>17</em>(2), 159–172. (<a
href="https://doi.org/10.4310/22-SII752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider a random projection method for a large-scale community detection task. We introduce a random Gaussian matrix that generates several projections on the column space of the network adjacency matrix. The $k$-means algorithm is then applied with the low-dimensional projected matrix. The computational complexity is much lower than that of the classic spectral clustering methods. Furthermore, the algorithm is easy to implement and accessible for privacy preservation. We can theoretically establish a strong consistency result of the algorithm under the stochastic block model. Extensive numerical studies are conducted to verify the theoretical findings and illustrate the usefulness of the proposed method.},
  archive      = {J_SII},
  author       = {Qi, Haobo and Wang, Hansheng and Zhu, Xuening},
  doi          = {10.4310/22-SII752},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {159-172},
  shortjournal = {Stat. Interface},
  title        = {A random projection method for large-scale community detection},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Community detection in temporal citation network via a
tensor-based approach. <em>SII</em>, <em>17</em>(2), 145–158. (<a
href="https://doi.org/10.4310/22-SII751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, network analysis has attracted widespread attention. Detecting and tracking community evolution in temporal networks can uncover important and interesting behaviors. In this paper, we analyze a temporal citation network constructed by publications collected from 44 statistical journals between 2001 and 2018. We propose an approach named Tensor-based Directed Spectral Clustering On Ratios of Eigenvectors (TD-SCORE) which can correct for degree heterogeneity to detect the community structure of the temporal citation network. We first explore the characteristics of the temporal network via in-degree distribution and visualization of different snapshots, and we find that both the community structure and the key nodes change over time. Then, we apply the TD-SCORE method to the core network of our temporal citation network. Seven communities are identified, including variable selection, Bayesian analysis, functional data analysis, and many others. Finally, we track the evolution of the above communities and reach some conclusions.},
  archive      = {J_SII},
  author       = {Gao, Tianchen and Pan, Rui and Zhang, Junfei and Wang, Hansheng},
  doi          = {10.4310/22-SII751},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {145-158},
  shortjournal = {Stat. Interface},
  title        = {Community detection in temporal citation network via a tensor-based approach},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Special issue on statistical learning of tensor
data. <em>SII</em>, <em>17</em>(2), 143–144. (<a
href="https://intlpress.com/site/pub/pages/journals/items/sii/content/vols/0017/0002/f001/index.php">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SII},
  author       = {Hu, Guanyu and Wang, HaiYing and Wu, Jing and Zhang, Anru and Chen, Ming-Hui and Wang, Yuedong},
  journal      = {Statistics and Its Interface},
  number       = {2},
  pages        = {143-144},
  shortjournal = {Stat. Interface},
  title        = {Editorial: Special issue on statistical learning of tensor data},
  url          = {https://intlpress.com/site/pub/pages/journals/items/sii/content/vols/0017/0002/f001/index.php},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of nonparametric regression methods for
longitudinal data. <em>SII</em>, <em>17</em>(1), 127–142. (<a
href="https://doi.org/10.4310/23-SII801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Longitudinal data, which involve measuring a group of subjects repeatedly over time, frequently arise in many clinical and biomedical applications. To identify the complex patterns of change in the outcome and their association with covariates over time, a sufficiently flexible model is always required. Nonparametric regression, known for being data-adaptive and less restrictive than parametric approaches, becomes a promising tool for handling longitudinal data. This paper reviews various nonparametric regression methods for longitudinal data, including specific traditional nonparametric methods for the univariate case and several representative methods for the multivariate case, among which tree-based techniques are dominant. We summarize their motivations and provide a brief practical performance comparison of these methods in simulations, as well as discuss potential future research directions.},
  archive      = {J_SII},
  author       = {Yang, Changxin and Zhu, Zhongyi},
  doi          = {10.4310/23-SII801},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {127-142},
  shortjournal = {Stat. Interface},
  title        = {A review of nonparametric regression methods for longitudinal data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asymptotic properties of relative error estimation for
accelerated failure time model with divergent number of parameters.
<em>SII</em>, <em>17</em>(1), 107–125. (<a
href="https://doi.org/10.4310/23-SII816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper considers the problem of parameter estimation in the accelerated failure time model with divergent number of parameters under fixed design. We propose an estimator based on the general relative error criterion. We show that the proposed estimator is consistent and asymptotically normal under mild regular conditions. We also propose a variable selection procedure and show its oracle property as well as the consistency of model selection. Numerical studies have been conducted to compare the performance of different general relative error based estimators.},
  archive      = {J_SII},
  author       = {Ye, Fei and Zhou, Hongyi and Yang, Ying},
  doi          = {10.4310/23-SII816},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {107-125},
  shortjournal = {Stat. Interface},
  title        = {Asymptotic properties of relative error estimation for accelerated failure time model with divergent number of parameters},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Abnormal sample detection based on robust mahalanobis
distance estimation in adversarial machine learning. <em>SII</em>,
<em>17</em>(1), 91–106. (<a
href="https://doi.org/10.4310/23-SII818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of abnormal sample detection in deep learning-based computer vision, focusing on two types of abnormal samples: outlier samples and adversarial samples. The presence of these abnormal samples can significantly degrade the performance and robustness of deep learning models, posing security risks in critical areas. To address this, we propose a method that combines robust Mahalanobis distance (RMD) estimation with a pretrained convolutional neural networks (CNNs) model. The RMD estimation involves using minimum covariance matrix determinant (MCD), $T$-type, and $S$ estimators. Furthermore, we theoretically analyze the breakdown point and influence function of the $T$-type estimator. To evaluate the effectiveness and robustness of our method, we utilize public datasets, CNN models, and adversarial sample generation algorithms commonly employed in the field. The experimental results demonstrate the effectiveness of our algorithm in detecting abnormal samples.},
  archive      = {J_SII},
  author       = {Tian, Wan and Zhang, Lingyue and Cui, Hengjian},
  doi          = {10.4310/23-SII818},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {91-106},
  shortjournal = {Stat. Interface},
  title        = {Abnormal sample detection based on robust mahalanobis distance estimation in adversarial machine learning},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Latent class proportional hazards regression with
heterogeneous survival data. <em>SII</em>, <em>17</em>(1), 79–90. (<a
href="https://doi.org/10.4310/23-SII785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous survival data are commonly present in chronic disease studies. Delineating meaningful disease subtypes directly linked to a survival outcome can generate useful scientific implications. In this work, we develop a latent class proportional hazards (PH) regression framework to address such an interest. We propose mixture proportional hazards modeling, which flexibly accommodates class-specific covariate effects while allowing for the baseline hazard function to vary across latent classes. Adapting the strategy of nonparametric maximum likelihood estimation, we derive an Expectation-Maximization (E‑M) algorithm to estimate the proposed model. We establish the theoretical properties of the resulting estimators. Extensive simulation studies are conducted, demonstrating satisfactory finite-sample performance of the proposed method as well as the predictive benefit from accounting for the heterogeneity across latent classes. We further illustrate the practical utility of the proposed method through an application to a mild cognitive impairment (MCI) cohort in the Uniform Data Set.},
  archive      = {J_SII},
  author       = {Fei, Teng and Hanfelt, John J. and Peng, Limin},
  doi          = {10.4310/23-SII785},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {79-90},
  shortjournal = {Stat. Interface},
  title        = {Latent class proportional hazards regression with heterogeneous survival data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A nonparametric concurrent regression model with
multivariate functional inputs. <em>SII</em>, <em>17</em>(1), 69–78. (<a
href="https://doi.org/10.4310/23-SII782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression models with functional responses and covariates have attracted extensive research. Nevertheless, there is no existing method for the situation where the functional covariates are bivariate functions with one of the variables in common with the response function. In this article, we propose a nonparametric function-on-function regression method. We construct model spaces using a Gaussian kernel function and smoothing spline ANOVA decomposition. We estimate the nonparametric function using penalized likelihood and study properties of the Gaussian kernel function and the convergence rate of the proposed estimation method. We evaluate the proposed methods using simulations and illustrate them using two real data examples.},
  archive      = {J_SII},
  author       = {Zhai, Yutong and Wang, Zhanfeng and Wang, Yuedong},
  doi          = {10.4310/23-SII782},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {69-78},
  shortjournal = {Stat. Interface},
  title        = {A nonparametric concurrent regression model with multivariate functional inputs},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aligning sample size calculations with estimands in clinical
trials with time-to-event outcomes. <em>SII</em>, <em>17</em>(1), 63–68.
(<a href="https://doi.org/10.4310/23-SII804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ICH E9(R1) guidance recommended a framework to align planning, design, conduct, analysis, and interpretation of any clincial trial with its objective and estimand. How to handle intercurrent events (ICEs) is one of the five attributes of an estimand and sample size calculation is a key step in the trial planning and design. Therefore, sample size calculation should be aligned with the estimand and, in particular, with how the ICEs are handled. ICH E9(R1) summarized five strategies for handling ICEs, and five approaches have been proposed in the literature for sample size calculation when planning trials with quantitative and binary outcomes. In this paper, we discuss how to apply the five strategies to deal with ICEs in clinical trials with time-to-event outcomes and propose five approaches for sample size calculation that are aligned with the five strategies, respectively.},
  archive      = {J_SII},
  author       = {Fang, Yixin and Jin, Man and Wu, Chengqing},
  doi          = {10.4310/23-SII804},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {63-68},
  shortjournal = {Stat. Interface},
  title        = {Aligning sample size calculations with estimands in clinical trials with time-to-event outcomes},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust and powerful gene-environment interaction tests using
rare genetic variants in case-control studies. <em>SII</em>,
<em>17</em>(1), 51–62. (<a
href="https://doi.org/10.4310/23-SII800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many association analysis methods have been developed to detect disease related rare genetic variants or gene-environment interactions. Most of them are based on prospectively likelihood, so they are robust but might not be powerful enough. On the other hand, retrospective likelihood based methods assuming gene-environment independence can effectively improve the association test power, but they suffer from type‑I error rate inflation if the independence assumption is violated. The aim of this paper is to develop novel test methods to balance power and robustness by appropriately weighting the above retrospective likelihood based tests and the existing prospective likelihood based tests. The desired finite sample performances of the proposed methods are demonstrated through simulation studies and the application to a real dataset.},
  archive      = {J_SII},
  author       = {Zhao, Yanan and Zhang, Hong},
  doi          = {10.4310/23-SII800},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {51-62},
  shortjournal = {Stat. Interface},
  title        = {Robust and powerful gene-environment interaction tests using rare genetic variants in case-control studies},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sieve maximum likelihood estimation for generalized linear
mixed models with an unknown link function. <em>SII</em>,
<em>17</em>(1), 39–49. (<a
href="https://doi.org/10.4310/23-SII813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the generalized linear mixed models with an unknown link function for correlated outcome data. We propose sieve maximum likelihood estimation procedures by using B‑splines. Specifically, we estimate the unknown link function in a sieve space spanned by the B‑spline basis of the linear predictor that includes both the fixed and random terms. We establish the consistency and asymptotic normality of the proposed sieve maximum likelihood estimators. Extensive simulation studies, along with an application to an epileptic study, are provided to evaluate the finite-sample performance of the proposed method.},
  archive      = {J_SII},
  author       = {Diao, Guoqing and Yuan, Mengdie},
  doi          = {10.4310/23-SII813},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {39-49},
  shortjournal = {Stat. Interface},
  title        = {Sieve maximum likelihood estimation for generalized linear mixed models with an unknown link function},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Copy number variation detection based on constraint least
squares. <em>SII</em>, <em>17</em>(1), 27–37. (<a
href="https://doi.org/10.4310/23-SII814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Copy number variations (CNVs) are a form of structural variation of a DNA sequence, including amplification and deletion of a particular DNA segment on chromosomes. Due to the huge amount of data in every DNA sequence, there is a great need for a computationally fast algorithm that accurately identifies CNVs. In this paper, we formulate the detection of CNVs as a constraint least squares problem and show that circular binary segmentation is a greedy approach to solving this problem. To solve this problem with high accuracy and efficiency, we first derived a necessary optimality condition for its solution based on the alternating minimization technique and then developed a computationally efficient algorithm named AMIAS. The performance of our method was tested on both simulated data and two realworld applications using genomic data from diagnosed primal glioblastoma and the HapMap project. Our proposed method has competitive performance in identifying CNVs with high-throughput genotypic data.},
  archive      = {J_SII},
  author       = {Wang, Xiaopu and Wang, Xueqin and Zhang, Aijun and Wen, Canhong},
  doi          = {10.4310/23-SII814},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {27-37},
  shortjournal = {Stat. Interface},
  title        = {Copy number variation detection based on constraint least squares},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Frequentist bayesian compound inference. <em>SII</em>,
<em>17</em>(1), 9–26. (<a
href="https://doi.org/10.4310/23-SII797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practice often either the Bayesian or frequentist method is used, although there are some combined uses of the two methods, a formal unified methodology of the two hasn’t been seen. Here we first give a brief review of the two methods and some combination of the two, then propose a procedure using both the frequentist likelihood and the Bayesian posterior loss in parameter estimation and hypothesis testing, as an attempt to unify the two methods. Basic properties of the proposed method are studied, and simulation studies are carried out to evaluate the performance of the method.},
  archive      = {J_SII},
  author       = {Xu, Jinfeng and Yuan, Ao},
  doi          = {10.4310/23-SII797},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {9-26},
  shortjournal = {Stat. Interface},
  title        = {Frequentist bayesian compound inference},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guiding light: An essay for professor lincheng zhao on the
occasion of his 80th birthday. <em>SII</em>, <em>17</em>(1), 3–8. (<a
href="https://doi.org/10.4310/22-SII772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lincheng Zhao was admitted to the Department of Applied Mathematics of the University of Science and Technology of China (USTC) in 1960, three years before me, and then took a year off due to illness and transferred to the entering class of 1961. We were both not good at socializing, so although we had been classmates for three years, we didn’t know each other. In 1978, when we were both admitted to the Department of Mathematics for graduate studies, we got to know each other. Since then, we have known each other, made friends, and helped each other in all aspects of research and life, and we have become good mentors and friends with each other. On the occasion of Professor Zhao’s 80th birthday, I would like to recall a little of the past events of our acquaintance and friendship to express my gratitude to Academic Elder Brother Zhao.},
  archive      = {J_SII},
  author       = {Bai, Zhidong},
  doi          = {10.4310/22-SII772},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {3-8},
  shortjournal = {Stat. Interface},
  title        = {Guiding light: An essay for professor lincheng zhao on the occasion of his 80th birthday},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Introduction. <em>SII</em>, <em>17</em>(1), 1–2. (<a
href="https://intlpress.com/site/pub/pages/journals/items/sii/content/vols/0017/0001/f001/index.php">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SII},
  author       = {Ma, Shuangge and Tong, Tiejun and Xu, Jinfeng and Zhang, Hong and Chen, Ming-Hui and Wang, Yuedong},
  journal      = {Statistics and Its Interface},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Stat. Interface},
  title        = {Introduction},
  url          = {https://intlpress.com/site/pub/pages/journals/items/sii/content/vols/0017/0001/f001/index.php},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
