<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FDATA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="fdata---95">FDATA - 95</h2>
<ul>
<li><details>
<summary>
(2024). Advancing cybersecurity and privacy with artificial
intelligence: Current trends and future research directions.
<em>FDATA</em>, <em>7</em>, 1497535. (<a
href="https://doi.org/10.3389/fdata.2024.1497535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Achuthan, Krishnashree and Ramanathan, Sasangan and Srinivas, Sethuraman and Raman, Raghu},
  doi          = {10.3389/fdata.2024.1497535},
  journal      = {Frontiers in Big Data},
  month        = {12},
  pages        = {1497535},
  shortjournal = {Front. Big Data},
  title        = {Advancing cybersecurity and privacy with artificial intelligence: Current trends and future research directions},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging compact convolutional transformers for enhanced
COVID-19 detection in chest x-rays: A grad-CAM visualization approach.
<em>FDATA</em>, <em>7</em>, 1489020. (<a
href="https://doi.org/10.3389/fdata.2024.1489020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of Deep Learning (DL) methodologies has significantly enhanced the field of medical Imaging, particularly in the interpretation of chest radiographs (CXRs). Among these advancements, Convolutional Neural Networks (CNNs) have emerged as a paramount technology for processing and Classifying CXR images and demonstrating exceptional proficiency in detecting COVID-19-related signs [1]. Although Reverse Transcription Polymerase Chain Reaction (RT-PCR) tests surpass CXRs in accuracy And reliability for virus detection, the latter remains an ubiquitous tool in clinical practice [2]. RT-PCR excels in early detection capabilities, enabling prompt treatment initiation, and uniquely identifies the virus in asymptomatic individuals through the analysis of: Saliva samples, throat samples, and nasal passage samples, demonstrating superior performance over CXR evaluations in these aspects.A recent investigation employed a Convolutional Neural Network (CNN) model to distinguish between:The CNN model, trained on an extensive dataset comprising images from:• Patients diagnosed with pneumonia • Those testing positive for COVID -19 Healthy subjects achieved a remarkable precision rate of 97.6% in identifying COVID-19 cases on chest radiographs (CXR). This exceptional level of precision surpasses that of traditional CXR diagnostic techniques, demonstrating the potential of deep learning algorithms to improve diagnostic accuracy [3]. In the current healthcare landscape, the surge in demand for intensive care units (ICUs) has exposed the capacity constraints of healthcare systems in several developed countries. The influx of patients suffering from COVID-19-induced pneumonia into the ICU underscores this pressing challenge, highlighting the need for effective diagnostic tools and strategies to manage the burden on healthcare resources [4].The system employs relational feature intelligence to analyze and interpret the interactions among various elements within an image, enabling the assessment of:• Spatial relationships • Dynamics between different components This capability facilitates the evaluation of:• Tumor-tissue interactions• Inter-organ relationships (e.g., heart-lung interactions) which is crucial for diagnosing conditions like:• Heart failure• Pulmonary embolismThe relational feature intelligence of the system enables the analysis of complex interactions within medical images, providing valuable information on spatial relationships and dynamics between different elements [5] [6] [7]. This capability is particularly beneficial in:• Oncology (accurate diagnosis and treatment planning)• Cardiovascular and pulmonary diseases (diagnosing conditions like heart failure and pulmonary embolism)As depicted in Figure 1, the radiographic features characteristics of COVID-19 typically encompass:• Bilateral and lower-zone dominant ground-glass opacities (GGOs)• Consolidations, predominantly peripheral in distribution • Interlobular septal thickening • Pleural effusionsIn contrast, viral pneumonia caused by non-SARS-CoV-2 viruses, such as influenza-A, tends to exhibit:• Unilateral, central, and upper-zone dominant GGOs and consolidations Using these distinctions, medical experts advocate the concurrent use of:• Chest radiography• Nucleic acid amplification tests as a primary diagnostic strategy for early identification of this novel pneumonia strain. The primary objective of this examination is to detect the presence of the virus within a patient, which is achieved through the analysis of specific biomarkers [8]. To augment this assessment, medical practitioners often employ a multimodal diagnostic approach, incorporating additional methodologies such as:• Antibody tests • Antigen tests • Radiographic analysis via chest X-rays to verify infection and facilitate accurate diagnosis. However, it is crucial to acknowledge that these supplementary tests may not always yield precise outcomes, highlighting the necessity for their combined application with other diagnostic techniques to ensure a definitive diagnosis [9] [10].A significant limitation of this specific examination is the considerable:• Processing time • Expenses associated with its execution, which may hinder its applicability in resource-constrained settings.To minimize diagnostic errors, healthcare professionals are advised to utilize automated imaging analysis software, powered by artificial intelligence (AI), when interpreting X-ray photographs. These advanced tools excel at identifying complex patterns within images, thereby improving diagnostic accuracy. Additionally, to maintain a high level of diagnostic precision, medical staff should take periodic breaks to avoid fatigue and seek second opinions from colleagues to ensure reliability and accuracy. Innovations in diagnostic methodologies, such as the integration of AI and machine learning (ML) technologies, can significantly reduce both the time and financial costs associated with diagnostic processes, enhancing efficiency and reliability. Specifically, AI and ML can accelerate and refine disease diagnosis by analyzing medical data. In addition, digital biomarkers, such as data from wearable technologies, offer real-time information, enabling the early detection and monitoring of various health conditions. The synergy of ML and AI has facilitated the development of sophisticated algorithms capable of detecting and diagnosing diseases with remarkable precision. These advancements have transformed the diagnostic landscape, enabling healthcare professionals to make more accurate and timely diagnoses [11]. Artificial intelligence (AI)-empowered systems can efficiently process vast datasets, enhancing the capacity for early disease detection and the formulation of customized treatment plans. The advent of telemedicine and remote monitoring tools enables healthcare practitioners to oversee patient health remotely, providing timely interventions when necessary. This approach has been particularly advantageous during the pandemic. Pre-trained models can address complex issues with speed and accuracy, offering a significant advantage in medical diagnostics. Leveraging pre-trained models reduces the time and resources required for training a model from scratch, while enhancing precision. These models facilitate knowledge transfer across different domains, enabling more efficient and accurate solutions. The Grad-CAM algorithm serves as a visualization tool, elucidating the decision-making process of convolutional neural networks (CNNs). By utilizing gradients pertaining to a selected target class, Grad-CAM generates a localization map highlighting pivotal areas within an image critical for identifying a specific concept. This study introduces a comprehensive transfer model for synchronous COVID-19 detection and visualization of affected areas using X-ray imaging [12]. Unlike prior research, our work focuses on COVID-19 detection via X-ray images. Given the pressure on healthcare systems, it is crucial to leverage every available resource efficiently. Integrating the Grad-Cam localization feature aids in identifying COVID-19 and assessing severity, assisting in determining whether immediate healthcare intervention is needed. [13] In our investigation, we leveraged a diverse range of pretrained models for the classification task, including:• ResNet34 • ResNet50 • EfficientNet-B4 • EfficientNet-B5 architecturesThe incorporation of Grad-CAM into our methodology enabled the precise identification of affected regions, with the EfficientNet architecture being utilized for its exceptional:• Efficiency • EffectivenessThe utilization of pre-trained models offers significant advantages, primarily due to their pre-learned weights, which make them exceptionally valuable even when working with limited datasets. This constitutes the primary benefit of integrating pre-trained models into our investigative approach. Additionally, the employment of pretrained models reduces the: In this study, we leveraged publicly accessible datasets of X-ray images as the primary experimental medium. The architecture of our experiment is designed as an end-to-end system, eliminating the need for manual feature extraction or selection, thereby streamlining the process for enhanced efficiency and effectiveness. We employed the Grad-CAM technique in conjunction with a Convolutional Neural Network (CNN) model to improve the diagnostic accuracy of our system. The integration of Grad-CAM enables the visualization of feature importance, allowing us to identify the most relevant regions in the X-ray images for diagnostic decision-making. By utilizing this approach, we aimed to develop a robust and accurate diagnostic system, capable of automatically detecting and localizing abnormalities in X-ray images, thereby assisting clinicians in making informed decisions.The core of our methodological approach integrates the Gradient-weighted Class Activation Mapping (Grad-CAM) technique with Convolutional Neural Network (CNN) architectures, aiming to refine diagnostic precision through the following formulation:□□ □□□□□□□□-□□□□□□ = □□□□□□□□(∑ □□ □□ □□ □□ □□ □□ )(1)whereLGrad-CAM represents the localization map highlighting regions of interest, □□ □□ □□ denotes the weights for the k-th feature map A k contributing to a target class c, and ReLU ensures the activation map focuses on features positively influencing the class prediction.For classification purposes, we employed a selection of pre-trained models:• ResNet34 and ResNet50, • EfficientNet-B4 and EfficientNet-B5, fine-tuned to adapt their learned representations to our specific task. This process exploits the models&amp;#39; preexisting knowledge, significantly economizing on computational resources and training time The Grad-CAM heatmap is computed using the equation: L Grad-CAM = ReLU(∑ k a k e A k ). This equation is crucial in visualizing the regions of the input image that significantly influence the model&amp;#39;s decision-making process. In our study, we utilize the feature maps A k from the last convolutional layer of the CNN and importance weights a k e derived from the gradients of the predicted class score with respect to A k . These weights represent the contribution of each feature map to the prediction. The ReLU function ensures that only positive contributions are considered, highlighting the most relevant regions for class prediction. This equation enables the generation of Grad-CAM heatmaps, which are overlaid on original chest X-rays to help clinicians identify critical regions that influence the model&amp;#39;s classification.Our investigation scrutinizes the influence of the characteristics of the data set and image processing techniques on the precision of disease detection. This entails a dual analysis approach: Dataset Analysis:∆ □□□□□□□□□□□□□□□□ = □□(□□□□□□□□□□□□□□ □□□□□□□□□□□□□□ , □□□□□□□□□□ □□□□ℎ□□□□□□□□□□□□□□□□ ) (2)where ∆accuracy measures the change in diagnostic accuracy as a function of dataset balance and image enhancement techniques.The employment of image enhancement, particularly for X-ray and CT-Scan images, was operationalized through the application of Contrast Limited Adaptive Histogram Equalization (CLAHE), aiming to ameliorate image quality for more accurate diagnostic interpretation.When selecting models for this research, several factors were considered to ensure the best choices for the task at hand. First, computational feasibility was evaluated. While models like DenseNet and Inception are powerful, they require significant computational resources without offering substantial accuracy improvements over other options. So, more efficient architectures that strike a balance between performance and computational demands were selected. The selected models are known for their ability to adapt well to different datasets, which is crucial given the variations in chest X-ray imaging conditions. By considering these factors, the research offers the best combination of accuracy, efficiency, and generalizability.To evaluate the model&amp;#39;s robustness, sensitivity analyses were performed on key hyperparameters.A significant performance drop was observed when the learning rate deviated from the optimal value of 10^-3, highlighting its crucial role in convergence. To address this, a learning rate scheduler was employed to dynamically adjust the learning rate upon validation loss plateauing.Increasing the batch size to 64 negatively impacted performance due to poorer gradient estimates on limited GPU memory. Conversely, smaller batch sizes increased training time.Dropout rates below 0.2 led to overfitting, characterized by high training accuracy but low validation accuracy. In contrast, dropout rates above 0.5 hindered the learning process.The Adam optimizer demonstrated robustness for the dataset used in this study, showing less sensitivity to small learning rate changes compared to SGD The collaborative efforts of Eduardo A. Soares, Plamen P. Angelov, and Sarah Biaso have culminated in a significant contribution to the field of medical imaging for infectious diseases. They have developed and made publicly available a comprehensive dataset of CT scans specific to SARS-CoV-2, enabling the advancement of diagnostic capabilities.The team crafted an innovative algorithm, meticulously training it on CT scans from both:• Confirmed SARS-CoV-2 positive patients • Patients without the infection This training phase was followed by a rigorous testing phase, where the algorithm&amp;#39;s efficacy was validated on a distinct dataset encompassing CT scans from individuals with and without SARS-CoV-2 infection.The outcomes of this testing phase demonstrated the algorithm&amp;#39;s precision in accurately detecting SARS-CoV-2 infection, highlighting its potential utility in enhancing diagnostic processes within clinical settings. This contribution has the potential to significantly impact the field of medical imaging for infectious diseases, improving patient outcomes and streamlining diagnostic procedures [14]. In a groundbreaking study, Sara Haseli and Nastaran Khalili have significantly advanced our understanding of COVID-19 pneumonia through comprehensive radiological analysis of chest CT imaging. Their research elucidated distinct hallmark features characteristic of the condition, including:• Bilateral ground-glass opacities • Consolidation • Interlobular septal thickeningThese findings align with established diagnostic criteria for COVID-19 pneumonia, providing critical insights into the disease&amp;#39;s pulmonary manifestations. Furthermore, their investigation revealed additional complications in a subset of patients, including:• Pleural effusions • Lymphadenopathy • Pulmonary embolismThese findings broaden our understanding of the disease&amp;#39;s impact on pulmonary structures, underscoring the importance of vigilant radiological monitoring and timely diagnosis [15]. In terms of pulmonary involvement, the posterior segment of the left lower lobe (LLL) was identified as the most frequently affected segment, exhibiting a high propensity for involvement. Additionally, significant instances of involvement were observed in the right middle lobe (RML) and the right lower lobe (RLL), suggesting a bilateral distribution of pulmonary affliction. Upon analyzing the data based on lobar distribution, the LLL exhibited the highest frequency of affliction, with the RLL and RML closely following in prevalence, indicating a relatively even distribution of pulmonary involvement across the lobes [16]. Upon examining the demographics of age and gender in relation to chest CT imaging outcomes, a notable pattern emerged, suggesting a gender-specific predilection for lobar involvement. Male patients exhibited a significant propensity for left lower lobe (LLL) involvement, whereas female patients demonstrated a tendency towards more frequent involvement of the right lower lobe (RLL). Further analysis revealed a distinct age-related pattern, with the left lower lobe (LLL) being predominantly affected in the older population ( 65 years). In contrast, the right lower lobe (RLL) showed a higher incidence of involvement among younger individuals (&amp;lt; 65 years). These findings suggest that age and gender may play a role in determining the lobar distribution of pulmonary involvement [17].Shuai Wang and colleagues developed a cutting-edge algorithm for the detection of COVID-19 pneumonia via chest CT image analysis, leveraging an adapted Inception transfer-learning framework. The algorithm&amp;#39;s performance was rigorously validated through both internal and external validation processes, demonstrating its efficacy in identifying COVID-19 pneumonia with a high degree of accuracy [18].In their investigative study, Ali Narin and Ceren Kaya put forward three models grounded in convolutional neural network technologyaˆ C&amp;quot;ResNet50, InceptionV3, and InceptionResNetV2aˆ C&amp;quot;for the purpose of identifying coronavirus pneumonia from chest X-ray images. These models underwent rigorous evaluation on a dataset that included both confirmed COVID-19 cases and cases of conventional viral pneumonia, demonstrating the application of advanced deep learning techniques in the differentiation and diagnosis of respiratory illnesses [19][20] [21]. In a pioneering approach, the developed system leveraged a hybrid architecture, synergistically integrating a Long Short-Term Memory (LSTM) classifier with a Convolutional Neural Network (CNN) dedicated to feature extraction and selection. The system&amp;#39;s performance was rigorously evaluated using a dataset comprising 421 cases, including 141 instances with features indicative of COVID-19. Following the completion of its training phase, the model demonstrated exceptional performance capabilities, adeptly categorizing images as either COVID-19 positive or negative. The evaluation of the model&amp;#39;s efficacy involved the application of 10fold cross-validation, yielding an impressive accuracy rate of 97.3%. This remarkable achievement underscores the system&amp;#39;s potential in medical imaging analysis, showcasing its ability to accurately classify images and support diagnostic decision-making [23][24] [25]. Extensive validation was conducted on an independent dataset of chest X-ray images, where the proposed model achieved an exceptional accuracy of 97.7%. This remarkable performance demonstrates the model&amp;#39;s precision in distinguishing COVID-19 cases, showcasing its potential in medical imaging analysis. The utilized dataset comprised 88 confirmed instances of COVID-19, 101 cases of bacterial pneumonia, and 86 instances classified as normal based on CT scan analyses. Comparative assessments were conducted to evaluate the model&amp;#39;s performance relative to traditional frameworks, including Res-Net, Dense-Net, and VGG16. The results underscore the proposed model&amp;#39;s enhanced performance, demonstrating its effectiveness through rigorous analysis [26][27] [28].This study combines bone suppression and lung segmentation with multi-modal classification to improve COVID-19 detection accuracy. By isolating lung regions, the model reduces noise from surrounding structures, enhancing diagnostic performance. This approach refines lung images, contributing to more accurate identification of COVID-19 in chest X-rays [31] [32].This comparative study investigates various linear multiple instance learning (MIL) models applied to COVID-19 detection in chest X-rays. Analysing how linear MIL models handle weakly labelled data, the study identifies effective techniques for classifying X-ray images without extensive manual annotations. The findings reveal that certain MIL techniques can efficiently pinpoint COVID-19 indicators, making them suitable for large-scale screenings [33] [34].CNN-based methods have shown significant promise in detecting COVID-19 from X-ray images. This research explores CNN architectures designed for medical image analysis, fine-tuned to identify COVID-19&amp;#39;s unique patterns in X-rays. Using convolutional layers that capture spatial features, CNNs offer high sensitivity in recognizing infection signs, allowing for robust classification [35] [36].Beyond deep learning, various machine learning algorithms have been applied to COVID-19 classification in chest X-rays. These techniques include support vector machines (SVMs), decision trees, and ensemble methods. The study highlights the effectiveness of these algorithms in scenarios with limited data, where traditional machine learning methods can outperform deep learning models by leveraging feature extraction and selection methods. These studies demonstrate the potential of AI techniques in enhancing COVID-19 detection accuracy using chest X-rays. Each approach offers unique strengths, and their combination could lead to more effective diagnosis and treatment [37] [38].While our dataset provides a substantial amount of data for training and evaluating our model, it&amp;#39;s important to acknowledge its limitations. The dataset may not fully capture the diversity of COVID-19 cases seen across different populations and imaging conditions, which could impact the generalizability of our model&amp;#39;s predictions in real-world clinical settings. For instance, variations in demographics, geographic regions, and imaging equipment could affect the robustness of our model, particularly when applied to data from populations or conditions not represented in the training dataset. To address this limitation, future work should consider incorporating datasets from a broader range of demographics and imaging environments. This would enhance our model&amp;#39;s adaptability and effectiveness in diverse healthcare contexts, ensuring that it can provide accurate predictions for a wide range of patients and scenarios. By expanding our dataset in this way, we can increase the confidence in our model&amp;#39;s performance and its potential to improve patient outcomes in real-world clinical settings.The diagnosis of COVID-19 in this study is conducted through the analysis of pulmonary (chest) X-ray images. The dataset is categorized into three primary classes:• COVID- The allocation of the dataset for various purposes is segmented as follows:- *• Evaluation: 30% of the total dataset •While convolutional layers are responsible for extracting hierarchical features, fully connected layers serve as classifiers, mapping the learned features to output classes through matrix multiplication. These layers interpret the high-level features extracted by the convolutional layers, with the aim of accurately classifying the input data.Pooling layers are designed to reduce the spatial dimensions of the input data, thereby condensing the information and retaining the most salient features. A common pooling operation is max pooling, mathematically represented as:□□ = max □□ □□,□□ □□, □□ ∈ □□ (4)where □□ is the output of the pooling operation over a region R, and □□ □□,□□ are the input features within the pooling window. This operation effectively downsamples the input while preserving the most significant activations.The dimensions of the output feature map are determined by the stride and filter size used during the convolutional operation, as described by the following equation:□□□□□□□□□□□□_□□□□□□□□ = 1 + □□□□□□□□□□_□□□□□□□□-□□□□□□□□□□□□_□□□□□□□□ □□□□□□□□□□□□(5)The equation Output_size = 1 + (Input_size -Filter_size) / Stride is a fundamental concept in convolutional operations, determining the dimensions of the output feature map after applying a convolution operation to an input image. In our study, this equation plays a crucial role in designing and understanding the architecture of CNN models. The input size, filter size, and stride are critical parameters that affect the dimensionality reduction and feature extraction capabilities of the network. By using this equation, we can ensure that the network architecture is compatible with the input image dimensions and optimize computational efficiency. This equation is essential for understanding how CNN models process visual data and make predictions, as illustrated in Figure 4. Residual Networks (ResNets) introduce an innovative architecture in deep learning designed to effectively mitigate the vanishing gradient problem, a significant challenge in training deep neural networks. As the network depth increases, the gradients often become exceedingly small, rendering weight updates ineffective and hindering the network&amp;#39;s ability to learn and converge. ResNets address this issue through the use of skip connections, a key architectural feature that facilitates better gradient flow.The skip connections, also known as residual connections, provide an alternative pathway for gradients to propagate, thereby bypassing one or more layers. The fundamental concept of ResNets can be mathematically expressed as:□□ = □□(□□, {□□ □□ }) + □□(6)In this equation, x represents the input to a layer, □□(□□, {□□ □□ }) denotes the residual function to be learned by the network, and y is the output of the layer. The inclusion of the term x allows the network to skip certain layers, ensuring that the gradient can be propagated directly back through the network without significant reduction in magnitude. This mechanism is crucial for maintaining the effectiveness of gradient-based learning in deep networks, as depicted in Figure 5.The introduction of ResNets has significantly impacted various domains within deep learning, including but not limited to image recognition, object detection, and natural language processing. Furthermore, their application extends to medical imaging, where they facilitate tasks such as tumor detection and segmentation.The EfficientNet architecture introduces a holistic optimization strategy that synergistically combines advanced convolutional techniques with squeeze-and-excitation modules. Its primary objective is to enhance model efficiency and accuracy without incurring a proportional increase in computational demands, thereby achieving a optimal tradeoff between performance and computational resources. The core of Efficient Net&amp;#39;s design philosophy lies in the compound scaling method which achieves a balanced scaling of the network&amp;#39;s dimensions depth, width, and resolution. This approach is mathematically formalized as:depth : d = α ϕ , width : w = β ϕ ,resolution : r = γ ϕ , subject to α•β 2 •γ 2 ≈ 2 and α•β •γ ≈ 1 (7)Where ϕ is a user-defined coefficient that determines the scaling of the model based on the available computational resources. The constants α, β, and γ defines the specific scaling factors for each dimensions depth, width, and resolution, respectively. The constraints ensure a balanced scaling across these dimensions, optimizing the model&amp;#39;s performance while maintaining computational efficiency.The compound scaling formula is a crucial component of EfficientNet, balancing image resolution, network depth, and width scaling factors to optimize model accuracy and efficiency. Unlike traditional scaling methods, compound scaling ensures a proportional and systematic scaling across all three dimensions, resulting in a better-performing model without unnecessary computational costs.EfficientNet&amp;#39;s compound scaling method optimizes the balance between model accuracy and efficiency. The input image resolution is scaled to 224x224 pixels to capture finer details without overwhelming computational resources.To further optimize performance, EfficientNet incorporates an efficient convolutional block alongside the mobile inverted bottleneck (MBConv) block. The MBConv block, a pivotal component, enhances model efficiency through an inverted residual structure shown in Figure 6. The integration of transformer encoders into CNN-based classification algorithms marks a significant advancement in machine learning, enhancing model capabilities by effectively leveraging transfer learning principles. In the initial training phase, a CNN model is trained on a specific dataset, resulting in a set of learned weights. These weights enable the model to classify features similar to those encountered during training. The process of transfer learning can be mathematically represented as:□□ ′ = □□(□□, □□ □□□□□□ )(8)where W ′ represents the adapted weights post-transfer learning, W denotes the original pre-trained weights, and Dnew is the new dataset. By incorporating transformer encoders, the model&amp;#39;s ability to generalize and apply learned patterns to novel datasets is significantly enhanced. This process can be formalized as:□□ □□□□□□□□□□□□□□□□□□□□□□ = □□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□□(□□ □□□□□□□□□□ )(9)where Einput denotes the input embeddings fed into the transformer encoder, and Etransformed represents the output embeddings, now enriched with contextual information through the encoder&amp;#39;s processing. The synergistic integration of Convolutional Vision Transformers (CVT) and Convolutional Channel Transformers (CCT) represents a groundbreaking approach in object recognition, harnessing the complementary strengths of Convolutional Neural Networks (CNNs) and transformers to process images with enhanced efficacy. This innovative methodology enables a comprehensive and holistic analysis of images, significantly improving the model&amp;#39;s efficiency and deployment capability. The remarkable performance of this approach is particularly evident in the classification of COVID-19 images, as illustrated in Figure 8 and 9 respectively. By combining the spatial hierarchies of CNNs with the self-attention mechanisms of transformers, CVT and CCT facilitate a more detailed and nuanced understanding of image features, leading to improved recognition accuracy and robustness. This integrated approach demonstrates a significant advancement in computer vision, enabling more effective and efficient image analysis in various applications, including medical imaging and disease. The categorical cross-entropy loss function is used for multi-class classification problems. It measures the divergence between predicted and true class probabilities, penalizing predictions based on their confidence in the correct class. Regularization techniques, such as L2 regularization and dropout regularization, are applied to prevent overfitting and improve generalization. The loss function is directly tied to the SoftMax activation function in the output layer, ensuring predicted probabilities sum to 1 across all classes as shown in Equation 10.L_Weighted CCE = -(1/N) * ∑(i=1 to N) ∑(c=1 to C) w_c * y_i,c * log(y_i,c)(10)The metrics are defined as follows, where TP represents true positives, TN denotes true negatives, FP stands for false positives, and FN signifies false negatives:Accuracy measures the proportion of true results (both true positives and true negatives) in the total number of cases examined. Precision assesses the proportion of positive identifications that were actually correct.(15)The F1-Score is the harmonic mean of Precision and Recall, providing a balance between the two.□□1 -□□□□□□□□□□ = 2 &amp;#215; ( □□□□□□□□□□□□□□□□ &amp;#215;□□□□□□□□□□□□ □□□□□□□□□□□□□□□□+□□□□□□□□□□□□ ) (16)The primary objective of this experiment was to evaluate the performance of classification models on a dataset of X-ray images, encompassing categories such as standard, lung opacity, pneumonia, and COVID-19 cases. To ensure optimal model training and evaluation, data enhancement and balancing techniques were applied, as illustrated in Tables 1 and2.To ensure fair and reliable model predictions, techniques were applied to address class imbalance in the dataset, which could otherwise bias the model toward overrepresented classes. Methods such as class weighting and oversampling were employed to balance the distribution among the COVID-19, pneumonia, and normal classes. Class weighting adjusted the loss function to give higher importance to minority classes, while oversampling involved duplicating samples from underrepresented classes to create a more balanced dataset. These approaches aimed to reduce bias and improve the model&amp;#39;s ability to accurately classify images across all categories, enhancing its reliability and robustness in clinical applications.The first step in the experimental process involved the enhancement of X-ray images using the Contrast Limited Adaptive Histogram Equalization (CLAHE) technique, mathematically represented as:□□ □□□□ℎ□□□□□□□□ = □□□□□□□□□□(□□ □□□□□□□□□□□□□□□□ ) (17)where Ioriginal is the original X-ray image, and Ienhanced is the result after applying CLAHE.The images were resized to a uniform resolution of 224 &amp;#215; 224 pixels. This standardization is critical for compatibility with the input size requirements of the employed neural network architectures (e.g., EfficientNet,To increase the variability of the dataset and reduce overfitting, the following augmentation techniques were applied during training: Random Rotations: Introduced angular variations to simulate different orientations.Horizontal and Vertical Flipping: Created mirror-like reflections to enhance diversity. Random Cropping and Zooming: Enabled the model to focus on varying regions of the image. Brightness Adjustments: Improved robustness by simulating different lighting conditions. Noise Reduction: Basic noise reduction filters were applied to remove potential artifacts in the X-ray images, which could otherwise interfere with the feature extraction process.While CLAHE specifically focuses on improving local contrast, global histogram equalization was also used as an optional step during exploratory stages to further analyze its impact on image clarity.The dataset was systematically divided into three distinct subsets to facilitate the classification task: training, testing, and validation. The data distribution was as follows:Training Set: 70%Testing Set: 20%Validation Set: 10%To ensure fairness in model evaluation, the dataset was balanced, equalizing the number of images across classes. This was quantitatively managed as:□□ □□□□□□□□□□ = □□□□□□□□□□□□□□□□ , ∀ □□□□□□□□□□□□□□(18)where Nclass denotes the number of images in each class.Four models were trained using distinct versions of the dataset:• Original Dataset The initial phase of our image data pre-processing involved two critical steps: image enhancement using CLAHE and subsequent data augmentation. This comprehensive approach was designed to improve the quality and variability of the dataset, thereby aiding in the robustness of the subsequent classification models. To boost the quality of input images and enhance model accuracy, a technique called Contrast Limited Adaptive Histogram Equalization (CLAHE) was used to refine each image. This step improves contrast and highlights important features within X-ray images, leading to more accurate predictions. Additionally, image resolution standardization was performed to ensure consistent image sizes, making the model adaptable to various image sources and minimizing potential variability from different imaging devices. These preprocessing steps lead to a more robust model that can generalize across diverse imaging conditions, ensuring reliable performance in realworld applications.Contrast Limited Adaptive Histogram Equalization (CLAHE) was employed to enhance the visual clarity of the images. This technique is mathematically represented as:□□ □□□□ℎ□□□□□□□□□□=□□□□□□□□□□ (□□ □□□□□□□□□□□□□□□□ )(19)where Ioriginal denotes the original image, and Ienhanced represents the image after contrast enhancement.Figure 10 illustrates the effect of CLAHE on an example image from the dataset. Following the enhancement, data augmentation techniques were applied to increase the diversity of the dataset, crucial for training more generalized models. The augmentation process involved transformations such as rotations, translations, and flipping. Subsequent to the enhancement, data augmentation techniques were employed to increase the diversity of the dataset, a crucial step in training more generalized models. The augmentation process included a range of transformations, such as:Rotations: Random angular transformations to simulate varying orientations.• Translations: Random spatial transformations to simulate different positions.• Flipping: Horizontal and vertical flipping to simulate mirror-like reflections These transformations enabled the generation of a more comprehensive and diverse dataset, thereby enhancing the model&amp;#39;s ability to generalize across various scenarios and improving its robustness in The datasets were subjected to preprocessing using Contrast Limited Adaptive Histogram Equalization (CLAHE), followed by division into two distinct sets: the original set and the balanced set, with and without additional enhancement. A comprehensive evaluation of various models was conducted on these datasets, assessing their performance based on accuracy and loss metrics across three phases:• Training phase: Model training and optimization.• Testing phase: Model evaluation on unseen data.• Validation phase: Model validation and hyper parameter tuning.This rigorous evaluation framework enabled a thorough analysis of model performance, facilitating the identification of optimal models and hyper parameters for the task at hand.Each model was trained over 10 epochs using a batch size of 8. The following equation represents the general form of the loss function minimized during training: (20) where N is the number of samples, M is the number of classes, yij is the binary indicator of class j for sample i, and pij(θ) is the predicted probability of sample i being in class j, with model parameters θ.□□(□□) = -1 N ∑ ∑ y ij log (p ij (□□)) M j=1 N i=1To prevent overfitting and enhance the model&amp;#39;s generalizability, several techniques were employed during training. First, cross-validation was used to ensure robust model evaluation across different data splits, which helped identify any potential overfitting to specific subsets. Additionally, data augmentation techniques such as random rotations, translations, and flips were applied to increase dataset variability and reduce the model&amp;#39;s reliance on specific image features. Dropout layers were also incorporated within the model architecture prevent neurons from co-adapting too strongly, which often leads to overfitting. Despite these measures, validating the model on external datasets is crucial to further assess its adaptability and effectiveness across varied real-world settings and populations. This will be a key focus of future work, as it is essential to ensure that the model can generalize well to new, unseen data and provide accurate predictions for a diverse range of patients and scenarios.The models evaluated included Xception, InceptionV3, and InceptionResNetV2. The performance metrics revealed variations in accuracy and loss across the datasets: The DataLoader class, integral to our process, dynamically assigns classifications for each dataset, preparing them for submission to the network with appropriately set dimensions and normalization. Utilizing pretrained weights from the ImageNet dataset, the neural network configuration is defined, including the number of classes and layers requiring enhancements. Each model integrates a classifier head, concluding with a ReLU function, to process the logits for each class output by the final linear layer.Training involves selecting Cross-Entropy Loss as the loss function, Adam for optimization, and a step function for learning rate scheduling. The protocol entails training for N epochs, initially modifying only the final layer weights for the first K epochs, then adjusting the entire network&amp;#39;s weights for the remaining N-K epochs. For CCT models, all weights are trainable from the outset. Model performance on the validation set dictates the saving of the best model at each epoch. Table 5 summarizes each model&amp;#39;s accuracy metrics across the training, testing, and validation phases. We list the results for each model accuracy on the test augmented train, and validation datasets which are shown in Table 6. Model Performance Metrics under CLAHE and BALANCED Datasets shown in Table 7. The performance of various models was analyzed using both original, unbalanced datasets and additional, varied datasets to understand each model&amp;#39;s generalizability and tendency towards overfitting. The mathematical representation of model accuracy, α, is defined as the ratio of correctly predicted observations, □□ □□ , to the total observations, □□ □□ .□□ = □□ □□ □□ □□(21)Overfitting is quantitatively assessed by comparing training accuracy, αtrain, and validation accuracy, αval, where a significant discrepancy indicates potential overfitting:□□□□□□□□□□□□□□□□□□□□□□ □□□□□□□□□□□□□□□□□□ = □□ □□□□□□□□□□ -□□ □□□□□□(22)To put our model&amp;#39;s performance into perspective, we compared it to other state-of-the-art models in COVID-19 detection using chest X-ray images. The results are summarized in Table X, which shows key performance metrics like accuracy, precision, recall, and F1-score for each model. This comparison highlights the strengths of our approach and demonstrates its effectiveness in detecting COVID-19 from chest X-rays. By benchmarking our model against others in the field, we can see how it stacks up against the current state of the art. This comparison is essential for understanding the advancements in COVID-19 detection and how our model contributes to the ongoing efforts. Our goal is to provide a comprehensive view of the current landscape in COVID-19 detection using chest X-ray images and demonstrate the value of our approach in this critical area of research. Analysis revealed that MobileNet yielded the highest accuracy for the original, unbalanced dataset. Conversely, VGG16 demonstrated superior performance across all other datasets but exhibited clear signs of overfitting on the original, unbalanced dataset, as highlighted by its performance metrics.The differential performance of MobileNet and VGG16 underscores the importance of selecting appropriate models based on dataset characteristics. The observed overfitting of VGG16 on the unbalanced dataset emphasizes the need for careful model evaluation and dataset preprocessing and the heatmap generation is shown in Figure 12. Disease localization in medical images is a critical step in diagnostic processes. The application of Grad-CAM to models trained on various datasets elucidates the relationship between training data quality, model accuracy, image resolution, and localization precision. Grad-CAM uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions for predicting the concept. Mathematically, it can be represented as□□ □□□□□□□□-□□□□□□ □□ = □□□□□□□□(∑ □□ □□ □□ □□ □□ □□ )(23)Where □□ □□□□□□□□-□□□□□□ □□ is is the localization map for class c, α k c are the weights for feature map k , □□ □□ is the activation of k-th feature map, ReLU is applied to focus on features that have positive influence on the class of interest. Results The application of Grad-CAM on models trained with initial and enhanced 478 datasets revealed that models trained on initial data more accurately highlighted disease-affected areas. This accuracy in localization is directly proportional to the model&amp;#39;s overall accuracy and the image resolution, described as:□□□□□□□□□□□□□□□□□□□□□□□□ □□□□□□□□□□□□□□□□□□ ∝ □□□□□□□□□□ □□□□□□□□□□□□□□□□ &amp;#215; □□□□□□□□□□ □□□□□□□□□□□□□□□□□□□□(24)emphasizing the compounded effect of higher accuracy and better resolution on precise disease localization. Our findings underscore the importance of image quality and model accuracy for effective disease localization using Grad-CAM. The study advocates for the optimization of these factors to improve diagnostic efficiency in medical imaging as shown in Figure 13 and Figure 14.While Grad-CAM provides valuable insights into the decision-making process behind COVID-19 predictions, deep learning models are often criticized for their lack of transparency. This &amp;quot;black box&amp;quot; nature can be a significant barrier for clinical adoption, as clinicians may struggle to understand the reasoning behind model predictions. To address this, future work could explore combining Grad-CAM with other explainability techniques, such as LIME or SHAP. These methods offer unique perspectives on model behavior, providing clinicians with a more comprehensive understanding of prediction rationales. By shedding light on the decisionmaking process, we can increase trust and usability in medical settings. The advent of deep learning in medical imaging has facilitated the development of automated diagnostic tools. This paper presents an evaluation of transfer learning models, specifically EfficientNet and MobileNet, in the classification of chest X-ray images. Transfer learning models were trained on a comprehensive dataset comprising images categorized as COVID-19, normal, and viral pneumonia. The performance was assessed based on the accuracy of classifications, with further analysis conducted through confusion matrices and ROC curves.The models&amp;#39; diagnostic capabilities were visualized as follows:• Classification results are depicted in Figure 15.• The confusion matrix for validation dataset diagnoses is shown in Figure 16.• ROC curve analysis for the EfficientNet model is presented in Figure 17.• Accuracy progression of the MobileNet model over epochs is illustrated in Figures 18 and19. In response to the COVID-19 pandemic, our study demonstrates promising results for COVID-19 detection using chest X-rays. However, we must note that our model has not yet been tested in real-world clinical settings, which limits our ability to fully assess its performance in a practical healthcare environment. To address this, we plan to validate our model in clinical settings to evaluate its effectiveness, robustness, and potential impact on patient diagnosis and care. This will provide valuable insights into our model&amp;#39;s applicability in different medical scenarios and move us closer to broader adoption in clinical practice. Our proposed solution leverages the power of pretrained models and demonstrates commendable efficacy, achieving an accuracy rate of 88.48% in training and 88.1% in validation on the initial dataset. By harnessing Efficient Net-based transfer learning on a balanced and enhanced dataset, our developed models have attained exemplary performance, registering training and validation accuracies of 95.64% and 97.31%, respectively. These results not only parallel but, in some instances, surpass the accuracy levels of existing models, demonstrating the robustness of our approach. Notably, our models&amp;#39; enhanced capability to precisely localize affected areas significantly bolsters their diagnostic utility, providing a valuable tool for physicians in the fight against COVID-19. Our study contributes to the growing body of research in AI-assisted medical imaging, showcasing the potential of deep learning architectures to revolutionize healthcare diagnostics.The future directions section would benefit from a more comprehensive roadmap. Specifically, the paper should address several promising avenues: (1) the integration of advanced explainability techniques like SHAP or LIME to enhance model interpretability; (2) validation across diverse datasets from different domains to establish broader generalizability; and (3) exploration of hybrid approaches combining the current method with emerging techniques in the field. These extensions could address current limitations while advancing the broader research agenda.First, while our dataset includes chest X-ray images, it may not fully represent the diversity of COVID-19 cases across different populations and imaging equipment. The model, though showing high accuracy in experimental settings, requires validation in real-world clinical environments to establish practical utility. While we employed Grad-CAM for visualization, we recognize that our model&amp;#39;s interpretability could be enhanced through additional techniques like SHAP or LIME to increase clinician trust. Despite implementing class weighting and oversampling, inherent dataset imbalances persist, potentially affecting prediction reliability for minority classes. The model&amp;#39;s computational requirements may pose challenges in resource-constrained settings, suggesting a need for architectural optimization. Although we implemented dropout and data augmentation, the high-test accuracy warrants external validation to conclusively demonstrate generalizability. Finally, our focus on X-ray imaging alone may not capture all relevant COVID-19 clinical features, indicating potential value in incorporating additional imaging modalities like CT scans or clinical data in future work.},
  archive      = {J_FDATA},
  author       = {V, Aravinda C. and B, Sudeepa K. and Pradeep, S. and Suraksha, P. and Lin, Meng},
  doi          = {10.3389/fdata.2024.1489020},
  journal      = {Frontiers in Big Data},
  month        = {12},
  pages        = {1489020},
  shortjournal = {Front. Big Data},
  title        = {Leveraging compact convolutional transformers for enhanced COVID-19 detection in chest X-rays: A grad-CAM visualization approach},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting student self-efficacy in muslim societies using
machine learning algorithms. <em>FDATA</em>, <em>7</em>, 1449572. (<a
href="https://doi.org/10.3389/fdata.2024.1449572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Ba-Aoum, Mohammed and Alrezq, Mohammed and Datta, Jyotishka and Triantis, Konstantinos P.},
  doi          = {10.3389/fdata.2024.1449572},
  journal      = {Frontiers in Big Data},
  month        = {12},
  pages        = {1449572},
  shortjournal = {Front. Big Data},
  title        = {Predicting student self-efficacy in muslim societies using machine learning algorithms},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How critical is SME financial literacy and digital financial
access for financial and economic development in the expanded BRICS
block? <em>FDATA</em>, <em>7</em>, 1448571. (<a
href="https://doi.org/10.3389/fdata.2024.1448571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {M., Manoj Kumar and Almuraqab, Nasser and Moonesar, Immanuel Azaad and Braendle, Udo Christian and Rao, Ananth},
  doi          = {10.3389/fdata.2024.1448571},
  journal      = {Frontiers in Big Data},
  month        = {12},
  pages        = {1448571},
  shortjournal = {Front. Big Data},
  title        = {How critical is SME financial literacy and digital financial access for financial and economic development in the expanded BRICS block?},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of a localized morphometrics approach to
imaging-derived brain phenotypes for genotype-phenotype associations in
pediatric mental health and neurodevelopmental disorders.
<em>FDATA</em>, <em>7</em>, 1429910. (<a
href="https://doi.org/10.3389/fdata.2024.1429910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Dagasso, Gabrielle and Wilms, Matthias and MacEachern, Sarah J. and Forkert, Nils D.},
  doi          = {10.3389/fdata.2024.1429910},
  journal      = {Frontiers in Big Data},
  month        = {12},
  pages        = {1429910},
  shortjournal = {Front. Big Data},
  title        = {Application of a localized morphometrics approach to imaging-derived brain phenotypes for genotype-phenotype associations in pediatric mental health and neurodevelopmental disorders},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-border collaboration, communication, and research
frontiers on biologics in chronic rhinosinusitis from 2004 to 2023.
<em>FDATA</em>, <em>7</em>, 1428074. (<a
href="https://doi.org/10.3389/fdata.2024.1428074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Huang, Guan-Jiang and Fan, Zhi-Jun and Lu, Biao-Qing},
  doi          = {10.3389/fdata.2024.1428074},
  journal      = {Frontiers in Big Data},
  month        = {12},
  pages        = {1428074},
  shortjournal = {Front. Big Data},
  title        = {Cross-border collaboration, communication, and research frontiers on biologics in chronic rhinosinusitis from 2004 to 2023},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How does digitally enabled micro-finance promote income
equality for the vulnerable in the expanded BRICS block during the
pandemic? <em>FDATA</em>, <em>7</em>, 1417752. (<a
href="https://doi.org/10.3389/fdata.2024.1417752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {M. V., Manoj Kumar and Almuraqab, Nasser and Moonesar, Immanuel Azaad and Braendle, Udo Christian and Rao, Ananth},
  doi          = {10.3389/fdata.2024.1417752},
  journal      = {Frontiers in Big Data},
  month        = {12},
  pages        = {1417752},
  shortjournal = {Front. Big Data},
  title        = {How does digitally enabled micro-finance promote income equality for the vulnerable in the expanded BRICS block during the pandemic?},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing sentiment and intent analysis in public health via
fine-tuned large language models on tobacco and e-cigarette-related
tweets. <em>FDATA</em>, <em>7</em>, 1501154. (<a
href="https://doi.org/10.3389/fdata.2024.1501154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Elmitwalli, Sherif and Mehegan, John and Gallagher, Allen and Alebshehy, Raouf},
  doi          = {10.3389/fdata.2024.1501154},
  journal      = {Frontiers in Big Data},
  month        = {11},
  pages        = {1501154},
  shortjournal = {Front. Big Data},
  title        = {Enhancing sentiment and intent analysis in public health via fine-tuned large language models on tobacco and e-cigarette-related tweets},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Credibility-based knowledge graph embedding for identifying
social brand advocates. <em>FDATA</em>, <em>7</em>, 1469819. (<a
href="https://doi.org/10.3389/fdata.2024.1469819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Abu-Salih, Bilal and Alotaibi, Salihah and Al-Okaily, Manaf and Aljaafari, Mohammed and Almiani, Muder},
  doi          = {10.3389/fdata.2024.1469819},
  journal      = {Frontiers in Big Data},
  month        = {11},
  pages        = {1469819},
  shortjournal = {Front. Big Data},
  title        = {Credibility-based knowledge graph embedding for identifying social brand advocates},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Establishing and evaluating trustworthy AI: Overview and
research challenges. <em>FDATA</em>, <em>7</em>, 1467222. (<a
href="https://doi.org/10.3389/fdata.2024.1467222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Kowald, Dominik and Scher, Sebastian and Pammer-Schindler, Viktoria and Müllner, Peter and Waxnegger, Kerstin and Demelius, Lea and Fessl, Angela and Toller, Maximilian and Mendoza Estrada, Inti Gabriel and Šimić, Ilija and Sabol, Vedran and Trügler, Andreas and Veas, Eduardo and Kern, Roman and Nad, Tomislav and Kopeinik, Simone},
  doi          = {10.3389/fdata.2024.1467222},
  journal      = {Frontiers in Big Data},
  month        = {11},
  pages        = {1467222},
  shortjournal = {Front. Big Data},
  title        = {Establishing and evaluating trustworthy AI: Overview and research challenges},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cognitive warfare: A conceptual analysis of the NATO ACT
cognitive warfare exploratory concept. <em>FDATA</em>, <em>7</em>,
1452129. (<a href="https://doi.org/10.3389/fdata.2024.1452129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {S. Schaal, Gary and Deppe, Christoph},
  doi          = {10.3389/fdata.2024.1452129},
  journal      = {Frontiers in Big Data},
  month        = {11},
  pages        = {1452129},
  shortjournal = {Front. Big Data},
  title        = {Cognitive warfare: A conceptual analysis of the NATO ACT cognitive warfare exploratory concept},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cybermycelium: A reference architecture for domain-driven
distributed big data systems. <em>FDATA</em>, <em>7</em>, 1448481. (<a
href="https://doi.org/10.3389/fdata.2024.1448481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe ubiquity of digital devices, the infrastructure of today, and the ever-increasing proliferation of digital products have dawned a new era, the era of big data (BD). This era began when the volume, variety, and velocity of data overwhelmed traditional systems that used to analyze and store that data. This precipitated a new class of software systems, namely, BD systems. Whereas BD systems provide a competitive advantage to businesses, many have failed to harness the power of them. It has been estimated that only 20% of companies have successfully implemented a BD project.MethodsThis study aims to facilitate BD system development by introducing Cybermycelium, a domain-driven decentralized BD reference architecture (RA). The artifact was developed following the guidelines of empirically grounded RAs and evaluated through implementation in a real-world scenario using the Architecture Tradeoff Analysis Method (ATAM).ResultsThe evaluation revealed that Cybermycelium successfully addressed key architectural qualities: performance (achieving &amp;lt;1,000 ms response times), availability (through event brokers and circuit breaking), and modifiability (enabling rapid service deployment and configuration). The prototype demonstrated effective handling of data processing, scalability challenges, and domain-specific requirements in a large-scale international company setting.DiscussionThe results highlight important architectural trade-offs between event backbone implementation and service mesh design. While the domain-driven distributed approach improved scalability and maintainability compared to traditional monolithic architectures, it requires significant technical expertise for implementation. This contribution advances the field by providing a validated reference architecture that addresses the challenges of adopting BD in modern enterprises.},
  archive      = {J_FDATA},
  author       = {Ataei, Pouya},
  doi          = {10.3389/fdata.2024.1448481},
  journal      = {Frontiers in Big Data},
  month        = {11},
  pages        = {1448481},
  shortjournal = {Front. Big Data},
  title        = {Cybermycelium: A reference architecture for domain-driven distributed big data systems},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient out-of-distribution detection via layer-adaptive
scoring and early stopping. <em>FDATA</em>, <em>7</em>, 1444634. (<a
href="https://doi.org/10.3389/fdata.2024.1444634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Wang, Haoliang and Zhao, Chen and Chen, Feng},
  doi          = {10.3389/fdata.2024.1444634},
  journal      = {Frontiers in Big Data},
  month        = {11},
  pages        = {1444634},
  shortjournal = {Front. Big Data},
  title        = {Efficient out-of-distribution detection via layer-adaptive scoring and early stopping},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TSPDB: A curated resource of tailspike proteins with
potential applications in phage research. <em>FDATA</em>, <em>7</em>,
1437580. (<a href="https://doi.org/10.3389/fdata.2024.1437580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bacteriophages (phages) are viruses that infect and replicate within host bacteria and archaea (Chatterjee and Duerkop, 2018;Dion et al., 2020). Phages are the most abundant entities in the biosphere (Dion et al., 2020) and are distributed across different biomes populated by bacterial and archaeal hosts, including the gastrointestinal tract of humans and animals, and oceanic beds (Chevallereau et al., 2022;Clokie et al., 2011). They play a vital role in the rapid evolution and adaptation of their hosts in various environments (Dion et al., 2020).Phages exhibit high genomic, morphological, and structural diversity, composed of DNA or RNA that can be single-stranded or double-stranded and packaged into a capsid (Dion et al., 2020;Fokine and Rossmann, 2014). The structural form of the capsid was a major feature used in the taxonomic classification of phages until the advent of whole-genome sequencing, which has now become the gold standard for this classification. (Dion et al., 2020;Fokine and Rossmann, 2014;Turner et al., 2023). Phages are broadly classified as tailed or non-tailed, with double-stranded DNA tailed phages constituting about 96% of all known phages (Dion et al., 2020). Phages possess a diverse array of tail structures essential for host recognition, attachment, and penetration, making them important targets in phage therapy research (Fokine and Rossmann, 2014;Gil et al., 2023). Phage infection of its host begins with the recognition of a receptor on the bacterial cell surface for attachment (Dowah and Clokie, 2018;Latka et al., 2017). To penetrate the host cell, phages must overcome various complex barriers on the bacterial cell wall, such as the outer membrane of Gram-negative bacteria and the lipoteichoic acids of Gram-positive bacteria (Chen et al., 2014;Latka et al., 2017). Phages encode virion-associated carbohydrate-degrading enzymes called depolymerases, which are distinct from the endolysins produced by phages during the lysis stage (Knecht et al., 2020;Yan et al., 2014). These depolymerases, encoded by tailspike protein (TSP) genes, recognize, bind, and degrade cell-surface associated polysaccharides, unmasking phage receptors and making them accessible for bacterial infection (Gil et al., 2023;Greenfield et al., 2019;Latka et al., 2017).Tailspike proteins are integral components of phage tail structures, and their activities as polysaccharide depolymerases are related to host specificity and infectivity (Greenfield et al., 2019). A hallmark of TSPs is their host specificity, high thermostability, resistance to protease treatment, and stability in the presence of high concentrations of urea and sodium dodecyl sulfate (Chen et al., 2014). Phage TSPs possess carbohydrate depolymerase activity and recognize capsule, and lipopolysaccharides (LPS) where they cleave components of the LPS to position the phage towards a secondary membrane receptor during infection (Knecht et al., 2020). TSPs have been observed to decrease bacterial viability, leading to antimicrobial applications. For example, Ayariga and colleagues (Ayariga et al., 2021) demonstrated that the ɛ34 phage tailspike protein has enzymatic property as a LPS hydrolase and synergizes with Vero Cell culture supernatant in killing Salmonella Newington. The ɛ34 TSP also showed bactericidal efficacy against different Salmonella serovars in various matrices (Ibrahim et al., 2023). Miletic and colleagues (Miletic et al., 2016) expressed the receptor binding domain of the Phage P22 Gp9 tailspike protein in plant tissue (Nicotiana benthamiana), and demonstrated that, upon oral administration of lyophilized leaves expressing Gp9 TSP to newly hatched chickens, Salmonella concentrations were reduced on average by approximately 0.75 log relative to controls. Others have shown that TSPs can be used to control the growth of plant pathogens. For example, expression of the Erwinia spp. phage TSP DpoEa1h in transgenic apple and pear plants significantly reduced fire blight (Erwinia amylovora) susceptibility, (Malnoy et al., 2005;Roach and Donovan, 2015) likely due to removal of the main virulence factor amylovoran and exposing the E. amylovora cells to host plant defenses (Kim et al., 2004). Finally, phage LKA1 TSP exhibits disruptive activity against biofilms while also reducing virulence in Pseudomonas in an infection model (Olszak et al., 2017). Collectively, these studies demonstrate the utility of TSPs as novel antimicrobials to control the growth of food and plant-borne pathogens in foods.Despite the known antimicrobial applications of TSPs, only a few have been fully characterized to date. This could be partly due to the laborious nature of detection techniques, which include plaque assays followed by examination under a transmission electron microscope (TEM) to identify &amp;quot;bulblike&amp;quot; baseplate structures at the base of phage tails indicative of TSPs (Bhandare et al., 2024;Knecht et al., 2020). The decreasing costs of sequencing and the availability of improved bioinformatics tools have facilitated the construction of large-scale genome and metagenome datasets (Emond-Rheault et al., 2017;Wattam et al., 2014). High-throughput in silico detection of TSP-encoding genes in genomic data would not only provide further details regarding the diversity of TSPs in virulent phages but could also be used to identify TSPs in prophages. In this report, we present a high-level curated resource called TSP database (TSPDB) for the rapid detection of tailspike proteins in multiomics sequence data. This TSPDB will be an indispensable resource for researchers in phage biology, drug discovery, and antimicrobial resistance domains to further contribute to the understanding of the structure and function of these proteins to harness their potential for diverse applications, such as the development of phage therapy for bacterial infections or phage-based biocontrol of foodborne pathogens, and drug discovery (Brives and Pourraz, 2020;Roach and Donovan, 2015).Data Mining and Quality Check: The DDBJ/ENA/GenBank and UniProt databases (Sayers et al., 2022;The UniProt Consortium et al., 2023) were queried for TSPs using search terms commonly associated with tailspike proteins, such as &amp;quot;phage tailspike,&amp;quot; &amp;quot;tail spike proteins,&amp;quot; &amp;quot;phage endopeptidase,&amp;quot; and &amp;quot;phage endorhamnosidase.&amp;quot; (Figure 1). Hits were systematically filtered based on annotation criterion to exclude duplicate results. Nucleotide sequences of TSPs were retrieved from public databases using accession numbers obtained from the database query via NCBI Entrez Programming Utilities (E-utilities) (National Center for Biotechnology Information,Dataset Curation: From this exercise, 17,211 sequences were obtained from the queried public databases. Duplicated sequences were removed using thresholds of ≥ 95% sequence coverage and nucleotide similarity with cd-hit (Li and Godzik, 2006) and Seqkit (Shen et al., 2016), resulting in 9,129 unique TSP sequences. To assess the sequence length distribution and perform quality checks on unique TSP sequences, Gaussian distribution analysis was conducted. Sequences shorter than 400 bp, which could represent partial region or incomplete sequences that may lack critical functional domains required for accurate annotation and functional prediction, were excluded from the dataset. By excluding these shorter sequences, we reduce the possibility of including fragments that could introduce noise or inaccuracies into the database. This threshold helps ensure that the TSPDB contains more reliable and complete sequences for functional analysis and annotation. This filtering process resulted in a total of 8,105 unique TSP sequences (Figure 1). TSP sequences with a length of ≤10,000 bp were retained to include those originating from Gram-positive bacteria such as Clostridium and Streptococcus, among others. Overall size range of TSPs retrieved from the public databases is 405 to 9990 bp (Figure 2A). Further analysis of TSP genes in the TSPDB reveals a significant difference (p &amp;lt; 0.001) in the sizes of TSPs between Gram-negative and Gram-positive bacteria. Specifically, the average size of TSPs for Gram-negative bacteria is 2,070 bp, while the average size for Gram-positive bacteria is substantially larger, at 3,255 bp (Figure 2B). The TSPDB contains TSPs from more than 400 bacterial genera. Among these, the top 13 genera represented were Gram-positive bacteria, with TSPs from Bacillus (n=1616) being the most common, followed by Streptococcus (n=1152), Clostridium (n=683), Enterococcus (n=387), and Staphylococcus (n=372). Additionally, TSPs from Gram-negative bacterial genera, Salmonella (n=80), Escherichia (n=58), Klebsiella (n=52), and Pseudomonas (n=25) were among the top 38 TSPs in the database (Figure 2C). To assess the normality of the distribution of TSP frequencies across bacterial genera, we performed a Shapiro-Wilk test. This test yielded a statistic of 0.487 and a p-value &amp;lt; 0.0001, confirming a significant departure from normality. This result supports the observation of a skewed distribution, where Gram positive bacteria host genera (e.g., Bacillus and Streptococcus) exhibit notably high TSP counts compared to others.To assess the diversity of the 8,105 unduplicated TSP sequences and their suitability for database creation, we employed a phylogeny-based approach. The TSP sequences were aligned using MAFFT v7.453 (Katoh, 2002), and a maximum likelihood tree was constructed with FastTree v2.1.11 (Price et al., 2010) using the generalized time reversible mode and 1000 bootstrap replicates for node support. The resulting phylogenetic tree was visualized using the web-based Microreact visualization tool (Argim&amp;#243;n et al., 2016) (Figure 2D). The phylogeny revealed the high diversity of TSPs in the TSPDB, further supporting the uniqueness of individual TSPs. TSPs from the same species often belonged to different clusters. For example, TSPs from Bacillus and Listeria were distributed across multiple clusters in the phylogeny. While the majority of TSPs from Salmonella belonged to the same cluster, there were also a few instances of TSPs from this host genus in separate clusters (Figure 2D).The deduplicated TSP nucleotide sequences were utilized to construct the TSP database using makeblastdb (Camacho et al., 2009). This database is compatible for use with ABRicate (https://github.com/tseemann/abricate) and other bioinformatics tools equipped with embedded BLAST algorithms, such as BLAST suites and SRST2 (Inouye et al., 2014), among others.The TSPDB was recently utilized in a study by (Bhandare et al., 2024), where the database was implemented within an ABRicate container. The database index files suitable for use with blast was generated using makeblast_db option in ABRicate. The step-by-step guide on how to incorporate TSPDB into ABRicate for rapid screening of large genomic dataset is detailed on the ABRicate Github page (https://github.com/tseemann/abricate). The presence of TSPs in a collection of phage genomes were determined using stringent parameters (≥ 90% identity and ≥ 70% coverage). TSPDB provides valuable applications across various fields, particularly in phage therapy, biocontrol, and functional genomics and would contribute to advancing the application of TSPs in biocontrol strategies in agriculture and food safety. Overall, the TSPDB contains a vast dataset of diverse TSPs found in phages, and the integration of this database into phage detection tools will enhance the functional annotation of these genes in large genomic and metagenomic datasets. Lastly, the TSPDB described here will undergo regular updates and expansion to include new TSPs as they become available in public databases ensuring that the database remains comprehensive.Limitations: It is acknowledged that mis-annotation of some TSPs as hypothetical proteins or tail fibers in public databases may have resulted in the omission of certain TSP genes in this study.However, the TSPDB will be continually updated to incorporate additional TSP genes.The TSPDB is freely accessible on GitHub at the following link: https://github.com/yemilawal/Tailspike-proteins or by searching for the title &amp;quot;TSPDB: A curated resource of tailspike proteins with potential applications in phage research&amp;quot; on GitHub. Additionally, accession numbers of genes encoding phage tailspike proteins in TSPDB are available on the GitHub page. A backup version is also available for download on Figshare at https://doi.org/10.6084/m9.figshare.25526323. To assess the normality of the distribution of TSP frequencies across bacterial genera, we performed a Shapiro-Wilk test. In this analysis, the Shapiro-Wilk test yielded a statistic of 0.487 and a p-value &amp;lt; 0.0001, confirming a significant departure from normality. This result supports the observation of a skewed distribution, where a small number of genera (e.g., Bacillus and Streptococcus) exhibit notably high TSP counts compared to others.},
  archive      = {J_FDATA},
  author       = {Lawal, Opeyemi U. and Goodridge, Lawrence},
  doi          = {10.3389/fdata.2024.1437580},
  journal      = {Frontiers in Big Data},
  month        = {11},
  pages        = {1437580},
  shortjournal = {Front. Big Data},
  title        = {TSPDB: A curated resource of tailspike proteins with potential applications in phage research},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Camera-view supervision for bird’s-eye-view semantic
segmentation. <em>FDATA</em>, <em>7</em>, 1431346. (<a
href="https://doi.org/10.3389/fdata.2024.1431346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bird&#39;s-eye-view Semantic Segmentation (BEVSS) is a powerful and crucial component of planning and control systems in many autonomous vehicles. Current methods rely on end-to-end learning to train models. We propose a novel method of supervising feature extraction with camera-view depth and segmentation information, which improves the quality of feature extraction and projection in the BEVSS pipeline. Through extensive empirical evaluation, we demonstrate that our approach achieves superior performance compared to existing methods, improving the robustness and reliability of BEVSS for autonomous driving systems. Our method achieves very competitive inference and training computational cost when compared to other real-time BEVSS methods, while maintaining superior accuracy. The codes and implementation details and code can be found at https://github.com/bluffish/sucam.},
  archive      = {J_FDATA},
  author       = {Yang, Bowen and Yu, LinLin and Chen, Feng},
  doi          = {10.3389/fdata.2024.1431346},
  journal      = {Frontiers in Big Data},
  month        = {11},
  pages        = {1431346},
  shortjournal = {Front. Big Data},
  title        = {Camera-view supervision for bird&#39;s-eye-view semantic segmentation},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ActiveReach: An active learning framework for approximate
reachability query answering in large-scale graphs. <em>FDATA</em>,
<em>7</em>, 1427104. (<a
href="https://doi.org/10.3389/fdata.2024.1427104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Raghebi, Zohreh and Banaei-Kashani, Farnoush},
  doi          = {10.3389/fdata.2024.1427104},
  journal      = {Frontiers in Big Data},
  month        = {11},
  pages        = {1427104},
  shortjournal = {Front. Big Data},
  title        = {ActiveReach: An active learning framework for approximate reachability query answering in large-scale graphs},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cultural big data: Nineteenth to twenty-first century
panoramic visualization. <em>FDATA</em>, <em>7</em>, 1309887. (<a
href="https://doi.org/10.3389/fdata.2024.1309887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From the nineteenth-century panorama to the emergence of the digital panoramic format in the 1990&#39;s, the visualization of large images frequently relies on panoramic viewing strategies. Originally rendered in the form of epic painted canvases, these strategies are now amplified through gigapixel imaging, computer vision and machine learning. Whether for scientific analysis, dissemination, or to visualize cultural big data, panoramic strategies pivot on the illusion of immersion. The latter is achieved through human-centered design situated within a large-scale environment combined with a multi-sensory experience spanning sight, sound, touch, and smell. In this article, we present the original research undertaken to realize a digital twin of the 1894 panorama of the battle of Murten. Following a brief history of the panorama, the methods and technological framework systems developed for Murten panorama&#39;s visualization are delineated. Novel visualization methodologies are further discussed, including how to create the illusion of immersion for the world&#39;s largest image of a single physical object and its cultural big data. We also present the visualization strategies developed for the augmentation of the layered narratives and histories embedded in the final interactive viewing experience of the Murten panorama. This article offers researchers in heritage big data new schemas for the visualization and augmentation of gigapixel images in digital panoramas.},
  archive      = {J_FDATA},
  author       = {Chau, Tsz Kin and Bourke, Paul and Hibberd, Lily and Jaquet, Daniel and Kenderdine, Sarah},
  doi          = {10.3389/fdata.2024.1309887},
  journal      = {Frontiers in Big Data},
  month        = {11},
  pages        = {1309887},
  shortjournal = {Front. Big Data},
  title        = {Cultural big data: Nineteenth to twenty-first century panoramic visualization},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Utilizing big data and deep learning to improve
healthcare intelligence and biomedical service delivery. <em>FDATA</em>,
<em>7</em>, 1502398. (<a
href="https://doi.org/10.3389/fdata.2024.1502398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of big data and deep learning in healthcare is rapidly transforming the landscape of medical research, diagnostics, and patient care. Our Research Topic, &amp;quot;Utilizing Big Data and Deep Learning to Improve Healthcare Intelligence and Biomedical Service Delivery,&amp;quot; compiles groundbreaking studies that demonstrate the innovative applications and significant impact of these technologies on healthcare systems worldwide. This editorial synthesizes the contributions of seven featured articles, highlighting their collective advancements in healthcare intelligence.The primary aim of this Research Topic is to explore and showcase innovative research that harnesses the power of big data and deep learning to address critical challenges in healthcare. By presenting a diverse range of studies, we aim to provide a comprehensive overview of how these technologies are utilized to improve diagnostic accuracy, patient care, and overall healthcare system efficiency.The exponential growth of healthcare data necessitates advanced analytical tools capable of extracting meaningful insights. Traditional data analysis methods often fall short in managing the volume, variety, and velocity of modern healthcare data. Deep learning algorithms, with their capacity to learn from complex datasets, offer a robust solution to these challenges. These technologies are particularly valuable in personalized medicine, public health monitoring, and clinical decision support, enabling tailored treatments and proactive health management. Rowalt Alibudbud&amp;#39;s review examines the use of Wikipedia page views as a data source for health research. The study analyzed 29 publications utilizing Wikipedia page views to inform public health services and policies. These studies covered various topics, including non-communicable and infectious diseases, health interventions, and the impact of public events on health information usage. The review highlights the potential of Wikipedia page views to estimate disease incidence, predict public interest in health topics, and improve health education activities. Future research is encouraged to address replication limitations and explore other health topics on Wikipedia.Huanyu Li et al. introduce DIET-AI, a novel diagnostic system combining dual-channel images and extracted text for diagnosing skin diseases. Developed using a dataset of over 200,000 images and 220,000 medical records from Asian populations, DIET-AI demonstrated diagnostic performance comparable to senior dermatologists across 31 common skin diseases. This study underscores the importance of integrating multimodal data to enhance the accuracy and reliability of AI-driven diagnostic tools, highlighting its potential for clinical application in regions with limited access to specialist care.Yu Yao and Fei Yang discuss the legal and ethical challenges of using real-world data (RWD) in public health research in China. The article addresses the complexities of balancing personal information protection with the public value of health data. The implementation of the Personal Information Protection Law (PIPL) in 2021 underscores the need for clear guidelines on &amp;quot;separate consent,&amp;quot; cross-border data transfer, and exceptions for scientific research. The authors propose a shift in the legal framework to better support public health research while respecting privacy, essential for advancing RWD use in improving health outcomes and guiding policy decisions.Liuying Li et al. present an innovative method for automated segmentation of heart sounds to improve cardiovascular disease prediction and diagnosis. The study designed an audio data analysis tool to segment heart sounds from single heart cycles, validated using a finger oxygen meter. By combining an electronic stethoscope with AI technology, the study achieved accurate identification of heart sounds and murmurs, providing an objective basis for heart sound auscultation and visual display, enhancing the prediction and diagnosis of heart disease. Dongjin Chen et al. explore the adoption patterns of mobile apps by doctors for patient communication in Hangzhou and Yancheng, China. The mixed methods study found that social context influences doctors&amp;#39; choice of apps, with doctors in traditional societies favoring social networking apps to maintain social connections, while those in modern societies prefer medical platform apps for reputation marketing. The study provides insights into how societal attributes impact technology adoption in healthcare.Lan He et al. developed a deep learning algorithm using bilinear convolutional and residual neural networks (BCNN-ResNet) to detect carotid plaques and assess their stability. The study involved training and testing on ultrasound images from multiple hospitals. The algorithm demonstrated high accuracy, sensitivity, and specificity in identifying plaque presence and stability, offering a consistent and objective diagnostic method for carotid artery screening, crucial for stroke prevention. Areej Alhhazmi et al. employed deep learning (DL) and Bayesian optimization (BOA) methods to predict COVID-19 cases in Saudi Arabia. The study compared the efficacy of BOA and DL, finding that the DL approach, particularly the DQN model, provided more accurate predictions. This research underscores the importance of advanced predictive models in managing public health crises, highlighting AI&amp;#39;s role in improving response strategies during pandemics.The Research Topic &amp;quot;Utilizing Big Data and Deep Learning to Improve Healthcare Intelligence and Biomedical Service Delivery&amp;quot; showcases significant advancements in healthcare technology. The articles demonstrate the practical applications and potential benefits of integrating big data and deep learning into healthcare systems. By addressing critical challenges and proposing innovative solutions, these studies contribute to the ongoing transformation of healthcare intelligence and biomedical service delivery.We extend our gratitude to all the authors and reviewers who contributed to this Research Topic. Their dedication and insights have significantly enriched our understanding of how big data and deep learning can revolutionize healthcare.Dr. Sathishkumar V E Lecturer, Department of Computing and Information Systems Sunway University, Malaysia},
  archive      = {J_FDATA},
  author       = {Sathishkumar, V. E.},
  doi          = {10.3389/fdata.2024.1502398},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1502398},
  shortjournal = {Front. Big Data},
  title        = {Editorial: Utilizing big data and deep learning to improve healthcare intelligence and biomedical service delivery},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Promoting fairness in link prediction with graph
enhancement. <em>FDATA</em>, <em>7</em>, 1489306. (<a
href="https://doi.org/10.3389/fdata.2024.1489306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is a crucial task in network analysis, but it has been shown to be prone to biased predictions, particularly when links are unfairly predicted between nodes from different sensitive groups. In this paper, we study the fair link prediction problem, which aims to ensure that the predicted link probability is independent of the sensitive attributes of the connected nodes. Existing methods typically incorporate debiasing techniques within graph embeddings to mitigate this issue. However, training on large real-world graphs is already challenging, and adding fairness constraints can further complicate the process. To overcome this challenge, we propose FairLink, a method that learns a fairness-enhanced graph to bypass the need for debiasing during the link predictor&#39;s training. FairLink maintains link prediction accuracy by ensuring that the enhanced graph follows a training trajectory similar to that of the original input graph. Meanwhile, it enhances fairness by minimizing the absolute difference in link probabilities between node pairs within the same sensitive group and those between node pairs from different sensitive groups. Our extensive experiments on multiple large-scale graphs demonstrate that FairLink not only promotes fairness but also often achieves link prediction accuracy comparable to baseline methods. Most importantly, the enhanced graph exhibits strong generalizability across different GNN architectures. FairLink is highly scalable, making it suitable for deployment in real-world large-scale graphs, where maintaining both fairness and accuracy is critical.},
  archive      = {J_FDATA},
  author       = {Liu, Yezi and Chen, Hanning and Imani, Mohsen},
  doi          = {10.3389/fdata.2024.1489306},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1489306},
  shortjournal = {Front. Big Data},
  title        = {Promoting fairness in link prediction with graph enhancement},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring code portability solutions for HEP with a particle
tracking test code. <em>FDATA</em>, <em>7</em>, 1485344. (<a
href="https://doi.org/10.3389/fdata.2024.1485344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, high energy physics (HEP) experiments have relied on x86 CPUs for the majority of their significant computing needs. As the field looks ahead to the next generation of experiments such as DUNE and the High-Luminosity LHC, the computing demands are expected to increase dramatically. To cope with this increase, it will be necessary to take advantage of all available computing resources, including GPUs from different vendors. A broad landscape of code portability tools—including compiler pragma-based approaches, abstraction libraries, and other tools—allow the same source code to run efficiently on multiple architectures. In this paper, we use a test code taken from a HEP tracking algorithm to compare the performance and experience of implementing different portability solutions. While in several cases portable implementations perform close to the reference code version, we find that the performance varies significantly depending on the details of the implementation. Achieving optimal performance is not easy, even for relatively simple applications such as the test codes considered in this work. Several factors can affect the performance, such as the choice of the memory layout, the memory pinning strategy, and the compiler used. The compilers and tools are being actively developed, so future developments may be critical for their deployment in HEP experiments.},
  archive      = {J_FDATA},
  author       = {Ather, Hammad and Berkman, Sophie and Cerati, Giuseppe and Kortelainen, Matti J. and Kwok, Ka Hei Martin and Lantz, Steven and Lee, Seyong and Norris, Boyana and Reid, Michael and Reinsvold Hall, Allison and Riley, Daniel and Strelchenko, Alexei and Wang, Cong},
  doi          = {10.3389/fdata.2024.1485344},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1485344},
  shortjournal = {Front. Big Data},
  title        = {Exploring code portability solutions for HEP with a particle tracking test code},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ontology extension by online clustering with large language
model agents. <em>FDATA</em>, <em>7</em>, 1463543. (<a
href="https://doi.org/10.3389/fdata.2024.1463543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An ontology is a structured framework that categorizes entities, concepts, and relationships within a domain to facilitate shared understanding, and it is important in computational linguistics and knowledge representation. In this paper, we propose a novel framework to automatically extend an existing ontology from streaming data in a zero-shot manner. Specifically, the zero-shot ontology extension framework uses online and hierarchical clustering to integrate new knowledge into existing ontologies without substantial annotated data or domain-specific expertise. Focusing on the medical field, this approach leverages Large Language Models (LLMs) for two key tasks: Symptom Typing and Symptom Taxonomy among breast and bladder cancer survivors. Symptom Typing involves identifying and classifying medical symptoms from unstructured online patient forum data, while Symptom Taxonomy organizes and integrates these symptoms into an existing ontology. The combined use of online and hierarchical clustering enables real-time and structured categorization and integration of symptoms. The dual-phase model employs multiple LLMs to ensure accurate classification and seamless integration of new symptoms with minimal human oversight. The paper details the framework&#39;s development, experiments, quantitative analyses, and data visualizations, demonstrating its effectiveness in enhancing medical ontologies and advancing knowledge-based systems in healthcare.},
  archive      = {J_FDATA},
  author       = {Wu, Guanchen and Ling, Chen and Graetz, Ilana and Zhao, Liang},
  doi          = {10.3389/fdata.2024.1463543},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1463543},
  shortjournal = {Front. Big Data},
  title        = {Ontology extension by online clustering with large language model agents},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised machine learning model for detecting anomalous
volumetric modulated arc therapy plans for lung cancer patients.
<em>FDATA</em>, <em>7</em>, 1462745. (<a
href="https://doi.org/10.3389/fdata.2024.1462745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PurposeVolumetric modulated arc therapy (VMAT) is a new treatment modality in modern radiotherapy. To ensure the quality of the radiotherapy plan, a physics plan review is routinely conducted by senior clinicians; however, this process is less efficient and less accurate. In this study, a multi-task AutoEncoder (AE) is proposed to automate anomaly detection of VMAT plans for lung cancer patients.MethodsThe feature maps are first extracted from a VMAT plan. Then, a multi-task AE is trained based on the input of a feature map, and its output is the two targets (beam aperture and prescribed dose). Based on the distribution of reconstruction errors on the training set, a detection threshold value is obtained. For a testing sample, its reconstruction error is calculated using the AE model and compared with the threshold value to determine its classes (anomaly or regular). The proposed multi-task AE model is compared to the other existing AE models, including Vanilla AE, Contractive AE, and Variational AE. The area under the receiver operating characteristic curve (AUC) and the other statistics are used to evaluate the performance of these models.ResultsAmong the four tested AE models, the proposed multi-task AE model achieves the highest values in AUC (0.964), accuracy (0.821), precision (0.471), and F1 score (0.632), and the lowest value in FPR (0.206).ConclusionThe proposed multi-task AE model using two-dimensional (2D) feature maps can effectively detect anomalies in radiotherapy plans for lung cancer patients. Compared to the other existing AE models, the multi-task AE is more accurate and efficient. The proposed model provides a feasible way to carry out automated anomaly detection of VMAT plans in radiotherapy.},
  archive      = {J_FDATA},
  author       = {Huang, Peng and Shang, Jiawen and Fan, Yuhan and Hu, Zhihui and Dai, Jianrong and Liu, Zhiqiang and Yan, Hui},
  doi          = {10.3389/fdata.2024.1462745},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1462745},
  shortjournal = {Front. Big Data},
  title        = {Unsupervised machine learning model for detecting anomalous volumetric modulated arc therapy plans for lung cancer patients},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Big data and AI for gender equality in health: Bias is a big
challenge. <em>FDATA</em>, <em>7</em>, 1436019. (<a
href="https://doi.org/10.3389/fdata.2024.1436019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence and machine learning are rapidly evolving fields that have the potential to transform women&#39;s health by improving diagnostic accuracy, personalizing treatment plans, and building predictive models of disease progression leading to preventive care. Three categories of women&#39;s health issues are discussed where machine learning can facilitate accessible, affordable, personalized, and evidence-based healthcare. In this perspective, firstly the promise of big data and machine learning applications in the context of women&#39;s health is elaborated. Despite these promises, machine learning applications are not widely adapted in clinical care due to many issues including ethical concerns, patient privacy, informed consent, algorithmic biases, data quality and availability, and education and training of health care professionals. In the medical field, discrimination against women has a long history. Machine learning implicitly carries biases in the data. Thus, despite the fact that machine learning has the potential to improve some aspects of women&#39;s health, it can also reinforce sex and gender biases. Advanced machine learning tools blindly integrated without properly understanding and correcting for socio-cultural sex and gender biased practices and policies is therefore unlikely to result in sex and gender equality in health.},
  archive      = {J_FDATA},
  author       = {Joshi, Anagha},
  doi          = {10.3389/fdata.2024.1436019},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1436019},
  shortjournal = {Front. Big Data},
  title        = {Big data and AI for gender equality in health: Bias is a big challenge},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating longitudinal mental health data into a staging
database: Harnessing DDI-lifecycle and OMOP vocabularies within the
INSPIRE network datahub. <em>FDATA</em>, <em>7</em>, 1435510. (<a
href="https://doi.org/10.3389/fdata.2024.1435510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundLongitudinal studies are essential for understanding the progression of mental health disorders over time, but combining data collected through different methods to assess conditions like depression, anxiety, and psychosis presents significant challenges. This study presents a mapping technique allowing for the conversion of diverse longitudinal data into a standardized staging database, leveraging the Data Documentation Initiative (DDI) Lifecycle and the Observational Medical Outcomes Partnership (OMOP) Common Data Model (CDM) standards to ensure consistency and compatibility across datasets.MethodsThe “INSPIRE” project integrates longitudinal data from African studies into a staging database using metadata documentation standards structured with a snowflake schema. This facilitates the development of Extraction, Transformation, and Loading (ETL) scripts for integrating data into OMOP CDM. The staging database schema is designed to capture the dynamic nature of longitudinal studies, including changes in research protocols and the use of different instruments across data collection waves.ResultsUtilizing this mapping method, we streamlined the data migration process to the staging database, enabling subsequent integration into the OMOP CDM. Adherence to metadata standards ensures data quality, promotes interoperability, and expands opportunities for data sharing in mental health research.ConclusionThe staging database serves as an innovative tool in managing longitudinal mental health data, going beyond simple data hosting to act as a comprehensive study descriptor. It provides detailed insights into each study stage and establishes a data science foundation for standardizing and integrating the data into OMOP CDM.},
  archive      = {J_FDATA},
  author       = {Mugotitsa, Bylhah and Bhattacharjee, Tathagata and Ochola, Michael and Mailosi, Dorothy and Amadi, David and Andeso, Pauline and Kuria, Joseph and Momanyi, Reinpeter and Omondi, Evans and Kajungu, Dan and Todd, Jim and Kiragga, Agnes and Greenfield, Jay},
  doi          = {10.3389/fdata.2024.1435510},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1435510},
  shortjournal = {Front. Big Data},
  title        = {Integrating longitudinal mental health data into a staging database: Harnessing DDI-lifecycle and OMOP vocabularies within the INSPIRE network datahub},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced whale optimization algorithm for task scheduling
in edge computing environments. <em>FDATA</em>, <em>7</em>, 1422546. (<a
href="https://doi.org/10.3389/fdata.2024.1422546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of mobile devices and compute-intensive applications has increased the connection of smart devices to networks, generating significant data. Real-time execution faces challenges due to limited resources and demanding applications in edge computing environments. To address these challenges, an enhanced whale optimization algorithm (EWOA) was proposed for task scheduling. A multi-objective model based on CPU, memory, time, and resource utilization was developed. The model was transformed into a whale optimization problem, incorporating chaotic mapping to initialize populations and prevent premature convergence. A nonlinear convergence factor was introduced to balance local and global search. The algorithm&#39;s performance was evaluated in an experimental edge computing environment and compared with ODTS, WOA, HWACO, and CATSA algorithms. Experimental results demonstrated that EWOA reduced costs by 29.22%, decreased completion time by 17.04%, and improved node resource utilization by 9.5%. While EWOA offers significant advantages, limitations include the lack of consideration for potential network delays and user mobility. Future research will focus on fault-tolerant scheduling techniques to address dynamic user needs and improve service robustness and quality.},
  archive      = {J_FDATA},
  author       = {Han, Li and Zhu, Shuaijie and Zhao, Haoyang and He, Yanqiang},
  doi          = {10.3389/fdata.2024.1422546},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1422546},
  shortjournal = {Front. Big Data},
  title        = {An enhanced whale optimization algorithm for task scheduling in edge computing environments},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning-based remission prediction in rheumatoid
arthritis patients treated with biologic disease-modifying
anti-rheumatic drugs: Findings from the kuwait rheumatic disease
registry. <em>FDATA</em>, <em>7</em>, 1406365. (<a
href="https://doi.org/10.3389/fdata.2024.1406365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundRheumatoid arthritis (RA) is a common condition treated with biological disease-modifying anti-rheumatic medicines (bDMARDs). However, many patients exhibit resistance, necessitating the use of machine learning models to predict remissions in patients treated with bDMARDs, thereby reducing healthcare costs and minimizing negative effects.ObjectiveThe study aims to develop machine learning models using data from the Kuwait Registry for Rheumatic Diseases (KRRD) to identify clinical characteristics predictive of remission in RA patients treated with biologics.MethodsThe study collected follow-up data from 1,968 patients treated with bDMARDs from four public hospitals in Kuwait from 2013 to 2022. Machine learning techniques like lasso, ridge, support vector machine, random forest, XGBoost, and Shapley additive explanation were used to predict remission at a 1-year follow-up.ResultsThe study used the Shapley plot in explainable Artificial Intelligence (XAI) to analyze the effects of predictors on remission prognosis across different types of bDMARDs. Top clinical features were identified for patients treated with bDMARDs, each associated with specific mean SHAP values. The findings highlight the importance of clinical assessments and specific treatments in shaping treatment outcomes.ConclusionThe proposed machine learning model system effectively identifies clinical features predicting remission in bDMARDs, potentially improving treatment efficacy in rheumatoid arthritis patients.},
  archive      = {J_FDATA},
  author       = {Alsaber, Ahmad R. and Al-Herz, Adeeba and Alawadhi, Balqees and Doush, Iyad Abu and Setiya, Parul and AL-Sultan, Ahmad T. and Saleh, Khulood and Al-Awadhi, Adel and Hasan, Eman and Al-Kandari, Waleed and Mokaddem, Khalid and Ghanem, Aqeel A. and Attia, Yousef and Hussain, Mohammed and AlHadhood, Naser and Ali, Yaser and Tarakmeh, Hoda and Aldabie, Ghaydaa and AlKadi, Amjad and Alhajeri, Hebah},
  doi          = {10.3389/fdata.2024.1406365},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1406365},
  shortjournal = {Front. Big Data},
  title        = {Machine learning-based remission prediction in rheumatoid arthritis patients treated with biologic disease-modifying anti-rheumatic drugs: Findings from the kuwait rheumatic disease registry},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI security and cyber risk in IoT systems. <em>FDATA</em>,
<em>7</em>, 1402745. (<a
href="https://doi.org/10.3389/fdata.2024.1402745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet-of-Things (IoT) refers to low-memory connected devices used in various new technologies, including drones, autonomous machines, and robotics. The article aims to understand better cyber risks in low-memory devices and the challenges in IoT risk management. The article includes a critical reflection on current risk methods and their level of appropriateness for IoT. We present a dependency model tailored in context toward current challenges in data strategies and make recommendations for the cybersecurity community. The model can be used for cyber risk estimation and assessment and generic risk impact assessment. The model is developed for cyber risk insurance for new technologies (e.g., drones, robots). Still, practitioners can apply it to estimate and assess cyber risks in organizations and enterprises. Furthermore, this paper critically discusses why risk assessment and management are crucial in this domain and what open questions on IoT risk assessment and risk management remain areas for further research. The paper then presents a more holistic understanding of cyber risks in the IoT. We explain how the industry can use new risk assessment, and management approaches to deal with the challenges posed by emerging IoT cyber risks. We explain how these approaches influence policy on cyber risk and data strategy. We also present a new approach for cyber risk assessment that incorporates IoT risks through dependency modeling. The paper describes why this approach is well suited to estimate IoT risks.},
  archive      = {J_FDATA},
  author       = {Radanliev, Petar and De Roure, David and Maple, Carsten and Nurse, Jason R. C. and Nicolescu, Razvan and Ani, Uchenna},
  doi          = {10.3389/fdata.2024.1402745},
  journal      = {Frontiers in Big Data},
  month        = {10},
  pages        = {1402745},
  shortjournal = {Front. Big Data},
  title        = {AI security and cyber risk in IoT systems},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction and classification of obesity risk based on a
hybrid metaheuristic machine learning approach. <em>FDATA</em>,
<em>7</em>, 1469981. (<a
href="https://doi.org/10.3389/fdata.2024.1469981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAs the global prevalence of obesity continues to rise, it has become a major public health concern requiring more accurate prediction methods. Traditional regression models often fail to capture the complex interactions between genetic, environmental, and behavioral factors contributing to obesity.MethodsThis study explores the potential of machine-learning techniques to improve obesity risk prediction. Various supervised learning algorithms, including the novel ANN-PSO hybrid model, were applied following comprehensive data preprocessing and evaluation.ResultsThe proposed ANN-PSO model achieved a remarkable accuracy rate of 92%, outperforming traditional regression methods. SHAP was employed to analyze feature importance, offering deeper insights into the influence of various factors on obesity risk.DiscussionThe findings highlight the transformative role of advanced machine-learning models in public health research, offering a pathway for personalized healthcare interventions. By providing detailed obesity risk profiles, these models enable healthcare providers to tailor prevention and treatment strategies to individual needs. The results underscore the need to integrate innovative machine-learning approaches into global public health efforts to combat the growing obesity epidemic.},
  archive      = {J_FDATA},
  author       = {Helforoush, Zarindokht and Sayyad, Hossein},
  doi          = {10.3389/fdata.2024.1469981},
  journal      = {Frontiers in Big Data},
  month        = {9},
  pages        = {1469981},
  shortjournal = {Front. Big Data},
  title        = {Prediction and classification of obesity risk based on a hybrid metaheuristic machine learning approach},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Making the most of big qualitative datasets: A living
systematic review of analysis methods. <em>FDATA</em>, <em>7</em>,
1455399. (<a href="https://doi.org/10.3389/fdata.2024.1455399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionQualitative data provides deep insights into an individual&#39;s behaviors and beliefs, and the contextual factors that may shape these. Big qualitative data analysis is an emerging field that aims to identify trends and patterns in large qualitative datasets. The purpose of this review was to identify the methods used to analyse large bodies of qualitative data, their cited strengths and limitations and comparisons between manual and digital analysis approaches.MethodsA multifaceted approach has been taken to develop the review relying on academic, gray and media-based literature, using approaches such as iterative analysis, frequency analysis, text network analysis and team discussion.ResultsThe review identified 520 articles that detailed analysis approaches of big qualitative data. From these publications a diverse range of methods and software used for analysis were identified, with thematic analysis and basic software being most common. Studies were most commonly conducted in high-income countries, and the most common data sources were open-ended survey responses, interview transcripts, and first-person narratives.DiscussionWe identified an emerging trend to expand the sources of qualitative data (e.g., using social media data, images, or videos), and develop new methods and software for analysis. As the qualitative analysis field may continue to change, it will be necessary to conduct further research to compare the utility of different big qualitative analysis methods and to develop standardized guidelines to raise awareness and support researchers in the use of more novel approaches for big qualitative analysis.Systematic review registrationhttps://osf.io/hbvsy/?view_only=.},
  archive      = {J_FDATA},
  author       = {Chandrasekar, Abinaya and Clark, Sigrún Eyrúnardóttir and Martin, Sam and Vanderslott, Samantha and Flores, Elaine C. and Aceituno, David and Barnett, Phoebe and Vindrola-Padros, Cecilia and Vera San Juan, Norha},
  doi          = {10.3389/fdata.2024.1455399},
  journal      = {Frontiers in Big Data},
  month        = {9},
  pages        = {1455399},
  shortjournal = {Front. Big Data},
  title        = {Making the most of big qualitative datasets: A living systematic review of analysis methods},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SparkDWM: A scalable design of a data washing machine using
apache spark. <em>FDATA</em>, <em>7</em>, 1446071. (<a
href="https://doi.org/10.3389/fdata.2024.1446071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data volume has been one of the fast-growing assets of most real-world applications. This increases the rate of human errors such as duplication of records, misspellings, and erroneous transpositions, among other data quality issues. Entity Resolution is an ETL process that aims to resolve data inconsistencies by ensuring entities are referring to the same real-world objects. One of the main challenges of most traditional Entity Resolution systems is ensuring their scalability to meet the rising data needs. This research aims to refactor a working proof-of-concept entity resolution system called the Data Washing Machine to be highly scalable using Apache Spark distributed data processing framework. We solve the single-threaded design problem of the legacy Data Washing Machine by using PySpark&#39;s Resilient Distributed Dataset and improve the Data Washing Machine design to use intrinsic metadata information from references. We prove that our systems achieve the same results as the legacy Data Washing Machine using 18 synthetically generated datasets. We also test the scalability of our system using a variety of real-world benchmark ER datasets from a few thousand to millions. Our experimental results show that our proposed system performs better than a MapReduce-based Data Washing Machine. We also compared our system with Famer and concluded that our system can find more clusters when given optimal starting parameters for clustering.},
  archive      = {J_FDATA},
  author       = {Hagan, Nicholas Kofi Akortia and Talburt, John R.},
  doi          = {10.3389/fdata.2024.1446071},
  journal      = {Frontiers in Big Data},
  month        = {9},
  pages        = {1446071},
  shortjournal = {Front. Big Data},
  title        = {SparkDWM: A scalable design of a data washing machine using apache spark},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). When we talk about big data, what do we really mean? Toward
a more precise definition of big data. <em>FDATA</em>, <em>7</em>,
1441869. (<a href="https://doi.org/10.3389/fdata.2024.1441869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the lack of consensus on an official definition of Big Data, research and studies have continued to progress based on this “no consensus” stance over the years. However, the lack of a clear definition and scope for Big Data results in scientific research and communication lacking a common ground. Even with the popular “V” characteristics, Big Data remains elusive. The term is broad and is used differently in research, often referring to entirely different concepts, which is rarely stated explicitly in papers. While many studies and reviews attempt to draw a comprehensive understanding of Big Data, there has been little systematic research on the position and practical implications of the term Big Data in research environments. To address this gap, this paper presents a Systematic Literature Review (SLR) on secondary studies to provide a comprehensive overview of how Big Data is used and understood across different scientific domains. Our objective was to monitor the application of the Big Data concept in science, identify which technologies are prevalent in which fields, and investigate the discrepancies between the theoretical understanding and practical usage of the term. Our study found that various Big Data technologies are being used in different scientific fields, including machine learning algorithms, distributed computing frameworks, and other tools. These manifestations of Big Data can be classified into four major categories: abstract concepts, large datasets, machine learning techniques, and the Big Data ecosystem. This study revealed that despite the general agreement on the “V” characteristics, researchers in different scientific fields have varied implicit understandings of Big Data. These implicit understandings significantly influence the content and discussions of studies involving Big Data, although they are often not explicitly stated. We call for a clearer articulation of the meaning of Big Data in research to facilitate smoother scientific communication.},
  archive      = {J_FDATA},
  author       = {Han, Xiaoyao and Gstrein, Oskar Josef and Andrikopoulos, Vasilios},
  doi          = {10.3389/fdata.2024.1441869},
  journal      = {Frontiers in Big Data},
  month        = {9},
  pages        = {1441869},
  shortjournal = {Front. Big Data},
  title        = {When we talk about big data, what do we really mean? toward a more precise definition of big data},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Current state of data stewardship tools in life science.
<em>FDATA</em>, <em>7</em>, 1428568. (<a
href="https://doi.org/10.3389/fdata.2024.1428568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today&#39;s data-centric landscape, effective data stewardship is critical for facilitating scientific research and innovation. This article provides an overview of essential tools and frameworks for modern data stewardship practices. Over 300 tools were analyzed in this study, assessing their utility, relevance to data stewardship, and applicability within the life sciences domain.},
  archive      = {J_FDATA},
  author       = {Aksenova, Anna and Johny, Anoop and Adams, Tim and Gribbon, Phil and Jacobs, Marc and Hofmann-Apitius, Martin},
  doi          = {10.3389/fdata.2024.1428568},
  journal      = {Frontiers in Big Data},
  month        = {9},
  pages        = {1428568},
  shortjournal = {Front. Big Data},
  title        = {Current state of data stewardship tools in life science},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deepfake: Definitions, performance metrics and standards,
datasets, and a meta-review. <em>FDATA</em>, <em>7</em>, 1400024. (<a
href="https://doi.org/10.3389/fdata.2024.1400024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in AI, especially deep learning, have contributed to a significant increase in the creation of new realistic-looking synthetic media (video, image, and audio) and manipulation of existing media, which has led to the creation of the new term “deepfake.” Based on both the research literature and resources in English, this paper gives a comprehensive overview of deepfake, covering multiple important aspects of this emerging concept, including (1) different definitions, (2) commonly used performance metrics and standards, and (3) deepfake-related datasets. In addition, the paper also reports a meta-review of 15 selected deepfake-related survey papers published since 2020, focusing not only on the mentioned aspects but also on the analysis of key challenges and recommendations. We believe that this paper is the most comprehensive review of deepfake in terms of the aspects covered.},
  archive      = {J_FDATA},
  author       = {Altuncu, Enes and Franqueira, Virginia N. L. and Li, Shujun},
  doi          = {10.3389/fdata.2024.1400024},
  journal      = {Frontiers in Big Data},
  month        = {9},
  pages        = {1400024},
  shortjournal = {Front. Big Data},
  title        = {Deepfake: Definitions, performance metrics and standards, datasets, and a meta-review},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven classification and explainable-AI in the field
of lung imaging. <em>FDATA</em>, <em>7</em>, 1393758. (<a
href="https://doi.org/10.3389/fdata.2024.1393758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting lung diseases in medical images can be quite challenging for radiologists. In some cases, even experienced experts may struggle with accurately diagnosing chest diseases, leading to potential inaccuracies due to complex or unseen biomarkers. This review paper delves into various datasets and machine learning techniques employed in recent research for lung disease classification, focusing on pneumonia analysis using chest X-ray images. We explore conventional machine learning methods, pretrained deep learning models, customized convolutional neural networks (CNNs), and ensemble methods. A comprehensive comparison of different classification approaches is presented, encompassing data acquisition, preprocessing, feature extraction, and classification using machine vision, machine and deep learning, and explainable-AI (XAI). Our analysis highlights the superior performance of transfer learning-based methods using CNNs and ensemble models/features for lung disease classification. In addition, our comprehensive review offers insights for researchers in other medical domains too who utilize radiological images. By providing a thorough overview of various techniques, our work enables the establishment of effective strategies and identification of suitable methods for a wide range of challenges. Currently, beyond traditional evaluation metrics, researchers emphasize the importance of XAI techniques in machine and deep learning models and their applications in classification tasks. This incorporation helps in gaining a deeper understanding of their decision-making processes, leading to improved trust, transparency, and overall clinical decision-making. Our comprehensive review serves as a valuable resource for researchers and practitioners seeking not only to advance the field of lung disease detection using machine learning and XAI but also from other diverse domains.},
  archive      = {J_FDATA},
  author       = {Shah, Syed Taimoor Hussain and Shah, Syed Adil Hussain and Khan, Iqra Iqbal and Imran, Atif and Shah, Syed Baqir Hussain and Mehmood, Atif and Qureshi, Shahzad Ahmad and Raza, Mudassar and Di Terlizzi, Angelo and Cavaglià, Marco and Deriu, Marco Agostino},
  doi          = {10.3389/fdata.2024.1393758},
  journal      = {Frontiers in Big Data},
  month        = {9},
  pages        = {1393758},
  shortjournal = {Front. Big Data},
  title        = {Data-driven classification and explainable-AI in the field of lung imaging},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Navigating pathways to automated personality prediction: A
comparative study of small and medium language models. <em>FDATA</em>,
<em>7</em>, 1387325. (<a
href="https://doi.org/10.3389/fdata.2024.1387325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionRecent advancements in Natural Language Processing (NLP) and widely available social media data have made it possible to predict human personalities in various computational applications. In this context, pre-trained Large Language Models (LLMs) have gained recognition for their exceptional performance in NLP benchmarks. However, these models require substantial computational resources, escalating their carbon and water footprint. Consequently, a shift toward more computationally efficient smaller models is observed.MethodsThis study compares a small model ALBERT (11.8M parameters) with a larger model, RoBERTa (125M parameters) in predicting big five personality traits. It utilizes the PANDORA dataset comprising Reddit comments, processing them on a Tesla P100-PCIE-16GB GPU. The study customized both models to support multi-output regression and added two linear layers for fine-grained regression analysis.ResultsResults are evaluated on Mean Squared Error (MSE) and Root Mean Squared Error (RMSE), considering the computational resources consumed during training. While ALBERT consumed lower levels of system memory with lower heat emission, it took higher computation time compared to RoBERTa. The study produced comparable levels of MSE, RMSE, and training loss reduction.DiscussionThis highlights the influence of training data quality on the model&#39;s performance, outweighing the significance of model size. Theoretical and practical implications are also discussed.},
  archive      = {J_FDATA},
  author       = {Habib, Fatima and Ali, Zeeshan and Azam, Akbar and Kamran, Komal and Pasha, Fahad Mansoor},
  doi          = {10.3389/fdata.2024.1387325},
  journal      = {Frontiers in Big Data},
  month        = {9},
  pages        = {1387325},
  shortjournal = {Front. Big Data},
  title        = {Navigating pathways to automated personality prediction: A comparative study of small and medium language models},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient use of binned data for imputing univariate time
series data. <em>FDATA</em>, <em>7</em>, 1422650. (<a
href="https://doi.org/10.3389/fdata.2024.1422650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data are recorded in various sectors, resulting in a large amount of data. However, the continuity of these data is often interrupted, resulting in periods of missing data. Several algorithms are used to impute the missing data, and the performance of these methods is widely varied. Apart from the choice of algorithm, the effective imputation depends on the nature of missing and available data. We conducted extensive studies using different types of time series data, specifically heart rate data and power consumption data. We generated the missing data for different time spans and imputed using different algorithms with binned data of different sizes. The performance was evaluated using the root mean square error (RMSE) metric. We observed a reduction in RMSE when using binned data compared to the entire dataset, particularly in the case of the expectation–maximization (EM) algorithm. We found that RMSE was reduced when using binned data for 1-, 5-, and 15-min missing data, with greater reduction observed for 15-min missing data. We also observed the effect of data fluctuation. We conclude that the usefulness of binned data depends precisely on the span of missing data, sampling frequency of the data, and fluctuation within data. Depending on the inherent characteristics, quality, and quantity of the missing and available data, binned data can impute a wide variety of data, including biological heart rate data derived from the Internet of Things (IoT) device smartwatch and non-biological data such as household power consumption data.},
  archive      = {J_FDATA},
  author       = {Darji, Jay and Biswas, Nupur and Padul, Vijay and Gill, Jaya and Kesari, Santosh and Ashili, Shashaanka},
  doi          = {10.3389/fdata.2024.1422650},
  journal      = {Frontiers in Big Data},
  month        = {8},
  pages        = {1422650},
  shortjournal = {Front. Big Data},
  title        = {Efficient use of binned data for imputing univariate time series data},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Equitable differential privacy. <em>FDATA</em>, <em>7</em>,
1420344. (<a href="https://doi.org/10.3389/fdata.2024.1420344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy (DP) has been in the public spotlight since the announcement of its use in the 2020 U.S. Census. While DP algorithms have substantially improved the confidentiality protections provided to Census respondents, concerns have been raised about the accuracy of the DP-protected Census data. The extent to which the use of DP distorts the ability to draw inferences that drive policy about small-populations, especially marginalized communities, has been of particular concern to researchers and policy makers. After all, inaccurate information about marginalized populations can often engender policies that exacerbate rather than ameliorate social inequities. Consequently, computer science experts have focused on developing mechanisms that help achieve equitable privacy, i.e., mechanisms that mitigate the data distortions introduced by privacy protections to ensure equitable outcomes and benefits for all groups, particularly marginalized groups. Our paper extends the conversation on equitable privacy by highlighting the importance of inclusive communication in ensuring equitable outcomes for all social groups through all the stages of deploying a differentially private system. We conceptualize Equitable DP as the design, communication, and implementation of DP algorithms that ensure equitable outcomes. Thus, in addition to adopting computer scientists&#39; recommendations of incorporating equity parameters within DP algorithms, we suggest that it is critical for an organization to also facilitate inclusive communication throughout the design, development, and implementation stages of a DP algorithm to ensure it has an equitable impact on social groups and does not hinder the redressal of social inequities. To demonstrate the importance of communication for Equitable DP, we undertake a case study of the process through which DP was adopted as the newest disclosure avoidance system for the 2020 U.S. Census. Drawing on the Inclusive Science Communication (ISC) framework, we examine the extent to which the Census Bureau&#39;s communication strategies encouraged engagement across the diverse groups of users that employ the decennial Census data for research and policy making. Our analysis provides lessons that can be used by other government organizations interested in incorporating the Equitable DP approach in their data collection practices.},
  archive      = {J_FDATA},
  author       = {Kaul, Vasundhara and Mukherjee, Tamalika},
  doi          = {10.3389/fdata.2024.1420344},
  journal      = {Frontiers in Big Data},
  month        = {8},
  pages        = {1420344},
  shortjournal = {Front. Big Data},
  title        = {Equitable differential privacy},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse and expandable network for google’s pathways.
<em>FDATA</em>, <em>7</em>, 1348030. (<a
href="https://doi.org/10.3389/fdata.2024.1348030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionRecently, Google introduced Pathways as its next-generation AI architecture. Pathways must address three critical challenges: learning one general model for several continuous tasks, ensuring tasks can leverage each other without forgetting old tasks, and learning from multi-modal data such as images and audio. Additionally, Pathways must maintain sparsity in both learning and deployment. Current lifelong multi-task learning approaches are inadequate in addressing these challenges.MethodsTo address these challenges, we propose SEN, a Sparse and Expandable Network. SEN is designed to handle multiple tasks concurrently by maintaining sparsity and enabling expansion when new tasks are introduced. The network leverages multi-modal data, integrating information from different sources while preventing interference between tasks.ResultsThe proposed SEN model demonstrates significant improvements in multi-task learning, successfully managing task interference and forgetting. It effectively integrates data from various modalities and maintains efficiency through sparsity during both the learning and deployment phases.DiscussionSEN offers a straightforward yet effective solution to the limitations of current lifelong multi-task learning methods. By addressing the challenges identified in the Pathways architecture, SEN provides a promising approach for developing AI systems capable of learning and adapting over time without sacrificing performance or efficiency.},
  archive      = {J_FDATA},
  author       = {Ling, Charles X. and Wang, Ganyu and Wang, Boyu},
  doi          = {10.3389/fdata.2024.1348030},
  journal      = {Frontiers in Big Data},
  month        = {8},
  pages        = {1348030},
  shortjournal = {Front. Big Data},
  title        = {Sparse and expandable network for google&#39;s pathways},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data science’s cultural construction: Qualitative ideas for
quantitative work. <em>FDATA</em>, <em>7</em>, 1287442. (<a
href="https://doi.org/10.3389/fdata.2024.1287442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction“Data scientists” quickly became ubiquitous, often infamously so, but they have struggled with the ambiguity of their novel role. This article studies data science&#39;s collective definition on Twitter.MethodsThe analysis responds to the challenges of studying an emergent case with unclear boundaries and substance through a cultural perspective and complementary datasets ranging from 1,025 to 752,815 tweets. It brings together relations between accounts that tweeted about data science, the hashtags they used, indicating purposes, and the topics they discussed.ResultsThe first results reproduce familiar commercial and technical motives. Additional results reveal concerns with new practical and ethical standards as a distinctive motive for constructing data science.DiscussionThe article provides a sensibility for local meaning in usually abstract datasets and a heuristic for navigating increasingly abundant datasets toward surprising insights. For data scientists, it offers a guide for positioning themselves vis-à-vis others to navigate their professional future.},
  archive      = {J_FDATA},
  author       = {Brandt, Philipp},
  doi          = {10.3389/fdata.2024.1287442},
  journal      = {Frontiers in Big Data},
  month        = {8},
  pages        = {1287442},
  shortjournal = {Front. Big Data},
  title        = {Data science&#39;s cultural construction: Qualitative ideas for quantitative work},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global explanation supervision for graph neural networks.
<em>FDATA</em>, <em>7</em>, 1410424. (<a
href="https://doi.org/10.3389/fdata.2024.1410424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of Graph Neural Networks (GNNs) for predictive tasks on graph structured data, research on their explainability is becoming more critical and achieving significant progress. Although many methods are proposed to explain the predictions of GNNs, their focus is mainly on “how to generate explanations.” However, other important research questions like “whether the GNN explanations are inaccurate,” “what if the explanations are inaccurate,” and “how to adjust the model to generate more accurate explanations” have gained little attention. Our previous GNN Explanation Supervision (GNES) framework demonstrated effectiveness on improving the reasonability of the local explanation while still keep or even improve the backbone GNNs model performance. In many applications instead of per sample explanations, we need to find global explanations which are reasonable and faithful to the domain data. Simply learning to explain GNNs locally is not an optimal solution to a global understanding of the model. To improve the explainability power of the GNES framework, we propose the Global GNN Explanation Supervision (GGNES) technique which uses a basic trained GNN and a global extension of the loss function used in the GNES framework. This GNN creates local explanations which are fed to a Global Logic-based GNN Explainer, an existing technique that can learn the global Explanation in terms of a logic formula. These two frameworks are then trained iteratively to generate reasonable global explanations. Extensive experiments demonstrate the effectiveness of the proposed model on improving the global explanations while keeping the performance similar or even increase the model prediction power.},
  archive      = {J_FDATA},
  author       = {Etemadyrad, Negar and Gao, Yuyang and Manoj Pudukotai Dinakarrao, Sai and Zhao, Liang},
  doi          = {10.3389/fdata.2024.1410424},
  journal      = {Frontiers in Big Data},
  month        = {7},
  pages        = {1410424},
  shortjournal = {Front. Big Data},
  title        = {Global explanation supervision for graph neural networks},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Random kernel k-nearest neighbors regression.
<em>FDATA</em>, <em>7</em>, 1402384. (<a
href="https://doi.org/10.3389/fdata.2024.1402384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k-nearest neighbors (KNN) regression method, known for its nonparametric nature, is highly valued for its simplicity and its effectiveness in handling complex structured data, particularly in big data contexts. However, this method is susceptible to overfitting and fit discontinuity, which present significant challenges. This paper introduces the random kernel k-nearest neighbors (RK-KNN) regression as a novel approach that is well-suited for big data applications. It integrates kernel smoothing with bootstrap sampling to enhance prediction accuracy and the robustness of the model. This method aggregates multiple predictions using random sampling from the training dataset and selects subsets of input variables for kernel KNN (K-KNN). A comprehensive evaluation of RK-KNN on 15 diverse datasets, employing various kernel functions including Gaussian and Epanechnikov, demonstrates its superior performance. When compared to standard KNN and the random KNN (R-KNN) models, it significantly reduces the root mean square error (RMSE) and mean absolute error, as well as improving R-squared values. The RK-KNN variant that employs a specific kernel function yielding the lowest RMSE will be benchmarked against state-of-the-art methods, including support vector regression, artificial neural networks, and random forests.},
  archive      = {J_FDATA},
  author       = {Srisuradetchai, Patchanok and Suksrikran, Korn},
  doi          = {10.3389/fdata.2024.1402384},
  journal      = {Frontiers in Big Data},
  month        = {7},
  pages        = {1402384},
  shortjournal = {Front. Big Data},
  title        = {Random kernel k-nearest neighbors regression},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient enhancement of low-rank tensor completion via thin
QR decomposition. <em>FDATA</em>, <em>7</em>, 1382144. (<a
href="https://doi.org/10.3389/fdata.2024.1382144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rank tensor completion (LRTC), which aims to complete missing entries from tensors with partially observed terms by utilizing the low-rank structure of tensors, has been widely used in various real-world issues. The core tensor nuclear norm minimization (CTNM) method based on Tucker decomposition is one of common LRTC methods. However, the CTNM methods based on Tucker decomposition often have a large computing cost due to the fact that the general factor matrix solving technique involves multiple singular value decompositions (SVDs) in each loop. To address this problem, this article enhances the method and proposes an effective CTNM method based on thin QR decomposition (CTNM-QR) with lower computing complexity. The proposed method extends the CTNM by introducing tensor versions of the auxiliary variables instead of matrices, while using the thin QR decomposition to solve the factor matrix rather than the SVD, which can save the computational complexity and improve the tensor completion accuracy. In addition, the CTNM-QR method&#39;s convergence and complexity are analyzed further. Numerous experiments in synthetic data, real color images, and brain MRI data at different missing rates demonstrate that the proposed method not only outperforms in terms of completion accuracy and visualization, but also conducts more efficiently than most state-of-the-art LRTC methods.},
  archive      = {J_FDATA},
  author       = {Wu, Yan and Jin, Yunzhi},
  doi          = {10.3389/fdata.2024.1382144},
  journal      = {Frontiers in Big Data},
  month        = {7},
  pages        = {1382144},
  shortjournal = {Front. Big Data},
  title        = {Efficient enhancement of low-rank tensor completion via thin QR decomposition},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real driving cycles and emissions for urban freight
transport. <em>FDATA</em>, <em>7</em>, 1375455. (<a
href="https://doi.org/10.3389/fdata.2024.1375455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to evaluate the driving style effects, through the construction of driving cycles, on the polluting gases, in the context of urban freight transportation. For this, the method used was the construction of cycles through the Vehicle Specific Power (VSP) parameter, which considers instantaneous vehicle and road parameters better to represent driving patterns and freight transportation&#39;s environmental impacts. The study was conducted in Fortaleza city, Ceará, Brazil, with a professional driver&#39;s group. The road types, land use and traffic light location were considered to analyze and discuss the results. The results show collector roads presented higher speeds than arterial roads, and the use of the land around the road also directly impacted vehicle driving patterns. Regarding CO2 emissions, higher concentrations measured were observed on the arterial roads.},
  archive      = {J_FDATA},
  author       = {Azevedo, Julie Anne Holanda and Cassiano, Demostenis Ramos and Bertoncini, Bruno Vieira},
  doi          = {10.3389/fdata.2024.1375455},
  journal      = {Frontiers in Big Data},
  month        = {7},
  pages        = {1375455},
  shortjournal = {Front. Big Data},
  title        = {Real driving cycles and emissions for urban freight transport},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The development and application of a novel e-commerce
recommendation system used in electric power B2B sector. <em>FDATA</em>,
<em>7</em>, 1374980. (<a
href="https://doi.org/10.3389/fdata.2024.1374980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of the digital era has transformed E-commerce platforms into critical tools for industry, yet traditional recommendation systems often fall short in the specialized context of the electric power industry. These systems typically struggle with the industry&#39;s unique challenges, such as infrequent and high-stakes transactions, prolonged decision-making processes, and sparse data. This research has developed a novel recommendation engine tailored to these specific conditions, such as to handle the low frequency and long cycle nature of Business-to-Business (B2B) transactions. This approach includes algorithmic enhancements to better process and interpret the limited data available, and data pre-processing techniques designed to enrich the sparse datasets characteristic of this industry. This research also introduces a methodological innovation that integrates multi-dimensional data, combining user E-commerce activities, product specifics, and essential non-tendering information. The proposed engine employs advanced machine learning techniques to provide more accurate and relevant recommendations. The results demonstrate a marked improvement over traditional models, offering a more robust and effective tool for facilitating B2B transactions in the electric power industry. This research not only addresses the sector&#39;s unique challenges but also provides a blueprint for adapting recommendation systems to other industries with similar B2B characteristics.},
  archive      = {J_FDATA},
  author       = {Meng, Wenjun and Chen, Lili and Dong, Zhaomin},
  doi          = {10.3389/fdata.2024.1374980},
  journal      = {Frontiers in Big Data},
  month        = {7},
  pages        = {1374980},
  shortjournal = {Front. Big Data},
  title        = {The development and application of a novel E-commerce recommendation system used in electric power B2B sector},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Technologies and main functionalities of the telemonitoring
application reCOVeryaID. <em>FDATA</em>, <em>7</em>, 1360092. (<a
href="https://doi.org/10.3389/fdata.2024.1360092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has highlighted the need to take advantage of specific and effective patient telemonitoring platforms, with specific reference to the constant monitoring of vital parameters of patients most at risk. Among the various applications developed in Italy, certainly there is reCOVeryaID, a web application aimed at remotely monitoring patients potentially, currently or no longer infected with COVID-19. Therefore, in this paper we present a system model, consisting of a multi-platform intelligent telemonitoring application, that enables remote monitoring and provision of integrated home care to both patients symptomatic, asymptomatic and pre-symptomatic with severe acute respiratory infectious disease or syndrome caused by viruses belonging to the Coronavirus family, as well as simply to people with respiratory problems and/or related diseases (chronic obstructive pulmonary disease or asthma). In fact, in this paper we focus on exposing the technologies and various functionalities offered by the system, which constitute the practical implementation of the theoretical framework described in detail in another paper. Specifically, the reCOVeryaID telemonitoring application is a stand-alone, knowledge base-supported application that can promptly react and inform physicians if dangerous trends in a patient&#39;s short- and long-term vital signs are detected, thus enabling them to be monitored continuously, both in the hospital and at home. The paper also reports an evaluation of user satisfaction, carried out by actual patients and medical doctors.},
  archive      = {J_FDATA},
  author       = {D&#39;Auria, Daniela and Bettini, Fabio and Tognarelli, Selene and Calvanese, Diego and Menciassi, Arianna},
  doi          = {10.3389/fdata.2024.1360092},
  journal      = {Frontiers in Big Data},
  month        = {7},
  pages        = {1360092},
  shortjournal = {Front. Big Data},
  title        = {Technologies and main functionalities of the telemonitoring application reCOVeryaID},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond surveillance: Privacy, ethics, and regulations in
face recognition technology. <em>FDATA</em>, <em>7</em>, 1337465. (<a
href="https://doi.org/10.3389/fdata.2024.1337465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial recognition technology (FRT) has emerged as a powerful tool for public governance and security, but its rapid adoption has also raised significant concerns about privacy, civil liberties, and ethical implications. This paper critically examines the current rules and policies governing FRT, highlighting the tensions between state and corporate interests on one hand, and individual rights and ethical considerations on the other. The study also investigates international legal frameworks aimed at protecting individual rights and privacy, arguing that current legislative measures often fall short of robust scholarly standards and international human rights norms. The paper concludes with recommendations for developing principled and adaptable governance frameworks that harness the benefits of FRT while mitigating its risks and negative impacts, underscoring the importance of placing human rights and ethics at the center of regulating this transformative technology.},
  archive      = {J_FDATA},
  author       = {Wang, Xukang and Wu, Ying Cheng and Zhou, Mengjie and Fu, Hongpeng},
  doi          = {10.3389/fdata.2024.1337465},
  journal      = {Frontiers in Big Data},
  month        = {7},
  pages        = {1337465},
  shortjournal = {Front. Big Data},
  title        = {Beyond surveillance: Privacy, ethics, and regulations in face recognition technology},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). YOLOv8’s advancements in tuberculosis identification from
chest images. <em>FDATA</em>, <em>7</em>, 1401981. (<a
href="https://doi.org/10.3389/fdata.2024.1401981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tuberculosis (TB) is a chronic and pathogenic disease that leads to life-threatening situations like death. Many people have been affected by TB owing to inaccuracy, late diagnosis, and deficiency of treatment. The early detection of TB is important to protect people from the severity of the disease and its threatening consequences. Traditionally, different manual methods have been used for TB prediction, such as chest X-rays and CT scans. Nevertheless, these approaches are identified as time-consuming and ineffective for achieving optimal results. To resolve this problem, several researchers have focused on TB prediction. Conversely, it results in a lack of accuracy, overfitting of data, and speed. For improving TB prediction, the proposed research employs the Selection Focal Fusion (SFF) block in the You Look Only Once v8 (YOLOv8, Ultralytics software company, Los Angeles, United States) object detection model with attention mechanism through the Kaggle TBX-11k dataset. The YOLOv8 is used for its ability to detect multiple objects in a single pass. However, it struggles with small objects and finds it impossible to perform fine-grained classifications. To evade this problem, the proposed research incorporates the SFF technique to improve detection performance and decrease small object missed detection rates. Correspondingly, the efficacy of the projected mechanism is calculated utilizing various performance metrics such as recall, precision, F1Score, and mean Average Precision (mAP) to estimate the performance of the proposed framework. Furthermore, the comparison of existing models reveals the efficiency of the proposed research. The present research is envisioned to contribute to the medical world and assist radiologists in identifying tuberculosis using the YOLOv8 model to obtain an optimal outcome.},
  archive      = {J_FDATA},
  author       = {Parveen Rahamathulla, Mohamudha and Sam Emmanuel, W. R. and Bindhu, A. and Mustaq Ahmed, Mohamed},
  doi          = {10.3389/fdata.2024.1401981},
  journal      = {Frontiers in Big Data},
  month        = {6},
  pages        = {1401981},
  shortjournal = {Front. Big Data},
  title        = {YOLOv8&#39;s advancements in tuberculosis identification from chest images},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unilateral boundary time series forecasting. <em>FDATA</em>,
<em>7</em>, 1376023. (<a
href="https://doi.org/10.3389/fdata.2024.1376023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is an essential tool across numerous domains, yet traditional models often falter when faced with unilateral boundary conditions, where data is systematically overestimated or underestimated. This paper introduces a novel approach to the task of unilateral boundary time series forecasting. Our research bridges the gap in existing methods by proposing a specialized framework to accurately forecast within these skewed datasets. The cornerstone of our approach is the unilateral mean square error (UMSE), an asymmetric loss function that strategically addresses underestimation biases in training data, improving the precision of forecasts. We further enhance model performance through the implementation of a dual model structure that processes underestimated and accurately estimated data points separately, allowing for a nuanced analysis of the data trends. Additionally, feature reconstruction is employed to recapture obscured dynamics, ensuring a comprehensive understanding of the data. We demonstrate the effectiveness of our methods through extensive experimentation with LightGBM and GRU models across diverse datasets, showcasing superior accuracy and robustness in comparison to traditional models and existing methods. Our findings not only validate the efficacy of our approach but also reveal its model-independence and broad applicability. This work lays the groundwork for future research in this domain, opening new avenues for sophisticated analytical models in various industries where precise time series forecasting is crucial.},
  archive      = {J_FDATA},
  author       = {Chang, Chao-Min and Li, Cheng-Te and Lin, Shou-De},
  doi          = {10.3389/fdata.2024.1376023},
  journal      = {Frontiers in Big Data},
  month        = {6},
  pages        = {1376023},
  shortjournal = {Front. Big Data},
  title        = {Unilateral boundary time series forecasting},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MedT5SQL: A transformers-based large language model for
text-to-SQL conversion in the healthcare domain. <em>FDATA</em>,
<em>7</em>, 1371680. (<a
href="https://doi.org/10.3389/fdata.2024.1371680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionIn response to the increasing prevalence of electronic medical records (EMRs) stored in databases, healthcare staff are encountering difficulties retrieving these records due to their limited technical expertise in database operations. As these records are crucial for delivering appropriate medical care, there is a need for an accessible method for healthcare staff to access EMRs.MethodsTo address this, natural language processing (NLP) for Text-to-SQL has emerged as a solution, enabling non-technical users to generate SQL queries using natural language text. This research assesses existing work on Text-to-SQL conversion and proposes the MedT5SQL model specifically designed for EMR retrieval. The proposed model utilizes the Text-to-Text Transfer Transformer (T5) model, a Large Language Model (LLM) commonly used in various text-based NLP tasks. The model is fine-tuned on the MIMICSQL dataset, the first Text-to-SQL dataset for the healthcare domain. Performance evaluation involves benchmarking the MedT5SQL model on two optimizers, varying numbers of training epochs, and using two datasets, MIMICSQL and WikiSQL.ResultsFor MIMICSQL dataset, the model demonstrates considerable effectiveness in generating question-SQL pairs achieving accuracy of 80.63%, 98.937%, and 90% for exact match accuracy matrix, approximate string-matching, and manual evaluation, respectively. When testing the performance of the model on WikiSQL dataset, the model demonstrates efficiency in generating SQL queries, with an accuracy of 44.2% on WikiSQL and 94.26% for approximate string-matching.DiscussionResults indicate improved performance with increased training epochs. This work highlights the potential of fine-tuned T5 model to convert medical-related questions written in natural language to Structured Query Language (SQL) in healthcare domain, providing a foundation for future research in this area.},
  archive      = {J_FDATA},
  author       = {Marshan, Alaa and Almutairi, Anwar Nais and Ioannou, Athina and Bell, David and Monaghan, Asmat and Arzoky, Mahir},
  doi          = {10.3389/fdata.2024.1371680},
  journal      = {Frontiers in Big Data},
  month        = {6},
  pages        = {1371680},
  shortjournal = {Front. Big Data},
  title        = {MedT5SQL: A transformers-based large language model for text-to-SQL conversion in the healthcare domain},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An encoding framework for binarized images using
hyperdimensional computing. <em>FDATA</em>, <em>7</em>, 1371518. (<a
href="https://doi.org/10.3389/fdata.2024.1371518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionHyperdimensional Computing (HDC) is a brain-inspired and lightweight machine learning method. It has received significant attention in the literature as a candidate to be applied in the wearable Internet of Things, near-sensor artificial intelligence applications, and on-device processing. HDC is computationally less complex than traditional deep learning algorithms and typically achieves moderate to good classification performance. A key aspect that determines the performance of HDC is encoding the input data to the hyperdimensional (HD) space.MethodsThis article proposes a novel lightweight approach relying only on native HD arithmetic vector operations to encode binarized images that preserves the similarity of patterns at nearby locations by using point of interest selection and local linear mapping.ResultsThe method reaches an accuracy of 97.92% on the test set for the MNIST data set and 84.62% for the Fashion-MNIST data set.DiscussionThese results outperform other studies using native HDC with different encoding approaches and are on par with more complex hybrid HDC models and lightweight binarized neural networks. The proposed encoding approach also demonstrates higher robustness to noise and blur compared to the baseline encoding.},
  archive      = {J_FDATA},
  author       = {Smets, Laura and Van Leekwijck, Werner and Tsang, Ing Jyh and Latré, Steven},
  doi          = {10.3389/fdata.2024.1371518},
  journal      = {Frontiers in Big Data},
  month        = {6},
  pages        = {1371518},
  shortjournal = {Front. Big Data},
  title        = {An encoding framework for binarized images using hyperdimensional computing},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward the design of persuasive systems for a healthy
workplace: A real-time posture detection. <em>FDATA</em>, <em>7</em>,
1359906. (<a href="https://doi.org/10.3389/fdata.2024.1359906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persuasive technologies, in connection with human factor engineering requirements for healthy workplaces, have played a significant role in ensuring a change in human behavior. Healthy workplaces suggest different best practices applicable to body posture, proximity to the computer system, movement, lighting conditions, computer system layout, and other significant psychological and cognitive aspects. Most importantly, body posture suggests how users should sit or stand in workplaces in line with best and healthy practices. In this study, we developed two study phases (pilot and main) using two deep learning models: convolutional neural networks (CNN) and Yolo-V3. To train the two models, we collected posture datasets from creative common license YouTube videos and Kaggle. We classified the dataset into comfortable and uncomfortable postures. Results show that our YOLO-V3 model outperformed CNN model with a mean average precision of 92%. Based on this finding, we recommend that YOLO-V3 model be integrated in the design of persuasive technologies for a healthy workplace. Additionally, we provide future implications for integrating proximity detection taking into consideration the ideal number of centimeters users should maintain in a healthy workplace.},
  archive      = {J_FDATA},
  author       = {Ataguba, Grace and Orji, Rita},
  doi          = {10.3389/fdata.2024.1359906},
  journal      = {Frontiers in Big Data},
  month        = {6},
  pages        = {1359906},
  shortjournal = {Front. Big Data},
  title        = {Toward the design of persuasive systems for a healthy workplace: A real-time posture detection},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Source-free domain adaptation for semantic image
segmentation using internal representations. <em>FDATA</em>, <em>7</em>,
1359317. (<a href="https://doi.org/10.3389/fdata.2024.1359317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation models trained on annotated data fail to generalize well when the input data distribution changes over extended time period, leading to requiring re-training to maintain performance. Classic unsupervised domain adaptation (UDA) attempts to address a similar problem when there is target domain with no annotated data points through transferring knowledge from a source domain with annotated data. We develop an online UDA algorithm for semantic segmentation of images that improves model generalization on unannotated domains in scenarios where source data access is restricted during adaptation. We perform model adaptation by minimizing the distributional distance between the source latent features and the target features in a shared embedding space. Our solution promotes a shared domain-agnostic latent feature space between the two domains, which allows for classifier generalization on the target dataset. To alleviate the need of access to source samples during adaptation, we approximate the source latent feature distribution via an appropriate surrogate distribution, in this case a Gaussian mixture model (GMM).},
  archive      = {J_FDATA},
  author       = {Stan, Serban and Rostami, Mohammad},
  doi          = {10.3389/fdata.2024.1359317},
  journal      = {Frontiers in Big Data},
  month        = {6},
  pages        = {1359317},
  shortjournal = {Front. Big Data},
  title        = {Source-free domain adaptation for semantic image segmentation using internal representations},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Facial recognition technology: Regulations, rights and the
rule of law. <em>FDATA</em>, <em>7</em>, 1354659. (<a
href="https://doi.org/10.3389/fdata.2024.1354659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite their pronounced potential, unacceptable risk AI systems, such as facial recognition, have been used as tools for, inter alia, digital surveillance, and policing. This usage raises concerns in relation to the protection of basic freedoms and liberties and upholding the rule of law. This article contributes to the legal discussion by investigating how the law must intervene, control, and regulate the use of unacceptable risk AI systems that concern biometric data from a human-rights and rule of law perspective. In doing so, the article first examines the collection of biometric data and the use of facial recognition technology. Second, it describes the nature of the obligation or duty of states to regulate in relation to new technologies. The article, lastly, assesses the legal implications resulting from the failure of states to regulate new technologies and investigates possible legal remedies. The article uses some relevant EU regulations as an illustrative example.},
  archive      = {J_FDATA},
  author       = {Qandeel, Mais},
  doi          = {10.3389/fdata.2024.1354659},
  journal      = {Frontiers in Big Data},
  month        = {6},
  pages        = {1354659},
  shortjournal = {Front. Big Data},
  title        = {Facial recognition technology: Regulations, rights and the rule of law},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Particulate matter forecast and prediction in curitiba using
machine learning. <em>FDATA</em>, <em>7</em>, 1412837. (<a
href="https://doi.org/10.3389/fdata.2024.1412837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAir quality is directly affected by pollutant emission from vehicles, especially in large cities and metropolitan areas or when there is no compliance check for vehicle emission standards. Particulate Matter (PM) is one of the pollutants emitted from fuel burning in internal combustion engines and remains suspended in the atmosphere, causing respiratory and cardiovascular health problems to the population. In this study, we analyzed the interaction between vehicular emissions, meteorological variables, and particulate matter concentrations in the lower atmosphere, presenting methods for predicting and forecasting PM2.5.MethodsMeteorological and vehicle flow data from the city of Curitiba, Brazil, and particulate matter concentration data from optical sensors installed in the city between 2020 and 2022 were organized in hourly and daily averages. Prediction and forecasting were based on two machine learning models: Random Forest (RF) and Long Short-Term Memory (LSTM) neural network. The baseline model for prediction was chosen as the Multiple Linear Regression (MLR) model, and for forecast, we used the naive estimation as baseline.ResultsRF showed that on hourly and daily prediction scales, the planetary boundary layer height was the most important variable, followed by wind gust and wind velocity in hourly or daily cases, respectively. The highest PM prediction accuracy (99.37%) was found using the RF model on a daily scale. For forecasting, the highest accuracy was 99.71% using the LSTM model for 1-h forecast horizon with 5 h of previous data used as input variables.DiscussionThe RF and LSTM models were able to improve prediction and forecasting compared with MLR and Naive, respectively. The LSTM was trained with data corresponding to the period of the COVID-19 pandemic (2020 and 2021) and was able to forecast the concentration of PM2.5 in 2022, in which the data show that there was greater circulation of vehicles and higher peaks in the concentration of PM2.5. Our results can help the physical understanding of factors influencing pollutant dispersion from vehicle emissions at the lower atmosphere in urban environment. This study supports the formulation of new government policies to mitigate the impact of vehicle emissions in large cities.},
  archive      = {J_FDATA},
  author       = {Chaves, Marianna Gonçalves Dias and da Silva, Adriel Bilharva and Mercuri, Emílio Graciliano Ferreira and Noe, Steffen Manfred},
  doi          = {10.3389/fdata.2024.1412837},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1412837},
  shortjournal = {Front. Big Data},
  title        = {Particulate matter forecast and prediction in curitiba using machine learning},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A time-robust group recommender for featured comments on
news platforms. <em>FDATA</em>, <em>7</em>, 1399739. (<a
href="https://doi.org/10.3389/fdata.2024.1399739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionRecently, content moderators on news platforms face the challenging task to select high-quality comments to feature on the webpage, a manual and time-consuming task exacerbated by platform growth. This paper introduces a group recommender system based on classifiers to aid moderators in this selection process.MethodsUtilizing data from a Dutch news platform, we demonstrate that integrating comment data with user history and contextual relevance yields high ranking scores. To evaluate our models, we created realistic evaluation scenarios based on unseen online discussions from both 2020 and 2023, replicating changing news cycles and platform growth.ResultsWe demonstrate that our best-performing models maintain their ranking performance even when article topics change, achieving an optimum mean NDCG@5 of 0.89.DiscussionThe expert evaluation by platform-employed moderators underscores the subjectivity inherent in moderation practices, emphasizing the value of recommending comments over classification. Our research contributes to the advancement of (semi-)automated content moderation and the understanding of deliberation quality assessment in online discourse.},
  archive      = {J_FDATA},
  author       = {Waterschoot, Cedric and van den Bosch, Antal},
  doi          = {10.3389/fdata.2024.1399739},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1399739},
  shortjournal = {Front. Big Data},
  title        = {A time-robust group recommender for featured comments on news platforms},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantifying uncertainty in graph neural network
explanations. <em>FDATA</em>, <em>7</em>, 1392662. (<a
href="https://doi.org/10.3389/fdata.2024.1392662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, analyzing the explanation for the prediction of Graph Neural Networks (GNNs) has attracted increasing attention. Despite this progress, most existing methods do not adequately consider the inherent uncertainties stemming from the randomness of model parameters and graph data, which may lead to overconfidence and misguiding explanations. However, it is challenging for most of GNN explanation methods to quantify these uncertainties since they obtain the prediction explanation in a post-hoc and model-agnostic manner without considering the randomness of graph data and model parameters. To address the above problems, this paper proposes a novel uncertainty quantification framework for GNN explanations. For mitigating the randomness of graph data in the explanation, our framework accounts for two distinct data uncertainties, allowing for a direct assessment of the uncertainty in GNN explanations. For mitigating the randomness of learned model parameters, our method learns the parameter distribution directly from the data, obviating the need for assumptions about specific distributions. Moreover, the explanation uncertainty within model parameters is also quantified based on the learned parameter distributions. This holistic approach can integrate with any post-hoc GNN explanation methods. Empirical results from our study show that our proposed method sets a new standard for GNN explanation performance across diverse real-world graph benchmarks.},
  archive      = {J_FDATA},
  author       = {Jiang, Junji and Ling, Chen and Li, Hongyi and Bai, Guangji and Zhao, Xujiang and Zhao, Liang},
  doi          = {10.3389/fdata.2024.1392662},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1392662},
  shortjournal = {Front. Big Data},
  title        = {Quantifying uncertainty in graph neural network explanations},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Big data and its impact on the 3Rs: A home cage monitoring
oriented review. <em>FDATA</em>, <em>7</em>, 1390467. (<a
href="https://doi.org/10.3389/fdata.2024.1390467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Undisturbed home cage recording of mouse activity and behavior has received increasing attention in recent years. In parallel, several technologies have been developed in a bid to automate data collection and interpretation. Thanks to these expanding technologies, massive datasets can be recorded and saved in the long term, providing a wealth of information concerning animal wellbeing, clinical status, baseline activity, and subsequent deviations in case of experimental interventions. Such large datasets can also serve as a long-term reservoir of scientific data that can be reanalyzed and repurposed upon need. In this review, we present how the impact of Big Data deriving from home cage monitoring (HCM) data acquisition, particularly through Digital Ventilated Cages (DVCs), can support the application of the 3Rs by enhancing Refinement, Reduction, and even Replacement of research in animals.},
  archive      = {J_FDATA},
  author       = {Fuochi, Sara and Rigamonti, Mara and O&#39;Connor, Eoin C. and De Girolamo, Paolo and D&#39;Angelo, Livia},
  doi          = {10.3389/fdata.2024.1390467},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1390467},
  shortjournal = {Front. Big Data},
  title        = {Big data and its impact on the 3Rs: A home cage monitoring oriented review},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic literature review on the impact of AI models on
the security of code generation. <em>FDATA</em>, <em>7</em>, 1386720.
(<a href="https://doi.org/10.3389/fdata.2024.1386720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionArtificial Intelligence (AI) is increasingly used as a helper to develop computing programs. While it can boost software development and improve coding proficiency, this practice offers no guarantee of security. On the contrary, recent research shows that some AI models produce software with vulnerabilities. This situation leads to the question: How serious and widespread are the security flaws in code generated using AI models?MethodsThrough a systematic literature review, this work reviews the state of the art on how AI models impact software security. It systematizes the knowledge about the risks of using AI in coding security-critical software.ResultsIt reviews what security flaws of well-known vulnerabilities (e.g., the MITRE CWE Top 25 Most Dangerous Software Weaknesses) are commonly hidden in AI-generated code. It also reviews works that discuss how vulnerabilities in AI-generated code can be exploited to compromise security and lists the attempts to improve the security of such AI-generated code.DiscussionOverall, this work provides a comprehensive and systematic overview of the impact of AI in secure coding. This topic has sparked interest and concern within the software security engineering community. It highlights the importance of setting up security measures and processes, such as code verification, and that such practices could be customized for AI-aided code production.},
  archive      = {J_FDATA},
  author       = {Negri-Ribalta, Claudia and Geraud-Stewart, Rémi and Sergeeva, Anastasia and Lenzini, Gabriele},
  doi          = {10.3389/fdata.2024.1386720},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1386720},
  shortjournal = {Front. Big Data},
  title        = {A systematic literature review on the impact of AI models on the security of code generation},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tradescantia response to air and soil pollution, stamen hair
cells dataset and ANN color classification. <em>FDATA</em>, <em>7</em>,
1384240. (<a href="https://doi.org/10.3389/fdata.2024.1384240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tradescantia plant is a complex system that is sensible to environmental factors such as water supply, pH, temperature, light, radiation, impurities, and nutrient availability. It can be used as a biomonitor for environmental changes; however, the bioassays are time-consuming and have a strong human interference factor that might change the result depending on who is performing the analysis. We have developed computer vision models to study color variations from Tradescantia clone 4430 plant stamen hair cells, which can be stressed due to air pollution and soil contamination. The study introduces a novel dataset, Trad-204, comprising single-cell images from Tradescantia clone 4430, captured during the Tradescantia stamen-hair mutation bioassay (Trad-SHM). The dataset contain images from two experiments, one focusing on air pollution by particulate matter and another based on soil contaminated by diesel oil. Both experiments were carried out in Curitiba, Brazil, between 2020 and 2023. The images represent single cells with different shapes, sizes, and colors, reflecting the plant&#39;s responses to environmental stressors. An automatic classification task was developed to distinguishing between blue and pink cells, and the study explores both a baseline model and three artificial neural network (ANN) architectures, namely, TinyVGG, VGG-16, and ResNet34. Tradescantia revealed sensibility to both air particulate matter concentration and diesel oil in soil. The results indicate that Residual Network architecture outperforms the other models in terms of accuracy on both training and testing sets. The dataset and findings contribute to the understanding of plant cell responses to environmental stress and provide valuable resources for further research in automated image analysis of plant cells. Discussion highlights the impact of turgor pressure on cell shape and the potential implications for plant physiology. The comparison between ANN architectures aligns with previous research, emphasizing the superior performance of ResNet models in image classification tasks. Artificial intelligence identification of pink cells improves the counting accuracy, thus avoiding human errors due to different color perceptions, fatigue, or inattention, in addition to facilitating and speeding up the analysis process. Overall, the study offers insights into plant cell dynamics and provides a foundation for future investigations like cells morphology change. This research corroborates that biomonitoring should be considered as an important tool for political actions, being a relevant issue in risk assessment and the development of new public policies relating to the environment.},
  archive      = {J_FDATA},
  author       = {Rodrigues, Leatrice Talita and Goeldner, Barbara Sanches Antunes and Mercuri, Emílio Graciliano Ferreira and Noe, Steffen Manfred},
  doi          = {10.3389/fdata.2024.1384240},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1384240},
  shortjournal = {Front. Big Data},
  title        = {Tradescantia response to air and soil pollution, stamen hair cells dataset and ANN color classification},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Challenges and efforts in managing AI trustworthiness risks:
A state of knowledge. <em>FDATA</em>, <em>7</em>, 1381163. (<a
href="https://doi.org/10.3389/fdata.2024.1381163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the critical gaps in existing AI risk management frameworks, emphasizing the neglect of human factors and the absence of metrics for socially related or human threats. Drawing from insights provided by NIST AI RFM and ENISA, the research underscores the need for understanding the limitations of human-AI interaction and the development of ethical and social measurements. The paper explores various dimensions of trustworthiness, covering legislation, AI cyber threat intelligence, and characteristics of AI adversaries. It delves into technical threats and vulnerabilities, including data access, poisoning, and backdoors, highlighting the importance of collaboration between cybersecurity engineers, AI experts, and social-psychology-behavior-ethics professionals. Furthermore, the socio-psychological threats associated with AI integration into society are examined, addressing issues such as bias, misinformation, and privacy erosion. The manuscript proposes a comprehensive approach to AI trustworthiness, combining technical and social mitigation measures, standards, and ongoing research initiatives. Additionally, it introduces innovative defense strategies, such as cyber-social exercises, digital clones, and conversational agents, to enhance understanding of adversary profiles and fortify AI security. The paper concludes with a call for interdisciplinary collaboration, awareness campaigns, and continuous research efforts to create a robust and resilient AI ecosystem aligned with ethical standards and societal expectations.},
  archive      = {J_FDATA},
  author       = {Polemi, Nineta and Praça, Isabel and Kioskli, Kitty and Bécue, Adrien},
  doi          = {10.3389/fdata.2024.1381163},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1381163},
  shortjournal = {Front. Big Data},
  title        = {Challenges and efforts in managing AI trustworthiness risks: A state of knowledge},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From theory to practice: Insights and hurdles in collecting
social media data for social science research. <em>FDATA</em>,
<em>7</em>, 1379921. (<a
href="https://doi.org/10.3389/fdata.2024.1379921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media has profoundly changed our modes of self-expression, communication, and participation in public discourse, generating volumes of conversations and content that cover every aspect of our social lives. Social media platforms have thus become increasingly important as data sources to identify social trends and phenomena. In recent years, academics have steadily lost ground on access to social media data as technology companies have set more restrictions on Application Programming Interfaces (APIs) or entirely closed public APIs. This circumstance halts the work of many social scientists who have used such data to study issues of public good. We considered the viability of eight approaches for image-based social media data collection: data philanthropy organizations, data repositories, data donation, third-party data companies, homegrown tools, and various web scraping tools and scripts. This paper discusses the advantages and challenges of these approaches from literature and from the authors&#39; experience. We conclude the paper by discussing mechanisms for improving social media data collection that will enable this future frontier of social science research.},
  archive      = {J_FDATA},
  author       = {Chen, Yan and Sherren, Kate and Lee, Kyung Young and McCay-Peet, Lori and Xue, Shan and Smit, Michael},
  doi          = {10.3389/fdata.2024.1379921},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1379921},
  shortjournal = {Front. Big Data},
  title        = {From theory to practice: Insights and hurdles in collecting social media data for social science research},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive investigation of clustering algorithms for
user and entity behavior analytics. <em>FDATA</em>, <em>7</em>, 1375818.
(<a href="https://doi.org/10.3389/fdata.2024.1375818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionGovernment agencies are now encouraging industries to enhance their security systems to detect and respond proactively to cybersecurity incidents. Consequently, equipping with a security operation center that combines the analytical capabilities of human experts with systems based on Machine Learning (ML) plays a critical role. In this setting, Security Information and Event Management (SIEM) platforms can effectively handle network-related events to trigger cybersecurity alerts. Furthermore, a SIEM may include a User and Entity Behavior Analytics (UEBA) engine that examines the behavior of both users and devices, or entities, within a corporate network.MethodsIn recent literature, several contributions have employed ML algorithms for UEBA, especially those based on the unsupervised learning paradigm, because anomalous behaviors are usually not known in advance. However, to shorten the gap between research advances and practice, it is necessary to comprehensively analyze the effectiveness of these methodologies. This paper proposes a thorough investigation of traditional and emerging clustering algorithms for UEBA, considering multiple application contexts, i.e., different user-entity interaction scenarios.Results and discussionOur study involves three datasets sourced from the existing literature and fifteen clustering algorithms. Among the compared techniques, HDBSCAN and DenMune showed promising performance on the state-of-the-art CERT behavior-related dataset, producing groups with a density very close to the number of users.},
  archive      = {J_FDATA},
  author       = {Artioli, Pierpaolo and Maci, Antonio and Magrì, Alessio},
  doi          = {10.3389/fdata.2024.1375818},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1375818},
  shortjournal = {Front. Big Data},
  title        = {A comprehensive investigation of clustering algorithms for user and entity behavior analytics},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Forecasting cryptocurrency’s buy signal with a bagged tree
learning approach to enhance purchase decisions. <em>FDATA</em>,
<em>7</em>, 1369895. (<a
href="https://doi.org/10.3389/fdata.2024.1369895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe cryptocurrency market is captivating the attention of both retail and institutional investors. While this highly volatile market offers investors substantial profit opportunities, it also entails risks due to its sensitivity to speculative news and the erratic behavior of major investors, both of which can provoke unexpected price fluctuations.MethodsIn this study, we contend that extreme and sudden price changes and atypical patterns might compromise the performance of technical signals utilized as the basis for feature extraction in a machine learning-based trading system by either augmenting or diminishing the model&#39;s generalization capability. To address this issue, this research uses a bagged tree (BT) model to forecast the buy signal for the cryptocurrency market. To achieve this, traders must acquire knowledge about the cryptocurrency market and modify their strategies accordingly.Results and discussionTo make an informed decision, we depended on the most prevalently utilized oscillators, namely, the buy signal in the cryptocurrency market, comprising the Relative Strength Index (RSI), Bollinger Bands (BB), and the Moving Average Convergence/Divergence (MACD) indicator. Also, the research evaluates how accurately a model can predict the performance of different cryptocurrencies such as Bitcoin (BTC), Ethereum (ETH), Cardano (ADA), and Binance Coin (BNB). Furthermore, the efficacy of the most popular machine learning model in precisely forecasting outcomes within the cryptocurrency market is examined. Notably, predicting buy signal values using a BT model provides promising results.},
  archive      = {J_FDATA},
  author       = {Alsini, Raed and Abu Al-Haija, Qasem and Alsulami, Abdulaziz A. and Alturki, Badraddin and Alqurashi, Abdulaziz A. and Mashat, Mouhamad D. and Alqahtani, Ali and Alhebaishi, Nawaf},
  doi          = {10.3389/fdata.2024.1369895},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1369895},
  shortjournal = {Front. Big Data},
  title        = {Forecasting cryptocurrency&#39;s buy signal with a bagged tree learning approach to enhance purchase decisions},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward explainable AI in radiology: Ensemble-CAM for
effective thoracic disease localization in chest x-ray images using weak
supervised learning. <em>FDATA</em>, <em>7</em>, 1366415. (<a
href="https://doi.org/10.3389/fdata.2024.1366415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest X-ray (CXR) imaging is widely employed by radiologists to diagnose thoracic diseases. Recently, many deep learning techniques have been proposed as computer-aided diagnostic (CAD) tools to assist radiologists in minimizing the risk of incorrect diagnosis. From an application perspective, these models have exhibited two major challenges: (1) They require large volumes of annotated data at the training stage and (2) They lack explainable factors to justify their outcomes at the prediction stage. In the present study, we developed a class activation mapping (CAM)-based ensemble model, called Ensemble-CAM, to address both of these challenges via weakly supervised learning by employing explainable AI (XAI) functions. Ensemble-CAM utilizes class labels to predict the location of disease in association with interpretable features. The proposed work leverages ensemble and transfer learning with class activation functions to achieve three objectives: (1) minimizing the dependency on strongly annotated data when locating thoracic diseases, (2) enhancing confidence in predicted outcomes by visualizing their interpretable features, and (3) optimizing cumulative performance via fusion functions. Ensemble-CAM was trained on three CXR image datasets and evaluated through qualitative and quantitative measures via heatmaps and Jaccard indices. The results reflect the enhanced performance and reliability in comparison to existing standalone and ensembled models.},
  archive      = {J_FDATA},
  author       = {Aasem, Muhammad and Javed Iqbal, Muhammad},
  doi          = {10.3389/fdata.2024.1366415},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1366415},
  shortjournal = {Front. Big Data},
  title        = {Toward explainable AI in radiology: Ensemble-CAM for effective thoracic disease localization in chest X-ray images using weak supervised learning},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stable tensor neural networks for efficient deep learning.
<em>FDATA</em>, <em>7</em>, 1363978. (<a
href="https://doi.org/10.3389/fdata.2024.1363978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from complex, multidimensional data has become central to computational mathematics, and among the most successful high-dimensional function approximators are deep neural networks (DNNs). Training DNNs is posed as an optimization problem to learn network weights or parameters that well-approximate a mapping from input to target data. Multiway data or tensors arise naturally in myriad ways in deep learning, in particular as input data and as high-dimensional weights and features extracted by the network, with the latter often being a bottleneck in terms of speed and memory. In this work, we leverage tensor representations and processing to efficiently parameterize DNNs when learning from high-dimensional data. We propose tensor neural networks (t-NNs), a natural extension of traditional fully-connected networks, that can be trained efficiently in a reduced, yet more powerful parameter space. Our t-NNs are built upon matrix-mimetic tensor-tensor products, which retain algebraic properties of matrix multiplication while capturing high-dimensional correlations. Mimeticity enables t-NNs to inherit desirable properties of modern DNN architectures. We exemplify this by extending recent work on stable neural networks, which interpret DNNs as discretizations of differential equations, to our multidimensional framework. We provide empirical evidence of the parametric advantages of t-NNs on dimensionality reduction using autoencoders and classification using fully-connected and stable variants on benchmark imaging datasets MNIST and CIFAR-10.},
  archive      = {J_FDATA},
  author       = {Newman, Elizabeth and Horesh, Lior and Avron, Haim and Kilmer, Misha E.},
  doi          = {10.3389/fdata.2024.1363978},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1363978},
  shortjournal = {Front. Big Data},
  title        = {Stable tensor neural networks for efficient deep learning},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development and application of a machine learning-based
predictive model for obstructive sleep apnea screening. <em>FDATA</em>,
<em>7</em>, 1353469. (<a
href="https://doi.org/10.3389/fdata.2024.1353469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ObjectiveTo develop a robust machine learning prediction model for the automatic screening and diagnosis of obstructive sleep apnea (OSA) using five advanced algorithms, namely Extreme Gradient Boosting (XGBoost), Logistic Regression (LR), Support Vector Machine (SVM), Light Gradient Boosting Machine (LightGBM), and Random Forest (RF) to provide substantial support for early clinical diagnosis and intervention.MethodsWe conducted a retrospective analysis of clinical data from 439 patients who underwent polysomnography at the Affiliated Hospital of Xuzhou Medical University between October 2019 and October 2022. Predictor variables such as demographic information [age, sex, height, weight, body mass index (BMI)], medical history, and Epworth Sleepiness Scale (ESS) were used. Univariate analysis was used to identify variables with significant differences, and the dataset was then divided into training and validation sets in a 4:1 ratio. The training set was established to predict OSA severity grading. The validation set was used to assess model performance using the area under the curve (AUC). Additionally, a separate analysis was conducted, categorizing the normal population as one group and patients with moderate-to-severe OSA as another. The same univariate analysis was applied, and the dataset was divided into training and validation sets in a 4:1 ratio. The training set was used to build a prediction model for screening moderate-to-severe OSA, while the validation set was used to verify the model&#39;s performance.ResultsAmong the four groups, the LightGBM model outperformed others, with the top five feature importance rankings of ESS total score, BMI, sex, hypertension, and gastroesophageal reflux (GERD), where Age, ESS total score and BMI played the most significant roles. In the dichotomous model, RF is the best performer of the five models respectively. The top five ranked feature importance of the best-performing RF models were ESS total score, BMI, GERD, age and Dry mouth, with ESS total score and BMI being particularly pivotal.ConclusionMachine learning-based prediction models for OSA disease grading and screening prove instrumental in the early identification of patients with moderate-to-severe OSA, revealing pertinent risk factors and facilitating timely interventions to counter pathological changes induced by OSA. Notably, ESS total score and BMI emerge as the most critical features for predicting OSA, emphasizing their significance in clinical assessments. The dataset will be publicly available on my Github.},
  archive      = {J_FDATA},
  author       = {Liu, Kang and Geng, Shi and Shen, Ping and Zhao, Lei and Zhou, Peng and Liu, Wen},
  doi          = {10.3389/fdata.2024.1353469},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1353469},
  shortjournal = {Front. Big Data},
  title        = {Development and application of a machine learning-based predictive model for obstructive sleep apnea screening},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analyzing political party positions through multi-language
twitter text embeddings. <em>FDATA</em>, <em>7</em>, 1330392. (<a
href="https://doi.org/10.3389/fdata.2024.1330392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional monolingual word embedding models transform words into high-dimensional vectors which represent semantics relations between words as relationships between vectors in the high-dimensional space. They serve as productive tools to interpret multifarious aspects of the social world in social science research. Building on the previous research which interprets multifaceted meanings of words by projecting them onto word-level dimensions defined by differences between antonyms, we extend the architecture of establishing word-level cultural dimensions to the sentence level and adopt a Language-agnostic BERT model (LaBSE) to detect position similarities in a multi-language environment. We assess the efficacy of our sentence-level methodology using Twitter data from US politicians, comparing it to the traditional word-level embedding model. We also adopt Latent Dirichlet Allocation (LDA) to investigate detailed topics in these tweets and interpret politicians&#39; positions from different angles. In addition, we adopt Twitter data from Spanish politicians and visualize their positions in a multi-language space to analyze position similarities across countries. The results show that our sentence-level methodology outperform traditional word-level model. We also demonstrate that our methodology is effective dealing with fine-sorted themes from the result that political positions towards different topics vary even within the same politicians. Through verification using American and Spanish political datasets, we find that the positioning of American and Spanish politicians on our defined liberal-conservative axis aligns with social common sense, political news, and previous research. Our architecture improves the standard word-level methodology and can be considered as a useful architecture for sentence-level applications in the future.},
  archive      = {J_FDATA},
  author       = {Chen, Jinghui and Mizuno, Takayuki and Doi, Shohei},
  doi          = {10.3389/fdata.2024.1330392},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1330392},
  shortjournal = {Front. Big Data},
  title        = {Analyzing political party positions through multi-language twitter text embeddings},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modal recommender system for predicting project
manager performance within a competency-based framework. <em>FDATA</em>,
<em>7</em>, 1295009. (<a
href="https://doi.org/10.3389/fdata.2024.1295009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of performance using competencies within a structured framework holds significant importance across various professional domains, particularly in roles like project manager. Typically, this assessment process, overseen by senior evaluators, involves scoring competencies based on data gathered from interviews, completed forms, and evaluation programs. However, this task is tedious and time-consuming, and requires the expertise of qualified professionals. Moreover, it is compounded by the inconsistent scoring biases introduced by different evaluators. In this paper, we propose a novel approach to automatically predict competency scores, thereby facilitating the assessment of project managers&#39; performance. Initially, we performed data fusion to compile a comprehensive dataset from various sources and modalities, including demographic data, profile-related data, and historical competency assessments. Subsequently, NLP techniques were used to pre-process text data. Finally, recommender systems were explored to predict competency scores. We compared four different recommender system approaches: content-based filtering, demographic filtering, collaborative filtering, and hybrid filtering. Using assessment data collected from 38 project managers, encompassing scores across 67 different competencies, we evaluated the performance of each approach. Notably, the content-based approach yielded promising results, achieving a precision rate of 81.03%. Furthermore, we addressed the challenge of cold-starting, which in our context involves predicting scores for either a new project manager lacking competency data or a newly introduced competency without historical records. Our analysis revealed that demographic filtering achieved an average precision of 54.05% when dealing with new project managers. In contrast, content-based filtering exhibited remarkable performance, achieving a precision of 85.79% in predicting scores for new competencies. These findings underscore the potential of recommender systems in competency assessment, thereby facilitating more effective performance evaluation process.},
  archive      = {J_FDATA},
  author       = {Jemal, Imene and Naoussi Sijou, Wilfried Armand and Chikhaoui, Belkacem},
  doi          = {10.3389/fdata.2024.1295009},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1295009},
  shortjournal = {Front. Big Data},
  title        = {Multi-modal recommender system for predicting project manager performance within a competency-based framework},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visualization as irritation: Producing knowledge about
medieval courts through uncertainty. <em>FDATA</em>, <em>7</em>,
1188620. (<a href="https://doi.org/10.3389/fdata.2024.1188620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visualizations are ubiquitous in data-driven research, serving as both tools for knowledge production and genuine means of knowledge communication. Despite criticisms targeting the alleged objectivity of visualizations in the digital humanities (DH) and reflections on how they may serve as representations of both scholarly perspective and uncertainty within the data analysis pipeline, there remains a notable scarcity of in-depth theoretical grounding for these assumptions in DH discussions. It is our understanding that only through theoretical foundations such as basic semiotic principles and perspectives on media modality one can fully assess the use and potential of visualizations for innovation in scholarly interpretation. We argue that visualizations have the capacity to “productively irritate” existing scholarly knowledge in a given research field. This does not just mean that visualizations depict patterns in datasets that seem not in line with prior research and thus stimulate deeper examination. Complementarily, “irritation” here consists of visualizations producing uncertainty about their own meaning—yet it is precisely this uncertainty in which the potential for greater insight lies. It stimulates questions about what is depicted and what is not. This turns out to be a valuable resource for scholarly interpretation, and one could argue that visualizing big data is particularly prolific in this sense, because due to their complexity researchers cannot interpret the data without visual representations. However, we argue that “productive irritation” can also happen below the level of big data. We see this potential rooted in the genuinely semiotic and semantic properties of visual media, which studies in multimodality and specifically in the field of Bildlinguistik have carved out: a visualization&#39;s holistic overview of data patterns is juxtaposed to its semantic vagueness, which gives way to deep interpretations and multiple perspectives on that data. We elucidate this potential using examples from medieval English legal history. Visualizations of data relating to legal functions and social constellations of various people in court offer surprising insights that can lead to new knowledge through “productive irritation.”},
  archive      = {J_FDATA},
  author       = {Schwandt, Silke and Wachter, Christian},
  doi          = {10.3389/fdata.2024.1188620},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1188620},
  shortjournal = {Front. Big Data},
  title        = {Visualization as irritation: Producing knowledge about medieval courts through uncertainty},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The role of big data in financial technology toward
financial inclusion. <em>FDATA</em>, <em>7</em>, 1184444. (<a
href="https://doi.org/10.3389/fdata.2024.1184444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the rapidly evolving landscape of financial technology (FinTech), big data stands as a cornerstone, driving significant transformations. This study delves into the pivotal role of big data in FinTech and its implications for financial inclusion. Employing a comprehensive literature review methodology, we analyze diverse sources including academic journals, industry reports, and online articles. Our findings illuminate how big data catalyzes the development of novel financial products and services, enhances risk management, and boosts operational efficiency, thereby fostering financial inclusion. Particularly, big data&#39;s capability to offer insightful customer behavior analytics is highlighted as a key driver for creating inclusive financial services. However, challenges such as data privacy and security, and the need for ethical algorithmic practices are also identified. This research contributes valuable insights for policymakers, regulators, and industry practitioners, suggesting a need for balanced regulatory frameworks to harness big data&#39;s potential ethically and responsibly. The outcomes of this study underscore the transformative power of big data in FinTech, indicating a pathway toward a more inclusive financial ecosystem.},
  archive      = {J_FDATA},
  author       = {Mhlanga, David},
  doi          = {10.3389/fdata.2024.1184444},
  journal      = {Frontiers in Big Data},
  month        = {5},
  pages        = {1184444},
  shortjournal = {Front. Big Data},
  title        = {The role of big data in financial technology toward financial inclusion},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Corrigendum: A community focused approach toward making
healthy and affordable daily diet recommendations. <em>FDATA</em>,
<em>7</em>, 1396638. (<a
href="https://doi.org/10.3389/fdata.2024.1396638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Germino, Joe and Szymanski, Annalisa and Eicher-Miller, Heather A. and Metoyer, Ronald and Chawla, Nitesh V.},
  doi          = {10.3389/fdata.2024.1396638},
  journal      = {Frontiers in Big Data},
  month        = {4},
  pages        = {1396638},
  shortjournal = {Front. Big Data},
  title        = {Corrigendum: A community focused approach toward making healthy and affordable daily diet recommendations},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Reviews in recommender systems: 2022.
<em>FDATA</em>, <em>7</em>, 1384460. (<a
href="https://doi.org/10.3389/fdata.2024.1384460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Kowald, Dominik and Yang, Deqing and Lacic, Emanuel},
  doi          = {10.3389/fdata.2024.1384460},
  journal      = {Frontiers in Big Data},
  month        = {4},
  pages        = {1384460},
  shortjournal = {Front. Big Data},
  title        = {Editorial: reviews in recommender systems: 2022},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph learning for particle accelerator operations.
<em>FDATA</em>, <em>7</em>, 1366469. (<a
href="https://doi.org/10.3389/fdata.2024.1366469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle accelerators play a crucial role in scientific research, enabling the study of fundamental physics and materials science, as well as having important medical applications. This study proposes a novel graph learning approach to classify operational beamline configurations as good or bad. By considering the relationships among beamline elements, we transform data from components into a heterogeneous graph. We propose to learn from historical, unlabeled data via our self-supervised training strategy along with fine-tuning on a smaller, labeled dataset. Additionally, we extract a low-dimensional representation from each configuration that can be visualized in two dimensions. Leveraging our ability for classification, we map out regions of the low-dimensional latent space characterized by good and bad configurations, which in turn can provide valuable feedback to operators. This research demonstrates a paradigm shift in how complex, many-dimensional data from beamlines can be analyzed and leveraged for accelerator operations.},
  archive      = {J_FDATA},
  author       = {Wang, Song and Tennant, Chris and Moser, Daniel and Larrieu, Theo and Li, Jundong},
  doi          = {10.3389/fdata.2024.1366469},
  journal      = {Frontiers in Big Data},
  month        = {4},
  pages        = {1366469},
  shortjournal = {Front. Big Data},
  title        = {Graph learning for particle accelerator operations},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Redefining governance: A critical analysis of sustainability
transformation in e-governance. <em>FDATA</em>, <em>7</em>, 1349116. (<a
href="https://doi.org/10.3389/fdata.2024.1349116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of information and communication technologies, governments worldwide are embracing digital transformation to enhance service delivery and governance practices. In the rapidly evolving landscape of information technology (IT), secure data management stands as a cornerstone for organizations aiming to safeguard sensitive information. Robust data modeling techniques are pivotal in structuring and organizing data, ensuring its integrity, and facilitating efficient retrieval and analysis. As the world increasingly emphasizes sustainability, integrating eco-friendly practices into data management processes becomes imperative. This study focuses on the specific context of Pakistan and investigates the potential of cloud computing in advancing e-governance capabilities. Cloud computing offers scalability, cost efficiency, and enhanced data security, making it an ideal technology for digital transformation. Through an extensive literature review, analysis of case studies, and interviews with stakeholders, this research explores the current state of e-governance in Pakistan, identifies the challenges faced, and proposes a framework for leveraging cloud computing to overcome these challenges. The findings reveal that cloud computing can significantly enhance the accessibility, scalability, and cost-effectiveness of e-governance services, thereby improving citizen engagement and satisfaction. This study provides valuable insights for policymakers, government agencies, and researchers interested in the digital transformation of e-governance in Pakistan and offers a roadmap for leveraging cloud computing technologies in similar contexts. The findings contribute to the growing body of knowledge on e-governance and cloud computing, supporting the advancement of digital governance practices globally. This research identifies monitoring parameters necessary to establish a sustainable e-governance system incorporating big data and cloud computing. The proposed framework, Monitoring and Assessment System using Cloud (MASC), is validated through secondary data analysis and successfully fulfills the research objectives. By leveraging big data and cloud computing, governments can revolutionize their digital governance practices, driving transformative changes and enhancing efficiency and effectiveness in public administration.},
  archive      = {J_FDATA},
  author       = {Abbas, Qaiser and Alyas, Tahir and Alghamdi, Turki and Alkhodre, Ahmad B. and Albouq, Sami and Niazi, Mushtaq and Tabassum, Nadia},
  doi          = {10.3389/fdata.2024.1349116},
  journal      = {Frontiers in Big Data},
  month        = {4},
  pages        = {1349116},
  shortjournal = {Front. Big Data},
  title        = {Redefining governance: A critical analysis of sustainability transformation in e-governance},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Acupuncture and tuina knowledge graph with prompt learning.
<em>FDATA</em>, <em>7</em>, 1346958. (<a
href="https://doi.org/10.3389/fdata.2024.1346958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionAcupuncture and tuina, acknowledged as ancient and highly efficacious therapeutic modalities within the domain of Traditional Chinese Medicine (TCM), have provided pragmatic treatment pathways for numerous patients. To address the problems of ambiguity in the concept of Traditional Chinese Medicine (TCM) acupuncture and tuina treatment protocols, the lack of accurate quantitative assessment of treatment protocols, and the diversity of TCM systems, we have established a map-filling technique for modern literature to achieve personalized medical recommendations.Methods(1) Extensive acupuncture and tuina data were collected, analyzed, and processed to establish a concise TCM domain knowledge base. (2)A template-free Chinese text NER joint training method (TemplateFC) was proposed, which enhances the EntLM model with BiLSTM and CRF layers. Appropriate rules were set for ERE. (3) A comprehensive knowledge graph comprising 10,346 entities and 40,919 relationships was constructed based on modern literature.ResultsA robust TCM KG with a wide range of entities and relationships was created. The template-free joint training approach significantly improved NER accuracy, especially in Chinese text, addressing issues related to entity identification and tokenization differences. The KG provided valuable insights into acupuncture and tuina, facilitating efficient information retrieval and personalized treatment recommendations.DiscussionThe integration of KGs in TCM research is essential for advancing diagnostics and interventions. Challenges in NER and ERE were effectively tackled using hybrid approaches and innovative techniques. The comprehensive TCM KG our built contributes to bridging the gap in TCM knowledge and serves as a valuable resource for specialists and non-specialists alike.},
  archive      = {J_FDATA},
  author       = {Li, Xiaoran and Han, Xiaosong and Wei, Siqing and Liang, Yanchun and Guan, Renchu},
  doi          = {10.3389/fdata.2024.1346958},
  journal      = {Frontiers in Big Data},
  month        = {4},
  pages        = {1346958},
  shortjournal = {Front. Big Data},
  title        = {Acupuncture and tuina knowledge graph with prompt learning},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How different are offline and online diplomacy? A
comparative analysis of public statements and SNS posts by delegates to
the united nations. <em>FDATA</em>, <em>7</em>, 1304806. (<a
href="https://doi.org/10.3389/fdata.2024.1304806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThis article investigates the evolving landscape of diplomacy in the digital age, focusing on diplomats at the United Nations (UN) Headquarters in New York. The central inquiry revolves around how diplomatic actors use digital tools to complement or augment traditional face-to-face diplomacy.MethodsWe systematically compare a substantial corpus of X posts (tweets) from UN diplomats with their public statements at the United Nations Security Council (UNSC), employing advanced computational social science techniques. This study applies a range of large-scale text analysis methods, including word embedding, topic modeling, and sentiment analysis, to investigate systematic differences between offline and online communication.ResultsOur analysis reveals that, while the essence of diplomacy remains consistent across both domains, there is strategic selectivity in the use of online platforms by diplomats. Online communication emphasizes non-security topics, ceremonial matters, and prominent policy stances, in contrast to the operational issues common in UNSC deliberations. Additionally, online discourse adopts a less confrontational, more public diplomacy-oriented tone, with variations among countries.DiscussionThis study offers one of the first systematic comparisons between offline and online diplomatic messages. It illuminates how diplomats navigate the digital realm to complement traditional roles. The findings indicate that some elements of public diplomacy and nation branding, directed toward a wider audience far beyond the council chamber, have become an integral part of multilateral diplomacy unfolding at the UNSC.},
  archive      = {J_FDATA},
  author       = {Sakamoto, Takuto and Araki, Momoko and Ito, Hiroto and Matsuoka, Tomoyuki},
  doi          = {10.3389/fdata.2024.1304806},
  journal      = {Frontiers in Big Data},
  month        = {4},
  pages        = {1304806},
  shortjournal = {Front. Big Data},
  title        = {How different are offline and online diplomacy? a comparative analysis of public statements and SNS posts by delegates to the united nations},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring dermoscopic structures for melanoma lesions’
classification. <em>FDATA</em>, <em>7</em>, 1366312. (<a
href="https://doi.org/10.3389/fdata.2024.1366312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BackgroundMelanoma is one of the deadliest skin cancers that originate from melanocytes due to sun exposure, causing mutations. Early detection boosts the cure rate to 90%, but misclassification drops survival to 15–20%. Clinical variations challenge dermatologists in distinguishing benign nevi and melanomas. Current diagnostic methods, including visual analysis and dermoscopy, have limitations, emphasizing the need for Artificial Intelligence understanding in dermatology.ObjectivesIn this paper, we aim to explore dermoscopic structures for the classification of melanoma lesions. The training of AI models faces a challenge known as brittleness, where small changes in input images impact the classification. A study explored AI vulnerability in discerning melanoma from benign lesions using features of size, color, and shape. Tests with artificial and natural variations revealed a notable decline in accuracy, emphasizing the necessity for additional information, such as dermoscopic structures.MethodologyThe study utilizes datasets with clinically marked dermoscopic images examined by expert clinicians. Transformers and CNN-based models are employed to classify these images based on dermoscopic structures. Classification results are validated using feature visualization. To assess model susceptibility to image variations, classifiers are evaluated on test sets with original, duplicated, and digitally modified images. Additionally, testing is done on ISIC 2016 images. The study focuses on three dermoscopic structures crucial for melanoma detection: Blue-white veil, dots/globules, and streaks.ResultsIn evaluating model performance, adding convolutions to Vision Transformers proves highly effective for achieving up to 98% accuracy. CNN architectures like VGG-16 and DenseNet-121 reach 50–60% accuracy, performing best with features other than dermoscopic structures. Vision Transformers without convolutions exhibit reduced accuracy on diverse test sets, revealing their brittleness. OpenAI Clip, a pre-trained model, consistently performs well across various test sets. To address brittleness, a mitigation method involving extensive data augmentation during training and 23 transformed duplicates during test time, sustains accuracy.ConclusionsThis paper proposes a melanoma classification scheme utilizing three dermoscopic structures across Ph2 and Derm7pt datasets. The study addresses AI susceptibility to image variations. Despite a small dataset, future work suggests collecting more annotated datasets and automatic computation of dermoscopic structural features.},
  archive      = {J_FDATA},
  author       = {Malik, Fiza Saeed and Yousaf, Muhammad Haroon and Sial, Hassan Ahmed and Viriri, Serestina},
  doi          = {10.3389/fdata.2024.1366312},
  journal      = {Frontiers in Big Data},
  month        = {3},
  pages        = {1366312},
  shortjournal = {Front. Big Data},
  title        = {Exploring dermoscopic structures for melanoma lesions&#39; classification},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing cancer stage prediction through hybrid deep neural
networks: A comparative study. <em>FDATA</em>, <em>7</em>, 1359703. (<a
href="https://doi.org/10.3389/fdata.2024.1359703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently detecting and treating cancer at an early stage is crucial to improve the overall treatment process and mitigate the risk of disease progression. In the realm of research, the utilization of artificial intelligence technologies holds significant promise for enhancing advanced cancer diagnosis. Nonetheless, a notable hurdle arises when striving for precise cancer-stage diagnoses through the analysis of gene sets. Issues such as limited sample volumes, data dispersion, overfitting, and the use of linear classifiers with simple parameters hinder prediction performance. This study introduces an innovative approach for predicting early and late-stage cancers by integrating hybrid deep neural networks. A deep neural network classifier, developed using the open-source TensorFlow library and Keras network, incorporates a novel method that combines genetic algorithms, Extreme Learning Machines (ELM), and Deep Belief Networks (DBN). Specifically, two evolutionary techniques, DBN-ELM-BP and DBN-ELM-ELM, are proposed and evaluated using data from The Cancer Genome Atlas (TCGA), encompassing mRNA expression, miRNA levels, DNA methylation, and clinical information. The models demonstrate outstanding prediction accuracy (89.35%−98.75%) in distinguishing between early- and late-stage cancers. Comparative analysis against existing methods in the literature using the same cancer dataset reveals the superiority of the proposed hybrid method, highlighting its enhanced accuracy in cancer stage prediction.},
  archive      = {J_FDATA},
  author       = {Amanzholova, Alina and Coşkun, Aysun},
  doi          = {10.3389/fdata.2024.1359703},
  journal      = {Frontiers in Big Data},
  month        = {3},
  pages        = {1359703},
  shortjournal = {Front. Big Data},
  title        = {Enhancing cancer stage prediction through hybrid deep neural networks: A comparative study},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sentiment analysis of COP9-related tweets: A comparative
study of pre-trained models and traditional techniques. <em>FDATA</em>,
<em>7</em>, 1357926. (<a
href="https://doi.org/10.3389/fdata.2024.1357926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionSentiment analysis has become a crucial area of research in natural language processing in recent years. The study aims to compare the performance of various sentiment analysis techniques, including lexicon-based, machine learning, Bi-LSTM, BERT, and GPT-3 approaches, using two commonly used datasets, IMDB reviews and Sentiment140. The objective is to identify the best-performing technique for an exemplar dataset, tweets associated with the WHO Framework Convention on Tobacco Control Ninth Conference of the Parties in 2021 (COP9).MethodsA two-stage evaluation was conducted. In the first stage, various techniques were compared on standard sentiment analysis datasets using standard evaluation metrics such as accuracy, F1-score, and precision. In the second stage, the best-performing techniques from the first stage were applied to partially annotated COP9 conference-related tweets.ResultsIn the first stage, BERT achieved the highest F1-scores (0.9380 for IMDB and 0.8114 for Sentiment 140), followed by GPT-3 (0.9119 and 0.7913) and Bi-LSTM (0.8971 and 0.7778). In the second stage, GPT-3 performed the best for sentiment analysis on partially annotated COP9 conference-related tweets, with an F1-score of 0.8812.DiscussionThe study demonstrates the effectiveness of pre-trained models like BERT and GPT-3 for sentiment analysis tasks, outperforming traditional techniques on standard datasets. Moreover, the better performance of GPT-3 on the partially annotated COP9 tweets highlights its ability to generalize well to domain-specific data with limited annotations. This provides researchers and practitioners with a viable option of using pre-trained models for sentiment analysis in scenarios with limited or no annotated data across different domains.},
  archive      = {J_FDATA},
  author       = {Elmitwalli, Sherif and Mehegan, John},
  doi          = {10.3389/fdata.2024.1357926},
  journal      = {Frontiers in Big Data},
  month        = {3},
  pages        = {1357926},
  shortjournal = {Front. Big Data},
  title        = {Sentiment analysis of COP9-related tweets: A comparative study of pre-trained models and traditional techniques},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Urban delineation through a prism of intraday commute
patterns. <em>FDATA</em>, <em>7</em>, 1356116. (<a
href="https://doi.org/10.3389/fdata.2024.1356116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionUrban mobility patterns are crucial for effective urban and transportation planning. This study investigates the dynamics of urban mobility in Brno, Czech Republic, utilizing the rich dataset provided by passive mobile phone data. Understanding these patterns is essential for optimizing infrastructure and planning strategies.MethodsWe developed a methodological framework that incorporates bidirectional commute flows and integrates both urban and suburban commute networks. This comprehensive approach allows for a detailed representation of Brno&#39;s mobility landscape. By employing clustering techniques, we aimed to identify distinct mobility patterns within the city.ResultsOur analysis revealed consistent structural features within Brno&#39;s mobility patterns. We identified three distinct clusters: a central business district, residential communities, and an intermediate hybrid cluster. These clusters highlight the diversity of mobility demands across different parts of the city.DiscussionThe study demonstrates the significant potential of passive mobile phone data in enhancing our understanding of urban mobility patterns. The insights gained from intraday mobility data are invaluable for transportation planning decisions, allowing for the optimization of infrastructure utilization. The identification of distinct mobility patterns underscores the practical utility of our methodological advancements in informing more effective and efficient transportation planning strategies.},
  archive      = {J_FDATA},
  author       = {Bogomolov, Yuri and Belyi, Alexander and Sobolevsky, Stanislav},
  doi          = {10.3389/fdata.2024.1356116},
  journal      = {Frontiers in Big Data},
  month        = {3},
  pages        = {1356116},
  shortjournal = {Front. Big Data},
  title        = {Urban delineation through a prism of intraday commute patterns},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). City composition and accessibility statistics in and around
paris. <em>FDATA</em>, <em>7</em>, 1354007. (<a
href="https://doi.org/10.3389/fdata.2024.1354007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionIs Paris a 15-min city, where inhabitants can access essential amenities such as schools and shops with a 15-min walk or bike ride? The concept of a 15-min (more generally, X-minute) city was launched in the French capital and was part of the current mayor&#39;s plan in her latest re-election campaign. Yet, its fit with the existing urban structure had not been previously assessed.MethodsThis article combines open map data from a large participatory project and geo-localized socio-economic data from official statistics to fill this gap.ResultsWe show that, while the city of Paris is rather homogeneous, it is nonetheless characterized by remarkable inequalities between a highly accessible city center (though with some internal differences in terms of types of amenities) and a less well-equipped periphery, where lower-income neighborhoods are more often found. The heterogeneity increases if we consider Paris together with its immediate surroundings, the &quot;Petite Couronne,&quot; where large numbers of daily commuters and other users of city facilities live.DiscussionWe thus conclude that successful implementation of the X-minute-city concept requires addressing existing socio-economic inequalities, and that especially in big cities, it should be extended beyond the narrow boundaries of the municipality itself to encompass the larger area around it.},
  archive      = {J_FDATA},
  author       = {Thaury, Marie-Olive and Genet, Simon and Maurice, Léopold and Tubaro, Paola and Berkemer, Sarah J.},
  doi          = {10.3389/fdata.2024.1354007},
  journal      = {Frontiers in Big Data},
  month        = {3},
  pages        = {1354007},
  shortjournal = {Front. Big Data},
  title        = {City composition and accessibility statistics in and around paris},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data pipeline for real-time energy consumption data
management and prediction. <em>FDATA</em>, <em>7</em>, 1308236. (<a
href="https://doi.org/10.3389/fdata.2024.1308236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing utilization of data in various industries and applications, constructing an efficient data pipeline has become crucial. In this study, we propose a machine learning operations-centric data pipeline specifically designed for an energy consumption management system. This pipeline seamlessly integrates the machine learning model with real-time data management and prediction capabilities. The overall architecture of our proposed pipeline comprises several key components, including Kafka, InfluxDB, Telegraf, Zookeeper, and Grafana. To enable accurate energy consumption predictions, we adopt two time-series prediction models, long short-term memory (LSTM), and seasonal autoregressive integrated moving average (SARIMA). Our analysis reveals a clear trade-off between speed and accuracy, where SARIMA exhibits faster model learning time while LSTM outperforms SARIMA in prediction accuracy. To validate the effectiveness of our pipeline, we measure the overall processing time by optimizing the configuration of Telegraf, which directly impacts the load in the pipeline. The results are promising, as our pipeline achieves an average end-to-end processing time of only 0.39 s for handling 10,000 data records and an impressive 1.26 s when scaling up to 100,000 records. This indicates 30.69–90.88 times faster processing compared to the existing Python-based approach. Additionally, when the number of records increases by ten times, the increased overhead is reduced by 3.07 times. This verifies that the proposed pipeline exhibits an efficient and scalable structure suitable for real-time environments.},
  archive      = {J_FDATA},
  author       = {Im, Jeonghwan and Lee, Jaekyu and Lee, Somin and Kwon, Hyuk-Yoon},
  doi          = {10.3389/fdata.2024.1308236},
  journal      = {Frontiers in Big Data},
  month        = {3},
  pages        = {1308236},
  shortjournal = {Front. Big Data},
  title        = {Data pipeline for real-time energy consumption data management and prediction},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impact of comorbidities and economic inequality on
COVID-19 mortality in mexico: A machine learning approach.
<em>FDATA</em>, <em>7</em>, 1298029. (<a
href="https://doi.org/10.3389/fdata.2024.1298029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionStudies from different parts of the world have shown that some comorbidities are associated with fatal cases of COVID-19. However, the prevalence rates of comorbidities are different around the world, therefore, their contribution to COVID-19 mortality is different. Socioeconomic factors may influence the prevalence of comorbidities; therefore, they may also influence COVID-19 mortality.MethodsThis study conducted feature analysis using two supervised machine learning classification algorithms, Random Forest and XGBoost, to examine the comorbidities and level of economic inequalities associated with fatal cases of COVID-19 in Mexico. The dataset used was collected by the National Epidemiology Center from February 2020 to November 2022, and includes more than 20 million observations and 40 variables describing the characteristics of the individuals who underwent COVID-19 testing or treatment. In addition, socioeconomic inequalities were measured using the normalized marginalization index calculated by the National Population Council and the deprivation index calculated by NASA.ResultsThe analysis shows that diabetes and hypertension were the main comorbidities defining the mortality of COVID-19, furthermore, socioeconomic inequalities were also important characteristics defining the mortality. Similar features were found with Random Forest and XGBoost.DiscussionIt is imperative to implement programs aimed at reducing inequalities as well as preventable comorbidities to make the population more resilient to future pandemics. The results apply to regions or countries with similar levels of inequality or comorbidity prevalence.},
  archive      = {J_FDATA},
  author       = {Méndez-Astudillo, Jorge},
  doi          = {10.3389/fdata.2024.1298029},
  journal      = {Frontiers in Big Data},
  month        = {3},
  pages        = {1298029},
  shortjournal = {Front. Big Data},
  title        = {The impact of comorbidities and economic inequality on COVID-19 mortality in mexico: A machine learning approach},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A scalable MapReduce-based design of an unsupervised entity
resolution system. <em>FDATA</em>, <em>7</em>, 1296552. (<a
href="https://doi.org/10.3389/fdata.2024.1296552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional data curation processes typically depend on human intervention. As data volume and variety grow exponentially, organizations are striving to increase efficiency of their data processes by automating manual processes and making them as unsupervised as possible. An additional challenge is to make these unsupervised processes scalable to meet the demands of increased data volume. This paper describes the parallelization of an unsupervised entity resolution (ER) process. ER is a component of many different data curation processes because it clusters records from multiple data sources that refer to the same real-world entity, such as the same customer, patient, or product. The ability to scale ER processes is particularly important because the computation effort of ER increases quadratically with data volume. The Data Washing Machine (DWM) is an already proposed unsupervised ER system which clusters references from diverse data sources. This work aims at solving the single-threaded nature of the DWM by adopting the parallelization nature of Hadoop MapReduce. However, the proposed parallelization method can be applied to both supervised systems, where matching rules are created by experts, and unsupervised systems, where expert intervention is not required. The DWM uses an entropy measure to self-evaluate the quality of record clustering. The current single-threaded implementations of the DWM in Python and Java are not scalable beyond a few 1,000 records and rely on large, shared memory. The objective of this research is to solve the major two shortcomings of the current design of the DWM which are the creation and usage of shared memory and lack of scalability by leveraging on the power of Hadoop MapReduce. We propose Hadoop Data Washing Machine (HDWM), a MapReduce implementation of the legacy DWM. The scalability of the proposed system is displayed using publicly available ER datasets. Based on results from our experiment, we conclude that HDWM can cluster from 1,000&#39;s to millions of equivalent references using multiple computational nodes with independent RAM and CPU cores.},
  archive      = {J_FDATA},
  author       = {Hagan, Nicholas Kofi Akortia and Talburt, John R. and Anderson, Kris E. and Hagan, Deasia},
  doi          = {10.3389/fdata.2024.1296552},
  journal      = {Frontiers in Big Data},
  month        = {3},
  pages        = {1296552},
  shortjournal = {Front. Big Data},
  title        = {A scalable MapReduce-based design of an unsupervised entity resolution system},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Cyber security in the wake of fourth industrial
revolution: Opportunities and challenges. <em>FDATA</em>, <em>7</em>,
1369159. (<a href="https://doi.org/10.3389/fdata.2024.1369159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Ukwandu, Elochukwu and Hewage, Chaminda and Hindy, Hanan},
  doi          = {10.3389/fdata.2024.1369159},
  journal      = {Frontiers in Big Data},
  month        = {2},
  pages        = {1369159},
  shortjournal = {Front. Big Data},
  title        = {Editorial: cyber security in the wake of fourth industrial revolution: opportunities and challenges},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Internet of medical things and computational
intelligence in healthcare 4.0. <em>FDATA</em>, <em>7</em>, 1368581. (<a
href="https://doi.org/10.3389/fdata.2024.1368581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Dash, Sujata and Pani, Subhendu Kumar and Santos, Wellington Pinheiro dos},
  doi          = {10.3389/fdata.2024.1368581},
  journal      = {Frontiers in Big Data},
  month        = {2},
  pages        = {1368581},
  shortjournal = {Front. Big Data},
  title        = {Editorial: Internet of medical things and computational intelligence in healthcare 4.0},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing multi-objective task scheduling in fog computing
with GA-PSO algorithm for big data application. <em>FDATA</em>,
<em>7</em>, 1358486. (<a
href="https://doi.org/10.3389/fdata.2024.1358486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the volume and velocity of Big Data continue to grow, traditional cloud computing approaches struggle to meet the demands of real-time processing and low latency. Fog computing, with its distributed network of edge devices, emerges as a compelling solution. However, efficient task scheduling in fog computing remains a challenge due to its inherently multi-objective nature, balancing factors like execution time, response time, and resource utilization. This paper proposes a hybrid Genetic Algorithm (GA)-Particle Swarm Optimization (PSO) algorithm to optimize multi-objective task scheduling in fog computing environments. The hybrid approach combines the strengths of GA and PSO, achieving effective exploration and exploitation of the search space, leading to improved performance compared to traditional single-algorithm approaches. The proposed hybrid algorithm results improved the execution time by 85.68% when compared with GA algorithm, by 84% when compared with Hybrid PWOA and by 51.03% when compared with PSO algorithm as well as it improved the response time by 67.28% when compared with GA algorithm, by 54.24% when compared with Hybrid PWOA and by 75.40% when compared with PSO algorithm as well as it improved the completion time by 68.69% when compared with GA algorithm, by 98.91% when compared with Hybrid PWOA and by 75.90% when compared with PSO algorithm when various tasks inputs are given. The proposed hybrid algorithm results also improved the execution time by 84.87% when compared with GA algorithm, by 88.64% when compared with Hybrid PWOA and by 85.07% when compared with PSO algorithm it improved the response time by 65.92% when compared with GA algorithm, by 80.51% when compared with Hybrid PWOA and by 85.26% when compared with PSO algorithm as well as it improved the completion time by 67.60% when compared with GA algorithm, by 81.34% when compared with Hybrid PWOA and by 85.23% when compared with PSO algorithm when various fog nodes are given.},
  archive      = {J_FDATA},
  author       = {Saad, Muhammad and Enam, Rabia Noor and Qureshi, Rehan},
  doi          = {10.3389/fdata.2024.1358486},
  journal      = {Frontiers in Big Data},
  month        = {2},
  pages        = {1358486},
  shortjournal = {Front. Big Data},
  title        = {Optimizing multi-objective task scheduling in fog computing with GA-PSO algorithm for big data application},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Big scientific data analytics on HPC and cloud.
<em>FDATA</em>, <em>7</em>, 1353988. (<a
href="https://doi.org/10.3389/fdata.2024.1353988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FDATA},
  author       = {Wang, Jianwu and Yin, Junqi and Nguyen, Mai H. and Wang, Jingbo and Xu, Weijia},
  doi          = {10.3389/fdata.2024.1353988},
  journal      = {Frontiers in Big Data},
  month        = {2},
  pages        = {1353988},
  shortjournal = {Front. Big Data},
  title        = {Editorial: Big scientific data analytics on HPC and cloud},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge-based recommender systems: Overview and research
directions. <em>FDATA</em>, <em>7</em>, 1304439. (<a
href="https://doi.org/10.3389/fdata.2024.1304439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are decision support systems that help users to identify items of relevance from a potentially large set of alternatives. In contrast to the mainstream recommendation approaches of collaborative filtering and content-based filtering, knowledge-based recommenders exploit semantic user preference knowledge, item knowledge, and recommendation knowledge, to identify user-relevant items which is of specific relevance when dealing with complex and high-involvement items. Such recommenders are primarily applied in scenarios where users specify (and revise) their preferences, and related recommendations are determined on the basis of constraints or attribute-level similarity metrics. In this article, we provide an overview of the existing state-of-the-art in knowledge-based recommender systems. Different related recommendation techniques are explained on the basis of a working example from the domain of survey software services. On the basis of our analysis, we outline different directions for future research.},
  archive      = {J_FDATA},
  author       = {Uta, Mathias and Felfernig, Alexander and Le, Viet-Man and Tran, Thi Ngoc Trang and Garber, Damian and Lubos, Sebastian and Burgstaller, Tamim},
  doi          = {10.3389/fdata.2024.1304439},
  journal      = {Frontiers in Big Data},
  month        = {2},
  pages        = {1304439},
  shortjournal = {Front. Big Data},
  title        = {Knowledge-based recommender systems: Overview and research directions},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting risk of preterm birth in singleton pregnancies
using machine learning algorithms. <em>FDATA</em>, <em>7</em>, 1291196.
(<a href="https://doi.org/10.3389/fdata.2024.1291196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We aimed to develop, train, and validate machine learning models for predicting preterm birth (&amp;lt;37 weeks&#39; gestation) in singleton pregnancies at different gestational intervals. Models were developed based on complete data from 22,603 singleton pregnancies from a prospective population-based cohort study that was conducted in 51 midwifery clinics and hospitals in Wenzhou City of China between 2014 and 2016. We applied Catboost, Random Forest, Stacked Model, Deep Neural Networks (DNN), and Support Vector Machine (SVM) algorithms, as well as logistic regression, to conduct feature selection and predictive modeling. Feature selection was implemented based on permutation-based feature importance lists derived from the machine learning models including all features, using a balanced training data set. To develop prediction models, the top 10%, 25%, and 50% most important predictive features were selected. Prediction models were developed with the training data set with 5-fold cross-validation for internal validation. Model performance was assessed using area under the receiver operating curve (AUC) values. The CatBoost-based prediction model after 26 weeks&#39; gestation performed best with an AUC value of 0.70 (0.67, 0.73), accuracy of 0.81, sensitivity of 0.47, and specificity of 0.83. Number of antenatal care visits before 24 weeks&#39; gestation, aspartate aminotransferase level at registration, symphysis fundal height, maternal weight, abdominal circumference, and blood pressure emerged as strong predictors after 26 completed weeks. The application of machine learning on pregnancy surveillance data is a promising approach to predict preterm birth and we identified several modifiable antenatal predictors.},
  archive      = {J_FDATA},
  author       = {Yu, Qiu-Yan and Lin, Ying and Zhou, Yu-Run and Yang, Xin-Jun and Hemelaar, Joris},
  doi          = {10.3389/fdata.2024.1291196},
  journal      = {Frontiers in Big Data},
  month        = {2},
  pages        = {1291196},
  shortjournal = {Front. Big Data},
  title        = {Predicting risk of preterm birth in singleton pregnancies using machine learning algorithms},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficacy of federated learning on genomic data: A study on
the UK biobank and the 1000 genomes project. <em>FDATA</em>, <em>7</em>,
1266031. (<a href="https://doi.org/10.3389/fdata.2024.1266031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining training data from multiple sources increases sample size and reduces confounding, leading to more accurate and less biased machine learning models. In healthcare, however, direct pooling of data is often not allowed by data custodians who are accountable for minimizing the exposure of sensitive information. Federated learning offers a promising solution to this problem by training a model in a decentralized manner thus reducing the risks of data leakage. Although there is increasing utilization of federated learning on clinical data, its efficacy on individual-level genomic data has not been studied. This study lays the groundwork for the adoption of federated learning for genomic data by investigating its applicability in two scenarios: phenotype prediction on the UK Biobank data and ancestry prediction on the 1000 Genomes Project data. We show that federated models trained on data split into independent nodes achieve performance close to centralized models, even in the presence of significant inter-node heterogeneity. Additionally, we investigate how federated model accuracy is affected by communication frequency and suggest approaches to reduce computational complexity or communication costs.},
  archive      = {J_FDATA},
  author       = {Kolobkov, Dmitry and Mishra Sharma, Satyarth and Medvedev, Aleksandr and Lebedev, Mikhail and Kosaretskiy, Egor and Vakhitov, Ruslan},
  doi          = {10.3389/fdata.2024.1266031},
  journal      = {Frontiers in Big Data},
  month        = {2},
  pages        = {1266031},
  shortjournal = {Front. Big Data},
  title        = {Efficacy of federated learning on genomic data: A study on the UK biobank and the 1000 genomes project},
  volume       = {7},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trends of the COVID-19 dynamics in 2022 and 2023 vs. The
population age, testing and vaccination levels. <em>FDATA</em>,
<em>6</em>, 1355080. (<a
href="https://doi.org/10.3389/fdata.2023.1355080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionThe population, governments, and researchers show much less interest in the COVID-19 pandemic. However, many questions still need to be answered: why the much less vaccinated African continent has accumulated 15 times less deaths per capita than Europe? or why in 2023 the global value of the case fatality risk is almost twice higher than in 2022 and the UK figure is four times higher than the global one?MethodsThe averaged daily numbers of cases DCC and death DDC per million, case fatality risks DDC/DCC were calculated for 34 countries and regions with the use of John Hopkins University (JHU) datasets. Possible linear and non-linear correlations with the averaged daily numbers of tests per thousand DTC, median age of population A, and percentages of vaccinations VC and boosters BC were investigated.ResultsStrong correlations between age and DCC and DDC values were revealed. One-year increment in the median age yielded 39.8 increase in DCC values and 0.0799 DDC increase in 2022 (in 2023 these figures are 5.8 and 0.0263, respectively). With decreasing of testing level DTC, the case fatality risk can increase drastically. DCC and DDC values increase with increasing the percentages of fully vaccinated people and boosters, which definitely increase for greater A. After removing the influence of age, no correlations between vaccinations and DCC and DDC values were revealed.DiscussionThe presented analysis demonstrates that age is a pivot factor of visible (registered) part of the COVID-19 pandemic dynamics. Much younger Africa has registered less numbers of cases and death per capita due to many unregistered asymptomatic patients. Of great concern is the fact that COVID-19 mortality in 2023 in the UK is still at least 4 times higher than the global value caused by seasonal flu.},
  archive      = {J_FDATA},
  author       = {Nesteruk, Igor},
  doi          = {10.3389/fdata.2023.1355080},
  journal      = {Frontiers in Big Data},
  month        = {1},
  pages        = {1355080},
  shortjournal = {Front. Big Data},
  title        = {Trends of the COVID-19 dynamics in 2022 and 2023 vs. the population age, testing and vaccination levels},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel approach to fake news classification using
LSTM-based deep learning models. <em>FDATA</em>, <em>6</em>, 1320800.
(<a href="https://doi.org/10.3389/fdata.2023.1320800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid dissemination of information has been accompanied by the proliferation of fake news, posing significant challenges in discerning authentic news from fabricated narratives. This study addresses the urgent need for effective fake news detection mechanisms. The spread of fake news on digital platforms has necessitated the development of sophisticated tools for accurate detection and classification. Deep learning models, particularly Bi-LSTM and attention-based Bi-LSTM architectures, have shown promise in tackling this issue. This research utilized Bi-LSTM and attention-based Bi-LSTM models, integrating an attention mechanism to assess the significance of different parts of the input data. The models were trained on an 80% subset of the data and tested on the remaining 20%, employing comprehensive evaluation metrics including Recall, Precision, F1-Score, Accuracy, and Loss. Comparative analysis with existing models revealed the superior efficacy of the proposed architectures. The attention-based Bi-LSTM model demonstrated remarkable proficiency, outperforming other models in terms of accuracy (97.66%) and other key metrics. The study highlighted the potential of integrating advanced deep learning techniques in fake news detection. The proposed models set new standards in the field, offering effective tools for combating misinformation. Limitations such as data dependency, potential for overfitting, and language and context specificity were acknowledged. The research underscores the importance of leveraging cutting-edge deep learning methodologies, particularly attention mechanisms, in fake news identification. The innovative models presented pave the way for more robust solutions to counter misinformation, thereby preserving the veracity of digital information. Future research should focus on enhancing data diversity, model efficiency, and applicability across various languages and contexts.},
  archive      = {J_FDATA},
  author       = {Padalko, Halyna and Chomko, Vasyl and Chumachenko, Dmytro},
  doi          = {10.3389/fdata.2023.1320800},
  journal      = {Frontiers in Big Data},
  month        = {1},
  pages        = {1320800},
  shortjournal = {Front. Big Data},
  title        = {A novel approach to fake news classification using LSTM-based deep learning models},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CTAB-GAN+: Enhancing tabular data synthesis. <em>FDATA</em>,
<em>6</em>, 1296508. (<a
href="https://doi.org/10.3389/fdata.2023.1296508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The usage of synthetic data is gaining momentum in part due to the unavailability of original data due to privacy and legal considerations and in part due to its utility as an augmentation to the authentic data. Generative adversarial networks (GANs), a paragon of generative models, initially for images and subsequently for tabular data, has contributed many of the state-of-the-art synthesizers. As GANs improve, the synthesized data increasingly resemble the real data risking to leak privacy. Differential privacy (DP) provides theoretical guarantees on privacy loss but degrades data utility. Striking the best trade-off remains yet a challenging research question. In this study, we propose CTAB-GAN+ a novel conditional tabular GAN. CTAB-GAN+ improves upon state-of-the-art by (i) adding downstream losses to conditional GAN for higher utility synthetic data in both classification and regression domains; (ii) using Wasserstein loss with gradient penalty for better training convergence; (iii) introducing novel encoders targeting mixed continuous-categorical variables and variables with unbalanced or skewed data; and (iv) training with DP stochastic gradient descent to impose strict privacy guarantees. We extensively evaluate CTAB-GAN+ on statistical similarity and machine learning utility against state-of-the-art tabular GANs. The results show that CTAB-GAN+ synthesizes privacy-preserving data with at least 21.9% higher machine learning utility (i.e., F1-Score) across multiple datasets and learning tasks under given privacy budget.},
  archive      = {J_FDATA},
  author       = {Zhao, Zilong and Kunar, Aditya and Birke, Robert and Van der Scheer, Hiek and Chen, Lydia Y.},
  doi          = {10.3389/fdata.2023.1296508},
  journal      = {Frontiers in Big Data},
  month        = {1},
  pages        = {1296508},
  shortjournal = {Front. Big Data},
  title        = {CTAB-GAN+: Enhancing tabular data synthesis},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybridization of long short-term memory neural network in
fractional time series modeling of inflation. <em>FDATA</em>,
<em>6</em>, 1282541. (<a
href="https://doi.org/10.3389/fdata.2023.1282541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inflation is capable of significantly impacting monetary policy, thereby emphasizing the need for accurate forecasts to guide decisions aimed at stabilizing inflation rates. Given the significant relationship between inflation and monetary, it becomes feasible to detect long-memory patterns within the data. To capture these long-memory patterns, Autoregressive Fractionally Moving Average (ARFIMA) was developed as a valuable tool in data mining. Due to the challenges posed in residual assumptions, time series model has to be developed to address heteroscedasticity. Consequently, the implementation of a suitable model was imperative to rectify this effect within the residual ARFIMA. In this context, a novel hybrid model was proposed, with Generalized Autoregressive Conditional Heteroscedasticity (GARCH) being replaced by Long Short-Term Memory (LSTM) neural network. The network was used as iterative model to address this issue and achieve optimal parameters. Through a sensitivity analysis using mean absolute percentage error (MAPE), mean squared error (MSE), and mean absolute error (MAE), the performance of ARFIMA, ARFIMA-GARCH, and ARFIMA-LSTM models was assessed. The results showed that ARFIMA-LSTM excelled in simulating the inflation rate. This provided further evidence that inflation data showed characteristics of long memory, and the accuracy of the model was improved by integrating LSTM neural network.},
  archive      = {J_FDATA},
  author       = {Arif, Erman and Herlinawati, Elin and Devianto, Dodi and Yollanda, Mutia and Permana, Dony},
  doi          = {10.3389/fdata.2023.1282541},
  journal      = {Frontiers in Big Data},
  month        = {1},
  pages        = {1282541},
  shortjournal = {Front. Big Data},
  title        = {Hybridization of long short-term memory neural network in fractional time series modeling of inflation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
