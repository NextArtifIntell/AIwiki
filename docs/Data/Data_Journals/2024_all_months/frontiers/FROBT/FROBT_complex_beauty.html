<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>FROBT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="frobt---261">FROBT - 261</h2>
<ul>
<li><details>
<summary>
(2024). Editorial: Artificial intelligence and robotic applications
for smart monitoring and assistance in healthcare services.
<em>FROBT</em>, <em>11</em>, 1527773. (<a
href="https://doi.org/10.3389/frobt.2024.1527773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The collection of research presented here underscores the impact that advanced technologies, 70 especially AI and robotic applications, can have in revolutionizing healthcare systems. Advanced 71 technologies, for instance, will not only contribute to enhancing clinical decision-making but also 72 contribute to offering a more patient-centered and preventive approach to care. As these tools 73 continue to evolve, they promise a more efficient, responsive, and data-driven healthcare ecosystem. 74 However, to maximize their impact and mitigate potential risks, all stakeholders must address issues 75 related to data privacy, ethical AI applications, and equitable access to ensure the responsible and 76 effective implementation of these technologies. 77The works presented in this editorial represent early steps toward a future where these technologies 78 are fully integrated into routine healthcare practice. However, realizing this future will require 79 continued research, cross-disciplinary collaboration, and thoughtful integration of new tools into 80 clinical workflows. Future efforts are needed from researchers across clinical and engineering fields 81 to improve the integration of technological advancements and facilitate the transfer of these 82 innovations into clinical practice. Cross-disciplinary collaboration will be essential for refining proof-83 of-concept tools and ensuring their practical application in healthcare.},
  archive      = {J_FROBT},
  author       = {Mennella, Ciro and Maniscalco, Umberto and Masala, Giovanni Luca and Esposito, Massimo},
  doi          = {10.3389/frobt.2024.1527773},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1527773},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Artificial intelligence and robotic applications for smart monitoring and assistance in healthcare services},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparative analysis of creative problem solving tasks
across age groups using modular cube robotics. <em>FROBT</em>,
<em>11</em>, 1497511. (<a
href="https://doi.org/10.3389/frobt.2024.1497511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Anik, Mehedi Hasan and Romero, Margarida},
  doi          = {10.3389/frobt.2024.1497511},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1497511},
  shortjournal = {Front. Robot. AI},
  title        = {Comparative analysis of creative problem solving tasks across age groups using modular cube robotics},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A versatile real-time vision-led runway localisation system
for enhanced autonomy. <em>FROBT</em>, <em>11</em>, 1490812. (<a
href="https://doi.org/10.3389/frobt.2024.1490812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tsapparellas, Kyriacos and Jelev, Nickolay and Waters, Jonathon and Shrikhande, Aditya M. and Brunswicker, Sabine and Mihaylova, Lyudmila S.},
  doi          = {10.3389/frobt.2024.1490812},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1490812},
  shortjournal = {Front. Robot. AI},
  title        = {A versatile real-time vision-led runway localisation system for enhanced autonomy},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting passive behaviours for diverse musical playing
using the parametric hand. <em>FROBT</em>, <em>11</em>, 1463744. (<a
href="https://doi.org/10.3389/frobt.2024.1463744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Gilday, Kieran and Pyeon, Dohyeon and Dhanush, S. and Cho, Kyu-Jin and Hughes, Josie},
  doi          = {10.3389/frobt.2024.1463744},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1463744},
  shortjournal = {Front. Robot. AI},
  title        = {Exploiting passive behaviours for diverse musical playing using the parametric hand},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Can a human sing with an unseen artificial partner?
Coordination dynamics when singing with an unseen human or artificial
partner. <em>FROBT</em>, <em>11</em>, 1463477. (<a
href="https://doi.org/10.3389/frobt.2024.1463477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Nishiyama, Rina and Nonaka, Tetsushi},
  doi          = {10.3389/frobt.2024.1463477},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1463477},
  shortjournal = {Front. Robot. AI},
  title        = {Can a human sing with an unseen artificial partner? coordination dynamics when singing with an unseen human or artificial partner},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Music, body, and machine: Gesture-based synchronization in
human-robot musical interaction. <em>FROBT</em>, <em>11</em>, 1461615.
(<a href="https://doi.org/10.3389/frobt.2024.1461615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Gao, Xuedan and Rogel, Amit and Sankaranarayanan, Raghavasimhan and Dowling, Brody and Weinberg, Gil},
  doi          = {10.3389/frobt.2024.1461615},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1461615},
  shortjournal = {Front. Robot. AI},
  title        = {Music, body, and machine: Gesture-based synchronization in human-robot musical interaction},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fostering children’s creativity through LLM-driven
storytelling with a social robot. <em>FROBT</em>, <em>11</em>, 1457429.
(<a href="https://doi.org/10.3389/frobt.2024.1457429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Elgarf, Maha and Salam, Hanan and Peters, Christopher},
  doi          = {10.3389/frobt.2024.1457429},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1457429},
  shortjournal = {Front. Robot. AI},
  title        = {Fostering children’s creativity through LLM-driven storytelling with a social robot},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). What about spiritual needs? Care robotics and spiritual
care. <em>FROBT</em>, <em>11</em>, 1455133. (<a
href="https://doi.org/10.3389/frobt.2024.1455133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Simmerlein, Jonas and Tretter, Max},
  doi          = {10.3389/frobt.2024.1455133},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1455133},
  shortjournal = {Front. Robot. AI},
  title        = {What about spiritual needs? care robotics and spiritual care},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Launching stealth AutoGuideTM robot for stereotactic biopsy
procedures in a neurosurgical centre: Learning curve and workflow
optimization. <em>FROBT</em>, <em>11</em>, 1437568. (<a
href="https://doi.org/10.3389/frobt.2024.1437568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Barth, Marcus and Holl, Etienne and Flaschka, Fabian and Karakaya, Sila and Körbler, Vitus and Pichlsberger, Melanie and Wolfsberger, Stefan and Micko, Alexander},
  doi          = {10.3389/frobt.2024.1437568},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1437568},
  shortjournal = {Front. Robot. AI},
  title        = {Launching stealth AutoGuideTM robot for stereotactic biopsy procedures in a neurosurgical centre: Learning curve and workflow optimization},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A roadmap for improving data quality through standards for
collaborative intelligence in human-robot applications. <em>FROBT</em>,
<em>11</em>, 1434351. (<a
href="https://doi.org/10.3389/frobt.2024.1434351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Mehak, Shakra and Ramos, Inês F. and Sagar, Keerthi and Ramasubramanian, Aswin and Kelleher, John D. and Guilfoyle, Michael and Gianini, Gabriele and Damiani, Ernesto and Leva, Maria Chiara},
  doi          = {10.3389/frobt.2024.1434351},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1434351},
  shortjournal = {Front. Robot. AI},
  title        = {A roadmap for improving data quality through standards for collaborative intelligence in human-robot applications},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization design and experiment of cam-elliptical gear
combined vegetables curved surface labeling mechanism. <em>FROBT</em>,
<em>11</em>, 1431078. (<a
href="https://doi.org/10.3389/frobt.2024.1431078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Zhang, Lei and Zhou, Heng and Chen, Jianneng and Tong, Junhua and Liu, Yang and Zhang, Xiaowei},
  doi          = {10.3389/frobt.2024.1431078},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1431078},
  shortjournal = {Front. Robot. AI},
  title        = {Optimization design and experiment of cam-elliptical gear combined vegetables curved surface labeling mechanism},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing teleoperation for legged manipulation with
wearable motion capture. <em>FROBT</em>, <em>11</em>, 1430842. (<a
href="https://doi.org/10.3389/frobt.2024.1430842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Zhou, Chengxu and Wan, Yuhui and Peers, Christopher and Delfaki, Andromachi Maria and Kanoulas, Dimitrios},
  doi          = {10.3389/frobt.2024.1430842},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1430842},
  shortjournal = {Front. Robot. AI},
  title        = {Advancing teleoperation for legged manipulation with wearable motion capture},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Augmenting visual feedback with visualized interaction
forces in haptic-assisted virtual-reality teleoperation. <em>FROBT</em>,
<em>11</em>, 1427095. (<a
href="https://doi.org/10.3389/frobt.2024.1427095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {van den Berg, Alex and Hofland, Jelle and Heemskerk, Cock J. M. and Abbink, David A. and Peternel, Luka},
  doi          = {10.3389/frobt.2024.1427095},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1427095},
  shortjournal = {Front. Robot. AI},
  title        = {Augmenting visual feedback with visualized interaction forces in haptic-assisted virtual-reality teleoperation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiuser design of an architecture for social robots in
education: Teachers, students, and researchers perspectives.
<em>FROBT</em>, <em>11</em>, 1409671. (<a
href="https://doi.org/10.3389/frobt.2024.1409671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tozadore, Daniel C. and Romero, Roseli A. F.},
  doi          = {10.3389/frobt.2024.1409671},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1409671},
  shortjournal = {Front. Robot. AI},
  title        = {Multiuser design of an architecture for social robots in education: Teachers, students, and researchers perspectives},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple-agent promotion in a grocery store: Effects of
modality and variability of agents on customer memory. <em>FROBT</em>,
<em>11</em>, 1397230. (<a
href="https://doi.org/10.3389/frobt.2024.1397230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Mizuho, Takato and Okafuji, Yuki and Baba, Jun and Narumi, Takuji},
  doi          = {10.3389/frobt.2024.1397230},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1397230},
  shortjournal = {Front. Robot. AI},
  title        = {Multiple-agent promotion in a grocery store: Effects of modality and variability of agents on customer memory},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MACRPO: Multi-agent cooperative recurrent policy
optimization. <em>FROBT</em>, <em>11</em>, 1394209. (<a
href="https://doi.org/10.3389/frobt.2024.1394209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Kargar, Eshagh and Kyrki, Ville},
  doi          = {10.3389/frobt.2024.1394209},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1394209},
  shortjournal = {Front. Robot. AI},
  title        = {MACRPO: Multi-agent cooperative recurrent policy optimization},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). L-AVATeD: The lidar and visual walking terrain dataset.
<em>FROBT</em>, <em>11</em>, 1384575. (<a
href="https://doi.org/10.3389/frobt.2024.1384575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Worldwide, a significant number of individuals depend on assistive robotic technologies, such as sophisticated lower-limb prostheses and comprehensive exoskeletons to address challenges related to gait and mobility (Laschowski et al. (2020); Hu et al. (2018)). These innovative devices significantly improve the quality of life for people with various disabilities, enabling them to navigate real-world environments more effectively and with greater independence. Despite significant advancements in recent decades, these systems often struggle with prompt and accurate responses to changes in the local environment Hu et al. (2018). Typically, users either control these systems directly or use semi-autonomous modes, frequently needing to manually switch locomotion modes to adapt to different terrains (Laschowski et al. (2022)). This requirement imposes an additional cognitive burden, potentially leading to distraction or injury. Recent research highlights the potential for substantial enhancements in exoskeleton control systems by transitioning away from user-initiated to automated locomotion mode changes (such as shifting from walking on flat surfaces to climbing stairs) to more autonomous control systems. A critical aspect of such systems is their ability to precisely classify the local environment Laschowski et al. (2020)).Conventionally, the study and diagnosis of gait conditions is conducted in laboratory settings, where clinicians can control numerous variables and observe patients on a known walking surface. While this ensures accuracy, it limits the evaluation of gait patterns in varied natural environments and walking terrains Adamczyk et al. (2023).Emerging studies, (e.g. Dixon et al. (2018)) have demonstrated that gait is materially affected by the walking surface. Specifically, walking surfaces have been shown to impact lower-extremity muscle activity (Voloshina and Ferris (2015)), joint kinematics (Dixon et al. (2021)), inter-joint coordination and variability (Ippersiel et al. (2021), Ippersiel et al. (2022)), and joint kinetics (Lay et al. (2006)). Freeing researchers from the constraints imposed by the laboratory requires moving away from measurement systems designed to operate in a fixed environment, towards more portable hardware solutions that can function in ecological contexts. One issue that remains, however, is the ability of portable systems to accurately classify walking surfaces.Portable gait analysis systems with multiple participant-mounted inertial measurement units (IMUs) can themselves be used to classify walking terrain. Shah et al. (2022) used 6 sensors to distinguish 9 surface types in a group of 30 young healthy adults using a machine learning algorithm. It remains unclear however if terrain classification accuracy from IMU data would be affected by patient pathology. That is, algorithms based on IMU data alone may incorrectly assess patient pathology or severity of impairment due to particularities of terrain on which walking is performed. The data IMUs produce is valuable, but data collection outside of the lab could cause them to suffer from exactly the problem they are trying to solve; namely the lack of a known, controlled walking surface. While these mobile systems capture patient gait characteristics, they must also leverage additional sensor capabilities to simultaneously deliver an accurate, ground-truth classification of the local walking terrain.Advancements in Deep Learning, particularly in Convolutional Neural Network (CNN) architectures, have shown remarkable success in image classification Krizhevsky et al. (2012). Various studies (Laschowski et al. (2022); Diaz et al. (2018); Diaz et al. (2018)) have successfully used deep learning and visual data for accurate terrain identification, but these techniques require expansive data sets for their training. Combining multiple data modalities, such as depth sensors (Zhang et al. (2011); Zhang et al. (2019)) and IMUs (Shah et al. (2022)) show promise, though more comprehensive studies (e.g. Zhang et al. (2011)), and publicly available datasets remain scarce. While databases hosting visual images or depth data are available, few if any exist in this domain that provide both modalities of data captured of a single scene (Laschowski et al. (2020)). Further, none could be found that combine these modalities of data with simultaneous measurement of the device orientation sensors.The proliferation of interpreted (stereo camera) or directly measured (LiDAR) depth data into a modern smartphone&amp;#39;s sensor capabilities presents a new opportunity for terrain classification. Gyroscopes, magnetometer (compass), and accelerometer sensors are now included in even modest smartphones and allow capture of device orientation and inertia at the same instant as image and depth data. This synergy of visual, depth, and orientation data can potentially enhance environmental recognition accuracy. This paper presents a method to capture a high-resolution, multi-modal dataset in real-time without expensive, professional grade equipment, and an novel dataset that can be used in the aforementioned domains. We expect that providing access to a dataset that hosts multiple modalities of simultaneously captured data will prove invaluable to many groups, from engineers developing high level control systems for exoskeletons, to researchers studying gait. Whether using visual, depth, or other modalities of data, In this data report, we provide a detailed description of the dataset, our hardware and methods for collecting the data, and post-processing steps taken to improve the utility and accessibility of the data. We conclude with suggestions for how other researchers may use this dataset. Analyses of the database for walking terrain classification will be presented in future work.To accurately reflect surfaces common in the built environment inside and surrounding typical North-American academic and healthcare institutions, 9 terrain classes were chosen for this investigation: banked-left, banked-right, irregular, flat-even, grass, sloped-up, sloped-down, stairs-up and stairs-down.While the class names were designed to be as descriptive as possible, some explanation is warranted.The banked-[left,right] labels were applied in cases where the terrain declined significantly, perpendicular to the direction of motion. In cases where another class might also apply (e.g. grass, irregular), these labels were given precedence.The flat-even class was a base-case; indicating any terrain that was generally smooth and solid, and neither sloped, banked nor grassy. Samples may include any material (e.g. concrete, tile) or color (there are many examples exhibiting bright colours and patterns).Irregular surfaces were defined as those that had no slope up/down or left/right and had enough irregularity that they might be expected to materially affect gait. Examples include cobblestone, gravel, and rough mud.Surfaces were labelled as grass if they were generally flat, similar to irregular in that they should be neither sloped nor banked, and consisted primarily of short grasses found on typical found in North American lawns.sloped-[up,down] were defined as any surface (including grassy ones) which had a significant incline or decline in the immediate direction of motion.stairs- [up,down] were the easiest to label, and consisted of stairs of any material, indoors or out.Examples of visual and LiDAR image from each class can be seen in figure 1.Apple&amp;#39;s (Apple Inc., Cupertino, USA) iPhone (iOS) was chosen as the platform for collecting our walking terrain dataset due to their built-in LiDAR sensor as well as extensive, well-documented APIs for capturing and manipulating depth data. Data were captured on three physical devices (1 iPhone 12 Pro and 2 iPhone 14 Pros). While it&amp;#39;s possible to extract depth data from mobile devices which interpret depth data using stereoscopic methods Wang et al. (2019), we chose devices which contain a built-in LiDAR scanner, for accuracy and consistency.Visual (RGB) images were captured in landscape orientation using the front-facing cameras of each of the iPhone 12 and 14. Data were captured at the native resolution of the sensor: 4032&amp;#215;3024 pixels, RGB, 8-bit per channel and were stored using the Apple High Efficiency Image File Format (HEIF).The specifications for the LiDAR scanner are not available directly from the manufacturer, but Luetzenburg et al. (2021) performed and in-depth analysis of the iPhone 12/14 LiDAR hardware (the devices share the same sensor) for applications in geosciences. Their conclusions coincide with the output LiDAR depth map dimensions we recorded, at 768x576 pixels. In this dataset, each LiDAR &amp;quot;pixel&amp;quot; uses a full 32-bits to store depth data.It should be noted that while differing device models were used to collect samples, both the visual and LiDAR data were identical in spatial and depth resolution. Data were collected over six months during the spring and summer of 2023, by three young healthy adult members of our research lab. Participants were fitted with a chest-mounted mobile-phone harness.The harness allowed for hands free data capture and provided some consistency in data capture across participants. iPhones were clipped to the harness horizontally (i.e. in &amp;quot;landscape orientation&amp;quot;) using the built-in mount, with an initial angle between 30-50 degrees downward from the horizon. This orientation provided a wide view of the local walking surface within about a meter in front of the participant and up to roughly 5 meters away, depending on the local terrain. The variation in mounting angle was similar in magnitude to the small up and down variation of camera field of view introduced by simple act of walking. This small amount of noise acts, in effect, as a natural regularizer for the dataset, and will help e.g. a Convolutional Neural Network trained on it to better generalize on unseen data.A custom iOS application was written to simplify simultaneous capture and labelling of visual, LiDAR, and device orientation data at 1Hz. This capture frequency provided a balance between volume of data recorded while preventing too many captures of the same visual scene (i.e., walking terrain). In an individual capture session, participants would select the terrain type (based on their visual interpretation upcoming terrain and the definitions above) in the capture application, tap begin data capture, and terminate capture before the terrain class changed. The data would then be automatically labelled and stored on the device. Data were imported from each device into a central repository and individually reviewed (by D.W.) for labelling errors. All members who participated in data collection were briefed on use of the system prior to data collection. Data were labelled in sequence, with a numeric prefix indicating the order of capture [000-999], and a unique suffix in the form of a universally unique identifier (UUID). Every image pair has the same file name, apart from an additional suffix &amp;quot; depth&amp;quot; on the LiDAR disparity map and differing file extension.The gravity vector data was captured into individual comma-separated-values files, each with the matching UUID suffix. 7,968 RGB/LiDAR image pairs were captured along with the device orientation gravity vector, but due to availability of suitable terrain, class data is imbalanced (Table 1). Class imbalance, while not ideal, can be easily handled using any number of techniques when actually making use of the data. While training a Convolutional Neural Network for example, oversampling of the minority class, adding class weights to the loss function, or using ensemble methods such as bagging and boosting are some common solutions.With the goal of making the dataset more manageable (the raw dataset is almost 45GBs in size), RGB images were pre-processed by reducing their size from 4032x3024 pixels to 512x384 pixels. Resizing used Apple&amp;#39;s Scriptable Image Processing System (SIPS) and simultaneously converted images to a more standard JPEG format from their native HEIF format.Processing the LiDAR data required special care, as it is captured in a format not readily consumed by typical image libraries. LiDAR data were captured and stored natively as 32-bit disparity maps (disparity = 1 / distance) and saved to TIFF files. These files were down sampled and normalized using OpenCV Itseez (2015), converted to 8-bit grayscale, and exported to JPEG. At 768x576 pixels, the spatial resolution of the built-in LiDAR scanner is much lower than the visual camera, and so these images were not pre-scaled.A device orientation vector was also recorded at the instant both the visual and LiDAR data were captured. This orientation vector is recorded relative to gravity and the iPhone device axes. It is normalized in each direction in units of the accepted acceleration due to gravity at Earth&amp;#39;s surface, i.e. 9.8m/s 2 . These vectors are difficult to use in their raw (x, y, z) vector format, and were translated to more understandable pitch and roll values using the 2-element arc-tangent function:pitch = atan2(z, x)(1)and,roll = atan2(z, y)(2)where pitch is defined as the angle down from the horizon, and roll as deviation either clockwise or anti-clockwise from the horizon line itself.A comprehensive understanding of the local walking context is crucial both for human gait analysis and the advanced control systems of robotic prostheses. Relying solely on laboratory analysis limits researchers&amp;#39; capacity to accurately evaluate clinical gait in patients and hinders the optimal functioning of robotic prostheses in varied ecological contexts. Consequently, conducting studies across a spectrum of walking terrains is essential to address these limitations. A ground-truth understanding of walking terrain is traditionally identified using simple visual data and Deep Neural Networks, in particular ConvolutionalNeural Networks (CNNs). While CNNs are ideal for this classification task, they require extensive training data which may not be readily available.Multiple studies ((Ophoff et al., 2019), (Melotti et al., 2018), (AlDahoul et al., 2021)) have revealed that classifiers trained using multi-modal data (and in particular a combination of depth and visual data) can outperform simple visual classification in object-detection and image classification (Schwarz et al., 2015). Previous datasets in the context of walking terrain have provided only a single modality of data L-AVATeD is notable for being the only open-source database of its kind to provide not just two, but three modalities of data captured simultaneously for a given scene of walking terrain. While not as large as the largest available walking terrain datasets reviewed by Laschowski et al. (2020), at almost 8,000 samples L-AVATeD matches the median dataset size. Further, the spatial resolution of the published RGB images in L-AVATeD (at 4032x3024 pixels) is more than 9 times higher than the highest resolution presented. Images at resolutions of this magnitude may prove unwieldy for most neural networks, especially the low-resource-optimized architectures available for use in mobile and edge-computation hardware. It remains important however to preserve as much signal as possible to not limit future research, and so full-resolution images are provided.Depth data, captured via LiDAR were in fact saved as disparity maps (i.e. 1/distance). Notably, signal decreases as distance increases. At 768x576 &amp;quot;pixels&amp;quot; of native spatial resolution, these too are the most information-dense depth measurements in any of the environment recognition systems reviewed in Laschowski et al. (2020). To ensure we did not introduce any algorithmic bias to the depth data, the capture program was instructed to replace missing signal (depth &amp;quot;pixels&amp;quot;) with a placeholder N aN value rather than automatically interpolating such points. This allows researchers to handle the missing data however they see fit, for example: replacing with zeros, average depth, or an interpolation scheme. The raw depth maps are available as TIFF files. To make the depth data easily accessible, a copy is provided created using a very simple algorithm of replacing missing data with zeros, normalizing, and then compressing the depth dimension into 8 bits before saving the file as a JPEG. This format provides a representation suitable for use in most deep neural network software packages. It should be noted however that this simple algorithm is effectively a lossy compression of the data, and while useful, should not be considered as the most information-rich representation. Examples of these lossy depth-data representations can be seen in Figure 1 (bottom row).Device orientation data were captured as a gravity vector. The raw data are available as comma-separated values, indexed with the sample UUID. This raw format is not easily interpreted by humans, and so each was converted to a more easily understood pitch (camera angle up and down relative to the horizon) and roll (camera rotation clockwise and anti-clockwise relative to the horizon). Per-class pitch and roll statistics are provided in Table 1. Preliminary post-hoc analyses of these statistics do not immediately reveal significant signal, but used in combination with the RGB and LiDAR data counterparts, in a deep learning context in particular could prove fruitful. For example, researchers might use this data to &amp;quot;de-rotate&amp;quot; an image using the inverse device rotation angle before passing it into the classifier, potentially improving classifications where horizon angle of the scene may be important.},
  archive      = {J_FROBT},
  author       = {Whipps, David and Ippersiel, Patrick and Dixon, Philippe C.},
  doi          = {10.3389/frobt.2024.1384575},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1384575},
  shortjournal = {Front. Robot. AI},
  title        = {L-AVATeD: The lidar and visual walking terrain dataset},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating collaborative robots in manufacturing,
logistics, and agriculture: Expert perspectives on technical, safety,
and human factors. <em>FROBT</em>, <em>11</em>, 1342130. (<a
href="https://doi.org/10.3389/frobt.2024.1342130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Pietrantoni, Luca and Favilla, Marco and Fraboni, Federico and Mazzoni, Elvis and Morandini, Sofia and Benvenuti, Martina and De Angelis, Marco},
  doi          = {10.3389/frobt.2024.1342130},
  journal      = {Frontiers in Robotics and AI},
  month        = {12},
  pages        = {1342130},
  shortjournal = {Front. Robot. AI},
  title        = {Integrating collaborative robots in manufacturing, logistics, and agriculture: Expert perspectives on technical, safety, and human factors},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Influential voices in soft robotics.
<em>FROBT</em>, <em>11</em>, 1521226. (<a
href="https://doi.org/10.3389/frobt.2024.1521226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Each paper in this collection provides a fresh perspective on soft robotics, highlighting new approaches to design, novel materials, and enhanced methodologies. Together, these articles not only advance the science of soft robotics but also open the door to exciting new applications. Below is a summary of the contributions from this research topic, each illustrating a unique facet of the field.Addressing the theoretical foundations of soft robotics, Stella and Hughes offer a critical review of soft robot design methodologies. They explore the scientific motivations and challenges in designing soft robots, emphasizing the multidisciplinary nature of this endeavor. Their review covers bio-inspired design, computational methods, and emerging technologies, offering insights into how these approaches can enhance the creativity and functionality of soft robots. By formalizing the scientific questions that drive soft robot design, this paper lays the groundwork for future innovations in this field.One of the contributions in this collection is the study of omnidirectional soft pneumatic actuators by Moutousi and Polygerinos. Their work presents a novel design and optimization framework using finite element methods, focusing on achieving maximum performance by considering multiple design parameters simultaneously. This approach enables users to customize soft pneumatic actuators (SPAs) for various applications, such as rehabilitation and delicate object handling. The study offers valuable guidelines for SPA design optimization, contributing to more efficient and versatile soft actuators.Another fascinating advancement is highlighted in self-excited pneumatic valves for soft robotics by Nabae and Kitamura. Their research tackles the challenges of bulky driving systems in soft robotics by introducing a simplified self-excited valve system using a flat ring tube. This development promises to reduce the complexity of soft robotic systems, making them more efficient and adaptable to compact environments like pipelines or minimally invasive surgery. The success of their prototype demonstrates the potential for integrating this technology into locomotion systems, further pushing the boundaries of soft robot capabilities.In the realm of continuum robotics, the work on trunk-like soft robotic arms by Tang et al. stands out. Inspired by the dexterity and strength of biological structures like elephant trunks, this study investigates how design parameters such as material hardness and actuator arrangement can enhance performance in terms of workspace, stiffness, and payload capacity. Their findings provide a comprehensive methodology for improving the design of trunk-like soft arms, offering significant potential for applications requiring high adaptability, such as search and rescue missions or hazardous environment exploration.Finally, visuo-dynamic self-modeling in soft robotics, presented by Marques Monteiro et al., pushes the boundaries of control systems in soft robotics. Their end-to-end learning-based approach models soft robotic systems dynamically using visual data, allowing for more accurate control across a wide range of tasks, from trajectory tracking to obstacle avoidance. This method is a step forward in the quest for more intelligent and autonomous soft robots, capable of adapting to complex environments in real-time.Collectively, these contributions highlight the extraordinary potential of soft robotics while acknowledging the challenges that lie ahead. Each article in this collection showcases innovative solutions to critical problems in the field, ranging from optimization techniques for soft actuators to new control methodologies and bio-inspired designs. As soft robotics continues to evolve, the researchers featured here are poised to lead the next wave of innovation, pushing the boundaries of what these adaptable systems can achieve. By amplifying their voices, this collection not only recognizes their contributions but also underscores the importance of early-career researchers in shaping the future of robotics.We invite readers to explore these groundbreaking works and follow these influential voices as they continue to redefine the capabilities of soft robotics.},
  archive      = {J_FROBT},
  author       = {Polygerinos, Panagiotis},
  doi          = {10.3389/frobt.2024.1521226},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1521226},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Influential voices in soft robotics},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Autonomous (re)production, learning and
bio-inspired robotics workshop. <em>FROBT</em>, <em>11</em>, 1513495.
(<a href="https://doi.org/10.3389/frobt.2024.1513495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imagine an environment where autonomous systems (robots) are not designed by humans (or indeed designed at all) but are created through a series of steps that follow evolutionary processes. These robots will be &amp;quot;born&amp;quot; through the use of 3D manufacturing, for example, with novel materials and a hybridised hardware-software evolutionary architecture. &amp;quot;Child&amp;quot; robots will learn in a safe and controlled environment where success will be rewarded. The most successful individuals will make available their genetic code for reproduction and for the improvement of future generations. Building and using such systems will ultimately lead to a change in the way things are designed and manufactured.The Triangle of Life model, first presented in [1] and illustrated in figure 1, underpins this vision by proposing a generic conceptual framework for such systems in which robots can actually reproduce. This framework can be instantiated with different hardware approaches and different reproduction mechanisms, but in all cases the system revolves around the conception of a new robot organism. The other components of the Triangle capture the principal stages of such a system; the Triangle as a whole serves as a guide for realising this anticipated breakthrough and building systems where robot morphologies and controllers can evolve in real-time and real-space. The Autonomous (re)Production, Learning and Bio-inspired Robotics workshop was held in the historic city of York 17 th -19 th October 2022, supported by the EPSRC grant Autonomous Robot Evolution and inspired by The Triangle of Life. The workshop highlighted emerging trends and future directions in the field of robotics and featured invited position papers from world-leading researchers across the field, and a range of reviewed papers. Papers focused on the potential for future developments within the field of bio-inspired robotics and autonomous design and manufacture. The papers addressed areas such as: Novel methods for simultaneous evolution of morphology and control; Novel methods for facilitating learning and adaptation during lifetime; Evolution of learnability in a robot population; Investigating the balance between morphological intelligence and brain intelligence; Robot evolution in hardware; Evolution of morphologies using novel materials; Simulation of soft robots; Closing the reality gap; Evolving behavioural/morphological diversity within a robotic eco-system; Issues related to manufacturability and viability of robotic genotypes; Surrogate methods for fitness evaluations. This special issue includes three papers from that workshop and a strongly related paper to this area.Practical hardware for evolvable robots, by Angus et al. This paper explores in detail the design of an example system for realising diverse evolved physical robot bodies, and specifically how this interacts with the evolutionary process. The ultimate goal of evolutionary robotics is to evolve robots that are of practical use in real-world applications. To achieve this, it is necessary to progress beyond simulation and implement in hardware, addressing the challenges that this entails. The paper examines the interplay between an evolutionary robotics process and the hardware with which the evolved robots are to be implemented. An important finding highlighted in this paper is that the evolutionary process is not separable from the hardware, since the many constraints introduced by the hardware fundamentally define the nature of the phenotype space that the evolutionary process explores.On Evolutionary Robotics as a modelling tool in Evolutionary Biology, by Winfield explores the use of evolutionary robotics (ER) as a scientific instrument for addressing questions in evolutionary biology. The paper asks the question, What kind of model is an ER system?, by first using model descriptions to compare three case studies that have shed new light on the evolution of fish backbones, altruism, and modularity. The paper develops an analysis of the strengths and limitations of ER as a tool for modelling evolutionary biology followed by a review of the deeper questions in evolution and which of these might be modelled by ER. The paper concludes that that while ER is a weak model of evolution its bottom-up approach to modelling populations of evolving phenotypes and their embodied interactions does have value to biologists for testing and generating hypotheses.From real-time adaptation to social learning in robot ecosystems, by Szorkovszky et al. proposes and demonstrates a novel means for social learning of gait patterns, based on sensorimotor synchronization. The paper argues that using movement patterns of other robots as inputs can drive nonlinear decentralised controllers such as Central Pattern Generators into new limit cycles, hence encouraging diversity of movement patterns. The paper demonstrates a proof of principle using a simple social learning scheme for robot gaits. It is illustrated that useful behaviours can be imitated by only communicating a series of foot contact events, such as via audible footsteps. The approach allows for multiple behaviours to be learned and switched between.Learning hybrid locomotion skills-Learn to exploit residual actions and modulate model-based gait control, by Kasaei et al. proposes a locomotion framework based on a tight coupling between analytical control and deep reinforcement learning to leverage the potential of both approaches. The framework uses a model-based, full parametric closed-loop and analytical controller as a kernel to generate gait patterns. A neural network with symmetric partial data augmentation is used to automatically adjust the parameters for the gait kernel, and generate compensatory actions for all joints, augmenting the stability under unexpected perturbations. The paper indicates that the trained policies, in simulation, are robust to noise and model inaccuracies.[1] A. Eiben, N. Bredeche, M. Hoogendoorn, J. Stradner, J. Timmis, A. Tyrrell, and A. Winfield, &amp;quot;The triangle of life: Evolving robots in real-time and real-space&amp;quot; in Proc. of the 12th European Conference on the Synthesis and Simulation of Living Systems (ECAL 2013)},
  archive      = {J_FROBT},
  author       = {Tyrrell, Andy M. and Hart, Emma and Winfield, Alan and Eiben, A. E. and Timmis, Jon},
  doi          = {10.3389/frobt.2024.1513495},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1513495},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Autonomous (re)production, learning and bio-inspired robotics workshop},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Human–robot collaboration in industry 5.0: A
human-centric AI-based approach. <em>FROBT</em>, <em>11</em>, 1511126.
(<a href="https://doi.org/10.3389/frobt.2024.1511126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industry 5.0 is taking humans at the center of the workspace, avoiding to involve them in non-added value tasks, which can be automatized through the use of robots. In such a way, heavy, onerous, tedious, repetitive operations can be demanded of autonomous systems capable of adapting to the operating conditions, while the operator supervises the process, intervening if necessary. The operators’ expertise is indeed exploited in added-value tasks, enhancing their role. To effectively implement the Industry 5.0 paradigm, the full potential of human-robot collaboration has to be unleashed. The robot has to efficiently interact with the human, with natural and intuitive communication modalities. It also has to adapt to the requests of the operator, based on the operating environment. To this end, the adoption of AI techniques allows the deployment of intelligent systems, capable of perceiving the environment and the humans, embedding reasoning capabilities to make decisions, and learning from the humans and their own experience. These topics are tackled by the papers published in this Research Topic: robots for human assistance in the industrial setting [1], the effects of robotics on humans [2], human-robot collaboration modalities [3], and performance evaluation in human-robot collaboration [4]. In this Research Topic, the use of AI to enhance human-robot collaboration is indeed investigated. In [1] the authors discuss how humans can be augmented and not replaced by robotics and AI. The paper focuses on the state-of-the-art human-robot collaboration empowered by AI and its challenges and potential to implement the Industry 5.0 paradigm. [2] studies the eƯect on the users of diƯerent human-robot interaction modalities. This paper aims to better understand the acceptance and perception operators have of their robotic colleagues. [3] analyzes different human-robot communication modalities, especially concentrating on the naturalness of the interaction. The paper aims to evaluate which interaction approach would be suitable for an eƯective human-robot interaction in industry. In [4] the EUROBENCH software framework is introduced to evaluate the performance of bipedal robots, which might be used in the industrial setting to collaborate with humans (i.e., humanoid robots). This paper investigates how to evaluate the performance of such robots in complex scenarios, to better understand how they can assist humans in real workplaces. In conclusion, this Research topic provides an overview of current applications of robotics to Industry 5.0, especially making use of artiﬁcial intelligence to address the related open issues and challenges. The contributed papers provide interesting approaches to the topic, paving the way to enhanced human-robot collaboration in the industrial setting.},
  archive      = {J_FROBT},
  author       = {Roveda, Loris},
  doi          = {10.3389/frobt.2024.1511126},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1511126},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: human–robot collaboration in industry 5.0: a human-centric AI-based approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Advanced motion control and navigation of robots
in extreme environments. <em>FROBT</em>, <em>11</em>, 1510013. (<a
href="https://doi.org/10.3389/frobt.2024.1510013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The content of this issue has been organized as follows. The first paper (Mansfield and Montazeri, 2024) is a review paper discusses the application of reinforcement learning (RL) in active environmental monitoring (EM) systems. The need for reliable and intelligent monitoring solutions to address environmental pollution and climate change is highlighted, with a focus on the use of RL to train agents for adaptive and robust sensing in dynamic and extreme environments. The paper proposes a framework that formulates active sensing as an RL problem, unifying various EM tasks such as coverage, patrolling, source seeking, and exploration. Despite the potential of RL for EM applications, practical implementation and research in multi-agent systems are lacking, with most work remaining in the simulation phase.The next five papers address the navigation problems in unstructured and extreme environments. (Sadeghzadeh-Nokhodbderiz et. al. 2023) study the problem of attitude estimation of a quad-copter system when the quad is equipped with camera and gyroscope sensors in which cameras, usually suffer from a slow sampling rate and processing time delay compared to inertial sensors, such as gyroscopes. Toward this, a sampling importance resampling (SIR) particle filter (PF) is extended using a discretized attitude kinematics in Euler angles and the processing images captured by the camera using the ORB feature extraction method and the homography method in Python-OpenCV. Experimental results are provided for a DJI Tello type quadcopter to demonstrate the performance of the proposed method.(Sadeghzadeh-Nokhodberiz et. al., 2024) solves the problem of simultaneously localization and mapping (SLAM) for a multi-robot system in a dynamic environment. The use of several robots in large, complex, and dynamic environments can significantly improve performance on the localization and mapping task, which has attracted many researchers to this problem more recently. Toward this, a modified Fast-SLAM method is proposed by implementing SLAM in a decentralized manner by considering moving landmarks in the environment. Due to the unknown initial correspondence of the robots, a geographical approach is embedded in the proposed algorithm to align and merge their maps. Data association is also embedded in the algorithm; this is performed using the measurement predictions in the SLAM process of each robot.The study conducted by (Lim and Jo, 2022) introduces WA*DH+, an improved version of WA*DH for path planning and navigation of robots in the extreme environments. WA*DH struggles to find suboptimal nodes due to its filtering method, so the study inflated the suboptimality of the initial solution. WA*DH + uses the GBFS algorithm with an infinitely bounded suboptimal solution, resulting in faster solution returns than WA*DH.The work in (Sadeghzadeh-Nokhodberiz et. al., 2024), however, addresses the inter-agent collision avoidance problem for a group of quadcopters cooperate each other for a totally distributed collision-free formation tracking control using Barrier Lyapunov function (BLF). The problem is formulated in a backstepping setting where both tracking and inter-agent collision avoidance are obtained through a predefined accuracy due to the use of BLFs. Virtual control inputs are considered for the translational (x and y axes) subsystems that are then used to generate the desired values for the roll and pitch angles for the attitude control subsystem to solve the underactuated nature of the system leading to a hierarchical controller structure for each quadcopter. Finally, the attitude controller is designed for each quadcopter locally by taking into account a predetermined error limit by another BLF. Simulation results demonstrate the performance of the proposed approach.Nevertheless, the fifth paper on navigation published by (Sands, 2022) has incorporated optimality criteria in problem formulation. Optimization techniques are useful for autonomous navigation but face challenges like noisy multi-sensor technologies and computational burdens. This study aims to highlight the efficacy and limitations of common methods and proposes more, applying them to full, nonlinear, coupled equations of motion. Five different types of optimum guidance and control algorithms are presented and compared to a classical benchmark. Real-time optimization with singular switching and nonlinear transport theorem decoupling is introduced, showing superior performance in tracking errors, fuel usage, and computational burden.The investigation by (Hathaway et. al., 2023) addresses the need of teleoperation in challenging environments. The use of telerobotics for semi-autonomous robotic disassembly of electric vehicle batteries is studies in this work. It compares a traditional haptic-cobot framework with identical cobots, revealing a time reduction of 22%-57%. However, this improvement is mainly due to expanded workspace and 1:1 positional mapping, and a 10%-30% reduction in first attempt success rate. The study also highlights the importance of realism in directional information for unbolting and grasping tasks.The last paper is dealing with designing advanced motion controllers for robotics applications in front of external disturbances and uncertainties. (Nguyet and Ba, 2022) introduces the taskspace position-tracking control of robotic manipulators using an adaptive robust Jacobianbased controller. The controller&amp;#39;s structure is based on the conventional Proportional-Integral-Derivative (PID) paradigm. To compensate for both internal and external disturbances in the robot dynamics, an additional neural control signal is then synthesized under a non-linear learning law. Then, a novel gain learning feature is included to automatically change the PID gains for different operating situations, providing the high robustness of such a controller. Lyapunov constraints ensure the closed-loop system&amp;#39;s stability. Results from extensive simulations are used to rigorously verify the suggested controller&amp;#39;s effectiveness.},
  archive      = {J_FROBT},
  author       = {Montazeri, Allahyar and Sadeghzadeh-Nokhodberiz, Nargess and Shojaei, Khoshnam and Althoefer, Kaspar},
  doi          = {10.3389/frobt.2024.1510013},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1510013},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Advanced motion control and navigation of robots in extreme environments},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Localization and scene understanding in urban
environments. <em>FROBT</em>, <em>11</em>, 1509637. (<a
href="https://doi.org/10.3389/frobt.2024.1509637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regarding the reference map, nowadays different proposals from mapping companies such as TomTom [1] and Here [2], as well as self-driving companies like Waymo [3], are paving the way for reliable sources of information. On the other hand, open-source community-created geospatial projects like OpenStreetMap are also a valuable source of information that have been extensively used for research purposes over the last decade. Localization algorithms are responsible for accurate localization of the vehicle within the map. This is achieved using different on-board sensors, starting with the most obvious: GNSS. Despite these systems&amp;#39; ability to provide very good localization accuracies, up to the order of 0.01m, their reliability issues place them in the danger tier, especially in urban areas. This is due to the need for a clear line of sight to a significant part of the sky, which can be often obstructed by trees, buildings or urban canyons or even thick clouds.Matteo Frosi et al. investigated this aspect in their first contribution, focusing on the evaluation of the positioning accuracy and precision of localization systems that are not based on GNSS sensors. Besides presenting also a novel Simultaneous Localization and Mapping (SLAM) system that achieves real-time performance, the authors benchmarked a set of algorithms on manually collected datasets, demonstrating the active interest of the scientific community in the topic. They presented a comparison of algorithms that use LiDAR data coupled with inertial measurements units, a technique that has been extensively investigated over the last decade. Results from both outdoor and indoor scenarios show very promising results for real-world applications such as autonomous driving.In a second contribution, a different group also led by Matteo Frosi, proposed an algorithm that directly connects with the HD mapping concept previously described. Among all the features that HD maps integrate, they interestingly used one of the major sources of problems: the buildings themselves. They extended a SLAM system to exploit mapped buildings in OpenStreetMap by matching single LiDAR scan inputs. Their contribution also presented the re-localization capabilities of their systems. This approach is interesting and paves the way to further investigation in the field, as similar techniques could also be used for other elements of mapped environments.In this perspective, the work of the group led by Simone Mentasti proposes a pipeline to enrich HD-maps with traffic lights, enhancing their detection with specific features like shape, orientation, and pictogram. Unlike the previous two contributions, their focus is leveraging image information from onboard cameras on surveying vehicles and state-of-theart deep neural networks for traffic light detection. Furthermore, to accommodate GNSS errors during the mapping process, the authors proposed to use Kalman filtering techniques to provide the most accurate traffic light position possible.Even though localization is, in a way, a lower scale of complexity compared to SLAM algorithms, as they exploit already available maps, all the algorithms presented so far use special techniques that require high computational resources. Most of the time, parts of these algorithms include high-consuming subprocesses due to repetitive massive sets of operations performed on the sensed data. This can be the case of either LiDAR input with thousands of 3D points as well as imagery data, processed using deep neural networks. While specific hardware is available to speedup inference and classification of images, the same hardware can be used to parallelize consolidated filtering techniques. This is demonstrated in the last work presented in this collection, where Lesia Mochurad proposed an implementation of a parallel Kalman filter algorithm to speedup vehicle localization based on a specific usage of the LiDAR data. Using the CUDA programming language and NVIDIA hardware, her proposal achieved a 3.8x speedup compared to the original unparallelized implementation of the Kalman algorithm, which is remarkable as it allows easy scaling with the number of 3D LiDAR points used for localization.},
  archive      = {J_FROBT},
  author       = {Parra Alonso, Ignacio and Sorrenti, Domenico G. and Cattaneo, Daniele and Ballardini, Augusto Luis},
  doi          = {10.3389/frobt.2024.1509637},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1509637},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Localization and scene understanding in urban environments},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Pipeline inspection robots. <em>FROBT</em>,
<em>11</em>, 1497809. (<a
href="https://doi.org/10.3389/frobt.2024.1497809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Editorial on the Research Topic: Pipeline Inspection Robots, Autonomous underwater interventionRecent years have witnessed an incredible progress in Artificial Intelligence (AI), Machine Learning, Robotics and Digital Technologies. The research topic: &amp;quot;Pipeline Inspection Robots&amp;quot; demonstrates the power of AI to introduce autonomy is difficult underground environments, not so friendly for human operations.This special issue identifies challenges and proposes potential solutions to autonomous robot tasks in pipe networks. Some of the challenges are due to a number of factors: the infrastructure (e.g. winding pipes, curved or branched), the sensors and intelligent sensing methods, robot resilience to sub-terrain environments and GPS-denied communications. This special issue introduces the state-of-the-art research on pipeline inspection robots and contains contribution articles showing the potential of autonomous robots to revolutionise work and empower maintenance teams in their difficult tasks. This special issue also brings together papers from very different perspectives: autonomous control of in-pipe inspection robots, robot localization, environmental adaptation mechanisms, and safety in collaborative robotics.We called for the participation of researchers and engineers working in this field and we collected the contributions on the topics described in the next section. Four papers were accepted as a result of the call for manuscripts.Article (Nauert and Kampmann) identifies key requirements to autonomous underwater robots and major challenges which need to be addressed in development of new technologies. High level of autonomy constitutes the main challenge. The paper gives an overview of works for inspection, including inspection with visual, acoustic and electromagnetic methods. Different inspection and maintenance tasks performed by industry are discussed in connection with the technology and the current state-of-the-art of underwater robots is presented. This work focuses on maintenance and inspection from the outside of the underwater pipe. The inspection and maintenance tasks, required by the industry and the currently employed tooling, are described and the current state of underwater robots was presentedIn (Kakogawa and Ma) an in-pipe crawler robot is developed. It has a modular structure and can automatically shift its body shape. The robot can shift its body shape to a parallelogram and adapts to obstacles and environmental conditions thanks to the crawlers. The influence of the robot roll angle, torques, parameters and external factors are studied in detail. The impact of the initial robot resistance is also thoroughly studied. The advantages of the designed mechanism are demonstrated over real experiments.Pipe networks challenge vision-based navigation systems since there are no well pronounced features in images, such as corners, lines and repeated texture. To address this challenge, Edwards et al. develop a method for robot localisation in pipe networks that is able to deal with the sparse image features. The importance of approximate localization methods operating in one degree-of-freedom environment along the pipe length that are robust to environmental changes is discussed with respect to accurate odometry methods, operating in six degrees of freedom, but requiring well visible image features.Nguyen et al. introduce a miniaturised mobile robot with efficient control for pipe inspection. The aim is to fully automate the inspection of 75-mm-diameter sewers without any visual aid or power-intensive image processing tools. The wheel-legs mechanism allow the robot to move through uneven terrains. The robot implements an interesting idea about a high-level control and low-level control. Low-level control is primarily aimed at achieving stability, moving to and along the center of pipes. High-level control is used to determine the local robot state, and for during decision making.However, the common points among them are how we develop the high performance robot within the extremely large space limitation and the harsh environment. This requires how to maximize the performance under limited conditions, which is very useful information not only for pipe inspection robots but also for many other robotics research and development efforts in terms of robot size and weight reduction, simplification, cost reduction, etc. We hope that the results of this special issue will be helpful to readers in a wide range of fields and lead to further development.Computational aspects and efficiency are essential since these robots operate under constraints, including from energy perspectives.The creation of miniature robots, equipped with computational and communication resources requires further attention. This issue presents current developments from this area.},
  archive      = {J_FROBT},
  author       = {Nakamura, Taro and Kakogawa, Atsushi and Mihaylova, Lyudmila},
  doi          = {10.3389/frobt.2024.1497809},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1497809},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Pipeline inspection robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). X-ray fluoroscopy guided localization and steering of
miniature robots using virtual reality enhancement. <em>FROBT</em>,
<em>11</em>, 1495445. (<a
href="https://doi.org/10.3389/frobt.2024.1495445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ceylan, Hakan and Le, Tuan Anh and ALABAY, Husnu Halid},
  doi          = {10.3389/frobt.2024.1495445},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1495445},
  shortjournal = {Front. Robot. AI},
  title        = {X-ray fluoroscopy guided localization and steering of miniature robots using virtual reality enhancement},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Abraded optical fibre-based dynamic range force sensor for
tissue palpation. <em>FROBT</em>, <em>11</em>, 1489884. (<a
href="https://doi.org/10.3389/frobt.2024.1489884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Althoefer, Kaspar and Angelmahr, Martin and Godaba, Hareesh and Zhang, Zhenyu and Mack, Thomas and Chavali, Vamsi K. and Dawood, Abu Bakar},
  doi          = {10.3389/frobt.2024.1489884},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1489884},
  shortjournal = {Front. Robot. AI},
  title        = {Abraded optical fibre-based dynamic range force sensor for tissue palpation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of an upper limb passive exosuit for the 2023
ASTM exo games. <em>FROBT</em>, <em>11</em>, 1485177. (<a
href="https://doi.org/10.3389/frobt.2024.1485177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Kindt, Stijn and Thiery, Elias and Hamelryckx, Stijn and Deraes, Adrien and Verstraten, Tom},
  doi          = {10.3389/frobt.2024.1485177},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1485177},
  shortjournal = {Front. Robot. AI},
  title        = {Development of an upper limb passive exosuit for the 2023 ASTM exo games},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning signs with NAO: Humanoid robot as a tool for
helping to learn colombian sign language. <em>FROBT</em>, <em>11</em>,
1475069. (<a href="https://doi.org/10.3389/frobt.2024.1475069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Castellanos, Jorge and Garzón-Castro, Claudia L. and Mora Zarate, Juan Esteban},
  doi          = {10.3389/frobt.2024.1475069},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1475069},
  shortjournal = {Front. Robot. AI},
  title        = {Learning signs with NAO: Humanoid robot as a tool for helping to learn colombian sign language},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the feasibility of a robotic probe manipulator for
echocardiography in the prone position. <em>FROBT</em>, <em>11</em>,
1474077. (<a href="https://doi.org/10.3389/frobt.2024.1474077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Gifari, Muhammad Wildan and Machino-Ohtsuka, Tomoko and Machino, Takeshi and Hassan, Modar and Suzuki, Kenji},
  doi          = {10.3389/frobt.2024.1474077},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1474077},
  shortjournal = {Front. Robot. AI},
  title        = {On the feasibility of a robotic probe manipulator for echocardiography in the prone position},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Addressing catastrophic forgetting in payload parameter
identification using incremental ensemble learning. <em>FROBT</em>,
<em>11</em>, 1470163. (<a
href="https://doi.org/10.3389/frobt.2024.1470163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sun, Ronglei and Al-Yacoub, Ali and Elgeneidy, Khaled and Taie, Wael},
  doi          = {10.3389/frobt.2024.1470163},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1470163},
  shortjournal = {Front. Robot. AI},
  title        = {Addressing catastrophic forgetting in payload parameter identification using incremental ensemble learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How to arrange the robotic environment? Leveraging
experience in both motion planning and environment optimization.
<em>FROBT</em>, <em>11</em>, 1468385. (<a
href="https://doi.org/10.3389/frobt.2024.1468385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Lu, Jiaxi and Takamido, Ryota and Wang, Yusheng and Ota, Jun},
  doi          = {10.3389/frobt.2024.1468385},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1468385},
  shortjournal = {Front. Robot. AI},
  title        = {How to arrange the robotic environment? leveraging experience in both motion planning and environment optimization},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Variable autonomy for human-robot teaming.
<em>FROBT</em>, <em>11</em>, 1465183. (<a
href="https://doi.org/10.3389/frobt.2024.1465183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern era, the integration of robots has become a cornerstone of progress in various sectors, 5 from entertainment and companionship to first responders and defence. One of the critical aspects of this 6 integration is the concept of Human-Robot Teaming (HRT). Unlike traditional automation, where robots 7 operate in isolation or perform predefined tasks, HRT involves robots working alongside humans and 8 aiming to achieve shared goals, often in dynamic and interactive environments. This collaboration leverages 9 the strengths of both humans and robots to achieve goals that neither could accomplish as effectively alone.10 Such capabilities often involve teaming with well-defined and static control frameworks: humans in-, 11 on-, or out-of-theloop. However, as the world is not static and more complex tasks are required of the 12 team, the ability to dynamically allocate tasks with varying levels of autonomy becomes essential. Variable 13 Autonomy (VA) refers to the ability of the robotic systems to dynamically vary their level or degree of Human-robot teams must handle a diverse array of tasks of variable complexity, from gross and fine 25 motor skills to visual perception, cognitive processing, and speech. Such tasks may coincide or occur in 26 quick succession. For efficient teaming, robots must be able to identify these composite, concurrent tasks 27 performed by humans.28 (Baskaran and Adams, 2023) review over a hundred task recognition algorithms and evaluate them on six 29 criteria: sensitivity, suitability, generalizability, composite factor, concurrency, and anomaly awareness.Through the extensive review, (Baskaran and Adams, 2023) make multiple recommendations for future 31 directions, including the need for ecologically valid HRT datasets and adaptively segmenting metrics.The need for more efficient metrics in HRT is tackled by another paper of our collection. (Verhagen 33 et al., 2024) propose an evaluation method to verify if dynamic task allocation using variable autonomy in 34 human-robot teams ensures not just completion of the task but also meaningful human control by satisfying 35 accountability, responsibility, and transparency. This approach quantifies traceability both subjectively and 36 objectively by analysing human responses during and after simulated collaborative activities. Additionally, 37 it incorporates semi-structured interviews following the simulation to uncover the underlying reasons 38 for the outcomes and gather suggestions for enhancing the variable autonomy strategy. In their article, a 39 real-world illustration with firefighters is presented.ROBOT PERCEPTION AND AUTONOMY ADJUSTMENT (Lakhnati et al., 2024) the use of Large Language Models (LLMs) to facilitate variable autonomy through},
  archive      = {J_FROBT},
  author       = {Rothfuß, Simon and Lacerda, Bruno and Chiou, Manolis and Theodorou, Andreas},
  doi          = {10.3389/frobt.2024.1465183},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1465183},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Variable autonomy for human-robot teaming},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Handle shape influences system usability in
telemanipulation. <em>FROBT</em>, <em>11</em>, 1457926. (<a
href="https://doi.org/10.3389/frobt.2024.1457926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Zoller, Esther I. and von Ballmoos, Sibylle and Gerig, Nicolas and Cattin, Philippe C. and Rauter, Georg},
  doi          = {10.3389/frobt.2024.1457926},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1457926},
  shortjournal = {Front. Robot. AI},
  title        = {Handle shape influences system usability in telemanipulation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey of learning-based approaches for robotic in-hand
manipulation. <em>FROBT</em>, <em>11</em>, 1455431. (<a
href="https://doi.org/10.3389/frobt.2024.1455431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sintov, Avishai and Azulay, Osher and Shirizly, Alon and Weinberg, Abraham I.},
  doi          = {10.3389/frobt.2024.1455431},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1455431},
  shortjournal = {Front. Robot. AI},
  title        = {Survey of learning-based approaches for robotic in-hand manipulation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trajectory shaping guidance for impact angle control of
planetary hopping robots. <em>FROBT</em>, <em>11</em>, 1452997. (<a
href="https://doi.org/10.3389/frobt.2024.1452997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Mondal, Sabyasachi},
  doi          = {10.3389/frobt.2024.1452997},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1452997},
  shortjournal = {Front. Robot. AI},
  title        = {Trajectory shaping guidance for impact angle control of planetary hopping robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collider-based movement detection and control of wearable
soft robots for visually augmenting dance performance. <em>FROBT</em>,
<em>11</em>, 1450177. (<a
href="https://doi.org/10.3389/frobt.2024.1450177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Twomey, Patrick and Varma, Vaibhavsingh and Bush, Leslie L. and Trkov, Mitja},
  doi          = {10.3389/frobt.2024.1450177},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1450177},
  shortjournal = {Front. Robot. AI},
  title        = {Collider-based movement detection and control of wearable soft robots for visually augmenting dance performance},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Embodied intelligence for drumming; a reinforcement learning
approach to drumming robots. <em>FROBT</em>, <em>11</em>, 1450097. (<a
href="https://doi.org/10.3389/frobt.2024.1450097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Karbasi, Seyed Mojtaba and Jensenius, Alexander Refsum and Godøy, Rolf Inge and Torresen, Jim},
  doi          = {10.3389/frobt.2024.1450097},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1450097},
  shortjournal = {Front. Robot. AI},
  title        = {Embodied intelligence for drumming; a reinforcement learning approach to drumming robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Controller design and experimental validation of walking for
a musculoskeletal bipedal lower limb robot based on the spring-loaded
inverted pendulum model. <em>FROBT</em>, <em>11</em>, 1449721. (<a
href="https://doi.org/10.3389/frobt.2024.1449721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Hosoda, Koh and Jiang, Yelin and Li, Yiqi},
  doi          = {10.3389/frobt.2024.1449721},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1449721},
  shortjournal = {Front. Robot. AI},
  title        = {Controller design and experimental validation of walking for a musculoskeletal bipedal lower limb robot based on the spring-loaded inverted pendulum model},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing interpretability and accuracy of AI models in
healthcare: A comprehensive review on challenges and future directions.
<em>FROBT</em>, <em>11</em>, 1444763. (<a
href="https://doi.org/10.3389/frobt.2024.1444763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ennab, Mohammad and Mcheick, Hamid},
  doi          = {10.3389/frobt.2024.1444763},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1444763},
  shortjournal = {Front. Robot. AI},
  title        = {Enhancing interpretability and accuracy of AI models in healthcare: A comprehensive review on challenges and future directions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design of an intelligent wearable device for real-time
cattle health monitoring. <em>FROBT</em>, <em>11</em>, 1441960. (<a
href="https://doi.org/10.3389/frobt.2024.1441960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Yu, Zhenhua and Han, Yalou and Cha, Lukas and Chen, Shihong and Wang, Zeyu and Zhang, Yang},
  doi          = {10.3389/frobt.2024.1441960},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1441960},
  shortjournal = {Front. Robot. AI},
  title        = {Design of an intelligent wearable device for real-time cattle health monitoring},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motion-generation system for violin-playing robot using
reinforcement learning differences in bowing parameters due to changes
in learning conditions and sound pressure values. <em>FROBT</em>,
<em>11</em>, 1439629. (<a
href="https://doi.org/10.3389/frobt.2024.1439629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Horigome, Kenzo and Shibuya, Koji},
  doi          = {10.3389/frobt.2024.1439629},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1439629},
  shortjournal = {Front. Robot. AI},
  title        = {Motion-generation system for violin-playing robot using reinforcement learning differences in bowing parameters due to changes in learning conditions and sound pressure values},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synthetic consciousness architecture. <em>FROBT</em>,
<em>11</em>, 1437496. (<a
href="https://doi.org/10.3389/frobt.2024.1437496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Spasokukotskiy, Konstantyn},
  doi          = {10.3389/frobt.2024.1437496},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1437496},
  shortjournal = {Front. Robot. AI},
  title        = {Synthetic consciousness architecture},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulating the psychological and neural effects of affective
touch with soft robotics: An experimental study. <em>FROBT</em>,
<em>11</em>, 1419262. (<a
href="https://doi.org/10.3389/frobt.2024.1419262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Zheng, Caroline Y. and Wang, Ker-Jiun and Wairagkar, Maitreyee and von Mohr, Mariana and Lintunen, Erik and Fotopoulou, Aikaterini},
  doi          = {10.3389/frobt.2024.1419262},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1419262},
  shortjournal = {Front. Robot. AI},
  title        = {Simulating the psychological and neural effects of affective touch with soft robotics: An experimental study},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling interpersonal perception in dyadic interactions:
Towards robot-assisted social mediation in the real world.
<em>FROBT</em>, <em>11</em>, 1410957. (<a
href="https://doi.org/10.3389/frobt.2024.1410957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Javed, Hifza and Wang, Weinan and Usman, Affan Bin and Jamali, Nawid},
  doi          = {10.3389/frobt.2024.1410957},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1410957},
  shortjournal = {Front. Robot. AI},
  title        = {Modeling interpersonal perception in dyadic interactions: Towards robot-assisted social mediation in the real world},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Speaking out for speakers: A guide for and analysis of robot
speaker design. <em>FROBT</em>, <em>11</em>, 1394700. (<a
href="https://doi.org/10.3389/frobt.2024.1394700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Nwagwu, Nnamdi and Schneider, Adeline and Phelps, Tyler K. and Zhang, Brian J. and Fitter, Naomi T.},
  doi          = {10.3389/frobt.2024.1394700},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1394700},
  shortjournal = {Front. Robot. AI},
  title        = {Speaking out for speakers: A guide for and analysis of robot speaker design},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heuristic satisficing inferential decision making in human
and robot active perception. <em>FROBT</em>, <em>11</em>, 1384609. (<a
href="https://doi.org/10.3389/frobt.2024.1384609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ferrari, Silvia and Sommer, Marc A and Egner, Tobias and Zhu, Pingping and Chen, Yucheng},
  doi          = {10.3389/frobt.2024.1384609},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1384609},
  shortjournal = {Front. Robot. AI},
  title        = {Heuristic satisficing inferential decision making in human and robot active perception},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An analysis of dialogue repair in virtual assistants.
<em>FROBT</em>, <em>11</em>, 1356847. (<a
href="https://doi.org/10.3389/frobt.2024.1356847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Galbraith, Matthew Carson},
  doi          = {10.3389/frobt.2024.1356847},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1356847},
  shortjournal = {Front. Robot. AI},
  title        = {An analysis of dialogue repair in virtual assistants},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation of different robotic grippers for simultaneous
multi-object grasping. <em>FROBT</em>, <em>11</em>, 1351932. (<a
href="https://doi.org/10.3389/frobt.2024.1351932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Friedl, Werner A.},
  doi          = {10.3389/frobt.2024.1351932},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1351932},
  shortjournal = {Front. Robot. AI},
  title        = {Evaluation of different robotic grippers for simultaneous multi-object grasping},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary robotics as a modelling tool in evolutionary
biology. <em>FROBT</em>, <em>11</em>, 1278983. (<a
href="https://doi.org/10.3389/frobt.2024.1278983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Winfield, Alan F.},
  doi          = {10.3389/frobt.2024.1278983},
  journal      = {Frontiers in Robotics and AI},
  month        = {11},
  pages        = {1278983},
  shortjournal = {Front. Robot. AI},
  title        = {Evolutionary robotics as a modelling tool in evolutionary biology},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Vibration-based robot locomotion. <em>FROBT</em>,
<em>11</em>, 1508130. (<a
href="https://doi.org/10.3389/frobt.2024.1508130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {1. Bidirectional Locomotion of Soft Inchworm Crawler Using Dynamic Gaits (Liang Du et al.) This paper investigates a crawling mechanism that enables a soft robot to perform bidirectional locomotion using body deformation. The authors propose two different differential friction forces integrated into the robot&amp;#39;s body structure, allowing the robot to generate two different motion directions as the body deforms. With the proposed dynamic gaits, the robot can move in multiple directions with a simple system configuration and a minimalist actuation input. This paper provides an interesting example of how soft structure vibrations can be used for challenging robotic tasks.2. Controlling the motion of gas-lubricated adhesive disks using multiple vibration sources (Chengzhe Jia et al.) This paper discusses a new approach for robots that can generate adhesive force on a surface and move freely by overcoming their gravity. The authors developed a system that allows adhesion while moving along a surface using multiple vibration sources. The experiments show that gas-lubricated adhesive disks can move on the surface without any auxiliary operating system. This study constitutes a step towards constructing smallsized wireless robots that can overcome gravity and move freely in a general environment.This study considers a new design in which a wheeled robot is equipped with an enhanced pantograph-type suspension. The research includes mathematical modeling, computer simulation, and experimental tests of the robot&amp;#39;s locomotion conditions. The results show the time dependencies of different kinematic parameters in the robot operating conditions and reveal the potential of this robot design for use in applications such as inspection and cleaning of pipelines. The study provides an essential roadmap by suggesting further analysis of power consumption, average speed, and operating efficiency.4. Robust self-propulsion in sand using simply controlled vibrating cubes (Bangyuan Liu et al.) This paper explores a self-propulsion mechanism via vibration as an alternative solution to the difficulty of moving on loose granular surfaces. The authors developed a cube-shaped robot with an embedded vibration motor and conducted various experiments on granular surfaces. The results show that such a robot can move faster and more stably on granular surfaces. The numerical simulations confirm that the robotmovement is driven by oscillations triggered at the distance from the center of mass. This simple design and control structure highlights vibratory locomotion as a valuable way to provide reliable movement on granular surfaces.These four studies present various innovative vibration-based solutions to enhance the locomotion capabilities of different robotic systems. The proposed innovative designs, such as soft robots, gas-lubricated adhesive disks, improved suspension systems, and vibrating cubes, aim to increase the efficiency of robots regardless of the type of soil. Each study makes significant contributions to the field of robotics by combining applied and theoretical knowledge to enhance the mobility of mobile robots in complex environmental conditions. In the future, the findings of these studies may inspire more advanced and efficient robot designs and applications.},
  archive      = {J_FROBT},
  author       = {Adar, Nurettin G. and Doria, Alberto and Cocuzza, Silvio and Reis, Murat},
  doi          = {10.3389/frobt.2024.1508130},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1508130},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Vibration-based robot locomotion},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Corrigendum: SonoBox: Development of a robotic ultrasound
tomograph for the ultrasound diagnosis of paediatric forearm fractures.
<em>FROBT</em>, <em>11</em>, 1505171. (<a
href="https://doi.org/10.3389/frobt.2024.1505171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Error in Figure/Table LegendIn the published article, there was an error in the legend for \textbf{Figure 1} as published. The author of the figure was not named properly and credit was not given for her creation. The correct legend appears below.\parA concept sketch of the envisioned SonoBox device. Figure reproduced with permission of the author, Annika Dell, MSc, Fraunhofer Research Institution for Individualized and Cell-Based Medical Engineering, L&amp;#252;beck, Germany.\parThe authors apologize for this error and state that this does not change the scientific conclusions of the article in any way. The original article has been updated.Text CorrectionIn the published article, there was an error. A person is missing in the acknowledgement section.\parA correction has been made to the \textbf{Acknowledgments} section. This sentence previously stated:\parThe authors would like to thank David Sindermann, BSc, and Jonas Kremmers, BSc, whose efforts contributed substantially to the idea of the SonoBox project and building its prototypes.\par The corrected sentence appears below:\parThe authors would like to thank David Sindermann, BSc, and Jonas Kremmers, BSc, whose efforts contributed substantially to the idea of the SonoBox project and building its prototypes as well as Annika Dell, MSc, from the Fraunhofer Research Institution for Individualized and Cell-Based Medical Engineering (IMTE) in L&amp;#252;beck whose concept sketch we were allowed to use in this publication.\par The authors apologize for this error and state that this does not change the scientific conclusions of the article in any way. The original article has been updated.},
  archive      = {J_FROBT},
  author       = {Tüshaus, Ludger and Osburg, Jonas and Ernst, Floris},
  doi          = {10.3389/frobt.2024.1505171},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1505171},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: SonoBox: development of a robotic ultrasound tomograph for the ultrasound diagnosis of paediatric forearm fractures},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Corrigendum: [Optimal sway motion reduction in forestry
cranes]. <em>FROBT</em>, <em>11</em>, 1491980. (<a
href="https://doi.org/10.3389/frobt.2024.1491980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Error in Figure In the published article, there was an error in Figure 7 as published. The figure was incorrectly replaced with a duplicate of Figure 4, resulting in the intended Figure 7 not being displayed. The corrected Figure 7 and its caption Comparison of Optimal FF controller and without a controller - Slew motion appear below. The authors apologize for this error and state that this does not change the scientific conclusions of the article in any way. The original article has been updated.},
  archive      = {J_FROBT},
  author       = {Kowsari, Elham and Ghabcheloo, Reza},
  doi          = {10.3389/frobt.2024.1491980},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1491980},
  shortjournal = {Front. Robot. AI},
  title        = {Corrigendum: [Optimal sway motion reduction in forestry cranes]},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nature redux: Interrogating biomorphism and soft robot
aesthetics through generative AI. <em>FROBT</em>, <em>11</em>, 1472051.
(<a href="https://doi.org/10.3389/frobt.2024.1472051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Jørgensen, Jonas and Rafsanjani, Ahmad and Christiansen, Mads Bering},
  doi          = {10.3389/frobt.2024.1472051},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1472051},
  shortjournal = {Front. Robot. AI},
  title        = {Nature redux: Interrogating biomorphism and soft robot aesthetics through generative AI},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey of space robotic manipulators for
on-orbit servicing. <em>FROBT</em>, <em>11</em>, 1470950. (<a
href="https://doi.org/10.3389/frobt.2024.1470950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Alizadeh, Mohammad and Zhu, Zheng H.},
  doi          = {10.3389/frobt.2024.1470950},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1470950},
  shortjournal = {Front. Robot. AI},
  title        = {A comprehensive survey of space robotic manipulators for on-orbit servicing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced outdoor visual localization using py-net voting
segmentation approach. <em>FROBT</em>, <em>11</em>, 1469588. (<a
href="https://doi.org/10.3389/frobt.2024.1469588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Wang, Jing and Guo, Cheng and Hu, Shaoyi and Wang, Yibo and Fan, Xuhui},
  doi          = {10.3389/frobt.2024.1469588},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1469588},
  shortjournal = {Front. Robot. AI},
  title        = {Enhanced outdoor visual localization using py-net voting segmentation approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep neural network-based robotic visual servoing for
satellite target tracking. <em>FROBT</em>, <em>11</em>, 1469315. (<a
href="https://doi.org/10.3389/frobt.2024.1469315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ghiasvand, Shayan and Xie, Wenfang and Mohebbi, Abolfazl},
  doi          = {10.3389/frobt.2024.1469315},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1469315},
  shortjournal = {Front. Robot. AI},
  title        = {Deep neural network-based robotic visual servoing for satellite target tracking},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards a computational model for higher orders of theory of
mind in social agents. <em>FROBT</em>, <em>11</em>, 1468756. (<a
href="https://doi.org/10.3389/frobt.2024.1468756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tavella, Federico and Manzi, Federico and Vinanzi, Samuele and Di Dio, Cinzia and Massaro, Davide and Cangelosi, Angelo and Marchetti, Antonella},
  doi          = {10.3389/frobt.2024.1468756},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1468756},
  shortjournal = {Front. Robot. AI},
  title        = {Towards a computational model for higher orders of theory of mind in social agents},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Human-centered solutions and synergies across
robotic and digital systems for rehabilitation. <em>FROBT</em>,
<em>11</em>, 1462558. (<a
href="https://doi.org/10.3389/frobt.2024.1462558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a provisional file, not the final typesetThe growing need for effective, personalized, clinically compliant, and engaging rehabilitation -based 31 on methodologies for the restoration of functions -can leverage the step-changes 32 offered by interaction technologies to obtain optimal results matching the initial requests of the users 33 (patients and clinicians). Human-Centered Design approaches may disclose the full potential of such 34 solutions, especially considering the impact of smart systems powered by robotic devices and digital 35 settings. In particular, virtual reality (VR) and augmented reality (AR) constitute a broad sub-class of 36 digital settings, often intertwined with serious games (including exergames devised to promote training 37 activities) and gamification (introducing game features in non-leisure solutions) for sustaining the 38 users&amp;#39; effort over time in repetitive exercises. Furthermore, they can be connected to smart mechatronic 39 systems (especially through their artificial intelligence -AI -features) for achieving higher versatility 40 and efficiency (making rehabilitation more sustainable for the individual and for the healthcare system 41 as a whole, as in telerehabilitation frameworks) (Adlakha, Chhabra, &amp;amp; Shukla, 2020;},
  archive      = {J_FROBT},
  author       = {Platz, Thomas and Brichetto, Giampaolo and Archambault, Philippe and Grant, Edward and Matamala-Gomez, Marta and Faria, Ana L. and Barresi, Giacinto},
  doi          = {10.3389/frobt.2024.1462558},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1462558},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Human-centered solutions and synergies across robotic and digital systems for rehabilitation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Talking body: The effect of body and voice anthropomorphism
on perception of social agents. <em>FROBT</em>, <em>11</em>, 1456613.
(<a href="https://doi.org/10.3389/frobt.2024.1456613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Haresamudram, Kashyap and Torre, Ilaria and Behling, Magnus and Wagner, Christoph and Larsson, Stefan},
  doi          = {10.3389/frobt.2024.1456613},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1456613},
  shortjournal = {Front. Robot. AI},
  title        = {Talking body: The effect of body and voice anthropomorphism on perception of social agents},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cybernic robot hand-arm that realizes cooperative work as a
new hand-arm for people with a single upper-limb dysfunction.
<em>FROBT</em>, <em>11</em>, 1455582. (<a
href="https://doi.org/10.3389/frobt.2024.1455582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sankai, Yoshiyuki and Kawamoto, Hiroaki and Toyama, Hiroaki},
  doi          = {10.3389/frobt.2024.1455582},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1455582},
  shortjournal = {Front. Robot. AI},
  title        = {Cybernic robot hand-arm that realizes cooperative work as a new hand-arm for people with a single upper-limb dysfunction},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental learning of humanoid robot behavior from natural
interaction and large language models. <em>FROBT</em>, <em>11</em>,
1455375. (<a href="https://doi.org/10.3389/frobt.2024.1455375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Bärmann, Leonard and Kartmann, Rainer and Peller-Konrad, Fabian and Niehues, Jan and Waibel, Alex and Asfour, Tamim},
  doi          = {10.3389/frobt.2024.1455375},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1455375},
  shortjournal = {Front. Robot. AI},
  title        = {Incremental learning of humanoid robot behavior from natural interaction and large language models},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Remote science at sea with remotely operated vehicles.
<em>FROBT</em>, <em>11</em>, 1454923. (<a
href="https://doi.org/10.3389/frobt.2024.1454923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Raineault, Nicole and Mirmalek, Zara},
  doi          = {10.3389/frobt.2024.1454923},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1454923},
  shortjournal = {Front. Robot. AI},
  title        = {Remote science at sea with remotely operated vehicles},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancements in the use of AI in the diagnosis and
management of inflammatory bowel disease. <em>FROBT</em>, <em>11</em>,
1453194. (<a href="https://doi.org/10.3389/frobt.2024.1453194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Manfredi, Luigi and Braverman-Jaiven, Dalia},
  doi          = {10.3389/frobt.2024.1453194},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1453194},
  shortjournal = {Front. Robot. AI},
  title        = {Advancements in the use of AI in the diagnosis and management of inflammatory bowel disease},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel bio-inspired soft actuators for upper-limb
exoskeletons: Design, fabrication and feasibility study. <em>FROBT</em>,
<em>11</em>, 1451231. (<a
href="https://doi.org/10.3389/frobt.2024.1451231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Deshpande, Ashish and Hingwe, Ashwin and Bae, Jung Hyun and Naquila, Gabrielle and Zhang, Haiyun},
  doi          = {10.3389/frobt.2024.1451231},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1451231},
  shortjournal = {Front. Robot. AI},
  title        = {Novel bio-inspired soft actuators for upper-limb exoskeletons: Design, fabrication and feasibility study},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulation and real-life implementation of UAV autonomous
landing system based on object recognition and tracking for safe landing
in uncertain environments. <em>FROBT</em>, <em>11</em>, 1450266. (<a
href="https://doi.org/10.3389/frobt.2024.1450266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Jeong, Heon and Baidya, Ranjai},
  doi          = {10.3389/frobt.2024.1450266},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1450266},
  shortjournal = {Front. Robot. AI},
  title        = {Simulation and real-life implementation of UAV autonomous landing system based on object recognition and tracking for safe landing in uncertain environments},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Targeted weed management of palmer amaranth using robotics
and deep learning (YOLOv7). <em>FROBT</em>, <em>11</em>, 1441371. (<a
href="https://doi.org/10.3389/frobt.2024.1441371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Pitla, Santosh and Jhala, Amit J. and Singh, Mandeep and Chamara, Nipuna and Liew, Chee Town and Behera, Shaswati and Balabantaray, Amlan},
  doi          = {10.3389/frobt.2024.1441371},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1441371},
  shortjournal = {Front. Robot. AI},
  title        = {Targeted weed management of palmer amaranth using robotics and deep learning (YOLOv7)},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging imitation learning in agricultural robotics: A
comprehensive survey and comparative analysis. <em>FROBT</em>,
<em>11</em>, 1441312. (<a
href="https://doi.org/10.3389/frobt.2024.1441312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Wang, Dongyi and Bist, Ramesh B. and Davar, Amirreza and Mahmoudi, Siavash},
  doi          = {10.3389/frobt.2024.1441312},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1441312},
  shortjournal = {Front. Robot. AI},
  title        = {Leveraging imitation learning in agricultural robotics: A comprehensive survey and comparative analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). JourneyTracker: Driver alerting system with a deep learning
approach. <em>FROBT</em>, <em>11</em>, 1433795. (<a
href="https://doi.org/10.3389/frobt.2024.1433795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {N L, Yashaswini and Arun, Vanishri and B M, Shashikala and Raj, Shyla and H Y, Vani and Flammini, Francesco},
  doi          = {10.3389/frobt.2024.1433795},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1433795},
  shortjournal = {Front. Robot. AI},
  title        = {JourneyTracker: Driver alerting system with a deep learning approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed intelligence in industrial and automotive
cyber–physical systems: A review. <em>FROBT</em>, <em>11</em>, 1430740.
(<a href="https://doi.org/10.3389/frobt.2024.1430740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Moustakas, Konstantinos and Sarigiannidis, Panagiotis and Radoglou-Grammatikis, Panagiotis and Lalos, Aris and Nousias, Stavros and Arvanitis, Gerasimos and Gkillas, Alexandros and Piperigkos, Nikos},
  doi          = {10.3389/frobt.2024.1430740},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1430740},
  shortjournal = {Front. Robot. AI},
  title        = {Distributed intelligence in industrial and automotive cyber–physical systems: A review},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Humanoid patient robot for diagnostic training in medical
and psychiatric education. <em>FROBT</em>, <em>11</em>, 1424845. (<a
href="https://doi.org/10.3389/frobt.2024.1424845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Schwarz, Patricia and Hellmers, Sandra and Spanknebel, Sebastian and Hurlemann, Rene and Hein, Andreas},
  doi          = {10.3389/frobt.2024.1424845},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1424845},
  shortjournal = {Front. Robot. AI},
  title        = {Humanoid patient robot for diagnostic training in medical and psychiatric education},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Psychophysics of user acceptance of social cyber-physical
systems. <em>FROBT</em>, <em>11</em>, 1414853. (<a
href="https://doi.org/10.3389/frobt.2024.1414853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Chavdarov, Ivan and Krastev, Aleksandar and Madzharov, Anastas and Chehlarova, Neda and Dimitrova, Maya},
  doi          = {10.3389/frobt.2024.1414853},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1414853},
  shortjournal = {Front. Robot. AI},
  title        = {Psychophysics of user acceptance of social cyber-physical systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Satisfaction analysis of 5G remote ultrasound robot for
diagnostics based on a structural equation model. <em>FROBT</em>,
<em>11</em>, 1413065. (<a
href="https://doi.org/10.3389/frobt.2024.1413065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Han, Zhi-Li and Lei, Yu-Meng and Yu, Jing and Lei, Bing-Song and Ye, Hua-Rong and Zhang, Ge},
  doi          = {10.3389/frobt.2024.1413065},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1413065},
  shortjournal = {Front. Robot. AI},
  title        = {Satisfaction analysis of 5G remote ultrasound robot for diagnostics based on a structural equation model},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting humor effectiveness of robots for human line
cutting. <em>FROBT</em>, <em>11</em>, 1407095. (<a
href="https://doi.org/10.3389/frobt.2024.1407095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Kanda, Takayuki and Satake, Satoru and Ushijima, Yuto},
  doi          = {10.3389/frobt.2024.1407095},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1407095},
  shortjournal = {Front. Robot. AI},
  title        = {Predicting humor effectiveness of robots for human line cutting},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A greedy assist-as-needed controller for end-effect upper
limb rehabilitation robot based on 3-DOF potential field constraints.
<em>FROBT</em>, <em>11</em>, 1404814. (<a
href="https://doi.org/10.3389/frobt.2024.1404814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Zuo, Guokun and Chai, Guohong and Zhang, Jiaji},
  doi          = {10.3389/frobt.2024.1404814},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1404814},
  shortjournal = {Front. Robot. AI},
  title        = {A greedy assist-as-needed controller for end-effect upper limb rehabilitation robot based on 3-DOF potential field constraints},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Customisation’s impact on strengthening affective bonds and
decision-making with socially assistive robots. <em>FROBT</em>,
<em>11</em>, 1384610. (<a
href="https://doi.org/10.3389/frobt.2024.1384610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Bremner, Paul and Leonards, Ute and Giuliani, Manuel and Ahmed, Mohammed Shabaj},
  doi          = {10.3389/frobt.2024.1384610},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1384610},
  shortjournal = {Front. Robot. AI},
  title        = {Customisation’s impact on strengthening affective bonds and decision-making with socially assistive robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A pipeline for estimating human attention toward objects
with on-board cameras on the iCub humanoid robot. <em>FROBT</em>,
<em>11</em>, 1346714. (<a
href="https://doi.org/10.3389/frobt.2024.1346714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Natale, Lorenzo and Lombardi, Maria and Maiettini, Elisa and Hanifi, Shiva},
  doi          = {10.3389/frobt.2024.1346714},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1346714},
  shortjournal = {Front. Robot. AI},
  title        = {A pipeline for estimating human attention toward objects with on-board cameras on the iCub humanoid robot},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AAT4IRS: Automated acceptance testing for industrial robotic
systems. <em>FROBT</em>, <em>11</em>, 1346580. (<a
href="https://doi.org/10.3389/frobt.2024.1346580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Dos Santos, Marcela G. and Hallé, Sylvain and Petrillo, Fabio and Guéhéneuc, Yann-Gael},
  doi          = {10.3389/frobt.2024.1346580},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1346580},
  shortjournal = {Front. Robot. AI},
  title        = {AAT4IRS: Automated acceptance testing for industrial robotic systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HoLLiECares -development of a multi-functional robot for
professional care. <em>FROBT</em>, <em>11</em>, 1325143. (<a
href="https://doi.org/10.3389/frobt.2024.1325143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Brünett, Matthias and Gebert, Anne and Gisa, Kevin and Hermann, Andreas and Lengenfelder, Christian and Roennau, Arne and Schneider, Julian and Schuh, Svea M. and Steffen, Lea},
  doi          = {10.3389/frobt.2024.1325143},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1325143},
  shortjournal = {Front. Robot. AI},
  title        = {HoLLiECares -development of a multi-functional robot for professional care},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation of fabric-based pneumatic actuator enclosure and
anchoring configurations in a pediatric soft robotic exosuit.
<em>FROBT</em>, <em>11</em>, 1302862. (<a
href="https://doi.org/10.3389/frobt.2024.1302862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sahin, Ipsita and Ayazi, Mehrnoosh and Mucchiani, Caio and Dube, Jared and Karydis, Konstantinos and Kokkoni, Elena},
  doi          = {10.3389/frobt.2024.1302862},
  journal      = {Frontiers in Robotics and AI},
  month        = {10},
  pages        = {1302862},
  shortjournal = {Front. Robot. AI},
  title        = {Evaluation of fabric-based pneumatic actuator enclosure and anchoring configurations in a pediatric soft robotic exosuit},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Automated vehicles: Intelligent decision-making,
trajectory planning, and chassis execution. <em>FROBT</em>, <em>11</em>,
1464199. (<a href="https://doi.org/10.3389/frobt.2024.1464199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Cheng, Shuo and Li, Liang and Lei, Yong and Xia, Xin and Lv, Chen},
  doi          = {10.3389/frobt.2024.1464199},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1464199},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: automated vehicles: intelligent decision-making, trajectory planning, and chassis execution},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Validations of various in-hand object manipulation
strategies employing a novel tactile sensor developed for an
under-actuated robot hand. <em>FROBT</em>, <em>11</em>, 1460589. (<a
href="https://doi.org/10.3389/frobt.2024.1460589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Singh, Avinash and Pinto, Massimilano and Kaltsas, Petros and Pirozzi, Salvatore and Sulaiman, Shifa and Ficuciello, Fanny},
  doi          = {10.3389/frobt.2024.1460589},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1460589},
  shortjournal = {Front. Robot. AI},
  title        = {Validations of various in-hand object manipulation strategies employing a novel tactile sensor developed for an under-actuated robot hand},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact linearization and control of a mobile robot for the
inspection of soil resources in solanum tuberosum crops. <em>FROBT</em>,
<em>11</em>, 1459902. (<a
href="https://doi.org/10.3389/frobt.2024.1459902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Pulido-Aponte, Álvaro and Garzón-Castro, Claudia L.},
  doi          = {10.3389/frobt.2024.1459902},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1459902},
  shortjournal = {Front. Robot. AI},
  title        = {Exact linearization and control of a mobile robot for the inspection of soil resources in solanum tuberosum crops},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SwAV-driven diagnostics: New perspectives on grading
diabetic retinopathy from retinal photography. <em>FROBT</em>,
<em>11</em>, 1445565. (<a
href="https://doi.org/10.3389/frobt.2024.1445565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ul Alam, Md Nuho and Bahadur, Erfanul H. and Masum, Abdul Kadar M. and Noori, Farzan Majeed and Uddin, Md Zia},
  doi          = {10.3389/frobt.2024.1445565},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1445565},
  shortjournal = {Front. Robot. AI},
  title        = {SwAV-driven diagnostics: New perspectives on grading diabetic retinopathy from retinal photography},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimal perception: Enabling autonomy in
resource-constrained robots. <em>FROBT</em>, <em>11</em>, 1431826. (<a
href="https://doi.org/10.3389/frobt.2024.1431826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Singh, Chahat Deep and He, Botao and Fermuller, Cornelia and Metzler, Christopher and Aloimonos, Yiannis},
  doi          = {10.3389/frobt.2024.1431826},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1431826},
  shortjournal = {Front. Robot. AI},
  title        = {Minimal perception: Enabling autonomy in resource-constrained robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of a bionic hexapod robot with adaptive gait and
clearance for enhanced agricultural field scouting. <em>FROBT</em>,
<em>11</em>, 1426269. (<a
href="https://doi.org/10.3389/frobt.2024.1426269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {ZHANG, ZHENGHUA and He, Weilong and Wu, Fan and Quesada-Ocampo, Lina M. and Xiang, Lirong},
  doi          = {10.3389/frobt.2024.1426269},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1426269},
  shortjournal = {Front. Robot. AI},
  title        = {Development of a bionic hexapod robot with adaptive gait and clearance for enhanced agricultural field scouting},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual place recognition from end-to-end semantic scene text
features. <em>FROBT</em>, <em>11</em>, 1424883. (<a
href="https://doi.org/10.3389/frobt.2024.1424883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Zelek, John and Raisi, Zobeir},
  doi          = {10.3389/frobt.2024.1424883},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1424883},
  shortjournal = {Front. Robot. AI},
  title        = {Visual place recognition from end-to-end semantic scene text features},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Siamese and triplet network-based pain expression in robotic
avatars for care and nursing training. <em>FROBT</em>, <em>11</em>,
1419584. (<a href="https://doi.org/10.3389/frobt.2024.1419584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Lee, Miran and Lee, Minjeong and Kim, Suyeong},
  doi          = {10.3389/frobt.2024.1419584},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1419584},
  shortjournal = {Front. Robot. AI},
  title        = {Siamese and triplet network-based pain expression in robotic avatars for care and nursing training},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Omnidirectional soft pneumatic actuators: A design and
optimization framework. <em>FROBT</em>, <em>11</em>, 1418484. (<a
href="https://doi.org/10.3389/frobt.2024.1418484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Moutousi, Maria and Polygerinos, Panagiotis},
  doi          = {10.3389/frobt.2024.1418484},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1418484},
  shortjournal = {Front. Robot. AI},
  title        = {Omnidirectional soft pneumatic actuators: A design and optimization framework},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Augmenting perceived stickiness of physical objects through
tactile feedback after finger lift-off. <em>FROBT</em>, <em>11</em>,
1415464. (<a href="https://doi.org/10.3389/frobt.2024.1415464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Kurogi, Tadatoshi and Inoue, Yuki and Fujiwara, Takeshi and Minamizawa, Kouta},
  doi          = {10.3389/frobt.2024.1415464},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1415464},
  shortjournal = {Front. Robot. AI},
  title        = {Augmenting perceived stickiness of physical objects through tactile feedback after finger lift-off},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploratory analysis of human perceptions of social robot
deception behaviors. <em>FROBT</em>, <em>11</em>, 1409712. (<a
href="https://doi.org/10.3389/frobt.2024.1409712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Rosero, Andres and Dula, Elizabeth and Kelly, Harris and Malle, Bertram and Phillips, Elizabeth},
  doi          = {10.3389/frobt.2024.1409712},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1409712},
  shortjournal = {Front. Robot. AI},
  title        = {Exploratory analysis of human perceptions of social robot deception behaviors},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bridging vision and touch: Advancing robotic interaction
prediction with self-supervised multimodal learning. <em>FROBT</em>,
<em>11</em>, 1407519. (<a
href="https://doi.org/10.3389/frobt.2024.1407519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Li, Luchen and George Thuruthel, Thomas},
  doi          = {10.3389/frobt.2024.1407519},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1407519},
  shortjournal = {Front. Robot. AI},
  title        = {Bridging vision and touch: Advancing robotic interaction prediction with self-supervised multimodal learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effect of simulated hearing loss on automatic speech
recognition for an android robot-patient. <em>FROBT</em>, <em>11</em>,
1391818. (<a href="https://doi.org/10.3389/frobt.2024.1391818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Röhl, Jan Hendrik and Günther, Ulf and Hein, Andreas and Cauchi, Benjamin},
  doi          = {10.3389/frobt.2024.1391818},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1391818},
  shortjournal = {Front. Robot. AI},
  title        = {Effect of simulated hearing loss on automatic speech recognition for an android robot-patient},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tangle-and contact-free path planning for a tethered mobile
robot using deep reinforcement learning. <em>FROBT</em>, <em>11</em>,
1388634. (<a href="https://doi.org/10.3389/frobt.2024.1388634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Shimada, Ryuki and Ishigami, Genya},
  doi          = {10.3389/frobt.2024.1388634},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1388634},
  shortjournal = {Front. Robot. AI},
  title        = {Tangle-and contact-free path planning for a tethered mobile robot using deep reinforcement learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unveiling human biomechanics: Insights into lower limb
responses to disturbances that can trigger a fall. <em>FROBT</em>,
<em>11</em>, 1367474. (<a
href="https://doi.org/10.3389/frobt.2024.1367474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ferrete Ribeiro, Nuno and Armada, Miguel and Nunes, João and Carvalho, Oscar and Santos, Cristina P.},
  doi          = {10.3389/frobt.2024.1367474},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1367474},
  shortjournal = {Front. Robot. AI},
  title        = {Unveiling human biomechanics: Insights into lower limb responses to disturbances that can trigger a fall},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Software patterns and data structures for runtime
coordination of robots, with a focus on realtime execution performance.
<em>FROBT</em>, <em>11</em>, 1363041. (<a
href="https://doi.org/10.3389/frobt.2024.1363041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Artigas, María I. and Rodrigues, Rômulo T. and Vanderseypen, Lars and Bruyninckx, Herman},
  doi          = {10.3389/frobt.2024.1363041},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1363041},
  shortjournal = {Front. Robot. AI},
  title        = {Software patterns and data structures for runtime coordination of robots, with a focus on realtime execution performance},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unraveling the thread: Understanding and addressing
sequential failures in human-robot interaction anonymous.
<em>FROBT</em>, <em>11</em>, 1359782. (<a
href="https://doi.org/10.3389/frobt.2024.1359782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tisserand, Lucien and Stephenson, Brooke and Baldauf-Quilliatre, Heike and Lefort, Mathieu and Armetta, Frédéric},
  doi          = {10.3389/frobt.2024.1359782},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1359782},
  shortjournal = {Front. Robot. AI},
  title        = {Unraveling the thread: Understanding and addressing sequential failures in human-robot interaction anonymous},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ExTraCT - explainable trajectory corrections for
language-based human-robot interaction using textual feature
descriptions. <em>FROBT</em>, <em>11</em>, 1345693. (<a
href="https://doi.org/10.3389/frobt.2024.1345693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Yow, J-Anne and Garg, Neha P. and Ramanathan, Manoj and Ang, Wei Tech},
  doi          = {10.3389/frobt.2024.1345693},
  journal      = {Frontiers in Robotics and AI},
  month        = {9},
  pages        = {1345693},
  shortjournal = {Front. Robot. AI},
  title        = {ExTraCT - Explainable trajectory corrections for language-based human-robot interaction using textual feature descriptions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A compact motorized end-effector for ankle rehabilitation
training. <em>FROBT</em>, <em>11</em>, 1453097. (<a
href="https://doi.org/10.3389/frobt.2024.1453097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Renxiang, Wu and Luo, Mingyang and Fan, Jiaming and Ma, Jingting and Zhang, Naiwen and Li, Jianjun and Li, Qiuyuan and GAO, Fei and Dan, Guo},
  doi          = {10.3389/frobt.2024.1453097},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1453097},
  shortjournal = {Front. Robot. AI},
  title        = {A compact motorized end-effector for ankle rehabilitation training},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Remotely actuated programmable self-folding strings using
magnetic induction heating. <em>FROBT</em>, <em>11</em>, 1443379. (<a
href="https://doi.org/10.3389/frobt.2024.1443379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Lahondes, Quentin M. and Miyashita, Shuhei},
  doi          = {10.3389/frobt.2024.1443379},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1443379},
  shortjournal = {Front. Robot. AI},
  title        = {Remotely actuated programmable self-folding strings using magnetic induction heating},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine psychology: Integrating operant conditioning with
the non-axiomatic reasoning system for advancing artificial general
intelligence research. <em>FROBT</em>, <em>11</em>, 1440631. (<a
href="https://doi.org/10.3389/frobt.2024.1440631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Johansson, Robert},
  doi          = {10.3389/frobt.2024.1440631},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1440631},
  shortjournal = {Front. Robot. AI},
  title        = {Machine psychology: Integrating operant conditioning with the non-axiomatic reasoning system for advancing artificial general intelligence research},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autonomous navigation and control of magnetic microcarriers
using potential field algorithm and adaptive non-linear PID.
<em>FROBT</em>, <em>11</em>, 1439427. (<a
href="https://doi.org/10.3389/frobt.2024.1439427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sallam, Mohamed and Shamseldin, Mohamed A. and Ficuciello, Fanny},
  doi          = {10.3389/frobt.2024.1439427},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1439427},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous navigation and control of magnetic microcarriers using potential field algorithm and adaptive non-linear PID},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Concepts for drone based pipeline leak detection.
<em>FROBT</em>, <em>11</em>, 1426206. (<a
href="https://doi.org/10.3389/frobt.2024.1426206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Bretschneider, Lutz and Bollmann, Sven B. and Houssin-Agbomson, Deborah and Shaw, Jacob and Howes, Neil and Nguyen, Linh and Robinson, Rod and Helmore, Jon and Lichtenstern, Michael and Nwaboh, Javis and Pogány, Andrea and Ebert, Volker and Lampert, Astrid},
  doi          = {10.3389/frobt.2024.1426206},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1426206},
  shortjournal = {Front. Robot. AI},
  title        = {Concepts for drone based pipeline leak detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robotic in-space servicing, assembly and manufacturing.
<em>FROBT</em>, <em>11</em>, 1421697. (<a
href="https://doi.org/10.3389/frobt.2024.1421697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Barnhart, David and Mukherjee, Rudranarayan and Rai, Mini C. and D&#39;Amore, Nicholas and Henshaw, Carl G.},
  doi          = {10.3389/frobt.2024.1421697},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1421697},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic in-space servicing, assembly and manufacturing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Optimal sway motion reduction in forestry cranes.
<em>FROBT</em>, <em>11</em>, 1417741. (<a
href="https://doi.org/10.3389/frobt.2024.1417741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Kowsari, Elham and Ghabcheloo, Reza},
  doi          = {10.3389/frobt.2024.1417741},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1417741},
  shortjournal = {Front. Robot. AI},
  title        = {Optimal sway motion reduction in forestry cranes},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive approach for tracking movements of biological
targets: Application to robot-based intervention for prostate cancer.
<em>FROBT</em>, <em>11</em>, 1416662. (<a
href="https://doi.org/10.3389/frobt.2024.1416662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {SMAHI, Abdeslem and Lakhal, Othman and Chettibi, Taha and Sanz Lopez, Mario and Pasquier, David and Merzouki, Rochdi},
  doi          = {10.3389/frobt.2024.1416662},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1416662},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive approach for tracking movements of biological targets: Application to robot-based intervention for prostate cancer},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An experimental study of the sensorized strain wave gear
RT1-t and its capabilities for torque control in robotic joints.
<em>FROBT</em>, <em>11</em>, 1416360. (<a
href="https://doi.org/10.3389/frobt.2024.1416360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Schuller, Robert and Reinecke, Jens and Maurenbrecher, Henry and Ott, Christian and Albu-Schäffer, Alin and Deutschmann, Bastian and Buettner, Fred and Heim, Jens and Benkert, Frank and Glueck, Stefan},
  doi          = {10.3389/frobt.2024.1416360},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1416360},
  shortjournal = {Front. Robot. AI},
  title        = {An experimental study of the sensorized strain wave gear RT1-T and its capabilities for torque control in robotic joints},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Influences of different parameters on selected properties of
gears for robot-like systems. <em>FROBT</em>, <em>11</em>, 1414238. (<a
href="https://doi.org/10.3389/frobt.2024.1414238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Oberneder, Florian and Landler, Stefan and Otto, Michael and Vogel-Heuser, Birgit and Zimmermann, Markus and Stahl, Karsten},
  doi          = {10.3389/frobt.2024.1414238},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1414238},
  shortjournal = {Front. Robot. AI},
  title        = {Influences of different parameters on selected properties of gears for robot-like systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SonoBox: Development of a robotic ultrasound tomograph for
the ultrasound diagnosis of paediatric forearm fractures.
<em>FROBT</em>, <em>11</em>, 1405169. (<a
href="https://doi.org/10.3389/frobt.2024.1405169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ernst, Floris and Osburg, Jonas and Tüshaus, Ludger},
  doi          = {10.3389/frobt.2024.1405169},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1405169},
  shortjournal = {Front. Robot. AI},
  title        = {SonoBox: Development of a robotic ultrasound tomograph for the ultrasound diagnosis of paediatric forearm fractures},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hardness changing tactile displays for simulating the feel
of organic tissues. <em>FROBT</em>, <em>11</em>, 1404543. (<a
href="https://doi.org/10.3389/frobt.2024.1404543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Brown, Joshua and Bello, Fernando},
  doi          = {10.3389/frobt.2024.1404543},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1404543},
  shortjournal = {Front. Robot. AI},
  title        = {Hardness changing tactile displays for simulating the feel of organic tissues},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Implementing social and affective touch to enhance user
experience in human-robot interaction. <em>FROBT</em>, <em>11</em>,
1403679. (<a href="https://doi.org/10.3389/frobt.2024.1403679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Cansev, Mehmet Ege and Miller, Alexandra and Brown, Jeremy and Beckerle, Philipp},
  doi          = {10.3389/frobt.2024.1403679},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1403679},
  shortjournal = {Front. Robot. AI},
  title        = {Implementing social and affective touch to enhance user experience in human-robot interaction},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Socially assistive walker for daily living assistance in
older adults. <em>FROBT</em>, <em>11</em>, 1401663. (<a
href="https://doi.org/10.3389/frobt.2024.1401663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sierra M., Sergio D. and Harris, Nigel and Munera, Marcela and Cifuentes, Carlos A.},
  doi          = {10.3389/frobt.2024.1401663},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1401663},
  shortjournal = {Front. Robot. AI},
  title        = {Socially assistive walker for daily living assistance in older adults},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced accuracy with segmentation of colorectal polyp
using NanoNetB, and conditional random field test-time augmentation.
<em>FROBT</em>, <em>11</em>, 1387491. (<a
href="https://doi.org/10.3389/frobt.2024.1387491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Hussain, Muhammad S. and Asgher, Umer and Shaukat, Arslan and Wang, Jinhui and Socha, Vladimír and Feng, Tian and Nisar, Sajid and Paracha, Rehan Z. and Khan, Muhammad Ali},
  doi          = {10.3389/frobt.2024.1387491},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1387491},
  shortjournal = {Front. Robot. AI},
  title        = {Enhanced accuracy with segmentation of colorectal polyp using NanoNetB, and conditional random field test-time augmentation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Social robots as skilled ignorant peers for supporting
learning. <em>FROBT</em>, <em>11</em>, 1385780. (<a
href="https://doi.org/10.3389/frobt.2024.1385780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Nasir, Jauwairia and Bruno, Barbara and Dillenbourg, Pierre},
  doi          = {10.3389/frobt.2024.1385780},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1385780},
  shortjournal = {Front. Robot. AI},
  title        = {Social robots as skilled ignorant peers for supporting learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary optimisation for risk-aware heterogeneous
multi-agent path planning in uncertain environments. <em>FROBT</em>,
<em>11</em>, 1375393. (<a
href="https://doi.org/10.3389/frobt.2024.1375393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Rekabi Bana, Fatemeh and Krajnik, Tomas and Arvin, Farshad},
  doi          = {10.3389/frobt.2024.1375393},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1375393},
  shortjournal = {Front. Robot. AI},
  title        = {Evolutionary optimisation for risk-aware heterogeneous multi-agent path planning in uncertain environments},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tissue palpation in endoscopy using EIT and soft actuators.
<em>FROBT</em>, <em>11</em>, 1372936. (<a
href="https://doi.org/10.3389/frobt.2024.1372936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Alian, Amirhosein and Avery, James and Mylonas, George P.},
  doi          = {10.3389/frobt.2024.1372936},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1372936},
  shortjournal = {Front. Robot. AI},
  title        = {Tissue palpation in endoscopy using EIT and soft actuators},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Composable and executable scenarios for simulation-based
testing of mobile robots. <em>FROBT</em>, <em>11</em>, 1363281. (<a
href="https://doi.org/10.3389/frobt.2024.1363281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ortega Sainz, Argentina and Parra, Samuel and Schneider, Sven and Hochgeschwender, Nico},
  doi          = {10.3389/frobt.2024.1363281},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1363281},
  shortjournal = {Front. Robot. AI},
  title        = {Composable and executable scenarios for simulation-based testing of mobile robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From care practices to speculative vignettes -design
considerations for robots in good care. <em>FROBT</em>, <em>11</em>,
1347367. (<a href="https://doi.org/10.3389/frobt.2024.1347367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Vetter, Ralf and Dobrosovestnova, Anna and Frijns, Helena A. and Vogel, Laura and Brunnmayr, Katharina and Frauenberger, Christopher},
  doi          = {10.3389/frobt.2024.1347367},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1347367},
  shortjournal = {Front. Robot. AI},
  title        = {From care practices to speculative vignettes -design considerations for robots in good care},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust control of electrohydraulic soft robots.
<em>FROBT</em>, <em>11</em>, 1333837. (<a
href="https://doi.org/10.3389/frobt.2024.1333837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Volchko, Angella and Mitchell, Shane K. and Scripps, Tyler G. and Turin, Zoe and Humbert, J S.},
  doi          = {10.3389/frobt.2024.1333837},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1333837},
  shortjournal = {Front. Robot. AI},
  title        = {Robust control of electrohydraulic soft robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Do you wanna dance? Tales of trust and driving trust factors
in robot medication counselling in the pharmacy context. <em>FROBT</em>,
<em>11</em>, 1332110. (<a
href="https://doi.org/10.3389/frobt.2024.1332110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Hägglund, Susanne and Andtfolk, Malin and Rosenberg, Sara and Wingren, Mattias and Andersson, Sören and Nyholm, Linda},
  doi          = {10.3389/frobt.2024.1332110},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1332110},
  shortjournal = {Front. Robot. AI},
  title        = {Do you wanna dance? tales of trust and driving trust factors in robot medication counselling in the pharmacy context},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust self-propulsion in sand using simply controlled
vibrating cubes. <em>FROBT</em>, <em>11</em>, 1298676. (<a
href="https://doi.org/10.3389/frobt.2024.1298676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Liu, Bangyuan and Wang, Tianyu and Kojouharov, Velin and Hammond III, Frank L. and Goldman, Daniel I.},
  doi          = {10.3389/frobt.2024.1298676},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1298676},
  shortjournal = {Front. Robot. AI},
  title        = {Robust self-propulsion in sand using simply controlled vibrating cubes},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical path-planning from speech instructions with
spatial concept-based topometric semantic mapping. <em>FROBT</em>,
<em>11</em>, 1291426. (<a
href="https://doi.org/10.3389/frobt.2024.1291426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Taniguchi, Akira and Ito, Shuya and Taniguchi, Tadahiro},
  doi          = {10.3389/frobt.2024.1291426},
  journal      = {Frontiers in Robotics and AI},
  month        = {8},
  pages        = {1291426},
  shortjournal = {Front. Robot. AI},
  title        = {Hierarchical path-planning from speech instructions with spatial concept-based topometric semantic mapping},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assistance personalization/customization for human
locomotion tasks by using wearable lower-limb robotic devices.
<em>FROBT</em>, <em>11</em>, 1448100. (<a
href="https://doi.org/10.3389/frobt.2024.1448100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Zhang, Qiang (Jason) and Bao, Xuefeng and Guo, Zhao and Lv, Ge and Kim, Myunghee},
  doi          = {10.3389/frobt.2024.1448100},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1448100},
  shortjournal = {Front. Robot. AI},
  title        = {Assistance Personalization/Customization for human locomotion tasks by using wearable lower-limb robotic devices},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Head tracking using an optical soft tactile sensing surface.
<em>FROBT</em>, <em>11</em>, 1410858. (<a
href="https://doi.org/10.3389/frobt.2024.1410858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Gandhi, Bhoomika and Mihaylova, Lyudmila and Dogramadzi, Sanja},
  doi          = {10.3389/frobt.2024.1410858},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1410858},
  shortjournal = {Front. Robot. AI},
  title        = {Head tracking using an optical soft tactile sensing surface},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robotont 3 - an accessible 3D-printable ROS-supported
open-source mobile robot for education and research. <em>FROBT</em>,
<em>11</em>, 1406645. (<a
href="https://doi.org/10.3389/frobt.2024.1406645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Mõtshärg, Eva and Vunder, Veiko and Raudmäe, Renno and Muro, Marko and Drikkit, Ingvar and Tšigrinski, Leonid and Köidam, Raimo and Aabloo, Alvo and Kruusamäe, Karl},
  doi          = {10.3389/frobt.2024.1406645},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1406645},
  shortjournal = {Front. Robot. AI},
  title        = {Robotont 3 - An accessible 3D-printable ROS-supported open-source mobile robot for education and research},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Human-centered robot vision and artificial
perception. <em>FROBT</em>, <em>11</em>, 1406280. (<a
href="https://doi.org/10.3389/frobt.2024.1406280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Gao, Qing and Zhang, Xin and Tian, Chunwei and Gao, Hongwei and Ju, Zhaojie},
  doi          = {10.3389/frobt.2024.1406280},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1406280},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Human-centered robot vision and artificial perception},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive satellite attitude control for varying masses using
deep reinforcement learning. <em>FROBT</em>, <em>11</em>, 1402846. (<a
href="https://doi.org/10.3389/frobt.2024.1402846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Retagne, Wiebke and Dauer, Jonas and Waxenegger-Wilfing, Günther},
  doi          = {10.3389/frobt.2024.1402846},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1402846},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive satellite attitude control for varying masses using deep reinforcement learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SNN4Agents: A framework for developing energy-efficient
embodied spiking neural networks for autonomous agents. <em>FROBT</em>,
<em>11</em>, 1401677. (<a
href="https://doi.org/10.3389/frobt.2024.1401677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Putra, Rachmad Vidya Wicaksana and Marchisio, Alberto and Shafique, Muhammad},
  doi          = {10.3389/frobt.2024.1401677},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1401677},
  shortjournal = {Front. Robot. AI},
  title        = {SNN4Agents: A framework for developing energy-efficient embodied spiking neural networks for autonomous agents},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing emotional expression in cat-like robots:
Strategies for utilizing tail movements with human-like gazes.
<em>FROBT</em>, <em>11</em>, 1399012. (<a
href="https://doi.org/10.3389/frobt.2024.1399012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Wang, Xinxiang and Yang, Yiming and Li, Zihan and Wang, Songyang and Peng, Yibo and Fu, Changzeng},
  doi          = {10.3389/frobt.2024.1399012},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1399012},
  shortjournal = {Front. Robot. AI},
  title        = {Enhancing emotional expression in cat-like robots: Strategies for utilizing tail movements with human-like gazes},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gaze detection as a social cue to initiate natural
human-robot collaboration in an assembly task. <em>FROBT</em>,
<em>11</em>, 1394379. (<a
href="https://doi.org/10.3389/frobt.2024.1394379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Lavit Nicora, Matteo and Prajod, Pooja and Mondellini, Marta and Tauro, Giovanni and Vertechy, Rocco and André, Elisabeth and Malosio, Matteo},
  doi          = {10.3389/frobt.2024.1394379},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1394379},
  shortjournal = {Front. Robot. AI},
  title        = {Gaze detection as a social cue to initiate natural human-robot collaboration in an assembly task},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation of a passive wearable arm ExoNET. <em>FROBT</em>,
<em>11</em>, 1387177. (<a
href="https://doi.org/10.3389/frobt.2024.1387177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Ryali, Partha and Wilson, Valentino and Celian, Courtney and Srivatsa, Adith V. and Ghani, Yaseen and Lentz, Jeremy and Patton, James},
  doi          = {10.3389/frobt.2024.1387177},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1387177},
  shortjournal = {Front. Robot. AI},
  title        = {Evaluation of a passive wearable arm ExoNET},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of ontology-enabled processes for dependable robot
autonomy. <em>FROBT</em>, <em>11</em>, 1377897. (<a
href="https://doi.org/10.3389/frobt.2024.1377897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Aguado, Esther and Gomez, Virgilio and Hernando, Miguel and Rossi, Claudio and Sanz, Ricardo},
  doi          = {10.3389/frobt.2024.1377897},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1377897},
  shortjournal = {Front. Robot. AI},
  title        = {A survey of ontology-enabled processes for dependable robot autonomy},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Investigating the performance of soft robotic adaptive feet
with longitudinal and transverse arches. <em>FROBT</em>, <em>11</em>,
1375515. (<a href="https://doi.org/10.3389/frobt.2024.1375515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Pace, Anna and Grioli, Giorgio and Ghezzi, Alice and Bicchi, Antonio and Catalano, Manuel G.},
  doi          = {10.3389/frobt.2024.1375515},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1375515},
  shortjournal = {Front. Robot. AI},
  title        = {Investigating the performance of soft robotic adaptive feet with longitudinal and transverse arches},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards reconciling usability and usefulness of policy
explanations for sequential decision-making systems. <em>FROBT</em>,
<em>11</em>, 1375490. (<a
href="https://doi.org/10.3389/frobt.2024.1375490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tambwekar, Pradyumna and Gombolay, Matthew},
  doi          = {10.3389/frobt.2024.1375490},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1375490},
  shortjournal = {Front. Robot. AI},
  title        = {Towards reconciling usability and usefulness of policy explanations for sequential decision-making systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed safe formation tracking control of
multi-quadcopter systems using barrier lyapunov function.
<em>FROBT</em>, <em>11</em>, 1370104. (<a
href="https://doi.org/10.3389/frobt.2024.1370104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sadeghi, Mohammad R. and Sadeghzadeh-Nokhodberiz, Nargess and Barzamini, Roohollah and Montazeri, Allahyar},
  doi          = {10.3389/frobt.2024.1370104},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1370104},
  shortjournal = {Front. Robot. AI},
  title        = {Distributed safe formation tracking control of multi-quadcopter systems using barrier lyapunov function},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collective predictive coding hypothesis: Symbol emergence as
decentralized bayesian inference. <em>FROBT</em>, <em>11</em>, 1353870.
(<a href="https://doi.org/10.3389/frobt.2024.1353870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Taniguchi, Tadahiro},
  doi          = {10.3389/frobt.2024.1353870},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1353870},
  shortjournal = {Front. Robot. AI},
  title        = {Collective predictive coding hypothesis: Symbol emergence as decentralized bayesian inference},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Child-centered home service design for a family robot
companion. <em>FROBT</em>, <em>11</em>, 1346257. (<a
href="https://doi.org/10.3389/frobt.2024.1346257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Lym, Hyo Jeong and Son, Hyo In and Kim, Da-Young and Kim, Juhyun and Chung, Jae Hee and Kim, Min-Gyu},
  doi          = {10.3389/frobt.2024.1346257},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1346257},
  shortjournal = {Front. Robot. AI},
  title        = {Child-centered home service design for a family robot companion},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic learning from keyframe demonstration using object
attribute constraints. <em>FROBT</em>, <em>11</em>, 1340334. (<a
href="https://doi.org/10.3389/frobt.2024.1340334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Sen, Busra and Elfring, Jos and Torta, Elena and van de Molengraft, René},
  doi          = {10.3389/frobt.2024.1340334},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1340334},
  shortjournal = {Front. Robot. AI},
  title        = {Semantic learning from keyframe demonstration using object attribute constraints},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding consumer attitudes towards second-hand robots
for the home. <em>FROBT</em>, <em>11</em>, 1324519. (<a
href="https://doi.org/10.3389/frobt.2024.1324519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {McGloin, Helen and Studley, Matthew and Mawle, Richard and Winfield, Alan F.},
  doi          = {10.3389/frobt.2024.1324519},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1324519},
  shortjournal = {Front. Robot. AI},
  title        = {Understanding consumer attitudes towards second-hand robots for the home},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing buoyant force learning through a visuo-haptic
environment: A case study. <em>FROBT</em>, <em>11</em>, 1276027. (<a
href="https://doi.org/10.3389/frobt.2024.1276027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Neri, Luis and Noguez, Julieta and Escobar-Castillejos, David and Robledo-Rella, Víctor and García-Castelán, Rosa María Guadalupe and Gonzalez-Nucamendi, Andres and Magana, Alejandra J. and Benes, Bedrich},
  doi          = {10.3389/frobt.2024.1276027},
  journal      = {Frontiers in Robotics and AI},
  month        = {7},
  pages        = {1276027},
  shortjournal = {Front. Robot. AI},
  title        = {Enhancing buoyant force learning through a visuo-haptic environment: A case study},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assimilation of socially assistive robots by older adults:
An interplay of uses, constraints and outcomes. <em>FROBT</em>,
<em>11</em>, 1438912. (<a
href="https://doi.org/10.3389/frobt.2024.1438912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Zafrani, Oded},
  doi          = {10.3389/frobt.2024.1438912},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1438912},
  shortjournal = {Front. Robot. AI},
  title        = {Assimilation of socially assistive robots by older adults: An interplay of uses, constraints and outcomes},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive robotic system for inspection of aerospace slat
actuators mount. <em>FROBT</em>, <em>11</em>, 1423319. (<a
href="https://doi.org/10.3389/frobt.2024.1423319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Morsi, Nour M. and Mata, Mario and Harrison, Colin and Semple, David},
  doi          = {10.3389/frobt.2024.1423319},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1423319},
  shortjournal = {Front. Robot. AI},
  title        = {Adaptive robotic system for inspection of aerospace slat actuators mount},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visuo-dynamic self-modelling of soft robotic systems.
<em>FROBT</em>, <em>11</em>, 1403733. (<a
href="https://doi.org/10.3389/frobt.2024.1403733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots exhibit complex nonlinear dynamics with large degrees of freedom, making their modelling and control challenging. Typically, reduced-order models in time or space are used in addressing these challenges, but the resulting simplification limits soft robot control accuracy and restricts their range of motion. In this work, we introduce an end-to-end learning-based approach for fully dynamic modelling of any general robotic system that does not rely on predefined structures, learning dynamic models of the robot directly in the visual space. The generated models possess identical dimensionality to the observation space, resulting in models whose complexity is determined by the sensory system without explicitly decomposing the problem. To validate the effectiveness of our proposed method, we apply it to a fully soft robotic manipulator, and we demonstrate its applicability in controller development through an open-loop optimization-based controller. We achieve a wide range of dynamic control tasks including shape control, trajectory tracking and obstacle avoidance using a model derived from just 90 min of real-world data. Our work thus far provides the most comprehensive strategy for controlling a general soft robotic system, without constraints on the shape, properties, or dimensionality of the system.},
  archive      = {J_FROBT},
  author       = {Marques Monteiro, Richard and Shi, Jialei and Wurdemann, Helge and Iida, Fumiya and George Thuruthel, Thomas},
  doi          = {10.3389/frobt.2024.1403733},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1403733},
  shortjournal = {Front. Robot. AI},
  title        = {Visuo-dynamic self-modelling of soft robotic systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Handheld robotic device for endoscopic neurosurgery: System
integration and pre-clinical evaluation. <em>FROBT</em>, <em>11</em>,
1400017. (<a href="https://doi.org/10.3389/frobt.2024.1400017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Expanded Endoscopic Endonasal Approach, one of the best examples of endoscopic neurosurgery, allows access to the skull base through the natural orifice of the nostril. Current standard instruments lack articulation limiting operative access and surgeon dexterity, and thus, could benefit from robotic articulation. In this study, a handheld robotic system with a series of detachable end-effectors for this approach is presented. This system is comprised of interchangeable articulated 2/3 degrees-of-freedom 3 mm instruments that expand the operative workspace and enhance the surgeon’s dexterity, an ergonomically designed handheld controller with a rotating joystick-body that can be placed at the position most comfortable for the user, and the accompanying control box. The robotic instruments were experimentally evaluated for their workspace, structural integrity, and force-delivery capabilities. The entire system was then tested in a pre-clinical context during a phantom feasibility test, followed up by a cadaveric pilot study by a cohort of surgeons of varied clinical experience. Results from this series of experiments suggested enhanced dexterity and adequate robustness that could be associated with feasibility in a clinical context, as well as improvement over current neurosurgical instruments.},
  archive      = {J_FROBT},
  author       = {Dimitrakakis, Emmanouil and Dwyer, George and Newall, Nicola and Khan, Danyal Z. and Marcus, Hani J. and Stoyanov, Danail},
  doi          = {10.3389/frobt.2024.1400017},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1400017},
  shortjournal = {Front. Robot. AI},
  title        = {Handheld robotic device for endoscopic neurosurgery: System integration and pre-clinical evaluation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review of collaborative robots for nurses:
Where are we now, and where is the evidence? <em>FROBT</em>,
<em>11</em>, 1398140. (<a
href="https://doi.org/10.3389/frobt.2024.1398140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Robots present an opportunity to enhance healthcare delivery. Rather than targeting complete automation and nurse replacement, collaborative robots, or “cobots”, might be designed to allow nurses to focus on high-value caregiving. While many institutions are now investing in these platforms, there is little publicly available data on how cobots are being developed, implemented, and evaluated to determine if and how they support nursing practice in the real world.Methods: This systematic review investigates the current state of cobotic technologies designed to assist nurses in hospital settings, their intended applications, and impacts on nurses and patient care. A comprehensive database search identified 28 relevant peer-reviewed articles published since 2018 which involve real studies with robotic platforms in simulated or actual clinical contexts.Results: Few cobots were explicitly designed to reduce nursing workload through administrative or logistical assistance. Most included studies were designed as patient-centered rather than nurse-centered, but included assistance for tasks like medication delivery, vital monitoring, and social interaction. Most applications emerged from India, with limited evidence from the United States despite commercial availability of nurse-assistive cobots. Robots ranged from proof-of-concept to commercially deployed systems.Discussion: This review highlights the need for further published studies on cobotic development and evaluation. A larger body of evidence is needed to recognize current limitations and pragmatic opportunities to assist nurses and patients using state-of-the-art robotics. Human-centered design can assist in discovering the right opportunities for cobotic assistance. Committed research-practice partnerships and human-centered design are needed to guide the technical development of nurse-centered cobotic solutions.},
  archive      = {J_FROBT},
  author       = {Babalola, Grace Titilayo and Gaston, Jenna-Marie and Trombetta, Joseph and Tulk Jesso, Stephanie},
  doi          = {10.3389/frobt.2024.1398140},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1398140},
  shortjournal = {Front. Robot. AI},
  title        = {A systematic review of collaborative robots for nurses: Where are we now, and where is the evidence?},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid controller with neural network PID/FOPID operations
for two-link rigid robot manipulator based on the zebra optimization
algorithm. <em>FROBT</em>, <em>11</em>, 1386968. (<a
href="https://doi.org/10.3389/frobt.2024.1386968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of the robotic manipulator is negatively impacted by outside disturbances and uncertain parameters. The system’s variables are also highly coupled, complex, and nonlinear, indicating that it is a multi-input, multi-output system. Therefore, it is necessary to develop a controller that can control the variables in the system in order to handle these complications. This work proposes six control structures based on neural networks (NNs) with proportional integral derivative (PID) and fractional-order PID (FOPID) controllers to operate a 2-link rigid robot manipulator (2-LRRM) for trajectory tracking. These are named as set-point-weighted PID (W-PID), set-point weighted FOPID (W-FOPID), recurrent neural network (RNN)-like PID (RNNPID), RNN-like FOPID (RNN-FOPID), NN+PID, and NN+FOPID controllers. The zebra optimization algorithm (ZOA) was used to adjust the parameters of the proposed controllers while reducing the integral-time-square error (ITSE). A new objective function was proposed for tuning to generate controllers with minimal chattering in the control signal. After implementing the proposed controller designs, a comparative robustness study was conducted among these controllers by altering the initial conditions, disturbances, and model uncertainties. The simulation results demonstrate that the NN+FOPID controller has the best trajectory tracking performance with the minimum ITSE and best robustness against changes in the initial states, external disturbances, and parameter uncertainties compared to the other controllers.},
  archive      = {J_FROBT},
  author       = {Jasim Mohamed, Mohamed and Oleiwi, Bashra Kadhim and Azar, Ahmad Taher and Mahlous, Ahmed Redha},
  doi          = {10.3389/frobt.2024.1386968},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1386968},
  shortjournal = {Front. Robot. AI},
  title        = {Hybrid controller with neural network PID/FOPID operations for two-link rigid robot manipulator based on the zebra optimization algorithm},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How did COVID-19 pandemic affect the older adults’ needs for
robot technologies in japan?: Comparison of participatory design
workshops during versus after the COVID-19 pandemic. <em>FROBT</em>,
<em>11</em>, 1363243. (<a
href="https://doi.org/10.3389/frobt.2024.1363243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social technology can improve the quality of social lives of older adults (OAs) and mitigate negative mental and physical health outcomes. When people engage with technology, they can do so to stimulate social interaction (stimulation hypothesis) or disengage from their real world (disengagement hypothesis), according to Nowland et al.‘s model of the relationship between social Internet use and loneliness. External events, such as large periods of social isolation like during the COVID-19 pandemic, can also affect whether people use technology in line with the stimulation or disengagement hypothesis. We examined how the COVID-19 pandemic affected the social challenges OAs faced and their expectations for robot technology to solve their challenges. We conducted two participatory design (PD) workshops with OAs during and after the COVID-19 pandemic. During the pandemic, OAs’ primary concern was distanced communication with family members, with a prevalent desire to assist them through technology. They also wanted to share experiences socially, as such OA’s attitude toward technology could be explained mostly by the stimulation hypothesis. However, after COVID-19 the pandemic, their focus shifted towards their own wellbeing. Social isolation and loneliness were already significant issues for OAs, and these were exacerbated by the COVID-19 pandemic. Therefore, such OAs’ attitudes toward technology after the pandemic could be explained mostly by the disengagement hypothesis. This clearly reflect the OA’s current situation that they have been getting further digitally excluded due to rapid technological development during the pandemic. Both during and after the pandemic, OAs found it important to have technologies that were easy to use, which would reduce their digital exclusion. After the pandemic, we found this especially in relation to newly developed technologies meant to help people keep at a distance. To effectively integrate these technologies and avoid excluding large parts of the population, society must address the social challenges faced by OAs.},
  archive      = {J_FROBT},
  author       = {Komatsu, Takanori and Fraune, Marlena R. and Tsui, Katherine M. and Suda, Shogo and Kobayashi, Mizuki},
  doi          = {10.3389/frobt.2024.1363243},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1363243},
  shortjournal = {Front. Robot. AI},
  title        = {How did COVID-19 pandemic affect the older adults’ needs for robot technologies in japan?: Comparison of participatory design workshops during versus after the COVID-19 pandemic},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing unmanned ground vehicle performance in SAR
operations: Integrated gesture-control and deep learning framework for
optimised victim detection. <em>FROBT</em>, <em>11</em>, 1356345. (<a
href="https://doi.org/10.3389/frobt.2024.1356345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we address the critical need for enhanced situational awareness and victim detection capabilities in Search and Rescue (SAR) operations amidst disasters. Traditional unmanned ground vehicles (UGVs) often struggle in such chaotic environments due to their limited manoeuvrability and the challenge of distinguishing victims from debris. Recognising these gaps, our research introduces a novel technological framework that integrates advanced gesture-recognition with cutting-edge deep learning for camera-based victim identification, specifically designed to empower UGVs in disaster scenarios. At the core of our methodology is the development and implementation of the Meerkat Optimization Algorithm—Stacked Convolutional Neural Network—Bi—Long Short Term Memory—Gated Recurrent Unit (MOA-SConv-Bi-LSTM-GRU) model, which sets a new benchmark for hand gesture detection with its remarkable performance metrics: accuracy, precision, recall, and F1-score all approximately 0.9866. This model enables intuitive, real-time control of UGVs through hand gestures, allowing for precise navigation in confined and obstacle-ridden spaces, which is vital for effective SAR operations. Furthermore, we leverage the capabilities of the latest YOLOv8 deep learning model, trained on specialised datasets to accurately detect human victims under a wide range of challenging conditions, such as varying occlusions, lighting, and perspectives. Our comprehensive testing in simulated emergency scenarios validates the effectiveness of our integrated approach. The system demonstrated exceptional proficiency in navigating through obstructions and rapidly locating victims, even in environments with visual impairments like smoke, clutter, and poor lighting. Our study not only highlights the critical gaps in current SAR response capabilities but also offers a pioneering solution through a synergistic blend of gesture-based control, deep learning, and purpose-built robotics. The key findings underscore the potential of our integrated technological framework to significantly enhance UGV performance in disaster scenarios, thereby optimising life-saving outcomes when time is of the essence. This research paves the way for future advancements in SAR technology, with the promise of more efficient and reliable rescue operations in the face of disaster.},
  archive      = {J_FROBT},
  author       = {Zafar, Muhammad Hamza and Moosavi, Syed Kumayl Raza and Sanfilippo, Filippo},
  doi          = {10.3389/frobt.2024.1356345},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1356345},
  shortjournal = {Front. Robot. AI},
  title        = {Enhancing unmanned ground vehicle performance in SAR operations: Integrated gesture-control and deep learning framework for optimised victim detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A navigated, robot-driven laser craniotomy tool for
frameless depth electrode implantation. An in-vivo recovery animal
study. <em>FROBT</em>, <em>11</em>, 1355409. (<a
href="https://doi.org/10.3389/frobt.2024.1355409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Winter, Fabian and Pilz, Patrick and Kramer, Anne M. and Beer, Daniel and Gono, Patrick and Morawska, Marta M. and Hainfellner, Johannes and Klotz, Sigrid and Tomschik, Matthias and Pataraia, Ekaterina and Hangel, Gilbert and Dorfer, Christian and Roessler, Karl},
  doi          = {10.3389/frobt.2024.1355409},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1355409},
  shortjournal = {Front. Robot. AI},
  title        = {A navigated, robot-driven laser craniotomy tool for frameless depth electrode implantation. an in-vivo recovery animal study},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning manufacturing computer vision systems using tiny
YOLOv4. <em>FROBT</em>, <em>11</em>, 1331249. (<a
href="https://doi.org/10.3389/frobt.2024.1331249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementing and deploying advanced technologies are principal in improving manufacturing processes, signifying a transformative stride in the industrial sector. Computer vision plays a crucial innovation role during this technological advancement, demonstrating broad applicability and profound impact across various industrial operations. This pivotal technology is not merely an additive enhancement but a revolutionary approach that redefines quality control, automation, and operational efficiency parameters in manufacturing landscapes. By integrating computer vision, industries are positioned to optimize their current processes significantly and spearhead innovations that could set new standards for future industrial endeavors. However, the integration of computer vision in these contexts necessitates comprehensive training programs for operators, given this advanced system’s complexity and abstract nature. Historically, training modalities have grappled with the complexities of understanding concepts as advanced as computer vision. Despite these challenges, computer vision has recently surged to the forefront across various disciplines, attributed to its versatility and superior performance, often matching or exceeding the capabilities of other established technologies. Nonetheless, there is a noticeable knowledge gap among students, particularly in comprehending the application of Artificial Intelligence (AI) within Computer Vision. This disconnect underscores the need for an educational paradigm transcending traditional theoretical instruction. Cultivating a more practical understanding of the symbiotic relationship between AI and computer vision is essential. To address this, the current work proposes a project-based instructional approach to bridge the educational divide. This methodology will enable students to engage directly with the practical aspects of computer vision applications within AI. By guiding students through a hands-on project, they will learn how to effectively utilize a dataset, train an object detection model, and implement it within a microcomputer infrastructure. This immersive experience is intended to bolster theoretical knowledge and provide a practical understanding of deploying AI techniques within computer vision. The main goal is to equip students with a robust skill set that translates into practical acumen, preparing a competent workforce to navigate and innovate in the complex landscape of Industry 4.0. This approach emphasizes the criticality of adapting educational strategies to meet the evolving demands of advanced technological infrastructures. It ensures that emerging professionals are adept at harnessing the potential of transformative tools like computer vision in industrial settings.},
  archive      = {J_FROBT},
  author       = {Medina, Adan and Bradley, Russel and Xu, Wenhao and Ponce, Pedro and Anthony, Brian and Molina, Arturo},
  doi          = {10.3389/frobt.2024.1331249},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1331249},
  shortjournal = {Front. Robot. AI},
  title        = {Learning manufacturing computer vision systems using tiny YOLOv4},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Silicone-layered waterproof electrohydraulic soft actuators
for bioinspired underwater robots. <em>FROBT</em>, <em>11</em>, 1298624.
(<a href="https://doi.org/10.3389/frobt.2024.1298624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Shibuya, Takumi and Watanabe, Shuya and Shintake, Jun},
  doi          = {10.3389/frobt.2024.1298624},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1298624},
  shortjournal = {Front. Robot. AI},
  title        = {Silicone-layered waterproof electrohydraulic soft actuators for bioinspired underwater robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). What helps, what hinders?—focus group findings on barriers
and facilitators for mobile service robot use in a psychosocial group
therapy for people with dementia. <em>FROBT</em>, <em>11</em>, 1258847.
(<a href="https://doi.org/10.3389/frobt.2024.1258847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IntroductionMany countries are facing a shortage of healthcare workers. Furthermore, healthcare workers are experiencing many stressors, resulting in psychological issues, impaired health, and increased intentions to leave the workplace. In recent years, different technologies have been implemented to lighten workload on healthcare workers, such as electronic patient files. Robotic solutions are still rather uncommon. To help with acceptance and actual use of robots their functionalities should correspond to the users’ needs.MethodIn the pilot study Care4All–Initial, we developed and field-tested applications for a mobile service robot in a psychosocial, multimodal group therapy for people with dementia. To guide the process and assess possible facilitators and barriers, we conducted a reoccurring focus group including people with dementia, therapists, professional caregivers as well as researchers from different disciplines with a user-centered design approach. The focus group suggested and reviewed applications and discussed ethical implications. We recorded the focus group discussions in writing and used content analysis.ResultsThe focus group discussed 15 different topics regarding ethical concerns that we used as a framework for the research project: Ethical facilitators were respect for the autonomy of the people with dementia and their proxies regarding participating and data sharing. Furthermore, the robot had to be useful for the therapists and attendees. Ethical barriers were the deception and possible harm of the people with dementia or therapists. The focus group suggested 32 different applications. We implemented 13 applications that centered on the robot interacting with the people with dementia and lightening the workload off the therapists. The implemented applications were facilitated through utilizing existing hard- and software and building on applications. Barriers to implementation were due to hardware, software, or applications not fitting the scope of the project.DiscussionTo prevent barriers of robot employment in a group therapy for people with dementia, the robot’s applications have to be developed sufficiently for a flawless and safe use, the use of the robot should not cause irritation or agitation, but rather be meaningful and useful to its users. To facilitate the development sufficient time, money, expertise and planning is essential.},
  archive      = {J_FROBT},
  author       = {Wasic, Catharina and Erzgräber, Robert and Unger-Büttner, Manja and Donath, Carolin and Böhme, Hans-Joachim and Graessel, Elmar},
  doi          = {10.3389/frobt.2024.1258847},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1258847},
  shortjournal = {Front. Robot. AI},
  title        = {What helps, what hinders?—Focus group findings on barriers and facilitators for mobile service robot use in a psychosocial group therapy for people with dementia},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Socially adaptive cognitive architecture for human-robot
collaboration in industrial settings. <em>FROBT</em>, <em>11</em>,
1248646. (<a href="https://doi.org/10.3389/frobt.2024.1248646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces DAC-HRC, a novel cognitive architecture designed to optimize human-robot collaboration (HRC) in industrial settings, particularly within the context of Industry 4.0. The architecture is grounded in the Distributed Adaptive Control theory and the principles of joint intentionality and interdependence, which are key to effective HRC. Joint intentionality refers to the shared goals and mutual understanding between a human and a robot, while interdependence emphasizes the reliance on each other’s capabilities to complete tasks. DAC-HRC is applied to a hybrid recycling plant for the disassembly and recycling of Waste Electrical and Electronic Equipment (WEEE) devices. The architecture incorporates several cognitive modules operating at different timescales and abstraction levels, fostering adaptive collaboration that is personalized to each human user. The effectiveness of DAC-HRC is demonstrated through several pilot studies, showcasing functionalities such as turn-taking interaction, personalized error-handling mechanisms, adaptive safety measures, and gesture-based communication. These features enhance human-robot collaboration in the recycling plant by promoting real-time robot adaptation to human needs and preferences. The DAC-HRC architecture aims to contribute to the development of a new HRC paradigm by paving the way for more seamless and efficient collaboration in Industry 4.0 by relying on socially adept cognitive architectures.},
  archive      = {J_FROBT},
  author       = {Freire, Ismael T. and Guerrero-Rosado, Oscar and Amil, Adrián F. and Verschure, Paul F. M. J.},
  doi          = {10.3389/frobt.2024.1248646},
  journal      = {Frontiers in Robotics and AI},
  month        = {6},
  pages        = {1248646},
  shortjournal = {Front. Robot. AI},
  title        = {Socially adaptive cognitive architecture for human-robot collaboration in industrial settings},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Decision-making and planning for multi-agent
systems. <em>FROBT</em>, <em>11</em>, 1422344. (<a
href="https://doi.org/10.3389/frobt.2024.1422344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tsiotras, Panagiotis and Gombolay, Matthew and Foerster, Jakob},
  doi          = {10.3389/frobt.2024.1422344},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1422344},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Decision-making and planning for multi-agent systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Human-like robotic hands for biomedical
applications and beyond. <em>FROBT</em>, <em>11</em>, 1414971. (<a
href="https://doi.org/10.3389/frobt.2024.1414971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Secco, Emanuele Lindo and Noh, Yohan},
  doi          = {10.3389/frobt.2024.1414971},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1414971},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Human-like robotic hands for biomedical applications and beyond},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Understanding and engineering cyber-physical
collectives. <em>FROBT</em>, <em>11</em>, 1407421. (<a
href="https://doi.org/10.3389/frobt.2024.1407421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Casadei, Roberto and Esterle, Lukas and Gamble, Rose and Harvey, Paul and Wanner, Elizabeth F.},
  doi          = {10.3389/frobt.2024.1407421},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1407421},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Understanding and engineering cyber-physical collectives},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Controlling the fold: Proprioceptive feedback in a soft
origami robot. <em>FROBT</em>, <em>11</em>, 1396082. (<a
href="https://doi.org/10.3389/frobt.2024.1396082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate proprioceptive feedback control of a one degree of freedom soft, pneumatically actuated origami robot and an assembly of two robots into a two degree of freedom system. The base unit of the robot is a 41 mm long, 3-D printed Kresling-inspired structure with six sets of sidewall folds and one degree of freedom. Pneumatic actuation, provided by negative fluidic pressure, causes the robot to contract. Capacitive sensors patterned onto the robot provide position estimation and serve as input to a feedback controller. Using a finite element approach, the electrode shapes are optimized for sensitivity at larger (more obtuse) fold angles to improve control across the actuation range. We demonstrate stable position control through discrete-time proportional-integral-derivative (PID) control on a single unit Kresling robot via a series of static set points to 17 mm, dynamic set point stepping, and sinusoidal signal following, with error under 3 mm up to 10 mm contraction. We also demonstrate a two-unit Kresling robot with two degree of freedom extension and rotation control, which has error of 1.7 mm and 6.1°. This work contributes optimized capacitive electrode design and the demonstration of closed-loop feedback position control without visual tracking as an input. This approach to capacitance sensing and modeling constitutes a major step towards proprioceptive state estimation and feedback control in soft origami robotics.},
  archive      = {J_FROBT},
  author       = {Hanson, Nathaniel and Mensah, Immanuel Ampomah and Roberts, Sonia F. and Healey, Jessica and Wu, Celina and Dorsey, Kristen L.},
  doi          = {10.3389/frobt.2024.1396082},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1396082},
  shortjournal = {Front. Robot. AI},
  title        = {Controlling the fold: Proprioceptive feedback in a soft origami robot},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Flow in human-robot collaboration—multimodal analysis and
perceived challenge detection in industrial scenarios. <em>FROBT</em>,
<em>11</em>, 1393795. (<a
href="https://doi.org/10.3389/frobt.2024.1393795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Flow state, the optimal experience resulting from the equilibrium between perceived challenge and skill level, has been extensively studied in various domains. However, its occurrence in industrial settings has remained relatively unexplored. Notably, the literature predominantly focuses on Flow within mentally demanding tasks, which differ significantly from industrial tasks. Consequently, our understanding of emotional and physiological responses to varying challenge levels, specifically in the context of industry-like tasks, remains limited.Methods: To bridge this gap, we investigate how facial emotion estimation (valence, arousal) and Heart Rate Variability (HRV) features vary with the perceived challenge levels during industrial assembly tasks. Our study involves an assembly scenario that simulates an industrial human-robot collaboration task with three distinct challenge levels. As part of our study, we collected video, electrocardiogram (ECG), and NASA-TLX questionnaire data from 37 participants.Results: Our results demonstrate a significant difference in mean arousal and heart rate between the low-challenge (Boredom) condition and the other conditions. We also found a noticeable trend-level difference in mean heart rate between the adaptive (Flow) and high-challenge (Anxiety) conditions. Similar differences were also observed in a few other temporal HRV features like Mean NN and Triangular index. Considering the characteristics of typical industrial assembly tasks, we aim to facilitate Flow by detecting and balancing the perceived challenge levels. Leveraging our analysis results, we developed an HRV-based machine learning model for discerning perceived challenge levels, distinguishing between low and higher-challenge conditions.Discussion: This work deepens our understanding of emotional and physiological responses to perceived challenge levels in industrial contexts and provides valuable insights for the design of adaptive work environments.},
  archive      = {J_FROBT},
  author       = {Prajod, Pooja and Lavit Nicora, Matteo and Mondellini, Marta and Falerni, Matteo Meregalli and Vertechy, Rocco and Malosio, Matteo and André, Elisabeth},
  doi          = {10.3389/frobt.2024.1393795},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1393795},
  shortjournal = {Front. Robot. AI},
  title        = {Flow in human-robot collaboration—multimodal analysis and perceived challenge detection in industrial scenarios},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Realistic 3D human saccades generated by a 6-DOF biomimetic
robotic eye under optimal control. <em>FROBT</em>, <em>11</em>, 1393637.
(<a href="https://doi.org/10.3389/frobt.2024.1393637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We recently developed a biomimetic robotic eye with six independent tendons, each controlled by their own rotatory motor, and with insertions on the eye ball that faithfully mimic the biomechanics of the human eye. We constructed an accurate physical computational model of this system, and learned to control its nonlinear dynamics by optimising a cost that penalised saccade inaccuracy, movement duration, and total energy expenditure of the motors. To speed up the calculations, the physical simulator was approximated by a recurrent neural network (NARX). We showed that the system can produce realistic eye movements that closely resemble human saccades in all directions: their nonlinear main-sequence dynamics (amplitude-peak eye velocity and duration relationships), cross-coupling of the horizontal and vertical movement components leading to approximately straight saccade trajectories, and the 3D kinematics that restrict 3D eye orientations to a plane (Listing’s law). Interestingly, the control algorithm had organised the motors into appropriate agonist-antagonist muscle pairs, and the motor signals for the eye resembled the well-known pulse-step characteristics that have been reported for monkey motoneuronal activity. We here fully analyse the eye-movement properties produced by the computational model across the entire oculomotor range and the underlying control signals. We argue that our system may shed new light on the neural control signals and their couplings within the final neural pathways of the primate oculomotor system, and that an optimal control principle may account for a wide variety of oculomotor behaviours. The generated data are publicly available at https://data.ru.nl/collections/di/dcn/DSC_626870_0003_600.},
  archive      = {J_FROBT},
  author       = {Van Opstal, A. John and Javanmard Alitappeh, Reza and John, Akhil and Bernardino, Alexandre},
  doi          = {10.3389/frobt.2024.1393637},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1393637},
  shortjournal = {Front. Robot. AI},
  title        = {Realistic 3D human saccades generated by a 6-DOF biomimetic robotic eye under optimal control},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Impact of politeness and performance quality of android
robots on future interaction decisions: A conversational design
perspective. <em>FROBT</em>, <em>11</em>, 1393456. (<a
href="https://doi.org/10.3389/frobt.2024.1393456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite robots being applied in various situations of modern society, some people avoid them or do not feel comfortable interacting with them. Designs that allow robots to interact appropriately with people will make a positive impression on them resulting in a better evaluation of robots, which will solve this problem. To establish such a design, this study conducted two scenario-based experiments focusing on the politeness of the robot’s conversation and behavior, and examined the impressions caused when the robot succeeds or slightly fails at a task. These two experiments revealed that regardless of whether the partner is a robot or a human, politeness not only affected the impression of interaction but also the expectations for better task results on the next occasion. Although the effect of politeness on preference toward robot agents was smaller than those toward human agents when agents failed a task, people were more likely to interact with polite robots and human agents again because they thought that they would not fail the next time. This study revealed that politeness motivates people to interact with robots repeatedly even if they make minor mistakes, suggesting that the politeness design is important for encouraging human-robot interaction.},
  archive      = {J_FROBT},
  author       = {Saeki, Waka and Ueda, Yoshiyuki},
  doi          = {10.3389/frobt.2024.1393456},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1393456},
  shortjournal = {Front. Robot. AI},
  title        = {Impact of politeness and performance quality of android robots on future interaction decisions: A conversational design perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed training of CosPlace for large-scale visual
place recognition. <em>FROBT</em>, <em>11</em>, 1386464. (<a
href="https://doi.org/10.3389/frobt.2024.1386464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual place recognition (VPR) is a popular computer vision task aimed at recognizing the geographic location of a visual query, usually within a tolerance of a few meters. Modern approaches address VPR from an image retrieval standpoint using a kNN on top of embeddings extracted by a deep neural network from both the query and images in a database. Although most of these approaches rely on contrastive learning, which limits their ability to be trained on large-scale datasets (due to mining), the recently reported CosPlace proposes an alternative training paradigm using a classification task as the proxy. This has been shown to be effective in expanding the potential of VPR models to learn from large-scale and fine-grained datasets. In this work, we experimentally analyze CosPlace from a continual learning perspective and show that its sequential training procedure leads to suboptimal results. As a solution, we propose a different formulation that not only solves the pitfalls of the original training strategy effectively but also enables faster and more efficient distributed training. Finally, we discuss the open challenges in further speeding up large-scale image retrieval for VPR.},
  archive      = {J_FROBT},
  author       = {Zaccone, Riccardo and Berton, Gabriele and Masone, Carlo},
  doi          = {10.3389/frobt.2024.1386464},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1386464},
  shortjournal = {Front. Robot. AI},
  title        = {Distributed training of CosPlace for large-scale visual place recognition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autonomous ultrasound scanning robotic system based on human
posture recognition and image servo control: An application for cardiac
imaging. <em>FROBT</em>, <em>11</em>, 1383732. (<a
href="https://doi.org/10.3389/frobt.2024.1383732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In traditional cardiac ultrasound diagnostics, the process of planning scanning paths and adjusting the ultrasound window relies solely on the experience and intuition of the physician, a method that not only affects the efficiency and quality of cardiac imaging but also increases the workload for physicians. To overcome these challenges, this study introduces a robotic system designed for autonomous cardiac ultrasound scanning, with the goal of advancing both the degree of automation and the quality of imaging in cardiac ultrasound examinations. The system achieves autonomous functionality through two key stages: initially, in the autonomous path planning stage, it utilizes a camera posture adjustment method based on the human body’s central region and its planar normal vectors to achieve automatic adjustment of the camera’s positioning angle; precise segmentation of the human body point cloud is accomplished through efficient point cloud processing techniques, and precise localization of the region of interest (ROI) based on keypoints of the human body. Furthermore, by applying isometric path slicing and B-spline curve fitting techniques, it independently plans the scanning path and the initial position of the probe. Subsequently, in the autonomous scanning stage, an innovative servo control strategy based on cardiac image edge correction is introduced to optimize the quality of the cardiac ultrasound window, integrating position compensation through admittance control to enhance the stability of autonomous cardiac ultrasound imaging, thereby obtaining a detailed view of the heart’s structure and function. A series of experimental validations on human and cardiac models have assessed the system’s effectiveness and precision in the correction of camera pose, planning of scanning paths, and control of cardiac ultrasound imaging quality, demonstrating its significant potential for clinical ultrasound scanning applications.},
  archive      = {J_FROBT},
  author       = {Tang, Xiuhong and Wang, Hongbo and Luo, Jingjing and Jiang, Jinlei and Nian, Fan and Qi, Lizhe and Sang, Lingfeng and Gan, Zhongxue},
  doi          = {10.3389/frobt.2024.1383732},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1383732},
  shortjournal = {Front. Robot. AI},
  title        = {Autonomous ultrasound scanning robotic system based on human posture recognition and image servo control: An application for cardiac imaging},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Max well-being: A modular platform for the gamification of
rehabilitation. <em>FROBT</em>, <em>11</em>, 1382157. (<a
href="https://doi.org/10.3389/frobt.2024.1382157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a modular platform to improve the adoption of gamification in conventional physical rehabilitation programs. The effectiveness of rehabilitation is correlated to a patient’s adherence to the program. This adherence can be diminished due to factors such as motivation, feedback, and isolation. Gamification is a means of adding game-like elements to a traditionally non-game activity. This has been shown to be effective in providing a more engaging experience and improving adherence. The platform is made of three main parts; a central hardware hub, various wired and wireless sensors, and a software program with a stream-lined user interface. The software interface and hardware peripherals were all designed to be simple to use by either a medical specialist or an end-user patient without the need for technical training. A usability study was performed using a group of university students and a group of medical specialists. Using the System Usability Scale, the system received an average score of 69.25 ± 20.14 and 72.5 ± 17.16 by the students and medical specialists, respectively. We also present a framework that attempts to assist in selecting commercial games that are viable for physical rehabilitation.},
  archive      = {J_FROBT},
  author       = {Kennard, Maxwell and Hassan, Modar and Shimizu, Yukiyo and Suzuki, Kenji},
  doi          = {10.3389/frobt.2024.1382157},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1382157},
  shortjournal = {Front. Robot. AI},
  title        = {Max well-being: A modular platform for the gamification of rehabilitation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mapless mobile robot navigation at the edge using
self-supervised cognitive map learners. <em>FROBT</em>, <em>11</em>,
1372375. (<a href="https://doi.org/10.3389/frobt.2024.1372375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigation of mobile agents in unknown, unmapped environments is a critical task for achieving general autonomy. Recent advancements in combining Reinforcement Learning with Deep Neural Networks have shown promising results in addressing this challenge. However, the inherent complexity of these approaches, characterized by multi-layer networks and intricate reward objectives, limits their autonomy, increases memory footprint, and complicates adaptation to energy-efficient edge hardware. To overcome these challenges, we propose a brain-inspired method that employs a shallow architecture trained by a local learning rule for self-supervised navigation in uncharted environments. Our approach achieves performance comparable to a state-of-the-art Deep Q Network (DQN) method with respect to goal-reaching accuracy and path length, with a similar (slightly lower) number of parameters, operations, and training iterations. Notably, our self-supervised approach combines novelty-based and random walks to alleviate the need for objective reward definition and enhance agent autonomy. At the same time, the shallow architecture and local learning rule do not call for error backpropagation, decreasing the memory overhead and enabling implementation on edge neuromorphic processors. These results contribute to the potential of embodied neuromorphic agents utilizing minimal resources while effectively handling variability.},
  archive      = {J_FROBT},
  author       = {Polykretis, Ioannis and Danielescu, Andreea},
  doi          = {10.3389/frobt.2024.1372375},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1372375},
  shortjournal = {Front. Robot. AI},
  title        = {Mapless mobile robot navigation at the edge using self-supervised cognitive map learners},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). When a notification at the right time is not enough: The
reminding process for socially assistive robots in institutional care.
<em>FROBT</em>, <em>11</em>, 1369438. (<a
href="https://doi.org/10.3389/frobt.2024.1369438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reminding is often identified as a central function of socially assistive robots in the healthcare sector. The robotic reminders are supposed to help people with memory impairments to remember to take their medicine, to drink and eat, or to attend appointments. Such standalone reminding technologies can, however, be too demanding for people with memory injuries. In a co-creation process, we developed an individual reminder robot together with a person with traumatic brain injury and her care personnel. During this process, we learned that while current research describe reminding as a prototypical task for socially assistive robots, there is no clear definition of what constitutes a reminder nor that it is based on complex sequences of interactions that evolve over time and space, across different actions, actors and technologies. Based on our data from the co-creation process and the first deployment, we argue for a shift towards a sequential and socially distributed character of reminding. Understanding socially assistive robots as rehabilitative tools for people with memory impairment, they need to be reconsidered as interconnected elements in institutional care practices instead of isolated events for the remindee.},
  archive      = {J_FROBT},
  author       = {Rehm, Matthias and Krummheuer, Antonia L.},
  doi          = {10.3389/frobt.2024.1369438},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1369438},
  shortjournal = {Front. Robot. AI},
  title        = {When a notification at the right time is not enough: The reminding process for socially assistive robots in institutional care},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Haptic based fundamentals of laparoscopic surgery simulation
for training with objective assessments. <em>FROBT</em>, <em>11</em>,
1363952. (<a href="https://doi.org/10.3389/frobt.2024.1363952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Force is crucial for learning psychomotor skills in laparoscopic tissue manipulation. Fundamental laparoscopic surgery (FLS), on the other hand, only measures time and position accuracy. FLS is a commonly used training program for basic laparoscopic training through part tasks. The FLS is employed in most of the laparoscopic training systems, including box trainers and virtual reality (VR) simulators. However, many laparoscopic VR simulators lack force feedback and measure tissue damage solely through visual feedback based on virtual collisions. Few VR simulators that provide force feedback have subjective force metrics. To provide an objective force assessment for haptic skills training in the VR simulators, we extend the FLS part tasks to haptic-based FLS (HFLS), focusing on controlled force exertion. We interface the simulated HFLS part tasks with a customized bi-manual haptic simulator that offers five degrees of freedom (DOF) for force feedback. The proposed tasks are evaluated through face and content validity among laparoscopic surgeons of varying experience levels. The results show that trainees perform better in HFLS tasks. The average Likert score observed for face and content validity is greater than 4.6 ± 0.3 and 4 ± 0.5 for all the part tasks, which indicates the acceptance of the simulator among subjects for its appearance and functionality. Face and content validations show the need to improve haptic realism, which is also observed in existing simulators. To enhance the accuracy of force rendering, we incorporated a laparoscopic tool force model into the simulation. We study the effectiveness of the model through a psychophysical study that measures just noticeable difference (JND) for the laparoscopic gripping task. The study reveals an insignificant decrease in gripping-force JND. A simple linear model could be sufficient for gripper force feedback, and a non-linear LapTool force model does not affect the force perception for the force range of 0.5–2.5 N. Further study is required to understand the usability of the force model in laparoscopic training at a higher force range. Additionally, the construct validity of HFLS will confirm the applicability of the developed simulator to train surgeons with different levels of experience.},
  archive      = {J_FROBT},
  author       = {Abinaya, P. and Manivannan, M.},
  doi          = {10.3389/frobt.2024.1363952},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1363952},
  shortjournal = {Front. Robot. AI},
  title        = {Haptic based fundamentals of laparoscopic surgery simulation for training with objective assessments},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recommendations for designing conversational companion
robots with older adults through foundation models. <em>FROBT</em>,
<em>11</em>, 1363713. (<a
href="https://doi.org/10.3389/frobt.2024.1363713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Companion robots are aimed to mitigate loneliness and social isolation among older adults by providing social and emotional support in their everyday lives. However, older adults’ expectations of conversational companionship might substantially differ from what current technologies can achieve, as well as from other age groups like young adults. Thus, it is crucial to involve older adults in the development of conversational companion robots to ensure that these devices align with their unique expectations and experiences. The recent advancement in foundation models, such as large language models, has taken a significant stride toward fulfilling those expectations, in contrast to the prior literature that relied on humans controlling robots (i.e., Wizard of Oz) or limited rule-based architectures that are not feasible to apply in the daily lives of older adults. Consequently, we conducted a participatory design (co-design) study with 28 older adults, demonstrating a companion robot using a large language model (LLM), and design scenarios that represent situations from everyday life. The thematic analysis of the discussions around these scenarios shows that older adults expect a conversational companion robot to engage in conversation actively in isolation and passively in social settings, remember previous conversations and personalize, protect privacy and provide control over learned data, give information and daily reminders, foster social skills and connections, and express empathy and emotions. Based on these findings, this article provides actionable recommendations for designing conversational companion robots for older adults with foundation models, such as LLMs and vision-language models, which can also be applied to conversational robots in other domains.},
  archive      = {J_FROBT},
  author       = {Irfan, Bahar and Kuoppamäki, Sanna and Skantze, Gabriel},
  doi          = {10.3389/frobt.2024.1363713},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1363713},
  shortjournal = {Front. Robot. AI},
  title        = {Recommendations for designing conversational companion robots with older adults through foundation models},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quasi-steady aerodynamic modeling and dynamic stability of
mosquito-inspired flapping wing pico aerial vehicle. <em>FROBT</em>,
<em>11</em>, 1362206. (<a
href="https://doi.org/10.3389/frobt.2024.1362206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent exploration in insect-inspired robotics has generated considerable interest. Among insects navigating at low Reynolds numbers, mosquitoes exhibit distinct flight characteristics, including higher wingbeat frequencies, reduced stroke amplitudes, and slender wings. This leads to unique aerodynamic traits such as trailing edge vortices via wake capture, diminished reliance on leading vortices, and rotational drag. This paper shows the energetic analysis of a mosquito-inspired flapping-wing Pico aerial vehicle during hovering, contributing insights to its future design and fabrication. The investigation relies on kinematic and quasi-steady aerodynamic modeling of a symmetric flapping-wing model with a wingspan of approximately 26 mm, considering translational, rotational, and wake capture force components. The control strategy adapts existing bird flapping wing approaches to accommodate insect wing kinematics and aerodynamic features. Flight controller design is grounded in understanding the impact of kinematics on wing forces. Additionally, a thorough analysis of the dynamic stability of the mosquito-inspired PAV model is conducted, revealing favorable controller response and maneuverability at a small scale. The modified model, incorporating rigid body dynamics and non-averaged aerodynamics, exhibits weak stability without a controller or sufficient power density. However, the controller effectively stabilizes the PAV model, addressing attitude and maneuverability. These preliminary findings offer valuable insights for the mechanical design, aerodynamics, and fabrication of RoboMos, an insect-inspired flapping wing pico aerial vehicle developed at UPM Malaysia.},
  archive      = {J_FROBT},
  author       = {Singh, Balbir and Ahmad, Kamarul Arifin and Murugaiah, Manikandan and Yidris, Noorfaizal and Basri, Adi Azriff and Pai, Raghuvir},
  doi          = {10.3389/frobt.2024.1362206},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1362206},
  shortjournal = {Front. Robot. AI},
  title        = {Quasi-steady aerodynamic modeling and dynamic stability of mosquito-inspired flapping wing pico aerial vehicle},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Applications of a vacuum-actuated multi-material hybrid soft
gripper: Lessons learnt from RoboSoft manipulation challenge.
<em>FROBT</em>, <em>11</em>, 1356692. (<a
href="https://doi.org/10.3389/frobt.2024.1356692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft grippers are garnering increasing attention for their adeptness in conforming to diverse objects, particularly delicate items, without warranting precise force control. This attribute proves especially beneficial in unstructured environments and dynamic tasks such as food handling. Human hands, owing to their elevated dexterity and precise motor control, exhibit the ability to delicately manipulate complex food items, such as small or fragile objects, by dynamically adjusting their grasping configurations. Furthermore, with their rich sensory receptors and hand-eye coordination that provide valuable information involving the texture and form factor, real-time adjustments to avoid damage or spill during food handling appear seamless. Despite numerous endeavors to replicate these capabilities through robotic solutions involving soft grippers, matching human performance remains a formidable engineering challenge. Robotic competitions serve as an invaluable platform for pushing the boundaries of manipulation capabilities, simultaneously offering insights into the adoption of these solutions across diverse domains, including food handling. Serving as a proxy for the future transition of robotic solutions from the laboratory to the market, these competitions simulate real-world challenges. Since 2021, our research group has actively participated in RoboSoft competitions, securing victories in the Manipulation track in 2022 and 2023. Our success was propelled by the utilization of a modified iteration of our Retractable Nails Soft Gripper (RNSG), tailored to meet the specific requirements of each task. The integration of sensors and collaborative manipulators further enhanced the gripper’s performance, facilitating the seamless execution of complex grasping tasks associated with food handling. This article encapsulates the experiential insights gained during the application of our highly versatile soft gripper in these competition environments.},
  archive      = {J_FROBT},
  author       = {Dontu, Saikrishna and Kanhere, Elgar and Stalin, Thileepan and Dharmawan, Audelia Gumarus and Hegde, Chidanand and Su, Jiangtao and Chen, Xiaodong and Magdassi, Shlomo and Soh, Gim Song and Valdivia Y. Alvarado, Pablo},
  doi          = {10.3389/frobt.2024.1356692},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1356692},
  shortjournal = {Front. Robot. AI},
  title        = {Applications of a vacuum-actuated multi-material hybrid soft gripper: Lessons learnt from RoboSoft manipulation challenge},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AiroTouch: Enhancing telerobotic assembly through
naturalistic haptic feedback of tool vibrations. <em>FROBT</em>,
<em>11</em>, 1355205. (<a
href="https://doi.org/10.3389/frobt.2024.1355205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teleoperation allows workers to safely control powerful construction machines; however, its primary reliance on visual feedback limits the operator’s efficiency in situations with stiff contact or poor visibility, hindering its use for assembly of pre-fabricated building components. Reliable, economical, and easy-to-implement haptic feedback could fill this perception gap and facilitate the broader use of robots in construction and other application areas. Thus, we adapted widely available commercial audio equipment to create AiroTouch, a naturalistic haptic feedback system that measures the vibration experienced by each robot tool and enables the operator to feel a scaled version of this vibration in real time. Accurate haptic transmission was achieved by optimizing the positions of the system’s off-the-shelf accelerometers and voice-coil actuators. A study was conducted to evaluate how adding this naturalistic type of vibrotactile feedback affects the operator during telerobotic assembly. Thirty participants used a bimanual dexterous teleoperation system (Intuitive da Vinci Si) to build a small rigid structure under three randomly ordered haptic feedback conditions: no vibrations, one-axis vibrations, and summed three-axis vibrations. The results show that users took advantage of both tested versions of the naturalistic haptic feedback after gaining some experience with the task, causing significantly lower vibrations and forces in the second trial. Subjective responses indicate that haptic feedback increased the realism of the interaction and reduced the perceived task duration, task difficulty, and fatigue. As hypothesized, higher haptic feedback gains were chosen by users with larger hands and for the smaller sensed vibrations in the one-axis condition. These results elucidate important details for effective implementation of naturalistic vibrotactile feedback and demonstrate that our accessible audio-based approach could enhance user performance and experience during telerobotic assembly in construction and other application domains.},
  archive      = {J_FROBT},
  author       = {Gong, Yijie and Mat Husin, Haliza and Erol, Ecda and Ortenzi, Valerio and Kuchenbecker, Katherine J.},
  doi          = {10.3389/frobt.2024.1355205},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1355205},
  shortjournal = {Front. Robot. AI},
  title        = {AiroTouch: Enhancing telerobotic assembly through naturalistic haptic feedback of tool vibrations},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comparison of visual and auditory EEG interfaces for robot
multi-stage task control. <em>FROBT</em>, <em>11</em>, 1329270. (<a
href="https://doi.org/10.3389/frobt.2024.1329270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shared autonomy holds promise for assistive robotics, whereby physically-impaired people can direct robots to perform various tasks for them. However, a robot that is capable of many tasks also introduces many choices for the user, such as which object or location should be the target of interaction. In the context of non-invasive brain-computer interfaces for shared autonomy—most commonly electroencephalography-based—the two most common choices are to provide either auditory or visual stimuli to the user—each with their respective pros and cons. Using the oddball paradigm, we designed comparable auditory and visual interfaces to speak/display the choices to the user, and had users complete a multi-stage robotic manipulation task involving location and object selection. Users displayed differing competencies—and preferences—for the different interfaces, highlighting the importance of considering modalities outside of vision when constructing human-robot interfaces.},
  archive      = {J_FROBT},
  author       = {Arulkumaran, Kai and Di Vincenzo, Marina and Dossa, Rousslan Fernand Julien and Akiyama, Shogo and Ogawa Lillrank, Dan and Sato, Motoshige and Tomeoka, Kenichi and Sasai, Shuntaro},
  doi          = {10.3389/frobt.2024.1329270},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1329270},
  shortjournal = {Front. Robot. AI},
  title        = {A comparison of visual and auditory EEG interfaces for robot multi-stage task control},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computational kinematics of dance: Distinguishing hip hop
genres. <em>FROBT</em>, <em>11</em>, 1295308. (<a
href="https://doi.org/10.3389/frobt.2024.1295308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dance plays a vital role in human societies across time and culture, with different communities having invented different systems for artistic expression through movement (genres). Differences between genres can be described by experts in words and movements, but these descriptions can only be appreciated by people with certain background abilities. Existing dance notation schemes could be applied to describe genre-differences, however they fall substantially short of being able to capture the important details of movement across a wide spectrum of genres. Our knowledge and practice around dance would benefit from a general, quantitative and human-understandable method of characterizing meaningful differences between aspects of any dance style; a computational kinematics of dance. Here we introduce and apply a novel system for encoding bodily movement as 17 macroscopic, interpretable features, such as expandedness of the body or the frequency of sharp movements. We use this encoding to analyze Hip Hop Dance genres, in part by building a low-cost machine-learning classifier that distinguishes genre with high accuracy. Our study relies on an open dataset (AIST++) of pose-sequences from dancers instructed to perform one of ten Hip Hop genres, such as Breakdance, Popping, or Krump. For comparison we evaluate moderately experienced human observers at discerning these sequence’s genres from movements alone (38% where chance = 10%). The performance of a baseline, Ridge classifier model was fair (48%) and that of the model resulting from our automated machine learning pipeline was strong (76%). This indicates that the selected features represent important dimensions of movement for the expression of the attitudes, stories, and aesthetic values manifested in these dance forms. Our study offers a new window into significant relations of similarity and difference between the genres studied. Given the rich, complex, and culturally shaped nature of these genres, the interpretability of our features, and the lightweight techniques used, our approach has significant potential for generalization to other movement domains and movement-related applications.},
  archive      = {J_FROBT},
  author       = {Baker, Ben and Liu, Tony and Matelsky, Jordan and Parodi, Felipe and Mensh, Brett and Krakauer, John W. and Kording, Konrad},
  doi          = {10.3389/frobt.2024.1295308},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1295308},
  shortjournal = {Front. Robot. AI},
  title        = {Computational kinematics of dance: Distinguishing hip hop genres},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CEPB dataset: A photorealistic dataset to foster the
research on bin picking in cluttered environments. <em>FROBT</em>,
<em>11</em>, 1222465. (<a
href="https://doi.org/10.3389/frobt.2024.1222465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several datasets have been proposed in the literature, focusing on object detection and pose estimation. The majority of them are interested in recognizing isolated objects or the pose of objects in well-organized scenarios. This work introduces a novel dataset that aims to stress vision algorithms in the difficult task of object detection and pose estimation in highly cluttered scenes concerning the specific case of bin picking for the Cluttered Environment Picking Benchmark (CEPB). The dataset provides about 1.5M virtually generated photo-realistic images (RGB + depth + normals + segmentation) of 50K annotated cluttered scenes mixing rigid, soft, and deformable objects of varying sizes used in existing robotic picking benchmarks together with their 3D models (40 objects). Such images include three different camera positions, three light conditions, and multiple High Dynamic Range Imaging (HDRI) maps for domain randomization purposes. The annotations contain the 2D and 3D bounding boxes of the involved objects, the centroids’ poses (translation + quaternion), and the visibility percentage of the objects’ surfaces. Nearly 10K separated object images are presented to perform simple tests and compare them with more complex cluttered scenarios tests. A baseline performed with the DOPE neural network is reported to highlight the challenges introduced by the novel dataset.},
  archive      = {J_FROBT},
  author       = {Tripicchio, Paolo and D’Avella, Salvatore and Avizzano, Carlo Alberto},
  doi          = {10.3389/frobt.2024.1222465},
  journal      = {Frontiers in Robotics and AI},
  month        = {5},
  pages        = {1222465},
  shortjournal = {Front. Robot. AI},
  title        = {CEPB dataset: A photorealistic dataset to foster the research on bin picking in cluttered environments},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Design, modeling and control of kinematically
redundant robots. <em>FROBT</em>, <em>11</em>, 1399217. (<a
href="https://doi.org/10.3389/frobt.2024.1399217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Lee, Yangming and Virgala, Ivan and Sadati, S. M. Hadi and Falotico, Egidio},
  doi          = {10.3389/frobt.2024.1399217},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1399217},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Design, modeling and control of kinematically redundant robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Educational robotics and competitions.
<em>FROBT</em>, <em>11</em>, 1394849. (<a
href="https://doi.org/10.3389/frobt.2024.1394849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Martins, Felipe N. and Lima, José and Oliveira, Andre Schneider de and Costa, Paulo and Eguchi, Amy},
  doi          = {10.3389/frobt.2024.1394849},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1394849},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Educational robotics and competitions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Magnetic multilayer hydrogel oral microrobots for digestive
tract treatment. <em>FROBT</em>, <em>11</em>, 1392297. (<a
href="https://doi.org/10.3389/frobt.2024.1392297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oral administration is a convenient drug delivery method in our daily lives. However, it remains a challenge to achieve precise target delivery and ensure the efficacy of medications in extreme environments within the digestive system with complex environments. This paper proposes an oral multilayer magnetic hydrogel microrobot for targeted delivery and on-demand release driven by a gradient magnetic field. The inner hydrogel shells enclose designated drugs and magnetic microparticles. The outer hydrogel shells enclose the inner hydrogel shells, magnetic microparticles, and pH neutralizers. The drug release procedure is remotely implemented layer-by-layer. When the required gradient magnetic field is applied, the outer hydrogel shells are destroyed to release their inclusions. The enclosed pH neutralizers scour the surrounding environment to avoid damaging drugs by the pH environment. Subsequently, the inner hydrogel shells are destroyed to release the drugs. A set of experiments are conducted to demonstrate the wirelessly controllable target delivery and release in a Petri dish and biological tissues. The results demonstrated attractive advantages of the reported microrobot in microcargo delivery with almost no loss, remote controllable release, and drug protection by the pH neutralizers. It is a promising approach to advance next-generation precision oral therapies in the digestive system.},
  archive      = {J_FROBT},
  author       = {Xu, Ziheng and Wu, Zehao and Xu, Zichen and Xu, Qingsong},
  doi          = {10.3389/frobt.2024.1392297},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1392297},
  shortjournal = {Front. Robot. AI},
  title        = {Magnetic multilayer hydrogel oral microrobots for digestive tract treatment},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the design of deep learning-based control algorithms for
visually guided UAVs engaged in power tower inspection tasks.
<em>FROBT</em>, <em>11</em>, 1378149. (<a
href="https://doi.org/10.3389/frobt.2024.1378149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the design of Convolution Neural Networks to visually guide an autonomous Unmanned Aerial Vehicle required to inspect power towers. The network is required to precisely segment images taken by a camera mounted on a UAV in order to allow a motion module to generate collision-free and inspection-relevant manoeuvres of the UAV along different types of towers. The images segmentation process is particularly challenging not only because of the different structures of the towers but also because of the enormous variability of the background, which can vary from the uniform blue of the sky to the multi-colour complexity of a rural, forest, or urban area. To be able to train networks that are robust enough to deal with the task variability, without incurring into a labour-intensive and costly annotation process of physical-world images, we have carried out a comparative study in which we evaluate the performances of networks trained either with synthetic images (i.e., the synthetic dataset), physical-world images (i.e., the physical-world dataset), or a combination of these two types of images (i.e., the hybrid dataset). The network used is an attention-based U-NET. The synthetic images are created using photogrammetry, to accurately model power towers, and simulated environments modelling a UAV during inspection of different power towers in different settings. Our findings reveal that the network trained on the hybrid dataset outperforms the networks trained with the synthetic and the physical-world image datasets. Most notably, the networks trained with the hybrid dataset demonstrates a superior performance on multiples evaluation metrics related to the image-segmentation task. This suggests that, the combination of synthetic and physical-world images represents the best trade-off to minimise the costs related to capturing and annotating physical-world images, and to maximise the task performances. Moreover, the results of our study demonstrate the potential of photogrammetry in creating effective training datasets to design networks to automate the precise movement of visually-guided UAVs.},
  archive      = {J_FROBT},
  author       = {Maitre, Guillaume and Martinot, Dimitri and Tuci, Elio},
  doi          = {10.3389/frobt.2024.1378149},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1378149},
  shortjournal = {Front. Robot. AI},
  title        = {On the design of deep learning-based control algorithms for visually guided UAVs engaged in power tower inspection tasks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation of force pain thresholds to ensure collision
safety in worker-robot collaborative operations. <em>FROBT</em>,
<em>11</em>, 1374999. (<a
href="https://doi.org/10.3389/frobt.2024.1374999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing demand for robots in the industrial field, robot-related technologies with various functions have been introduced. One notable development is the implementation of robots that operate in collaboration with human workers to share tasks, without the need of any physical barriers such as safety fences. The realization of such collaborative operations in practice necessitates the assurance of safety if humans and robots collide. Thus, it is important to establish criteria for such collision scenarios to ensure robot safety and prevent injuries. Collision safety must be ensured in both pinching (quasi-static contact) and impact (transient contact) situations. To this end, we measured the force pain thresholds associated with impacts and evaluated the biomechanical limitations. This measurements were obtained through clinical trials involving physical collisions between human subjects and a device designed for generating impacts, and the force pain thresholds associated with transient collisions between humans and robots were analyzed. Specifically, the force pain threshold was measured at two different locations on the bodies of 37 adults aged 19–32 years, using two impactors with different shapes. The force pain threshold was compared with the results of other relevant studies. The results can help identify biomechanical limitations in a precise and reliable manner to ensure the safety of robots in collaborative applications.},
  archive      = {J_FROBT},
  author       = {Han, D. and Park, M. Y. and Choi, J. and Shin, H. and Behrens, R. and Rhim, S.},
  doi          = {10.3389/frobt.2024.1374999},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1374999},
  shortjournal = {Front. Robot. AI},
  title        = {Evaluation of force pain thresholds to ensure collision safety in worker-robot collaborative operations},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Webcam-based gaze estimation for computer screen
interaction. <em>FROBT</em>, <em>11</em>, 1369566. (<a
href="https://doi.org/10.3389/frobt.2024.1369566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel webcam-based approach for gaze estimation on computer screens. Utilizing appearance based gaze estimation models, the system provides a method for mapping the gaze vector from the user’s perspective onto the computer screen. Notably, it determines the user’s 3D position in front of the screen, using only a 2D webcam without the need for additional markers or equipment. The study presents a comprehensive comparative analysis, assessing the performance of the proposed method against established eye tracking solutions. This includes a direct comparison with the purpose-built Tobii Eye Tracker 5, a high-end hardware solution, and the webcam-based GazeRecorder software. In experiments replicating head movements, especially those imitating yaw rotations, the study brings to light the inherent difficulties associated with tracking such motions using 2D webcams. This research introduces a solution by integrating Structure from Motion (SfM) into the Convolutional Neural Network (CNN) model. The study’s accomplishments include showcasing the potential for accurate screen gaze tracking with a simple webcam, presenting a novel approach for physical distance computation, and proposing compensation for head movements, laying the groundwork for advancements in real-world gaze estimation scenarios.},
  archive      = {J_FROBT},
  author       = {Falch, Lucas and Lohan, Katrin Solveig},
  doi          = {10.3389/frobt.2024.1369566},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1369566},
  shortjournal = {Front. Robot. AI},
  title        = {Webcam-based gaze estimation for computer screen interaction},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recruiting neural field theory for data augmentation in a
motor imagery brain–computer interface. <em>FROBT</em>, <em>11</em>,
1362735. (<a href="https://doi.org/10.3389/frobt.2024.1362735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel approach to training data augmentation in brain–computer interfaces (BCIs) using neural field theory (NFT) applied to EEG data from motor imagery tasks. BCIs often suffer from limited accuracy due to a limited amount of training data. To address this, we leveraged a corticothalamic NFT model to generate artificial EEG time series as supplemental training data. We employed the BCI competition IV ‘2a’ dataset to evaluate this augmentation technique. For each individual, we fitted the model to common spatial patterns of each motor imagery class, jittered the fitted parameters, and generated time series for data augmentation. Our method led to significant accuracy improvements of over 2% in classifying the “total power” feature, but not in the case of the “Higuchi fractal dimension” feature. This suggests that the fit NFT model may more favorably represent one feature than the other. These findings pave the way for further exploration of NFT-based data augmentation, highlighting the benefits of biophysically accurate artificial data.},
  archive      = {J_FROBT},
  author       = {Polyakov, Daniel and Robinson, Peter A. and Muller, Eli J. and Shriki, Oren},
  doi          = {10.3389/frobt.2024.1362735},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1362735},
  shortjournal = {Front. Robot. AI},
  title        = {Recruiting neural field theory for data augmentation in a motor imagery brain–computer interface},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation of co-speech gestures grounded in
word-distributed representation. <em>FROBT</em>, <em>11</em>, 1362463.
(<a href="https://doi.org/10.3389/frobt.2024.1362463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The condition for artificial agents to possess perceivable intentions can be considered that they have resolved a form of the symbol grounding problem. Here, the symbol grounding is considered an achievement of the state where the language used by the agent is endowed with some quantitative meaning extracted from the physical world. To achieve this type of symbol grounding, we adopt a method for characterizing robot gestures with quantitative meaning calculated from word-distributed representations constructed from a large corpus of text. In this method, a “size image” of a word is generated by defining an axis (index) that discriminates the “size” of the word in the word-distributed vector space. The generated size images are converted into gestures generated by a physical artificial agent (robot). The robot’s gesture can be set to reflect either the size of the word in terms of the amount of movement or in terms of its posture. To examine the perception of communicative intention in the robot that performs the gestures generated as described above, the authors examine human ratings on “the naturalness” obtained through an online survey, yielding results that partially validate our proposed method. Based on the results, the authors argue for the possibility of developing advanced artifacts that achieve human-like symbolic grounding.},
  archive      = {J_FROBT},
  author       = {Sasaki, Kosuke and Nishikawa, Jumpei and Morita, Junya},
  doi          = {10.3389/frobt.2024.1362463},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1362463},
  shortjournal = {Front. Robot. AI},
  title        = {Evaluation of co-speech gestures grounded in word-distributed representation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The integration of GPS and visual navigation for autonomous
navigation of an ackerman steering mobile robot in cotton fields.
<em>FROBT</em>, <em>11</em>, 1359887. (<a
href="https://doi.org/10.3389/frobt.2024.1359887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous navigation in agricultural fields presents a unique challenge due to the unpredictable outdoor environment. Various approaches have been explored to tackle this task, each with its own set of challenges. These include GPS guidance, which faces availability issues and struggles to avoid obstacles, and vision guidance techniques, which are sensitive to changes in light, weeds, and crop growth. This study proposes a novel idea that combining GPS and visual navigation offers an optimal solution for autonomous navigation in agricultural fields. Three solutions for autonomous navigation in cotton fields were developed and evaluated. The first solution utilized a path tracking algorithm, Pure Pursuit, to follow GPS coordinates and guide a mobile robot. It achieved an average lateral deviation of 8.3 cm from the pre-recorded path. The second solution employed a deep learning model, specifically a fully convolutional neural network for semantic segmentation, to detect paths between cotton rows. The mobile rover then navigated using the Dynamic Window Approach (DWA) path planning algorithm, achieving an average lateral deviation of 4.8 cm from the desired path. Finally, the two solutions were integrated for a more practical approach. GPS served as a global planner to map the field, while the deep learning model and DWA acted as a local planner for navigation and real-time decision-making. This integrated solution enabled the robot to navigate between cotton rows with an average lateral distance error of 9.5 cm, offering a more practical method for autonomous navigation in cotton fields.},
  archive      = {J_FROBT},
  author       = {Mwitta, Canicius and Rains, Glen C.},
  doi          = {10.3389/frobt.2024.1359887},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1359887},
  shortjournal = {Front. Robot. AI},
  title        = {The integration of GPS and visual navigation for autonomous navigation of an ackerman steering mobile robot in cotton fields},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A containerised approach for multiform robotic applications.
<em>FROBT</em>, <em>11</em>, 1358978. (<a
href="https://doi.org/10.3389/frobt.2024.1358978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the area of robotics achieves promising results, there is an increasing need to scale robotic software architectures towards real-world domains. Traditionally, robotic architectures are integrated using common frameworks, such as ROS. Therefore, systems with a uniform structure are produced, making it difficult to integrate third party contributions. Virtualisation technologies can simplify the problem, but their use is uncommon in robotics and general integration procedures are still missing. This paper proposes and evaluates a containerised approach for designing and integrating multiform robotic architectures. Our approach aims at augmenting preexisting architectures by including third party contributions. The integration complexity and computational performance of our approach is benchmarked on the EU H2020 SecondHands robotic architecture. Results demonstrate that our approach grants simplicity and flexibility of setup when compared to a non-virtualised version. The computational overhead of using our approach is negligible as resources were optimally exploited.},
  archive      = {J_FROBT},
  author       = {Cotugno, Giuseppe and Rodrigues, Rafael Afonso and Deacon, Graham and Konstantinova, Jelizaveta},
  doi          = {10.3389/frobt.2024.1358978},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1358978},
  shortjournal = {Front. Robot. AI},
  title        = {A containerised approach for multiform robotic applications},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-based trajectory tracking of a compliant continuum
robot. <em>FROBT</em>, <em>11</em>, 1358857. (<a
href="https://doi.org/10.3389/frobt.2024.1358857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Compliant mechanisms, especially continuum robots, are becoming integral to advancements in minimally invasive surgery due to their ability to autonomously navigate natural pathways, significantly reducing collision severity. A major challenge lies in developing an effective control strategy to accurately reflect their behavior for enhanced operational precision.Methods: This study examines the trajectory tracking capabilities of a tendon-driven continuum robot at its tip. We introduce a novel feedforward control methodology that leverages a mathematical model based on Cosserat rod theory. To mitigate the computational challenges inherent in such models, we implement an implicit time discretization strategy. This approach simplifies the governing equations into space-domain ordinary differential equations, facilitating real-time computational efficiency. The control strategy is devised to enable the robot tip to follow a dynamically prescribed trajectory in two dimensions.Results: The efficacy of the proposed control method was validated through experimental tests on six different demand trajectories, with a motion capture system employed to assess positional accuracy. The findings indicate that the robot can track trajectories with an accuracy within 9.5%, showcasing consistent repeatability across different runs.Discussion: The results from this study mark a significant step towards establishing an efficient and precise control methodology for compliant continuum robots. The demonstrated accuracy and repeatability of the control approach significantly enhance the potential of these robots in minimally invasive surgical applications, paving the way for further research and development in this field.},
  archive      = {J_FROBT},
  author       = {Pekris, Solomon and Williams, Robert D. and Atkins, Thibaud and Georgilas, Ioannis and Bailey, Nicola},
  doi          = {10.3389/frobt.2024.1358857},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1358857},
  shortjournal = {Front. Robot. AI},
  title        = {Model-based trajectory tracking of a compliant continuum robot},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human-in-the-loop error detection in an object organization
task with a social robot. <em>FROBT</em>, <em>11</em>, 1356827. (<a
href="https://doi.org/10.3389/frobt.2024.1356827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In human-robot collaboration, failures are bound to occur. A thorough understanding of potential errors is necessary so that robotic system designers can develop systems that remedy failure cases. In this work, we study failures that occur when participants interact with a working system and focus especially on errors in a robotic system’s knowledge base of which the system is not aware. A human interaction partner can be part of the error detection process if they are given insight into the robot’s knowledge and decision-making process. We investigate different communication modalities and the design of shared task representations in a joint human-robot object organization task. We conducted a user study (N = 31) in which the participants showed a Pepper robot how to organize objects, and the robot communicated the learned object configuration to the participants by means of speech, visualization, or a combination of speech and visualization. The multimodal, combined condition was preferred by 23 participants, followed by seven participants preferring the visualization. Based on the interviews, the errors that occurred, and the object configurations generated by the participants, we conclude that participants tend to test the system’s limitations by making the task more complex, which provokes errors. This trial-and-error behavior has a productive purpose and demonstrates that failures occur that arise from the combination of robot capabilities, the user’s understanding and actions, and interaction in the environment. Moreover, it demonstrates that failure can have a productive purpose in establishing better user mental models of the technology.},
  archive      = {J_FROBT},
  author       = {Frijns, Helena Anna and Hirschmanner, Matthias and Sienkiewicz, Barbara and Hönig, Peter and Indurkhya, Bipin and Vincze, Markus},
  doi          = {10.3389/frobt.2024.1356827},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1356827},
  shortjournal = {Front. Robot. AI},
  title        = {Human-in-the-loop error detection in an object organization task with a social robot},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning-based personalisation of robot behaviour for
robot-assisted therapy. <em>FROBT</em>, <em>11</em>, 1352152. (<a
href="https://doi.org/10.3389/frobt.2024.1352152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During robot-assisted therapy, a robot typically needs to be partially or fully controlled by therapists, for instance using a Wizard-of-Oz protocol; this makes therapeutic sessions tedious to conduct, as therapists cannot fully focus on the interaction with the person under therapy. In this work, we develop a learning-based behaviour model that can be used to increase the autonomy of a robot’s decision-making process. We investigate reinforcement learning as a model training technique and compare different reward functions that consider a user’s engagement and activity performance. We also analyse various strategies that aim to make the learning process more tractable, namely i) behaviour model training with a learned user model, ii) policy transfer between user groups, and iii) policy learning from expert feedback. We demonstrate that policy transfer can significantly speed up the policy learning process, although the reward function has an important effect on the actions that a robot can choose. Although the main focus of this paper is the personalisation pipeline itself, we further evaluate the learned behaviour models in a small-scale real-world feasibility study in which six users participated in a sequence learning game with an assistive robot. The results of this study seem to suggest that learning from guidance may result in the most adequate policies in terms of increasing the engagement and game performance of users, but a large-scale user study is needed to verify the validity of that observation.},
  archive      = {J_FROBT},
  author       = {Stolarz, Michał and Mitrevski, Alex and Wasil, Mohammad and Plöger, Paul G.},
  doi          = {10.3389/frobt.2024.1352152},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1352152},
  shortjournal = {Front. Robot. AI},
  title        = {Learning-based personalisation of robot behaviour for robot-assisted therapy},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of visual SLAM for robotics: Evolution, properties,
and future applications. <em>FROBT</em>, <em>11</em>, 1347985. (<a
href="https://doi.org/10.3389/frobt.2024.1347985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual simultaneous localization and mapping (V-SLAM) plays a crucial role in the field of robotic systems, especially for interactive and collaborative mobile robots. The growing reliance on robotics has increased complexity in task execution in real-world applications. Consequently, several types of V-SLAM methods have been revealed to facilitate and streamline the functions of robots. This work aims to showcase the latest V-SLAM methodologies, offering clear selection criteria for researchers and developers to choose the right approach for their robotic applications. It chronologically presents the evolution of SLAM methods, highlighting key principles and providing comparative analyses between them. The paper focuses on the integration of the robotic ecosystem with a robot operating system (ROS) as Middleware, explores essential V-SLAM benchmark datasets, and presents demonstrative figures for each method’s workflow.},
  archive      = {J_FROBT},
  author       = {Al-Tawil, Basheer and Hempel, Thorsten and Abdelrahman, Ahmed and Al-Hamadi, Ayoub},
  doi          = {10.3389/frobt.2024.1347985},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1347985},
  shortjournal = {Front. Robot. AI},
  title        = {A review of visual SLAM for robotics: Evolution, properties, and future applications},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring a GPT-based large language model for variable
autonomy in a VR-based human-robot teaming simulation. <em>FROBT</em>,
<em>11</em>, 1347538. (<a
href="https://doi.org/10.3389/frobt.2024.1347538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a rapidly evolving digital landscape autonomous tools and robots are becoming commonplace. Recognizing the significance of this development, this paper explores the integration of Large Language Models (LLMs) like Generative pre-trained transformer (GPT) into human-robot teaming environments to facilitate variable autonomy through the means of verbal human-robot communication. In this paper, we introduce a novel simulation framework for such a GPT-powered multi-robot testbed environment, based on a Unity Virtual Reality (VR) setting. This system allows users to interact with simulated robot agents through natural language, each powered by individual GPT cores. By means of OpenAI’s function calling, we bridge the gap between unstructured natural language input and structured robot actions. A user study with 12 participants explores the effectiveness of GPT-4 and, more importantly, user strategies when being given the opportunity to converse in natural language within a simulated multi-robot environment. Our findings suggest that users may have preconceived expectations on how to converse with robots and seldom try to explore the actual language and cognitive capabilities of their simulated robot collaborators. Still, those users who did explore were able to benefit from a much more natural flow of communication and human-like back-and-forth. We provide a set of lessons learned for future research and technical implementations of similar systems.},
  archive      = {J_FROBT},
  author       = {Lakhnati, Younes and Pascher, Max and Gerken, Jens},
  doi          = {10.3389/frobt.2024.1347538},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1347538},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring a GPT-based large language model for variable autonomy in a VR-based human-robot teaming simulation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Safe contact-based robot active search using bayesian
optimization and control barrier functions. <em>FROBT</em>, <em>11</em>,
1344367. (<a href="https://doi.org/10.3389/frobt.2024.1344367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotics, active exploration and learning in uncertain environments must take into account safety, as the robot may otherwise damage itself or its surroundings. This paper presents a method for safe active search using Bayesian optimization and control barrier functions. As robot paths undertaken during sampling are continuous, we consider an informative continuous expected improvement acquisition function. To safely bound the contact forces between the robot and its surroundings, we leverage exponential control barrier functions, utilizing the derivative of the force in the contact model to increase robustness to uncertainty in the contact boundary. Our approach is demonstrated on a fully autonomous robot for ultrasound scanning of rheumatoid arthritis (RA). Here, active search is a critical component of ensuring high image quality. Furthermore, bounded contact forces between the ultrasound probe and the patient ensure patient safety and better scan quality. To the best of our knowledge, our results are both the first demonstration of safe active search on a fully autonomous robot for ultrasound scanning of rheumatoid arthritis and the first experimental evaluation of bounding contact forces in the context of medical robotics using control barrier functions. The results show that when search time is limited to less than 60 s, informative continuous expected improvement leads to a 92% success, a 13% improvement compared to expected improvement. Meanwhile, exponential control barrier functions can limit the force applied by the robot to under 5 N, even in cases where the contact boundary is specified incorrectly by −1 or +4 mm.},
  archive      = {J_FROBT},
  author       = {Vinter-Hviid, Frederik and Sloth, Christoffer and Savarimuthu, Thiusius Rajeeth and Iturrate, Iñigo},
  doi          = {10.3389/frobt.2024.1344367},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1344367},
  shortjournal = {Front. Robot. AI},
  title        = {Safe contact-based robot active search using bayesian optimization and control barrier functions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Outline of an evolutionary morphology generator towards the
modular design of a biohybrid catheter. <em>FROBT</em>, <em>11</em>,
1337722. (<a href="https://doi.org/10.3389/frobt.2024.1337722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biohybrid machines (BHMs) are an amalgam of actuators composed of living cells with synthetic materials. They are engineered in order to improve autonomy, adaptability and energy efficiency beyond what conventional robots can offer. However, designing these machines is no trivial task for humans, provided the field’s short history and, thus, the limited experience and expertise on designing and controlling similar entities, such as soft robots. To unveil the advantages of BHMs, we propose to overcome the hindrances of their design process by developing a modular modeling and simulation framework for the digital design of BHMs that incorporates Artificial Intelligence powered algorithms. Here, we present the initial workings of the first module in an exemplar framework, namely, an evolutionary morphology generator. As proof-of-principle for this project, we use the scenario of developing a biohybrid catheter as a medical device capable of arriving to hard-to-reach regions of the human body to release drugs. We study the automatically generated morphology of actuators that will enable the functionality of that catheter. The primary results presented here enforced the update of the methodology used, in order to better depict the problem under study, while also provided insights for the future versions of the software module.},
  archive      = {J_FROBT},
  author       = {Tsompanas, Michail-Antisthenis and Balaz, Igor},
  doi          = {10.3389/frobt.2024.1337722},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1337722},
  shortjournal = {Front. Robot. AI},
  title        = {Outline of an evolutionary morphology generator towards the modular design of a biohybrid catheter},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assimilation of socially assistive robots by older adults:
An interplay of uses, constraints and outcomes. <em>FROBT</em>,
<em>11</em>, 1337380. (<a
href="https://doi.org/10.3389/frobt.2024.1337380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By supporting autonomy, aging in place, and wellbeing in later life, Socially Assistive Robots are expected to help humanity face the challenges posed by the rapid aging of the world’s population. For the successful acceptance and assimilation of SARs by older adults, it is necessary to understand the factors affecting their Quality Evaluations Previous studies examining Human-Robot Interaction in later life indicated that three aspects shape older adults’ overall QEs of robots: uses, constraints, and outcomes. However, studies were usually limited in duration, focused on acceptance rather than assimilation, and typically explored only one aspect of the interaction. In the present study, we examined uses, constraints, and outcomes simultaneously and over a long period. Nineteen community-dwelling older adults aged 75–97 were given a SAR for physical training for 6 weeks. Their experiences were documented via in-depth interviews conducted before and after the study period, short weekly telephone surveys, and reports produced by the robots. Analysis revealed two distinct groups: (A) The ‘Fans’ - participants who enjoyed using the SAR, attributed added value to it, and experienced a successful assimilation process; and (B) The ‘Skeptics’ - participants who did not like it, negatively evaluated its use, and experienced a disappointing assimilation process. Despite the vast differences between the groups, both reported more positive evaluations of SARs at the end of the study than before it began. Overall, the results indicated that the process of SARs’ assimilation is not homogeneous and provided a profound understanding of the factors shaping older adults’ QE of SARs following actual use. Additionally, the findings demonstrated the theoretical and practical usefulness of a holistic approach in researching older SARs users.},
  archive      = {J_FROBT},
  author       = {Zafrani, Oded and Nimrod, Galit and Krakovski, Maya and Kumar, Shikhar and Bar-Haim, Simona and Edan, Yael},
  doi          = {10.3389/frobt.2024.1337380},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1337380},
  shortjournal = {Front. Robot. AI},
  title        = {Assimilation of socially assistive robots by older adults: An interplay of uses, constraints and outcomes},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clustering user preferences for personalized teleoperation
control schemes via trajectory similarity analysis. <em>FROBT</em>,
<em>11</em>, 1330812. (<a
href="https://doi.org/10.3389/frobt.2024.1330812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Successful operation of a teleoperated robot depends on a well-designed control scheme to translate human motion into robot motion; however, a single control scheme may not be suitable for all users. On the other hand, individual personalization of control schemes may be infeasible for designers to produce. In this paper, we present a method by which users may be classified into groups with mutually compatible control scheme preferences. Users are asked to demonstrate freehand motions to control a simulated robot in a virtual reality environment. Hand pose data is captured and compared with other users using SLAM trajectory similarity analysis techniques. The resulting pairwise trajectory error metrics are used to cluster participants based on their control motions, without foreknowledge of the number or types of control scheme preferences that may exist. The clusters identified for two different robots shows that a small number of clusters form stably for each case, each with its own control scheme paradigm. Survey data from participants validates that the clusters identified through this method correspond to the participants’ control scheme rationales, and also identify nuances in participant control scheme descriptions that may not be obvious to designers relying only on participant explanations of their preferences.},
  archive      = {J_FROBT},
  author       = {Molnar, Jennifer and Agrawal, Varun and Chernova, Sonia},
  doi          = {10.3389/frobt.2024.1330812},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1330812},
  shortjournal = {Front. Robot. AI},
  title        = {Clustering user preferences for personalized teleoperation control schemes via trajectory similarity analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Managing social-educational robotics for students with
autism spectrum disorder through business model canvas and customer
discovery. <em>FROBT</em>, <em>11</em>, 1328467. (<a
href="https://doi.org/10.3389/frobt.2024.1328467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social-educational robotics, such as NAO humanoid robots with social, anthropomorphic, humanlike features, are tools for learning, education, and addressing developmental disorders (e.g., autism spectrum disorder or ASD) through social and collaborative robotic interactions and interventions. There are significant gaps at the intersection of social robotics and autism research dealing with how robotic technology helps ASD individuals with their social, emotional, and communication needs, and supports teachers who engage with ASD students. This research aims to (a) obtain new scientific knowledge on social-educational robotics by exploring the usage of social robots (especially humanoids) and robotic interventions with ASD students at high schools through an ASD student–teacher co-working with social robot–social robotic interactions triad framework; (b) utilize Business Model Canvas (BMC) methodology for robot design and curriculum development targeted at ASD students; and (c) connect interdisciplinary areas of consumer behavior research, social robotics, and human-robot interaction using customer discovery interviews for bridging the gap between academic research on social robotics on the one hand, and industry development and customers on the other. The customer discovery process in this research results in eight core research propositions delineating the contexts that enable a higher quality learning environment corresponding with ASD students’ learning requirements through the use of social robots and preparing them for future learning and workforce environments.},
  archive      = {J_FROBT},
  author       = {Arora, Anshu Saxena and Arora, Amit and Sivakumar, K. and McIntyre, John R.},
  doi          = {10.3389/frobt.2024.1328467},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1328467},
  shortjournal = {Front. Robot. AI},
  title        = {Managing social-educational robotics for students with autism spectrum disorder through business model canvas and customer discovery},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural dynamics of robust legged robots. <em>FROBT</em>,
<em>11</em>, 1324404. (<a
href="https://doi.org/10.3389/frobt.2024.1324404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legged robot control has improved in recent years with the rise of deep reinforcement learning, however, much of the underlying neural mechanisms remain difficult to interpret. Our aim is to leverage bio-inspired methods from computational neuroscience to better understand the neural activity of robust robot locomotion controllers. Similar to past work, we observe that terrain-based curriculum learning improves agent stability. We study the biomechanical responses and neural activity within our neural network controller by simultaneously pairing physical disturbances with targeted neural ablations. We identify an agile hip reflex that enables the robot to regain its balance and recover from lateral perturbations. Model gradients are employed to quantify the relative degree that various sensory feedback channels drive this reflexive behavior. We also find recurrent dynamics are implicated in robust behavior, and utilize sampling-based ablation methods to identify these key neurons. Our framework combines model-based and sampling-based methods for drawing causal relationships between neural network activity and robust embodied robot behavior.},
  archive      = {J_FROBT},
  author       = {Rush, Eugene R. and Heckman, Christoffer and Jayaram, Kaushik and Humbert, J. Sean},
  doi          = {10.3389/frobt.2024.1324404},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1324404},
  shortjournal = {Front. Robot. AI},
  title        = {Neural dynamics of robust legged robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tangible document sharing: Handing over paper documents
across a videoconferencing display. <em>FROBT</em>, <em>11</em>,
1303440. (<a href="https://doi.org/10.3389/frobt.2024.1303440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional techniques for sharing paper documents in teleconferencing tend to introduce two inconsistencies: 1) media inconsistency: a paper document is converted into a digital image on the remote site; 2) space inconsistency: a workspace deliberately inverts the partner’s handwriting to make a document easy to read. In this paper, we present a novel system that eliminates these inconsistencies. The media and space inconsistencies are resolved by reproducing a real paper document on a remote site and allowing a user to handover the paper document to a remote partner across a videoconferencing display. From a series of experiments, we found that reproducing a real paper document contributes to a higher sense of information sharing. We also found that handing over a document enhances a sense of space sharing, regardless of whether the document is digital or paper-based. These findings provide insights into designing systems for sharing paper documents across distances.},
  archive      = {J_FROBT},
  author       = {Tanaka, Kazuaki and Oshiro, Kentaro and Yamashita, Naomi and Nakanishi, Hideyuki},
  doi          = {10.3389/frobt.2024.1303440},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1303440},
  shortjournal = {Front. Robot. AI},
  title        = {Tangible document sharing: Handing over paper documents across a videoconferencing display},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating tactile feedback in addition to kinesthetic
feedback for haptic shape rendering: A pilot study. <em>FROBT</em>,
<em>11</em>, 1298537. (<a
href="https://doi.org/10.3389/frobt.2024.1298537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In current virtual reality settings for motor skill training, only visual information is usually provided regarding the virtual objects the trainee interacts with. However, information gathered through cutaneous (tactile feedback) and muscle mechanoreceptors (kinesthetic feedback) regarding, e.g., object shape, is crucial to successfully interact with those objects. To provide this essential information, previous haptic interfaces have targeted to render either tactile or kinesthetic feedback while the effectiveness of multimodal tactile and kinesthetic feedback on the perception of the characteristics of virtual objects still remains largely unexplored. Here, we present the results from an experiment we conducted with sixteen participants to evaluate the effectiveness of multimodal tactile and kinesthetic feedback on shape perception. Using a within-subject design, participants were asked to reproduce virtual shapes after exploring them without visual feedback and with either congruent tactile and kinesthetic feedback or with only kinesthetic feedback. Tactile feedback was provided with a cable-driven platform mounted on the fingertip, while kinesthetic feedback was provided using a haptic glove. To measure the participants’ ability to perceive and reproduce the rendered shapes, we measured the time participants spent exploring and reproducing the shapes and the error between the rendered and reproduced shapes after exploration. Furthermore, we assessed the participants’ workload and motivation using well-established questionnaires. We found that concurrent tactile and kinesthetic feedback during shape exploration resulted in lower reproduction errors and longer reproduction times. The longer reproduction times for the combined condition may indicate that participants could learn the shapes better and, thus, were more careful when reproducing them. We did not find differences between conditions in the time spent exploring the shapes or the participants’ workload and motivation. The lack of differences in workload between conditions could be attributed to the reported minimal-to-intermediate workload levels, suggesting that there was little room to further reduce the workload. Our work highlights the potential advantages of multimodal congruent tactile and kinesthetic feedback when interacting with tangible virtual objects with applications in virtual simulators for hands-on training applications.},
  archive      = {J_FROBT},
  author       = {Ratschat, Alexandre L. and van Rooij, Bob M. and Luijten, Johannes and Marchal-Crespo, Laura},
  doi          = {10.3389/frobt.2024.1298537},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1298537},
  shortjournal = {Front. Robot. AI},
  title        = {Evaluating tactile feedback in addition to kinesthetic feedback for haptic shape rendering: A pilot study},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Promising directions for human-robot interactions defined by
older adults. <em>FROBT</em>, <em>11</em>, 1289414. (<a
href="https://doi.org/10.3389/frobt.2024.1289414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Older adults are engaging more and more with voice-based agent and social robot technologies, and roboticists are increasingly designing interactions for these systems with older adults in mind. Older adults are often not included in these design processes, yet there are many opportunities for older adults to collaborate with design teams to design future robot interactions and help guide directions for robot development.Methods: Through a year-long co-design project, we collaborated with 28 older adults to understand the key focus areas that older adults see promise in for older adult-robot interaction in their everyday lives and how they would like these interactions to be designed. This paper describes and explores the robot-interaction guidelines and future directions identified by older adults, specifically investigating the change and trajectory of these guidelines through the course of the co-design process from the initial interview to the design guideline generation session to the final interview. Results were analyzed through an adapted ethnographic decision tree modeling approach to understand older adults’ decision making surrounding the various focus areas and guidelines for social robots.Results: Overall, over the course of the co-design process between the beginning and end, older adults developed a better understanding of the robot that translated to them being more certain of their attitudes of how they would like a robot to engage with them in their lives. Older adults were more accepting of transactional functions such as reminders and scheduling and less open to functions that would involve sharing sensitive information and tracking and/or monitoring of them, expressing concerns around surveillance. There was some promise in robot interactions for connecting with others, body signal monitoring, and emotional wellness, though older adults brought up concerns around autonomy, privacy, and naturalness of the interaction with a robot that need to be further explored.Discussion: This work provides guidance for future interaction development for robots that are being designed to interact with older adults and highlights areas that need to be further investigated with older adults to understand how best to design for user concerns.},
  archive      = {J_FROBT},
  author       = {Ostrowski, Anastasia K. and Zhang, Jenny and Breazeal, Cynthia and Park, Hae Won},
  doi          = {10.3389/frobt.2024.1289414},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1289414},
  shortjournal = {Front. Robot. AI},
  title        = {Promising directions for human-robot interactions defined by older adults},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft bioreactor systems: A necessary step toward engineered
MSK soft tissue? <em>FROBT</em>, <em>11</em>, 1287446. (<a
href="https://doi.org/10.3389/frobt.2024.1287446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key objective of tissue engineering (TE) is to produce in vitro funcional grafts that can replace damaged tissues or organs in patients. TE uses bioreactors, which are controlled environments, allowing the application of physical and biochemical cues to relevant cells growing in biomaterials. For soft musculoskeletal (MSK) tissues such as tendons, ligaments and cartilage, it is now well established that applied mechanical stresses can be incorporated into those bioreactor systems to support tissue growth and maturation via activation of mechanotransduction pathways. However, mechanical stresses applied in the laboratory are often oversimplified compared to those found physiologically and may be a factor in the slow progression of engineered MSK grafts towards the clinic. In recent years, an increasing number of studies have focused on the application of complex loading conditions, applying stresses of different types and direction on tissue constructs, in order to better mimic the cellular environment experienced in vivo. Such studies have highlighted the need to improve upon traditional rigid bioreactors, which are often limited to uniaxial loading, to apply physiologically relevant multiaxial stresses and elucidate their influence on tissue maturation. To address this need, soft bioreactors have emerged. They employ one or more soft components, such as flexible soft chambers that can twist and bend with actuation, soft compliant actuators that can bend with the construct, and soft sensors which record measurements in situ. This review examines types of traditional rigid bioreactors and their shortcomings, and highlights recent advances of soft bioreactors in MSK TE. Challenges and future applications of such systems are discussed, drawing attention to the exciting prospect of these platforms and their ability to aid development of functional soft tissue engineered grafts.},
  archive      = {J_FROBT},
  author       = {Dvorak, Nicole and Liu, Zekun and Mouthuy, Pierre-Alexis},
  doi          = {10.3389/frobt.2024.1287446},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1287446},
  shortjournal = {Front. Robot. AI},
  title        = {Soft bioreactor systems: A necessary step toward engineered MSK soft tissue?},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Swing-phase detection of locomotive mode transitions for
smooth multi-functional robotic lower-limb prosthesis control.
<em>FROBT</em>, <em>11</em>, 1267072. (<a
href="https://doi.org/10.3389/frobt.2024.1267072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic lower-limb prostheses, with their actively powered joints, may significantly improve amputee users’ mobility and enable them to obtain healthy-like gait in various modes of locomotion in daily life. However, timely recognition of the amputee users’ locomotive mode and mode transition still remains a major challenge in robotic lower-limb prosthesis control. In the paper, the authors present a new multi-dimensional dynamic time warping (mDTW)-based intent recognizer to provide high-accuracy recognition of the locomotion mode/mode transition sufficiently early in the swing phase, such that the prosthesis’ joint-level motion controller can operate in the correct locomotive mode and assist the user to complete the desired (and often power-demanding) motion in the stance phase. To support the intent recognizer development, the authors conducted a multi-modal gait data collection study to obtain the related sensor signal data in various modes of locomotion. The collected data were then segmented into individual cycles, generating the templates used in the mDTW classifier. Considering the large number of sensor signals available, we conducted feature selection to identify the most useful sensor signals as the input to the mDTW classifier. We also augmented the standard mDTW algorithm with a voting mechanism to make full use of the data generated from the multiple subjects. To validate the proposed intent recognizer, we characterized its performance using the data cumulated at different percentages of progression into the gait cycle (starting from the beginning of the swing phase). It was shown that the mDTW classifier was able to recognize three locomotive mode/mode transitions (walking, walking to stair climbing, and walking to stair descending) with 99.08% accuracy at 30% progression into the gait cycle, well before the stance phase starts. With its high performance, low computational load, and easy personalization (through individual template generation), the proposed mDTW intent recognizer may become a highly useful building block of a prosthesis control system to facilitate the robotic prostheses’ real-world use among lower-limb amputees.},
  archive      = {J_FROBT},
  author       = {Haque, Md Rejwanul and Islam, Md Rafi and Sazonov, Edward and Shen, Xiangrong},
  doi          = {10.3389/frobt.2024.1267072},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1267072},
  shortjournal = {Front. Robot. AI},
  title        = {Swing-phase detection of locomotive mode transitions for smooth multi-functional robotic lower-limb prosthesis control},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Would you be impressed: Applying principles of magic to
chatbot conversations. <em>FROBT</em>, <em>11</em>, 1256937. (<a
href="https://doi.org/10.3389/frobt.2024.1256937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A magician’s trick and a chatbot conversation have something in common: most of their audiences do not know how they work. Both are also constrained by their own limitations: magicians by the constraints of biology and physics, and dialogue systems by the status of current technology. Magicians and chatbot creators also share a goal: they want to engage their audience. But magicians, unlike the designers of dialogue systems, have centuries of practice in gracefully skirting limitations in order to engage their audience and enhance a sense of awe. In this paper, we look at these practices and identify several key principles of magic and psychology to apply to conversations between chatbots and humans. We formulate a model of communication centered on controlling the user’s attention, expectations, decisions, and memory based on examples from the history of magic. We apply these magic principles to real-world conversations between humans and a social robot and evaluate their effectiveness in a Magical conversation setting compared to a Control conversation that does not incorporate magic principles. We find that human evaluators preferred interactions that incorporated magical principles over interactions that did not. In particular, magical interactions increased 1) the personalization of experience, 2) user engagement, and 3) character likability. Firstly, the magical experience was “personalized.” According to survey results, the magical conversation demonstrated a statistically significant increase in “emotional connection” and “robot familiarity.” Therefore, the personalization of the experience leads to higher levels of perceived impressiveness and emotional connection. Secondly, in the Magical conversation, we find that the human interlocutor is perceived to have statistically-significantly higher engagement levels in four of seven characteristics. Thirdly, participants judged the robot in the magical conversation to have a significantly greater degree of “energeticness,”“humorousness,” and “interestingness.” Finally, evaluation of the conversations with questions intended to measure contribution of the magical principals showed statistically-significant differences for five out of nine principles, indicating a positive contribution of the magical principles to the perceived conversation experience. Overall, our evaluation demonstrates that the psychological principles underlying a magician’s showmanship can be applied to the design of conversational systems to achieve more personalized, engaging, and fun interactions.},
  archive      = {J_FROBT},
  author       = {Siskind, Sarah Rose and Nichols, Eric and Gomez, Randy},
  doi          = {10.3389/frobt.2024.1256937},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1256937},
  shortjournal = {Front. Robot. AI},
  title        = {Would you be impressed: Applying principles of magic to chatbot conversations},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decentralized multi-agent reinforcement learning based on
best-response policies. <em>FROBT</em>, <em>11</em>, 1229026. (<a
href="https://doi.org/10.3389/frobt.2024.1229026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Multi-agent systems are an interdisciplinary research field that describes the concept of multiple decisive individuals interacting with a usually partially observable environment. Given the recent advances in single-agent reinforcement learning, multi-agent reinforcement learning (RL) has gained tremendous interest in recent years. Most research studies apply a fully centralized learning scheme to ease the transfer from the single-agent domain to multi-agent systems.Methods: In contrast, we claim that a decentralized learning scheme is preferable for applications in real-world scenarios as this allows deploying a learning algorithm on an individual robot rather than deploying the algorithm to a complete fleet of robots. Therefore, this article outlines a novel actor–critic (AC) approach tailored to cooperative MARL problems in sparsely rewarded domains. Our approach decouples the MARL problem into a set of distributed agents that model the other agents as responsive entities. In particular, we propose using two separate critics per agent to distinguish between the joint task reward and agent-based costs as commonly applied within multi-robot planning. On one hand, the agent-based critic intends to decrease agent-specific costs. On the other hand, each agent intends to optimize the joint team reward based on the joint task critic. As this critic still depends on the joint action of all agents, we outline two suitable behavior models based on Stackelberg games: a game against nature and a dyadic game against each agent. Following these behavior models, our algorithm allows fully decentralized execution and training.Results and Discussion: We evaluate our presented method using the proposed behavior models within a sparsely rewarded simulated multi-agent environment. Although our approach already outperforms the state-of-the-art learners, we conclude this article by outlining possible extensions of our algorithm that future research may build upon.},
  archive      = {J_FROBT},
  author       = {Gabler, Volker and Wollherr, Dirk},
  doi          = {10.3389/frobt.2024.1229026},
  journal      = {Frontiers in Robotics and AI},
  month        = {4},
  pages        = {1229026},
  shortjournal = {Front. Robot. AI},
  title        = {Decentralized multi-agent reinforcement learning based on best-response policies},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Artificial intelligence solutions for decision
making in robotics. <em>FROBT</em>, <em>11</em>, 1389191. (<a
href="https://doi.org/10.3389/frobt.2024.1389191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Abu Al-Haija, Qasem},
  doi          = {10.3389/frobt.2024.1389191},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1389191},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Artificial intelligence solutions for decision making in robotics},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time active constraint generation and enforcement for
surgical tools using 3D detection and localisation network.
<em>FROBT</em>, <em>11</em>, 1365632. (<a
href="https://doi.org/10.3389/frobt.2024.1365632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Collaborative robots, designed to work alongside humans for manipulating end-effectors, greatly benefit from the implementation of active constraints. This process comprises the definition of a boundary, followed by the enforcement of some control algorithm when the robot tooltip interacts with the generated boundary. Contact with the constraint boundary is communicated to the human operator through various potential forms of feedback. In fields like surgical robotics, where patient safety is paramount, implementing active constraints can prevent the robot from interacting with portions of the patient anatomy that shouldn’t be operated on. Despite improvements in orthopaedic surgical robots, however, there exists a gap between bulky systems with haptic feedback capabilities and miniaturised systems that only allow for boundary control, where interaction with the active constraint boundary interrupts robot functions. Generally, active constraint generation relies on optical tracking systems and preoperative imaging techniques.Methods: This paper presents a refined version of the Signature Robot, a three degrees-of-freedom, hands-on collaborative system for orthopaedic surgery. Additionally, it presents a method for generating and enforcing active constraints “on-the-fly” using our previously introduced monocular, RGB, camera-based network, SimPS-Net. The network was deployed in real-time for the purpose of boundary definition. This boundary was subsequently used for constraint enforcement testing. The robot was utilised to test two different active constraints: a safe region and a restricted region.Results: The network success rate, defined as the ratio of correct over total object localisation results, was calculated to be 54.7% ± 5.2%. In the safe region case, haptic feedback resisted tooltip manipulation beyond the active constraint boundary, with a mean distance from the boundary of 2.70 mm ± 0.37 mm and a mean exit duration of 0.76 s ± 0.11 s. For the restricted-zone constraint, the operator was successfully prevented from penetrating the boundary in 100% of attempts.Discussion: This paper showcases the viability of the proposed robotic platform and presents promising results of a versatile constraint generation and enforcement pipeline.},
  archive      = {J_FROBT},
  author       = {Souipas, Spyridon and Nguyen, Anh and Laws, Stephen G. and Davies, Brian L. and Rodriguez y Baena, Ferdinando},
  doi          = {10.3389/frobt.2024.1365632},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1365632},
  shortjournal = {Front. Robot. AI},
  title        = {Real-time active constraint generation and enforcement for surgical tools using 3D detection and localisation network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative robots (cobots) for disaster risk resilience:
A framework for swarm of snake robots in delivering first aid in
emergency situations. <em>FROBT</em>, <em>11</em>, 1362294. (<a
href="https://doi.org/10.3389/frobt.2024.1362294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cobots are robots that are built for human-robot collaboration (HRC) in a shared environment. In the aftermath of disasters, cobots can cooperate with humans to mitigate risks and increase the possibility of rescuing people in distress. This study examines the resilient and dynamic synergy between a swarm of snake robots, first responders and people to be rescued. The possibility of delivering first aid to potential victims dispersed around a disaster environment is implemented. In the HRC simulation framework presented in this study, the first responder initially deploys a UAV, swarm of snake robots and emergency items. The UAV provides the first responder with the site planimetry, which includes the layout of the area, as well as the precise locations of the individuals in need of rescue and the aiding goods to be delivered. Each individual snake robot in the swarm is then assigned a victim. Subsequently an optimal path is determined by each snake robot using the A* algorithm, to approach and reach its respective target while avoiding obstacles. By using their prehensile capabilities, each snake robot adeptly grasps the aiding object to be dispatched. The snake robots successively arrive at the delivering location near the victim, following their optimal paths, and proceed to release the items. To demonstrate the potential of the framework, several case studies are outlined concerning the execution of operations that combine locomotion, obstacle avoidance, grasping and deploying. The Coppelia-Sim Robotic Simulator is utilised for this framework. The analysis of the motion of the snake robots on the path show highly accurate movement with and without the emergency item. This study is a step towards a holistic semi-autonomous search and rescue operation.},
  archive      = {J_FROBT},
  author       = {Moosavi, Syed Kumayl Raza and Zafar, Muhammad Hamza and Sanfilippo, Filippo},
  doi          = {10.3389/frobt.2024.1362294},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1362294},
  shortjournal = {Front. Robot. AI},
  title        = {Collaborative robots (cobots) for disaster risk resilience: A framework for swarm of snake robots in delivering first aid in emergency situations},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Sequential model based on human cognitive processing to
robot acceptance. <em>FROBT</em>, <em>11</em>, 1362044. (<a
href="https://doi.org/10.3389/frobt.2024.1362044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots have tremendous potential, and have recently been introduced not only for simple operations in factories, but also in workplaces where customer service communication is required. However, communication robots have not always been accepted. This study proposes a three-stage (first contact, interaction, and decision) model for robot acceptance based on the human cognitive process flow to design preferred robots and clarifies the elements of the robot and the processes that affect robot acceptance decision-making. Unlike previous robot acceptance models, the current model focuses on a sequential account of how people decide to accept, considering the interaction (or carry-over) effect between impressions established at each stage. According to the model, this study conducted a scenario-based experiment focusing on the impression of the first contact (a robot’s appearance) and that formed during the interaction with robot (politeness of its conversation and behavior) on robot acceptance in both successful and slightly failed situations. The better the appearance of the robot and the more polite its behavior, the greater the acceptance rate. Importantly, there was no interaction between these two factors. The results indicating that the impressions of the first contact and interaction are additively processed suggest that we should accumulate findings that improving the appearance of the robot and making its communication behavior more human-like in politeness will lead to a more acceptable robot design.},
  archive      = {J_FROBT},
  author       = {Saeki, Waka and Ueda, Yoshiyuki},
  doi          = {10.3389/frobt.2024.1362044},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1362044},
  shortjournal = {Front. Robot. AI},
  title        = {Sequential model based on human cognitive processing to robot acceptance},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Enhanced human modeling in robotics for
socially-aware place navigation. <em>FROBT</em>, <em>11</em>, 1348022.
(<a href="https://doi.org/10.3389/frobt.2024.1348022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Tsintotas, Konstantinos A. and Kansizoglou, Ioannis and Pastra, Katerina and Aloimonos, Yiannis and Gasteratos, Antonios and Sirakoulis, Giorgios Ch. and Sandini, Giulio},
  doi          = {10.3389/frobt.2024.1348022},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1348022},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Enhanced human modeling in robotics for socially-aware place navigation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on autonomous environmental monitoring approaches:
Towards unifying active sensing and reinforcement learning.
<em>FROBT</em>, <em>11</em>, 1336612. (<a
href="https://doi.org/10.3389/frobt.2024.1336612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The environmental pollution caused by various sources has escalated the climate crisis making the need to establish reliable, intelligent, and persistent environmental monitoring solutions more crucial than ever. Mobile sensing systems are a popular platform due to their cost-effectiveness and adaptability. However, in practice, operation environments demand highly intelligent and robust systems that can cope with an environment’s changing dynamics. To achieve this reinforcement learning has become a popular tool as it facilitates the training of intelligent and robust sensing agents that can handle unknown and extreme conditions. In this paper, a framework that formulates active sensing as a reinforcement learning problem is proposed. This framework allows unification with multiple essential environmental monitoring tasks and algorithms such as coverage, patrolling, source seeking, exploration and search and rescue. The unified framework represents a step towards bridging the divide between theoretical advancements in reinforcement learning and real-world applications in environmental monitoring. A critical review of the literature in this field is carried out and it is found that despite the potential of reinforcement learning for environmental active sensing applications there is still a lack of practical implementation and most work remains in the simulation phase. It is also noted that despite the consensus that, multi-agent systems are crucial to fully realize the potential of active sensing there is a lack of research in this area.},
  archive      = {J_FROBT},
  author       = {Mansfield, David and Montazeri, Allahyar},
  doi          = {10.3389/frobt.2024.1336612},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1336612},
  shortjournal = {Front. Robot. AI},
  title        = {A survey on autonomous environmental monitoring approaches: Towards unifying active sensing and reinforcement learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing walking efficiency of adolescents with
neurological impairments using an exosuit for ambulatory activities of
daily living. <em>FROBT</em>, <em>11</em>, 1335733. (<a
href="https://doi.org/10.3389/frobt.2024.1335733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Children and adolescents with neurological impairments face reduced participation and independence in daily life activities due to walking difficulties. Existing assistive devices often offer insufficient support, potentially leading to wheelchair dependence and limiting physical activity and daily life engagement. Mobile wearable robots, such as exoskeletons and exosuits, have shown promise in supporting adults during activities of daily living but are underexplored for children.Methods: We conducted a cross-sectional study to examine the potential of a cable-driven exosuit, the Myosuit, to enhance walking efficiency in adolescents with diverse ambulatory impairments. Each participant walked a course including up-hill, down-hill, level ground walking, and stairs ascending and descending, with and without the exosuit’s assistance. We monitored the time and step count to complete the course and the average heart rate and muscle activity. Additionally, we assessed the adolescents’ perspective on the exosuit’s utility using a visual analog scale.Results: Six adolescents completed the study. Although not statistically significant, five participants completed the course with the exosuit’s assistance in reduced time (time reduction range: [-3.87, 17.42]%, p-value: 0.08, effect size: 0.88). The number of steps taken decreased significantly with the Myosuit’s assistance (steps reduction range: [1.07, 15.71]%, p-value: 0.04, effect size: 0.90). Heart rate and muscle activity did not differ between Myosuit-assisted and unassisted conditions (p-value: 0.96 and 0.35, effect size: 0.02 and 0.42, respectively). Participants generally perceived reduced effort and increased safety with the Myosuit’s assistance, especially during tasks involving concentric contractions (e.g., walking uphill). Three participants expressed a willingness to use the Myosuit in daily life, while the others found it heavy or too conspicuous.Discussion: Increased walking speed without increasing physical effort when performing activities of daily living could lead to higher levels of participation and increased functional independence. Despite perceiving the benefits introduced by the exosuit’s assistance, adolescents reported the need for further modification of the device design before using it extensively at home and in the community.},
  archive      = {J_FROBT},
  author       = {Basla, Chiara and Mariani, Giulia and Wolf, Peter and Riener, Robert and van Hedel, Hubertus J. A.},
  doi          = {10.3389/frobt.2024.1335733},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1335733},
  shortjournal = {Front. Robot. AI},
  title        = {Enhancing walking efficiency of adolescents with neurological impairments using an exosuit for ambulatory activities of daily living},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Our business, not the robot’s: Family conversations about
privacy with social robots in the home. <em>FROBT</em>, <em>11</em>,
1331347. (<a href="https://doi.org/10.3389/frobt.2024.1331347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The targeted use of social robots for the family demands a better understanding of multiple stakeholders’ privacy concerns, including those of parents and children. Through a co-learning workshop which introduced families to the functions and hypothetical use of social robots in the home, we present preliminary evidence from 6 families that exhibits how parents and children have different comfort levels with robots collecting and sharing information across different use contexts. Conversations and booklet answers reveal that parents adopted their child’s decision in scenarios where they expect children to have more agency, such as in cases of homework completion or cleaning up toys, and when children proposed what their parents found to be acceptable reasoning for their decisions. Families expressed relief when they shared the same reasoning when coming to conclusive decisions, signifying an agreement of boundary management between the robot and the family. In cases where parents and children did not agree, they rejected a binary, either-or decision and opted for a third type of response, reflecting skepticism, uncertainty and/or compromise. Our work highlights the benefits of involving parents and children in child- and family-centered research, including parental abilities to provide cognitive scaffolding and personalize hypothetical scenarios for their children.},
  archive      = {J_FROBT},
  author       = {Levinson, Leigh and McKinney, Jessica and Nippert-Eng, Christena and Gomez, Randy and Šabanović, Selma},
  doi          = {10.3389/frobt.2024.1331347},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1331347},
  shortjournal = {Front. Robot. AI},
  title        = {Our business, not the robot’s: Family conversations about privacy with social robots in the home},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards an AI-driven soft toy for automatically detecting
and classifying infant-toy interactions using optical force sensors.
<em>FROBT</em>, <em>11</em>, 1325296. (<a
href="https://doi.org/10.3389/frobt.2024.1325296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: It is crucial to identify neurodevelopmental disorders in infants early on for timely intervention to improve their long-term outcomes. Combining natural play with quantitative measurements of developmental milestones can be an effective way to swiftly and efficiently detect infants who are at risk of neurodevelopmental delays. Clinical studies have established differences in toy interaction behaviors between full-term infants and pre-term infants who are at risk for cerebral palsy and other developmental disorders.Methods: The proposed toy aims to improve the quantitative assessment of infant-toy interactions and fully automate the process of detecting those infants at risk of developing motor delays. This paper describes the design and development of a toy that uniquely utilizes a collection of soft lossy force sensors which are developed using optical fibers to gather play interaction data from infants laying supine in a gym. An example interaction database was created by having 15 adults complete a total of 2480 interactions with the toy consisting of 620 touches, 620 punches—“kick substitute,” 620 weak grasps and 620 strong grasps.Results: The data is analyzed for patterns of interaction with the toy face using a machine learning model developed to classify the four interactions present in the database. Results indicate that the configuration of 6 soft force sensors on the face created unique activation patterns.Discussion: The machine learning algorithm was able to identify the distinct action types from the data, suggesting the potential usability of the toy. Next steps involve sensorizing the entire toy and testing with infants.},
  archive      = {J_FROBT},
  author       = {Udayagiri, Rithwik and Yin, Jessica and Cai, Xinyao and Townsend, William and Trivedi, Varun and Shende, Rohan and Sowande, O. Francis and Prosser, Laura A. and Pikul, James H. and Johnson, Michelle J.},
  doi          = {10.3389/frobt.2024.1325296},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1325296},
  shortjournal = {Front. Robot. AI},
  title        = {Towards an AI-driven soft toy for automatically detecting and classifying infant-toy interactions using optical force sensors},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving engineering students’ understanding of classical
physics through visuo-haptic simulations. <em>FROBT</em>, <em>11</em>,
1305615. (<a href="https://doi.org/10.3389/frobt.2024.1305615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: The teaching process plays a crucial role in the training of professionals. Traditional classroom-based teaching methods, while foundational, often struggle to effectively motivate students. The integration of interactive learning experiences, such as visuo-haptic simulators, presents an opportunity to enhance both student engagement and comprehension.Methods: In this study, three simulators were developed to explore the impact of visuo-haptic simulations on engineering students’ engagement and their perceptions of learning basic physics concepts. The study used an adapted end-user computing satisfaction questionnaire to assess students’ experiences and perceptions of the simulators’ usability and its utility in learning.Results: Feedback from participants suggests a positive reception towards the use of visuo-haptic simulators, highlighting their usefulness in improving the understanding of complex physics principles.Discussion: Results suggest that incorporating visuo-haptic simulations into educational contexts may offer significant benefits, particularly in STEM courses, where traditional methods may be limited. The positive responses from participants underscore the potential of computer simulations to innovate pedagogical strategies. Future research will focus on assessing the effectiveness of these simulators in enhancing students’ learning and understanding of these concepts in higher-education physics courses.},
  archive      = {J_FROBT},
  author       = {González-Mena, Guillermo and Lozada-Flores, Octavio and Murrieta Caballero, Dione and Noguez, Julieta and Escobar-Castillejos, David},
  doi          = {10.3389/frobt.2024.1305615},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1305615},
  shortjournal = {Front. Robot. AI},
  title        = {Improving engineering students’ understanding of classical physics through visuo-haptic simulations},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated disassembly of e-waste—requirements on modeling of
processes and product states. <em>FROBT</em>, <em>11</em>, 1303279. (<a
href="https://doi.org/10.3389/frobt.2024.1303279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated disassembly is increasingly in focus for Recycling, Re-use, and Remanufacturing (Re-X) activities. Trends in digitalization, in particular digital twin (DT) technologies and the digital product passport, as well as recently proposed European legislation such as the Net Zero and the Critical materials Acts will accelerate digitalization of product documentation and factory processes. In this contribution we look beyond these activities by discussing digital information for stakeholders at the Re-X segment of the value-chain. Furthermore, we present an approach to automated product disassembly based on different levels of available product information. The challenges for automated disassembly and the subsequent requirements on modeling of disassembly processes and product states for electronic waste are examined. The authors use a top-down (e.g., review of existing standards and process definitions) methodology to define an initial data model for disassembly processes. An additional bottom-up approach, whereby 5 exemplary electronics products were manually disassembled, was employed to analyze the efficacy of the initial data model and to offer improvements. This paper reports on our suggested informal data models for automatic electronics disassembly and the associated robotic skills.},
  archive      = {J_FROBT},
  author       = {Saenz, José and Felsch, Torsten and Walter, Christoph and König, Tim and Poenicke, Olaf and Bayrhammer, Eric and Vorbröcker, Mathias and Berndt, Dirk and Elkmann, Norbert and Arlinghaus, Julia},
  doi          = {10.3389/frobt.2024.1303279},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1303279},
  shortjournal = {Front. Robot. AI},
  title        = {Automated disassembly of e-waste—requirements on modeling of processes and product states},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Freedom comes at a cost?: An exploratory study on
affordances’ impact on users’ perception of a social robot.
<em>FROBT</em>, <em>11</em>, 1288818. (<a
href="https://doi.org/10.3389/frobt.2024.1288818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the development of speech and language technologies, the market for speech-enabled human-robot interactions (HRI) has grown in recent years. However, it is found that people feel their conversational interactions with such robots are far from satisfactory. One of the reasons is the habitability gap, where the usability of a speech-enabled agent drops when its flexibility increases. For social robots, such flexibility is reflected in the diverse choice of robots’ appearances, sounds and behaviours, which shape a robot’s ‘affordance’. Whilst designers or users have enjoyed the freedom of constructing a social robot by integrating off-the-shelf technologies, such freedom comes at a potential cost: the users’ perceptions and satisfaction. Designing appropriate affordances is essential for the quality of HRI. It is hypothesised that a social robot with aligned affordances could create an appropriate perception of the robot and increase users’ satisfaction when speaking with it. Given that previous studies of affordance alignment mainly focus on one interface’s characteristics and face-voice match, we aim to deepen our understanding of affordance alignment with a robot’s behaviours and use cases. In particular, we investigate how a robot’s affordances affect users’ perceptions in different types of use cases. For this purpose, we conducted an exploratory experiment that included three different affordance settings (adult-like, child-like, and robot-like) and three use cases (informative, emotional, and hybrid). Participants were invited to talk to social robots in person. A mixed-methods approach was employed for quantitative and qualitative analysis of 156 interaction samples. The results show that static affordance (face and voice) has a statistically significant effect on the perceived warmth of the first impression; use cases affect people’s perceptions more on perceived competence and warmth before and after interactions. In addition, it shows the importance of aligning static affordance with behavioural affordance. General design principles of behavioural affordances are proposed. We anticipate that our empirical evidence will provide a clearer guideline for speech-enabled social robots’ affordance design. It will be a starting point for more sophisticated design guidelines. For example, personalised affordance design for individual or group users in different contexts.},
  archive      = {J_FROBT},
  author       = {Huang, Guanyu and Moore, Roger K.},
  doi          = {10.3389/frobt.2024.1288818},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1288818},
  shortjournal = {Front. Robot. AI},
  title        = {Freedom comes at a cost?: An exploratory study on affordances’ impact on users’ perception of a social robot},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Embodied, visible, and courteous: Exploring robotic social
touch with virtual idols. <em>FROBT</em>, <em>11</em>, 1240408. (<a
href="https://doi.org/10.3389/frobt.2024.1240408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, virtual idols have garnered considerable attention because they can perform activities similar to real idols. However, as they are fictitious idols with nonphysical presence, they cannot perform physical interactions such as handshake. Combining a robotic hand with a display showing virtual idols is the one of the methods to solve this problem. Nonetheless a physical handshake is possible, the form of handshake that can effectively induce the desirable behavior is unclear. In this study, we adopted a robotic hand as an interface and aimed to imitate the behavior of real idols. To test the effects of this behavior, we conducted step-wise experiments. The series of experiments revealed that the handshake by the robotic hand increased the feeling of intimacy toward the virtual idol, and it became more enjoyable to respond to a request from the virtual idol. In addition, viewing the virtual idols during the handshake increased the feeling of intimacy with the virtual idol. Moreover, the method of the hand-shake peculiar to idols, which tried to keep holding the user’s hand after the conversation, increased the feeling of intimacy to the virtual idol.},
  archive      = {J_FROBT},
  author       = {Onishi, Yuya and Ogawa, Kosuke and Tanaka, Kazuaki and Nakanishi, Hideyuki},
  doi          = {10.3389/frobt.2024.1240408},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1240408},
  shortjournal = {Front. Robot. AI},
  title        = {Embodied, visible, and courteous: Exploring robotic social touch with virtual idols},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enabling robustness to failure with modular field robots.
<em>FROBT</em>, <em>11</em>, 1225297. (<a
href="https://doi.org/10.3389/frobt.2024.1225297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Actuator failure on a remotely deployed robot results in decreased efficiency or even renders it inoperable. Robustness to these failures will become critical as robots are required to be more independent and operate out of the range of repair. To address these challenges, we present two approaches based on modular robotic architecture to improve robustness to actuator failure of both fixed-configuration robots and modular reconfigurable robots. Our work uses modular reconfigurable robots capable of modifying their style of locomotion and changing their designed morphology through ejecting modules. This framework improved the distance travelled and decreased the effort to move through the environment of simulated and physical robots. When the deployed robot was allowed to change its locomotion style, it showed improved robustness to actuator failure when compared to a robot with a fixed controller. Furthermore, a robot capable of changing its locomotion and design morphology statistically outlasted both tests with a fixed morphology. Testing was carried out using a gazebo simulation and validated in multiple tests in the field. We show for the first time that ejecting modular failed components can improve the overall mission length.},
  archive      = {J_FROBT},
  author       = {Cordie, Troy and Roberts, Jonathan and Dunbabin, Matthew and Dungavell, Ross and Bandyopadhyay, Tirthankar},
  doi          = {10.3389/frobt.2024.1225297},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1225297},
  shortjournal = {Front. Robot. AI},
  title        = {Enabling robustness to failure with modular field robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). General value functions for fault detection in multivariate
time series data. <em>FROBT</em>, <em>11</em>, 1214043. (<a
href="https://doi.org/10.3389/frobt.2024.1214043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the greatest challenges to the automated production of goods is equipment malfunction. Ideally, machines should be able to automatically predict and detect operational faults in order to minimize downtime and plan for timely maintenance. While traditional condition-based maintenance (CBM) involves costly sensor additions and engineering, machine learning approaches offer the potential to learn from already existing sensors. Implementations of data-driven CBM typically use supervised and semi-supervised learning to classify faults. In addition to a large collection of operation data, records of faulty operation are also necessary, which are often costly to obtain. Instead of classifying faults, we use an approach to detect abnormal behaviour within the machine’s operation. This approach is analogous to semi-supervised anomaly detection in machine learning (ML), with important distinctions in experimental design and evaluation specific to the problem of industrial fault detection. We present a novel method of machine fault detection using temporal-difference learning and General Value Functions (GVFs). Using GVFs, we form a predictive model of sensor data to detect faulty behaviour. As sensor data from machines is not i.i.d. but closer to Markovian sampling, temporal-difference learning methods should be well suited for this data. We compare our GVF outlier detection (GVFOD) algorithm to a broad selection of multivariate and temporal outlier detection methods, using datasets collected from a tabletop robot emulating the movement of an industrial actuator. We find that not only does GVFOD achieve the same recall score as other multivariate OD algorithms, it attains significantly higher precision. Furthermore, GVFOD has intuitive hyperparameters which can be selected based upon expert knowledge of the application. Together, these findings allow for a more reliable detection of abnormal machine behaviour to allow ideal timing of maintenance; saving resources, time and cost.},
  archive      = {J_FROBT},
  author       = {Wong, Andy and Taghian Jazi, Mehran and Takeuchi, Tomoharu and Günther, Johannes and Zaïane, Osmar},
  doi          = {10.3389/frobt.2024.1214043},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1214043},
  shortjournal = {Front. Robot. AI},
  title        = {General value functions for fault detection in multivariate time series data},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on 3D object detection in real time for autonomous
driving. <em>FROBT</em>, <em>11</em>, 1212070. (<a
href="https://doi.org/10.3389/frobt.2024.1212070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey reviews advances in 3D object detection approaches for autonomous driving. A brief introduction to 2D object detection is first discussed and drawbacks of the existing methodologies are identified for highly dynamic environments. Subsequently, this paper reviews the state-of-the-art 3D object detection techniques that utilizes monocular and stereo vision for reliable detection in urban settings. Based on depth inference basis, learning schemes, and internal representation, this work presents a method taxonomy of three classes: model-based and geometrically constrained approaches, end-to-end learning methodologies, and hybrid methods. There is highlighted segment for current trend of multi-view detectors as end-to-end methods due to their boosted robustness. Detectors from the last two kinds were specially selected to exploit the autonomous driving context in terms of geometry, scene content and instances distribution. To prove the effectiveness of each method, 3D object detection datasets for autonomous vehicles are described with their unique features, e. g., varying weather conditions, multi-modality, multi camera perspective and their respective metrics associated to different difficulty categories. In addition, we included multi-modal visual datasets, i. e., V2X that may tackle the problems of single-view occlusion. Finally, the current research trends in object detection are summarized, followed by a discussion on possible scope for future research in this domain.},
  archive      = {J_FROBT},
  author       = {Contreras, Marcelo and Jain, Aayush and Bhatt, Neel P. and Banerjee, Arunava and Hashemi, Ehsan},
  doi          = {10.3389/frobt.2024.1212070},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1212070},
  shortjournal = {Front. Robot. AI},
  title        = {A survey on 3D object detection in real time for autonomous driving},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cooperative planning for physically interacting
heterogeneous robots. <em>FROBT</em>, <em>11</em>, 1172105. (<a
href="https://doi.org/10.3389/frobt.2024.1172105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous multi-agent systems can be deployed to complete a variety of tasks, including some that are impossible using a single generic modality. This paper introduces an approach to solving the problem of cooperative behavior planning in small heterogeneous robot teams where members can both function independently as well as physically interact with each other in ways that give rise to additional functionality. This approach enables, for the first time, the cooperative completion of tasks that are infeasible when using any single modality from those agents comprising the team.},
  archive      = {J_FROBT},
  author       = {Sebok, Michael A. and Tanner, Herbert G.},
  doi          = {10.3389/frobt.2024.1172105},
  journal      = {Frontiers in Robotics and AI},
  month        = {3},
  pages        = {1172105},
  shortjournal = {Front. Robot. AI},
  title        = {Cooperative planning for physically interacting heterogeneous robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Rising stars in field robotics: 2022.
<em>FROBT</em>, <em>11</em>, 1379661. (<a
href="https://doi.org/10.3389/frobt.2024.1379661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Kanoulas, Dimitrios and Khattak, Shehryar and Loianno, Giuseppe},
  doi          = {10.3389/frobt.2024.1379661},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1379661},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: rising stars in field robotics: 2022},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: The future of bio-inspired robotics: An early
career scientists’ perspective. <em>FROBT</em>, <em>11</em>, 1370948.
(<a href="https://doi.org/10.3389/frobt.2024.1370948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Calisti, Marcello and Wen, Li},
  doi          = {10.3389/frobt.2024.1370948},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1370948},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: the future of bio-inspired robotics: an early career scientists’ perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Implementation and analysis of a parallel kalman filter
algorithm for lidar localization based on CUDA technology.
<em>FROBT</em>, <em>11</em>, 1341689. (<a
href="https://doi.org/10.3389/frobt.2024.1341689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Navigation satellite systems can fail to work or work incorrectly in a number of conditions: signal shadowing, electromagnetic interference, atmospheric conditions, and technical problems. All of these factors can significantly affect the localization accuracy of autonomous driving systems. This emphasizes the need for other localization technologies, such as Lidar.Methods: The use of the Kalman filter in combination with Lidar can be very effective in various applications due to the synergy of their capabilities. The Kalman filter can improve the accuracy of lidar measurements by taking into account the noise and inaccuracies present in the measurements.Results: In this paper, we propose a parallel Kalman algorithm in three-dimensional space to speed up the computational speed of Lidar localization. At the same time, the initial localization accuracy of the latter is preserved. A distinctive feature of the proposed approach is that the Kalman localization algorithm itself is parallelized, rather than the process of building a map for navigation. The proposed algorithm allows us to obtain the result 3.8 times faster without compromising the localization accuracy, which was 3% for both cases, making it effective for real-time decision-making.Discussion: The reliability of this result is confirmed by a preliminary theoretical estimate of the acceleration rate based on Ambdahl’s law. Accelerating the Kalman filter with CUDA for Lidar localization can be of significant practical value, especially in real-time and in conditions where large amounts of data from Lidar sensors need to be processed.},
  archive      = {J_FROBT},
  author       = {Mochurad, Lesia},
  doi          = {10.3389/frobt.2024.1341689},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1341689},
  shortjournal = {Front. Robot. AI},
  title        = {Implementation and analysis of a parallel kalman filter algorithm for lidar localization based on CUDA technology},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-based methodologies for exoskeleton-assisted
rehabilitation of the lower limb: A review. <em>FROBT</em>, <em>11</em>,
1341580. (<a href="https://doi.org/10.3389/frobt.2024.1341580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, there has been a noticeable surge in efforts to design novel tools and approaches that incorporate Artificial Intelligence (AI) into rehabilitation of persons with lower-limb impairments, using robotic exoskeletons. The potential benefits include the ability to implement personalized rehabilitation therapies by leveraging AI for robot control and data analysis, facilitating personalized feedback and guidance. Despite this, there is a current lack of literature review specifically focusing on AI applications in lower-limb rehabilitative robotics. To address this gap, our work aims at performing a review of 37 peer-reviewed papers. This review categorizes selected papers based on robotic application scenarios or AI methodologies. Additionally, it uniquely contributes by providing a detailed summary of input features, AI model performance, enrolled populations, exoskeletal systems used in the validation process, and specific tasks for each paper. The innovative aspect lies in offering a clear understanding of the suitability of different algorithms for specific tasks, intending to guide future developments and support informed decision-making in the realm of lower-limb exoskeleton and AI applications.},
  archive      = {J_FROBT},
  author       = {Coser, Omar and Tamantini, Christian and Soda, Paolo and Zollo, Loredana},
  doi          = {10.3389/frobt.2024.1341580},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1341580},
  shortjournal = {Front. Robot. AI},
  title        = {AI-based methodologies for exoskeleton-assisted rehabilitation of the lower limb: A review},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robotic systems for upper-limb rehabilitation in multiple
sclerosis: A SWOT analysis and the synergies with virtual and augmented
environments. <em>FROBT</em>, <em>11</em>, 1335147. (<a
href="https://doi.org/10.3389/frobt.2024.1335147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robotics discipline is exploring precise and versatile solutions for upper-limb rehabilitation in Multiple Sclerosis (MS). People with MS can greatly benefit from robotic systems to help combat the complexities of this disease, which can impair the ability to perform activities of daily living (ADLs). In order to present the potential and the limitations of smart mechatronic devices in the mentioned clinical domain, this review is structured to propose a concise SWOT (Strengths, Weaknesses, Opportunities, and Threats) Analysis of robotic rehabilitation in MS. Through the SWOT Analysis, a method mostly adopted in business management, this paper addresses both internal and external factors that can promote or hinder the adoption of upper-limb rehabilitation robots in MS. Subsequently, it discusses how the synergy with another category of interaction technologies - the systems underlying virtual and augmented environments - may empower Strengths, overcome Weaknesses, expand Opportunities, and handle Threats in rehabilitation robotics for MS. The impactful adaptability of these digital settings (extensively used in rehabilitation for MS, even to approach ADL-like tasks in safe simulated contexts) is the main reason for presenting this approach to face the critical issues of the aforementioned SWOT Analysis. This methodological proposal aims at paving the way for devising further synergistic strategies based on the integration of medical robotic devices with other promising technologies to help upper-limb functional recovery in MS.},
  archive      = {J_FROBT},
  author       = {Albanese, Giulia A. and Bucchieri, Anna and Podda, Jessica and Tacchino, Andrea and Buccelli, Stefano and De Momi, Elena and Laffranchi, Matteo and Mannella, Kailynn and Holmes, Michael W. R. and Zenzeri, Jacopo and De Michieli, Lorenzo and Brichetto, Giampaolo and Barresi, Giacinto},
  doi          = {10.3389/frobt.2024.1335147},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1335147},
  shortjournal = {Front. Robot. AI},
  title        = {Robotic systems for upper-limb rehabilitation in multiple sclerosis: A SWOT analysis and the synergies with virtual and augmented environments},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Commonsense knowledge in cognitive robotics: A systematic
literature review. <em>FROBT</em>, <em>11</em>, 1328934. (<a
href="https://doi.org/10.3389/frobt.2024.1328934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the big challenges in robotics is the generalization necessary for performing unknown tasks in unknown environments on unknown objects. For us humans, this challenge is simplified by the commonsense knowledge we can access. For cognitive robotics, representing and acquiring commonsense knowledge is a relevant problem, so we perform a systematic literature review to investigate the current state of commonsense knowledge exploitation in cognitive robotics. For this review, we combine a keyword search on six search engines with a snowballing search on six related reviews, resulting in 2,048 distinct publications. After applying pre-defined inclusion and exclusion criteria, we analyse the remaining 52 publications. Our focus lies on the use cases and domains for which commonsense knowledge is employed, the commonsense aspects that are considered, the datasets/resources used as sources for commonsense knowledge and the methods for evaluating these approaches. Additionally, we discovered a divide in terminology between research from the knowledge representation and reasoning and the cognitive robotics community. This divide is investigated by looking at the extensive review performed by Zech et al. (The International Journal of Robotics Research, 2019, 38, 518–562), with whom we have no overlapping publications despite the similar goals.},
  archive      = {J_FROBT},
  author       = {Töberg, Jan-Philipp and Ngonga Ngomo, Axel-Cyrille and Beetz, Michael and Cimiano, Philipp},
  doi          = {10.3389/frobt.2024.1328934},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1328934},
  shortjournal = {Front. Robot. AI},
  title        = {Commonsense knowledge in cognitive robotics: A systematic literature review},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A scoping review of gaze and eye tracking-based control
methods for assistive robotic arms. <em>FROBT</em>, <em>11</em>,
1326670. (<a href="https://doi.org/10.3389/frobt.2024.1326670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Assistive Robotic Arms are designed to assist physically disabled people with daily activities. Existing joysticks and head controls are not applicable for severely disabled people such as people with Locked-in Syndrome. Therefore, eye tracking control is part of ongoing research. The related literature spans many disciplines, creating a heterogeneous field that makes it difficult to gain an overview.Objectives: This work focuses on ARAs that are controlled by gaze and eye movements. By answering the research questions, this paper provides details on the design of the systems, a comparison of input modalities, methods for measuring the performance of these controls, and an outlook on research areas that gained interest in recent years.Methods: This review was conducted as outlined in the PRISMA 2020 Statement. After identifying a wide range of approaches in use the authors decided to use the PRISMA-ScR extension for a scoping review to present the results. The identification process was carried out by screening three databases. After the screening process, a snowball search was conducted.Results: 39 articles and 6 reviews were included in this article. Characteristics related to the system and study design were extracted and presented divided into three groups based on the use of eye tracking.Conclusion: This paper aims to provide an overview for researchers new to the field by offering insight into eye tracking based robot controllers. We have identified open questions that need to be answered in order to provide people with severe motor function loss with systems that are highly useable and accessible.},
  archive      = {J_FROBT},
  author       = {Fischer-Janzen, Anke and Wendt, Thomas M. and Van Laerhoven, Kristof},
  doi          = {10.3389/frobt.2024.1326670},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1326670},
  shortjournal = {Front. Robot. AI},
  title        = {A scoping review of gaze and eye tracking-based control methods for assistive robotic arms},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meaningful human control and variable autonomy in
human-robot teams for firefighting. <em>FROBT</em>, <em>11</em>,
1323980. (<a href="https://doi.org/10.3389/frobt.2024.1323980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Humans and robots are increasingly collaborating on complex tasks such as firefighting. As robots are becoming more autonomous, collaboration in human-robot teams should be combined with meaningful human control. Variable autonomy approaches can ensure meaningful human control over robots by satisfying accountability, responsibility, and transparency. To verify whether variable autonomy approaches truly ensure meaningful human control, the concept should be operationalized to allow its measurement. So far, designers of variable autonomy approaches lack metrics to systematically address meaningful human control.Methods: Therefore, this qualitative focus group (n = 5 experts) explored quantitative operationalizations of meaningful human control during dynamic task allocation using variable autonomy in human-robot teams for firefighting. This variable autonomy approach requires dynamic allocation of moral decisions to humans and non-moral decisions to robots, using robot identification of moral sensitivity. We analyzed the data of the focus group using reflexive thematic analysis.Results: Results highlight the usefulness of quantifying the traceability requirement of meaningful human control, and how situation awareness and performance can be used to objectively measure aspects of the traceability requirement. Moreover, results emphasize that team and robot outcomes can be used to verify meaningful human control but that identifying reasons underlying these outcomes determines the level of meaningful human control.Discussion: Based on our results, we propose an evaluation method that can verify if dynamic task allocation using variable autonomy in human-robot teams for firefighting ensures meaningful human control over the robot. This method involves subjectively and objectively quantifying traceability using human responses during and after simulations of the collaboration. In addition, the method involves semi-structured interviews after the simulation to identify reasons underlying outcomes and suggestions to improve the variable autonomy approach.},
  archive      = {J_FROBT},
  author       = {Verhagen, Ruben S. and Neerincx, Mark A. and Tielman, Myrthe L.},
  doi          = {10.3389/frobt.2024.1323980},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1323980},
  shortjournal = {Front. Robot. AI},
  title        = {Meaningful human control and variable autonomy in human-robot teams for firefighting},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal fusion of EMG and vision for human grasp intent
inference in prosthetic hand control. <em>FROBT</em>, <em>11</em>,
1312554. (<a href="https://doi.org/10.3389/frobt.2024.1312554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective: For transradial amputees, robotic prosthetic hands promise to regain the capability to perform daily living activities. Current control methods based on physiological signals such as electromyography (EMG) are prone to yielding poor inference outcomes due to motion artifacts, muscle fatigue, and many more. Vision sensors are a major source of information about the environment state and can play a vital role in inferring feasible and intended gestures. However, visual evidence is also susceptible to its own artifacts, most often due to object occlusion, lighting changes, etc. Multimodal evidence fusion using physiological and vision sensor measurements is a natural approach due to the complementary strengths of these modalities.Methods: In this paper, we present a Bayesian evidence fusion framework for grasp intent inference using eye-view video, eye-gaze, and EMG from the forearm processed by neural network models. We analyze individual and fused performance as a function of time as the hand approaches the object to grasp it. For this purpose, we have also developed novel data processing and augmentation techniques to train neural network components.Results: Our results indicate that, on average, fusion improves the instantaneous upcoming grasp type classification accuracy while in the reaching phase by 13.66% and 14.8%, relative to EMG (81.64% non-fused) and visual evidence (80.5% non-fused) individually, resulting in an overall fusion accuracy of 95.3%.Conclusion: Our experimental data analyses demonstrate that EMG and visual evidence show complementary strengths, and as a consequence, fusion of multimodal evidence can outperform each individual evidence modality at any given time.},
  archive      = {J_FROBT},
  author       = {Zandigohar, Mehrshad and Han, Mo and Sharif, Mohammadreza and Günay, Sezen Yağmur and Furmanek, Mariusz P. and Yarossi, Mathew and Bonato, Paolo and Onal, Cagdas and Padır, Taşkın and Erdoğmuş, Deniz and Schirner, Gunar},
  doi          = {10.3389/frobt.2024.1312554},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1312554},
  shortjournal = {Front. Robot. AI},
  title        = {Multimodal fusion of EMG and vision for human grasp intent inference in prosthetic hand control},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of an earthworm-based soft robot for colon
sampling. <em>FROBT</em>, <em>11</em>, 1309220. (<a
href="https://doi.org/10.3389/frobt.2024.1309220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer as a major disease that poses a serious threat to human health continues to rise in incidence. And the timely colon examinations are crucial for the prevention, diagnosis, and treatment of this disease. Clinically, gastroscopy is used as a universal means of examination, prevention and diagnosis of this disease, but this detection method is not patient-friendly and can easily cause damage to the intestinal mucosa. Soft robots as an emerging technology offer a promising approach to examining, diagnosing, and treating intestinal diseases due to their high flexibility and patient-friendly interaction. However, existing research on intestinal soft robots mainly focuses on controlled movement and observation within the colon or colon-like environments, lacking additional functionalities such as sample collection from the intestine. Here, we designed and developed an earthworm-like soft robot specifically for colon sampling. It consists of a robot body with an earthworm-like structure for movement in the narrow and soft pipe-environments, and a sampling part with a flexible arm structure resembling an elephant trunk for bidirectional bending sampling. This soft robot is capable of flexible movement and sample collection within an colon-like environment. By successfully demonstrating the feasibility of utilizing soft robots for colon sampling, this work introduces a novel method for non-destructive inspection and sampling in the colon. It represents a significant advancement in the field of medical robotics, offering a potential solution for more efficient and accurate examination and diagnosis of intestinal diseases, specifically for colorectal cancer.},
  archive      = {J_FROBT},
  author       = {Li, Gongxin and Qiu, Wei and Wang, Mindong and Zhu, Yazhou and Liu, Fei},
  doi          = {10.3389/frobt.2024.1309220},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1309220},
  shortjournal = {Front. Robot. AI},
  title        = {Development of an earthworm-based soft robot for colon sampling},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Active learning strategies for robotic tactile texture
recognition tasks. <em>FROBT</em>, <em>11</em>, 1281060. (<a
href="https://doi.org/10.3389/frobt.2024.1281060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate texture classification empowers robots to improve their perception and comprehension of the environment, enabling informed decision-making and appropriate responses to diverse materials and surfaces. Still, there are challenges for texture classification regarding the vast amount of time series data generated from robots’ sensors. For instance, robots are anticipated to leverage human feedback during interactions with the environment, particularly in cases of misclassification or uncertainty. With the diversity of objects and textures in daily activities, Active Learning (AL) can be employed to minimize the number of samples the robot needs to request from humans, streamlining the learning process. In the present work, we use AL to select the most informative samples for annotation, thus reducing the human labeling effort required to achieve high performance for classifying textures. We also use a sliding window strategy for extracting features from the sensor’s time series used in our experiments. Our multi-class dataset (e.g., 12 textures) challenges traditional AL strategies since standard techniques cannot control the number of instances per class selected to be labeled. Therefore, we propose a novel class-balancing instance selection algorithm that we integrate with standard AL strategies. Moreover, we evaluate the effect of sliding windows of two-time intervals (3 and 6 s) on our AL Strategies. Finally, we analyze in our experiments the performance of AL strategies, with and without the balancing algorithm, regarding f1-score, and positive effects are observed in terms of performance when using our proposed data pipeline. Our results show that the training data can be reduced to 70% using an AL strategy regardless of the machine learning model and reach, and in many cases, surpass a baseline performance. Finally, exploring the textures with a 6-s window achieves the best performance, and using either Extra Trees produces an average f1-score of 90.21% in the texture classification data set.},
  archive      = {J_FROBT},
  author       = {Das, Shemonto and Prado da Fonseca, Vinicius and Soares, Amilcar},
  doi          = {10.3389/frobt.2024.1281060},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1281060},
  shortjournal = {Front. Robot. AI},
  title        = {Active learning strategies for robotic tactile texture recognition tasks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed agency in HRI—an exploratory study of a
narrative robot design. <em>FROBT</em>, <em>11</em>, 1253466. (<a
href="https://doi.org/10.3389/frobt.2024.1253466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore an alternative approach to the design of robots that deviates from the common envisionment of having one unified agent. What if robots are depicted as an agentic ensemble where agency is distributed over different components? In the project presented here, we investigate the potential contributions of this approach to creating entertaining and joyful human-robot interaction (HRI), which also remains comprehensible to human observers. We built a service robot—which takes care of plants as a Plant-Watering Robot (PWR)—that appears as a small ship controlled by a robotic captain accompanied by kinetic elements. The goal of this narrative design, which utilizes a distributed agency approach, is to make the robot entertaining to watch and foster its acceptance. We discuss the robot’s design rationale and present observations from an exploratory study in two contrastive settings, on a university campus and in a care home for people with dementia, using a qualitative video-based approach for analysis. Our observations indicate that such a design has potential regarding the attraction, acceptance, and joyfulness it can evoke. We discuss aspects of this design approach regarding the field of elderly care, limitations of our study, and identify potential fields of use and further scopes for studies.},
  archive      = {J_FROBT},
  author       = {Graf, Philipp and Zarp-Falden, Christian Sønderskov and Naik, Lakshadeep and Lefeuvre, Kevin Bruno and Marchetti, Emanuela and Hornecker, Eva and Sørensen, Mads Bergholdt and Hemmingsen, Laurits Valberg and Just Christensen, Ebbe Vincent and Bodenhagen, Leon and Krüger, Norbert and Bischof, Andreas},
  doi          = {10.3389/frobt.2024.1253466},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1253466},
  shortjournal = {Front. Robot. AI},
  title        = {Distributed agency in HRI—an exploratory study of a narrative robot design},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Opinion attribution improves motivation to exchange
subjective opinions with humanoid robots. <em>FROBT</em>, <em>11</em>,
1175879. (<a href="https://doi.org/10.3389/frobt.2024.1175879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the development of robots that can engage in non-task-oriented dialogue with people, such as chat, has received increasing attention. This study aims to clarify the factors that improve the user’s willingness to talk with robots in non-task oriented dialogues (e.g., chat). A previous study reported that exchanging subjective opinions makes such dialogue enjoyable and enthusiastic. In some cases, however, the robot’s subjective opinions are not realistic, i.e., the user believes the robot does not have opinions, thus we cannot attribute the opinion to the robot. For example, if a robot says that alcohol tastes good, it may be difficult to imagine the robot having such an opinion. In this case, the user’s motivation to exchange opinions may decrease. In this study, we hypothesize that regardless of the type of robot, opinion attribution affects the user’s motivation to exchange opinions with humanoid robots. We examined the effect by preparing various opinions of two kinds of humanoid robots. The experimental result suggests that not only the users’ interest in the topic but also the attribution of the subjective opinions to them influence their motivation to exchange opinions. Another analysis revealed that the android significantly increased the motivation when they are interested in the topic and do not attribute opinions, while the small robot significantly increased it when not interested and attributed opinions. In situations where there are opinions that cannot be attributed to humanoid robots, the result that androids are more motivating when users have the interests even if opinions are not attributed can indicate the usefulness of androids.},
  archive      = {J_FROBT},
  author       = {Uchida, Takahisa and Minato, Takashi and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2024.1175879},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1175879},
  shortjournal = {Front. Robot. AI},
  title        = {Opinion attribution improves motivation to exchange subjective opinions with humanoid robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Building causal models for finding actual causes of unmanned
aerial vehicle failures. <em>FROBT</em>, <em>11</em>, 1123762. (<a
href="https://doi.org/10.3389/frobt.2024.1123762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding actual causes of unmanned aerial vehicle (UAV) failures can be split into two main tasks: building causal models and performing actual causality analysis (ACA) over them. While there are available solutions in the literature to perform ACA, building comprehensive causal models is still an open problem. The expensive and time-consuming process of building such models, typically performed manually by domain experts, has hindered the widespread application of causality-based diagnosis solutions in practice. This study proposes a methodology based on natural language processing for automating causal model generation for UAVs. After collecting textual data from online resources, causal keywords are identified in sentences. Next, cause–effect phrases are extracted from sentences based on predefined dependency rules between tokens. Finally, the extracted cause–effect pairs are merged to form a causal graph, which we then use for ACA. To demonstrate the applicability of our framework, we scrape online text resources of Ardupilot, an open-source UAV controller software. Our evaluations using real flight logs show that the generated graphs can successfully be used to find the actual causes of unwanted events. Moreover, our hybrid cause–effect extraction module performs better than a purely deep-learning based tool (i.e., CiRA) by 32% in precision and 25% in recall in our Ardupilot use case.},
  archive      = {J_FROBT},
  author       = {Zibaei, Ehsan and Borth, Robin},
  doi          = {10.3389/frobt.2024.1123762},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1123762},
  shortjournal = {Front. Robot. AI},
  title        = {Building causal models for finding actual causes of unmanned aerial vehicle failures},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Augmented reality for supporting the interaction between
pedestrians and automated vehicles: An experimental outdoor study.
<em>FROBT</em>, <em>11</em>, 1324060. (<a
href="https://doi.org/10.3389/frobt.2024.1324060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Communication from automated vehicles (AVs) to pedestrians using augmented reality (AR) could positively contribute to traffic safety. However, previous AR research for pedestrians was mainly conducted through online questionnaires or experiments in virtual environments instead of real ones.Methods: In this study, 28 participants conducted trials outdoors with an approaching AV and were supported by four different AR interfaces. The AR experience was created by having participants wear a Varjo XR-3 headset with see-through functionality, with the AV and AR elements virtually overlaid onto the real environment. The AR interfaces were vehicle-locked (Planes on vehicle), world-locked (Fixed pedestrian lights, Virtual fence), or head-locked (Pedestrian lights HUD). Participants had to hold down a button when they felt it was safe to cross, and their opinions were obtained through rating scales, interviews, and a questionnaire.Results: The results showed that participants had a subjective preference for AR interfaces over no AR interface. Furthermore, the Pedestrian lights HUD was more effective than no AR interface in a statistically significant manner, as it led to participants more frequently keeping the button pressed. The Fixed pedestrian lights scored lower than the other interfaces, presumably due to low saliency and the fact that participants had to visually identify both this AR interface and the AV.Discussion: In conclusion, while users favour AR in AV-pedestrian interactions over no AR, its effectiveness depends on design factors like location, visibility, and visual attention demands. In conclusion, this work provides important insights into the use of AR outdoors. The findings illustrate that, in these circumstances, a clear and easily interpretable AR interface is of key importance.},
  archive      = {J_FROBT},
  author       = {Aleva, Thomas K. and Tabone, Wilbert and Dodou, Dimitra and de Winter, Joost C. F.},
  doi          = {10.3389/frobt.2024.1324060},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1324060},
  shortjournal = {Front. Robot. AI},
  title        = {Augmented reality for supporting the interaction between pedestrians and automated vehicles: An experimental outdoor study},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling of slip rate-dependent traversability for path
planning of wheeled mobile robot in sandy terrain. <em>FROBT</em>,
<em>11</em>, 1320261. (<a
href="https://doi.org/10.3389/frobt.2024.1320261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A planetary exploration rover has been employed for scientific endeavors or as a precursor for upcoming manned missions. Predicting rover traversability from its wheel slip ensures safe and efficient autonomous operations of rovers on deformable planetary surfaces; path planning algorithms that reduce slips by considering wheel-soil interaction or terrain data can minimize the risk of the rover becoming immobilized. Understanding wheel-soil interaction in transient states is vital for developing a more precise slip ratio prediction model, while path planning in the past assumes that slips generated at the path is a series of slip ratio in steady state. In this paper, we focus on the transient slip, or slip rate the time derivative of slip ratio, to explicitly address it into the cost function of path planning algorithm. We elaborated a regression model that takes slip rate and traction force as inputs and outputs slip ratio, which is employed in the cost function to minimize the rover slip in path planning phase. Experiments using a single wheel testbed revealed that even with the same wheel traction force, the slip ratio varies with different slip rates; we confirmed that the smaller the absolute value of the slip rate, the larger the slip ratio for the same traction force. The statistical analysis of the regression model confirms that the model can estimate the slip ratio within an accuracy of 85% in average. The path planning simulation with the regression model confirmed a reduction of 58% slip experienced by the rover when driving through rough terrain environments. The dynamics simulation results insisted that the proposed method can reduce the slip rate in rough terrain environments.},
  archive      = {J_FROBT},
  author       = {Sakayori, Go and Ishigami, Genya},
  doi          = {10.3389/frobt.2024.1320261},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1320261},
  shortjournal = {Front. Robot. AI},
  title        = {Modeling of slip rate-dependent traversability for path planning of wheeled mobile robot in sandy terrain},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human movement modifications induced by different levels of
transparency of an active upper limb exoskeleton. <em>FROBT</em>,
<em>11</em>, 1308958. (<a
href="https://doi.org/10.3389/frobt.2024.1308958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active upper limb exoskeletons are a potentially powerful tool for neuromotor rehabilitation. This potential depends on several basic control modes, one of them being transparency. In this control mode, the exoskeleton must follow the human movement without altering it, which theoretically implies null interaction efforts. Reaching high, albeit imperfect, levels of transparency requires both an adequate control method and an in-depth evaluation of the impacts of the exoskeleton on human movement. The present paper introduces such an evaluation for three different “transparent” controllers either based on an identification of the dynamics of the exoskeleton, or on force feedback control or on their combination. Therefore, these controllers are likely to induce clearly different levels of transparency by design. The conducted investigations could allow to better understand how humans adapt to transparent controllers, which are necessarily imperfect. A group of fourteen participants were subjected to these three controllers while performing reaching movements in a parasagittal plane. The subsequent analyses were conducted in terms of interaction efforts, kinematics, electromyographic signals and ergonomic feedback questionnaires. Results showed that, when subjected to less performing transparent controllers, participants strategies tended to induce relatively high interaction efforts, with higher muscle activity, which resulted in a small sensitivity of kinematic metrics. In other words, very different residual interaction efforts do not necessarily induce very different movement kinematics. Such a behavior could be explained by a natural human tendency to expend effort to preserve their preferred kinematics, which should be taken into account in future transparent controllers evaluation.},
  archive      = {J_FROBT},
  author       = {Verdel, Dorian and Farr, Anais and Devienne, Thibault and Vignais, Nicolas and Berret, Bastien and Bruneau, Olivier},
  doi          = {10.3389/frobt.2024.1308958},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1308958},
  shortjournal = {Front. Robot. AI},
  title        = {Human movement modifications induced by different levels of transparency of an active upper limb exoskeleton},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design and sequential jumping experimental validation of a
musculoskeletal bipedal robot based on the spring-loaded inverted
pendulum model. <em>FROBT</em>, <em>11</em>, 1296706. (<a
href="https://doi.org/10.3389/frobt.2024.1296706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To effectively control a robot’s motion, it is common to employ a simplified model that approximates the robot’s dynamics. Nevertheless, discrepancies between the actual mechanical properties of the robot and the simplified model can result in motion failures. To address this issue, this study introduces a pneumatic-driven bipedal musculoskeletal robot designed to closely match the mechanical characteristics of a simplified spring-loaded inverted pendulum (SLIP) model. The SLIP model is widely utilized in robotics due to its passive stability and dynamic properties resembling human walking patterns. A musculoskeletal bipedal robot was designed and manufactured to concentrate its center of mass within a compact body around the hip joint, featuring low leg inertia in accordance with SLIP model principles. Furthermore, we validated that the robot exhibits similar dynamic characteristics to the SLIP model through a sequential jumping experiment and by comparing its performance to SLIP model simulation.},
  archive      = {J_FROBT},
  author       = {Li, Yiqi and Jiang, Yelin and Hosoda, Koh},
  doi          = {10.3389/frobt.2024.1296706},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1296706},
  shortjournal = {Front. Robot. AI},
  title        = {Design and sequential jumping experimental validation of a musculoskeletal bipedal robot based on the spring-loaded inverted pendulum model},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards human-centered AI and robotics to reduce hospital
falls: Finding opportunities to enhance patient-nurse interactions
during toileting. <em>FROBT</em>, <em>11</em>, 1295679. (<a
href="https://doi.org/10.3389/frobt.2024.1295679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Patients who are hospitalized may be at a higher risk for falling, which can result in additional injuries, longer hospitalizations, and extra cost for healthcare organizations. A frequent context for these falls is when a hospitalized patient needs to use the bathroom. While it is possible that “high-tech” tools like robots and AI applications can help, adopting a human-centered approach and engaging users and other affected stakeholders in the design process can help to maximize benefits and avoid unintended consequences.Methods: Here, we detail our findings from a human-centered design research effort to investigate how the process of toileting a patient can be ameliorated through the application of advanced tools like robots and AI. We engaged healthcare professionals in interviews, focus groups, and a co-creation session in order to recognize common barriers in the toileting process and find opportunities for improvement.Results: In our conversations with participants, who were primarily nurses, we learned that toileting is more than a nuisance for technology to remove through automation. Nurses seem keenly aware and responsive to the physical and emotional pains experienced by patients during the toileting process, and did not see technology as a feasible or welcomed substitute. Instead, nurses wanted tools which supported them in providing this care to their patients. Participants envisioned tools which helped them anticipate and understand patient toileting assistance needs so they could plan to assist at convenient times during their existing workflows. Participants also expressed favorability towards mechanical assistive features which were incorporated into existing equipment to ensure ubiquitous availability when needed without adding additional mass to an already cramped and awkward environment.Discussion: We discovered that the act of toileting served more than one function, and can be viewed as a valuable touchpoint in which nurses can assess, support, and encourage their patients to engage in their own recovery process as they perform a necessary and normal function of life. While we found opportunities for technology to make the process safer and less burdensome for patients and clinical staff alike, we believe that designers should preserve and enhance the therapeutic elements of the nurse-patient interaction rather than eliminate it through automation.},
  archive      = {J_FROBT},
  author       = {Rafferty, Hannah and Cretaro, Cameron and Arfanis, Nicholas and Moore, Andrew and Pong, Douglas and Tulk Jesso, Stephanie},
  doi          = {10.3389/frobt.2024.1295679},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1295679},
  shortjournal = {Front. Robot. AI},
  title        = {Towards human-centered AI and robotics to reduce hospital falls: Finding opportunities to enhance patient-nurse interactions during toileting},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lower limb biomechanics of fully trained exoskeleton users
reveal complex mechanisms behind the reductions in energy cost with
human-in-the-loop optimization. <em>FROBT</em>, <em>11</em>, 1283080.
(<a href="https://doi.org/10.3389/frobt.2024.1283080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exoskeletons that assist in ankle plantarflexion can improve energy economy in locomotion. Characterizing the joint-level mechanisms behind these reductions in energy cost can lead to a better understanding of how people interact with these devices, as well as to improved device design and training protocols. We examined the biomechanical responses to exoskeleton assistance in exoskeleton users trained with a lengthened protocol. Kinematics at unassisted joints were generally unchanged by assistance, which has been observed in other ankle exoskeleton studies. Peak plantarflexion angle increased with plantarflexion assistance, which led to increased total and biological mechanical power despite decreases in biological joint torque and whole-body net metabolic energy cost. Ankle plantarflexor activity also decreased with assistance. Muscles that act about unassisted joints also increased activity for large levels of assistance, and this response should be investigated over long-term use to prevent overuse injuries.},
  archive      = {J_FROBT},
  author       = {Poggensee, Katherine L. and Collins, Steven H.},
  doi          = {10.3389/frobt.2024.1283080},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1283080},
  shortjournal = {Front. Robot. AI},
  title        = {Lower limb biomechanics of fully trained exoskeleton users reveal complex mechanisms behind the reductions in energy cost with human-in-the-loop optimization},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Open continuum robotics–one actuation module to create them
all. <em>FROBT</em>, <em>11</em>, 1272403. (<a
href="https://doi.org/10.3389/frobt.2024.1272403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experiments on physical continuum robot are the gold standard for evaluations. Currently, as no commercial continuum robot platform is available, a large variety of early-stage prototypes exists. These prototypes are developed by individual research groups and are often used for a single publication. Thus, a significant amount of time is devoted to creating proprietary hardware and software hindering the development of a common platform, and shifting away scarce time and efforts from the main research challenges. We address this problem by proposing an open-source actuation module, which can be used to build different types of continuum robots. It consists of a high-torque brushless electric motor, a high resolution optical encoder, and a low-gear-ratio transmission. For this article, we create three different types of continuum robots. In addition, we illustrate, for the first time, that continuum robots built with our actuation module can proprioceptively detect external forces. Consequently, our approach opens untapped and under-investigated research directions related to the dynamics and advanced control of continuum robots, where sensing the generalized flow and effort is mandatory. Besides that, we democratize continuum robots research by providing open-source software and hardware with our initiative called the Open Continuum Robotics Project, to increase the accessibility and reproducibility of advanced methods.},
  archive      = {J_FROBT},
  author       = {Grassmann, Reinhard M. and Shentu, Chengnan and Hamoda, Taqi and Dewi, Puspita Triana and Burgner-Kahrs, Jessica},
  doi          = {10.3389/frobt.2024.1272403},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1272403},
  shortjournal = {Front. Robot. AI},
  title        = {Open continuum robotics–one actuation module to create them all},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft touchless sensors and touchless sensing for soft
robots. <em>FROBT</em>, <em>11</em>, 1224216. (<a
href="https://doi.org/10.3389/frobt.2024.1224216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots are characterized by their mechanical compliance, making them well-suited for various bio-inspired applications. However, the challenge of preserving their flexibility during deployment has necessitated using soft sensors which can enhance their mobility, energy efficiency, and spatial adaptability. Through emulating the structure, strategies, and working principles of human senses, soft robots can detect stimuli without direct contact with soft touchless sensors and tactile stimuli. This has resulted in noteworthy progress within the field of soft robotics. Nevertheless, soft, touchless sensors offer the advantage of non-invasive sensing and gripping without the drawbacks linked to physical contact. Consequently, the popularity of soft touchless sensors has grown in recent years, as they facilitate intuitive and safe interactions with humans, other robots, and the surrounding environment. This review explores the emerging confluence of touchless sensing and soft robotics, outlining a roadmap for deployable soft robots to achieve human-level dexterity.},
  archive      = {J_FROBT},
  author       = {Sirithunge, Chapa and Wang, Huijiang and Iida, Fumiya},
  doi          = {10.3389/frobt.2024.1224216},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1224216},
  shortjournal = {Front. Robot. AI},
  title        = {Soft touchless sensors and touchless sensing for soft robots},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting the corruption of online questionnaires by
artificial intelligence. <em>FROBT</em>, <em>10</em>, 1277635. (<a
href="https://doi.org/10.3389/frobt.2023.1277635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online questionnaires that use crowdsourcing platforms to recruit participants have become commonplace, due to their ease of use and low costs. Artificial intelligence (AI)-based large language models (LLMs) have made it easy for bad actors to automatically fill in online forms, including generating meaningful text for open-ended tasks. These technological advances threaten the data quality for studies that use online questionnaires. This study tested whether text generated by an AI for the purpose of an online study can be detected by both humans and automatic AI detection systems. While humans were able to correctly identify the authorship of such text above chance level (76% accuracy), their performance was still below what would be required to ensure satisfactory data quality. Researchers currently have to rely on a lack of interest among bad actors to successfully use open-ended responses as a useful tool for ensuring data quality. Automatic AI detection systems are currently completely unusable. If AI submissions of responses become too prevalent, then the costs associated with detecting fraudulent submissions will outweigh the benefits of online questionnaires. Individual attention checks will no longer be a sufficient tool to ensure good data quality. This problem can only be systematically addressed by crowdsourcing platforms. They cannot rely on automatic AI detection systems and it is unclear how they can ensure data quality for their paying clients.},
  archive      = {J_FROBT},
  author       = {Lebrun, Benjamin and Temtsin, Sharon and Vonasch, Andrew and Bartneck, Christoph},
  doi          = {10.3389/frobt.2023.1277635},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1277635},
  shortjournal = {Front. Robot. AI},
  title        = {Detecting the corruption of online questionnaires by artificial intelligence},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time-dependant bayesian knowledge tracing—robots that model
user skills over time. <em>FROBT</em>, <em>10</em>, 1249241. (<a
href="https://doi.org/10.3389/frobt.2023.1249241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creating an accurate model of a user’s skills is an essential task for Intelligent Tutoring Systems (ITS) and robotic tutoring systems. This allows the system to provide personalized help based on the user’s knowledge state. Most user skill modeling systems have focused on simpler tasks such as arithmetic or multiple-choice questions, where the user’s model is only updated upon task completion. These tasks have a single correct answer and they generate an unambiguous observation of the user’s answer. This is not the case for more complex tasks such as programming or engineering tasks, where the user completing the task creates a succession of noisy user observations as they work on different parts of the task. We create an algorithm called Time-Dependant Bayesian Knowledge Tracing (TD-BKT) that tracks users’ skills throughout these more complex tasks. We show in simulation that it has a more accurate model of the user’s skills and, therefore, can select better teaching actions than previous algorithms. Lastly, we show that a robot can use TD-BKT to model a user and teach electronic circuit tasks to participants during a user study. Our results show that participants significantly improved their skills when modeled using TD-BKT.},
  archive      = {J_FROBT},
  author       = {Salomons, Nicole and Scassellati, Brian},
  doi          = {10.3389/frobt.2023.1249241},
  journal      = {Frontiers in Robotics and AI},
  month        = {2},
  pages        = {1249241},
  shortjournal = {Front. Robot. AI},
  title        = {Time-dependant bayesian knowledge tracing—Robots that model user skills over time},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: Language, affordance and physics in robot
cognition and intelligent systems. <em>FROBT</em>, <em>10</em>, 1355576.
(<a href="https://doi.org/10.3389/frobt.2023.1355576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_FROBT},
  author       = {Chen, Nutan and Mayol-Cuevas, Walterio W. and Karl, Maximilian and Aljalbout, Elie and Zeng, Andy and Cortese, Aurelio and Burgard, Wolfram and van Hoof, Herke},
  doi          = {10.3389/frobt.2023.1355576},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1355576},
  shortjournal = {Front. Robot. AI},
  title        = {Editorial: Language, affordance and physics in robot cognition and intelligent systems},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft gripper for small fruits harvesting and pick and place
operations. <em>FROBT</em>, <em>10</em>, 1330496. (<a
href="https://doi.org/10.3389/frobt.2023.1330496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture 4.0 presents several challenges for the automation of various operations, including the fundamental task of harvesting. One of the crucial aspects in the automatic harvesting of high value crops is the grip and detachment of delicate fruits without spoiling them or interfering with the environment. Soft robotic systems, particularly soft grippers, offer a promising solution for this problem, as they can operate in unstructured environments, manipulate objects delicately, and interact safely with humans. In this context, this article presents a soft gripper design for harvesting as well as for pick-and-place operations of small and medium-sized fruits. The gripper is fabricated using the 3D printing technology with a flexible thermoplastic elastomer filament. This approach enables the production of an economical, compact, easily replicable, and interchangeable gripper by utilizing soft robotics principles, such as flexible structures and pneumatic actuation.},
  archive      = {J_FROBT},
  author       = {Navas, Eduardo and Shamshiri, Redmond R. and Dworak, Volker and Weltzien, Cornelia and Fernández, Roemi},
  doi          = {10.3389/frobt.2023.1330496},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1330496},
  shortjournal = {Front. Robot. AI},
  title        = {Soft gripper for small fruits harvesting and pick and place operations},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tour guide robot: A 5G-enabled robot museum guide.
<em>FROBT</em>, <em>10</em>, 1323675. (<a
href="https://doi.org/10.3389/frobt.2023.1323675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents and discusses the development and deployment of a tour guide robot as part of the 5 g-TOURS EU research project, aimed at developing applications enabled by 5G technology in different use cases. The objective is the development of an autonomous robotic application where intelligence is off-loaded to a remote machine via 5G network, so as to lift most of the computational load from the robot itself. The application uses components that have been widely studied in robotics, (i.e., localization, mapping, planning, interaction). However, the characteristics of the network and interactions with visitors in the wild introduce specific problems which must be taken into account. The paper discusses in detail such problems, summarizing the main results achieved both from the methodological and the experimental standpoint, and is completed by the description of the general functional architecture of the whole system, including navigation and operational services. The software implementation is also publicly available.},
  archive      = {J_FROBT},
  author       = {Rosa, Stefano and Randazzo, Marco and Landini, Ettore and Bernagozzi, Stefano and Sacco, Giancarlo and Piccinino, Mara and Natale, Lorenzo},
  doi          = {10.3389/frobt.2023.1323675},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1323675},
  shortjournal = {Front. Robot. AI},
  title        = {Tour guide robot: A 5G-enabled robot museum guide},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-triggered robot self-assessment to aid in autonomy
adjustment. <em>FROBT</em>, <em>10</em>, 1294533. (<a
href="https://doi.org/10.3389/frobt.2023.1294533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Human–robot teams are being called upon to accomplish increasingly complex tasks. During execution, the robot may operate at different levels of autonomy (LOAs), ranging from full robotic autonomy to full human control. For any number of reasons, such as changes in the robot’s surroundings due to the complexities of operating in dynamic and uncertain environments, degradation and damage to the robot platform, or changes in tasking, adjusting the LOA during operations may be necessary to achieve desired mission outcomes. Thus, a critical challenge is understanding when and how the autonomy should be adjusted.Methods: We frame this problem with respect to the robot’s capabilities and limitations, known as robot competency. With this framing, a robot could be granted a level of autonomy in line with its ability to operate with a high degree of competence. First, we propose a Model Quality Assessment metric, which indicates how (un)expected an autonomous robot’s observations are compared to its model predictions. Next, we present an Event-Triggered Generalized Outcome Assessment (ET-GOA) algorithm that uses changes in the Model Quality Assessment above a threshold to selectively execute and report a high-level assessment of the robot’s competency. We validated the Model Quality Assessment metric and the ET-GOA algorithm in both simulated and live robot navigation scenarios.Results: Our experiments found that the Model Quality Assessment was able to respond to unexpected observations. Additionally, our validation of the full ET-GOA algorithm explored how the computational cost and accuracy of the algorithm was impacted across several Model Quality triggering thresholds and with differing amounts of state perturbations.Discussion: Our experimental results combined with a human-in-the-loop demonstration show that Event-Triggered Generalized Outcome Assessment algorithm can facilitate informed autonomy-adjustment decisions based on a robot’s task competency.},
  archive      = {J_FROBT},
  author       = {Conlon, Nicholas and Ahmed, Nisar and Szafir, Daniel},
  doi          = {10.3389/frobt.2023.1294533},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1294533},
  shortjournal = {Front. Robot. AI},
  title        = {Event-triggered robot self-assessment to aid in autonomy adjustment},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Digital threads in turbulent times: Unraveling technostress
and cleaner production in the food industry. <em>FROBT</em>,
<em>10</em>, 1293904. (<a
href="https://doi.org/10.3389/frobt.2023.1293904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: In the current landscape marked by swift digital transformations and global disruptions, comprehending the intersection of digitalization and sustainable business practices is imperative. This study focuses on the food industries of China and Pakistan, aiming to explore the influence of digitalization on cleaner production.Methods: Employing a cross-sectional design, data were gathered through online surveys involving a diverse group of employees. Special attention was given to the emergent phenomenon of technostress and its subsequent implications for individuals in the workplace.Results: The findings of the study demonstrate a significant impact of digitalization on both resource mobilization and interaction quality within the surveyed food industries. Notably, technostress emerged as a mediating factor, shedding light on the psychological challenges associated with digital transitions. The study further reveals the moderating role of the COVID-19 pandemic, altering the dynamics among the variables under investigation.Discussion: From a theoretical perspective, this research contributes to the cleaner production literature by bridging it with the human-centric nuances of technological adaptation. On a practical level, the study emphasizes the importance of aligning digital strategies with resource mobilization to achieve sustainable outcomes. For the food industry and potentially beyond, the research offers a roadmap for integrating digital tools into operations, ensuring efficiency, and promoting cleaner production.},
  archive      = {J_FROBT},
  author       = {Irfan, Muhammad and Sulehri, Numair Ahmed and Manickiam, Neelamehan},
  doi          = {10.3389/frobt.2023.1293904},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1293904},
  shortjournal = {Front. Robot. AI},
  title        = {Digital threads in turbulent times: Unraveling technostress and cleaner production in the food industry},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simultaneous localization and mapping in a multi-robot
system in a dynamic environment with unknown initial correspondence.
<em>FROBT</em>, <em>10</em>, 1291672. (<a
href="https://doi.org/10.3389/frobt.2023.1291672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A basic assumption in most approaches to simultaneous localization and mapping (SLAM) is the static nature of the environment. In recent years, some research has been devoted to the field of SLAM in dynamic environments. However, most of the studies conducted in this field have implemented SLAM by removing and filtering the moving landmarks. Moreover, the use of several robots in large, complex, and dynamic environments can significantly improve performance on the localization and mapping task, which has attracted many researchers to this problem more recently. In multi-robot SLAM, the robots can cooperate in a decentralized manner without the need for a central processing center to obtain their positions and a more precise map of the environment. In this article, a new decentralized approach is presented for multi-robot SLAM problems in dynamic environments with unknown initial correspondence. The proposed method applies a modified Fast-SLAM method, which implements SLAM in a decentralized manner by considering moving landmarks in the environment. Due to the unknown initial correspondence of the robots, a geographical approach is embedded in the proposed algorithm to align and merge their maps. Data association is also embedded in the algorithm; this is performed using the measurement predictions in the SLAM process of each robot. Finally, simulation results are provided to demonstrate the performance of the proposed method.},
  archive      = {J_FROBT},
  author       = {Malakouti-Khah, Hadiseh and Sadeghzadeh-Nokhodberiz, Nargess and Montazeri, Allahyar},
  doi          = {10.3389/frobt.2023.1291672},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1291672},
  shortjournal = {Front. Robot. AI},
  title        = {Simultaneous localization and mapping in a multi-robot system in a dynamic environment with unknown initial correspondence},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emergent communication of multimodal deep generative models
based on metropolis-hastings naming game. <em>FROBT</em>, <em>10</em>,
1290604. (<a href="https://doi.org/10.3389/frobt.2023.1290604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep generative models (DGM) are increasingly employed in emergent communication systems. However, their application in multimodal data contexts is limited. This study proposes a novel model that combines multimodal DGM with the Metropolis-Hastings (MH) naming game, enabling two agents to focus jointly on a shared subject and develop common vocabularies. The model proves that it can handle multimodal data, even in cases of missing modalities. Integrating the MH naming game with multimodal variational autoencoders (VAE) allows agents to form perceptual categories and exchange signs within multimodal contexts. Moreover, fine-tuning the weight ratio to favor a modality that the model could learn and categorize more readily improved communication. Our evaluation of three multimodal approaches - mixture-of-experts (MoE), product-of-experts (PoE), and mixture-of-product-of-experts (MoPoE)–suggests an impact on the creation of latent spaces, the internal representations of agents. Our results from experiments with the MNIST + SVHN and Multimodal165 datasets indicate that combining the Gaussian mixture model (GMM), PoE multimodal VAE, and MH naming game substantially improved information sharing, knowledge formation, and data reconstruction.},
  archive      = {J_FROBT},
  author       = {Hoang, Nguyen Le and Taniguchi, Tadahiro and Hagiwara, Yoshinobu and Taniguchi, Akira},
  doi          = {10.3389/frobt.2023.1290604},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1290604},
  shortjournal = {Front. Robot. AI},
  title        = {Emergent communication of multimodal deep generative models based on metropolis-hastings naming game},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring human-robot cooperation with gamified user
training: A user study on cooperative lifting. <em>FROBT</em>,
<em>10</em>, 1290104. (<a
href="https://doi.org/10.3389/frobt.2023.1290104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-robot cooperation (HRC) is becoming increasingly relevant with the surge in collaborative robots (cobots) for industrial applications. Examples of humans and robots cooperating actively on the same workpiece can be found in research labs around the world, but industrial applications are still mostly limited to robots and humans taking turns. In this paper, we use a cooperative lifting task (co-lift) as a case study to explore how well this task can be learned within a limited time, and how background factors of users may impact learning. The experimental study included 32 healthy adults from 20 to 54 years who performed a co-lift with a collaborative robot. The physical setup is designed as a gamified user training system as research has validated that gamification is an effective methodology for user training. Human motions and gestures were measured using Inertial Measurement Unit (IMU) sensors and used to interact with the robot across three role distributions: human as the leader, robot as the leader, and shared leadership. We find that regardless of age, gender, job category, gaming background, and familiarity with robots, the learning curve of all users showed a satisfactory progression and that all users could achieve successful cooperation with the robot on the co-lift task after seven or fewer trials. The data indicates that some of the background factors of the users such as occupation, past gaming habits, etc., may affect learning outcomes, which will be explored further in future experiments. Overall, the results indicate that the potential of the adoption of HRC in the industry is promising for a diverse set of users after a relatively short training process.},
  archive      = {J_FROBT},
  author       = {Venås, Gizem Ateş and Stølen, Martin Fodstad and Kyrkjebø, Erik},
  doi          = {10.3389/frobt.2023.1290104},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1290104},
  shortjournal = {Front. Robot. AI},
  title        = {Exploring human-robot cooperation with gamified user training: A user study on cooperative lifting},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Versatile vacuum-powered artificial muscles through
replaceable external reinforcements. <em>FROBT</em>, <em>10</em>,
1289074. (<a href="https://doi.org/10.3389/frobt.2023.1289074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft pneumatic artificial muscles are a well actuation scheme in soft robotics due to its key features for robotic machines being safe, lightweight, and conformable. In this work, we present a versatile vacuum-powered artificial muscle (VPAM) with manually tunable output motion. We developed an artificial muscle that consists of a stack of air chambers that can use replaceable external reinforcements. Different modes of operation are achieved by assembling different reinforcements that constrain the output motion of the actuator during actuation. We designed replaceable external reinforcements to produce single motions such as twisting, bending, shearing and rotary. We then conducted a deformation and lifting force characterization for these motions. We demonstrated sophisticated motions and reusability of the artificial muscle in two soft machines with different modes of locomotion. Our results show that our VPAM is reusable and versatile producing a variety and sophisticated output motions if needed. This key feature specially benefits unpredicted workspaces that require a soft actuator that can be adjusted for other tasks. Our scheme has the potential to offer new strategies for locomotion in machines for underwater or terrestrial operation, and wearable devices with different modes of operation.},
  archive      = {J_FROBT},
  author       = {Mendoza, Mijaíl Jaén and Cancán, Sergio and Surichaqui, Steve and Centeno, Esteban and Vilchez, Ricardo and Bertoldi, Katia and Vela, Emir A.},
  doi          = {10.3389/frobt.2023.1289074},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1289074},
  shortjournal = {Front. Robot. AI},
  title        = {Versatile vacuum-powered artificial muscles through replaceable external reinforcements},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using skeletal position to estimate human error rates in
telemanipulator operators. <em>FROBT</em>, <em>10</em>, 1287417. (<a
href="https://doi.org/10.3389/frobt.2023.1287417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In current telerobotics and telemanipulator applications, operators must perform a wide variety of tasks, often with a high risk associated with failure. A system designed to generate data-based behavioural estimations using observed operator features could be used to reduce risks in industrial teleoperation. This paper describes a non-invasive bio-mechanical feature capture method for teleoperators used to trial novel human-error rate estimators which, in future work, are intended to improve operational safety by providing behavioural and postural feedback to the operator. Operator monitoring studies were conducted in situ using the MASCOT teleoperation system at UKAEA RACE; the operators were given controlled tasks to complete during observation. Building upon existing works for vehicle-driver intention estimation and robotic surgery operator analysis, we used 3D point-cloud data capture using a commercially available depth camera to estimate an operator’s skeletal pose. A total of 14 operators were observed and recorded for a total of approximately 8 h, each completing a baseline task and a task designed to induce detectable but safe collisions. Skeletal pose was estimated, collision statistics were recorded, and questionnaire-based psychological assessments were made, providing a database of qualitative and quantitative data. We then trialled data-driven analysis by using statistical and machine learning regression techniques (SVR) to estimate collision rates. We further perform and present an input variable sensitivity analysis for our selected features.},
  archive      = {J_FROBT},
  author       = {Piercy, Thomas and Herrmann, Guido and Cangelosi, Angelo and Zoulias, Ioannis Dimitrios and Lopez, Erwin},
  doi          = {10.3389/frobt.2023.1287417},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1287417},
  shortjournal = {Front. Robot. AI},
  title        = {Using skeletal position to estimate human error rates in telemanipulator operators},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Smart haptic gloves for virtual reality surgery simulation:
A pilot study on external ventricular drain training. <em>FROBT</em>,
<em>10</em>, 1273631. (<a
href="https://doi.org/10.3389/frobt.2023.1273631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart haptic gloves are a new technology emerging in Virtual Reality (VR) with a promise to enhance sensory feedback in VR. This paper presents one of the first attempts to explore its application to surgical training for neurosurgery trainees using VR-based surgery simulators. We develop and evaluate a surgical simulator for External Ventricular Drain Placement (EVD), a common procedure in the field of neurosurgery. Haptic gloves are used in combination with a VR environment to augment the experience of burr hole placement, and flexible catheter manipulation. The simulator was integrated into the training curriculum at the 2022 Canadian Neurosurgery Rookie Bootcamp. Thirty neurosurgery residents used the simulator where objective performance metrics and subjective experience scores were acquired. We provide the details of the simulator development, as well as the user study results and draw conclusions on the benefits added by the haptic gloves and future directions.},
  archive      = {J_FROBT},
  author       = {Boutin, Jonah and Kamoonpuri, Jafer and Faieghi, Reza and Chung, Joon and de Ribaupierre, Sandrine and Eagleson, Roy},
  doi          = {10.3389/frobt.2023.1273631},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1273631},
  shortjournal = {Front. Robot. AI},
  title        = {Smart haptic gloves for virtual reality surgery simulation: A pilot study on external ventricular drain training},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-free control for autonomous prevention of adverse
events in robotics. <em>FROBT</em>, <em>10</em>, 1271748. (<a
href="https://doi.org/10.3389/frobt.2023.1271748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Preventive control is a critical feature in autonomous technology to ensure safe system operations. One application where safety is most important is robot-assisted needle interventions. During incisions into a tissue, adverse events such as mechanical buckling of the needle shaft and tissue displacements can occur on encounter with stiff membranes causing potential damage to the organ.Methods: To prevent these events before they occur, we propose a new control subroutine that autonomously chooses a) a reactive mechanism to stop the insertion procedure when a needle buckling or a severe tissue displacement event is predicted and b) an adaptive mechanism to continue the insertion procedure through needle steering control when a mild tissue displacement is detected. The subroutine is developed using a model-free control technique due to the nonlinearities of the unknown needle-tissue dynamics. First, an improved version of the model-free adaptive control (IMFAC) is developed by computing a fast time-varying partial pseudo derivative analytically from the dynamic linearization equation to enhance output convergence and robustness against external disturbances.Results and Discussion: Comparing IMFAC and MFAC algorithms on simulated nonlinear systems in MATLAB, IMFAC shows 20% faster output convergence against arbitrary disturbances. Next, IMFAC is integrated with event prediction algorithms from prior work to prevent adverse events during needle insertions in real time. Needle insertions in gelatin tissues with known environments show successful prevention of needle buckling and tissue displacement events. Needle insertions in biological tissues with unknown environments are performed using live fluoroscopic imaging as ground truth to verify timely prevention of adverse events. Finally, statistical ANOVA analysis on all insertion data shows the robustness of the prevention algorithm to various needles and tissue environments. Overall, the success rate of preventing adverse events in needle insertions through adaptive and reactive control was 95%, which is important toward achieving safety in robotic needle interventions.},
  archive      = {J_FROBT},
  author       = {Narayan, Meenakshi and Majewicz Fey, Ann},
  doi          = {10.3389/frobt.2023.1271748},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1271748},
  shortjournal = {Front. Robot. AI},
  title        = {Model-free control for autonomous prevention of adverse events in robotics},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging pleat folds and soft compliant elements in
inflatable fabric beams. <em>FROBT</em>, <em>10</em>, 1267642. (<a
href="https://doi.org/10.3389/frobt.2023.1267642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inflatable fabric beams (IFBs) integrating pleat folds can generate complex motion by modifying the pleat characteristics (e.g., dimensions, orientations). However, the capability of the IFB to return to the folded configuration relies upon the elasticity of the fabrics, requiring additional pressure inputs or complementary mechanisms. Using soft compliant elements (SCEs) assembled onto pleat folds is an appealing approach to improving the IFB elasticity and providing a range of spatial configurations when pressurized. This study introduces an actuator comprising an IFB with pleat folds and SCEs. By methodologically assembling the SCEs onto the pleat folds, we constrain the IFB unfolding to achieve out-of-plane motion at 5 kPa. Besides, the proposed actuator can generate angular displacement by regulating the input pressure (&lt;mml:math id=&quot;m1&quot; xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mo&gt;&amp;gt;&lt;/mml:mo&gt;&lt;/mml:math&gt; 5 kPa). A matrix-based representation and model are proposed to analyze the actuator motion. We experimentally study the actuator’s angular displacement by modifying SCE shapes, fold dimensions, and assembly distances of SCEs. Moreover, we analyze the effects of incorporating two SCEs onto a pleat fold. Our results show that the actuator motion can be tuned by integrating SCEs with different stiffness and varying the pleat fold dimensions. In addition, we demonstrate that the integration of two SCEs onto the pleat fold permits the actuator to return to its folded configuration when depressurized. In order to demonstrate the versatility of the proposed actuator, we devise and conduct experiments showcasing the implementation of a planar serial manipulator and a soft gripper with two grasping modalities.},
  archive      = {J_FROBT},
  author       = {Huaroto, Juan J. and Suarez, Etsel and Kim, Wangdo and Vela, Emir A.},
  doi          = {10.3389/frobt.2023.1267642},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1267642},
  shortjournal = {Front. Robot. AI},
  title        = {Leveraging pleat folds and soft compliant elements in inflatable fabric beams},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asymmetric communication: Cognitive models of humans toward
an android robot. <em>FROBT</em>, <em>10</em>, 1267560. (<a
href="https://doi.org/10.3389/frobt.2023.1267560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the development of dialogue systems for android robots, the goal is to achieve human-like communication. However, subtle differences between android robots and humans are noticeable, leading even human-like android robots to be perceived differently. Understanding how humans accept android robots and optimizing their behavior is crucial. Generally, human customers have various expectations and anxieties when interacting with a robotic salesclerk instead of a human. Asymmetric communication arises when android robots treat customers like humans while customers treat robots as machines. Focusing on human-robot interaction in a tourist guide scenario, In this paper, we propose an asymmetric communication strategy that does not use estimation technology for preference information, but instead performs changing the agent’s character in order to pretend to tailor to the customer. In line with this, we prepared an experimental method to evaluate asymmetric communication strategies, using video clips to simulate dialogues. Participants completed questionnaires without prior knowledge of whether the salesclerk was human-like or robotic. The method allowed us to assess how participants treated the salesclerk and the effectiveness of the asymmetric communication strategy. Additionally, during our demonstration in a dialogue robot competition, 29 visitors had a positive impression of the android robot’s asymmetric communication strategy and reported a high level of satisfaction with the dialogue.},
  archive      = {J_FROBT},
  author       = {Kawakubo, Daisuke and Shuzo, Masaki and Sugiyama, Hiroaki and Maeda, Eisaku},
  doi          = {10.3389/frobt.2023.1267560},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1267560},
  shortjournal = {Front. Robot. AI},
  title        = {Asymmetric communication: Cognitive models of humans toward an android robot},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulating cardiac signals on 3D human models for
photoplethysmography development. <em>FROBT</em>, <em>10</em>, 1266535.
(<a href="https://doi.org/10.3389/frobt.2023.1266535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Image-based heart rate estimation technology offers a contactless approach to healthcare monitoring that could improve the lives of millions of people. In order to comprehensively test or optimize image-based heart rate extraction methods, the dataset should contain a large number of factors such as body motion, lighting conditions, and physiological states. However, collecting high-quality datasets with complete parameters is a huge challenge.Methods: In this paper, we introduce a bionic human model based on a three-dimensional (3D) representation of the human body. By integrating synthetic cardiac signal and body involuntary motion into the 3D model, five well-known traditional and four deep learning iPPG (imaging photoplethysmography) extraction methods are used to test the rendered videos.Results: To compare with different situations in the real world, four common scenarios (stillness, expression/talking, light source changes, and physical activity) are created on each 3D human. The 3D human can be built with any appearance and different skin tones. A high degree of agreement is achieved between the signals extracted from videos with the synthetic human and videos with a real human-the performance advantages and disadvantages of the selected iPPG methods are consistent for both real and 3D humans.Discussion: This technology has the capability to generate synthetic humans within various scenarios, utilizing precisely controlled parameters and disturbances. Furthermore, it holds considerable potential for testing and optimizing image-based vital signs methods in challenging situations where real people with reliable ground truth measurements are difficult to obtain, such as in drone rescue.},
  archive      = {J_FROBT},
  author       = {Wang, Danyi and Chahl, Javaan},
  doi          = {10.3389/frobt.2023.1266535},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1266535},
  shortjournal = {Front. Robot. AI},
  title        = {Simulating cardiac signals on 3D human models for photoplethysmography development},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparison of strength profile representations using
musculoskeletal models and their applications in robotics.
<em>FROBT</em>, <em>10</em>, 1265635. (<a
href="https://doi.org/10.3389/frobt.2023.1265635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Musculoskeletal models provide an approach towards simulating the ability of the human body in a variety of human-robot applications. A promising use for musculoskeletal models is to model the physical capabilities of the human body, for example, estimating the strength at the hand. Several methods of modelling and representing human strength with musculoskeletal models have been used in ergonomic analysis, human-robot interaction and robotic assistance. However, it is currently unclear which methods best suit modelling and representing limb strength. This paper compares existing methods for calculating and representing the strength of the upper limb using musculoskeletal models. It then details the differences and relative advantages of the existing methods, enabling the discussion on the appropriateness of each method for particular applications.},
  archive      = {J_FROBT},
  author       = {Sutjipto, Sheila and Carmichael, Marc G. and Paul, Gavin},
  doi          = {10.3389/frobt.2023.1265635},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1265635},
  shortjournal = {Front. Robot. AI},
  title        = {Comparison of strength profile representations using musculoskeletal models and their applications in robotics},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reactive optimal motion planning for a class of holonomic
planar agents using reinforcement learning with provable guarantees.
<em>FROBT</em>, <em>10</em>, 1255696. (<a
href="https://doi.org/10.3389/frobt.2023.1255696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In control theory, reactive methods have been widely celebrated owing to their success in providing robust, provably convergent solutions to control problems. Even though such methods have long been formulated for motion planning, optimality has largely been left untreated through reactive means, with the community focusing on discrete/graph-based solutions. Although the latter exhibit certain advantages (completeness, complicated state-spaces), the recent rise in Reinforcement Learning (RL), provides novel ways to address the limitations of reactive methods. The goal of this paper is to treat the reactive optimal motion planning problem through an RL framework. A policy iteration RL scheme is formulated in a consistent manner with the control-theoretic results, thus utilizing the advantages of each approach in a complementary way; RL is employed to construct the optimal input without necessitating the solution of a hard, non-linear partial differential equation. Conversely, safety, convergence and policy improvement are guaranteed through control theoretic arguments. The proposed method is validated in simulated synthetic workspaces, and compared against reactive methods as well as a PRM and an RRT⋆ approach. The proposed method outperforms or closely matches the latter methods, indicating the near global optimality of the former, while providing a solution for planning from anywhere within the workspace to the goal position.},
  archive      = {J_FROBT},
  author       = {Rousseas, Panagiotis and Bechlioulis, Charalampos and Kyriakopoulos, Kostas},
  doi          = {10.3389/frobt.2023.1255696},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1255696},
  shortjournal = {Front. Robot. AI},
  title        = {Reactive optimal motion planning for a class of holonomic planar agents using reinforcement learning with provable guarantees},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). “Ick bin een berlina”: Dialect proficiency impacts a robot’s
trustworthiness and competence evaluation. <em>FROBT</em>, <em>10</em>,
1241519. (<a href="https://doi.org/10.3389/frobt.2023.1241519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Robots are increasingly used as interaction partners with humans. Social robots are designed to follow expected behavioral norms when engaging with humans and are available with different voices and even accents. Some studies suggest that people prefer robots to speak in the user’s dialect, while others indicate a preference for different dialects.Methods: Our study examined the impact of the Berlin dialect on perceived trustworthiness and competence of a robot. One hundred and twenty German native speakers (Mage = 32 years, SD = 12 years) watched an online video featuring a NAO robot speaking either in the Berlin dialect or standard German and assessed its trustworthiness and competence.Results: We found a positive relationship between participants’ self-reported Berlin dialect proficiency and trustworthiness in the dialect-speaking robot. Only when controlled for demographic factors, there was a positive association between participants’ dialect proficiency, dialect performance and their assessment of robot’s competence for the standard German-speaking robot. Participants’ age, gender, length of residency in Berlin, and device used to respond also influenced assessments. Finally, the robot’s competence positively predicted its trustworthiness.Discussion: Our results inform the design of social robots and emphasize the importance of device control in online experiments.},
  archive      = {J_FROBT},
  author       = {Kühne, Katharina and Herbold, Erika and Bendel, Oliver and Zhou, Yuefang and Fischer, Martin H.},
  doi          = {10.3389/frobt.2023.1241519},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1241519},
  shortjournal = {Front. Robot. AI},
  title        = {“Ick bin een berlina”: Dialect proficiency impacts a robot’s trustworthiness and competence evaluation},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sound masking by a low-pitch speech-shaped noise improves a
social robot’s talk in noisy environments. <em>FROBT</em>, <em>10</em>,
1205209. (<a href="https://doi.org/10.3389/frobt.2023.1205209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: There has been a surge in the use of social robots for providing information, persuasion, and entertainment in noisy public spaces in recent years. Considering the well-documented negative effect of noise on human cognition, masking sounds have been introduced. Masking sounds work, in principle, by making the intrusive background speeches less intelligible, and hence, less distracting. However, this reduced distraction comes with the cost of increasing annoyance and reduced cognitive performance in the users of masking sounds.Methods: In a previous study, it was shown that reducing the fundamental frequency of the speech-shaped noise as a masking sound significantly contributes to its being less annoying and more efficient. In this study, the effectiveness of the proposed masking sound was tested on the performance of subjects listening to a lecture given by a social robot in a noisy cocktail party environment.Results: The results indicate that the presence of the masking sound significantly increased speech comprehension, perceived understandability, acoustic satisfaction, and sound privacy of the individuals listening to the robot in an adverse listening condition.Discussion: To the knowledge of the authors, no previous work has investigated the application of sound masking technology in human-robot interaction designs. The future directions of this trend are discussed.},
  archive      = {J_FROBT},
  author       = {Pourfannan, Hamed and Mahzoon, Hamed and Yoshikawa, Yuichiro and Ishiguro, Hiroshi},
  doi          = {10.3389/frobt.2023.1205209},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1205209},
  shortjournal = {Front. Robot. AI},
  title        = {Sound masking by a low-pitch speech-shaped noise improves a social robot’s talk in noisy environments},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How should robots exercise with people? Robot-mediated
exergames win with music, social analogues, and gameplay clarity.
<em>FROBT</em>, <em>10</em>, 1155837. (<a
href="https://doi.org/10.3389/frobt.2023.1155837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: The modern worldwide trend toward sedentary behavior comes with significant health risks. An accompanying wave of health technologies has tried to encourage physical activity, but these approaches often yield limited use and retention. Due to their unique ability to serve as both a health-promoting technology and a social peer, we propose robots as a game-changing solution for encouraging physical activity.Methods: This article analyzes the eight exergames we previously created for the Rethink Baxter Research Robot in terms of four key components that are grounded in the video-game literature: repetition, pattern matching, music, and social design. We use these four game facets to assess gameplay data from 40 adult users who each experienced the games in balanced random order.Results: In agreement with prior research, our results show that relevant musical cultural references, recognizable social analogues, and gameplay clarity are good strategies for taking an otherwise highly repetitive physical activity and making it engaging and popular among users.Discussion: Others who study socially assistive robots and rehabilitation robotics can benefit from this work by considering the presented design attributes to generate future hypotheses and by using our eight open-source games to pursue follow-up work on social-physical exercise with robots.},
  archive      = {J_FROBT},
  author       = {Fitter, Naomi T. and Mohan, Mayumi and Preston, Rhian C. and Johnson, Michelle J. and Kuchenbecker, Katherine J.},
  doi          = {10.3389/frobt.2023.1155837},
  journal      = {Frontiers in Robotics and AI},
  month        = {1},
  pages        = {1155837},
  shortjournal = {Front. Robot. AI},
  title        = {How should robots exercise with people? robot-mediated exergames win with music, social analogues, and gameplay clarity},
  volume       = {10},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
