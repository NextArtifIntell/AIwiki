<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJAIT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijait---67">IJAIT - 67</h2>
<ul>
<li><details>
<summary>
(2024). Toward responsible AI: A framework for ethical design
utilizing deontic logic. <em>IJAIT</em>, <em>33</em>(8), 2550003. (<a
href="https://doi.org/10.1142/S0218213025500034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to give a brief demonstration on how deontic logic can be used to help the design of robots capable of choice, equipped with artificial intelligence, by providing a framework that will help maintain ethically sound behavior. We begin by presenting an overview of the potential applications of robots and the expansion of their use in various areas of our society as well as the ethical concerns artificial intelligence and robots raise. Then, we give a quick introduction to deontic logic, highlighting its key concepts and explaining what it offers to the field of ethics. In the third part of the paper, we present our own approach to deontic logic, based on common sense reasoning. The fourth part includes three short applications of our common sense deontic logic approach in the field of artificial intelligence and robotics. These applications illustrate how deontic logic can be used to guide robots in making morally sound decisions, using examples from the health sector. In the final section, we have the conclusions of our paper as well as our limitations and plans for future research.},
  archive      = {J_IJAIT},
  author       = {Dimitrios Zafeirakopoulos and Petros Stefaneas},
  doi          = {10.1142/S0218213025500034},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {8},
  pages        = {2550003},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Toward responsible AI: A framework for ethical design utilizing deontic logic},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The maximum influence k-plex problem and its
branch-and-bound algorithm. <em>IJAIT</em>, <em>33</em>(8), 2550002. (<a
href="https://doi.org/10.1142/S0218213025500022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k -plex is a relaxation of the classical clique structure, which is usually used to characterize the cohesiveness of a subgroup in social networks. In this paper, we propose a new notion called the k - plex influence to depict the outward connection of a k -plex. The influence of a k -plex is defined as the number of outside vertices adjacent to the vertices of the k -plex. With the new notion, we can distinguish different k -plexes and find more pivotal subgroups in networks. We propose an exact algorithm to find the k -plex with the maximum influence. The algorithm implements a branch-and-bound approach, in which we integrate a novel upper bound and an effective preprocessing strategy. We conducted experiments to evaluate the performance of the algorithm and compared it with the general mixed integer linear programming approach. The results show that both the preprocessing strategy and the upper bound can effectively reduce the search space, and the proposed branch-and-bound algorithm can solve the problem in massive graphs effectively and has a significant performance advantage over the general mixed integer linear programming approach.},
  archive      = {J_IJAIT},
  author       = {Liangyao Peng and Xue Cheng and Zhifei Zheng and Zhongyou Tang and Hua Jiang},
  doi          = {10.1142/S0218213025500022},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {8},
  pages        = {2550002},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {The maximum influence k-plex problem and its branch-and-bound algorithm},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence management system of floating
nuclear reactors for implementing remote distributed energy
environments. <em>IJAIT</em>, <em>33</em>(8), 2550001. (<a
href="https://doi.org/10.1142/S0218213025500010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores future energy systems primarily powered by innovative floating reactors. These reactors exhibit high potential, particularly for supplying power to remote areas beyond the reach of traditional power grids. In this study, a novel artificial intelligence (AI) system is introduced to optimize the management of floating reactors in remote, distributed environments, where the reactors must move between different sites and energize their local grids. This research marks the first application of AI in providing management decisions for those reactor types in such distributed assembled environments. Specifically, an intelligent management system has been developed to coordinate the reactor’s operations across various sites. The proposed system leverages fuzzy logic tools, which enable it to account for multiple uncertain factors when making management decisions. The system’s performance is tested through simulated scenarios and benchmarked against a round-robin fixed time method. The results demonstrate the system’s efficiency in delivering both economic and operational benefits.},
  archive      = {J_IJAIT},
  author       = {Miltiadis Alamaniotis},
  doi          = {10.1142/S0218213025500010},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {8},
  pages        = {2550001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Artificial intelligence management system of floating nuclear reactors for implementing remote distributed energy environments},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advanced machine learning techniques for detecting
irregularities in skin lesion borders: Enhancing early skin cancer
detection. <em>IJAIT</em>, <em>33</em>(8), 2450024. (<a
href="https://doi.org/10.1142/S0218213024500246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dermatograms are pivotal in the early detection of skin cancer, a disease with significant mortality rates. This paper introduces a novel feature extraction method that captures irregularities in the boundaries of abnormal skin regions. Each raw dermatogram is converted into a binary mask image using an effective segmentation algorithm. The boundary of the lesion region is extracted from the mask. The boundary, together with the centroid of the lesion mask, is used to define a set of directional vectors. An Arc is defined using these directional vectors, and a new Arc feature is calculated based on the number of times the lesion boundary crosses the arc. The proposed Arc feature is evaluated using three standard skin lesion datasets: ISBI 2016, HAM10000, and PH2. Additionally, color features and Local Binary Pattern (LBP) features are implemented for comparison. Classical machine learning algorithms are employed to evaluate these features. Results indicate that for the ISBI 2016 and HAM10000 datasets, the Arc feature set demonstrates superior classification accuracy. In contrast, the PH2 dataset benefits more from the LBP feature. Comparative analysis with recent studies highlights the dependency of accuracy on datasets and classifiers, underscoring the necessity for models incorporating feature fusion and ensemble classifiers. The proposed method outperforms traditional color and texture features and shows competitive results against deep learning models, particularly in scenarios with limited computational resources. These findings suggest that the Arc feature is a promising approach for improving skin cancer detection, although further investigation is needed to fine-tune performance, optimize classifier selection, and explore feature fusion strategies.},
  archive      = {J_IJAIT},
  author       = {G. Raju and P. Nikesh and K. R. Resmi and Debabrata Swain and Biswaranjan Acharya and Vassilis C. Gerogiannis and Andreas Kanavos},
  doi          = {10.1142/S0218213024500246},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {8},
  pages        = {2450024},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Advanced machine learning techniques for detecting irregularities in skin lesion borders: Enhancing early skin cancer detection},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recommender system based on unsupervised clustering and
supervised deep learning. <em>IJAIT</em>, <em>33</em>(8), 2450016. (<a
href="https://doi.org/10.1142/S0218213024500167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the Recommender System (RS) has gained much attention in industry and academia. RS offers valuable ideas to users while interacting with a website or application. With the advancements in the mobile environment (ME), the users’ interest has turned to the movie recommendation system. This model overcomes the problem of surplus information about movies and offers users only the relevant items by analyzing their interests and preferences. This work presents a hybrid movie recommendation system based on unsupervised clustering and supervised deep learning. Here, the dataset used is the IMDB movie reviews dataset. The clustering technique used is adaptive density-based clustering or adaptive DBSCAN. Next, the similarity calculation is performed using the cosine similarity metric. Finally, the Convolutional Neural Network (CNN) model integrated with the Adaptive Red Deer (ARD) Optimization offers the most relevant depictions on the movie list with higher accuracy. The implementation is performed on the MATLAB simulation environment. The system’s performance is measured in terms of accuracy, recall, precision, F-measure, RMSE and MAE.},
  archive      = {J_IJAIT},
  author       = {Dheeraj Kumar Sahni and Dhiraj Khurana and Yogesh Kumar},
  doi          = {10.1142/S0218213024500167},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {8},
  pages        = {2450016},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Recommender system based on unsupervised clustering and supervised deep learning},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review on drug-to-drug interaction prediction
and cryptographic mechanism for secure drug discovery using AI
techniques. <em>IJAIT</em>, <em>33</em>(8), 2450003. (<a
href="https://doi.org/10.1142/S0218213024500039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, poly-pharmacy persistence has greatly improved in treating multiple diseases effectively. However, determining potential drug–drug interaction (DDIs) during the drug design is critical for controlling the target clinical drug during secure testing. In the medical field, DDIs are significant for disease diagnosis and treatment, mainly aiding researchers in predicting the link between biomolecules for efficient drug discovery (DD). Artificial intelligence (AI) has recently witnessed researchers accurately predict DDIs at minimum time consumption. Although the AI models show accurate results by aiding physicians to determine poly-pharmacy, several unresolvable issues remain in promoting reliability due to high error, complexity and cost-effectiveness. This paper aims to provide a comprehensive review using AI techniques (machine learning (ML)–deep learning (DL) models) and security enhancement techniques to improve DDI prediction and DD, respectively. The recent state of DDI prediction and the security concerns are presented initially, along with a short discussion about the need for effective techniques. Then, the critical evaluation related to existing studies is analyzed and compared to current issues faced in those existing studies. Various pharmaceutical drugs and their pros are also surveyed in addition to the security analysis for the newly invented drugs. Several assessment measures for the surveyed techniques are also conquered and put forth the need for advancements in future techniques effectively. The performance variations produced by the existing studies are also surveyed, and their use in the medical industry is also provided in this review study. The review of this research encourages the researchers to analyze the various issues faced in the pharmaceutical industry so that a novel technique can be introduced in the upcoming studies.},
  archive      = {J_IJAIT},
  author       = {K. Soni Sharmila and S. Thanga Revathi and Pokkuluri Kiran Sree},
  doi          = {10.1142/S0218213024500039},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {8},
  pages        = {2450003},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A systematic review on drug-to-drug interaction prediction and cryptographic mechanism for secure drug discovery using AI techniques},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discrete variational feature transfer learning for
skeleton-based abnormal behavior detection. <em>IJAIT</em>,
<em>33</em>(7), 2440009. (<a
href="https://doi.org/10.1142/S0218213024400098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based models have achieved promising performance for video behavior anomaly detection, but these models require high computational complexity for processing video data. Moreover, the performance is severely restricted by different challenges, i.e., lighting conditions, background noise and occlusion. The human skeleton has a compact spatial structure and rich semantic information, which can be more robust to video data defection. Although the human skeleton has good real-time performance, the recognition accuracy still needs further improvement. To this end, we propose a novel discrete variational feature transfer learning (DVFTL) framework in which the spatiotemporal graph-embedded Transformer module is designed to construct feature extraction backbones. Specifically, we extract human skeleton information from video frames, and combine graph convolution with the Transformer encoder to explore the local and global dependencies of joint points in the human skeleton. To analyze abnormal behavior uncertainty, we constructed the extraction network based on the discrete variational reconstruction mechanism. Moreover, to further improve the skeleton detection performance, we introduce the distillation transfer learning mechanism from the video variational network to the skeleton variational network. we conducted extensive comparative experiments on two publicly available datasets. The experimental results show that the skeleton-based variational network achieves high performance. Moreover, the introduction of the transfer learning mechanism can further improve the performance of our proposed model.},
  archive      = {J_IJAIT},
  author       = {Yuan Shu and Youren Wang and Min Zhang and Jie Yang and Yi Wang and Jun Wang and Yunbin Zhang},
  doi          = {10.1142/S0218213024400098},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {7},
  pages        = {2440009},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Discrete variational feature transfer learning for skeleton-based abnormal behavior detection},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain transfer-based hypergraph convolutional network for
posture anomaly detection in physical education teaching.
<em>IJAIT</em>, <em>33</em>(7), 2440008. (<a
href="https://doi.org/10.1142/S0218213024400086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human skeleton-based posture anomaly detection has been widely applied in the field of physical education teaching. The existing spatio-temporal graph convolutional networks (ST-GCN) can fully utilize the local and global information of the human skeleton for action recognition, but the entire model requires a large amount of computation and the modeling of high-order relationships between joint points of the human skeleton is insufficient. To this end, this paper proposes a novel domain adaptive hypergraph convolutional network for basketball posture anomaly analysis by exploiting 2D skeleton information. First, we designed an effective hypergraph convolution feature extraction network to improve the high-order dependency modeling. To further improve the performance of the hypergraph convolutional network, we introduce domain adaptive learning technology to supervise the feature extraction learning of the target domain (2D skeleton) through the source domain (3D skeleton). At last, we construct a basketball action teaching analysis dataset for model evaluation. We conducted a large number of comparative experiments on the public dataset NTU RGB+D and our self-built dataset. All the results showed that our proposed hypergraph convolutional model effectively extracts features of 2D human skeletons, and by introducing domain adaptive learning, the performance of basketball anomaly detection is further improved.},
  archive      = {J_IJAIT},
  author       = {Yuzhu Jin and Ning Liu},
  doi          = {10.1142/S0218213024400086},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {7},
  pages        = {2440008},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Domain transfer-based hypergraph convolutional network for posture anomaly detection in physical education teaching},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain adaptation infrared forest fire detection method
based on YOLOv5 framework. <em>IJAIT</em>, <em>33</em>(7), 2440007. (<a
href="https://doi.org/10.1142/S0218213024400074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep networks have achieved great success in forest fire detection by exploiting visible light images. However, visible light images are susceptible to strong light, smoke, and obstruction interference. The infrared image has high sensitivity to temperature changes of targets, which can alleviate the deficiency of visible light image. Due to the significant distribution shift between visible light and infrared images, directly using the visible light-based pre-trained network for infrared forest fire results in a significant decrease in performance. To resolve this issue, this paper proposes an infrared image forest fire detection system based on domain adaptive learning. We adopt two YOLOv5 frameworks to extract features from visible light images (source domain) and infrared images (target domain). To align the features of the two domains, we construct a novel adaptation learning mechanism based on Kullback–Leibler (KL) loss and feature maximum mean discrepancy (FMMD) loss. We conducted extensive comparative experiments on two publicly available datasets to verify the effectiveness of the proposed model. All experimental results indicate that our proposed domain adaptive learning mechanism effectively improves the performance of infrared forest fire detection.},
  archive      = {J_IJAIT},
  author       = {Huan He and Lei Wang and Enze Zhou and Ruizeng Wei and Shuqin Liu},
  doi          = {10.1142/S0218213024400074},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {7},
  pages        = {2440007},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Domain adaptation infrared forest fire detection method based on YOLOv5 framework},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward domain adaptive learning-based variation autoencoder
emotional analysis in english teaching. <em>IJAIT</em>, <em>33</em>(7),
2440006. (<a href="https://doi.org/10.1142/S0218213024400062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech emotion analysis plays an important role in English teaching by analyzing the reading state of students. Teachers can dynamically adjust the teaching content according to the emotional feedback of students and improve the teaching quality of the school. Due to unstable student emotions and background noise, the accuracy of speech emotion recognition is constrained. Although multimodal data can alleviate the deficiency of a single modality, collecting and annotating multimodal samples requires a significant amount of resources. To resolve this issue, this paper proposes a novel multimodal sentiment analysis framework based on domain adaptive learning mechanisms to assist English teaching. We construct a novel multi-task variation autoencoder framework in which we simultaneously complete reconstruction and classification tasks. To improve speech emotion recognition performance, we introduce domain adaptive learning based on the Wasserstein distance between two variational hidden layers from the video domain (source domain) and speech domain (target domain). To validate the effectiveness of our proposed model, we conducted extensive comparative experiments on two public datasets and a self-built English oral dataset. All experimental results indicate that domain adaptation learning mechanisms can effectively improve the recognition performance of the target domain. On the self-built dataset for English teaching, the proposed model achieves higher performance compared to other deep models.},
  archive      = {J_IJAIT},
  author       = {Xue Wang},
  doi          = {10.1142/S0218213024400062},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {7},
  pages        = {2440006},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Toward domain adaptive learning-based variation autoencoder emotional analysis in english teaching},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Path planning for mobile robots using transfer reinforcement
learning. <em>IJAIT</em>, <em>33</em>(7), 2440005. (<a
href="https://doi.org/10.1142/S0218213024400050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The path planning of mobile robots helps robots to perceive environment using the information obtained from sensors and plan a route to reach the target. With the increasing difficulty of task, the environment the mobile robots face becomes more and more complex. Traditional path planning methods can no longer meet the requirements of mobile robot navigation in complex environment. Deep reinforcement learning (DRL) is introduced into robot navigation However, it may be time-consuming to train DRL model when the environment is very complex and the existing environment may differ from the unknown environment. In order to handle the robot navigation in heterogeneous environment, this paper utilizes deep transfer reinforcement learning (DTRL) for mobile robot path planning. Compared with DRL, DTRL does not require the distribution of the existing environment is the same as that of the unknown environment. Additionally, DTRL can transfer the knowledge of existing model to new scenario to reduce the training time. The simulations show that DTRL can reach higher success rate than DRL for heterogeneous environment robot navigation. By using local policy, it costs less time to train DTRL than DRL for a complex environment and DTRL can consume less navigation time.},
  archive      = {J_IJAIT},
  author       = {Xinwang Zheng and Wenjie Zheng and Yong Du and Tiejun Li and Zhansheng Yuan},
  doi          = {10.1142/S0218213024400050},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {7},
  pages        = {2440005},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Path planning for mobile robots using transfer reinforcement learning},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Music emotion intensity estimation using transfer ordinal
label learning under heterogeneous scenes. <em>IJAIT</em>,
<em>33</em>(7), 2440004. (<a
href="https://doi.org/10.1142/S0218213024400049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music emotion recognition plays an important role in many applications such as music material library construction and music recommendation system. The current music emotion recognition mainly focuses on discrete emotions or continuous emotions under single scene. However, on the one hand, intensity is one of important aspects of emotion, which can be represented as emotion rank or ordinal class. On the other hand, there may be not enough music emotion data in training set, which needs to transfer music emotion recognition model learnt from the music data in a source domain. The distribution of existing music data in target domain may differ from target music dataset. In order to overcome these two issues, this paper proposes to utilize transfer ordinal label learning (TOLL) to estimate music emotion. Compared with the previous works, TOLL-based music emotion intensity estimation implements music intensity estimation through transferring the knowledge in the existing source domain to unknown target domain. The experiments on several datasets show that TOLL can achieve promising results for emotion intensity estimation in single scene or across different scenes.},
  archive      = {J_IJAIT},
  author       = {Yiying Liu},
  doi          = {10.1142/S0218213024400049},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {7},
  pages        = {2440004},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Music emotion intensity estimation using transfer ordinal label learning under heterogeneous scenes},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rolling bearing fault detection using domain
adaptation-based anomaly detection. <em>IJAIT</em>, <em>33</em>(7),
2440003. (<a href="https://doi.org/10.1142/S0218213024400037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearings play an important role in rotating machinery. According to statistics, rolling bearings cause one-third faults of rotating machinery. Once a rolling bearing malfunctions, it may induce maintenance, affect work efficiency, or even cause the entire equipment to malfunction. Therefore, accurately determining the operating status of bearings is of great significance for maintaining the health of the rotating machinery. Most current fault detections of rolling bearing works focus on traditional anomaly detection models which assume the training set to follow the same distribution of test set. This assumption does not hold in fault detection of rolling bearings across different conditions and traditional anomaly detection models may be invalid. This paper introduces domain adaptation anomaly detection (DAAD) in the fault detection of rolling bearings to address this issue. DAAD can adapt anomaly detection across different distributions. The experiments of rolling bearing fault detection under single condition or across different condition show that DAAD is superior to most of the traditional anomaly detection models.},
  archive      = {J_IJAIT},
  author       = {Liantong Qin},
  doi          = {10.1142/S0218213024400037},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {7},
  pages        = {2440003},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Rolling bearing fault detection using domain adaptation-based anomaly detection},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Economic data forecasting through interval data analysis.
<em>IJAIT</em>, <em>33</em>(7), 2440002. (<a
href="https://doi.org/10.1142/S0218213024400025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important reflection of the national economy system, stock market is closely related to the development of a country, which has received widespread attention of researchers in the economics. With the daily trading of the stock market, stock price forecasting has gradually been one of the common concerns in the economic analysis. Compared with traditional forecasting task, the stock price is interval data which can be handled by interval data regression or multi-output regression. Previous stock forecasting merely considers the stock price in homogeneous scenarios. However, the price distributions from different stocks may be heterogeneous. It is a challenging task to analyze the relationship between different stocks which follow heterogeneous distributions. In order to forecast stocks in heterogeneous scenarios, this paper introduces multi-output transfer learning into stock price forecasting. Compared with traditional regression or multi-output regression models, the multi-output transfer regression can predict opening price, closing price, highest price and lowest price of stocks and utilize source domain of a known stock to enhance the prediction of target stock price which may have limited known data in training set. The experimental results on four public market indices demonstrate the effectiveness of multi-output transfer regression for stock price forecasting.},
  archive      = {J_IJAIT},
  author       = {Yan Cheng and Jinwen Su},
  doi          = {10.1142/S0218213024400025},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {7},
  pages        = {2440002},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Economic data forecasting through interval data analysis},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy rule-based heterogeneous domain adaptive: A case study
of particle motion in flow field from simulation to experiment.
<em>IJAIT</em>, <em>33</em>(7), 2440001. (<a
href="https://doi.org/10.1142/S0218213024400013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In fluid mechanics research, understanding the motion behavior of particles in a flow field is crucial for comprehending particle transport, mixing, and deposition processes. However, due to the complex interactions between particles and fluids, a single method is insufficient to accurately describe the particle motion. To tackle this problem, this study proposes an unsupervised heterogeneous domain adaptation method based on fuzzy principles, called Particle Flow Motion Analysis (PMFA). First, the data originating from both the source and target domains are preprocessed and subjected to Principal Component Analysis (PCA). Then, fuzzy rules are introduced for feature selection. Finally, the Maximum Mean Discrepancy (MMD) and Canonical Correlation Analysis (CCA) algorithms are employed to optimize the distribution disparities and correlations between the heterogeneous domains. By constructing domain adaptation tasks and comparing with five other methods, the performance of the proposed method is evaluated. The results demonstrate that the PFMA achieves an average accuracy of 89.44%, an average recall rate of 85.87%, and an F 1 value of 89.26% across four tasks, outperforming the other five comparative methods. The proposed method holds significant importance in gaining in-depth understanding of particle motion phenomena in fluids and revealing the underlying physical mechanisms and patterns.},
  archive      = {J_IJAIT},
  author       = {Changguo Liu and Jing Nie and Yang Li and Jingbin Li and Yujie Qiao},
  doi          = {10.1142/S0218213024400013},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {7},
  pages        = {2440001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Fuzzy rule-based heterogeneous domain adaptive: A case study of particle motion in flow field from simulation to experiment},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The automation of science? Possibilities and boundaries of
AI applications for conducting systematic literature reviews.
<em>IJAIT</em>, <em>33</em>(6), 2450023. (<a
href="https://doi.org/10.1142/S0218213024500234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Science automation, driven by advanced technologies, such as artificial intelligence (AI), is reshaping research in a variety of disciplines. The exponential growth of publications increases the need for automation in systematic literature reviews (SLRs). In this study, we investigated how AI applications support SLRs at different stages. After evaluating twenty-two AI applications, we identified the most useful based on their functionalities in the SLR process. This study provides important insights into the dynamic interplay between science automation, AI, and a systematic literature review. The main contribution is the identification and discussion of the relevance of the analyzed applications at different stages of the systematic literature review. We also discuss the potential for the automation and augmentation of research activities to address various scientific problems.},
  archive      = {J_IJAIT},
  author       = {Przemysław Tomczyk and Philipp Brüggemann and Tymoteusz Doligalski},
  doi          = {10.1142/S0218213024500234},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2450023},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {The automation of science? possibilities and boundaries of AI applications for conducting systematic literature reviews},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on intelligent digital manufacturing platform based
on artificial intelligence deep neural network. <em>IJAIT</em>,
<em>33</em>(6), 2450022. (<a
href="https://doi.org/10.1142/S0218213024500222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s information age, intelligent manufacturing has become a significant trend of future industrial development. The neural network plays a vital role as the basis of smart manufacturing. This is a kind of intelligent algorithm that can simulate human brain organization, with strong learning ability and computing power, and has achieved remarkable results in the application field; the most typical representative is deep neural network, especially in recent years, an artificial intelligence developed based on deep neural network has entered the application stage, providing a new idea and model for industrial production. Based on this, taking the clothing production process as an example, this paper combined transfer learning and network fine-tuning technology to build a Faster RCNN model based on the ResNet-101 network to realize the positioning and recognition of clothing style map features and create an intelligent generation platform for clothing process flow on this basis.},
  archive      = {J_IJAIT},
  author       = {Ming Wu and Long Ye and Huijie Han and Jun Tong and Zhenguo Wang},
  doi          = {10.1142/S0218213024500222},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2450022},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Research on intelligent digital manufacturing platform based on artificial intelligence deep neural network},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hypertension detection through speech analysis using machine
learning-based approaches with the identification of BP sensitive
phonemes and features. <em>IJAIT</em>, <em>33</em>(6), 2450021. (<a
href="https://doi.org/10.1142/S0218213024500210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are certain difficulties and unpleasant issues related to conventional diagnostic tools. These factors tilted the researchers toward finding an alternative non-invasive way of diagnosis. This alternate approach usually involves physiological and lifestyle-related data. The non-invasive tools are more convenient for common people as they are user-friendly and have no side effects. At the same time, they are cost-effective as well. The non-invasive diagnosis is also preferred by the people who live in places where medical facilities are not abundant. This study concentrates on detecting a person as hypertensive by analyzing certain parameters in speech using machine learning approaches. We identify some phonemes and features of speech that are more sensitive to capture the distortions in speech due to hypertension. Four different machine learning methods involving both classical and state-of-the-art methods in our study show the effectiveness of both types of machine learning methods in different dimensions. The study shows inspiring results in terms of prediction accuracy ( ∼ 95%) as well as identifying a minimal set of hypertension-sensitive features. It is also found that when we combine the predictions of both classical and state-of-the-art methods, the result gives more reliable predictions.},
  archive      = {J_IJAIT},
  author       = {Mousumi Malakar and Ravindra B. Keskar and Ajit Zadgaonkar},
  doi          = {10.1142/S0218213024500210},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2450021},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Hypertension detection through speech analysis using machine learning-based approaches with the identification of BP sensitive phonemes and features},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing constraint acquisition through hybrid learning: An
integration of passive and active learning strategies. <em>IJAIT</em>,
<em>33</em>(6), 2450020. (<a
href="https://doi.org/10.1142/S0218213024500209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraint Programming (CP) is a successful methodology for solving combinatorial problems from various domains. Efficiently modeling the problem at hand as a Constraint Satisfaction Problem is a crucial, but difficult task in CP. Toward this, a recent approach that is attracting increasing interest is Constraint Acquisition, i.e., the (semi)automatic learning of constraints through examples of solutions and non-solutions. This paper introduces a hybrid methodology that combines passive and active learning strategies to acquire both global and fixed arity constraints. This hybrid approach leverages the strengths of both techniques to address their individual limitations. Passive learning rapidly learns constraints from example solutions, while active learning refines and contextualizes constraints through user interaction. The core of the methodology consists of a passive learning module where subsets of variables are compared against global constraints and are validated using a CP solver. Constraints consistently present across multiple solution sets are identified as global constraints that belong to the model. Then, fixed arity constraints are refined through an active learning module with user input. Experiments across various problem types, from simple to complex, demonstrate the efficiency of the proposed hybrid methodology.},
  archive      = {J_IJAIT},
  author       = {Vasileios Balafas and Dimosthenis C. Tsouros and Nikolaos Ploskas and Kostas Stergiou},
  doi          = {10.1142/S0218213024500209},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2450020},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Enhancing constraint acquisition through hybrid learning: An integration of passive and active learning strategies},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overcoming the limitations of learning-based VQA for
counting questions with zero-shot learning. <em>IJAIT</em>,
<em>33</em>(6), 2450019. (<a
href="https://doi.org/10.1142/S0218213024500192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual question answering (VQA) research has garnered increasing attention in recent years. It is considered a visual Turing test because it requires a computer to respond to textual questions based on an image. Expertise in computer vision, natural language processing, knowledge understanding, and reasoning is required to solve the problem of VQA. Most techniques employed for VQA consist of models that are developed to learn the combination of image and question features along with the expected answer. The techniques chosen for image and question feature extraction and combining the features change with each model. This method of teaching a model of the question–answer pattern is ineffective for queries that involve counting and reasoning. This approach also requires considerable resources and large datasets for the training. The general VQA datasets feature a restricted number of items as responses to counting questions ( &lt; 1 0 ), and the distribution of the answers is not uniform. To investigate these issues in VQA, we created synthetic datasets that could be modified to adjust the number of objects in the image and the amount of occlusion. Specifically, a zero-shot learning VQA system was devised for counting-related questions that provide answers by analyzing the output of an object detector and the query keywords. Using synthetic datasets, our model generated 100% correct results. Testing on the benchmark datasets task directed image understanding challenge (TDIUC) and TallyQA-simple indicated that the proposed model matched the performance of the learning-based baseline models. This methodology can be used efficiently for counting VQA questions confined to certain domains when the number of items to be counted is significant.},
  archive      = {J_IJAIT},
  author       = {A. Lubna and Saidalavi Kalady},
  doi          = {10.1142/S0218213024500192},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2450019},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Overcoming the limitations of learning-based VQA for counting questions with zero-shot learning},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A recurrent stochastic configuration network for dynamic
system modeling and its application. <em>IJAIT</em>, <em>33</em>(6),
2450018. (<a href="https://doi.org/10.1142/S0218213024500180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to model nonlinear dynamic systems quickly and accurately, a recurrent stochastic configuration network (RSCN) with universal approximation ability is proposed in this paper. The method consists of network parameter learning and network structure determination. The network parameter learning strategy consists of input weights and the biases of hidden nodes generated randomly through a supervision mechanism, while the output weights of hidden nodes are determined by solving the least-squares problem. The network structure is determined incrementally by the training error of a single-layer recurrent neural network. The effectiveness of RSCN is tested and evaluated by using three nonlinear dynamic functions and historical data from a municipal solid waste incineration (MSWI) process. The experimental results show that the proposed method can improve modeling accuracy and reduce training time, which is valuable for applications in the field of industrial process modeling.},
  archive      = {J_IJAIT},
  author       = {Aijun Yan and Jingcheng Guo},
  doi          = {10.1142/S0218213024500180},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2450018},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A recurrent stochastic configuration network for dynamic system modeling and its application},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient deep learning mechanism for predicting fake
news/reviews in twitter data. <em>IJAIT</em>, <em>33</em>(6), 2450006.
(<a href="https://doi.org/10.1142/S0218213024500064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, social media platforms have been widely utilized as information sources due to their effortless accessibility and reduced costs. However, online platforms like Instagram, Twitter and Facebook get influenced by their users via fake news/reviews. The main intention of spreading fake news is to mislead other network users, which highly affects businesses, political parties, etc. Thus, an effective methodology is needed to predict fake news from social media automatically. The major objective of this proposed study is to identify and classify the given Twitter input data as real or fake through deep learning mechanisms. The proposed study involves four stages: pre-processing, embedded word analysis, feature extraction, and fake news/reviews prediction. Initially, pre-processing is performed to enhance the quality of data with the help of tokenization, stemming and stop word removal. Embedded word analysis is done using Advanced Word2Vec and GloVe modeling to enhance the performance of a proposed prediction model. Then, the hybrid deep learning model named Dense Convolutional assisted Gannet Optimal Bi-directional Network (DC_GO_BiNet) is introduced for feature extraction and prediction. A Dense Convolutional Neural Network (DCNN) is hybridized with a bi-directional long-short-term memory (Bi-LSTM) model to extract the essential features and predict fake news from the given input text. Also, the proposed model’s parameters are fine-tuned by adopting a gannet optimization (GO) algorithm. The proposed study used three different datasets and obtained higher classification accuracy as 99.5% in Fake News Detection on Twitter EDA, 99.59% in FakeNewsNet and 99.51% in ISOT. The analysis proves that the proposed model attains higher prediction results for each dataset than others.},
  archive      = {J_IJAIT},
  author       = {K. Parimala Kanaga Devan and G. S. Anandha Mala},
  doi          = {10.1142/S0218213024500064},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {6},
  pages        = {2450006},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {An efficient deep learning mechanism for predicting fake News/Reviews in twitter data},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond ROUGE: A comprehensive evaluation metric for
abstractive summarization leveraging similarity, entailment, and
acceptability. <em>IJAIT</em>, <em>33</em>(5), 2450017. (<a
href="https://doi.org/10.1142/S0218213024500179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A vast amount of textual information on the internet has amplified the importance of text summarization models. Abstractive summarization generates original words and sentences that may not exist in the source document to be summarized. Such abstractive models may suffer from shortcomings such as linguistic acceptability and hallucinations. Recall-Oriented Understudy for Gisting Evaluation (ROUGE) is a metric commonly used to evaluate abstractive summarization models. However, due to its n -gram-based approach, it ignores several critical linguistic aspects. In this work, we propose Similarity, Entailment, and Acceptability Score (SEAScore), an automatic evaluation metric for evaluating abstractive text summarization models using the power of state-of-the-art pre-trained language models. SEAScore comprises three language models (LMs) that extract meaningful linguistic features from candidate and reference summaries and a weighted sum aggregator that computes an evaluation score. Experimental results show that our LM-based SEAScore metric correlates better with human judgment than standard evaluation metrics such as ROUGE-N and BERTScore.},
  archive      = {J_IJAIT},
  author       = {Mohammed Khalid Hilmi Briman and Beytullah Yildiz},
  doi          = {10.1142/S0218213024500179},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2450017},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Beyond ROUGE: A comprehensive evaluation metric for abstractive summarization leveraging similarity, entailment, and acceptability},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward a hybrid approach combining deep learning and
case-based reasoning for phishing email detection. <em>IJAIT</em>,
<em>33</em>(5), 2450015. (<a
href="https://doi.org/10.1142/S0218213024500155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phishing attacks are increasing every year, both in terms of number and technique. Using only human weaknesses, an attacker can easily obtain the victim’s credentials or access their network. The problem persists despite many approaches offered by researchers, due to its dynamic nature, in which new phishing tactics are created every time. We, therefore, need more robust and effective methods to detect phishing emails. In this paper, we aim to detect phishing emails using the body text of the email with the hybrid approach combining case-based reasoning (CBR) and a deep learning model. Our proposed model, called DL-CBR, consists of a Bidirectional Long Short-Term Memory (Bi-LSTM) + Temporal Convolutional Network (TCN) network with an attention mechanism followed by a CBR classifier. The deep learning model is used for email representation, where it is trained using the N -pair loss function. To demonstrate the performance of DL-CBR, evaluation metrics, such as precision, accuracy, recall, and F-measure, were used, where we obtained an accuracy of 98.28%. The results show that our model outperformed other CBRs that utilize classical text representations like TF-IDF and Bag-of-Words. Additionally, while our model’s performance is slightly below that of the state-of-the-art models, it offers several advantages inherent to CBR. For instance, it can learn from new cases and update their database accordingly.},
  archive      = {J_IJAIT},
  author       = {Mohamed Abdelkarim Remmide and Fatima Boumahdi and Narhimene Boustia},
  doi          = {10.1142/S0218213024500155},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2450015},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Toward a hybrid approach combining deep learning and case-based reasoning for phishing email detection},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing speech assistive systems through a
sequence-to-vector representation approach for disordered speech.
<em>IJAIT</em>, <em>33</em>(5), 2450014. (<a
href="https://doi.org/10.1142/S0218213024500143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech assistive system for people with neuro disorders is a highly challenging task till date. Any kind of neuro cognitive disability affects the speech production mechanism that leads to speech impairment. Representation learning methods have recently emerged to improve the outcome of machine learning algorithms. In case of complex recognition tasks such as disordered speech recognition, learning compact and efficient representations for disordered speech utterances is important. Recent deep learning-based architectures need sufficiently large amount of impaired speech samples which are tedious with respect to neurologically disabled people. In this work, we focus on proposing a representation learning approach that uses traditional sequential model such as Hidden Markov Model (HMM) which works moderately well with small amount of impaired speech data. We propose a novel sequence to vector-based HMM State Sequence (HMM-SS) approach which is very compact and has proved to be an efficient representation for disordered speech utterances. The efficiency of the proposed HMM-SS approach is assessed using four datasets, namely 50 words of TORGO, 100-common words dataset of the UA-SPEECH, 50 help-seeking words and 100-common words of Impaired speech corpus in Tamil corpus. The proposed approach outperforms the baseline HMM, DNN-HMM and a recent state-of-the-art approach for all four datasets. The discriminative ability and the compactness of the proposed representation proved effective for disordered speech recognition.},
  archive      = {J_IJAIT},
  author       = {S. Vishnika Veni and B. Santhi},
  doi          = {10.1142/S0218213024500143},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2450014},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Enhancing speech assistive systems through a sequence-to-vector representation approach for disordered speech},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emotion-driven energy load forecasting: An ensemble
leveraging insights from news. <em>IJAIT</em>, <em>33</em>(5), 2450013.
(<a href="https://doi.org/10.1142/S0218213024500131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern times, system energy load forecasting is an extremely important process in a variety of contexts. Moreover, energy load time series fluctuations are influenced by a wide range of factors, ranging, inter alia, from environmental conditions, natural events, and demographics to both regional and global geopolitical contexts, economic conditions, energy sources, policies, and regulations. Given these, this paper examines the integration of news information from the global scene into Greek energy load forecasting schemes through the use of sentiment analysis. Investigating the ways the general emotional footprint of news worldwide affects and can be used in an energy modeling context, we benchmark possible ensemble configurations incorporating a multitude of 31 emotion polarities. Building on our previous work, an ensemble method that exploits specific outputs from a multi-label sentiment classifier and a sentiment analysis procedure under a multivariate forecasting scheme is presented. It is shown, through an empirical evaluation of the results, that the integration of emotion representations related to non-Greek news concerning global current affairs improves the predictions.},
  archive      = {J_IJAIT},
  author       = {Charalampos M. Liapis and Aikaterini Karanikola and Sotiris Kotsiantis},
  doi          = {10.1142/S0218213024500131},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2450013},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Emotion-driven energy load forecasting: An ensemble leveraging insights from news},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust clustering-based automated video shot boundary
detection using handcrafted and deep feature fusion. <em>IJAIT</em>,
<em>33</em>(5), 2450010. (<a
href="https://doi.org/10.1142/S0218213024500106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video shot boundary detection (VSBD) plays a key role in analyzing, summarizing, indexing and retrieving content-based data from videos. Many artificial intelligence (AI)-based techniques have recently been introduced to detect the gradual transition from video frames. However, those techniques fail to detect the presence of inter-classes like fade-in, fade-out and dissolve from gradual transition video frames. In addition, the existing techniques face high computational complexity during detecting transitions from the video frames. This research brings novel clustering-based techniques to classify the inter-classes like fade-in, fade-out and dissolve from gradual transition video frames. At the initial stage, color histogram differences (CHD) technique is introduced to detect the abrupt transition from the video frames. The identified abrupt transitions are completely removed from the video frames. Then, segmentation is done to segment the gradual transitions from the video frames. The segmented gradual transition frames are then given to extract the handcrafted and deep features from the video frames. The deep features are extracted from the segments using the Morlet Wavelet-assisted modified stacked autoencoder (MW-MSAE) technique. The extracted handcrafted features and deep features are then concatenated together, and finally, fused feature vectors are obtained. The fused features are then fed to the robust deep k -means map clustering method (RDKMM) to aggregate based on similar features. For calculating the similar features, a similarity-based correlation calculation (SBCC) is done in adjacent frames to determine gradual shot transitions like fade-in, fade-out and dissolve. The dataset used in this research is the TREC Video Retrieval Evaluation (TRECVID) 2021 dataset. In the experimental scenario, an accuracy of 95.5%, a sensitivity of 95.3%, a specificity of 96.9%, a precision of 93.9%, an F-measure of 94.6% and Mathew’s correlation coefficient (MCC) of 92.4% are obtained.},
  archive      = {J_IJAIT},
  author       = {Ravi Mishra and Priyanka Nandkishor Chopkar and Vishal Moyal and Devashree Shrish Marotkar and Vivek Rajkumar Kapur},
  doi          = {10.1142/S0218213024500106},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2450010},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Robust clustering-based automated video shot boundary detection using handcrafted and deep feature fusion},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient online big data stream clustering using dual
interactive wasserstein generative adversarial network. <em>IJAIT</em>,
<em>33</em>(5), 2450009. (<a
href="https://doi.org/10.1142/S021821302450009X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous real-world applications, such as online gaming, video streaming, and internet calls are streamed enormous volumes of data. So it is important to quickly process data streams in real-time. Data clustering methods are historically effective and efficient in extracting data from large datasets. Typically, they are ineffective for online data stream clustering. Therefore, an efficient online big data stream clustering using dual interactive Wasserstein generative adversarial network (OBDSC-DI-WGAN) is proposed in this paper. The proposed method consists of three phases: data initialization, online clustering, offline clustering. Initially, the input data are taken from Forest Cover Type dataset. During initialization phase, the dimensions of the input data can be reduced using kernel co-relation approach. After the initialization, the dimension-reduced data are fed to the dual interactive Wasserstein generative adversarial network (DI-WGAN) to accomplish efficient data stream clustering. Then the data enter the selected grid during the stage of online clustering. Afterward, the data stream is activated through the stage of online clustering and the data are activated in the stage of offline depending upon user request. The grid is regarded as a virtual data point in its geometric center during the offline phase. The density radius along cluster centers is determined under Billiards-inspired optimization algorithm. Finally, the clustering outcome is derived from optimum density radius. The proposed technique is activated in MATLAB, and its efficiency is analyzed under some performance metrics, such as accuracy, dice coefficient, purity, sensitivity, specificity, precision, processing time and jacquard coefficient. The proposed method provides better accuracy 27.5%, 10.32% and 16.65%, better precision 30.93%, 11.14% and 15.3% compared with existing methods, like fast grid-based clustering approach for hybrid data stream (FGCH-CCFD-OBDSC), optimized deep autoencoder including CNN for non-stationary environments surveillance data streams (DAE-CNN-OBDSC) and asynchronous dual-pipeline deep learning framework for online data stream classification (1D-CNN-OBDSC) respectively.},
  archive      = {J_IJAIT},
  author       = {Suresh Matheswaran and Nandhagopal Nachimuthu and G. Prakash},
  doi          = {10.1142/S021821302450009X},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2450009},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Efficient online big data stream clustering using dual interactive wasserstein generative adversarial network},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Summary augmenter: A text augmentation framework to improve
summarization quality. <em>IJAIT</em>, <em>33</em>(5), 2450005. (<a
href="https://doi.org/10.1142/S0218213024500052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation in Natural Language Processing (NLP) faces various challenges that hinder its widespread adoption, unlike its ever-present usage in the field of vision. It is even more the case for the text summarization task where one should focus on both article and summary. In this paper, we review the effect of back translation augmentation, present the diverse beam search decoding strategy, and masking as a method to generate synthetic data for text summarization. The approaches will be evaluated by ROUGE score, novelty, summary length, and GPT-4 to analyze their effectiveness. Our proposed framework presents multiple combinations of back translation and masking for articles, along with diverse augmentation for summaries. Although applicable to networks of any size, we decided to use BART-large, a relatively smaller model, in order to conduct a larger number of experiments. The experiments demonstrated superior performance across all specified metrics when compared to fine-tuning BART-large on the CNN/Dailymail dataset. Specifically, we showed a significant improvement in novelty; 158% and 56% increase rate for bigrams and unigrams, respectively. It could eliminate some copyright concerns around generating content similar to human writing. Additionally, the GPT-4 assessment indicates that models trained using the augmentation technique tend to capture important information more effectively than the baseline model.},
  archive      = {J_IJAIT},
  author       = {Ala Alam Falaki and Robin Gras},
  doi          = {10.1142/S0218213024500052},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2450005},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Summary augmenter: A text augmentation framework to improve summarization quality},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Metrics for domain shift characterization: Comparisons and
new directions. <em>IJAIT</em>, <em>33</em>(5), 2450002. (<a
href="https://doi.org/10.1142/S0218213024500027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation is an important area of research, as it aims to remedy the effects of the domain shift due to differences in the distribution between the source domain used for training and the target domain where prediction takes place. However, methods for characterizing the domain shift across datasets are lacking. In this work, we propose a domain shift metric called SpOT, which stands for spherical optimal transport, by operating on the spherical manifold. We realize our approach with a spherical network, used to obtain features, and an orthogonal projection loss, used to impose orthogonality in the feature space. The resulting spherical features have better inter-class separation and lower intra-class variation compared to features in Euclidean space. This type of feature clustering makes each domain representation more compact and more suitable for further analysis. The domain shift between the datasets is calculated using the optimal transport on the spherical features, which has a sound theoretical basis. Our results are further supported by experiments that show the correlation of SpOT with a new gain of transfer measure across domain adaptation datasets.},
  archive      = {J_IJAIT},
  author       = {Navya Nagananda and Andreas Savakis},
  doi          = {10.1142/S0218213024500027},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {5},
  pages        = {2450002},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Metrics for domain shift characterization: Comparisons and new directions},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid optimized gated recurrent unit with ridge classifier
for crop recommendation for precise agriculture using fused feature
selection concept. <em>IJAIT</em>, <em>33</em>(4), 2450012. (<a
href="https://doi.org/10.1142/S021821302450012X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture is considered the leading field around the world, which is also the backbone of India. Agriculture is in a flawed state because the temperature changes, along with their uncertainty, cause huge damage to the crops during the manufacturing process. So, the appropriate prediction of crop expansion plays a vital role in the management of crop growth. This prediction can enhance the federated industries to make their sustainability toward the occupation. Recently, the farmers have not selected suitable crops for their cultivation based on soil factors. This makes a negative impact on crop yield, and thus, the Indian farmers can suffer from severe losses besides the monetary front. Hence, the optimal crop recommendation model has to consider different parameters of the soil for forecasting the best crop for cultivation, which increases crop growth and crop production. Thus, this research work explores a new crop recommendation model for precision agriculture intending to promote crop yield and alleviate the loss to farmers. Initially, this research work gathers the standard data regarding the agricultural parameters of some areas. Then, the deep features using an autoencoder, and statistical features are gathered along with the Principal Component Analysis (PCA)-based features. Next, all three sets of features are fused and fed to the developed Adaptive Henry Gas Solubility Optimization (AHGSO) for selecting the optimal features. Finally, the chosen optimal features are fed to the recommendation stage, where a Gated Recurrent Unit with Ridge Classifier (GRU-RC) is suggested for getting the precise outcome regarding the recommended crop suitable to that agricultural parameter. Here, the optimal solutions are attained by tuning the parameters of GRU and ridge classifier with the same I-HGSO. At last, the results obtained from the hybrid method can be considered more efficient.},
  archive      = {J_IJAIT},
  author       = {Durai Arumugam S. S. L. and Praveen Kumar R.},
  doi          = {10.1142/S021821302450012X},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2450012},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Hybrid optimized gated recurrent unit with ridge classifier for crop recommendation for precise agriculture using fused feature selection concept},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse approximate pseudoinverse preconditioning for sparse
supervised learning problems with more features than samples.
<em>IJAIT</em>, <em>33</em>(4), 2450011. (<a
href="https://doi.org/10.1142/S0218213024500118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new technique for handling a class of sparse supervised learning problems, specifically focusing on regression, binary, and multi-class classification problems. Sparse regression problems are associated with datasets including both arithmetic and categorical features and by encoding the dataset leads to an underdetermined sparse linear system. Furthermore, logistic regression can be used for both sparse binary and multi-class classification problems, solving an underdetermined sparse linear system. A new technique called Sparse Approximate Pseudoinverse Preconditioning (SAPP), namely the Explicit Preconditioned Conjugate Gradient for Normal Equations (EPCGNE) method based on Generic Approximate Sparse Pseudoinverse matrices is introduced for solving underdetermined sparse least square problems. Numerical experiments were carried out demonstrating a significant improvement of the performance metrics for the proposed SAPP scheme compared to other learners.},
  archive      = {J_IJAIT},
  author       = {Anastasia-Dimitra E. Lipitakis and George A. Gravvanis and Christos K. Filelis-Papadopoulos and Sotiris Kotsiantis and Dimosthenis Anagnostopoulos},
  doi          = {10.1142/S0218213024500118},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2450011},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Sparse approximate pseudoinverse preconditioning for sparse supervised learning problems with more features than samples},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid classifier for crowd anomaly detection with bernoulli
map evaluation. <em>IJAIT</em>, <em>33</em>(4), 2450008. (<a
href="https://doi.org/10.1142/S0218213024500088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically detecting unusual behavior in a crowded environment greatly improves public safety. Unusual behaviors are those that depend on the rules established in the environment under consideration and cannot be properly described. This paper proposes a new deep feature-based crowd anomaly detection method. Priorly, the input image is preprocessed using the Weiner filtering method. Subsequently, AlexNet, VGGnet, and ResNet-based deep features are extracted. During this process, all three models were optimally tuned. For optimization, a new hybrid optimization method called Hybrid COOT and Bald Eagle with Bernoulli Map Evaluation (HCBEBME) is introduced in this work. This improves the performance of extracting features from the input. Finally, based on the proposed feature set, anomalies are detected by the hybrid detection model that combines LSTM and Bi-GRU models, respectively. Finally, the performance of the proposed model is validated over the conventional models. The detection accuracy of the suggested approach is 96.59%, whereas the minimal accuracy scores for the other methods BRCASO, GNNN, CNN-BILSTM, LSTM, BIGRU, BILSTM, CNN, and RNN are 93.63%, 79.16%, 87.57%, 73.85%, 70.59%, 77.08%, 81.44%, and 84.66% respectively.},
  archive      = {J_IJAIT},
  author       = {Rashmi Chaudhary and Manoj Kumar},
  doi          = {10.1142/S0218213024500088},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2450008},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Hybrid classifier for crowd anomaly detection with bernoulli map evaluation},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retail demand forecasting: A multivariate approach and
comparison of boosting and deep learning methods. <em>IJAIT</em>,
<em>33</em>(4), 2450001. (<a
href="https://doi.org/10.1142/S0218213024500015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retail demand forecasting is a highly intricate and multilevel problem as it may include numerous products, under multiple categories, and potentially sold in many different stores. Forecasts may also process products in isolation or collectively so as to detect mutual correlations. In technical terms, retail demand forecasting may be broken down to a multivariate time series forecasting problem where the time axis is prevalent and introduces added complexity which necessitates proper usage of advanced methodologies with machine/deep learning backgrounds. Popular boosting regressors, such as XGBoost and LightGBM, are excellent machine learning candidates with extensive bibliographic backgrounds covering multiple scientific fields and applications including generic multivariate time series forecasts. The Temporal Convolutional Network and the Temporal Fusion Transformer are recently proposed deep neural network architectures that found success in specific multivariate scenarios but are yet to be tested in a variety of related fields such as retail demand forecasting. Therefore, within this paper, these novel in-the-field models are compared to the aforementioned boosting approaches alongside popular statistical univariate methods, namely Exponential Smoothing and SARIMA. To properly compare the selected models and attempt to generalize their usability, two separate datasets are analyzed and forecasted; an item sales dataset with 500 time series and a category sales dataset with 540 time series. The findings suggest that the deep learning solutions are the better predictors, with the Transformer model surpassing the Boosting solutions by up to 16.8% sMAPE decrease and the statistical approaches by up to 28.6% decrease, further substantiating the notion that deep learning techniques are exceptionally promising in handling large-scale, non-linear and outlier data whilst suggesting that retail demand forecasting does benefit from multivariate approaches and the application of advanced machine learning methods.},
  archive      = {J_IJAIT},
  author       = {Georgios Theodoridis and Athanasios Tsadiras},
  doi          = {10.1142/S0218213024500015},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2450001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Retail demand forecasting: A multivariate approach and comparison of boosting and deep learning methods},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Outlier detection using a GPU-based parallel algorithm:
Quantum clustering. <em>IJAIT</em>, <em>33</em>(4), 2350077. (<a
href="https://doi.org/10.1142/S021821302350077X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel hypothesis in the field of outlier detection, suggesting that normal data tend to be distributed in regions where the density changes smoothly or is less pronounced, whereas abnormal data often exhibit distribution in areas characterized by abrupt changes in data density. Relying on this hypothesis, we develop a novel density-based unsupervised outlier detection method, referred to as Quantum Clustering (QC). This approach addresses the processing of unlabeled data and employs a potential function to identify the centroids of clusters and outliers effectively. Experimental results demonstrate that the potential function can accurately detect hidden outliers within data points. Furthermore, by adjusting the parameter σ , QC enables the identification of more subtle outliers. Additionally, our method is evaluated on several benchmarks from diverse research areas, affirming its broad applicability.},
  archive      = {J_IJAIT},
  author       = {Ding Liu and Zhe Wang and Hui Li},
  doi          = {10.1142/S021821302350077X},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350077},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Outlier detection using a GPU-based parallel algorithm: Quantum clustering},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PAC-UNet: Parallel dual self-attention with convolution for
meniscal MRI image segmentation. <em>IJAIT</em>, <em>33</em>(4),
2350076. (<a href="https://doi.org/10.1142/S0218213023500768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meniscal tears are common sports-injury disorders, and thus accurate segmentation of the meniscus is a worthwhile means of medical diagnosis. However, due to the limited research on image segmentation of the meniscus, most previous works have poor segmentation effects on the meniscus, which affects the adoption of assisted medical diagnosis of meniscus. To address this issue, we propose an improved neural network model, termed as the PAC-UNet model, which introduces a parallel dual self-attention with depth-wise convolution for the meniscus image segmentation. Firstly, in the encoder stage, the parallel block is used to eliminate the negative impact of weak modeling ability caused by weight sharing on shared dimensions, so as to better learn the semantic information. Then, in the decoder stage, the parallel block and patch expansion are used to restore the predicted results of meniscus segmentation by performing self-attention and up-sampling on the features. By analyzing the outcomes of experiments on the meniscus dataset, which were collected from the hospital, it is found that the proposed network performed better than other medical image segmentation networks, where the average Dice Similarity Coefficient (DSC), Intersection Over Union (IOU), precision, and Hausdorff_95 of the medial meniscus and lateral meniscus are up to 89.01%, 80.81%, 90.5%, and 2.43, respectively.},
  archive      = {J_IJAIT},
  author       = {Weijian Zhang and Meiling Feng and Chengyi Xia},
  doi          = {10.1142/S0218213023500768},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350076},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {PAC-UNet: Parallel dual self-attention with convolution for meniscal MRI image segmentation},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Resolving charging station placement issues for electric
vehicles: Hybrid optimization-assisted multi-objective framework.
<em>IJAIT</em>, <em>33</em>(4), 2350073. (<a
href="https://doi.org/10.1142/S0218213023500732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As new energy technology has advanced to a respectable level, Electric Vehicles (EV) have gained recognition from people all over the world and have become increasingly popular in a number of nations. Effective charging station placement is critical for the rapid growth of electric vehicles, as it is vital to provide convenience for electric vehicles while also ensuring the effectiveness of traffic networks. The location of an EV charging station is simply an application situation for the facility location problem. Traditional works often pay attention to the mileage concerns of electric vehicle customers while ignoring their competitive and strategic charging tactics. This research aims to frame the allocation of charging stations issue as a multi-faceted venture by assessing the aspects economically along with the characteristics of the power grid like “cost, Voltage stability, Reliability, and Power loss (VRP) index, waiting time, and accessibility index”. Further, we proposed a hybrid artificial intelligence to resolve the allocation issue. The proposed new Artificial Intelligence (AI) based algorithm is termed as Hybridized Salp and Harris Algorithm (HS-HA). The effectiveness and scalability of the presented algorithm for the charging station placement issue are also assessed through different plans in the IEEE 33-bus distribution systems. Finally, the efficiency of the presented approach is proved over the existing approaches with respect to various measures.},
  archive      = {J_IJAIT},
  author       = {Sanket Raval and Nilesh Patel and Thangadurai Natarajan and Sanchari Deb},
  doi          = {10.1142/S0218213023500732},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350073},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Resolving charging station placement issues for electric vehicles: Hybrid optimization-assisted multi-objective framework},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning-based reliable link prediction model for
achieving traffic-aware routing in mobile ad-hoc networks.
<em>IJAIT</em>, <em>33</em>(4), 2350072. (<a
href="https://doi.org/10.1142/S0218213023500720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most promising wireless network architectures is the mobile ad-hoc network (MANET). Researchers have introduced enormous protocols for efficient routing, but it does not provide a reliable communication link for data transmission. Therefore, this research proposes a reliable link prediction-based traffic-aware deep learning routing protocol in MANET to maintain path stability and reliability to construct efficient routing. The reliable traffic-aware link prediction model used in this research is Fuzzy-based Deep Extreme Q -Learning (FDEQL) model. The fuzzy logic rule is used to compute the status of a wireless link to build stable and faster paths toward destinations. Traffic patterns can affect the efficiency of a node. So, to cope with the traffic pattern in MANET, the point-to-point (P2P) and end-to-end (E2E) traffic matrices are initially constructed. To evaluate whether the wireless link is reliable or not, the proposed approach utilizes fuzzy rules by considering essential parameters such as neighborhood overlap (NOVER), bipartivity index (BI), node mobility (NM), data rate (DR), received signal strength indicator (RSSI) and buffer occupancy (BO). The output is the Q -value for reliable link prediction. The performance of a proposed model is validated with other baseline methods based on various measures such as energy consumption, route failure, throughput, delay, packet delivery ratio (PDR), normalized routing load (NRL) and buffer occupancy by varying the mobility speed from 5 to 30 m/sec, number of nodes and simulation time, respectively. At the mobility speed of 10 m/sec, the proposed model has a delay of 0.08 sec, PDR of 99% and throughput of 1903.4 kbps. The proposed model achieves a delay of 19.37 msec, PDR of 96.22%, and throughput of 132.95 kbps, respectively, for 30 nodes. If the simulation runs for 300 sec, the suggested model achieves a delay of 2.98 sec and a PDR of 0.946, respectively.},
  archive      = {J_IJAIT},
  author       = {Manjunath B. Talawar and D. V. Ashoka and R. Nagaraja},
  doi          = {10.1142/S0218213023500720},
  journal      = {International Journal on Artificial Intelligence Tools},
  number       = {4},
  pages        = {2350072},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A deep learning-based reliable link prediction model for achieving traffic-aware routing in mobile ad-hoc networks},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Winners of nikolaos bourbakis award for 2023.
<em>IJAIT</em>, <em>33</em>(3), 2482001. (<a
href="https://doi.org/10.1142/S0218213024820013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAIT},
  doi          = {10.1142/S0218213024820013},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2482001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Winners of nikolaos bourbakis award for 2023},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessing and addressing model trustworthiness trade-offs in
trauma triage. <em>IJAIT</em>, <em>33</em>(3), 2460007. (<a
href="https://doi.org/10.1142/S0218213024600078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trauma triage occurs in suboptimal environments for making consequential decisions. Published triage studies demonstrate the extremes of the complexity/accuracy trade-off, either studying simple models with poor accuracy or very complex models with accuracies nearing published goals. Using a Level I Trauma Center’s registry cases ( n = 50 644), this study describes, uses, and derives observations from a methodology to more thoroughly examine this trade-off. This or similar methods can provide the insight needed for practitioners to balance understandability with accuracy. Additionally, this study incorporates an evaluation of group-based fairness into this trade-off analysis to provide an additional dimension of insight into model selection. Lastly, this paper proposes and analyzes a multi-model approach to mitigating trust-related trade-offs. The experiments allow us to draw several conclusions regarding the machine learning models in the domain of trauma triage and demonstrate the value of our trade-off analysis to provide insight into choices regarding model complexity, model accuracy, and model fairness.},
  archive      = {J_IJAIT},
  author       = {Douglas A. Talbert and Katherine L. Phillips and Katherine E. Brown and Steve Talbert},
  doi          = {10.1142/S0218213024600078},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2460007},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Assessing and addressing model trustworthiness trade-offs in trauma triage},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reliable estimation of causal effects using predictive
models. <em>IJAIT</em>, <em>33</em>(3), 2460006. (<a
href="https://doi.org/10.1142/S0218213024600066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, machine learning algorithms have been widely adopted across many fields due to their efficiency and versatility. However, the complexity of predictive models has led to a lack of interpretability in automatic decision-making. Recent works have improved general interpretability by estimating the contributions of input features to the predictions of a pre-trained model. Drawing on these improvements, practitioners seek to gain causal insights into the underlying data-generating mechanisms. To this end, works have attempted to integrate causal knowledge into interpretability, as non-causal techniques can lead to paradoxical explanations. In this paper, we argue that each question about a causal effect requires its own reasoning and that relying on an initial predictive model trained on an arbitrary set of variables may result in quantification problems when estimating all possible effects. As an alternative, we advocate for a query-driven methodology that addresses each causal question separately. Assuming that the causal structure relating the variables is known, we propose to employ the tools of causal inference to quantify a particular effect as a formula involving observable probabilities. We then derive conditions on the selection of variables to train a predictive model that is tailored for the causal question of interest. Finally, we identify suitable eXplainable AI (XAI) techniques to estimate causal effects from the model predictions. Furthermore, we introduce a novel method for estimating direct effects through intervention on causal mechanisms.},
  archive      = {J_IJAIT},
  author       = {Mahdi Hadj Ali and Yann Le Biannic and Pierre-Henri Wuillemin},
  doi          = {10.1142/S0218213024600066},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2460006},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Reliable estimation of causal effects using predictive models},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive policing: A fairness-aware approach.
<em>IJAIT</em>, <em>33</em>(3), 2460005. (<a
href="https://doi.org/10.1142/S0218213024600054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Artificial Intelligence (AI) systems become increasingly embedded in our daily lives, it is of utmost importance to ensure that they are both fair and reliable. Regrettably, this is not always the case for predictive policing systems, as evidence shows biases based on age, race, and sex, leading to wrongful identifications of individuals as potential criminals. Given the existing criticism of the system’s unjust treatment of minority groups, it becomes essential to address and mitigate this concerning trend. This study delved into the infusion of domain knowledge in the predictive policing system, aiming to minimize prevailing fairness issues. The experimental results indicate a considerable increase in fairness across all metrics for all protected classes, thus fostering greater trust in the predictive policing system by reducing the unfair treatment of individuals.},
  archive      = {J_IJAIT},
  author       = {Ava Downey and Sheikh Rabiul Islam and Md Kamruzzman Sarker},
  doi          = {10.1142/S0218213024600054},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2460005},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Predictive policing: A fairness-aware approach},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effects of explanation types on user satisfaction and
performance in human-agent teams. <em>IJAIT</em>, <em>33</em>(3),
2460004. (<a href="https://doi.org/10.1142/S0218213024600042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated agents, with rapidly increasing capabilities and ease of deployment, will assume more key and decisive roles in our societies. We will encounter and work together with such agents in diverse domains and even in peer roles. To be trusted and for seamless coordination, these agents would be expected and required to explain their decision making, behaviors, and recommendations. We are interested in developing mechanisms that can be used by human-agent teams to maximally leverage relative strengths of human and automated reasoners. We are interested in ad hoc teams in which team members start to collaborate, often to respond to emergencies or short-term opportunities, without significant prior knowledge about each other. In this study, we use virtual ad hoc teams, consisting of a human and an agent, collaborating over a few episodes where each episode requires them to complete a set of tasks chosen from available task types. Team members are initially unaware of the capabilities of their partners for the available task types, and the agent task allocator must adapt the allocation process to maximize team performance. It is important in collaborative teams of humans and agents to establish user confidence and satisfaction, as well as to produce effective team performance. Explanations can increase user trust in agent team members and in team decisions. The focus of this paper is on analyzing how explanations of task allocation decisions can influence both user performance and the human workers’ perspective, including factors such as motivation and satisfaction. We evaluate different types of explanation, such as positive, strength-based explanations and negative, weakness-based explanations, to understand (a) how satisfaction and performance are improved when explanations are presented, and (b) how factors such as confidence, understandability, motivation, and explanatory power correlate with satisfaction and performance. We run experiments on the CHATboard platform that allows virtual collaboration over multiple episodes of task assignments, with MTurk workers. We present our analysis of the results and conclusions related to our research hypotheses.},
  archive      = {J_IJAIT},
  author       = {Bryan Lavender and Sami Abuhaimed and Sandip Sen},
  doi          = {10.1142/S0218213024600042},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2460004},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Effects of explanation types on user satisfaction and performance in human-agent teams},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fairness for deep learning predictions using bias parity
score based loss function regularization. <em>IJAIT</em>,
<em>33</em>(3), 2460003. (<a
href="https://doi.org/10.1142/S0218213024600030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rising acceptance of machine learning driven decision support systems underscores the need for ensuring fairness for all stakeholders. This work proposes a novel approach to increase a Neural Network model’s fairness during the training phase. We offer a frame-work to create a family of diverse fairness enhancing regularization components that can be used in tandem with the widely accepted binary-cross-entropy based accuracy loss. We use Bias Parity Score (BPS), a metric that quantifies model bias with a single value, to build loss functions pertaining to different statistical measures — even for those that may not be developed yet. We analyze behavior and impact of the newly minted regularization components on bias. We explore their impact in the realm of recidivism and census-based adult income prediction. The results illustrate that apt fairness loss functions can mitigate bias without forsaking accuracy even for imbalanced datasets.},
  archive      = {J_IJAIT},
  author       = {Bhanu Jain and Manfred Huber and Ramez Elmasri},
  doi          = {10.1142/S0218213024600030},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2460003},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Fairness for deep learning predictions using bias parity score based loss function regularization},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On bounding the behavior of neurons. <em>IJAIT</em>,
<em>33</em>(3), 2460002. (<a
href="https://doi.org/10.1142/S0218213024600029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A neuron with binary inputs and a binary output represents a Boolean function. Our goal is to extract this Boolean function into a tractable representation that will facilitate the explanation and formal verification of a neuron’s behavior. Unfortunately, extracting a neuron’s Boolean function is in general an NP-hard problem. However, it was recently shown that prime implicants of this Boolean function can be enumerated efficiently, with only polynomial time delay. Building on this result, we first propose a best-first search algorithm that is able to incrementally tighten the inner and outer bounds of a neuron’s Boolean function. Second, we show that these bounds correspond to truncated prime-implicant covers of the Boolean function. Next, we show how these bounds can be propagated in an elementary class of neural networks. Finally, we provide case studies that highlight our ability to bound the behavior of neurons.},
  archive      = {J_IJAIT},
  author       = {Richard Borowski and Arthur Choi},
  doi          = {10.1142/S0218213024600029},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2460002},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {On bounding the behavior of neurons},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding the limits of explainable ethical AI.
<em>IJAIT</em>, <em>33</em>(3), 2460001. (<a
href="https://doi.org/10.1142/S0218213024600017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificially intelligent systems are nowadays presented as systems that should, among other things, be explainable and ethical. In parallel, both in the popular culture and within the scientific literature, there is a tendency to anthropomorphize Artificial Intelligence (AI) and reify intelligent systems as persons. From the perspective of machine ethics and ethical AI, this has resulted in the belief that truly autonomous ethical agents (i.e., machines and algorithms) can be defined, and that machines could, by themselves, behave ethically and perform actions that are justified (explainable) from a normative (ethical) standpoint. Under this assumption, and given that utilities and risks are generally seen as quantifiable, many scholars have seen consequentialism (or utilitarianism) and rational choice theory as likely candidates to be implemented in automated ethical decision procedures, for instance to assess and manage risks as well as maximize expected utility. While some see this implementation as unproblematic, there are important limitations to such attempts that need to be made explicit so that we can properly understand what artificial autonomous ethical agents are, and what they are not. From the perspective of explainable AI, there are value-laden technical choices made during the implementation of automated ethical decision procedures that cannot be explained as decisions made by the system. Building on a recent example from the machine ethics literature, we use computer simulations to study whether autonomous ethical agents can be considered as explainable AI systems. Using these simulations, we argue that technical issues with ethical ramifications leave room for reasonable disagreement even when algorithms are based on ethical and rational foundations such as consequentialism and rational choice theory. By doing so, our aim is to illustrate the limitations of automated behavior and ethical AI and, incidentally, to raise awareness on the limits of so-called autonomous ethical agents.},
  archive      = {J_IJAIT},
  author       = {Clayton Peterson and Jan Broersen},
  doi          = {10.1142/S0218213024600017},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2460001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Understanding the limits of explainable ethical AI},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advances in explainable, fair, and trustworthy AI.
<em>IJAIT</em>, <em>33</em>(3), 2403001. (<a
href="https://doi.org/10.1142/S0218213024030015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This special issue encapsulates the multifaceted landscape of contemporary challenges and innovations in Artificial Intelligence (AI) and Machine Learning (ML), with a particular focus on issues related to explainability, fairness, and trustworthiness. The exploration begins with the computational intricacies of understanding and explaining the behavior of binary neurons within neural networks. Simultaneously, ethical dimensions in AI are scrutinized, emphasizing the nuanced considerations required in defining autonomous ethical agents. The pursuit of fairness is exemplified through frameworks and methodologies in machine learning, addressing biases and promoting trust, particularly in predictive policing systems. Human-agent interaction dynamics are elucidated, revealing the nuanced relationship between task allocation, performance, and user satisfaction. The imperative of interpretability in complex predictive models is highlighted, emphasizing a query-driven methodology. Lastly, in the context of trauma triage, the study underscores the delicate trade-off between model accuracy and practitioner-friendly interpretability, introducing innovative strategies to address biases and trust-related metrics.},
  archive      = {J_IJAIT},
  author       = {Sheikh Rabiul Islam and Ingrid Russell and William Eberle and Douglas Talbert and Md Golam Moula Mehedi Hasan},
  doi          = {10.1142/S0218213024030015},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2403001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Advances in explainable, fair, and trustworthy AI},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Preface. <em>IJAIT</em>, <em>33</em>(3), 2402001. (<a
href="https://doi.org/10.1142/S0218213024020019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAIT},
  author       = {Ingrid Russell and Sheikh Rabiul Islam and William Eberle and Douglas Talbert and Md Golam Moula Mehedi Hasan},
  doi          = {10.1142/S0218213024020019},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {3},
  pages        = {2402001},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Preface},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Abax: Extracting mathematical formulas from chart images
using spatial pixel information. <em>IJAIT</em>, <em>33</em>(2),
2450007. (<a href="https://doi.org/10.1142/S0218213024500076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current state-of-the-art techniques in 2D chart analysis primarily emphasize the recognition of textual information as a means of comprehending and summarizing chart contents. However, the effective analysis and understanding of information embedded in chart images depends on accurate reverse-engineering of the behavior of depicted variables. In this paper, we propose a methodology, named Abax, as an initial study for recognizing and approximating the mathematical functions that describe the behavior of variables illustrated in chart images, particularly those containing curves. Abax is focused on approximating the values of function parameters using spatial pixel information derived from the identified keypoints of each curve. Qualitative results of the described method are presented as a proof of concept, demonstrating accurate extraction of information from fives types of functions: linear, polynomial, asymptotic, sinusoidal and arbitrary.},
  archive      = {J_IJAIT},
  author       = {Michail S. Alexiou and Nikolaos G. Bourbakis},
  doi          = {10.1142/S0218213024500076},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2450007},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Abax: Extracting mathematical formulas from chart images using spatial pixel information},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IoT based wireless communication system for smart irrigation
and rice leaf disease prediction using ResNeXt-50. <em>IJAIT</em>,
<em>33</em>(2), 2450004. (<a
href="https://doi.org/10.1142/S0218213024500040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture not only plays a vital role in human survival but also contributes to the nation’s greater economic development. With the use of technologies like IoT, WSNs, remote sensing, camera surveillance, and many more, precision agriculture is the newest buzzword in the field of technology. Its primary goal is to lessen the labour of farmers while increasing the output of farms. Many machine learning techniques are designed to improve the productivity and quality of the crops, but the improper irrigation and disease prediction of the existing techniques leads to loss of productivity and quality. Hence, the IoT based wireless communication system is designed for smart irrigation and rice leaf prediction using ANN and ResNeXt-50 model. In this designed model, smart irrigation is controlled by collecting the temperature and moisture of the soil in the agricultural field by using the WSN. Likewise, a surveillance camera is placed in the agricultural field to capture the rice leaf to find the disease such as rice blast, leaf smut, brown spot and bacterial blight. These collected data are processed and classified for smart irrigation and rice leaf disease prediction. For evaluating the performance of both the ANN and ResNeXt-50 trained model, the performance metrics such as accuracy, sensitivity, specificity, precision, error etc. The performance metrics for the ANN and ResNeXt-50 model are 0.9427, 0.925, 0.903, 0.86, 0.0573 and 0.967, 0.935, 0.943, 0.939 and 0.033. Thus, the evaluation of the designed model results that the proposed approach is performing better compared to the current techniques.},
  archive      = {J_IJAIT},
  author       = {S. Sangeetha and N. Indumathi and Reena Grover and Rakshit Singh and Renu Mavi},
  doi          = {10.1142/S0218213024500040},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2450004},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {IoT based wireless communication system for smart irrigation and rice leaf disease prediction using ResNeXt-50},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent program correction and evaluation system.
<em>IJAIT</em>, <em>33</em>(2), 2350071. (<a
href="https://doi.org/10.1142/S0218213023500719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing popularity of computing applications has sparked the interest of students in computer programming languages. Minor mistakes are prevalent while writing small code blocks due to the coder’s lack of knowledge and carelessness. Instead of merely providing syntax warnings, it would be better to offer developers with an Integrated Development Environment (IDE) that can automatically correct short code blocks containing mistakes. This makes code composition easier and more time-efficient, thus improving the efficacy of large-scale development environments. Because Python is becoming more popular, the goal of our study is to enhance the efficiency of writing Python code by offering an automatic code-correcting approach. Furthermore, automatic program evaluation has been performed to assist in the debugging of small code blocks, which will ultimately be employed in the creation of real-time computer applications. The proposed technique would be useful for new learners who wish to create small Python code blocks for ease of writing and debugging on online platforms (like edX, Coursera, and Udacity). One of the major contributions of the project is to create an erroneous dataset of Python coding that contains all potential forms of probable syntax errors. The dataset induces variety through the use of multiple coding templates and is used to train deep learning models. We used the state-of-the-art text-to-text T5 transformer network model to automatically repair and evaluate the incorrect code. The outcomes of auto-correction are examined using the ROUGE and BLEU scores, as well as accuracy. The model corrects Python code with single, double, and the multiple number of errors with greater than 80% accuracy. Similarly, the performance of the basic T5 transformer network for program auto-evaluation with and without mistakes has been examined, and the model achieves greater than 65% accuracy in both cases. The proposed T5 base transformer outperforms the SOTA auto-correction models in terms of accuracy, according to a comparison study of the proposed method with the earlier techniques for auto-correcting codes.},
  archive      = {J_IJAIT},
  author       = {Isha Ganguli and Rajat Subhra Bhowmick and Shivam Biswas and Jaya Sil},
  doi          = {10.1142/S0218213023500719},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2350071},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Intelligent program correction and evaluation system},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MSA-UNet: A multiscale lightweight u-net lung CT image
segmentation algorithm under attention mechanism. <em>IJAIT</em>,
<em>33</em>(2), 2350069. (<a
href="https://doi.org/10.1142/S0218213023500690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic and precise segmentation of lung images can assist doctors in locating and diagnosing lung lesions. However, current traditional lung CT image lesion segmentation algorithms suffer from the problem of low segmentation accuracy, while deep learning-based segmentation algorithms struggle to strike a better balance between lightweight and high accuracy. In response to this issue, a multi-scale and lightweight U-Net lung image segmentation algorithm with an attention mechanism is proposed. This algorithm introduces CA convolution after the convolution in the encoding stage to extract channel relationships and positional information from the feature maps. Furthermore, the RFB module is employed to extract features from different perspectives. Lastly, upward residual connections are introduced between the RFB modules in the encoder and decoder to enhance inter-network information interaction. Experiments conducted on the LUNA (lung nodule analysis) dataset and the COVID-QU-Ex dataset for COVID-19 pneumonia demonstrate that the proposed MSA-UNet algorithm achieves the best results in terms of Precision and Dice metrics. It outperforms mainstream models such as U-Net++ and DeeplabV3+ in terms of segmentation effectiveness and segmentation generality. The model has a floating-point operation count (FLOPs) of 18.15 G, a network parameter counts of 8.83×106, and achieves a Precision of 99.37%. The algorithm achieves a good balance between computational efficiency, model size, and segmentation accuracy.},
  archive      = {J_IJAIT},
  author       = {Chuantao Wang and Shuo Shao and Jiajun Yin and Xiumin Wang and Baoxia Li},
  doi          = {10.1142/S0218213023500690},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2350069},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {MSA-UNet: A multiscale lightweight U-net lung CT image segmentation algorithm under attention mechanism},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Traffic congestion prediction using feature series LSTM
neural network and a new congestion index. <em>IJAIT</em>,
<em>33</em>(2), 2350067. (<a
href="https://doi.org/10.1142/S0218213023500677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large and expanding cities suffer from a traffic congestion problem that harms the environment, travelers, and the economy. This paper aims to predict short term traffic congestion on a road section of expressway in Delhi city. For this purpose, we first propose a traffic congestion index based on traffic speed and flow. Clustering techniques and the Greenshield’s model were used for the derivation of the congestion index. Using this congestion index, congested time intervals of each day and each location of a weekday were identified. This study also introduces a feature series long short-term memory neural network (FSLSTMNN), which links a long short-term memory (LSTM) layer to each feature. It is trained using the many heterogeneous traffic features data collected in Delhi city for the next five minutes of traffic flow and speed prediction. FSLSTMNN achieved the good capability to learn feature series data. We also trained several traditional and deep-learning models using the same traffic data. The FSLSTMNN reduces mean absolute error 12.90% and 17.13%, respectively, in speed and traffic flow prediction compared to the second good-performance long short-term memory neural network (LSTMNN). Finally, traffic congestion is predicted classwise (light, medium, and congested) using the developed congestion index and traffic speed and flow predicted by the FSLSTMNN. Predicted results are consistent with the measured field data. Study results confirm that the developed congestion index and FSLSTMNN can be used successfully to predict traffic congestion.},
  archive      = {J_IJAIT},
  author       = {Manoj Kumar and Kranti Kumar},
  doi          = {10.1142/S0218213023500677},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2350067},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Traffic congestion prediction using feature series LSTM neural network and a new congestion index},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intrusion detection using bat optimization algorithm and
DenseNet for IoT and cloud based systems. <em>IJAIT</em>,
<em>33</em>(2), 2350065. (<a
href="https://doi.org/10.1142/S0218213023500653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Internet of Things (IoT) and cloud systems, Intrusion Detection (ID) is very vital for protecting the security infrastructures. ID techniques are extensively used to detect and track malicious threats in cloud and IoT systems. In the IoT based ID, the conventional techniques work based on the manual traffic feature values that increase the complexity of the networks and achieve a limited detection rate on the larger IoT databases. For addressing the above-stated issues and achieving high classification results, an effective deep learning based ID-System (IDS) is implemented in this article. Initially, the IoT data is acquired from the NSW-NB15 and NSL-KDD databases, and then, the standard scaling normalization technique, known as Min-Max normalization, is applied to select the dominant attributes and to eliminate outliers from the acquired databases. Additionally, the optimal features are selected from the rescaled normalized data by implementing the Bat optimization algorithm. The selection of optimal features decreases the computational complexity and training time of the IDS. The chosen optimal features are passed into the DenseNet model for carrying out intrusion attack detection. Particularly, in the binary-class classification, the Bat-based DenseNet model obtained 98.89% and 98.40% of accuracy on the UNSW-NB15 and NSL-KDD databases, correspondingly. The obtained simulation results prove the higher effectiveness of the current study when it is related to the state-of-the-art classifiers.},
  archive      = {J_IJAIT},
  author       = {H. Kanakadurga Bella and S. Vasundra},
  doi          = {10.1142/S0218213023500653},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2350065},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Intrusion detection using bat optimization algorithm and DenseNet for IoT and cloud based systems},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classifying hindi news using various machine learning and
deep learning techniques. <em>IJAIT</em>, <em>33</em>(2), 2350064. (<a
href="https://doi.org/10.1142/S0218213023500641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification involves organizing textual information into predefined classes, a task which is particularly useful in domains like sentiment analysis, spam detection, and content labeling. In India, where a massive amount of information is generated daily through newspapers and social media, Hindi is one of the most widely used and spoken languages. However, there is limited research on Hindi text classification and, particularly, regarding Hindi news classification. This paper presents a research study to classify Hindi news articles published in Hindi-language newspapers in India by using and comparing various Machine Learning (ML) and Deep Learning (DL) algorithms. To prepare the textual news data for classification, pre-processing and feature engineering techniques, such as count vectorizer, Tf-Idf vectorizer and Doc2Vec, were used and applied to convert texts into vectors. This pre-processing step on the textual data was very challenging due to the presence of multimodal words, conjunctions, punctuation, and special characters in Hindi texts. The study considered Hindi news headlines from predetermined categories (Science, Sports, Entertainment and Business) and, among the different ML and DL models tested and evaluated, Linear Regression with Doc2Vec vectorizer and SGD classifier with Tf-Idf vectorizer produced best accuracies of 97.04% and 96.59%, respectively. The best performing DL model was found to be the Bi-LSTM with an accuracy of approximately 97% on the testing data.},
  archive      = {J_IJAIT},
  author       = {Anusha Chhabra and Monika Arora and Arpit Sharma and Harsh Singh and Saurabh Verma and Rachna Jain and Biswaranjan Acharya and Vassilis C. Gerogiannis and Dimitrios Tzimos and Andreas Kanavos},
  doi          = {10.1142/S0218213023500641},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2350064},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Classifying hindi news using various machine learning and deep learning techniques},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph CNN-ResNet-CSOA transfer learning architype for an
enhanced skin cancer detection and classification scheme in medical
image processing. <em>IJAIT</em>, <em>33</em>(2), 2350063. (<a
href="https://doi.org/10.1142/S021821302350063X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer is a perilous kind of cancer caused by damaged DNA and it leads to death. This damaged DNA causes uncontrolled proliferation of cells. Even though, the image analysis of lesions is highly difficult due to light reflections from skin surface, fluctuations at color lighting, variety of lesions’ forms and sizes in skin cancer. Because of these issues, automatic recognition of skin cancer accurateness is decreased. Therefore, a Graph Convolutional Neural Network (GCNN) by ResNet 152 Transfer Learning Architype optimized with Chameleon Swarm Optimization Algorithm (GCNN-ResNet 152 TL-CSOA) is proposed at this manuscript for enhancing skin cancer detection with classification in medical image processing. Initially, the input images are taken from International Skin Imaging Collaboration (ISIC) of dermoscopic skin cancer imagery data set. Afterward, the input images are pre-processed utilizing trilateral filter method for removing noise. The pre-processed output is supplied to the process of feature extraction. Here, image features, like morphologic, gray scale statistic and Haralick texture features are extracted by Gray-Level Co-Occurrence Matrix window adaptive approach (GLCM-WAA) technique. After that, the GCNN-ResNet 152 TL classifies the skin cancer images into Actinic Keratosis, Basal Cell Carcinoma, Malignant Melanoma and Squamous Cell Carcinoma. Additionally, GCNN-ResNet 152 TL weight parameters is tuned by Chameleon Swarm Optimization Algorithm (CSOA). The simulation process is executed at Python tool. From simulation, the proposed approach attains 23.34%, 12.03%, 21.42% improved accuracy and 18.23%, 21.23%, 14.56% higher sensitivity compared with existing approaches.},
  archive      = {J_IJAIT},
  author       = {G. N. Balaji and S. A. Sahaaya Arul Mary and Nagesh Mantravadi and Francis H. Shajin},
  doi          = {10.1142/S021821302350063X},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2350063},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Graph CNN-ResNet-CSOA transfer learning architype for an enhanced skin cancer detection and classification scheme in medical image processing},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Named entity recognition of tunisian arabic using the
bi-LSTM-CRF model. <em>IJAIT</em>, <em>33</em>(2), 2350062. (<a
href="https://doi.org/10.1142/S0218213023500628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named Entity Recognition (NER) is an NLP field that deals with recognizing and classifying entities in written text. Most Arabic NER research studies discuss the Arabic NER challenge for the Modern Standard Arabic (MSA) language. However, the presence of dialectal Arabic textual resources in social media, blogs, TV shows, etc. is increasingly progressive. Therefore, the treatment of named entities is rapidly becoming a necessity, particularly for dialectal Arabic. In this paper, we are interested in the collection and annotation of a corpus as well as the realization of a NER system for Tunisian Arabic (TA), named TUNER. To the best of the researchers’ knowledge, this is the first study that uses the suggested method for this purpose. In the present study, we adopt a hybrid method based on a Bi-LSTM-CRF model and a rule-based method. The proposed TUNER system yields an F-measure of 91.43%. This is an interesting improvement over comparable related work dialectal Arabic NER systems.},
  archive      = {J_IJAIT},
  author       = {Asma Mekki and Inès Zribi and Mariem Ellouze and Lamia Hadrich Belguith},
  doi          = {10.1142/S0218213023500628},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {2},
  pages        = {2350062},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Named entity recognition of tunisian arabic using the bi-LSTM-CRF model},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Text document clustering using modified particle swarm
optimization with k-means model. <em>IJAIT</em>, <em>33</em>(1),
2350061. (<a href="https://doi.org/10.1142/S0218213023500616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present digital era, vast amounts of data are generated by millions of Internet users in the form of unstructured text documents. The clustering and organizing of text documents play a crucial role in the applications of data analysis and market research. In this research manuscript, a new modified version of metaheuristic-based optimization technique is proposed with k-means for clustering the text documents. In the initial phase, the input data are acquired from the three-benchmark databases such as Reuters-21578, 20-Newsgroup and British Broadcasting Corporation (BBC)-sport. Further, the data denoising is accomplished by using the common techniques: stemming, lemmatization, tokenization, and stop word removal. In addition to this, the denoised data are transformed into feature vectors by utilizing Term Frequency (TF)-Inverse Document Frequency (IDF) technique. The computed feature vectors are given to the Modified Particle Swarm Optimization (MPSO) with k-means to group the closely related text documents by minimizing the similarity in different clusters. The experimental examination showed that the proposed MPSO with k-means model achieved accuracy of 0.85, 0.85 and 0.86 on the Reuters-21578, 20-Newsgroup and BBC-sport databases, which are superior to the comparative models.},
  archive      = {J_IJAIT},
  author       = {Ratnam Dodda and A. Suresh Babu},
  doi          = {10.1142/S0218213023500616},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350061},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Text document clustering using modified particle swarm optimization with k-means model},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel hybrid optimization-based backstepping fractional
order sliding mode proportional-integral-derivative controller for
nonlinear biological system. <em>IJAIT</em>, <em>33</em>(1), 2350060.
(<a href="https://doi.org/10.1142/S0218213023500604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the role of the control system in the bioengineering field plays a major part due to its significant improvement and demand. Usually, if there are any changes in the parameter of a biological system, then it tends to cause crucial diseases in humans. Previously, various control algorithms have been developed; however, the proper control process failed due to the high error rate, slow convergence, Computational Complexity, Tuning Complexity and inaccurate function. The proposed control strategy should ensure accurate tracking of the desired trajectory or reference signal, even in the presence of uncertainties and disturbances. The control system should be capable of adapting to changes in the system dynamics and maintaining stable operation. This complexity can lead to high computational requirements, making the controller computationally expensive and potentially unsuitable for real-time applications or systems with limited computing resources. To overcome these issues, in this work, the novel Hybrid Ant Lion Moth Flame Optimization (HALMFO) based Backstepping Fractional-Order Sliding mode Proportional-Integral-Derivative (BFO-SPID) controller is proposed for different nonlinear biological systems. The proposed method enhances the efficiency, improved performance, robustness, convergence speed, and solution quality of the optimization process. This paper addresses the challenge of controlling nonlinear biological systems by proposing a novel hybrid optimization-based backstepping approach combined with a fractional order sliding mode proportional-integral-derivative (PID) controller. This work’s essential contribution lies in addressing existing control strategies’ limitations by integrating multiple control techniques to achieve robust tracking performance and disturbance rejection. This system proposes predictive control with state estimation based on the backstepping sliding mode method. The gain parameters of the developed controller are optimized using the HALMFO method. The proposed control approach performance has been tested under biological systems such as Protein, Pancreas, and Genetic Regulatory Network (GRN). The execution of this proposed model is done in MATLAB/Simulink. Furthermore, the performance of the proposed control technique is compared with various state-of-the-art methods in terms of accuracy, Mean Average Error (MAE), Mean Square Error (MSE), settling time, overshoot, and rise time. The comparison illustrates that the projected controller has reached a steady condition with the least error rate in the control application. Thus the developed controller regulates the parameter variations in the biological system as per the desired level, providing significant effective outcomes to complex problems.},
  archive      = {J_IJAIT},
  author       = {Wakchaure Vrushali Balasaheb and Chaskar Uttam},
  doi          = {10.1142/S0218213023500604},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350060},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A novel hybrid optimization-based backstepping fractional order sliding mode proportional-integral-derivative controller for nonlinear biological system},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diagnosing attention deficit hyperactivity disorder using
machine learning methods on serious game-generated data. <em>IJAIT</em>,
<em>33</em>(1), 2350059. (<a
href="https://doi.org/10.1142/S0218213023500598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention Deﬁcit Hyperactivity Disorder (ADHD) is a frequent learning disorder affecting about 5%–8% of the student population globally. Currently, the traditional methods for ADHD diagnosis are not fully speciﬁed, due to difficulties in identifying the particular factors that cause this disorder. In this paper, we present a novel system for diagnosing ADHD, which does not need special equipment. Instead, it is based on the application of machine learning (ML), using data gathered from gameplay sessions of a serious game named “ADHD360”, developed for this purpose. Participants were recruited with particular criteria in order to generate data for the study. The beneﬁts of our approach include less subjectivity in the decision process, cost-efficiency and easier accessibility than the typical procedure. To this end, special data preprocessing steps and ML techniques were applied. Our models achieved up to 85.7% F1-score performance metric in predicting correctly a user’s label (ADHD or not) from his/her gameplay session in ADHD360. Our method also proved to be efficient using only a small amount of data for the training procedure. The results of our systems are very promising, indicating notable ability of the tool to distinguish players that probably suffer from ADHD than those who do not.},
  archive      = {J_IJAIT},
  author       = {Eleftherios Kouloumpris and Aristotelis Lazaridis and Anestis Fachantidis and Ioannis Vlahavas},
  doi          = {10.1142/S0218213023500598},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350059},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Diagnosing attention deficit hyperactivity disorder using machine learning methods on serious game-generated data},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Denoising convolutional autoencoder based approach for
disordered speech recognition. <em>IJAIT</em>, <em>33</em>(1), 2350058.
(<a href="https://doi.org/10.1142/S0218213023500586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient assistive speech technology is essential for persons with cognitive disorders to improve their standard of life. Various kinds of cognitive disorders affect the speech articulation. Disordered Speech Recognition (DSR) can be used for rehabilitation and gain much importance as the disordered speakers population keeps increasing in recent years. The speech utterance is commonly represented in the form of spectrogram. Since the spectrograms are noisy and incomplete, the corresponding spectrograms need to be enhanced. We propose an approach that explores Denoising Convolutional Autoencoder (DCAE) to enhance the spectrograms of disordered speech utterances which are then utilized to train CNN to recognize the disordered words. Evaluation of proposed approach is carried out using the 20 words (acoustically similar word classes) dataset and 50 words dataset of Impaired speech corpus in Tamil and 100 common words dataset of UA-Speech database. Significantly better performance is achieved by proposed approach than HMM, DNN-HMM, LFMMI and CNN without enhancement. The spectrogram enhancement using DCAE helps to obtain better discrimination among overlapping disordered word classes and achieves a maximum Word Recognition Accuracy.},
  archive      = {J_IJAIT},
  author       = {S. Chandrakala and Veni S Vishnika},
  doi          = {10.1142/S0218213023500586},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350058},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Denoising convolutional autoencoder based approach for disordered speech recognition},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Doctors versus YOLO: Comparison between YOLO algorithm,
orthopedic and traumatology resident doctors and general practitioners
on detection of proximal femoral fractures on x-ray images with multi
methods. <em>IJAIT</em>, <em>33</em>(1), 2350056. (<a
href="https://doi.org/10.1142/S0218213023500562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the 1950s, the concept of artificial intelligence emerged, suggesting that machines could possess the ability to think and learn. In the 21st century, with advancements in GPUs and CPUs, deep learning has become an integral part of human life. Proximal femoral fractures are known to be one of the leading causes of mortality and injuries among the elderly population. This study aims to detect proximal femoral fractures in X-ray images and compare the success of using the YOLOv4 algorithm and provide decision support system within the diagnosis. To retrain the algorithm, more than 500 patients’ X-ray images were examined. Through data augmentation techniques, the initial set of 410 patients’ femur proximal fracture X-ray images was expanded to 820 images. After retraining the YOLO algorithm, two different groups were included for comparing the algorithm’s performance: orthopedic specialists and general practitioners. The results from these three groups were evaluated using specific criteria. The YOLOv4 model demonstrated an accuracy of 90.33%. In comparison, orthopedic and traumatology resident doctors achieved an accuracy of 91.42%, while the general practitioner group achieved an accuracy of 81.30%.},
  archive      = {J_IJAIT},
  author       = {Muhammed Taha Zeren and Seher Arslankaya and Yusuf Altuntaş and Necmi Cam and Yasin Kırelli and Mustafa Hacı Özdemir},
  doi          = {10.1142/S0218213023500562},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350056},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Doctors versus YOLO: Comparison between YOLO algorithm, orthopedic and traumatology resident doctors and general practitioners on detection of proximal femoral fractures on X-ray images with multi methods},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An intelligent traffic analysis and prediction system using
deep learning technique. <em>IJAIT</em>, <em>33</em>(1), 2350055. (<a
href="https://doi.org/10.1142/S0218213023500550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of vehicles and estimating density in traffic surveillance systems is a challenging task, particularly in scenarios with closely spaced lanes. Single Shot MultiBox Detector (SSD) is introduced in vehicle detection and classification due to its speed and accuracy. It utilizes a transfer learning technique that enables them to utilize features from pretrained Convolutional Neural Networks (CNNs). Although the utilization of multi-scale feature maps in SSD has achieved efficient results in vehicle detection, it struggles to identify key features of vehicles due to its one-stage detection approach. Furthermore, the use of VGG16 as the backbone network in these approaches leads to the loss of fine-grained details, posing challenges in accurately localizing and classifying small vehicles. Also, there is no interaction between high- and low-level features, which restricts the networks ability to effectively integrate and utilize both features for accurate vehicle detection. To overcome these limitations, an improved SSD approach is introduced in this paper, leveraging interactive multi-scale attention characteristics to accurately detect and classify vehicles. This approach utilizes ResNet50 as the network backbone to overcome the limitations of traditional SSDs in detecting small vehicles. Also, an attention block is incorporated into it to focus on key details and assign higher attention to relevant pixels within the feature map. Also, the network employs a parallel detection framework and shares multi-scale layers (both high and low), enabling efficient detection of vehicles with various sizes. Then, traffic density is estimated based on the weights assigned to the categorized vehicles obtained from the improved SSD and the recorded area. Finally, traffic is classified as high, low, or moderate by comparing the estimated density to a threshold value. By adding attention characteristics of different scales to the original detection branch and replacing the VGG16 with ResNet50 of the SSD technique using our method, the feature representation capability and detection accuracy are both significantly improved.},
  archive      = {J_IJAIT},
  author       = {S. Sasikala and R. Neelaveni and P. Sweety Jose},
  doi          = {10.1142/S0218213023500550},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350055},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {An intelligent traffic analysis and prediction system using deep learning technique},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning polarity embedding attention for aspect-based
sentiment analysis. <em>IJAIT</em>, <em>33</em>(1), 2350054. (<a
href="https://doi.org/10.1142/S0218213023500549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary goal of Sentiment Analysis (SA) is to recognize the emotions present in natural language text. Generally, in opinion content, emotions are often driven by several aspects of their interests. Any SA task that groups data into various aspects and identifies sentiments is referred to as Aspect-Based Sentiment Analysis (ABSA). Recent advances in Deep Learning (DL) have brought revolutionary changes in the performance of Machine Learning models. Their ability to capture semantic and syntactic traits of any intrinsic data model is highly appreciated. In this research work, we use DL techniques to address the challenges of ABSA aiming to improve sentiment granularity at the aspect level. The proposed methodology works in two stages: (i) aspect terms extraction and (ii) sentiment polarity classification. The task of aspect terms extraction is achieved through the concept of Named-Entity Recognition (NER). However, most of the available NER models are domain dependent and utilize hand-crafted features for learning labeled data. Hence, for aspect terms extraction, a joint model based on Bi-GRU and Conditional Random Fields (CRF) is proposed. Similarly, for sentiment polarity classification, we introduce a novel attention-based neural network called Polarity Embedded Attention Network (PEAN). The intuition behind the PEAN is that, when an aspect term appears in a sentence, its related sentiment term is represented by the polarity embedding. Hence, PEAN combines sentence embedding with aspect and polarity embedding to learn the relationship between sentence and aspect terms. The effectiveness of the proposed model is realized through a comparative study of different models on benchmark datasets. It yields better results compared to other baseline techniques.},
  archive      = {J_IJAIT},
  author       = {Ramesh Wadawadagi and Sanjeevakumar M. Hatture and Veerappa Pagi},
  doi          = {10.1142/S0218213023500549},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350054},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Learning polarity embedding attention for aspect-based sentiment analysis},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid attention-based deep model for lung cancer subtype
classification from multimodality images. <em>IJAIT</em>,
<em>33</em>(1), 2350052. (<a
href="https://doi.org/10.1142/S0218213023500525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer is a deadly type of malignancy that poses a significant threat to human health. Accurately identifying the subtypes of lung cancer is critical for effective treatment. However, conventional methods for determining subtypes, such as histological examination, are invasive and time-consuming. In order to overcome this problem, a non-invasive approach for predicting lung cancer subtypes using multi-modality images with a hybrid model is proposed in this study. The model combines attention-based Convolutional Neural Networks (CNNs) and machine learning classifiers to achieve this objective. The model employs a soft-attention mechanism to focus on the pathological areas and extract both global and local features from the images. The stack-based ensemble classifier employs logistic regression as a meta-learner and four machine learning classifiers, including Support Vector Machine (SVM), Naive Bayes, Random Forest, and J48. The classifier categorizes lung cancer into Adenocarcinoma (ADC), Squamous Cell Carcinoma (SQC), and Small Cell Carcinoma (SCC). The suggested model validated using publically accessible datasets (Lung-PET-CT-DX, Lung1, and Lung3) achieved superior performance, with a validation accuracy of 98.8%, an F1-score of 0.986, and a Matthews Correlation Coefficient (MCC) of 0.988.},
  archive      = {J_IJAIT},
  author       = {Chinnu Jacob and Gopakumar C. Menon},
  doi          = {10.1142/S0218213023500525},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350052},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {A hybrid attention-based deep model for lung cancer subtype classification from multimodality images},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accommodation recommendation on shared platforms considering
bidirectional selection and review mechanisms. <em>IJAIT</em>,
<em>33</em>(1), 2350051. (<a
href="https://doi.org/10.1142/S0218213023500513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, shared accommodation platforms have developed rapidly and become increasingly popular. They commonly adopt unique bidirectional selection and review mechanisms. However, most existing accommodation recommendation strategies overlook the impact of these mechanisms on the recommendation performance. To address this gap, we propose a two-stage recommendation method as Shared Accommodation Recommendation based on Bidirectional Selection and Review mechanisms (SARBSR) to improve the recommendation performance of shared accommodation. The first stage combines a multi-attribute recommendation method (MAR) with a hybrid recommendation method based on similarity and ratings (HRSR) to predict guests’ preferences and generate candidate lists. In the second stage, considering bidirectional selection and reviews mechanisms, we assess hosts’ willingness to accept guests’ requests via trust evaluation and select rooms from the candidate lists as the final recommendation strategy. To evaluate the performance of SARBSR, an empirical study on real-world data from Airbnb is conducted. The results demonstrate the validity of SARBSR and indicate the necessity of considering bidirectional selection and review mechanisms.},
  archive      = {J_IJAIT},
  author       = {Yuanyuan Lin and Chao Huang and Xi Zhang and Xin Li and Wei Yao},
  doi          = {10.1142/S0218213023500513},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350051},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Accommodation recommendation on shared platforms considering bidirectional selection and review mechanisms},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent optimization algorithm for support vector
machine: Research and analysis of prediction ability. <em>IJAIT</em>,
<em>33</em>(1), 2350048. (<a
href="https://doi.org/10.1142/S0218213023500483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine is a very classical and popular model for data prediction. Traditional support vector machines use grid search to determine its parameters. In order to improve the accuracy of prediction, more and more frameworks are proposed. Among them, the combination of support vector machine and intelligent optimization algorithm is the most commonly used solution at present. The optimization objective is to determine the optimal penalty factor and kernel parameters of support vector machine to improve the prediction performance. In this paper, 10 intelligent optimization algorithms that are widely used at present are used for the optimization research of support vector machine. The performance of these optimization algorithms in support vector machine parameter optimization is analyzed in detail. Short-term wind speed and network traffic are chosen as the research object, and detailed performance indicators are given to judge the advantages and disadvantages of these intelligent optimization algorithms in optimizing support vector machine performance. Finally, the performance indicators, optimization speed, running memory usage, optimization success rate of different optimized SVM models, and impact of data distribution are analyzed in detail, and some conclusions are drawn. For the parameters optimization of support vector machine, various indicators are comprehensively considered, grey wolf optimizer algorithm and squirrel search algorithm are recommended.},
  archive      = {J_IJAIT},
  author       = {Lian Lian},
  doi          = {10.1142/S0218213023500483},
  journal      = {INTERNATIONAL JOURNAL on ARTIFICIAL INTELLIGENCE TOOLS},
  number       = {1},
  pages        = {2350048},
  shortjournal = {Int. J. Aritf. Intell. Tools},
  title        = {Intelligent optimization algorithm for support vector machine: Research and analysis of prediction ability},
  volume       = {33},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
