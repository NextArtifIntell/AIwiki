<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJPRAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijprai---187">IJPRAI - 187</h2>
<ul>
<li><details>
<summary>
(2024). A novel GEA–PSO method for optimizing the parameters of a
bird-like flapping wing robot. <em>IJPRAI</em>, <em>38</em>(16),
2459018. (<a href="https://doi.org/10.1142/S0218001424590183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel parameter optimization method, named the geyser algorithm based on particle swarm optimization (GEA–PSO) method, was proposed for optimizing the key parameters of a bird-like flapping wing robot. The kinematic model, the multiple objective functions, and some constraint conditions were first established. A novel GEA–PSO algorithm was designed. Some test functions verified the good superiority of the GEA–PSO method with a fast velocity and high accuracy. The key parameters of the robot were successfully optimized using the GEA–PSO method. Kinematic simulations were carried out to obtain some key quantities, such as the end trajectory, the flapping angle, and the folding angle. Robot experiments were conducted based on the robot prototype, which verified the effectiveness of the optimization method. The GEA–PSO method plays a crucial role in the parameter optimizations and the stable flights of the robot.},
  archive      = {J_IJPRAI},
  author       = {Changtao Ding},
  doi          = {10.1142/S0218001424590183},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2459018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel GEA–PSO method for optimizing the parameters of a bird-like flapping wing robot},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time information acquisition and processing method for
penetration information based on multi-information fusion.
<em>IJPRAI</em>, <em>38</em>(16), 2458008. (<a
href="https://doi.org/10.1142/S0218001424580084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the real-time performance and the target adaptability of penetration fuze detonation control systems, and to enhance the system fusion processing capability for multi-sensor information, this paper uses a modular design concept to construct a miniaturized ( ø 38 mm × 4 mm) fuze detonation control system that is capable of real-time processing of data from multiple information sources. The core component of this system is the GD32E230 microcontroller, which features a high dominant frequency and low power consumption. This device is integrated with a ferroelectric memory and signal processing circuits that match the sensors. To address the issue of unclear traditional acceleration signal penetration and the difficulties associated with the identification of these signals, the approach in this paper improves feature recognition accuracy through rapid acquisition and fusion of multiple types of sensor output signal, and self-adaptive identification of multilayered targets and single-layer thick targets is achieved. During the programming of the embedded system, the hardware register is operated directly, the instruction execution sequence is optimized, and the program execution efficiency is improved by using the function characteristic that some microcontroller unit peripherals do not occupy the central processing unit when working, thus allowing the intended purpose of improving the system’s real-time performance to be achieved. A semi-physical simulation method is then used to verify the performance of the penetration fuze detonation control system. The results obtained show that the system has 100%-layer counting accuracy for multilayered targets and a relative error of less than 1% for the calculated residual velocities of single-layer thick targets, thus validating the effectiveness of the system.},
  archive      = {J_IJPRAI},
  author       = {Zheyu Yang and Yao He and Li Sui and Dongya Wang},
  doi          = {10.1142/S0218001424580084},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2458008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Real-time information acquisition and processing method for penetration information based on multi-information fusion},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical feature fusion for cross-modality person
re-identification. <em>IJPRAI</em>, <em>38</em>(16), 2457017. (<a
href="https://doi.org/10.1142/S0218001424570179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitations of visible light cameras that cannot function effectively at night, infrared cameras have become the optimal supplement. However, current methods for visible–infrared cross-modality person re-identification focus solely on feature combination and fusion, neglecting the importance of feature alignment. To address this issue, we introduce a novel Hierarchical Feature Fusion (HFF) network, which comprehensively integrates features across various levels through sequential feature extraction. Specifically, we design a pixel-level contrastive loss function that makes pixels in the same region of cross-modality images more similar and distinguishes pixel features at different locations, thereby extracting similar low-frequency information in the shallow network. Furthermore, in the deep network, we extract high-frequency information of different modalities through the Bi-Transformer Layer and propose Node-level Coupling Attention and Modality-level Decoupling Attention. Coupling attention is used for high-frequency information coupling within the same modality while decoupling attention is used for high-frequency information decoupling between different modalities to obtain more texture and detail information. Through a series of experimental results, we validate the superiority of the proposed HFF network in cross-modality person re-identification. Our proposed method achieved 87.16% and 95.23% Rank-1 on the SYSU-MM01 and RegDB datasets, respectively, and extensive experiments have validated its effectiveness in feature alignment.},
  archive      = {J_IJPRAI},
  author       = {Wen Fu and Monghao Lim},
  doi          = {10.1142/S0218001424570179},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2457017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hierarchical feature fusion for cross-modality person re-identification},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robot navigation system based on improved a-star
algorithm. <em>IJPRAI</em>, <em>38</em>(16), 2456012. (<a
href="https://doi.org/10.1142/S0218001424560123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regarding global path planning for search and rescue robots, the traditional method of A* algorithm is slow and has many turning points along the intended route, which hinders its searching speed. A new and enhanced A* algorithm is presented in this paper, incorporating the Floyd-trajectory optimization algorithm. The search directions of the traditional A* algorithm were refined from eight to five. Next, we improved the cost estimation function by introducing a weight value to balance the estimated heuristic function value with the actual cost value, thereby enhancing the algorithm’s search efficiency. Finally, we applied the Floyd path optimization algorithm to eliminate redundant nodes from the route. The use of both the Floyd and A* algorithms in combination has been proven through simulations and experiments to improve search results by 40% compared to solely using the A* algorithm. This integration effectively reduces the search scope, diminishes the number of turning points by 63.8%, improves path smoothness, and effectively shortens the planned path length.},
  archive      = {J_IJPRAI},
  author       = {Xiangli Bu and Guangxing Li and Bo Tong and Xianyang Zhang},
  doi          = {10.1142/S0218001424560123},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2456012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A robot navigation system based on improved A-star algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shadclips: When parameter-efficient fine-tuning with
multimodal meets shadow removal. <em>IJPRAI</em>, <em>38</em>(16),
2454017. (<a href="https://doi.org/10.1142/S021800142454017X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segment Anything Model (SAM), an advanced universal image segmentation model trained on an expansive visual dataset, has set a new benchmark in image segmentation and computer vision. However, it faced challenges when it came to distinguishing between shadows and their backgrounds. To address this, we proposed ShadClips, which consists of SAM-optimizer and SONet. It has dramatically enhanced SAM’s ability to segment shadow images, differentiating between the background and both soft and hard shadows adeptly. Due to its dependence on pixel point inputs, the SAM-Optimizer interface could do better. This method presents challenges, especially when dealing with long, extended shadows. To make the user experience more intuitive and effective, we incorporated the capabilities of CLIPs. Therefore, simple text descriptions like “A photo of a shadow” can be used to guide the SAM-Optimizer, allowing it to select the most relevant shadow mask from SAM’s comprehensive category list. Meanwhile, we introduce SONet to shadow removal. A large number of experiments on ISTD/SRD prove that the proposed method is effective and satisfactory. The source code of the ShadClips can be accessed from https://github.com/zhangbaijin/SAM-helps-Shadow .},
  archive      = {J_IJPRAI},
  author       = {Xiaofeng Zhang and Chaochen Gu and Zishan Xu and Hao Tang and Hao Cheng and Kaijie Wu and Shanying Zhu},
  doi          = {10.1142/S021800142454017X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2454017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Shadclips: When parameter-efficient fine-tuning with multimodal meets shadow removal},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Face image recognition in smart city based on improved
convolutional neural network. <em>IJPRAI</em>, <em>38</em>(16), 2454016.
(<a href="https://doi.org/10.1142/S0218001424540168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of big data and artificial intelligence technology has given new vitality and value to smart cities, which provide rich algorithm models and knowledge computing capabilities. Since the recognition results of the traditional Convolutional Neural Network (CNN) model in the face database are prone to over-fitting, this paper proposes a face recognition algorithm based on an improved CNN model and deep learning. The improved CNN model has a good network image recognition performance, improves the data training speed, and optimizes the network structure parameters. Based on an improved CNN model, using the facial expression recognition (FER2013) data to test the model performance, to achieve more accurate face recognition. Experimental results show that the recognition rate of the improved model and deep learning algorithm on the FER2013 dataset reaches 98.36%, which is 4.63% higher than before the improvement.},
  archive      = {J_IJPRAI},
  author       = {Jing Tie and Mingxin Ji and Muteng Zhong and Yichen Ye and Qiwei Li and Rong Jie Zhang and Minrui Lin},
  doi          = {10.1142/S0218001424540168},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2454016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Face image recognition in smart city based on improved convolutional neural network},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new contrastive learning-based vision transformer for
sentiment analysis using scene text images. <em>IJPRAI</em>,
<em>38</em>(16), 2452029. (<a
href="https://doi.org/10.1142/S0218001424520293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis using scene text images is complex and challenging because it has an arbitrary background, and the method should rely on only visual features. Unlike most existing methods that use either text or images or both, this study uses only scene text images for sentiment analysis. The intuition to use only scene text images is that sometimes users express their feelings and emotions or convey their messages by writing text in different shapes with diverse background designs. It is noted that the existing methods ignore such vital cues for sentiment analysis. This work explores a vision transformer to extract visual features that represent contextual information about the appearance of the text image. Further, to strengthen the visual features, the proposed work introduces contrastive learning which maximizes the gap between inter-classes and minimizes the gap between intra-classes of positive, negative, and neutral. To demonstrate the effectiveness of the proposed method, it is tested on our own constructed dataset and benchmark dataset. A comparative study of our method with the existing method shows the proposed method is superior in the classification of positive, negative, and neutral scene text images.},
  archive      = {J_IJPRAI},
  author       = {Shivakumara Palaiahnakote and Dhruv Kapri and Muhammad Hammad Saleem and Umapada Pal},
  doi          = {10.1142/S0218001424520293},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2452029},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A new contrastive learning-based vision transformer for sentiment analysis using scene text images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AMFANet: Advanced deep learning techniques for high-quality
image style transfer. <em>IJPRAI</em>, <em>38</em>(16), 2452027. (<a
href="https://doi.org/10.1142/S021800142452027X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents AMFANet, an advanced deep learning model engineered for high-quality image style transfer. AMFANet integrates cutting-edge techniques such as the Adaptive Multi-Scale Feature Fusion (AMSF) module and Hybrid Attention Mechanism (HAM) to significantly improve style consistency, content fidelity, and texture preservation. The model also utilizes Segmented Atrous Spatial Pyramid Pooling (SASPP) for effective multi-scale feature extraction. Comprehensive experimental evaluations demonstrate that AMFANet surpasses current state-of-the-art models like StyleGAN3, ChipGAN, ACL-GAN, and CycleGAN in generating high-fidelity stylized images while preserving intricate details and artistic essence. Future research will focus on optimizing computational efficiency, enabling multi-style transfer, enhancing user interaction, and exploring cross-domain applications. These findings highlight AMFANet’s potential as a robust solution for advanced image style transfer in both artistic and practical domains.},
  archive      = {J_IJPRAI},
  author       = {HuaQun Liu},
  doi          = {10.1142/S021800142452027X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2452027},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AMFANet: Advanced deep learning techniques for high-quality image style transfer},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An RSC-based genetic algorithm for fixed-outline soft module
floorplanning. <em>IJPRAI</em>, <em>38</em>(16), 2451020. (<a
href="https://doi.org/10.1142/S0218001424510200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Floorplanning is a pivotal step in the early stages of integrated circuit physical design. In modern design, the outline of the chip is typically determined before floorplanning and each module must be placed within the specified fixed outline. However, when dealing with soft modules, the task becomes even more complex and challenging as it requires simultaneous determination of both position and shape. This paper proposes a genetic algorithm based on random subtree crossover to address the floorplanning problem of soft modules under fixed-outline constraints. First, a slicing tree is employed to represent the floorplan solution due to its advantage in handling the flexibility of soft modules. A three-step random subtree crossover (RSC) is proposed to generate feasible descendants specifically for slicing tree representation. Second, we adopt three types of perturbations as mutation operators and determine the probability of selecting a mutation operator on account of its empirical performance to improve the effectiveness of mutation. Then, to enhance the genetic algorithm’s rate of convergence, a step named insert after deletion (IAD) is incorporated into the evolutionary process to eliminate operator nodes with large dead spaces. Finally, the algorithm is verified by employing two standard circuits, MCNC and GSRC. The test consequences show that the proposed algorithm realized a 100% success rate across various aspect ratios while surpassing previous works in terms of wire length performance.},
  archive      = {J_IJPRAI},
  author       = {Runping Yang and Shimin Du},
  doi          = {10.1142/S0218001424510200},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2451020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An RSC-based genetic algorithm for fixed-outline soft module floorplanning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph-based multi-feature fusion method for speech emotion
recognition. <em>IJPRAI</em>, <em>38</em>(16), 2450023. (<a
href="https://doi.org/10.1142/S021800142450023X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring proper way to conduct multi-speech feature fusion for cross-corpus speech emotion recognition is crucial as different audio features could provide complementary cues reflecting human emotion status. Speech emotion recognition allows computers to analyze the specific emotional condition of the speaker through speech, which is of great significance to the development of human–computer interaction technology. While most previous approaches only extract a single speech feature for emotion recognition, existing fusion methods such as concatenation, parallel connection, and splicing ignore heterogeneous patterns in the interaction between features and features, resulting in performance of existing systems. In this paper, we propose a novel graph-based fusion method to explicitly model the relationships between every pair of audio features, which provides a new research idea for speech feature fusion. Specifically, we propose a multi-dimensional edge features learning strategy called graph-based multi-feature fusion method for speech emotion recognition. It represents each speech feature as a node and learns multi-dimensional edge features to explicitly describe the relationship between each feature-feature pair in the context of emotion recognition. This way, the learned multi-dimensional edge features encode speech feature-level information from both the vertex and edge dimensions. Our approach consists of three modules: an Audio Feature Generation (AFG) module, an Audio-Feature Multi-dimensional Edge Feature (AMEF) module and a Speech Emotion Recognition (SER) module. The proposed methodology yielded satisfactory outcomes on the SEWA dataset. Furthermore, the method demonstrated enhanced performance compared to the baseline in the AVEC 2019 Workshop and Challenge. We used data from two cultures as our training and validation sets: two cultures containing German and Hungarian on the SEWA dataset, the CCC scores for German are improved by 17.28% for arousal and 7.93% for liking, and for Hungarian, the CCC scores are improved by 11.15% for arousal and 131.11% for valence. The outcomes of our methodology demonstrate a 13% improvement over alternative fusion techniques, including those employing one-dimensional edge-based feature fusion approach. The experiments on some parts of the Aff-Wild 2 dataset demonstrate that our approach exhibits a certain degree of generalizability and robustness. Code is available at https://github.com/ChaosWang666/Graph-based-multi-Feature-fusion-method .},
  archive      = {J_IJPRAI},
  author       = {Xueyu Liu and Jie Lin and Chao Wang},
  doi          = {10.1142/S021800142450023X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {16},
  pages        = {2450023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Graph-based multi-feature fusion method for speech emotion recognition},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Study of the gearbox meshing coupling vibration law based on
mechanical signal and frequency signal. <em>IJPRAI</em>,
<em>38</em>(15), 2458009. (<a
href="https://doi.org/10.1142/S0218001424580096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the failure of a certain type of gearbox of a high-speed locomotive group with cracks is examined, and a gearbox failure assessment method that considers the coupled vibration is established and combined with mechanical signal and frequency signal to determine the basis for judging the failure of a faulty gearbox. First, according to the mechanical model of the finite element calculation, we determined the stress weak links and then the layout response stress measurement points and acceleration measurement points. We then calculated the gearbox ratio, meshing frequency, vibration frequency, mechanical response, modal response, and other frequency characteristics using the Hilbert–Huang transform (HHT) method and the fast Fourier transform (FFT) algorithm to analyze the vibration signals generated by different speeds and wheel out-of-roundness conditions. These were used to calculate the frequency of the different vibration sources of the mechanical response on the weak areas. The frequency correlations of the different vibration sources on the mechanical response in the weak areas were then analyzed, and the vibration transmission law of the gearbox case was obtained. The fault determination criterion was then determined, and the final cause of the fault was obtained.},
  archive      = {J_IJPRAI},
  author       = {Hua Zou and Bingbing Cui and Wenjing Wang and Zhaojin Liu},
  doi          = {10.1142/S0218001424580096},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2458009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Study of the gearbox meshing coupling vibration law based on mechanical signal and frequency signal},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IoMT-based smart intelligent healthcare system using
optimization-driven deep residual network for brain tumor detection.
<em>IJPRAI</em>, <em>38</em>(15), 2457011. (<a
href="https://doi.org/10.1142/S0218001424570118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical information system, like the Internet of Medical Things (IoMT), has gained more attention in recent decades. Disease diagnosis is an important facility of the medical healthcare system. Wearable devices become popular in a wide range of applications in the health monitoring system and this has stimulated the increasing growth of IoMT. Recently, a smart healthcare system has been more effective, and various methods have been developed to classify the disease at the beginning stage. To capture the patient’s information and detect the disease, a new framework is designed using the developed Conditional Auto regressive Mayfly Algorithm (CAMA)-based Deep Residual Network (DRN). Initially, pre-processing is done by the T2FCS filtering technique to increase the image quality by eliminating noises. The second step is segmentation. Here, the segmentation of brain tumor is done using U-Net. After that, data augmentation is performed to enhance image dimensions using the techniques, such as flipping, shearing, and translation to solve the issues of data samples. After processing the data augmentation mechanism, the next step is brain tumor detection, which is done using DRN. Here, DRN is trained by the proposed CAMA, which is the integration of conditional auto regressive value at risk (CAViaR) with the mayfly algorithm (MA). The developed model reduces computational complexity and increases effectiveness and robustness. The proposed CAMA-based DRN outperformed with an utmost testing accuracy of 0.921, sensitivity of 0.931, specificity of 0.928, distance of 52.842 and trust of 0.697.},
  archive      = {J_IJPRAI},
  author       = {AR. Sivakumaran and P. Shanthakumar and M. Robinson Joel},
  doi          = {10.1142/S0218001424570118},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2457011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {IoMT-based smart intelligent healthcare system using optimization-driven deep residual network for brain tumor detection},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SCML-GNN: A graph neural network model leveraging sensor
causality and meta-learning for mechanical fault classification.
<em>IJPRAI</em>, <em>38</em>(15), 2456011. (<a
href="https://doi.org/10.1142/S0218001424560111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault classification of mechanical equipment is a vital issue in modern industrial production. Mechanical equipment typically relies on multiple sensors to collect the operational data, which is represented as multivariate time-series data. However, existing methods for analyzing mechanical faults often overlook the causal relationships between sensors and struggle with the scarcity of labeled training samples. To address these challenges, we propose a graph neural network model leveraging sensor causality and meta-learning for mechanical fault classification (SCML-GNN). Specifically, we use transfer entropy to represent multivariate time-series data as a graph, with each sensor as a node and their causal relationships as edges. We then extract the node features using temporal convolutional layers and apply a graph neural network to learn the low-dimensional features. Additionally, graph pooling methods are used to obtain global embeddings. To further tackle the issue of limited labeled training samples, we introduce a metric-based class prototype attention mechanism within SCML-GNN. Extensive experiments conducted on three real-world mechanical equipment datasets demonstrate the superior effectiveness and efficiency of SCML-GNN in mechanical fault classification compared to the other existing methods.},
  archive      = {J_IJPRAI},
  author       = {Ziyi Xiao and Yueyang Wang and Gang Tan and Dandan He and Jianing Li and Wei Zhou},
  doi          = {10.1142/S0218001424560111},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2456011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SCML-GNN: A graph neural network model leveraging sensor causality and meta-learning for mechanical fault classification},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating the performance of vascular feature extraction
boosting algorithm for peripheral arterial disease detection.
<em>IJPRAI</em>, <em>38</em>(15), 2456010. (<a
href="https://doi.org/10.1142/S021800142456010X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common vascular disease called peripheral arterial disease (PAD) is characterized by constricted or blocked arteries in the legs, which lowers blood flow and raises the risk of consequences including cardiovascular events or amputation of a limb. Timely intervention and management of PAD are contingent upon early identification. Atherosclerosis, or plaque accumulation in the arteries, is the main cause of this illness. Therefore, leg pain, cramping, numbness, weakness, or coolness in the legs are possible signs of PAD, especially when engaging in physical activity. In addition to impairing mobility and quality of life, PAD raises the possibility of consequences like tissue damage, persistent sores, and even limb amputation if treatment is not received. Mixes of dietary adjustments, medication, and, in extreme situations, surgical procedures are used to manage PAD. A nutritious diet, frequent exercise, giving up smoking, and keeping a healthy weight are a few examples of lifestyle changes. It may be necessary to prescribe pharmaceuticals to decrease cholesterol, antiplatelet agents, blood flow improvers, and symptom managers. Procedures like angioplasty, stenting, or bypass surgery may be required in cases when PAD progresses and symptoms are severe to restore blood flow to the affected limbs. To avoid issues and enhance results, PAD must be identified early and managed effectively. As a result, those who are at risk such as those with diabetes, high blood pressure, high cholesterol, or a history of smoking should have screening for PAD regularly. All things considered, PAD is a dangerous illness that needs to be managed proactively to avoid complications and preserve a high standard of living. Through the management of risk factors, adoption of a healthy lifestyle, and adherence to an individualized treatment plan, people with PAD can effectively manage their illness and lower their chance of complications. For long-term treatment and best results, regular monitoring and follow-up with healthcare specialists are necessary. Vascular feature extraction boosting (VFEB), a hybrid algorithm that combines the strength of vascular feature extraction with boosting approaches, is the unique strategy for PAD identification that is present in this study. The VFEB approach makes use of gradient boosting machines (GBMs) to improve classification performance based on these features and convolutional neural networks (CNNs) to extract discriminative features from vascular imaging data. The goal of VFEB is to increase the precision and resilience of PAD detection by combining CNNs for feature extraction with GBMs for classification. Using a dataset of vascular imaging data, we assess the VFEB algorithm’s performance and compare it with other established techniques. The findings show that VFEB performs better than other methods at identifying PAD, providing encouraging opportunities for the early detection and treatment of this crippling vascular ailment. The VFEB system achieves an outstanding accuracy of 99.87%, an F1 Score of 99.64, and MCC 99%. Compared to the conventional methods, VFEB obtains improved accuracy, F1 Score, and MCC by integrating boosting techniques with vascular feature extraction. This study emphasizes the value of utilizing cutting-edge computational tools to improve vascular health outcomes and shows how hybrid algorithms, such as VFEB, may improve PAD identification.},
  archive      = {J_IJPRAI},
  author       = {B. Sivaramakrishna and Ch. N. Santhosh Kumar and B.V. Subba Rao and V. Rama Krishna and Rajendra Kumar Ganiya and J. Nageswara Rao},
  doi          = {10.1142/S021800142456010X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2456010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Evaluating the performance of vascular feature extraction boosting algorithm for peripheral arterial disease detection},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight object detection model for low-end UAVs.
<em>IJPRAI</em>, <em>38</em>(15), 2455020. (<a
href="https://doi.org/10.1142/S0218001424550206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth and widespread use of low-end commercial unmanned aerial vehicles (UAVs), it is critical to develop an object detection system that works well with these devices. This paper designs an efficient and lightweight object detection model specifically designed for low-end UAVs. Through excellent information interaction and the refined use of some techniques, our model can obtain multi-scale features and better focus on the details of different parts. Extensive experiments show that our model still maintains comparable accuracy while it consumes fewer parameters and FLOPs. In addition, our model has been applied to the tracking system of low-end UAVs, greatly enhancing the tracking performance.},
  archive      = {J_IJPRAI},
  author       = {Jun Liang and Nuo Zhou and Jiahao Long and Songsen Yu and Muhammad Faizan Khan},
  doi          = {10.1142/S0218001424550206},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2455020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A lightweight object detection model for low-end UAVs},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CNN pruning with multi-stage feature decorrelation.
<em>IJPRAI</em>, <em>38</em>(15), 2455019. (<a
href="https://doi.org/10.1142/S021800142455019X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a channel pruning method based on multi-stage feature de-correlation to obtain a more efficient convolutional neural network (CNN) model. Based on the correlation of hidden features at each level of the network, we refine more efficient features of each convolutional layer by applying feature de-correlation constraints (MFD Loss) to each convolutional layer of the network and then prune channels according to the modulus of the feature maps output from each layer. After several rounds of pruning and fine-tuning, a network with similar accuracy, a substantially smaller network size, and more efficient operation is generated compared to the original model. Our experiments on pruning various popular CNN models on many standard datasets demonstrate the method’s effectiveness. Specifically, for VGG-16 on CIFAR10, our approach eliminates parameters by 97.0%, saves Float-Point-Operations (FLOPs) by 66.9%, with a 0.4% accuracy gain and state-of-art performance. For ResNet-50 on the ImageNet dataset, our method eliminates parameters by 30.0%, and saves FLOPs by 52%, with 1.4% accuracy loss, which also proves the effectiveness of the method. The code for the paper can be found at https://github.com/lovelyemperor/MFD .},
  archive      = {J_IJPRAI},
  author       = {Qiuyu Zhu and Chengfei Liu},
  doi          = {10.1142/S021800142455019X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2455019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CNN pruning with multi-stage feature decorrelation},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MP-GIEN: Vehicle re-identification method based on
multi-view progressive graph interactive embedding network.
<em>IJPRAI</em>, <em>38</em>(15), 2455018. (<a
href="https://doi.org/10.1142/S0218001424550188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle re-identification primarily faces two challenges: significant intra-class variations caused by different camera views and subtle inter-class differences between vehicles of the same model. In this paper, we propose a Multi-View Progressive Graph Interaction Embedding Network (MP-GIEN) for vehicle re-identification. First, we design a global semantic extractor. By employing Graph Interaction Units (GI Units) and semantic context, we combine semantic information to facilitate contextual reasoning of image regions, thereby extracting global semantic features of the target. The global loss is then calculated using ID loss and triplet loss. Second, we devise a local view-aware extractor. The U-Net network is utilized to parse the image into four views (front, rear, top, and side). Subsequently, features are aligned through mask average pooling, and a progressive training strategy is adopted to address the learning of fine-grained information. Lastly, we design a feature fusion enhancer. We revise the typical triplet loss to avoid mismatches in local features. By optimizing the local triplet loss and global loss, we learn the embedding of visual features, which not only reduces the intra-instance distance but also enlarges the inter-instance differences. MP-GIEN facilitates the capture of stable discriminative information on vehicles under different views. Experiments conducted on the VeRi-Wild dataset demonstrate that our model significantly outperforms state-of-the-art methods.},
  archive      = {J_IJPRAI},
  author       = {Ruoda Wang and Min Guo and Miao Ma},
  doi          = {10.1142/S0218001424550188},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2455018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {MP-GIEN: Vehicle re-identification method based on multi-view progressive graph interactive embedding network},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SGM-YOLO: YOLO-based defect detection model for wood lumber.
<em>IJPRAI</em>, <em>38</em>(15), 2455012. (<a
href="https://doi.org/10.1142/S0218001424550127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wood lumber is widely used in the construction and furniture manufacturing industries. In order to solve the problems of poor recognition, low efficiency and few detection types of manual and traditional processing methods, this paper proposes a model SGM-YOLO for the detection of surface defects in wood lumber. The SGM-YOLO model references a new backbone feature network, SL-backbone, to enhance the model’s ability to detect defects of different sizes. And, a new GVE-neck layer structure will be proposed in this paper, which reduces the parameters as well as the accuracy. In addition, the Normalized Weighted Distance Loss (NWD) small target detection algorithm is combined with the MPDIOU boundary loss function to replace the original loss function to further enhance the small target detection capability. Experiments show that SGM-YOLO achieves an average recognition accuracy of 77.4% for wood lumber defects, compared with the original model YOLOv8, the mAP is improved by 3.8% and the FPS is improved by 4.4, while the number and size of parameters are reduced, which provides better detection of several defects that are difficult to be identified. The methods presented in this paper were also applied to the YOLOv5 model, yielding positive results, to confirm its generalizability. The results demonstrate the high application value of the SGM-YOLO model in the wood lumber processing and manufacturing industry’s final product inspection.},
  archive      = {J_IJPRAI},
  author       = {Liping Liu and Qiyu Zhang and Wenqi Peng and Ruiqi Wang and Jingtao Yin},
  doi          = {10.1142/S0218001424550127},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2455012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SGM-YOLO: YOLO-based defect detection model for wood lumber},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new symmetry-based transformer for text spotting in person
and vehicle re-identification images. <em>IJPRAI</em>, <em>38</em>(15),
2455011. (<a href="https://doi.org/10.1142/S0218001424550115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text spotting in person and vehicle re-identification images is complex due to the presence of multiple views of the same person and vehicle. Most existing models focus on text spotting in natural scene images, our work focuses on spotting in person and vehicle re-identification images. The rationale behind this work is that the person and the vehicles share symmetry properties and the bib number in the torso and license plate number in the vehicle are text. The method divides the input image into patches, and it explores vision transformation for encoding the patches into linear patches. The linearly embedded patches are fed to the feature similarity index step, which involves phase congruency and gradient magnitude to detect symmetric patches. The transformer is proposed to encode and capture textual information from the symmetry patches for text detection and recognition. The decoder receives the attention features from the encoder and fetches a multi-task head with the information about the detected and recognized text. The experiments on person and vehicle image benchmark, viz. (Person) Re-ID, RBNR, UFPR-ALPR and RodoSol datasets show significant improvement in performance when compared to other text spotting models. The effectiveness of the proposed model is validated by testing on the benchmark datasets, namely, ICDAR 2015, Total-Text and CTW1500 of natural scene images. Furthermore, cross-data validation shows the proposed method is independent of domains.},
  archive      = {J_IJPRAI},
  author       = {Aritro Pal Choudhury and Shivakumara Palaiahnakote and Umapada Pal},
  doi          = {10.1142/S0218001424550115},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2455011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A new symmetry-based transformer for text spotting in person and vehicle re-identification images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning algorithm for KOL segmentation on social
media videos. <em>IJPRAI</em>, <em>38</em>(15), 2452028. (<a
href="https://doi.org/10.1142/S0218001424520281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, there is high commercial demand for product replacement which places the products virtually in Key Opinion Leader’s (KOL’s) social media videos. However, one of the challenges of placing the products virtually is the KOL segmentation. Since KOLs often hold products in front of them, it requires the segmentation to segment not only humans but also different products. This paper introduces the state-of-the-art deep learning method, namely RSUDISNet, for KOL segmentation. The proposed technique integrates two deep Convolutional Neural Network (CNN) technologies. One is the Matting Objective Decomposition Network (MODNet), which segments KOLs well but not the products blocking the KOLs. The other one is the two-level nested U-structure network (U2Net) based on the salient object detection method to segment the objects well, but not the KOL. The key technique of the proposed research is to employ the feature of the U2Net to embed the MODNet to overcome the problem of KOL segmentation. Since both MODNet and U2Net are lightweights, the combined network can be used for real-time scenarios. After that, the Intermediate Supervision (IS) training strategy is utilized to overcome the overfitting. The experimental results show that our proposed method outperforms the MODNet and U2Net.},
  archive      = {J_IJPRAI},
  author       = {Cheng Yang and Fucheng Zheng and Duaa Zuhair Al-Hamid and Peter Han Joo Chong and Patrick Lam},
  doi          = {10.1142/S0218001424520281},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2452028},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A deep learning algorithm for KOL segmentation on social media videos},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-based student engagement classification in
online learning. <em>IJPRAI</em>, <em>38</em>(15), 2452026. (<a
href="https://doi.org/10.1142/S0218001424520268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online education has gained significant popularity during the COVID-19 pandemic. The availability of massive open online courses has further strengthened the online learning environment. One of the considerable challenges in online learning environments is to measure the learner’s engagement to meet the educational objectives. This paper addresses the challenge and proposes a convolutional neural network-based architecture that extracts discriminative features from the face (Affective) and the upper body (Behavioral) of the learner and classifies the engagement. The performance of the proposed architecture is evaluated on the publicly available Dataset of Affective States In E-Environments (DAiSEE) and the learning-centered affective state dataset curated from open-source datasets. The experimental results demonstrate that the proposed methodology with affective and behavioral features improves the engagement measurement results. The proposed method outperforms the state-of-the-art in terms of Unweighted Average Recall (UAR), Unweighted Average Precision (UAP), and Unweighted Average F1 (UAF1) with 79.14%, 49.62%, and 55.29% values, respectively. It is threefold more computationally efficient than the previous state-of-the-art method. The proposed method also improves the accuracy of the curated dataset by 2.07% of the prior method.},
  archive      = {J_IJPRAI},
  author       = {Sandeep Mandia and Kuldeep Singh and Rajendra Mitharwal},
  doi          = {10.1142/S0218001424520268},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2452026},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep learning-based student engagement classification in online learning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unraveling the potential: A systematic review and
performance evaluation of data-driven network anomaly detection
techniques. <em>IJPRAI</em>, <em>38</em>(15), 2439001. (<a
href="https://doi.org/10.1142/S0218001424390014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network anomalies significantly impact the efficiency and stability of network systems, making effective anomaly detection crucial for optimal performance and prevention of network breakdowns. However, conventional methods must be improved for handling anomalies’ complexities and evolving nature. Despite extensive research in network anomaly detection (NAD) techniques, there is a need for more systematic literature reviews incorporating recent advances, particularly in dynamic and heterogeneous network settings. Moreover, most review papers focus on individual detection methods, needing a unified framework for comprehensive anomaly detection. To bridge these gaps, this paper conducts a comprehensive analysis by conducting a systematic literature review and formulating five research questions to outline the objectives of this study. A holistic framework is proposed, integrating techniques based on preprocessing and Feature Selection into prediction models to develop more accurate, efficient, and reliable anomaly detection systems. The empirical evaluation assesses the effectiveness, accuracy, efficiency, and reliability of the data-driven NAD techniques. Finally, the study identifies research gaps and potential future directions to guide further advancements in developing accurate and efficient anomaly detection models. By synthesizing and analyzing 116 top-cited papers, this study contributes to the existing body of knowledge by highlighting the potential of emerging anomaly detection techniques in complex and dynamic network environments.},
  archive      = {J_IJPRAI},
  author       = {Niharika Sharma and Bhavna Arora},
  doi          = {10.1142/S0218001424390014},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2439001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Unraveling the potential: A systematic review and performance evaluation of data-driven network anomaly detection techniques},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CTF-net: Partial focus searching within holistic structure
for fine-grained object recognition. <em>IJPRAI</em>, <em>38</em>(15),
2435001. (<a href="https://doi.org/10.1142/S0218001424350019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most fine-grained visual recognition methods endeavor to directly locate discriminative regions in intricate environments, but tend to overlook the object’s holistic structure, which may lead to misclassification due to overemphasizing incorrect areas. In this paper, we propose a coarse-to-fine paradigm, which prioritizes locating holistic structural regions of the target object, followed by a gradual search to locate discriminative areas. Specifically, we first design the “look into object” module to locate the areas encompassing the target’s holistic structure using prior information. Subsequently, without introducing additional parameters, we design a partial focus searching module to enhance feature representations of discriminative regions within the target’s structural composition. Ultimately, we segregate the foreground components from the original image, attaining a more precise characterization of the target. Furthermore, we demonstrate the practical application potential of our model in real-world industries through our self-constructed DHU-Fine-grained-6000 dataset. Comparative experiments on three public datasets indicate that the superiority of our approach over many recent methods and holds promising application potential in industrial production processes.},
  archive      = {J_IJPRAI},
  author       = {Jintao Li and Bing Wei and Kuangrong Hao and Lei Gao and Lei Chen and Xiaoyan Liu},
  doi          = {10.1142/S0218001424350019},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {15},
  pages        = {2435001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CTF-net: Partial focus searching within holistic structure for fine-grained object recognition},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Node importance estimation for knowledge graphs based on
multi-perspectives attention fusion mechanism. <em>IJPRAI</em>,
<em>38</em>(14), 2459017. (<a
href="https://doi.org/10.1142/S0218001424590171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of the Internet has led to the emergence of multi-source heterogeneous knowledge graphs, which have become a crucial means of storing and disseminating knowledge. Node importance estimation is a technique that is employed extensively in a number of fields, including recommender systems, intelligent search and resource allocation. This study introduces a Multi-perspective attention mechanism Fusion Algorithm for the mapping of multi-perspective features of knowledge graphs to Node Importance Estimation (MFA-NIE). First, structural embedding features, relational predicate features, and attribute features (both textual and quantitative) are established for the nodes. Subsequently, an enhanced attention mechanism is employed to extract, compress, and fuse these features. The fused hidden layer vector is employed in the design of a key-based attention mechanism, which enables the propagation of messages from neighboring nodes to the source node. This process results in the iterative updating of the source node’s hidden features. Finally, TOPSIS centrality, based on the topology of the source node, is employed to dynamically adjust the mapping between the fused features and node importance. Experiments were conducted on real-world, large-scale, multi-source, heterogeneous knowledge graphs, comparing the MFA-NIE algorithm with traditional and advanced baseline algorithms, including PR, PPR, GENI, RGTN, CLINE, MCRL, and others. The results demonstrate that the MFA-NIE algorithm significantly improves effectiveness and accuracy, showcasing its superiority, versatility, and practical application value.},
  archive      = {J_IJPRAI},
  author       = {Kao Ge and Qing-Bang Han},
  doi          = {10.1142/S0218001424590171},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2459017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Node importance estimation for knowledge graphs based on multi-perspectives attention fusion mechanism},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DPDCD: The intelligent prediction strategy for the course
development of diabetic kidney disease. <em>IJPRAI</em>,
<em>38</em>(14), 2459015. (<a
href="https://doi.org/10.1142/S0218001424590158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic nephropathy (DKD) is a severe diabetes complication and a leading cause of mortality. While urine microalbuminuria and eGFR are common markers, some advanced cases may exhibit normal values. The progression from microalbuminuria to overt proteinuria in DKD is gradual and requires comprehensive physiological tests for diagnosis. This study employs deep reinforcement learning to predict DKD progression based on patients’ physiological data, aiming to assist clinical diagnosis and treatment. A multivariate logistic regression algorithm is used to describe the DKD prediction probability. An optimized DKD progression prediction algorithm (DPDCD) based on deep reinforcement learning determines the best model coefficients, enabling accurate prediction of DKD progression using routine clinical data. Experimental results demonstrate that DPDCD outperforms other algorithms in predicting DKD progression, providing valuable support for clinicians.},
  archive      = {J_IJPRAI},
  author       = {Jianfeng Wang and Guozhi Li and Jirui Li and Liang Liu},
  doi          = {10.1142/S0218001424590158},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2459015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DPDCD: The intelligent prediction strategy for the course development of diabetic kidney disease},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeepWhaleNet: Climate change-aware FFT-based deep neural
network for passive acoustic monitoring. <em>IJPRAI</em>,
<em>38</em>(14), 2459014. (<a
href="https://doi.org/10.1142/S0218001424590146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Climate change poses severe risks to the survival of many whale populations, whose habitats and migration patterns are affected by environmental changes. To detect these whales effectively, especially in deep-sea environments, we need to use AI-based techniques to handle the acoustic diversity and variability of different species. However, current methods for whale detection are based on pre- and post-processing steps that reduce their efficiency and generalizability. To address this issue, we present DeepWhaleNet, a novel deep-learning model that automates whale detection in Underwater Passive Acoustic Monitoring datasets. DeepWhaleNet simplifies the detection process by extracting relevant features from raw log-power spectrograms and helps protect these threatened species by supporting conservation efforts. Our model uses a larger short-time Fourier transform as input and a custom ResNet-18 architecture for classification, which enables it to separate whale sounds from noise and capture their temporal and spectral characteristics. We evaluate the performance of DeepWhaleNet and show that it surpasses state-of-the-art methods, achieving an 8.3% improvement in the F-1 score and 21% higher average precision of binary relevance than the baseline method. Moreover, our model demonstrates its versatility and suitability for species-specific retrieval problems through an ablation study on multi-label retrieval problems and a 99.1% recall for Blue Whales.},
  archive      = {J_IJPRAI},
  author       = {Nicholas Rasmussen and Rodrigue Rizk and Omera Matoo and KC Santosh},
  doi          = {10.1142/S0218001424590146},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2459014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DeepWhaleNet: Climate change-aware FFT-based deep neural network for passive acoustic monitoring},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning clustering algorithm for water
environmental monitoring. <em>IJPRAI</em>, <em>38</em>(14), 2459013. (<a
href="https://doi.org/10.1142/S0218001424590134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning based on genetic algorithms is an important application. The multi-dimensional ordered sample clustering problem is often solved using Fisher’s optimal segmentation method. However, this method has obvious shortcomings when encountering long sample problems due to its high storage requirements during the computation process. Therefore, Fisher’s optimal two - segmentation method is generally used in practical problems instead, which avoids storage problems. But it is prone to local optima. Based on the analysis of the shortcomings of the Fisher optimal segmentation and optimal two - segmentation algorithms, this paper proposes a genetic-based machine learning clustering algorithm, which overcomes the problem of Fisher’s optimal two - segmentation algorithm being prone to local optima and also solves the problem of high storage requirements during the computation process of Fisher’s optimal segmentation method. The application of this algorithm in the optimization system of water environment monitoring points shows that it is effective.},
  archive      = {J_IJPRAI},
  author       = {Hongfen Jiang and Junfeng Gu and Haixu Xi and Qian Yu and Xiaoyue Wang and Yijun Liu},
  doi          = {10.1142/S0218001424590134},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2459013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Machine learning clustering algorithm for water environmental monitoring},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved YOLOv8 network for multi-object detection with
large-scale differences in remote sensing images. <em>IJPRAI</em>,
<em>38</em>(14), 2455017. (<a
href="https://doi.org/10.1142/S0218001424550176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to address the challenges of low object detection precision in remote sensing images due to high background complexity and significant target scale variations, a novel model for large-scale disparate object detection in remote sensing images is proposed based on the modified YOLOv8. The model incorporates a Context Aggregation Module (CAM) with an attention mechanism in the backbone network to exploit contextual information, enabling multi-scale feature fusion for effective small object detection. The Neck network utilizes GSConv modules and employs the Slim-Neck design paradigm to enhance model robustness, making it better suited for detecting objects in high-complexity backgrounds. Furthermore, the model adopts the Wise-IoU as the loss function, incorporating a dynamic nonmonotonic focusing mechanism and a gradient gain allocation strategy to enhance the overall performance of disparate object detection. The experimental results indicate that promising performance improvements in the face of large-scale variations in remote sensing image targets. Specifically, the model achieves mAP values of 71.4% and 90.3% on the DOTA and NWPU VHR-10 datasets, respectively, representing increases of 4.4% and 3.7% compared to the original model. Compared to other typical algorithms, it also has considerable advantages in both comprehensive detection accuracy and detection speed.},
  archive      = {J_IJPRAI},
  author       = {Zhaofei Li and Hao Zhou and Yijie Zhang and Hongjie Tao and Hongchun Yu},
  doi          = {10.1142/S0218001424550176},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2455017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An improved YOLOv8 network for multi-object detection with large-scale differences in remote sensing images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TLCSFI: A pose-guided person re-identification method with
two-level channel–spatial feature integration. <em>IJPRAI</em>,
<em>38</em>(14), 2455016. (<a
href="https://doi.org/10.1142/S0218001424550164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification methods currently encounter challenges in feature learning, primarily due to difficulties in expressing the correlation between local features and integrating global and local features effectively. To address these issues, a pose-guided person re-identification method with Two-Level Channel–Spatial Feature Integration (TLCSFI) is proposed. In TLCSFI, a two-level integration mechanism is implemented. At the first level, TLCSFI integrates the spatial information from local features to generate fine-grained spatial features. At the second level, the fine-grained spatial feature and the coarse-grained channel feature are integrated together to complete channel–spatial feature integration. In the method, a Pose-based Spatial Feature Integration (PSFI) module is introduced to generate the pose union feature, which calculates intra-body affinity to guide the integration of spatial information among local pose feature maps. Then, a Channel and Spatial Union Feature Integration (CSUFI) module is proposed to efficiently integrate the channel information of the global feature and the spatial information of the pose union feature. Two individual networks are designed to extract channel and spatial information, respectively, in CSUFI, which are then weighted and integrated. Experiments are conducted on three publicly available datasets to evaluate TLCSFI, and the experimental results demonstrate its competitive performance.},
  archive      = {J_IJPRAI},
  author       = {Ruohong Huan and Xin Zhao and Nan Gao and Peng Chen and Ronghua Liang},
  doi          = {10.1142/S0218001424550164},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2455016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {TLCSFI: A pose-guided person re-identification method with two-level Channel–Spatial feature integration},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantics-fusion: Radar semantic information-based
radar–camera fusion for 3D object detection. <em>IJPRAI</em>,
<em>38</em>(14), 2455015. (<a
href="https://doi.org/10.1142/S0218001424550152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of millimeter-wave radar and camera for three-dimensional (3D) object detection represents a pivotal technology for autonomous driving, yet it is not without its inherent challenges. First, the radar point cloud contains clutter, which can result in the generation of impure radar features. Second, the radar point cloud is sparse, which presents a challenge in fully extracting the radar features. This can result in the loss of object information, leading to object misdetection, omission, and a reduction in the robustness. To address these issues, a 3D object detection method based on the semantic information of radar features and camera fusion (Semantics-Fusion) is proposed. Initially, the image features are extracted through the centroid detection network, resulting in the generation of a preliminary 3D bounding box for the objects. Subsequently, the radar point cloud is clustered based on the objects’ position and velocity, thereby eliminating irrelevant point cloud and clutter. The clustered radar point cloud is projected onto the image plane, thereby forming a radar 2D pseudo-image. This is then input to the designed 2D convolution module, which enables the full extraction of the semantic information of the radar features. Ultimately, the radar features are fused with the image features, and secondary regression is employed to achieve robust 3D object detection. The performance of our method was evaluated on the nuScenes dataset, achieving a mean average precision (mAP) of 0.325 and a nuScenes detection score (NDS) of 0.462.},
  archive      = {J_IJPRAI},
  author       = {Ziran Tian and Xiaohong Huang and Kunqiang Xu and Xujie Sun and Zhenmiao Deng},
  doi          = {10.1142/S0218001424550152},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2455015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Semantics-fusion: Radar semantic information-based Radar–Camera fusion for 3D object detection},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing incremental few-shot video action recognition with
cluster compression and generative separation. <em>IJPRAI</em>,
<em>38</em>(14), 2455013. (<a
href="https://doi.org/10.1142/S0218001424550139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Class Incremental Learning (FSCIL) is a trending topic in deep learning, addressing the need for models to incrementally learn novel classes, particularly in real-world scenarios where continuously emerging classes come with limited labeled samples. However, the majority of FSCIL research has been dedicated to image classification and object recognition tasks, with limited attention given to video action classification. In this paper, we present a new Cluster Compression and Generative Separation (CCGS) method for Incremental Few-Shot Video Action Recognition (iFSVAR), which introduces contrastive learning to boost the degree of class separation in the base session. Simultaneously, it creates numerous fine-grained classes with diverse semantics, effectively filling the unallocated representation space. Experimental results on UCF101, Kinetics, and Something-Something-V2 demonstrate the effectiveness of the framework.},
  archive      = {J_IJPRAI},
  author       = {Yanfei Qin and Renxin Chu and Baolin Liu},
  doi          = {10.1142/S0218001424550139},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2455013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Advancing incremental few-shot video action recognition with cluster compression and generative separation},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rib fracture detection model based on faster-RCNN-SE-FA
algorithm. <em>IJPRAI</em>, <em>38</em>(14), 2452025. (<a
href="https://doi.org/10.1142/S0218001424520256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problem of missed diagnosis in rib fracture detection from CT scans, this study introduces an enhanced model, called Faster-RCNN-SE-FA, which is built upon the traditional Faster-RCNN architecture. The proposed model integrates a novel filter anchor method and thoroughly considers the specific imaging characteristics of ribs in CT images. The preprocessing of the image is followed by applying the Squeeze-and-Excitation (SE) module, which enhances the discrimination of features in the channel dimension while preserving the location Sensitivity (Sen) important for target detection tasks. Consequently, this modification leads to a significant improvement in model performance. Empirical experiments, conducted on CT sequences of 130 rib feature cases provided by the First Affiliated Hospital of Ningbo University, demonstrate that the Faster-RCNN-SE-FA model achieves better Sen and accuracy compared to traditional methods, including the baseline Faster-RCNN.},
  archive      = {J_IJPRAI},
  author       = {Xiuchao He and Zhoujian Qiu and Yingqing Zeng and Zhaoqiang Shen and Yuning Pan and Chunliang Zhou},
  doi          = {10.1142/S0218001424520256},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2452025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Rib fracture detection model based on faster-RCNN-SE-FA algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motion recognition based on deep learning algorithm.
<em>IJPRAI</em>, <em>38</em>(14), 2452022. (<a
href="https://doi.org/10.1142/S0218001424520220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced scientific and technological measurement methods are the basis of sports research and the progress of sports research methods. It promotes the continuous improvement of sports technology to meet athletes’ pursuit of excellent sports achievements. Therefore, the method of sports scientific research must be changed from the traditional empirical training mode to the programmed training method, from the qualitative analysis of the training effect to the nuanced analysis of the training process. Based on this, this paper uses in-depth learning to study sports motion capture. First, two-dimensional human joints are extracted based on Mask R-CNN. Then, the 3D human motion skeleton is constructed by using the binocular vision system, and the Mask R-CNN human pose estimation algorithm is optimized. On this basis, a sports motion capture system is designed, and the system’s accuracy is verified. The error of the depth information obtained by the sports capture system constructed in this paper is less than 3% in the experiment of about 2 m. It has strong practicability.},
  archive      = {J_IJPRAI},
  author       = {Xue Wang and Li Liu and Yingxing Zhang},
  doi          = {10.1142/S0218001424520220},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2452022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Motion recognition based on deep learning algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Investigation on the optimization strategy of DWA algorithm
for path planning of the USVs with the consideration of environmental
factors. <em>IJPRAI</em>, <em>38</em>(14), 2451015. (<a
href="https://doi.org/10.1142/S0218001424510157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned surface vessels (USVs) are generally subjected to wind force, wave and undercurrent action. Some unidentified objects such as underwater obstacles and submerged reefs should be monitored and evaded with converged communication, autonomous control and network system so as to achieve autonomous and automatic avoidance of danger and real-time control of flight path. Next, based on performing interference mechanics analysis on the USVs under the disturbance of wind force and wave on water surface, the relationship parameters between the bow angle, the deviation angle, safety evaluation function and the external force were obtained, and the comprehensive information of water surface environment was evaluated in combination with the dynamic window approach (DWA) algorithm. Further, the related model was established for simulation by using the simulation software MATLAB, and both reliability and stability of the modified DWA algorithm were designed and examined. Accordingly, the modified DWA algorithm can enhance the safety of the USVs in autonomous path planning and achieve rapid obstacle avoidance and autonomous path planning of the USVs. Our simulation revealed that the modified DWA algorithm can safely and rapidly correct the bow angle and the deviation angle, optimize the path trajectory and reduce the risk of roll-over of the USVs under sudden external force.},
  archive      = {J_IJPRAI},
  author       = {Changjiang Liu and Jie Zhang and Ning Li and Qinghua Zhuo and Kaihuan Yu and Kaixin Lin},
  doi          = {10.1142/S0218001424510157},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2451015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Investigation on the optimization strategy of DWA algorithm for path planning of the USVs with the consideration of environmental factors},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection of novel classes in dynamic data streams.
<em>IJPRAI</em>, <em>38</em>(14), 2450021. (<a
href="https://doi.org/10.1142/S0218001424500216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every second, a huge volume of multi-dimensional data is generated in fields such as Social Networking, Industrial Internet of Things, Stock market and E-commerce applications. Knowledge and pattern extraction are a challenging task in the evolving nature of data stream. Major issues are (i) ‘concept drift’ occurs as a result of pattern changes in the data distribution and (ii) ‘concept evolution’ occurs when a new class evolves in the data stream. These issues degrade the performance of learning models. In this paper, we focus on detection of concept evolution and enhance the performance of classifiers. For this, we propose a new model to identify novel classes, namely, Detection of Novel Classes (DNC). The proposed method adopts long short term memory to continuously observe the streaming data in order to detect emerging classes. The continuous monitoring allows the model to distinguish between existing classes and the novel classes which save time and memory. Also, the proposed method is demonstrated for identifying more than one novel class. The experiments are performed over seven different datasets. The results confirm the efficiency is increased ranging from 6% to 34% by the proposed method in identifying new concepts in the evolving data stream than the existing methods available in the literature.},
  archive      = {J_IJPRAI},
  author       = {Nalini Nagendhiran and Lakshmanan Kuppusamy},
  doi          = {10.1142/S0218001424500216},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2450021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Detection of novel classes in dynamic data streams},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Review of hyperspectral image classification based on deep
learning. <em>IJPRAI</em>, <em>38</em>(14), 2432001. (<a
href="https://doi.org/10.1142/S021800142432001X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral Image (HSI) with its high resolution spatial and spectral information, has important applications in military, aerospace and civil applications. The classification methods have become the focus of the field as a significant research aspect of hyperspectral remote monitor engineering for earth reflexion. Because of its high dimensional nature, high relation between bands and spectral variety, traditional classification methods are difficult to achieve high precision and accuracy which limits the development of HSI classification technology. In the past years, with the fast recrudesce of deep learning engineering, its powerful feature extraction ability can remarkably ameliorate the accuracy of HSI classification, HSI classification on account of deep learning has become a feasibility study hotspot. In this paper, the methods of HSI classification on account of deep learning are reviewed. First, the research background of HSI classification is introduced and the deep neural network models which are expensively used in the field of HSI classification are summarized. On this basis, some HSI classification methods on account of deep learning are introduced in detail. Finally, the breakthrough aspects of deep learning in the map of HSI classification are summarized at the current stage and the future research direction is prospected.},
  archive      = {J_IJPRAI},
  author       = {Yujuan Liu and Aoxing Hao and Yanda Liu and Chunyu Liu and Zhiyong Zhang and Yiming Cao},
  doi          = {10.1142/S021800142432001X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2432001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Review of hyperspectral image classification based on deep learning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal information fusion dynamic target recognition for
autonomous driving. <em>IJPRAI</em>, <em>38</em>(14), 2355016. (<a
href="https://doi.org/10.1142/S0218001423550169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of autonomous driving technology, realizing high-precision road obstacle detection is crucial to ensure traffic safety and driving experience. However, traditional obstacle detection methods often perform poorly in complex driving scenarios, such as obstacle movement and occlusion. To cope with this problem, this study proposes a road obstacle detection method based on a two-stream convolutional neural network model, aiming to overcome the limitations of traditional methods in capturing spatiotemporal features and handling complex situations. Our research approach is based on the following innovations: First, we introduce a dual-stream convolutional neural network structure, where one stream is used to extract spatial features from the contour information of the obstacle frames, and the other stream extracts temporal features from the temporal stream information. This dual-stream structure can fully capture the appearance and dynamic information of the obstacles, thus improving detection accuracy. Second, we design a feature fusion module to fuse the two features to obtain richer obstacle features. In addition, we propose a new loss function, i.e. clustering loss, for better optimizing the model training process, reducing intra-class variation, and increasing inter-class differences, thus improving the generalization performance of the model. In the experimental section, we conducted extensive experimental analysis using Citycapes and BDD100K datasets. The experimental results show that our model achieves significant performance improvement compared to both the traditional convolutional neural network method and the YOLOv5 method in a variety of scenarios such as obstacle stationary, obstacle moving, and obstacle with occlusion. Specifically, our method improves the recognition rate up to 4.8% to 14.5% on the Citycapes dataset and 6.5% to 12.8% on the BDD100K dataset, respectively, under different scenarios. In addition, our model also exhibits more advantages on small datasets, showing higher generalization ability and robustness.},
  archive      = {J_IJPRAI},
  author       = {Mingrong Zhang and Qi Peng and Min Li and Yunpeng Shang},
  doi          = {10.1142/S0218001423550169},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {14},
  pages        = {2355016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multimodal information fusion dynamic target recognition for autonomous driving},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MASS and COLREGS–adaptability, challenges and coping
strategies. <em>IJPRAI</em>, <em>38</em>(13), 2459016. (<a
href="https://doi.org/10.1142/S021800142459016X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discussions surrounding Maritime Autonomous Surface Ships (MASS) are occurring in academia, industry, and the International Maritime Organization (IMO). Automatic collision avoidance, as one of the key technologies of MASS, is the core of the autonomous navigation function of MASS, and its role is to solve the autonomous collision avoidance problem during MASS navigation. Convention on the International Regulations for Preventing Collisions at Sea (COLREGS) is a fundamental basis for automatic collision avoidance, and the navigation of MASS should adhere to it. However, the applicability of MASS to COLREGS has not yet been resolved. Responding to these issues, the paper proceeds to analyze the principal challenges of MASS to COLREGS in terms of the application of MASS to good seamanship, the neglect provision, the lookout provision, the insight of one another provision, and the problems of the deviation provision. Furthermore, suggestions are put forth for the revision of COLREGS, including the mode of revision, the reconstruction of MASS collision liability, the long-term coexistence of MASS and traditional ships, and the risk control of COLREGS revision in the context of artificial intelligence. These suggestions aim to establish a foundation for a more effective adaptation to the advent of the MASS era.},
  archive      = {J_IJPRAI},
  author       = {Wen Ma and Mingqiao Chen and Xintong Huang and Yaxin Zeng},
  doi          = {10.1142/S021800142459016X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2459016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {MASS and COLREGS–Adaptability, challenges and coping strategies},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Speech fatigue recognition under small samples based on
generative adversarial networks and BLSTM. <em>IJPRAI</em>,
<em>38</em>(13), 2458005. (<a
href="https://doi.org/10.1142/S0218001424580059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issue of low accuracy in speech fatigue recognition (SFR) under small samples, a method for small-sample SFR based on generative adversarial networks (GANs) is proposed. First, we enable the generator and discriminator to adversarially train and learn the features of the samples, and use the generator to generate high-quality simulated samples to expand our dataset. Then, we transfer discriminator parameters to fatigue identification network to accelerate network training speed. Furthermore, we use a bidirectional long short-term memory network (BLSTM) to further learn temporal fatigue features and improve the recognition rate of fatigue. 720 speech samples from a self-made Chinese speech database (SUSP-SFD) were chosen for training and testing. The results indicate that compared with traditional SFR methods, like convolutional neural networks (CNNs) and long short-term memory network (LSTM), our method improved the SFR rate by about 2.3–6.7%, verifying the effectiveness of the method.},
  archive      = {J_IJPRAI},
  author       = {Shuxi Chen and Jianlin Qiu and Haifei Zhang and Yifan Yu and Hao Chen and Yiyang Sun},
  doi          = {10.1142/S0218001424580059},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2458005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Speech fatigue recognition under small samples based on generative adversarial networks and BLSTM},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An image dataset and an effective detection algorithm for
human body acupoints. <em>IJPRAI</em>, <em>38</em>(13), 2457012. (<a
href="https://doi.org/10.1142/S021800142457012X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of artificial intelligence, computer vision technology has been widely used in the fields of security monitoring, automatic driving and wisdom city. However, there has not been a research on the detection of the meridians in human bodies by using the computer vision technology. In order to promote the use of the computer vision technology in human meridian detection, this paper first releases a dataset based on human meridians, which makes up for the gap in the field of human meridian detection using image processing technology. Moreover, the human meridian detection dataset is manually annotated and proofread by experienced Traditional Chinese Medicine (TCM) practitioners according to the position and direction of the human meridians, so that the annotated human meridians are as accurate as possible. The released human meridian dataset label’s 12 meridians, including spleen meridian, pericardium meridian, stomach meridian, lung meridian, heart meridian, kidney meridian, gallbladder meridian, liver meridian, triple energizer meridian, bladder meridian, large intestine meridian and small intestine meridian. A total of 296 acupoints were labeled. At last, this paper proposes a method for data augmentation, especially for datasets with a small amount of data, wherein the data amount can be augmented by enhancing the underlying edge visual features of the data. Experimental results show that human meridians can be detected by using image processing technology, and the proposed method for data augmentation can effectively improve the detection accuracy of human meridians. The dataset can be downloaded from https://www.zksylf.com/col.jsp?id=127 .},
  archive      = {J_IJPRAI},
  author       = {Yugui Zhang and Anyi Feng and Liping Zhang and Bin Li and Lu Zhang and Fengcai Cao and Weijun Li and Linpeng Wang and Xu Liu and Mingliang Zhou},
  doi          = {10.1142/S021800142457012X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2457012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An image dataset and an effective detection algorithm for human body acupoints},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lightweight-shaped object grasping detection network based
on feature fusion. <em>IJPRAI</em>, <em>38</em>(13), 2455010. (<a
href="https://doi.org/10.1142/S0218001424550103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic grasping techniques for regular targets with known shapes are now well established. However, unknown shaped objects have complex features such as texture, shape, and appearance, which leads to inaccurate recognition and localization of shaped objects during grasp detection. To improve the generalization ability of the grasping detection network for unfamiliar shaped objects, we propose a lightweight shaped object grasping detection network (LSOGD) based on feature fusion, which solves the problem that the network repeatedly extracts features from images and ultimately improves the accuracy of model detection by combining different features. The effectiveness of LSOGD is confirmed by performance evaluation on the Cornell dataset and Jacquard dataset, where the detection accuracy reaches 97.9% and 96.7% for unknown objects, respectively. In addition, due to the small proportion of shaped objects in the current publicly available dataset, we added a portion of industrial-shaped pieces based on the selection of some shaped objects in the Cornell grasping dataset to build a shaped object dataset named X-Cornell on which the accuracy of our proposed model for grasping and detecting the unknown shaped objects is 94.6%. Finally, an actual robot grasping experiment was conducted using a Realsense d435i camera and a Kinova robotic arm, and the success rate of grasping shaped objects was 94%.},
  archive      = {J_IJPRAI},
  author       = {Peng Zhang and Yupei Xing and Shuang Li and Dongri Shan},
  doi          = {10.1142/S0218001424550103},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2455010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lightweight-shaped object grasping detection network based on feature fusion},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual target interaction modeling with multichannel data
fusion. <em>IJPRAI</em>, <em>38</em>(13), 2455008. (<a
href="https://doi.org/10.1142/S0218001424550085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facing the demand for accurate, fast, and natural human–computer interaction in the multi-screen control environment, the traditional exchange method of frequent switching control of multi-screen through mouse, keyboard, and other manual methods has problems of low efficiency, weak flexibility, and poor experience. In this paper, we research multi-screen precision control technology based on eye movement to break through the difficulties of precise recognition of human vision under complex environments and poor stability of vision estimation under frequent switching control of multi-screen. This study explores the technology for controlling multiple screens with high precision by tracking eye movements. It overcomes the challenges associated with reliably discerning human visual focus in intricate settings and the instability of visual assessments during rapid transitions between multiple screens. The experimental results of 1143 eye-movement capture tasks are studied, including the accurate recognition technology of human head posture and pupil gaze direction under complex backgrounds, illumination, and different visual field environments, and the theoretical modeling method of multi-screen precise target interaction based on eye-movement is explored. The expression data will be processed using convolutional neural networks, and the dataset will be trained through Python programming and tested on test samples collected by simulated flight crews in the laboratory with an accuracy rate of more than 85%.},
  archive      = {J_IJPRAI},
  author       = {Mingwei Zhao and Changlong Cai and Wenbo Huang and Longtao Mu and Hao Zhang and Lingzhi Yan and Yonghui Liu and Jiaming Wang},
  doi          = {10.1142/S0218001424550085},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2455008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Visual target interaction modeling with multichannel data fusion},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image super-resolution reconstruction based on dense
residual attention and multi-scale feature fusion. <em>IJPRAI</em>,
<em>38</em>(13), 2454015. (<a
href="https://doi.org/10.1142/S0218001424540156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to obtain super-resolution images with richer details and clearer textures, a method for image super-resolution reconstruction using dense residual attention and multi-scale fusion is proposed. First, different scale convolutions are used to fully extract shallow features of the image; then high-frequency features of the image are extracted through one three-layer cascaded multi-scale feature fusion and dense residual attention module, and the reuse of feature map is achieved; finally, residual branches are used to introduce shallow features and high-frequency features of each channel image, and the high-resolution images are reconstructed through up-sampling and sub-pixel convolution. The test results on the Set5, Set14, Bsd100, and Urban100 datasets show that the PSNR and SSIM of our model are superior to most current algorithms, especially in the case of × 4 reconstruction results. PSNR has improved by 0.2 dB on the Set5 and Bsd100 datasets, and the algorithm has a better subjective visual effect.},
  archive      = {J_IJPRAI},
  author       = {Jianguo Shi and Yu Xiu and Ganyi Tang},
  doi          = {10.1142/S0218001424540156},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2454015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Image super-resolution reconstruction based on dense residual attention and multi-scale feature fusion},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LL-diff: Low-light image enhancement utilizing langevin
sampling diffusion. <em>IJPRAI</em>, <em>38</em>(13), 2454013. (<a
href="https://doi.org/10.1142/S0218001424540132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new algorithm called LL-Diff, which is innovative compared to traditional augmentation methods in that it introduces the sampling method of Langevin dynamics. This sampling approach simulates the motion of particles in complex environments and can better handle noise and details in low-light conditions. We also incorporate a causal attention mechanism to achieve causality and address the issue of confounding effects. This attention mechanism enables us to better capture local information while avoiding over-enhancement. We have conducted experiments on the LOL-V1 and LOL-V2 datasets, and the results show that LL-Diff significantly improves computational speed and several evaluation metrics, demonstrating the superiority and effectiveness of our method for low-light image enhancement tasks. The code will be released on GitHub when the paper has been accepted.},
  archive      = {J_IJPRAI},
  author       = {Boren Ding and Xiaofeng Zhang and Zekun Yu and Zheng Hui},
  doi          = {10.1142/S0218001424540132},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2454013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {LL-diff: Low-light image enhancement utilizing langevin sampling diffusion},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global texts, unified action: Tackling cyberbullying across
multiple languages. <em>IJPRAI</em>, <em>38</em>(13), 2453003. (<a
href="https://doi.org/10.1142/S0218001424530033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyberbullying, a widespread issue in digital communication, involves using online platforms to harass or demean individuals. Addressing it effectively requires understanding its manifestations across different linguistic contexts. This study presents a novel approach to cyberbullying detection, exploring its manifestations in seven languages through two distinct research paradigms: monolingual and multilingual scenarios. The monolingual approach focuses on developing and testing detection models within a single language framework. In contrast, the multilingual approach, which has shown superior performance, integrates data from multiple languages to train a unified model. This innovative strategy aims to harness broader linguistic diversity and enhance the model’s generalizability. We utilized three computational models: SONAR + DNN, MUSE + CNN-BiLSTM, and XLM-RoBERTa, with the SONAR + DNN architecture demonstrating the most effective performance. This model combines SONAR’s sentence-level embeddings with the nuanced understanding of DNN, making it particularly adept at handling the complex variations of cyberbullying across languages. Our results indicate that multilingual models perform better, particularly in languages with significant representation, such as Arabic and English. Our evaluation shows that our models consistently outperform the best-recorded results on seven diverse datasets, achieving superior performance in six. This significant achievement underscores the robustness of our approach and marks an essential advancement in cyberbullying detection.},
  archive      = {J_IJPRAI},
  author       = {Azhi Faraj and Semih Utku},
  doi          = {10.1142/S0218001424530033},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2453003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Global texts, unified action: Tackling cyberbullying across multiple languages},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HPNet: Text detection network with hybrid attention and
pixel aggregation for irregularly-shaped nearby texts. <em>IJPRAI</em>,
<em>38</em>(13), 2453002. (<a
href="https://doi.org/10.1142/S0218001424530021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene text detection is a challenging topic in computer vision, characterized by complex illumination, irregular shape, and arbitrary size. While recent advancements have been made in scene text detection, it remains difficult to simultaneously distinguish nearby text and accommodate irregularly shaped text. Therefore, this paper introduces HPNet, an enhanced text detector, based on the segmentation method that predicts two-scale results. To improve the shape robustness, the Hybrid Attentional Feature Fusion (HAFF) module is integrated into Feature Pyramid Networks (FPN) to dynamically perform feature fusion. Additionally, to distinguish nearby text, the model predicts the text region covering text instances and the text kernel covering the central region of the text. The improved Pixel Aggregation (PA) algorithm is then utilized to guide the expansion from the text kernel to the text region. Experiments on IC15, Total-Text, and CTW1500 validate the effectiveness of these improvements and the superiority of HPNet. Compared with the previous method PSENet for nearby texts, the proposed HPNet has improved inference speed by 63.6% and F -measure metric by 2.6%, 3.7%, and 2.5% on three datasets, respectively.},
  archive      = {J_IJPRAI},
  author       = {Guojin Pei and Zekun Wang and Jian Chu and Genke Yang},
  doi          = {10.1142/S0218001424530021},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2453002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {HPNet: Text detection network with hybrid attention and pixel aggregation for irregularly-shaped nearby texts},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fire recognition method based on PSO-BP neural network and
ResNet50. <em>IJPRAI</em>, <em>38</em>(13), 2450022. (<a
href="https://doi.org/10.1142/S0218001424500228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of modern society and continuous urbanization have resulted in a proliferation of functional buildings, which offer significant convenience to individuals, but pose significant fire hazards as well. How to detect the fire at the early stage is always the focus of research. This paper proposes a multi-information source fusion fire recognition method based on particle swarm optimization (PSO)-backpropagation (BP) neural networks and ResNet50. The PSO algorithm is applied to optimize the initial parameters of a BP neural network model, while data from three sensors — temperature, humidity and smoke — are integrated, through iterative training of the system, accurate recognition of sensor data can be achieved. Additionally, a method is proposed for the recognition of infrared fire images using ResNet50 and transfer learning. By improving the ResNet50 network model and migrating the ResNet50 pre-trained network weight, infrared fire image recognition accuracy is further enhanced. Then the sensor information recognition results and image information recognition results are input into the fuzzy system for fusion reasoning again, and the final decision is output according to the set fuzzy rules. Experimental findings demonstrate that the multi-information source fusion approach utilizing the PSO-BP neural network and ResNet50 significantly enhances the accuracy and response time of fire recognition, and achieves a remarkable recognition effect.},
  archive      = {J_IJPRAI},
  author       = {Jing Ren and Xiaoyan Shi and Xianghong Cao},
  doi          = {10.1142/S0218001424500228},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2450022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Fire recognition method based on PSO-BP neural network and ResNet50},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ShNFN: Shepard neuro-fuzzy network for intrusion detection
in fog computing. <em>IJPRAI</em>, <em>38</em>(13), 2450018. (<a
href="https://doi.org/10.1142/S0218001424500186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing is a type of distributed computing that makes data storage and computation closer to the network edge. While fog computing offers numerous advantages, it also introduces several challenges, particularly in terms of security. Intrusion Detection System (IDS) plays a crucial role in securing fog computing environments by monitoring network traffic and system activities for signs of malicious behavior. Several techniques can be employed to enhance intrusion detection in fog computing environments. Accordingly, this paper proposes a Shepard Neuro-Fuzzy Network (ShNFN) for intrusion detection in fog computing. Initially, in the cloud layer, the input data are passed to data transformation to transform the unstructured data into structured form. Here, data transformation is done employing the Box-Cox transformation. Following this, the feature selection is done in terms of information gain and symmetric uncertainty process and it is used to create a relationship between two variables. After that, the data are classified by employing the proposed ShNFN. The ShNFN is attained by fusing two networks, such as Cascade Neuro-Fuzzy Network (Cascade NFN) and Shepard Convolutional Neural Networks (ShCNN). After this, the physical process is executed at the endpoint layer. Finally, intrusion detection is accomplished in the fog layer by the proposed ShNFN method. The performance of the intrusion detection using ShNFN is calculated by the metrics of recall, F -measure and precision. The proposed method achieves the values of 93.3%, 92.5% and 94.8% for recall, F -measure, and precision, respectively.},
  archive      = {J_IJPRAI},
  author       = {Ganeshan R and Meesala Sravani and Archana Kalidindi and Om Prakash P G},
  doi          = {10.1142/S0218001424500186},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2450018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {ShNFN: Shepard neuro-fuzzy network for intrusion detection in fog computing},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). X-ray bone image processing based on improved densenet.
<em>IJPRAI</em>, <em>38</em>(13), 2357005. (<a
href="https://doi.org/10.1142/S0218001423570057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of convolutional neural network has been gradually introduced in the field of X-ray bone images. At present, there is less research on methods to automatically detect abnormal parts of the skeleton. The method improves on the Densenet network by adjusting the network structure, adding a convolutional block attention module (CBAM) attention mechanism to the original Densenlayer, fusing spatial attention and channel attention to suppress unnecessary features and strengthen the network‘s capability to extract image features, and optimizing the Transition block by fusing two pooling strategies, average and maximum, to increase the model’s anti-interference capability. The data collected after the experiment show that the improved Densenet has increased accuracy in the detection of skeletal abnormalities at all sites compared with the traditional network. The average accuracy is 1–5% higher than the benchmark method, the highest elbow accuracy reached 77.62%, the lowest hand accuracy also reached 64.28% and the area under the receiver operating characteristic curve is increased by 3–7%, the highest reached 80.83%.},
  archive      = {J_IJPRAI},
  author       = {Nanxun Wang and Mengran Zhou},
  doi          = {10.1142/S0218001423570057},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {13},
  pages        = {2357005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {X-ray bone image processing based on improved densenet},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Configurable customized information extraction and
processing pipeline. <em>IJPRAI</em>, <em>38</em>(12), 2459012. (<a
href="https://doi.org/10.1142/S0218001424590122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting information from scanned business documents, while a necessary commercial task, continues to be mostly done manually, requiring significant human effort. Current solutions for automated document information extraction still have limited capabilities in regards to user-required customizability and extraction of dataset-specific information, leaving the area as a very active field of research. In this paper, we propose modifications and improvements to our previously developed custom pipeline for extracting and tabulating key-value pairs from commercial invoice documents. Our design changes and additions adapt the pipeline to a wider variety of document types and use cases, primarily through the implementation of dataset-specific configuration files that promote customizability along with new technical modules that address both general and dataset-specific complexities. We compare our pipeline’s performance against current machine learning and commercial solutions on a real-world dataset, and demonstrate that it is able to extract a wider variety of fields while maintaining competitive or greater accuracies compared to the alternate solutions.},
  archive      = {J_IJPRAI},
  author       = {Seok Kim and Pierce Lai and Dariyan Khan and Kevin Zhao and Brian Le and Alex Luchianov and Margaret Yu and Patrick Wang},
  doi          = {10.1142/S0218001424590122},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2459012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Configurable customized information extraction and processing pipeline},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structural design and flight simulation of firefighting and
rescue UAV based on coaxial dual rotors. <em>IJPRAI</em>,
<em>38</em>(12), 2458004. (<a
href="https://doi.org/10.1142/S0218001424580047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technology of firefighting unmanned aerial vehicles (UAVs) used in fire scene reconnaissance, water disaster investigation, and rescue missions, has become a crucial asset in responding to fires and emergencies. The key to this technology is to swiftly and effectively improve the operational efficiency of UAVs. Based on the premise of rapid and effective rescue, the stability, tracking, and safety of hexacopter UAVs technology improved the design and optimization innovative design of the storage and transportation convenience structure of unmanned aerial vehicles were carried out. An innovative high-pressure ejection mechanism for fire bombs (delivery items) has been designed. So, a portable, efficient, and fast unmanned aerial vehicle structure was designed. The PX4 flight control system was used to conduct simulation experiments on the newly designed UAV, and it was found that the structural design was reasonable, and the UAV was operated smoothly and accurately during the simulation flight. This structural design and simulation analysis can provide new ideas for the design of new fire-fighting equipment.},
  archive      = {J_IJPRAI},
  author       = {Shanshan Zhang and Chunming Tong and Yun Ni and Ning Li and Zhuliang Lin},
  doi          = {10.1142/S0218001424580047},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2458004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Structural design and flight simulation of firefighting and rescue UAV based on coaxial dual rotors},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Medical x-ray image enhancement using global
contrast-limited adaptive histogram equalization. <em>IJPRAI</em>,
<em>38</em>(12), 2457010. (<a
href="https://doi.org/10.1142/S0218001424570106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In medical imaging, accurate diagnosis heavily relies on effective image enhancement techniques, particularly for X-ray images. Existing methods often suffer from various challenges such as sacrificing global image characteristics over local image characteristics or vice versa. In this paper, we present a novel approach, called G-CLAHE (Global-Contrast Limited Adaptive Histogram Equalization), which perfectly suits medical imaging with a focus on X-rays. This method adapts from Global Histogram Equalization (GHE) and Contrast Limited Adaptive Histogram Equalization (CLAHE) to take both advantages and avoid weakness to preserve local and global characteristics. Experimental results show that it can significantly improve current state-of-the-art algorithms to effectively address their limitations and enhance the contrast and quality of X-ray images for diagnostic accuracy.},
  archive      = {J_IJPRAI},
  author       = {Sohrab Namazi Nia and Frank Y. Shih},
  doi          = {10.1142/S0218001424570106},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2457010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Medical X-ray image enhancement using global contrast-limited adaptive histogram equalization},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic segmentation model for parkinson’s images based on
SA-u2-net. <em>IJPRAI</em>, <em>38</em>(12), 2457009. (<a
href="https://doi.org/10.1142/S021800142457009X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To effectively solve the problem of a small proportion of substantia nigra and midbrain regions in Magnetic Resolution Imaging (MRI) images of Parkinson’s disease (PD) patients, unclear boundaries with surrounding tissues, and difficulty in accurately delineating boundaries, an improved U 2 -Net algorithm for Parkinson’s substantia nigra midbrain image segmentation was proposed. This algorithm first improves the Residual U-blocks (RSU) and RSU-4F modules using the Shuffle Attention (SA) module, enhancing the network’s attention to Parkinson’s substantia nigra and midbrain blurry regions in the encoding and decoding layers. Next, replace some ordinary convolutions in RSU-4F with DynamicConv (DyConv), capture local features through dynamic convolution kernels, and improve the segmentation performance of Parkinson’s images. The experimental data used clinical data, and the improved algorithm achieved Dice, Precision, Recall, and mIou of 80.27%, 89.99%, 88.88%, and 82.38% in substantia nigra segmentation, respectively. The experimental results show that this algorithm can achieve more precise segmentation of Parkinson’s images.},
  archive      = {J_IJPRAI},
  author       = {Hui Li and Zixuan Yang and Weimin Qi and Xinchen Yu and Jiaying Wu and Haining Li},
  doi          = {10.1142/S021800142457009X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2457009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automatic segmentation model for parkinson’s images based on SA-u2-net},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimized improved random forest-fostered glaucoma detection
from fundus retinal images. <em>IJPRAI</em>, <em>38</em>(12), 2457004.
(<a href="https://doi.org/10.1142/S0218001424570040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma is a major cause of irreversible blindness caused by optic nerve damage. The ophthalmologist uses retinal examination of the dilated pupil to diagnose this disease. Since this diagnosis is a manual and laborious procedure, an automated technique is required for faster diagnosis. Automated retinal image processing is deemed a competitive research field owing to its lower accuracy results, complication and improper effects related with it. Therefore, Optimized Improved Random Forest fostered Glaucoma Detection from Fundus Retinal Images (IRF-MOSOA-GD) is proposed in this paper. Here, Images are acquired through the datasets of DRISHTI-GS, ORIGA and RIM_ONE and given to the pre-processing. The pre-processing is carried out utilizing the Savitzky–Golay Denoising technique for eliminating the noise at the input images. Then the pre-processed image is given to the feature extraction phase. In the feature extraction phase, the region features are extracted with the help of the Fuzzy color and Texture histogram (FCTH), Edge histogram and Pyramid Histograms of Orientation Gradients (PHOG) method. Then, the extracted feature is fed to the Improved Random Forest (IRF) classifier for categorizing the normal and Glaucoma images. The hyperparameter of the IRF classifier is tuned with a Multi-Objective Squirrel Optimization Algorithm (MOSOA) to attain better categorization of normal and glaucoma images. The proposed technique is implemented in Java and its efficiency is analyzed under some metrics, like accuracy, F-scores and computational time. The IRF-MOSOA-GD method attains higher accuracy in the DRISHTI-GS dataset at 23.6%, 27.55% and 24.98% higher accuracy compared with existing techniques.},
  archive      = {J_IJPRAI},
  author       = {B. Pandeeswari and K. Alice},
  doi          = {10.1142/S0218001424570040},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2457004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimized improved random forest-fostered glaucoma detection from fundus retinal images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic face detection of farm images based on an enhanced
lightweight deep learning model. <em>IJPRAI</em>, <em>38</em>(12),
2456009. (<a href="https://doi.org/10.1142/S0218001424560093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of precise management, artificial intelligence has garnered significant attention and adoption, particularly within the domain of smart agriculture. In modern animal husbandry, animal face detection is conducive to individual identification, expression detection and behavior analysis of animals, and this technological advancement holds immense importance in fostering the advancement of intelligent farming practices. In order to solve the challenge of face detection caused by similar appearance features (color, texture, etc.) and no obvious feature differences between the solid-color goats and sheep in the natural environment, this research introduces a novel approach for face detection by combining the capabilities of YOLOv5 and a convolutional block attention module (CBAM). First, datasets of goats and sheep with different angles, scales and densities were constructed. Second, the basic framework of YOLOv5 was used for object detection. To address the obstacle posed by the limited presence of distinguishing features on the faces of goats and sheep, this study aims to overcome the challenge of extracting informative facial characteristics. The CBAM block was introduced to construct the YOLOv5-CBAM model to improve the feature extraction ability. Finally, 2412 images were selected and divided into training set and verification set according to 8:1. The experimental results of this dataset show that the proposed YOLOv5-CBAM model yielded remarkable results with a precision rate of 0.970, a recall rate of 0.890, a mAP@0.5 score of 0.935, an frames per second (FPS) of 140.845, and a model size of 14.680 MB. In comparison to other approaches such as Faster R-CNN, SSD, YOLOv3, and YOLOv5, the proposed model demonstrated superior performance in some aspects. In addition, it excelled in both lightweight design and overall effectiveness, and it is well-suited for real-time detection of animal faces in real-world farming settings, ensuring efficient identification and monitoring of animals within practical agricultural environments.},
  archive      = {J_IJPRAI},
  author       = {Xiaoping Huang and Fei Huang and Jiahui Hu and Huanyu Zheng and Mengyi Liu and Zihao Dou and Qing Jiang},
  doi          = {10.1142/S0218001424560093},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2456009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automatic face detection of farm images based on an enhanced lightweight deep learning model},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid convolution-based efficientnet-based hand gesture
recognition framework with optimized algorithm. <em>IJPRAI</em>,
<em>38</em>(12), 2456008. (<a
href="https://doi.org/10.1142/S0218001424560081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difficulties in communication and hearing are an important concern for deaf–dumb people, which stop access to their essential and basic needs. Many findings have been made to address sign languages even though this challenging problem is not still solved. Many methods aimed to propose vision-based classifiers through identical pattern investigation tasks by obtaining the difficult handcraft feature descriptions of gestures from the gathered images. However, the efficacy of all those models is less for performing with a huge signbook captured from uncontrolled and complex background conditions. So, an effective Indian Sign Language (ISL) classification method is developed by an advanced deep learning approach. At first, the hand gesture images are obtained from the data source. Only the image of the hand, even from a complicated background, is extracted from the obtained image. The features are extracted using the Scale-Invariant Feature Transform (SIFT) method and Multiscale Vision Transformer (MVT). Then, the extracted features are fed to the Hybrid Convolution-based EfficientNet (HCEN) model. The hyper-parameters in the developed HCEN model are tuned using the implemented Adaptive Political Optimizer (APO) algorithm. The recognized hand signs are obtained from the suggested HCEN model. Various experiments are conducted to determine the performance of the suggested deep learning-based hand gesture recognition model.},
  archive      = {J_IJPRAI},
  author       = {J. Jency Rubia and R. Babitha Lincy and C. Sherin Shibi},
  doi          = {10.1142/S0218001424560081},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2456008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hybrid convolution-based efficientnet-based hand gesture recognition framework with optimized algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CoFix: Advancing semi-supervised learning with noisy label
mitigation through sample selection and consistent regularization.
<em>IJPRAI</em>, <em>38</em>(12), 2452024. (<a
href="https://doi.org/10.1142/S0218001424520244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) have revolutionized various fields through their ability to model complex patterns, yet their performance critically hinges on the availability of large-scale, accurately labeled datasets. The costly and time-consuming process of creating such datasets has motivated research into Learning with Noisy Labels (LNL), which aims to reduce reliance on perfect labels. This paper introduces CoFix, an innovative LNL framework that integrates sample selection with semi-supervised learning techniques to address the challenge of noisy labels in training. CoFix employs a Gaussian Mixture Model (GMM) to dynamically segment the training data into clean and noisy subsets, leveraging semi-supervised learning approaches on both. Inspired by the FixMatch algorithm, CoFix refines consistent regularization and pseudo-labeling strategies, enhancing augmentation strategies and temperature sharpening techniques. Additionally, CoFix explores label smoothing to augment the loss function, further refining model performance. Our experiments demonstrate CoFix’s superiority over state-of-the-art methods, achieving significant improvements in fewer training epochs, particularly in lower noise scenarios. The robustness and versatility of CoFix are evident through its consistent performance across various benchmark datasets and noise levels. The contributions of this paper include a novel LNL method with enhanced generalization capability, an investigation into the impact of label smoothing on the loss function, and extensive testing that confirms CoFix’s efficiency and adaptability to different noise levels.},
  archive      = {J_IJPRAI},
  author       = {Yexin Ma},
  doi          = {10.1142/S0218001424520244},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2452024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CoFix: Advancing semi-supervised learning with noisy label mitigation through sample selection and consistent regularization},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DESMPA-deep CNN: Double exponential smoothing marine
predator algorithm-based deep CNN for liver tumor segmentation and
classification. <em>IJPRAI</em>, <em>38</em>(12), 2452021. (<a
href="https://doi.org/10.1142/S0218001424520219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, liver cancers are well-known cancers attacking the human body. The larger segment of liver carcinomas is highly affected by alcohol-associated hepatitis as well as cirrhosis circumstances. In order to increase the survival rate of humans, premature and early diagnosis of liver cancer is very vital. Currently, discriminating the tumor and liver segments from medical imaging with the help of entirely automated computer-aided software is a highly difficult task, because the liver tumor may differ from one human being to another human being. Thus, this paper endeavors to present a new liver tumor segmentation and classification approach by incorporating an optimization-enabled deep learning model. Here, the adopted model comprises four stages, pre-processing, liver segmentation, liver tumor detection, and classification. To begin with, the collected images are given to the pre-processing stage using the African vulture’s optimization-based adaptive histogram equalization (AVOAHE). The integration of the African vulture’s optimization (AVO) concept in adaptive histogram equalization is named AVOAHE. After the image pre-processing phase, the liver region is segmented by utilizing kernel-based fuzzy C-means clustering. Then, the detection of liver tumor is performed using the Swin-Unet. Finally, tumor detection is done by utilizing the deep convolutional neural network (Deep CNN). Moreover, a hybrid optimization approach, called double exponential smoothing (DES)-marine predator algorithm (MPA), is developed by combining DES and MPA, which is used to train Deep CNN and serves as an enhancement. Finally, the experimental analysis has shown that the adopted technique has achieved better results in terms of accuracy, specificity, sensitivity, and precision with values of 0.957, 0.969, 0.941 and 0.915, respectively.},
  archive      = {J_IJPRAI},
  author       = {Aparna P. R. and Libish T. M.},
  doi          = {10.1142/S0218001424520219},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2452021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DESMPA-deep CNN: Double exponential smoothing marine predator algorithm-based deep CNN for liver tumor segmentation and classification},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning optimization of target velocity curves in
hybrid electric trains. <em>IJPRAI</em>, <em>38</em>(12), 2451019. (<a
href="https://doi.org/10.1142/S0218001424510194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study tackles the challenge of refining the target velocity curves for hybrid electric trains, governed primarily by onboard Automatic Train Operation (ATO) systems. These systems take into account various factors, such as the interstation line conditions and the specific traction and braking characteristics of hybrid trains. Traditional approaches, which rely on fixed speed–position sequences to navigate trains and ensure safety through the Automatic Train Protection (ATP) system, struggle to adapt to dynamic environmental changes, leading to compromised operational efficiency. In response, our research adopts a machine learning framework, with a particular emphasis on reinforcement learning, to devise a real-time, flexible optimization model for determining the train’s target velocity curve. This model harnesses the potential of the double-depth Q network to enhance the optimization process. The primary objective is to improve the punctuality and energy efficiency of train operations while simultaneously increasing passenger comfort through better adaptation to environmental variations. Simulation results demonstrate that the newly optimized target velocity curve notably diminishes the on-time errors for hybrid trains and achieves approximately 0.98% in energy savings compared to traditional heuristic algorithms. These outcomes highlight the significant advantages of integrating sophisticated machine learning techniques like double-depth Q network to boost the efficiency and sustainability of hybrid electric train operations.},
  archive      = {J_IJPRAI},
  author       = {Jinling Ma and Jiye Zhang and Hao Sui},
  doi          = {10.1142/S0218001424510194},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2451019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Machine learning optimization of target velocity curves in hybrid electric trains},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of generative adversarial networks in
semi-annotated defect synthesis and detection under limited resources.
<em>IJPRAI</em>, <em>38</em>(12), 2450019. (<a
href="https://doi.org/10.1142/S0218001424500198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defect detection is a crucial technology that is extensively employed in the manufacturing industry to monitor and ensure the quality of output. Deep learning models have shown remarkable potential for defect detection. However, the success of these models heavily relies on voluminous training data. Collecting substantial amounts of defect data is challenging in practical settings, and the tedious process of pixel-level defect annotation further complicates the task. Among the common defects encountered in manufacturing, scratches are particularly significant. To address these challenges, this study proposes a two-phase generative adversarial network (GAN) approach for synthesizing defect images and generating semi-automatic pixel-wise labels for anomaly detection. The first phase primarily focuses on synthesizing images, while the second phase involves the pixel-wise labeling of the images. The synthesized paired images generated by the GANs serve as input to the semantic network. Notably, the proposed methodology requires only a few real defect samples for training and a small amount of annotated data, making it practical and computationally efficient for implementation in the manufacturing industry. Experimental results indicate the effectiveness of the proposed deep-learning solution in defect detection, specifically in identifying scratches on various textured and patterned surfaces. A notably high detection accuracy is achieved, validating the potential of the approach in real-world manufacturing scenarios.},
  archive      = {J_IJPRAI},
  author       = {Shih-Hsien Tseng and Yuan-Ke Tsai},
  doi          = {10.1142/S0218001424500198},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2450019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Application of generative adversarial networks in semi-annotated defect synthesis and detection under limited resources},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient voice-based emotion recognition using hybrid
capsule slime mould dense deep learning framework. <em>IJPRAI</em>,
<em>38</em>(12), 2450017. (<a
href="https://doi.org/10.1142/S0218001424500174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition is an acceptable task of understanding the other’s emotions and thoughts. Modern technology allows machines to recognize objects without the need for human intervention. The existing emotion recognition system faces more difficulties in making an accurate result with limited audio files. To address this problem, a Bag of audio terms-based hybrid deep learning models will be introduced it is known as the pioneering deep learning model. Input voice data is considered from a large dataset and pre-processed using a Data normalization and adaptive bilinear filtering approach. Afterward, acoustic features are taken out from the voice signals to capture related information for emotion recognition. These features can include linear prediction coefficients (LPC), three-dimensional (3D) log-mel spectrum, mel-frequency cepstral coefficients (MFCCs), and Prosodic features. Subsequently, feature selection is performed using an improved wild horse optimization (WHO) approach. Finally, a hybrid capsule slime mould dense deep learning framework (HCSDN) is used for voice-based emotion recognition. IEMOCAP and EMODB datasets are used to calculate system performance. The performance metrics denote the proposed system achieves 96.78% accuracy, 96.45% specificity, 95.81% precision, 4.256% error rate, and 94.256% sensitivity, 0.75% false positive rate in terms of the IEMOCAP dataset. Similarly, the proposed system achieves 96.85% accuracy, 95.74% specificity, 96.12% precision, 3.432% error rate, 95.25% sensitivity, and 0.62% false positive rate in terms of the EMODB dataset.},
  archive      = {J_IJPRAI},
  author       = {V. V. Satyanarayana Tallapragada and M. Naresh and G. V. Pradeep Kumar and V. Sireesha},
  doi          = {10.1142/S0218001424500174},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2450017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An efficient voice-based emotion recognition using hybrid capsule slime mould dense deep learning framework},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Abnormal detection of commutator surface defects based on
YOLOv8. <em>IJPRAI</em>, <em>38</em>(12), 2450013. (<a
href="https://doi.org/10.1142/S0218001424500137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The YOLOv8 model has high detection efficiency and classification accuracy in detecting commutator surface defects, aimed at the problem of low working efficiency of a commutator, caused by commutator surface defects. First, the theoretical framework of Region-based Convolutional Neural Networks (R-CNN), spatial pyramid pooling (SPP)-net, Fast R-CNN, and Faster R-CNN is introduced, and the detection principle and process are described in detail. Secondly, the principle of the YOLOv8 network structure, head structure, neck structure, and C2f module are explained, and the loss function is described. The average precision of the proposed algorithm for detecting cracks and small points is more than 98%, and the frames per second (FPS) is 27. The detection results are mapped to the original image, and the visualization of the commutator surface defect detection is obtained, which has a higher robustness, accuracy, and real-time performance than the R-CNN, SPP-net, Fast R-CNN, and Faster R-CNN algorithms.},
  archive      = {J_IJPRAI},
  author       = {ZhiYuan Li and Ban-Hoe Kwan and Mau-Luen Tham and Oon-Ee Ng and Patrick Shen-Pei Wang},
  doi          = {10.1142/S0218001424500137},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {12},
  pages        = {2450013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Abnormal detection of commutator surface defects based on YOLOv8},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On quantification of the nonlinearity of PPV in model
evaluation with imbalanced datasets. <em>IJPRAI</em>, <em>38</em>(11),
2459011. (<a href="https://doi.org/10.1142/S0218001424590110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a quantitative analysis of the nonlinearities of the positive predictive value (PPV) and its effect in evaluating two-class pattern classification models with imbalanced datasets. The analysis is made through an expression of the PPV as a function of two other classification ratios that are invariant to the data imbalance —the true positive rate (TPR) and false positive rate (FPR), and σ — the imbalance ratio (IR) of the dataset such that PPV = σ TPR/( σ TPR + FPR). The curvatures of PPV in the three-dimensional TPR–FPR– σ space are studied using the Hessian matrix, from which a saddle-shaped 3D surface in the space is revealed. This paper explores the nonlinear behaviors of PPV around the critical points, identified at FPR = σ TPR on the saddle surface, along with its scaling and sensitivity issues as performance measurements in model evaluation. The effect of the nonlinearities of PPV for the F1 and MCC metrics on imbalanced datasets is also studied. It is warned through the results of this study that the evaluations of classification models could be misleading if without an awareness and understanding of the nonlinearities associated with the PPV and its relevant metrics on imbalanced datasets.},
  archive      = {J_IJPRAI},
  author       = {Qiuming Zhu},
  doi          = {10.1142/S0218001424590110},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2459011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {On quantification of the nonlinearity of PPV in model evaluation with imbalanced datasets},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IoT computing collaboration and data-aware routing algorithm
for edge computing and DL. <em>IJPRAI</em>, <em>38</em>(11), 2459010.
(<a href="https://doi.org/10.1142/S0218001424590109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of mobile edge computing and neural network Deep Learning (DL), more and more scholars are studying the combination of the two. This paper mainly studies the application of mobile edge computing and neural network DL in IoT computing collaboration and data-aware routing algorithms. Therefore, this paper proposes the deployment options of MEC technology and ETSIMEC in mobile edge computing, combining mobile edge computing with DL, designs an optimization algorithm based on Markov decision process and feature expression learning, and then analyzes and optimizes IoT computing and VANET routing algorithm. In order to have a clearer direction for the optimization algorithm, this paper also designs the edge computing model training and experiment comparison, the DL algorithm comparison experiment, and the routing algorithm simulation experiment and performance analysis. Combined with the experimental results, it is optimized and compared with traditional IoT computing and routing algorithms. Finally, it is concluded that the computing efficiency of IoT computing based on edge computing and DL designed in this paper is 21.33% higher than that of traditional IoT computing. The efficiency of the routing algorithm based on edge computing and DL designed in this paper is 9.29% higher than that of the traditional routing algorithm.},
  archive      = {J_IJPRAI},
  author       = {Bo Li and JinHong Tang and Zhihe Yang and Qing Jiang and Jingyang Wei},
  doi          = {10.1142/S0218001424590109},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2459010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {IoT computing collaboration and data-aware routing algorithm for edge computing and DL},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Video surveillance system-based human activity recognition
using hierarchical auto-associative polynomial convolutional neural
network with garra rufa fish optimization. <em>IJPRAI</em>,
<em>38</em>(11), 2456007. (<a
href="https://doi.org/10.1142/S021800142456007X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, video surveillance systems are gaining increasing attention in the computer vision fields due to user demands for security purposes. Observing human movement and predicting such movement perception are promising due to video surveillance systems. In this work, Hierarchical Auto-Associative Polynomial Convolutional Neural Networks (HA-PCNN) with Garran Rufa Fish Optimization (GRFO) is proposed for Human Activity Recognition (HAR) using a video surveillance system. Initially, video surveillance systems-based human activity images are obtained, which are collected by video camera by recording daily human activities. After that, the input images are fed to a pre-processing approach named as Switched Mode Fuzzy Median Filter (SMFM) method. In this, the noise presented in the input images is reduced by applying the SMFM model to normalize the dataset and improve the image quality. After that, the pre-processed images are given to the developed Fast Discrete Curvelet Transform with Wrapping (FDCT-WRP)-based feature extraction method to extract the relevant features. Moreover, the extracted features are given to the HA-PCNN model for HA classification. Generally, the HA-PCNN method does not express any adoption of optimization methods for scaling the ideal parameters and classification. Here, Garra Rufa Fish Optimization (GRFO) is proposed to enhance the parameters of HA-PCNN. Thus, the proposed HA-PCNN-GRFO methodology can classify human activities like standing, sitting, running, walking and sleeping. By then the performance of the proposed HA-PCNN-GRFO methodology is evaluated using Python Platform, and metrics like recall, accuracy, F-measure, precision, and specificity are analyzed. Thus, the proposed HA-PCNN-GRFO approach achieved 97.3% average accuracy rate, 96.5% average recall, 97.2% average precision, 95.9% average specificity, and 96.8% average F1-score for classifying human activities using UCI HAR dataset. Also, the proposed HA-PCNN-GRFO approach is outperformed in HAR than the conventional approaches.},
  archive      = {J_IJPRAI},
  author       = {Prasanth Thiruvenkatam and Prabu Thangavel and Krishnasamy Balasubramanian and Sridhar Sekar},
  doi          = {10.1142/S021800142456007X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2456007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Video surveillance system-based human activity recognition using hierarchical auto-associative polynomial convolutional neural network with garra rufa fish optimization},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Underwater bubble plume recognition algorithm based on
multi-feature fusion understanding. <em>IJPRAI</em>, <em>38</em>(11),
2455009. (<a href="https://doi.org/10.1142/S0218001424550097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater bubble plume images contain a wealth of information on wave field and flow characteristics, which can provide valuable research data for marine development, environmental protection, and underwater surveys. However, based on fusing image features and wave field environment features, identifying accurately the underwater bubble plume is still very difficult. In order to improve the accuracy and robustness of bubble plume identification in complex underwater environments, an underwater bubble plume recognition algorithm based on multi-feature fusion understanding is proposed. In this paper, a weight-independent dual-channel residual convolutional neural network (CNN) for feature extraction of the original optical images and the nonsubsampled contourlet transform (NSCT) low-frequency images, and the multi-scale composite feature map groups are generated. Then adaptive fusion is performed based on the feature contribution of the target in different types of images. Next, logical region of interest (ROI) masks are generated by the attention mechanism and superimposed on the fused image to further highlight the target features. Finally, the multi-scale dual-channel fused feature maps containing ROI masks are used for underwater bubble plume target recognition. The experimental results show that the designed recognition network can effectively fuse the features of the original optical images and the NSCT low-frequency imagers, improve the depth of information fusion, and retain the target texture features and the morphological features while reducing the interference of the background information, and have good recognition accuracy and robustness for multi-scale bubble targets in the underwater environment.},
  archive      = {J_IJPRAI},
  author       = {Xue Yang and Shiming Sun},
  doi          = {10.1142/S0218001424550097},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2455009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Underwater bubble plume recognition algorithm based on multi-feature fusion understanding},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PCB defect detection based on improved deep learning model.
<em>IJPRAI</em>, <em>38</em>(11), 2454014. (<a
href="https://doi.org/10.1142/S0218001424540144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Printed circuit boards (PCBs) play a critical role in electronic products. Ensuring these products’ long-term reliability and consistent performance requires effective PCB defect detection. Although existing deep learning models for PCB defect detection are not highly accurate, they often neglect capability considerations. This paper introduces a precise, fast, and lightweight defect detection model, CCG-YOLO, based on an enhanced YOLOv5 model to address this issue. The enhancements in CCG-YOLO can be summarized as follows: (1) Improved Backbone network: The feature extraction ability of the Backbone network is enhanced by introducing a C3HB module, which fosters spatial interaction capabilities. (2) Lightweight feature fusion network: A lightweight convolution structure called Ghost-Shuffle Convolution is incorporated in the feature fusion network, remarkably reducing model parameters while maintaining performance. (3) Efficient residual networking: To enhance model performance further, a CNeB module is introduced based on the ConvNeXt network, which replaces the C3 module in the Neck. CNeB improves model detection accuracy and reduces the number of model parameters. The combination of these enhancements results in impressive performance. CCG-YOLO achieves mean average precision (mAP@0.5) of 99.5% and 88.75% in mAP@0.5:0.95 on the TDD-Net public dataset. Compared with the original YOLOv5s algorithm, CCG-YOLO offers a 4.24% improvement in mAP@0.5:0.95, a 1 MB reduction in model size, a 0.472 M decrease in the number of parameters, a 0.6G floating point operation reduction in computational complexity, and a 120 frames per second real-time inference speed. These experimental results underscore that the proposed model excels in accuracy and speed and has a compact size for PCB defect detection. Moreover, CCG-YOLO is easily deployable on low-end devices, making it well-suited for meeting the real-time requirements of industrial defect detection.},
  archive      = {J_IJPRAI},
  author       = {Shih-Hsien Tseng and Chi Kuo},
  doi          = {10.1142/S0218001424540144},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2454014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {PCB defect detection based on improved deep learning model},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Study on the effect of multi-gap arrester truncation on the
overvoltage of lightning intrusion wave. <em>IJPRAI</em>,
<em>38</em>(11), 2454009. (<a
href="https://doi.org/10.1142/S0218001424540090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightning protection near the fan is the key point of lightning protection in wind farm, which affects the safe and effective delivery of wind power resources. At present, the three-phase multi-gap arrester installed on a base tower behind the collector can cooperate with the zinc oxide arrester to reduce the system failure caused by the arrester failure. However, the chopped wave generated by the multi-gap arrester when it acts is transmitted to the fan box transformer along the line, which may threaten the insulation of the transformer winding. Based on the above problems, this paper builds a simulation model on ATP to analyze the impact of wave clipping of multi-gap arrester on the insulation of fan transformer windings, considers the conventional installation mode and the limit installation mode of multi-gap arrester, and calculates that the wave clipping overvoltage generated by multi-gap arrester after being struck by lightning in two cases is the impact on the insulation of fan transformer. Through the simulation analysis, it is found that the higher the amplitude of the lightning current, the larger the amplitude of the overvoltage generated by the truncated wave, the steeper the wave head, and the greater the threat to the insulation of the fan box. The damage degree of round lightning is less than that of counter lightning. When a multi-gap arrester is installed in a collector tower, the 100 kA lightning current may destroy the insulation of the fan box transformer winding and require additional protective measures. It is recommended that the multi-gap arrester be installed from the next pole tower of the collector tower in the wind farm.},
  archive      = {J_IJPRAI},
  author       = {Weixiang Huang and Xiuqing Lin and Qianyi Chen and Yeqiang Deng and Yu Wang and Caiwei Pan},
  doi          = {10.1142/S0218001424540090},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2454009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Study on the effect of multi-gap arrester truncation on the overvoltage of lightning intrusion wave},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An intelligent model of anomaly detection and anomaly
localization in images using hybrid heuristic adaptive multiscale
attention-based DenseNet and cascaded variational autoencoder.
<em>IJPRAI</em>, <em>38</em>(11), 2454007. (<a
href="https://doi.org/10.1142/S0218001424540077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection and localization become necessary since humans are unable to spot visual frauds. Since it differs from the normal representation of shapes, colors, textures, size, and location, it does not have the potential to be employed in such practical applications. Hence, the automatic anomaly detection and localization framework is suggested for supporting situations like industrial systems, healthcare systems and so on. The detection and localization are the most intriguing and challenging concerns in image processing. In general, anomalies can manifest themselves in diverse ways. Detection is the process of providing information about whether an image contains modifications or not. On the other hand, localization is defined as locating the anomalies in images. Several traditional models have been deployed, but they still lack such constraints to evade performance enhancement. To sort out this issue, a novel adaptive method is recommended for anomaly detection and localization in images. Initially, the source images are acquired from standard public data sources. Once the required images are collected, such abnormal or anomalous activities are detected by adopting the new method known as Adaptive Multiscale Attention-based DenseNet (AMA-DeNet), where the hyperparameters are tuned by a hybrid algorithm known as the Hybrid Chimp Grasshopper Optimization Algorithm (HCGOA). Subsequently, the final stage is localizing the anomalies in the detected images. This is to be accomplished by using the Cascaded Variational Autoencoder (CVA), in which parameters are optimally chosen by HCGOA. After implementation, the experimental results are computed across diverse validating measures. Hence, the extensive results elucidate that the recommended model contains the potential to detect the abnormalities in the images accurately, thereby enhancing the efficiency of the new system.},
  archive      = {J_IJPRAI},
  author       = {L. Leena Jenifer and K. Devaki},
  doi          = {10.1142/S0218001424540077},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2454007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An intelligent model of anomaly detection and anomaly localization in images using hybrid heuristic adaptive multiscale attention-based DenseNet and cascaded variational autoencoder},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced lithium-ion battery SOH estimation using
bayesian-optimized CNN deep learning approach. <em>IJPRAI</em>,
<em>38</em>(11), 2452020. (<a
href="https://doi.org/10.1142/S0218001424520207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate health status evaluation of lithium-ion batteries is crucial for preemptive identification of potential battery failures and averting hazardous incidents, given its essential role in indicating the extent of battery degradation. The challenge in determining the State of Health (SOH) arises from the absence of a precise and standardized definition, as well as the difficulty in measuring essential input variables. Therefore, this paper utilizes current and voltage data during the charge and discharge process as direct inputs for SOH estimation and proposes a deep learning-based lithium-ion battery SOH estimation approach. Specifically, it leverages Bayesian optimized Convolutional Neural Network (CNN) within a data-driven framework. Experimental results demonstrate that the proposed deep learning method achieves a Mean Absolute Error (MAE) of 1% and a Maximum Error (MAX) below 4% in estimation accuracy, highlighting its enhanced precision and robustness.},
  archive      = {J_IJPRAI},
  author       = {Xiaorong Huang and Jionghui Wei and Jieming Huang and Qingbo Zhang and Rongfu Zhong and Rijing Lai},
  doi          = {10.1142/S0218001424520207},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2452020},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Enhanced lithium-ion battery SOH estimation using bayesian-optimized CNN deep learning approach},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimized deep LSTM-based multi-object tracking with
occlusion handling mechanism. <em>IJPRAI</em>, <em>38</em>(11), 2452016.
(<a href="https://doi.org/10.1142/S0218001424520165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-object tracking is a basic computer vision process having a huge class of real-life tools that range from monitoring of medical video to surveillance. The goal of tracking numerous items is to place numerous objects in a scene, handle their identities throughout time, and construct trajectories for analysis. However, this is a complex task, because of certain issues like occlusions, complicated object dynamics, and variations in the appearance of objects. In this research, a new technique named TPRO-based Deep LSTM is developed for tracking multi-object with occlusion handling. Here, the videos are considered as input wherein the extraction of frames is done from each video. Each frame undergoes pre-processing with filtering to eliminate noise from frames. By using a sparse Fuzzy c-Means (FCM) and Local Optimal-Oriented Pattern (LOOP) features, the localization of objects is done. Moreover, the visual and spatial trackings are considered for hybrid tracking. The second derivative model and neighborhood search model are used to perform visual tracking. Then the occlusion handling is performed. Concurrently, with the use of Deep Long Short-Term Memory (Deep LSTM) the spatial tracking is performed and the Taylor Poor Rich Optimization (TPRO) algorithm assigns the weight and bias of the Deep LSTM. The TPRO is obtained by the unification of the Taylor series along with the Poor and Rich Optimization algorithm. By combining visual and spatial tracking, the final tracked output is generated. The devised method achieves a performance with the highest value of 88.9% for Multiple Object Tracking Precision (MOTP), smallest tracking distance (TD) of 4.185, average MOTP of 0.889, average TD of 4.201, and highest tracking number (TN) of 14.},
  archive      = {J_IJPRAI},
  author       = {Shital V. Sokashe-Ghorpade and Sanjay Arjunsing Pardeshi},
  doi          = {10.1142/S0218001424520165},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2452016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimized deep LSTM-based multi-object tracking with occlusion handling mechanism},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Applying machine learning techniques: Uncertainty
quantification in nonlinear dynamics characters predictions via gated
recurrent unit-based reduced-order models. <em>IJPRAI</em>,
<em>38</em>(11), 2451018. (<a
href="https://doi.org/10.1142/S0218001424510182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of reduced-order models has been a pivotal advancement in the computational analysis of fluid dynamics, substantially simplifying the complexity and boosting the efficiency of simulations. The accuracy and practicality of these models largely depend on the reduction techniques applied and the inherent characteristics of the fluid dynamics systems they represent. In this paper, we introduce an innovative machine-learning framework for assessing model uncertainty in computationally intensive reduced-order models. By combining subspace construction methods with advanced Bayesian inference techniques, our approach effectively captures the posterior distribution of model parameters, thereby providing an accurate representation of uncertainty in aerodynamic performance predictions. We employ the NACA0012 airfoil as a case study to validate our method’s ability to enhance the efficiency of reduced-order models and precisely measure the uncertainty inherent in predictions made by recurrent neural networks. It is important to note that our approach is influenced by specific constraints and variables that significantly impact the mean and variability of the predicted final lift coefficient distribution. Our findings indicate that setting the goodness of fit ( R 2) threshold above 0.985 markedly improves the correlation between Computational Fluid Dynamics (CFD) outcomes and model predictions, increasing from 72.2% to 97.9% as the interval amplification factor adjusts from 1.5 to 3. However, this adjustment causes a considerable expansion of the confidence interval, from 0.0737 to 0.1282, an increase of over 70%. Despite these challenges, our machine learning-based methodology provides essential insights into the further development of reduced-order modeling and uncertainty quantification in fluid dynamics. This highlights the need for ongoing research into the model parameters, especially in applications concerning aircraft control systems, to meet design specifications and ensure system reliability.},
  archive      = {J_IJPRAI},
  author       = {Xun Peng and Hao Zhu and Dajun Xu and Wenzhi Hao and Weizong Wang and Guobiao Cai},
  doi          = {10.1142/S0218001424510182},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2451018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Applying machine learning techniques: Uncertainty quantification in nonlinear dynamics characters predictions via gated recurrent unit-based reduced-order models},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A method of multiple targets and sensors track association
analysis. <em>IJPRAI</em>, <em>38</em>(11), 2450016. (<a
href="https://doi.org/10.1142/S0218001424500162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to reduce the probability of leakage and improve detection accuracy, multiple radar equipment is required to perform multiple detections on the same airspace. Due to the overlap of airspace, there are multiple local tracks reported by various radar equipment that belong to the same target. The local tracks reported by each radar require track fusion to form a system track, and track association is a prerequisite for track fusion. This paper proposes a multi-target and multi-sensor track association analysis method, which can distinguish whether local tracks come from the same target and associate local tracks with the same target, providing conditions for track fusion to form system tracks. This method divides track association into two steps: Coarse association and fine association, which greatly improves the accuracy of track association.},
  archive      = {J_IJPRAI},
  author       = {Shi Qu and Cangzhen Meng and Hongbin Jin and Xiaobin Huang and Lujun Feng},
  doi          = {10.1142/S0218001424500162},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2450016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A method of multiple targets and sensors track association analysis},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised object cosegmentation method devoted to image
classification. <em>IJPRAI</em>, <em>38</em>(11), 2450014. (<a
href="https://doi.org/10.1142/S0218001424500149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rich heterogeneous data provided by social networks can be very big, which imposes considerable challenges for object extraction and image classification. Therefore, the objective of this work is to propose an unsupervised object cosegmentation method that could be notably efficient to improve image classification performance. The main goal of cosegmentation is to extract the salient common objects within each image. To this end, we propose to minimize an energy function based on the Markov Random Field using the saliency detection, while considering linear dependence of generated foreground histograms of the input image collection. In fact, the saliency detection is processed in two steps. In each image, we detect salient objects, by considering appearance similarity and spatial distributions of image pixels. Then, fuzzy quantification is used to correct the belonging of pixels to the foreground objects. Finally, an iterative optimization permits to enhance the final segmentation results. The proposed method has been validated as a preprocessing step for image classification. Indeed, to enhance cosegmentation-based classification performance, we have applied a semi-supervised object classification based on ensemble projection. Qualitative and quantitative evaluations of the proposed cosegmentation and classification techniques on the iCoseg, CDS and Oxford Flowers 17 datasets demonstrate the effectiveness of the proposed framework.},
  archive      = {J_IJPRAI},
  author       = {Hager Merdassi and Walid Barhoumi and Ezzeddine Zagrouba},
  doi          = {10.1142/S0218001424500149},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {11},
  pages        = {2450014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Unsupervised object cosegmentation method devoted to image classification},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A four-grade astrocytoma classification system with optimal
feature selection using ant colony optimization algorithm.
<em>IJPRAI</em>, <em>38</em>(10), 2457008. (<a
href="https://doi.org/10.1142/S0218001424570088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient Four-Grade Astrocytoma brain tumor classification is proposed in this research work. The work highlights the optimal feature selection using a hybrid combination of Ant Colony Optimization (ACO) algorithm and machine learning techniques, leading to better classification accuracy. A diverse set of features including spatial and frequency domain features will provide better discrimination of patterns. ACO provides a robust and efficient mechanism for exploring the vast space of possible feature subsets. A total of 135 features are extracted including Tamura features, Gabor Wavelet Features, Coiflet Wavelet Coefficients, Speeded Up Robust Features, and GLCM features. Ant Colony Optimization is used to find out the optimum set of features. The selected feature set is used for training a Decision Tree classifier, where the Astrocytoma MRI images are categorized into four grades of astrocyoma namely, pilocytic astrocytoma, diffuse astrocytoma, anaplastic astrocytoma and glioblastoma multiforne. Classification is also performed using KNN classifier, SVM classifier and Ensemble Bagged Tree Classifier. Performance metrics like accuracy, sensitivity, specificity, precision and FScore are utilized to evaluate the proposed system’s performance. It is found out that the decision tree classifier outperforms the other classifiers. Thus this integrated approach of ACO with machine learning classifiers results in improved Astrocytoma classification performance aiding clinicians in making accurate treatment decisions.},
  archive      = {J_IJPRAI},
  author       = {Nimmy George and Manju Manuel},
  doi          = {10.1142/S0218001424570088},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2457008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A four-grade astrocytoma classification system with optimal feature selection using ant colony optimization algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-based segmentation of lesions from wide-field
vitiligo images. <em>IJPRAI</em>, <em>38</em>(10), 2457007. (<a
href="https://doi.org/10.1142/S0218001424570076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation of vitiligo relies on accurate segmentation of lesions, and traditional segmentation methods mainly focus on near-field images. This study proposes a deep learning-based model for accurately segmenting lesions in wide-field vitiligo images. In this study, a dataset of 1267 wide-field vitiligo images was established to train and evaluate segmentation models. A Swin R-CNN model, which combined a Swin Transformer tiny network with a watershed algorithm, was proposed for segmenting lesions. The performances of the Swin R-CNN model and five other models were evaluated and compared through visual and quantitative perspectives. Additionally, the Spearman rank correlation test was performed to analyze result consistency between the Swin R-CNN model and dermatologists in measuring lesion area. The Swin R-CNN model accurately segmented lesions in the wide-field vitiligo images, surpassing other models in both visual and quantitative performance, with an average precision of 84.72% and an average recall of 77.81%. The correlation coefficients between the evaluation results of the Swin R-CNN model and three dermatologists were 0.88, 0.94, and 0.91, respectively. The Swin R-CNN model accurately segments lesions in the wide-field vitiligo images and quantifies lesion area at the dermatologist level. The Swin R-CNN model can provide reliable analytical results for the vitiligo evaluation.},
  archive      = {J_IJPRAI},
  author       = {Zhuangzhuang Fan and Changqing Wang},
  doi          = {10.1142/S0218001424570076},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2457007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep learning-based segmentation of lesions from wide-field vitiligo images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the parameter calibration method for dual-spectral
triocular camera. <em>IJPRAI</em>, <em>38</em>(10), 2455006. (<a
href="https://doi.org/10.1142/S0218001424550061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dual-spectrum triocular camera system composed of a binocular visible light camera and mid-infrared camera is used for high-precision thermal fault detection and thermal field reconstruction of industrial equipment. The realization of its function depends on the high-precision camera parameter calibration. The difficulty lies in how to realize the infrared camera calibration quickly and improve the parameter accuracy of multi-lens camera. In this paper, according to the characteristics of the dual-spectral triocular camera system, the theoretical model is constructed, and the circular asymmetric calibration plate under infrared supplementary light is selected as the calibration object through experiments. A method for combining infrared image adaptive histogram enhancement and binarization processing based on the Sauvola algorithm is proposed to effectively calibrate the infrared camera. A global parameter optimization method based on traditional passive vision binocular stereo calibration is proposed. The optimization of experimental parameters finds the reprojection error value is 0.16, which meets the demand of high-precision calibration and solves the problem of difficult-to-calibrate weak image texture of infrared camera and the calibration accuracy of the camera under different imaging capabilities.},
  archive      = {J_IJPRAI},
  author       = {Peng Zhao and Yan Cao and Tao R. Wan and Yu Guo},
  doi          = {10.1142/S0218001424550061},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2455006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {On the parameter calibration method for dual-spectral triocular camera},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Euler characteristic computation by means of a chain code
applied to binary images. <em>IJPRAI</em>, <em>38</em>(10), 2454012. (<a
href="https://doi.org/10.1142/S0218001424540120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new approach for calculating the Euler characteristic in 2D binary images. The problem is addressed using the Three OrThogonal symbol chain code (3OT code), using only one symbol for the calculation of the Euler characteristic. Using this code, it is possible to introduce new geometric concepts represented by the same symbol of the 3OT alphabet and to simplify the overall equation of the Euler characteristic. This process is supported by the proof of a set of theorems and their numerical validation, using a set of binary images with a variable number of holes. Thus, this research proves that the 3OT code can be used not only for image compression as reported in the literature, but also to simplify the expression of the Euler characteristic as well as for the analysis and simplification of the shape of contours.},
  archive      = {J_IJPRAI},
  author       = {Elisa I. Gómez-Gómez and Hermilo Sánchez-Cruz},
  doi          = {10.1142/S0218001424540120},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2454012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Euler characteristic computation by means of a chain code applied to binary images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structured deep graph clustering network based on
consistency constraint. <em>IJPRAI</em>, <em>38</em>(10), 2452018. (<a
href="https://doi.org/10.1142/S0218001424520189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering is an essential task in data analysis. Recently, there has been a notable trend in the application of deep learning in graph clustering. However, it is worth noting that existing deep graph clustering methods primarily focus on the topological information of nodes while overlooking the use of attribute information in the learned feature representations. In addition, they do not address the consistency of the space distribution in attribute and structure clustering results. To tackle these critical issues, a novel structured deep graph clustering network with consistency constraint (CC-DGC) is proposed. The network first constructs an autoencoder to learn and transmit hierarchical attribute information to the graph autoencoder (GAE). Subsequently, the GAE integrates the received hierarchical attribute information with extracted topological information to generate enhanced clustering representations. Moreover, this paper designs a consistency constraint module to promote consistency between the autoencoder and the GAE by optimizing the cluster space distributions they produce. Finally, the feature extraction and clustering classification processes are synchronized and optimized in a self-supervised manner within a unified framework. Extensive experiments illustrate that the proposed CC-DGC demonstrates superiority over the state-of-the-art deep graph clustering methods on five benchmark datasets.},
  archive      = {J_IJPRAI},
  author       = {Bin Huang and Denghui Wang},
  doi          = {10.1142/S0218001424520189},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2452018},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Structured deep graph clustering network based on consistency constraint},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cr-coot: Chronological coot algorithm-based deep learning
model for video demosaicing. <em>IJPRAI</em>, <em>38</em>(10), 2452015.
(<a href="https://doi.org/10.1142/S0218001424520153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Usually, digital cameras comprise sensor arrays enclosed by Color Filter Arrays (CFAs), mosaics of minute color filters. Thus, every pixel sensor usually records limited spectral data regarding relevant pixels. Demosaicing is defined as the procedure of deducing the misplaced data for every pixel, which plays a vital role in recreating high-quality full-color images. Denoising and demosaicing are the major processes in the camera imaging chain for both videos and images. Here, reconstruction errors occur in these points and have undesirable effects on the final outcome, when it is not appropriately managed. The demosaicing process provokes color and spatial correlation of noises, and it is improved by means of imagining a pipeline. This organized noise usually destroys the quality of the image as well as fails to prevent accurate interpretation of an image. During the mitigation of this structured noise on processed data, denoising techniques diminish the texture and information. Therefore, an effectual demosaicing technique is essential for recreating the full-color image from the defective color samples. Thus, in this paper, an effectual video demosaicing model is proposed using an optimized deep learning system. The designed video demosaicing system achieved better performance with a Peak Signal-to-Noise Ratio (PSNR) of 59.74 dB, Second Derivative, like Measure of Enhancement (SDME) of 63.51, and Root Mean Squared Error (RMSE) of 0.3660.},
  archive      = {J_IJPRAI},
  author       = {A. Babitha and A. Boyed Wesley},
  doi          = {10.1142/S0218001424520153},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2452015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Cr-coot: Chronological coot algorithm-based deep learning model for video demosaicing},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Six-axis robotic gripping control algorithm based on deep
learning. <em>IJPRAI</em>, <em>38</em>(10), 2452004. (<a
href="https://doi.org/10.1142/S0218001424520049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to several complex factors such as the type, size, and shape of target object, vision-assisted robot grasping technology still faces serious challenges. In this research, a deep learning-based robot hand vision grasping algorithm was developed considering semi-structural environmental constraints. The proposed algorithm could build a deep learning network on the basis of the desired object, perform object recognition, category classification and position judgment, and complete robot hand-grasping tasks. The obtained experimental results demonstrated that the proposed algorithm effectively solved the problem of recognizing and classifying multi-category objects in a semi-structured environment, improving recognition rate and grasping rate and reducing collision rate.},
  archive      = {J_IJPRAI},
  author       = {Changwei Xiong and Yanqin Zhang and Yufeng Shu and Chaodong Chen},
  doi          = {10.1142/S0218001424520049},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2452004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Six-axis robotic gripping control algorithm based on deep learning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A divide-and-rule combined learning method for truly
multivariate time series prediction. <em>IJPRAI</em>, <em>38</em>(10),
2451013. (<a href="https://doi.org/10.1142/S0218001424510133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series prediction is a significant research area that aims to forecast future values based on past observations. Deep learning models with attention mechanisms have shown good predictive performance by emphasizing optimal-related sequences in the target series. However, these models ignore mutation information of nontarget sequences and the long short-term dependencies. To this end, a divide-and-rule combined learning method is proposed to address these limitations, which uses differentiated feature extractors to process different implicit features. First, we design a spatial and temporal information extractor to extract the time-dimensional feature information in the separation stage. Then, a multivariate mutation information extractor is constructed by convolution and maximum pooling layer to capture mutation information of nontarget sequences. Subsequently, the decoder component of the encoder-decoder model extracts long short-term dependencies while preserving the information of the target sequence to be predicted. Finally, in the cooperation stage, a feature fusion method based on a point attention mechanism is proposed, which can assign individual weights to each feature point and enhance the ability to focus on local areas. Experimental results on five real datasets in different domains show that the proposed method has better predictive performance compared to other baseline models.},
  archive      = {J_IJPRAI},
  author       = {Bing Wei and Shiqing Sang and Liangyong Yao and Lei Gao and Yan Liu and Tao Han and Jintao Li},
  doi          = {10.1142/S0218001424510133},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2451013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A divide-and-rule combined learning method for truly multivariate time series prediction},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A seismic fault recognition method based on region energy
algorithm. <em>IJPRAI</em>, <em>38</em>(10), 2450015. (<a
href="https://doi.org/10.1142/S0218001424500150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault recognition is a difficult problem in seismic exploration data interpretation, and there is still no solution both well in terms of accuracy and signal-to-noise ratio. To solve this problem, based on the region energy algorithm, a novel fault recognition method is proposed, which determines the direction of fault tracking based on region energy when identifying fault points. First, the third-generation coherence cube algorithm is adopted to calculate the coherence attribute of the seismic data volume. Then, fault tracking is performed on each seismic section. When conducting fault tracking, the seismic sample is scanned and identified one by one. If it is a fault point, it is assigned to the corresponding fault in the connected area, and then, track along a certain direction of the current pixel point in the front left, directly ahead, or front right direction. The selection of the tracking directions is based on the energy of the corresponding area in the direction. The direction with the highest energy is tracked in the direction until the complete fault is tracked or the stopping condition is reached. If the point is not judged as a fault point, a certain distance is tracked down continue and the path is stored temporarily. If a fault point is tracked, the tracking path is classified as a fault, otherwise return to continue scanning. When all the sample points on the seismic section are scanned, the fault tracking on the corresponding section is completed. Subsequently, the fault points are fitted using the least squares fitting algorithm, and the fault line is obtained. Finally, comparative experiments were conducted on actual seismic data, and the effectiveness of the novel method was validated.},
  archive      = {J_IJPRAI},
  author       = {Lei Chen and Yanqing Liang and Guanglei Qi and Ting Zhang},
  doi          = {10.1142/S0218001424500150},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2450015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A seismic fault recognition method based on region energy algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bovine viral diarrhea virus named entity recognition based
on BioBERT and MRC. <em>IJPRAI</em>, <em>38</em>(10), 2450009. (<a
href="https://doi.org/10.1142/S0218001424500095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utilizing deep learning for data mining in biomedicine often falls short in leveraging prior knowledge and adapting to the complexities of biomedical literature mining. Entity recognition, a fundamental task in information extraction, also provides data support for Natural Language Processing (NLP) downstream tasks. Bovine Viral Diarrhea Virus (BVDV) results in considerable economic losses in the cattle industry due to calf diarrhea, bovine respiratory syndrome, and cow abortion. This study aims to extract information on BVDV from relevant literature and build a knowledge base. It enhances feature extraction in the BioBERT pre-trained model using the Machine Reading Comprehension (MRC) framework for information fusion and bi-directionally extracts corpus information through the Bi-LSTM network, followed by a CRF layer for decoding and prediction. The results show the construction of a BVDV Corpus with 22 biomedical entities and introduce the BioBERT-Bi-LSTM-CRF Integrated with MRC (BBCM) model for Named Entity Recognition (NER), combining prior knowledge and the reading comprehension framework (MRC). The BBCM model achieves F 1 -scores of 78.79% and 76.3% on the public datasets JNLPBA and GENIA, respectively, and 67.52% on the BVDV Corpus, outperforming other models. This research presents a targeted NER method for BVDV, effectively identifying related entities and exploring their relationships, thus providing valuable data support for NLP’s downstream tasks.},
  archive      = {J_IJPRAI},
  author       = {YinFei Li and YunLi Bai and RuLin Wang and WeiGuang Zhou},
  doi          = {10.1142/S0218001424500095},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2450009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Bovine viral diarrhea virus named entity recognition based on BioBERT and MRC},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulation analysis and image processing of the exhaust
silencing chamber and coil. <em>IJPRAI</em>, <em>38</em>(10), 2434001.
(<a href="https://doi.org/10.1142/S0218001424340012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The compressor is the most core component of refrigeration products, and its performance directly affects the overall performance of the product. The exhaust silencing chamber and coil are key components of a refrigeration compressor, and their working stability and lifespan determine the reliability and economy of the refrigeration compressor. This paper obtains reference data for the fluid domain of the exhaust silencing chamber through simulation analysis and image processing of the existing exhaust silencing chamber structure and inner diameter size of the coil. Then, the optimal model of the prioritized exhaust chamber is obtained through pattern recognition method. Based on the image processing method, the internal flow field of the exhaust chamber are obtained, providing a strong reference for the optimal structural design of the exhaust silencing chamber and coil of the refrigeration compression body.},
  archive      = {J_IJPRAI},
  author       = {Xiaoyan Wu and Shu Wang},
  doi          = {10.1142/S0218001424340012},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {10},
  pages        = {2434001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Simulation analysis and image processing of the exhaust silencing chamber and coil},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-interest sequential recommendation with simplified
graph convolution and multiple item features. <em>IJPRAI</em>,
<em>38</em>(9), 2459009. (<a
href="https://doi.org/10.1142/S0218001424590092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-interest sequential recommendations leverage users’ historical behavior to provide recommendations that match multiple interests. Most of these methods have not fully extracted higher-order information hidden in users’ interactions and have overlooked the multiple features of items. To this end, this paper proposes a multi-interest model called “multi-interest sequential recommendation with simplified graph convolution and item multi-features (SGCMF)”. Firstly, a simplified graph convolution module is designed based on bipartite graphs, which utilizes mean pooling to aggregate neighboring information and employs a feedforward neural network (FNN) for nonlinear transformations and combinations. This method reduces redundant information and captures higher-order relationships, thereby simplifying the complexity of modeling high-order interactions and improving prediction accuracy. Secondly, an item multi-feature extraction module is proposed, which represents item features with multiple vectors, and analyzes each feature from multiple perspectives while preserving important relationships between features. The model correlates multiple features of the item with user interests, thereby achieving a fine-grained analysis of user interests. Extensive experiments are conducted on five real-world scenarios, and the results are compared with state-of-the-art methods. The experimental results show that SGCMF outperforms other baselines.},
  archive      = {J_IJPRAI},
  author       = {Kelei Sun and Mengqi He and Huaping Zhou and Yingying Wang and Sai Sun},
  doi          = {10.1142/S0218001424590092},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2459009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-interest sequential recommendation with simplified graph convolution and multiple item features},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting flight-driving attitudes through EEG-based
models. <em>IJPRAI</em>, <em>38</em>(9), 2459008. (<a
href="https://doi.org/10.1142/S0218001424590080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the correlation between a pilot’s brain electroencephalographic (EEG) activity and his driving posture, addressing the intricate relationship between cognition and behavior in aviation. We designed and implemented a simulated experiment that recorded the fly pilot’s attitude and collected EEG information as experimental data. The experiment is only based on EEG data to predict flight posture (pull, down, left, right). We propose a flight-driving attitude prediction model (CA-FAP) based on CEBRA and self-attention mechanism, with a prediction accuracy of 0.83. This model is better than common spatial pattern (CSP) and uniform manifold approximation and projection (UMAP) dimension reduction methods in the experiment. Moreover, a better effect can be obtained in the larger attitude radian dataset (accuracy is 0.85), and the effect is not obvious in the dataset of closing the six-axis motion platform, indicating that the model prediction of flight attitude is closely related to the pilot position transformation. By comparing the prediction effect of each category, the pull-up and drop are better than the steering prediction result. The study can help pilots adjust their posture and decisions, and serve as a basis for studying flight pilot cognitive load, mental load, mood changes, and flight performance.},
  archive      = {J_IJPRAI},
  author       = {Pengbo Wang and Hongxi Wang and Heming Zhang and Yawen Wang},
  doi          = {10.1142/S0218001424590080},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2459008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Predicting flight-driving attitudes through EEG-based models},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adjustment for neural network autocorrelation error in
sequence prediction based on frequency decomposition algorithm.
<em>IJPRAI</em>, <em>38</em>(9), 2457005. (<a
href="https://doi.org/10.1142/S0218001424570052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate analysis and prediction of carbon prices are crucial. Nevertheless, their complexity and high volatility pose significant prediction challenges. To address this, we introduce a novel hybrid prediction framework, combining decomposition algorithms with neural networks. Our framework’s core lies in dynamically adjusting data input using the Cochrane–Orcutt procedure, based on the prediction autocorrelation error of component series, enhancing accuracy. To validate its effectiveness, we conducted a comprehensive study using EEX–EUA data, integrating various decomposition algorithms and prediction models. Experimental results reveal that our framework outperforms other algorithms in predicting carbon price.},
  archive      = {J_IJPRAI},
  author       = {Tonghua Hu and Haobin Liang},
  doi          = {10.1142/S0218001424570052},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2457005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Adjustment for neural network autocorrelation error in sequence prediction based on frequency decomposition algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HDMA-CGAN: Advancing image style transfer with deep
learning. <em>IJPRAI</em>, <em>38</em>(9), 2452019. (<a
href="https://doi.org/10.1142/S0218001424520190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of artificial intelligence (AI) and deep learning heralds a transformative era in pattern recognition and computer vision, notably in image style transfer. We introduce the hierarchical dynamic multi-attention cycle generative adversarial network (HDMA-CGAN), an innovative deep learning architecture poised to redefine image style transfer capabilities. HDMA-CGAN employs a novel multi-attention mechanism and color optimization strategies, enabling precise style replication with improved fidelity and vibrancy. Our model surpasses existing benchmarks in image quality, validated by leading metrics such as peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), and Fréchet inception distance (FID). Although HDMA-CGAN advances the state of the art, it necessitates high computational resources and faces challenges with very high-resolution images. Future work could explore optimizing the model’s efficiency for real-time applications and extending its application to video content. This work enhances the tools available for visual content creation and digital media enhancement, leveraging advanced pattern recognition and AI techniques to significantly impact computer vision and image processing.},
  archive      = {J_IJPRAI},
  author       = {Huaqun Liu and Benxi Hu and Yu Cao},
  doi          = {10.1142/S0218001424520190},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2452019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {HDMA-CGAN: Advancing image style transfer with deep learning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-labeling learning ensemble via deep recurrent neural
network and self-representation for speech emotion recognition.
<em>IJPRAI</em>, <em>38</em>(9), 2452017. (<a
href="https://doi.org/10.1142/S0218001424520177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech emotion recognition (SER) methods rely on frames to analyze the speech data. However, the existing methods typically divide a speech sample into smaller speech frames and label them with a single emotional tag, which fails to consider the possibility of multiple emotion tags coexisting within a speech sample. To deal with this limitation, we present a novel approach called self-labeling learning ensemble via DRNN and self-representation (En-DRNN-SR) for SER. This method automatically segments speech sample into speech frames, and then the deep recurrent neural network (DRNN) is applied to learn the deep features, and next the self-representation is built to get a relational degree matrix, finally the speech frames is divided into three parts using a relational degree matrix: the key emotional frames, the compatible emotional frames and the noise frames. The emotion tags of the compatible emotional frames are adaptive cyclic learned based on the key emotion frames vias the relational degree matrix, while also checking the emotion tags associated with the key compatible frames. Additionally, we introduce a new self-labeling criterion based on fuzzy membership degree for SER. To evaluate the feasibility and effectiveness of the proposed En-DRNN-SR, we conducted extensive experiments on IEMOCAP, EMODB, and SAVEE database, the proposed En-DRNN-SR obtains 69.13%, 82.83%, and 52.31% results on IEMOCAP, EMODB, and SAVEE database, which outperformed all competing algorithms. The experimental results clearly demonstrate that the proposed approach outperforms state-of-the-art SER methods, achieving superior performance on feature learning and classification.},
  archive      = {J_IJPRAI},
  author       = {Yan Cui and Xiaoyan Jiang and Yue Dai},
  doi          = {10.1142/S0218001424520177},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2452017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Self-labeling learning ensemble via deep recurrent neural network and self-representation for speech emotion recognition},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep siamese domain adaptation convolutional neural network
optimized with honey badger algorithm for fetal arrhythmia detection and
classification from ECG signals. <em>IJPRAI</em>, <em>38</em>(9),
2452013. (<a href="https://doi.org/10.1142/S021800142452013X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning classification is commonly used to assess biomedical data. Fetal heart rate (FHR) signal data monitor the health of both the mother and the fetus and prevent mobility and death in fetuses at risk of hypoxia. But, the data imbalance is a major problem and happens frequently. To overcome this problem, a Deep Siamese domain adaptation convolutional Neural Network optimized with Honey Badger Algorithm (HBA) is proposed in this paper for Fetal Arrhythmia Detection and Classification from ECG signals (DSDACNN-HBA-FAC). The input ECG signals are collected from the fetal ECG dataset. Then, the ECG data are pre-processed using coherence shock filtering (CSF), which eliminates artifacts, like baseline drift, contact noise, muscle artifacts, electrode motion, electromyography artifacts. Using the improved non-subs sampled Shearlet transform (INSST) method, the pre-processed ECG data recover the mean, standard deviation, root mean square, skewness, kurtosis, zero-crossing, autoregressive coefficients, estimated entropy, and Higuchi’s fractal dimension. The DSDACNN classifier utilizes the features extracted to categorize the output as normal and arrhythmia. In general, DSDACNN does not agree on any optimization techniques to define the optimum parameters and to ensure accurate classification. Therefore, HBA is employed to optimize the DSDACNN weight parameters. The proposed method is implemented in MATLAB. The performance metrics, like sensitivity, precision, recall, f-measure, specificity, accuracy, computation time, RoC, and error rate are evaluated. The performance of DSDACNN-HBA-FAC achieves 3.101%, 7.12%, 7.73% high accuracy, 51.136%, 59.04%, 44.51% lower computation Time and 2.292%, 5.365%, 1.551% greater AUC compared with the existing techniques, like Fetal Arrhythmia Detection with Classification from ECG Signals: A NonInvasive Method (ANN-FAC), Semi-supervised active transfer learning for fetal ECG arrhythmia identification (DNN-FAC), fetal arrhythmia detection using adaptive single channel electrocardiogram extraction (CNN-FAC), respectively.},
  archive      = {J_IJPRAI},
  author       = {Joel T and Sethukarasi T},
  doi          = {10.1142/S021800142452013X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2452013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep siamese domain adaptation convolutional neural network optimized with honey badger algorithm for fetal arrhythmia detection and classification from ECG signals},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-pathway deep hashing-based adversarial learning for
cross-modal retrieval. <em>IJPRAI</em>, <em>38</em>(9), 2451017. (<a
href="https://doi.org/10.1142/S0218001424510170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of deep hashing methods for cross-modal retrieval has seen growing interest due to their storage efficiency and fast query execution. However, the challenge posed by the “heterogeneity gap” in multi-modal datasets cannot be understated. To address this, we present a novel framework named Dual-Pathway Deep Hashing-Based Adversarial Learning (DP-DHAL), engineered to surmount this challenge. The architecture of DP-DHAL integrates three key components: (a) a dual-pathway representation learning module tasked with extracting modality-specific features; (b) an adversarial module working to align the distributions of cross-modal features; and (c) a deep hashing module responsible for generating hash codes that uphold the similarity relationships across different modalities. Additionally, we have developed a unique Hamming triplet-margin loss function to refine the assessment of content similarities. The DP-DHAL model is trained through an adversarial process where the adversarial module’s goal is to discern cross-modal features with the aim of reducing the heterogeneity gap. Simultaneously, the representation learning module is focused on producing representations that can both deceive the adversarial module and preserve cross-modal similarities to yield distinctive hash codes. Comprehensive experiments on varied datasets have shown that our proposed method outperforms other leading cross-modal hashing techniques.},
  archive      = {J_IJPRAI},
  author       = {Zheng Zhang and Yueyang Chen and Tao Li and Lishen Pei},
  doi          = {10.1142/S0218001424510170},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2451017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Dual-pathway deep hashing-based adversarial learning for cross-modal retrieval},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diagnosis of arrhythmia from compressively sensed ECG
signals using machine learning algorithms. <em>IJPRAI</em>,
<em>38</em>(9), 2451016. (<a
href="https://doi.org/10.1142/S0218001424510169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases (CVDs) represent a significant health concern in the present era, with Electrocardiogram (ECG) serving as a crucial bio-signal for their detection. Efficient health monitoring necessitates rapid and precise diagnosis, thereby mandating the utilization of Compressive Sensing (CS) alongside Machine Learning (ML) algorithms. CS functions as a sensing methodology that reduces sample numbers by capturing sparse or compressible representations, simplifying and expediting the acquisition process. In this proposed study, ECG signals are compressively sensed and preprocessed using CS reconstruction algorithms, followed by the application of various ML algorithms for diagnostic purposes. The assessment of the reconstructed ECG signal entails the assessment of Peak Signal-to-Noise Ratio (PSNR) values and Percentage Root-mean-square Difference (PRD). Concurrently, ML algorithms are evaluated based on metrics including accuracy, specificity, and sensitivity. This work demonstrates exceptional performance in terms of acquisition time and computational complexity through the application of CS technology. Comparative analysis with the existing methodologies for CVD diagnosis reveals the proposed approach’s remarkable efficacy. Notably, the reduction in data volume and hardware complexity serves as a significant advantage over conventional methods. The integration of CS and ML algorithms in the proposed methodology proves highly effective in diagnosing CVDs, achieving a classification accuracy of 94.7%. These results underscore the methodology’s ability to deliver both speed and accuracy in diagnosis, positioning it as a promising approach for health monitoring.},
  archive      = {J_IJPRAI},
  author       = {Nimmy Ann Mathew and Renu Jose},
  doi          = {10.1142/S0218001424510169},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2451016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Diagnosis of arrhythmia from compressively sensed ECG signals using machine learning algorithms},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anomaly detection integration-framework for network services
in computer education systems. <em>IJPRAI</em>, <em>38</em>(9), 2451014.
(<a href="https://doi.org/10.1142/S0218001424510145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public computer education systems provide students essential opportunities to enhance computer literacy and information skills. However, the widespread adoption of online education technology exposes the field to several critical security risks. Threats, such as malware infections, data breaches, and other network intrusions, are all challenging the security of education systems, posing potential hazards to students’ personal information and even the entire teaching environment. To spur further work into specialized anomaly detection techniques for computer education, this paper presents an anomaly detection framework tailored for network services in computer education environments to safeguard these systems. Specifically, the proposed approach learns from large-scale online educational traffic data to classify the security state into five alert levels, enabling more granular anomaly detection and analysis. To assess their detection performance, deep learning and traditional machine learning algorithms are implemented and compared for multi-class intrusion classification. The results show that the proposed framework provides an effective security solution to bolster the integrity and stability of computer education systems against evolving network threats, enhancing threat intelligence to inform proactive security by detecting and characterizing anomalies through multilevel classification.},
  archive      = {J_IJPRAI},
  author       = {Shouhong Yang and Jiawei Lin and Qianyu Wang and Na Yang and Xuekai Wei and Xia Yang and Huayan Pu and Jun Luo and Hong Yue and Fei Cheng and Mingliang Zhou},
  doi          = {10.1142/S0218001424510145},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2451014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Anomaly detection integration-framework for network services in computer education systems},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online multi-resource allocation for network slicing in 5G
with distributed algorithms. <em>IJPRAI</em>, <em>38</em>(9), 2359021.
(<a href="https://doi.org/10.1142/S0218001423590218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing scale of mobile cellular network applications, 5G mobile network infrastructure provides customizable services to users in the form of network slices. How to effectively allocate existing resources in real dynamic networks with time-varying network utility is a key issue that previous work did not consider. This paper first initializes the multi-resource allocation problem of network slicing in an online manner, where the utility function is set to change over time. Therefore, we propose Metis, an online network slicing resource allocation framework that combines the time-varying nature of the network utility function given bandwidth and processing power constraints with the requirement of virtual network function isolation. The goal is to maximize the cumulative network utility in the long term and specify multiple resource allocation problems by utilizing concave optimization methods. In addition, a distributed algorithm based on the online alternating direction method of multipliers with regret optimization has been developed to achieve optimal resource allocation. Our mathematical analysis proves that Metis can provably converge to the optimal solution and the result of experiments demonstrates a steady state behavior of Metis, which converges in dynamic network settings.},
  archive      = {J_IJPRAI},
  author       = {Xuebin Tang},
  doi          = {10.1142/S0218001423590218},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {9},
  pages        = {2359021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Online multi-resource allocation for network slicing in 5G with distributed algorithms},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The research of EEG headset of brain–computer interface for
artificial intelligence-related applications. <em>IJPRAI</em>,
<em>38</em>(8), 2459007. (<a
href="https://doi.org/10.1142/S0218001424590079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, a wide range of brain–computer interface (BCI) applications with artificial intelligence (AI) assistance have emerged. While using a head-mounted electroencephalogram (EEG) device for BCI application, it often requires a user to wear the device close to the scalp so that clear EEG signals can be obtained from the head directly. Those signals can be used to determine a user’s mental state. Due to the head size differences between Chinese and European users, as well as the differences between Chinese users themselves, EEG headsets with fixed-electrode-point will enable some electrodes fail to capture a user’s EEG data accurately. Combined with previous research and related design methodology, the design of a head-mounted EEG device is proposed in this paper. In this study, Chinese youth are regarded as the target user group. After evaluating different designs of device structures, the possible positions and movement methods of electrodes, an EEG headset with movable electrodes for young Chinese users is finally delivered.},
  archive      = {J_IJPRAI},
  author       = {Wen Qi and Xi Yu},
  doi          = {10.1142/S0218001424590079},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2459007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {The research of EEG headset of Brain–Computer interface for artificial intelligence-related applications},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the use of pitch-based features for detecting
simultaneous fear emotion and deception behavior from speech.
<em>IJPRAI</em>, <em>38</em>(8), 2456006. (<a
href="https://doi.org/10.1142/S0218001424560068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last years, endowing the machine with emotional and behavioral intelligence has been one of the most challenging issues in the human–computer interaction area. In this context, this paper investigates the detection of simultaneous fear emotion and deception behavior in speech. To do so, a set of 72 pitch-based features has been investigated first to recognize fear and deception separately. Then, different feature selection techniques have been used in order to select the most relevant ones that best discriminate between fear/nonfear and deception/nondeception classes. Next, a decision-level fusion approach based on the belief theory has been proposed to infer whether fear and deception are detected simultaneously. Simulation results carried on databases dealing with fear/nonfear emotions and deception/truth behaviors have shown classification results reaching 83.33% and 72.45% as accuracy rates for fear and deception classifiers, respectively. The proposed fusion approach has revealed a correspondence between fear emotion and deception behavior in speech modality.},
  archive      = {J_IJPRAI},
  author       = {Safa Chebbi and Wafa Rekik and Sofia Ben Jebara},
  doi          = {10.1142/S0218001424560068},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2456006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {On the use of pitch-based features for detecting simultaneous fear emotion and deception behavior from speech},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive xception model for classification of brain
tumors. <em>IJPRAI</em>, <em>38</em>(8), 2456005. (<a
href="https://doi.org/10.1142/S0218001424560056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of different brain tumors is challenging due to unpredictable variations in intra-inter-classes. Unlike existing methods which are not effective for images of complex backgrounds, the proposed work aims at accurate classification of diverse types of brain tumors such that an appropriate model can be used for disease identification. This study considers glioma, meningioma, no tumor, and pituitary tumors for classification. To achieve an accurate classification, we explore the Xception architecture layer, which involves flattening, dropout, and dense layer operations. The model extracts features based on shapes, spatial relationships, and structure of the image, discriminating between the different brain tumor images. The model is evaluated on a dataset of 7023 MRI images for classification. The results of a large dataset and comparative study with the existing methods show that the proposed method is better than state of the art in terms of classification rate. Specifically, our method achieves more than a 90% average classification rate, which is better than state of the art. The results on noisy and blurred datasets show that the proposed model is robust to noise and blur.},
  archive      = {J_IJPRAI},
  author       = {Arastu Thakur and Mahesh T. R. and Surbhi Bhatia Khan and Shivakumara Palaiahnakote and V. Vinoth Kumar and Ahlam Almusharraf and Arwa Mashat},
  doi          = {10.1142/S0218001424560056},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2456005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An adaptive xception model for classification of brain tumors},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal gesture recognition with spatio-temporal features
fusion based on YOLOv5 and MediaPipe. <em>IJPRAI</em>, <em>38</em>(8),
2455007. (<a href="https://doi.org/10.1142/S0218001424550073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a natural, intuitive and easy-to-learn mode of interaction, gesture plays an important role in communication. Hand detection, containing multimodal information, includes static and dynamic detection and involves intricate spatial relationship problems such as different hand sizes, complex joints, occlusion and self-occlusion. This study focused on a multimodal hand gesture recognition system based on YOLOv5 and MediaPipe with fused spatio-temporal features. First, the Mediapipe and OpenCV libraries were employed to implement hand keypoint detection. Subsequently, the human–computer interaction (HCI) of volume control was realized by identifying the distance between thumb and index. Finally, model training was conducted based on the YOLOv5 algorithm, and the recognition of different gesture categories was realized. The performance was evaluated and compared through YOLOv5s, YOLOv5m, and YOLOv5l. The gesture recognition system interface visualization was achieved through pyqt5. Experiments show that the average detection accuracy of the model is 99.4% and the recognition speed is around 0.2 s.},
  archive      = {J_IJPRAI},
  author       = {Wenyi Cao and Peiqi Lu and Wenxin Cao},
  doi          = {10.1142/S0218001424550073},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2455007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multimodal gesture recognition with spatio-temporal features fusion based on YOLOv5 and MediaPipe},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cost-effective ground-moving object detection method in
aerial video by change detection of delaunay triangulation.
<em>IJPRAI</em>, <em>38</em>(8), 2455005. (<a
href="https://doi.org/10.1142/S021800142455005X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is dedicated to developing a cost-effective ground-moving object detection method in aerial videos. Without limitations on types, quantity, and distribution of moving objects, which were required by the previous methods, the proposed approach can detect various ground-moving objects in aerial videos captured through diverse flying states in various ground appearances. The proposed method is mainly composed of generation of the appropriate feature points, detection of moving objects, and target tracking. In the originality of our work, a novel detection strategy designed for ground-moving objects is based on change detection of Delaunay triangulation (CDDT) and a three-step motion vector search-based tracking algorithm is further exploited for enhancing the detection rate. Experimental results show that our method can achieve the detection rate of at least 95% (roughly similar to the famous existing state-of-the-art methods) and 0.03 second/frame (far less than the famous existing methods) using test videos (containing only several moving objects distributed in a sparse space) in the previous methods compared. Besides, the average detection rate of 86.81%, average false detection rate of 9.44%, and a frame rate of about 33 fps can be obtained using our test videos captured in the complicated ground appearances. This result makes the proposed method more attractive for detecting various ground-moving objects in aerial videos, when compared to other approaches, and can also achieve cost-effective performance.},
  archive      = {J_IJPRAI},
  author       = {Chao-Ho Chen and Deng-Yuan Huang and Yi-Jen Su and Chia-En Lin and Tsong-Yi Chen and Zai-Ci Jiao and Da-Jinn Wang and Cheng-Kang Wen},
  doi          = {10.1142/S021800142455005X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2455005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Cost-effective ground-moving object detection method in aerial video by change detection of delaunay triangulation},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hand gestures recognition model using adaptive feature
extraction with attention-based hybrid deep learning via optimization
strategy. <em>IJPRAI</em>, <em>38</em>(8), 2452002. (<a
href="https://doi.org/10.1142/S0218001424520025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on continuous hand gesture recognition is motivated by applications of deaf people to provide effective communication between one another. Numerous techniques are adapted for effectively identifying the hand gesture. Moreover, the collection of data becomes a challenging task in the existing models. In some instances, hand gesture in low-resolution images becomes a complicated task. In this research work, a deep learning-based hand gesture detection model is designed using hand data points to uncover patterns that are used to convey information. Initially, hand gesture images are obtained from public sources. The collected inputs are preprocessed through Contrast-Limited Adaptive Histogram Equalization and filtering to eliminate the unnecessary blurs in the images. The preprocessed images undergo hand segmentation using four methods color space transformation, skin color detection, active contour, and morphological operation. The segmented image is subjected to data point feature extraction, where the Adaptive Weighted Scale-Invariant Feature Transform is utilized for further enhancement. The hand data point-extracted features are given to the recognition of hand gestures with the support of an attention-based hybrid network, where the Attention-based Hybrid 1D Convolutional Neural Network with Recurrent Neural Network recognizes the hand gestures from the hand data points. In the hybridization network, the values are optimized with the help of the investigated Adaptive Dandelion White Shark Optimizer to enhance recognition effectiveness. The test results are validated with the existing hand gesture recognition models using diverse evaluation metrics. The findings of the recommended method show 97% and 99% in terms of accuracy and NPV. Thus, the developed model is validated to outperform significant performance rather than the existing models.},
  archive      = {J_IJPRAI},
  author       = {Gnanapriya Sampath and Rahimunnisa Kamal Basha and Mohana Muthu and L. Bhagyalakshmi},
  doi          = {10.1142/S0218001424520025},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2452002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hand gestures recognition model using adaptive feature extraction with attention-based hybrid deep learning via optimization strategy},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global path planning algorithm for unmanned vehicles based
on multi-objective particle swarm optimization strategy.
<em>IJPRAI</em>, <em>38</em>(8), 2451012. (<a
href="https://doi.org/10.1142/S0218001424510121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome the limitations of unmanned vehicle global path planning with the sole objective of distance, a multi-objective particle swarm optimization strategy is proposed for indoor unmanned vehicle path planning. This strategy integrates objectives related to travel distance and cumulative turning angle. The traditional distance function is enhanced to accelerate algorithm convergence, and cumulative turning angle is introduced to construct a comprehensive function, meeting the demands of multi-objective navigation. The Pareto solution set concept is incorporated, and through the multi-objective particle swarm optimization algorithm, optimal paths for different travel objectives are identified, enhancing solution comprehensiveness. Experimental results validate the feasibility and effectiveness of the improved algorithm.},
  archive      = {J_IJPRAI},
  author       = {Jun Xie and Qing Jiang and Yuxiao Wang and Yifan Zhang},
  doi          = {10.1142/S0218001424510121},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2451012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Global path planning algorithm for unmanned vehicles based on multi-objective particle swarm optimization strategy},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AEMNet: Unsupervised video anomaly detection method based on
attention-enhanced memory networks. <em>IJPRAI</em>, <em>38</em>(8),
2451011. (<a href="https://doi.org/10.1142/S021800142451011X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection has always been a challenging task in computer vision due to data imbalance and susceptibility to scene variations such as lighting and occlusions. In response to this challenge, this paper proposes an unsupervised video anomaly detection method based on an attention-enhanced memory network. The method utilizes a dual-stream network structure of autoencoders, enhancing the model’s learning ability for important features in appearance and motion by introducing coordinate attention mechanisms and variance attention mechanisms, emphasizing significant characteristics of static objects and rapidly moving regions. By adding memory modules to both the appearance and motion branches, the network structure’s memory information is reinforced, enabling it to capture long-term spatiotemporal dependencies in videos and thereby improving the accuracy of anomaly detection. Furthermore, by optimizing the network structure’s activation functions to handle negative inputs, it enhances its nonlinear modeling capabilities, enabling better adaptation to complex environments, including variations in lighting and occlusions, further improving the effectiveness of anomaly detection. The paper conducts comparative experiments and ablation studies using three public available datasets and various models. The results demonstrate that compared to baseline models, the AUC performance is improved by 3.9%, 4.7%, and 1.7% on UCSD Ped2, CHUK Avenue, and ShanghaiTech datasets, respectively. When compared with the other models, the average AUC performance is improved by 4.3%, 5.4%, and 6.2%, with an average improvement of 8.75% in the ERR metric, validating the effectiveness and adaptability of the proposed method. The code can be obtained at the following URL: https://github.com/AcademicWhite/AEMNet .},
  archive      = {J_IJPRAI},
  author       = {Linliang Zhang and Lianshan Yan and Shouxin Peng and Lihu Pan},
  doi          = {10.1142/S021800142451011X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2451011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AEMNet: Unsupervised video anomaly detection method based on attention-enhanced memory networks},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An intelligent moving object segmentation using hybrid
IFCM-CSS clustering model. <em>IJPRAI</em>, <em>38</em>(8), 2450012. (<a
href="https://doi.org/10.1142/S0218001424500125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a novel hybrid deep clustering approach is proposed for the effective moving object segmentation. Initially, the data is collected, and the keyframe selection is performed using the threshold-based Kennard–Stone method. Then, the preprocessing step involves noise filtering using bilateral wavelet thresholding and binary color conversion. The blob detection is performed using normalized Laplacian of Gaussian. Finally, the segmentation of moving objects is performed using a hybrid clustering approach called improved fuzzy C-mean (IFCM) clustering with chaotic salp swarm (CSS) optimization algorithm (Hybrid IFCM-CSS). The overall evaluation is done in MATLAB. The performance of the hybrid IFCM-CSS is compared to other approaches based on some measures. The proposed Hybrid IFCM-CSS achieves the highest precision of 0.971, using the SBM-RGBD dataset.},
  archive      = {J_IJPRAI},
  author       = {Vivaram Veera Raghavulu and Ande Prasad},
  doi          = {10.1142/S0218001424500125},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2450012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An intelligent moving object segmentation using hybrid IFCM-CSS clustering model},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Genetic clustering algorithm based on the division and
combination of layer series of development. <em>IJPRAI</em>,
<em>38</em>(8), 2436001. (<a
href="https://doi.org/10.1142/S0218001424360015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Petroleum is a critical industrial material. In the process of oilfield development, the Fisher’s optimal segmentation method is often used to solve the problem of division and combination of layer series of development. However, when encountering the problem of long samples, this method has particularly obvious drawbacks due to the high storage requirements of the calculation process. Therefore, in practical work, the Fisher’s optimal binary segmentation method is generally used instead. Although it avoids storage problems, it is prone to falling into local optima. On the basis of analyzing the shortcomings of Fisher’s optimal segmentation and optimal binary segmentation algorithms, this paper processes a genetic clustering algorithm. This algorithm overcomes the problem of Fisher’s optimal binary segmentation algorithm easily falling into local optima and solves the problem of high storage capacity requirements in the calculation process of Fisher’s optimal segmentation algorithm. Taking the data of 17 subzones in S-2 8-11 sand groups of the Shahejie Formation of the Lower Tertiary in the Dongxin area as an example, this algorithm is applied to divide and combine layer series of development. The experimental results show that the algorithm’s partitioning results are reasonable and can optimize the selection of development layers and provide decision support for the production of oil and gas resources.},
  archive      = {J_IJPRAI},
  author       = {Hongfen Jiang and Junfeng Gu and Haixu Xi and Qian Yu and Yijun Liu},
  doi          = {10.1142/S0218001424360015},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {8},
  pages        = {2436001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Genetic clustering algorithm based on the division and combination of layer series of development},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AIMHNet: An attribute-insensitive multiscale hourglass
network for rain streak and raindrop removal. <em>IJPRAI</em>,
<em>38</em>(7), 2459006. (<a
href="https://doi.org/10.1142/S0218001424590067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CNN-based methods have made great progress in single-image rain removal. Most recent methods improve performance by increasing the depth of the network. To fully extract local and global features while reducing inference time, we propose a top-to-down attribute-insensitive multiscale hourglass network for rain streak and raindrop removal. For the rain removal task, we expect that the constructed network can accurately identify the various attributes of the rain information characteristics of the small target. Considering the difference in the size, shape, direction and density of rain streak and raindrop, inspired by the performance of hourglass architecture to capture multiscale features in human pose estimation, we introduce an attribute-insensitive hourglass module to recognize the attributes of rain streak and raindrop in a unified framework. This feature extraction module could capture the characteristics of rain streak and raindrop with different attributes. This stacked hourglass blocks down-sample features and then up-samples them back to the original resolution based on discrete wavelet transform and inverse discrete wavelet transform. We perform extensive experiments on five synthetic and real-world de-raining datasets to validate the effectiveness of our proposed network on rain streak and raindrop removal. The qualitative and quantitative results show that our method is suitable for removing rain streak and raindrop in a unified framework. We present the results of generalization and ablation study for key components, we also report the accuracy of semantic segmentation after preprocessing with all rain removal methods. Our source code will be available on the GitHub: https://github.com/Ruini94/AIMHNet .},
  archive      = {J_IJPRAI},
  author       = {Ruini Zhao and Yi Han and Nan Kang and Jian Zhao and Yang Cui},
  doi          = {10.1142/S0218001424590067},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2459006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AIMHNet: An attribute-insensitive multiscale hourglass network for rain streak and raindrop removal},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpretable long-term forecasting based on dynamic
attention in smart city. <em>IJPRAI</em>, <em>38</em>(7), 2459005. (<a
href="https://doi.org/10.1142/S0218001424590055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction is of great significance to the construction of a smart city. However, current models only focus on mining the relationship among sequences and ignore the influence of the predicted sequences on future predictions, so we propose a Dynamic Attention Neural Network (DANN) based on encoder-decoder, which combines encoder context vectors and newly generated decoder context vectors to jointly dynamically representation learning, then generates corresponding predicted values. DANN processes data via the Bi-directional Long Short-Term Memory (Bi-LSTM) network as the fundamental structure of the network between encoder and decoder. What’s more, in order to produce a new feature representation with low redundancy, gate mechanism network module is used to adaptively learn the interdependence of multivariate feature data. The relevant experiments show that compared with baseline models, DANN has the most stable long-term prediction performance, which reduces the problem of error accumulation to a certain degree.},
  archive      = {J_IJPRAI},
  author       = {Changxia Ma and Jun Xie and Lisha Yang and Zhaoman Zhong and Xuefeng Zhao and Wenbin Hu},
  doi          = {10.1142/S0218001424590055},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2459005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Interpretable long-term forecasting based on dynamic attention in smart city},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Representation learning based on vision transformer.
<em>IJPRAI</em>, <em>38</em>(7), 2459004. (<a
href="https://doi.org/10.1142/S0218001424590043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the rapid development of information technology, the volume of image data has grown exponentially. However, these datasets typically contain a large amount of redundant information. To extract effective features and reduce redundancy from images, a representation learning method based on the Vision Transformer (ViT) has been proposed, and to our best knowledge, Transformer was first applied to zero-shot learning (ZSL). The method adopts a symmetric encoder–decoder structure, where the encoder incorporates Multi-Head Self-Attention (MSA) mechanism of ViT to reduce the dimensionality of image features, eliminate redundant information, and decrease computational burden. Consequently, it effectively extracts features, and the decoder is utilized for reconstructing image data. We evaluated the representation learning capability of the proposed method in various tasks, including data visualization, image reconstruction, face recognition, and ZSL. By comparing with state-of-the-art representation learning methods, the outstanding results obtained validate the effectiveness of this method in the field of representation learning.},
  archive      = {J_IJPRAI},
  author       = {Ruisheng Ran and Tianyu Gao and Qianwei Hu and Wenfeng Zhang and Shunshun Peng and Bin Fang},
  doi          = {10.1142/S0218001424590043},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2459004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Representation learning based on vision transformer},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incomplete footprint retrieval based on multi-scale feature
orthogonal fusion. <em>IJPRAI</em>, <em>38</em>(7), 2456004. (<a
href="https://doi.org/10.1142/S0218001424560044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, footprint image retrieval based on deep learning mainly focuses on complete footprint, but many of the footprints obtained in the field of public safety and criminal investigation are incomplete forms, Therefore, the feature analysis of incomplete footprint has important practical significance. Based on multiple scale features fusion, we proposed a method to solve incomplete footprints retrieval. On the basis of extracting the global feature of footprint, this method simultaneously extracts multiple local features from different stages of the backbone network to supplement the footprint feature information. The multi-scale feature orthogonal fusion module is used to reduce redundant features, improve the expression ability of footprint features, and solve the problem of incomplete footprint retrieval to a certain extent. The experiment shows that our method has certain effectiveness in retrieving problems on incomplete footprint, with a Top 1 accuracy of 87.08%, expanding the scope of footprint research.},
  archive      = {J_IJPRAI},
  author       = {Yan Zhang and Liqing Cao and Changkang Xu and Nian Wang},
  doi          = {10.1142/S0218001424560044},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2456004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Incomplete footprint retrieval based on multi-scale feature orthogonal fusion},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TSAD: Two-stage separable adversarial distortion-based
robust watermarking framework for diffusion tensor imaging.
<em>IJPRAI</em>, <em>38</em>(7), 2454011. (<a
href="https://doi.org/10.1142/S0218001424540119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent deep learning-based watermarking methods have achieved impressive results. However, they struggle with unknown distortions and often suffer from poor generalization, slow convergence, unstable training, and degraded visual quality in watermarked images. To address the above problems, this paper proposes a two-stage separable adversarial distortion (TSAD)-based robust watermarking algorithm for diffusion tensor imaging (DTI). The algorithm uses a noise-free end-to-end network in the first stage for learning and training DTI images. In the second stage, it fixes the watermark embedding network trained in the first stage, interacts the noise distortion network with the watermark extraction network to perform adversarial training for improving robustness. Experimental results show that our method achieves comparable or better robustness to seen distortions and better robustness to unseen distortions, along with enhanced stability, faster convergence, and improved visual quality in watermarked DTI images.},
  archive      = {J_IJPRAI},
  author       = {Long Zheng and Zhi Li and Zhangyu Liu and Dandan Li and Li Zhang and Hong Yue and Fei Cheng and Qin Mao and Xuekai Wei and Mingliang Zhou},
  doi          = {10.1142/S0218001424540119},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2454011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {TSAD: Two-stage separable adversarial distortion-based robust watermarking framework for diffusion tensor imaging},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integration of control strategies for cleaning based on
granular computing. <em>IJPRAI</em>, <em>38</em>(7), 2454010. (<a
href="https://doi.org/10.1142/S0218001424540107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cleaning control based on changes in cleaning loss rate and impurity rate has emerged as a hot topic in the research on intelligent control for rice and wheat combined harvesters. However, numerous operation parameters can lead to deviations beyond the normal range of cleaning loss rate and impurity rate. The impact of cleaning control parameters in rice and wheat combined harvesters on cleaning loss rate and impurity rate often tends to be contradictory. How to combine different contradictory cleaning control strategies to get a more widely used and better cleaning control strategy is a hot issue in the current cleaning control research. In this paper, the granularity of quotient space is introduced into the cleaning control based on operation parameters, and a cleaning control model based on granularity synthesis theory is proposed. This method first constructs a knowledge base for intelligent control of cleaning tailored to the cleaning loss rate and impurity rate using production rule representation, and considers that these control strategies constitute different quotient spaces, and then organizes these quotient spaces according to granularity synthesis theory to get the cleaning control strategy. The experimental results verify that the validity of the cleaning control based on granular computing is better than fuzzy control.},
  archive      = {J_IJPRAI},
  author       = {Jing Zhang and Xiancun Zhou and Chaochuan Jia and Qing Jiang and Cuicui Cai and Quan Zhou and Yu Liu},
  doi          = {10.1142/S0218001424540107},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2454010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Integration of control strategies for cleaning based on granular computing},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced emotion detection model using dusky canidae
optimization-based deep CNN classifier. <em>IJPRAI</em>, <em>38</em>(7),
2453001. (<a href="https://doi.org/10.1142/S021800142453001X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion detection involves distinguishing the complex nature of emotions, cross-cultural variations, and ethical considerations. The proposed model addresses cross-cultural issues through diverse training and ensures ethical data usage through advanced machine-learning techniques to enhance accuracy. The research aims to develop a Dusky Canidae Optimization-based Deep Convolutional Neural Network model (DCO opt deep CNN) for emotion recognition in audio-visual data, benefiting various advancements. During preprocessing, audio and video are separated to enhance sound quality and eliminate data redundancy while retaining vital information. Features are then extracted and employed for training and testing using the automation and effectiveness of Deep CNNs. The concatenated features are optimized using a hybrid approach that combines Dusky Hawk and Canidae Wolf Optimization (CWO), offering simplicity and interpretability with optimal parameter settings. The proposed DCO model effectively classifies emotions within the data. Evaluating the database, the DCO model exhibits a performance enhancement of 1.28%, 2.91%, and 1.28% in accuracy, sensitivity, and specificity with respect to the existing learner memorizing optimization-based deep NN model.},
  archive      = {J_IJPRAI},
  author       = {Sweta Nishant Padman and Dhiraj Magare},
  doi          = {10.1142/S021800142453001X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2453001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Enhanced emotion detection model using dusky canidae optimization-based deep CNN classifier},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Harmonic detection methods and optimization strategies for
charger in power grid. <em>IJPRAI</em>, <em>38</em>(7), 2452014. (<a
href="https://doi.org/10.1142/S0218001424520141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The charger’s operation in the power grid will cause harmonic pollution, affecting the service life of the equipment and the quality of the power grid. The harmonic characteristics and detection during the charging process are studied. The simulation model of charger is established first using MATLAB, the results of the experiment show that odd harmonics are mainly generated during charging, and the distortion rate of the current harmonics remains between 0.231 and 0.443 during the charging process. A new wavelet neural network is proposed to detect the harmonic method. Experimental results indicate that, compared with previous detection methods, this network has better detection efficiency and accuracy for harmonics. But detection result of this network is unstable and does not even converge. A new adaptive bat algorithm with improved focusing distance is presented here to optimize the wavelet neural network, which effectively solves the defect of being sensitive to the node number of hidden layer, resulting in higher detection accuracy, faster detection speed, and stable convergence. The detection error range is reduced from −0.03 to 0.02, and the number of iterations is reduced to around 1000.},
  archive      = {J_IJPRAI},
  author       = {Zhenliu Zhou and Zhixun Xu and Pizhen Zhang},
  doi          = {10.1142/S0218001424520141},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2452014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Harmonic detection methods and optimization strategies for charger in power grid},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The classification algorithm of nano targets based on
millimeter wave radar. <em>IJPRAI</em>, <em>38</em>(7), 2450010. (<a
href="https://doi.org/10.1142/S0218001424500101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nanodrones are insect-sized drones that could fly in complex environments and confined spaces, and act as an emerging tool for covert surveillance and intelligence attacks, which would become a potential threat to national security. Radar has the advantage of wide range, all-day, and all-weather detection ability, making it a means of detecting such threat. First, this paper introduces a pertinent multiple-input multiple-output (MIMO) millimeter-wave (MMW) radar system, with the advantages of low cost and high accuracy. It is utilized to detect three targets: nanodrone, small helicopter, and mechanical bird, through which more detailed features can be obtained. Then, the echo data of the three targets are processed and analyzed, and their distinct micro-Doppler characteristics were obtained. Finally, the Radar Transformer target classification network is used to classify and identify the targets. It has been confirmed that desired results could be achieved through the above process.},
  archive      = {J_IJPRAI},
  author       = {Jing Zhang and Xiancun Zhou and Chaochuan Jia and Cuicui Cai and Quan Zhou and Yu Liu and Qing Jiang and Yajun Li},
  doi          = {10.1142/S0218001424500101},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2450010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {The classification algorithm of nano targets based on millimeter wave radar},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameter identification method for collaborative robot
joint using a cuckoo search-BP neural network approach. <em>IJPRAI</em>,
<em>38</em>(7), 2450008. (<a
href="https://doi.org/10.1142/S0218001424500083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative robots face challenges in achieving high accuracy using existing parameter identification methods, especially in applications like dragging, teaching, and collision detection. To address the issue of robot dynamics identification accuracy in scenarios with unknown parameters, this paper introduces a method for robot joint parameter identification based on the Cuckoo Search-backpropagation neural network (CS-BPNN). Initially, a kinetic model incorporating Coulomb viscous friction is presented. Subsequently, a BPNN is employed to approximate and fit the nonlinear function, while the CS algorithm is integrated into the BPNN model to optimize its parameters. Collected data undergo third-order Butterworth filtering, and a loss function compares predicted values with actual values to ascertain the accuracy of the proposed method. Experimental results demonstrate that the CS-BPNN approach proposed herein can converge the mean square error (MSE) to 9 . 7 9 × 1 0 − 4 N⋅m when robot dynamics parameters are unknown. This method boasts of a lower MSE and superior discrimination accuracy compared to traditional methods like least squares (LS), genetic algorithm (GA), and BPNN. Consequently, the method presented in this study not only enhances the accuracy of parameter identification but also offers a fresh perspective for the parameter identification of robot joint dynamics models.},
  archive      = {J_IJPRAI},
  author       = {Liangping Xiong and Huifeng Hu and Kang An},
  doi          = {10.1142/S0218001424500083},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {7},
  pages        = {2450008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Parameter identification method for collaborative robot joint using a cuckoo search-BP neural network approach},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new approach for classification of spices to make special
herbal tea using caralluma fimbriata. <em>IJPRAI</em>, <em>38</em>(6),
2457003. (<a href="https://doi.org/10.1142/S0218001424570039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of multiple types of spice images is automatically challenging due to conflict between the texture patterns of spice images. This work aims to develop an automatic system for classifying different types of spice images so that the system can choose an appropriate spice to make herbal tea using Caralluma fimbriata. This work considers the following seven spices, namely, cinnamon, citrus peel, clove, ginger, jeera, kokum, mint, and Caralluma fimbriata as one more class for classification. Most of the existing systems need human intervention to choose different spices to make Caralluma fimbriata tea. It is observed that the pattern of different spice images represents different textures. This observation motivated us to extract features based on multi-Sobel kernels. To reduce the number of computations, the proposed work introduces a novel idea of corner detection based on Gaussian distribution. For each corner, the method performed is multi-Sobel kernels for extracting features. The features are fed to convolutional neural network layers for the classification of multiple spice images. The results of our dataset and comparative study with the state-of-the-art methods show that the proposed model is superior to existing methods in terms of classification rate.},
  archive      = {J_IJPRAI},
  author       = {P. Prajwal Kumar and Shivakumara Palaiahnakote and M. Basavanna and H. S. Ravikumar Patil and V. M. Vyshali},
  doi          = {10.1142/S0218001424570039},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2457003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A new approach for classification of spices to make special herbal tea using caralluma fimbriata},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of the motion postures in equestrian sports based
on multi-sensor data fusion. <em>IJPRAI</em>, <em>38</em>(6), 2457001.
(<a href="https://doi.org/10.1142/S0218001424570015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Horse riding, in its essence, is both an art and a captivating sport. In these events, riders showcase their refined skills and deep bond with their horses, most notably through changes in physical positioning. This research aims to accurately capture and analyze the spatial postures of riders in equestrian sports, exploring the dynamic differences between professional and amateur riders. To achieve this, we employed a multi-sensor data fusion approach based on human kinetics theories, enhanced by an extended Kalman filter. This method, combined with an optical tracking system, enabled us to intricately compare and analyze the 3D postures of riders during walking and trotting phases. Our research captured these nuanced postural shifts using an inertial sensor network, yielding nine-axis motion data of riders during their performance. The accuracy of our fusion technique was validated using the optical tracking system. By analyzing the motion data, we discerned posture variations among the riders of differing expertise levels, even when executing the same riding technique. The insights from this research offer a quantifiable metric for refining equestrian training and contribute to understanding the complex dynamics of rider–horse interaction.},
  archive      = {J_IJPRAI},
  author       = {Yi Yang and Yaoyao Yu and Xinyue Chen and Jie Li},
  doi          = {10.1142/S0218001424570015},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2457001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Analysis of the motion postures in equestrian sports based on multi-sensor data fusion},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective topology optimization of acquisition
pointing and tracking system. <em>IJPRAI</em>, <em>38</em>(6), 2456003.
(<a href="https://doi.org/10.1142/S0218001424560032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing need for the lightweight acquisition, tracking, and pointing (APT) system during satellite launches due to the escalating demand in space missions. The APT system may work under multiple loading cases during different launch steps. Hence, this study introduces an innovative amalgamation of genetic operation and bi-directional evolutionary structural optimization (BESO) to fulfill the multi-objective requirements through the attainment of Pareto optimal fronts. A typical instance in two dimensions illustrates the effectiveness of the innovative multi-objective approach by contrasting the outcomes acquired from a solitary fulfillment requirement under two distinct burdens. Furthermore, the novel multi-objective method is utilized to remove inefficient material from the APT system by 20.12%. To ensure the safety of the lightweight design, the simulation and experiment of random vibration are both investigated according to the fundamental natural frequency of the launcher.},
  archive      = {J_IJPRAI},
  author       = {Bo Gao and Hongtao Yang and Weining Chen and Hao Wang and Jiaqi Fei and Zimiao Qi},
  doi          = {10.1142/S0218001424560032},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2456003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-objective topology optimization of acquisition pointing and tracking system},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pattern-based recommender system using nuclear norm
minimization of three-mode tensor and quantum fidelity-based k-means.
<em>IJPRAI</em>, <em>38</em>(6), 2455004. (<a
href="https://doi.org/10.1142/S0218001424550048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems (RSs) consist of predicting missing ratings based on the observed ones. This problem corresponds to matrix completion where users are its rows and items are its columns and it contains the observed ratings. An efficient RS is the one promoting the personal relevancy of its users which is not the case in the matrix completion process. It takes into account all the rates for prediction without including the users’ and items’ characteristics. Patterns are the key enablers of such solutions. In this work, we present a three-mode tensor representation with two aspects namely user–item interactions (observed ratings) and item–item relationship (detected similarities). To capture the similarities, the patterns are grouped in an equivalent manner using a bi-quantum clustering process (Quantum K -means). This step is adopted to consider only the relevant observed ratings in the prediction process and express item-to-item relationship using fidelity distance. Then, for each missing rating r that a user u might give to an item i in the future, a sub-tensor is created according to the detected patterns. This sub-tensor then is completed by minimizing its rank. This problem is NP-hard, hence a surrogate is used which is the nuclear norm. The effectiveness of the proposed approach is measured according to information retrieval evaluation criteria: precision, recall and F 1 -measure. The proposed approach improved the precision of the state-of-the-art methods by 20 % .},
  archive      = {J_IJPRAI},
  author       = {Oumayma Banouar and Said Raghay},
  doi          = {10.1142/S0218001424550048},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2455004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Pattern-based recommender system using nuclear norm minimization of three-mode tensor and quantum fidelity-based K-means},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fine-grained image classification method built on
MobileViT. <em>IJPRAI</em>, <em>38</em>(6), 2454008. (<a
href="https://doi.org/10.1142/S0218001424540089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a rapid development of artificial intelligence technology, fine-grained image classification has gained widespread application. For mobile terminals, this paper introduces an image classification method built on MobileViT, and it can apply into fine-grained image classification. The original MobileViT model has been optimized in three ways. Initially, the h-swish activation function is used to enhance the network performance. Second, the cross-entropy loss function is used to further realize the parameter optimization and model accuracy improvement. Finally, a dropout layer is joined before the fully connected layer can effectively decrease the model recognition time and prevent over-fitting. Experimental data on public tomato disease datasets demonstrate that the improved fine-grained image classification method put forward in this paper exhibits higher classification accuracy, better stability and network generalization ability than other models.},
  archive      = {J_IJPRAI},
  author       = {Zhengqiu Lu and Haiying Wang},
  doi          = {10.1142/S0218001424540089},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2454008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A fine-grained image classification method built on MobileViT},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel dual u-net generative adversarial network for image
inpainting. <em>IJPRAI</em>, <em>38</em>(6), 2454006. (<a
href="https://doi.org/10.1142/S0218001424540065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to the rapid development of deep learning in recent years, image inpainting has made significant progress. As a fundamental task in the field of computer vision, many researchers are committed to exploring more efficient methods, and state-of-the-art research results prove that generative adversarial networks (GAN) have superior performance. However, due to the inherent ill-posedness of image inpainting tasks, these approaches suffer from lack of detailed information, local structural fractures or boundary artifacts. In this paper, we leverage the properties of GAN architecture to process images in more detail and more comprehensively. A novel dual U-Net GAN is designed to inpaint images, which is composed of a U-Net based generator and a U-Net-based discriminator. The former captures semantic information of different scales layer by layer and decodes it back to the original size to repair damaged images, while the latter optimizes the network by combining reconstruction loss, adversarial loss, perceptual loss and style loss. In particular, the U-Net-based discriminator allows per-pixel detail and global feedback to be provided to the generator, guaranteeing the global consistency of the inpainted image and the realism of local shapes and textures. Extensive experiments demonstrate that for different proportions of damage, the images inpainted by our proposed model have reasonable texture structure and contextual semantic information. Furthermore, the proposed model outperforms state-of-the-art models in both qualitative and quantitative comparisons. The code will be available at https://github.com/yjjswu .},
  archive      = {J_IJPRAI},
  author       = {Jianjun Yuan and Hong Wu and Fujun Wu},
  doi          = {10.1142/S0218001424540065},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2454006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel dual U-net generative adversarial network for image inpainting},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent controlling model for cleaning of rice–wheat
combine harvester based on multi-objective optimization particle swarm
method. <em>IJPRAI</em>, <em>38</em>(6), 2451010. (<a
href="https://doi.org/10.1142/S0218001424510108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent control has become an important research direction of a combine harvester. However, the impact of cleaning control parameters in rice–wheat combine harvesters on cleaning loss rate and impurity rate often tends to be contradictory. In this paper, an intelligent controlling model based on multi-objective optimization particle swarm (MOPSO) was constructed to solve this problem. The control model can real-time monitor the cleaning performance such as the cleaning loss rate and impurity rate and regulate the cleaning operation conditions such as the angle of the air distributor plate, the opening of the upper sieve and the fan speed. The field operation experiment of 10 kg feeding rice–wheat combine harvester proves that the control model based on MOPSO is more effective than the model based on fuzzy control.},
  archive      = {J_IJPRAI},
  author       = {Jing Zhang and Zelin Hu and Xiancun Zhou and Xueying Xu and Yifan Zhang},
  doi          = {10.1142/S0218001424510108},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2451010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Intelligent controlling model for cleaning of Rice–Wheat combine harvester based on multi-objective optimization particle swarm method},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SterAF: A scene text recognizer with appearance-flow
rectification. <em>IJPRAI</em>, <em>38</em>(6), 2450011. (<a
href="https://doi.org/10.1142/S0218001424500113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the demand for recognizing irregular text in natural scenes increases, people are increasingly realizing the value of such applications, such as license plate recognition systems, image search, handwriting recognition, and autonomous driving, which are profoundly changing our lives in the field of text recognition. Recent studies have shown that the recognition of curved text and perspective text has become an important challenge in the field of text recognition, and the correction of curved text is a key step to achieve accurate recognition. However, current methods use strained text image correction methods, resulting in poor recognition accuracy when recognizing curved text. Therefore, we propose an end-to-end framework called Scene Text Recognizer with Appearance-Flow rectification (SterAF), which includes a correction network and a recognition network. Specifically, the framework’s steps are as follows: first, the input text image is deformed through an appearance flow-based correction network to adaptively warp the text image, to prevent irregular and unnatural deformations of the text image. Second, a sequence-to-sequence recognition network predicts the sequence of characters in the corrected text image to accurately recognize the text in the image. Through subjective and objective experiments, our SterAF model has shown excellent performance in both qualitative and quantitative experiments.},
  archive      = {J_IJPRAI},
  author       = {Chunyan Liao and Chenghu Du and Yating Liu and Yanbao Tan},
  doi          = {10.1142/S0218001424500113},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2450011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {SterAF: A scene text recognizer with appearance-flow rectification},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligent human–computer dialogue support
platform for hospitals. <em>IJPRAI</em>, <em>38</em>(6), 2359019. (<a
href="https://doi.org/10.1142/S021800142359019X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To design a dialogue model and standard artificial programming interface (API), this paper designs an intelligent dialogue support for medical service systems and improving hospital intelligent serviceability, which combines patient pre-diagnosis, diagnosis, and post-diagnosis services with artificial intelligence depth. This is done via an intelligent man–machine dialogue support platform (MMDSP) suitable for medical services based on a multi-dimensional disease model and outpatient knowledge base with artificial intelligence. As a result of the intelligent service capability of the hospital service systems and platforms, patients’ medical experiences have significantly improved. The platform standardizes the multi-channel service process, improves patient service efficiency, and reduces the cost of human resources and business knowledge learning. In addition, the integration of intelligent multi-system service information provides data support for hospitals to serve patients accurately and has good application and promotion value.},
  archive      = {J_IJPRAI},
  author       = {Xin Xia and Yunlong Ma and Ye Luo and Jianwei Lu},
  doi          = {10.1142/S021800142359019X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2359019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Artificial intelligent Human–Computer dialogue support platform for hospitals},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of deep learning in social network public
opinion sentiment. <em>IJPRAI</em>, <em>38</em>(6), 2352014. (<a
href="https://doi.org/10.1142/S0218001423520146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of social network platform, in order to purify the network environment, prevent the abuse of public opinion information, and control public opinion in a very short time, this paper proposes the application research of deep learning in social network public opinion sentiment recognition and analysis. Through the construction of social network model and social network knowledge map and the analysis of key technology, a network public opinion algorithm based on deep learning is proposed, and a competitive public opinion information communication model in online social networks is constructed, and then a simulation experiment is conducted on the improved model of the constructed social networks. The result shows that in public opinion management and control, for users with larger node degree, this technology can effectively understand and obtain public opinion information in a very short time with faster and wider information propagation speed, so as to realize the effective control of public opinion information and the processing of massive information.},
  archive      = {J_IJPRAI},
  author       = {Lei Wu},
  doi          = {10.1142/S0218001423520146},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {6},
  pages        = {2352014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Application of deep learning in social network public opinion sentiment},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of cleaning loss of rice wheat combine harvester
based on dynamic bayesian. <em>IJPRAI</em>, <em>38</em>(5), 2459002. (<a
href="https://doi.org/10.1142/S021800142459002X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cleaning loss rate is a crucial performance metric for rice-wheat combine harvesters. Most studies on the relationship between the cleaning operation parameters of the combined harvester and the cleaning loss rate lack research on the dynamic correlation between harvest losses and operational parameters, specifically focusing on the dynamic correlation between harvest losses and multiple operational parameters such as the cleaning loss rate. In this paper, we formulate a dynamic deductive model for the scenario of harvesting loss regulation involving multiple operational parameters, delving into the dynamic associations between cleaning loss and the regulation of multiple operational parameters and constructing dynamic Bayesian network prediction model. Through experimental analysis of the dynamic Bayesian network prediction model for cleaning loss rates, the comparison of results among the other three algorithms demonstrated that it was efficient for our DBN to predict the cleaning loss rate.},
  archive      = {J_IJPRAI},
  author       = {Jing Zhang and Ting Zhu and Yang Liu and Yifan Zhang and Xiancun Zhou and Xueying Xu and Qing Jiang},
  doi          = {10.1142/S021800142459002X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2459002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Prediction of cleaning loss of rice wheat combine harvester based on dynamic bayesian},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Query expansion using proposed location-based algorithm for
hindi–english CLIR: Analyzing three test collections. <em>IJPRAI</em>,
<em>38</em>(5), 2459001. (<a
href="https://doi.org/10.1142/S0218001424590018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of contents on the Web in different languages increases the demand of Cross-Lingual Information Retrieval (CLIR). The accuracy of result suffers due to many problems such as ambiguity and drift issue in query. Query Expansion (QE) offers reliable solution for obtaining suitable documents for user queries. In this paper, we proposed an architecture for Hindi–English CLIR system using QE for improving the relevancy of retrieved results. In this architecture, for the addition of term(s) at appropriate position(s), we proposed a location-based algorithm to resolve the drift query issue in QE. User queries in Hindi language have been translated into document language (i.e. English) and the accuracy of translation is improved using Back-Translation. Google search has been performed and the retrieved documents are ranked using Okapi BM25 to arrange the documents in the order of decreasing relevancy to select the most suitable terms for QE. We used term selection value (TSV) for QE and for retrieving the terms, we created three test collections namely the (i) description and narration of the Forum for Information Retrieval Evaluation (FIRE) dataset, (ii) Snippets of retrieved documents against each query and (iii) Nearest-Neighborhood (NN) words against each query word among the ranked documents. To evaluate the system, 50 queries of Hindi language are selected from the FIRE-2012 dataset. In this paper, we performed two experiments: (i) impact of the proposed location-based algorithm on the proposed architecture of CLIR; and (ii) analysis of QE using three datasets, i.e. FIRE, NN and Snippets. In the first case, result shows that the relevancy of Hindi–English CLIR is improved by performing QE using the location-based algorithm and a 12% of improvement is achieved as compared to the results of QE obtained without applying the location-based algorithm. In the second case, the location-based algorithm is applied on three datasets. The Mean Average Precision (MAP) values of retrieved documents after QE are 0.5379 (NN), 0.6018 (FIRE) and 0.6406 (Snippets) for the three test collections, whereas the MAP before QE is 0.37102. This clearly shows the significant improvement of retrieved results for all three test collections. Among the three test collections, QE has been found most effective along with Snippets as indicated by the results with the improvements of 6.48% and 19.12% over FIRE and NN test collections, respectively.},
  archive      = {J_IJPRAI},
  author       = {Ganesh Chandra and Sanjay K. Dwivedi},
  doi          = {10.1142/S0218001424590018},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2459001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Query expansion using proposed location-based algorithm for Hindi–English CLIR: Analyzing three test collections},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial data prediction model integrated with k-nearest
neighbor mechanism in neural networks. <em>IJPRAI</em>, <em>38</em>(5),
2458003. (<a href="https://doi.org/10.1142/S0218001424580035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods of spatial interpolation, such as inverse distance weighting (IDW) and ordinary Kriging (OK), utilize geographic distance and specific assumptions to simplify the computation of geospatial data complexity. Nevertheless, these conventional approaches are not as practical in obtaining high-precision estimation because of the intricate nonlinear relationship between geographic distance and correlation weights. In this study, a novel spatial interpolation technique, named WFNNKM, is introduced, which integrates the K -nearest neighbor ( K NN) mechanism with a neural network to address this challenge. Firstly, the Lebesgue integral is used for clustering, and K NN tuples are obtained by clustering. Secondly, the K NN training task is constructed for interpolation points, and the bias parameters of each point are obtained through training. Finally, the pre-training parameters of a neural network are modified through bias parameters of nearest neighbors to obtain accurate prediction attribute values. In comparison with two conventional methods and three neural network approaches across three soil sample datasets, the results demonstrate a notably superior performance of the suggested approach compared to the five interpolation methods.},
  archive      = {J_IJPRAI},
  author       = {Xin Song and Liang Zhu and Yu Zhang and HaiBo Liu},
  doi          = {10.1142/S0218001424580035},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2458003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Spatial data prediction model integrated with K-nearest neighbor mechanism in neural networks},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PM2.5 concentration prediction model based on random forest
and SHAP. <em>IJPRAI</em>, <em>38</em>(5), 2452012. (<a
href="https://doi.org/10.1142/S0218001424520128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precisely forecasting the levels of PM 2 . 5 is crucial for environmental conservation and human health. Thus, it serves as an essential indicator of atmospheric purity. In this paper, a PM 2 . 5 concentration prediction model based on random forest and SHAP is proposed using air pollutants and meteorological conditions as the characterizing factors. Initially, pertinent information is gathered and subsequently manipulated, educated, and forecasted through the application of the random forest technique. Then, SHAP is used to explain the degree of influence of each feature in the model and the prediction results. Results of the experiment demonstrate that the random forest-based PM 2 . 5 concentration prediction model for the three cities surpass the comparison model in the RMSE, MAE, and R 2 indicators. Examining SHAP values, the essential elements influencing the PM 2 . 5 concentration are pinpointed.},
  archive      = {J_IJPRAI},
  author       = {Mengyao Pan and Bisheng Xia and Wenbo Huang and Ying Ren and Siyuan Wang},
  doi          = {10.1142/S0218001424520128},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2452012},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {PM2.5 concentration prediction model based on random forest and SHAP},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tool wear prediction based on LSTM and deep residual
network. <em>IJPRAI</em>, <em>38</em>(5), 2452011. (<a
href="https://doi.org/10.1142/S0218001424520116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the accuracy and efficiency of tool wear predictions, this study proposes a tool wear prediction model called LSTM_ResNet which is based on the long short-term memory (LSTM) network and the Residual Network (ResNet). The model utilizes LSTM layers for processing, where the first block and loop blocks serve as the core modules of the deep residual network. The model employs a series of methods including convolution, batch normalization (BN), and Rectified Linear Unit (ReLU) to enhance the model’s expression and prediction capabilities. The performance of the LSTM_ResNet model was evaluated using experimental data from the PHM2010 datasets and two different depths (64 and 128 layers), training both LSTM_ResNet models for 200 epochs. The 64-layer model’s root mean square error (RMSE) values are 3.36, 4.35, and 3.59, and the mean absolute error (MAE) values are 2.42, 2.85, and 2.21; using 128 layers, the RMSE values are 3.66, 3.99, and 3.77, and the MAE values are 2.49, 2.73, and 3.01. The results indicate that the 64-layer LSTM has smaller average errors, suggesting that compared to other common network structures, the LSTM_ResNet network has a higher performance. This research provides an effective solution for tool wear prediction and helps to improve the technical level of tool wear prediction in China.},
  archive      = {J_IJPRAI},
  author       = {Chun Fang and Yikang Gong and Xibo Ming and Liming Qin},
  doi          = {10.1142/S0218001424520116},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2452011},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Tool wear prediction based on LSTM and deep residual network},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient hand bone segmentation for medical applications
using refined DeepLab model. <em>IJPRAI</em>, <em>38</em>(5), 2452010.
(<a href="https://doi.org/10.1142/S0218001424520104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the medical field, analyzing various bone structures is crucial due to the rigid nature of bones. X-ray imaging plays an essential role in medical procedures, including bone age evaluation, fracture detection, and implant creation. However, operator involvement can introduce biases and increase processing time. Automating the process could reduce processing time and enhance diagnostic accuracy by minimizing biases and operator involvement. This paper introduces the Refined DeepLab model, a lightweight encoder–decoder-based approach for multiclass segmentation of hand bones. The primary objective is to assist physicians in tasks such as bone age analysis, fracture detection, hand movement analysis, and implant design. The research objectives are organized into three phases, with this work focusing on the first phase of our objectives, which is delineating bones from tissues, studying the bone structure, and multiclass segmentation of hand bones. The model utilizes DenseNet121 as its feature extractor and Sigmoid-weighted Linear Unit (SiLU) as its activation function. Experimental findings demonstrate promising performance in hand bone multiclass segmentation, with a Mean Intersection over Union (mIoU) of 85.02% and a Dice score of 92.2%. The comprehensive analysis of the results confirms that the proposed model excels, particularly in achieving the right balance between computational efficiency and precise segmentation.},
  archive      = {J_IJPRAI},
  author       = {Y. Nagaraju and R. Venkatesh and P. R. Thanu Shree Yadav and A. Vaishnavi and S. V. Tejashree},
  doi          = {10.1142/S0218001424520104},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2452010},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Efficient hand bone segmentation for medical applications using refined DeepLab model},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A study on robotic arm target recognition and grasping
method based on deep learning. <em>IJPRAI</em>, <em>38</em>(5), 2452005.
(<a href="https://doi.org/10.1142/S0218001424520050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, a 3D visual recognition system has been developed based on Wei deep learning algorithm using GPU. The proposed system consisted of a GPU with depth image function library, which performed image data acquisition, depth information operation, coordinate conversion, image contour search, convolutional class neural network model training, etc., and achieved object pinning by TCP/IP communication with motion control system. The obtained experimental results revealed that the recognition rate of the developed algorithm for target objects at different positions was as high as 92%. Experimental target recognition rates for different angles were relatively low, but reached 87%, and experimental accuracy rates of different luminance values also reached 89%. The errors of robot hand clamping targets also fell within 1–4 mm, which were higher than experimental expectation.},
  archive      = {J_IJPRAI},
  author       = {Yufeng Shu and Changwei Xiong and Chaodong Chen},
  doi          = {10.1142/S0218001424520050},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2452005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A study on robotic arm target recognition and grasping method based on deep learning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal sentiment analysis for movie scenes based on a
few-shot learning approach. <em>IJPRAI</em>, <em>38</em>(5), 2451009.
(<a href="https://doi.org/10.1142/S0218001424510091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis involves discerning the emotions of speakers through diverse features such as sound, text, and images. However, current research in this field heavily relies on extensive supervised datasets, demanding substantial labor and computational resources. This study introduces a meta-learning-based approach for multimodal sentiment analysis, aiming to delve into emotional information within movie scenes. Leveraging meta-learning techniques, this approach seeks to accurately capture emotions in movie scenes using a limited number of annotated samples, achieving model generalization under constrained labeled data. Specifically, we introduce an optimization-based meta-learning approach for the multimodal sentiment analysis tasks in text and vision, enhancing the model’s ability to generalize to new tasks with limited annotations. Additionally, an innovative strategy based on Meta-Prompting is proposed to handle multimodal data. The merits of the proposed method are validated across different datasets.},
  archive      = {J_IJPRAI},
  author       = {Hao Yang and Bo Li},
  doi          = {10.1142/S0218001424510091},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2451009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multimodal sentiment analysis for movie scenes based on a few-shot learning approach},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design of novel brain tumor segmentation system using hybrid
heuristic-aided multiscale self-guided attention mechanism-based
adaptive unet+++ with 3D brain MRI images. <em>IJPRAI</em>,
<em>38</em>(5), 2451001. (<a
href="https://doi.org/10.1142/S0218001424510017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of brain tumors attains great importance in the medical industry. As the brain tumor causes an earlier death, detection and diagnosis are required. Generally, brain tumor diagnosis is done by considering Magnetic Resonance Imaging (MRI) because it has superficial feature information. In the existing works, the different segmentation process is analyzed, yet it is more time-consuming, and has complexities. Thus, building of an efficient segmentation model is a quite challenging task. As the former implemented models are not in place to segment the abnormal region properly, it suggests developing an effective automated model using recently emerged techniques of deep learning. To surmount such challenging factors, a novel 3D brain tumor segmentation model is proposed with hybrid heuristic development. Initially, the brain images are collected from the standard benchmark datasets. The collected brain images are pre-processed using the adaptive technique of Contrast Limited Adaptive Histogram Equalization (CLAHE). The pre-processed images are segmented with the developed Multiscale Self-Guided Attention Mechanism-based Adaptive UNet3 + (MSGAM-AUNet3 + ), where the parameters are optimized with the hybrid optimization strategy of Modified Path Finder Coyote Optimization (MPFCO) to elevate the segmentation performance. The experimental analysis is carried out to estimate the efficiency of the developed framework with the comparison using diverse segmentation techniques.},
  archive      = {J_IJPRAI},
  author       = {D. Ramya and C. Lakshmi},
  doi          = {10.1142/S0218001424510017},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2451001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Design of novel brain tumor segmentation system using hybrid heuristic-aided multiscale self-guided attention mechanism-based adaptive unet+++ with 3D brain MRI images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Residual spatial reduced transformer based on YOLOv5 for UAV
images object detection. <em>IJPRAI</em>, <em>38</em>(5), 2450007. (<a
href="https://doi.org/10.1142/S0218001424500071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection on unmanned aerial vehicle (UAV) images is an important branch of object detection, belonging to small object detection in a broad sense. Detecting objects in UAV images poses a greater challenge due to the predominance of small objects and dense occlusion caused by UAV capturing images from varying heights and angles. To solve the above problems, we propose Residual Spatial Reduced Transformer based on YOLOv5 (RSRT-YOLOv5). Specifically, Slice Aided Enhancement Module (SAEM) is introduced to enhance the feature quality of small objects. Secondly, a Global attention-based Bi-directional Feature Fusion (GBFF) module is proposed. In the Neck architecture, an efficient Residual Spatial Reduced Transformer (RSRT) module is integrated in order to achieve more efficient feature representation and richer global contextual associations. Finally, our method is evaluated on the Visdrone2019 dataset, and the experimental results show that RSRT-YOLOv5 outperforms the baseline model (yolov5) and successfully improves the detection performance of UAV images.},
  archive      = {J_IJPRAI},
  author       = {Li Chen and Naimeng Cang and Wenbo Zhang and Chan Zhang and Weidong Zhang and Dongsheng Guo},
  doi          = {10.1142/S0218001424500071},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2450007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Residual spatial reduced transformer based on YOLOv5 for UAV images object detection},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HDR-YOLO: Adaptive object detection in haze, dark, and rain
scenes based on YOLO. <em>IJPRAI</em>, <em>38</em>(5), 2450006. (<a
href="https://doi.org/10.1142/S021800142450006X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of real-world environments, images acquired through surveillance cameras in such settings are frequently marred by issues including diminished contrast, suboptimal image quality, and color aberrations, rendering conventional object detection models ill-suited for the task. Taking inspiration from the foundational principles of image restoration, this study aims to extract environment-agnostic features across various weather conditions in order to enhance object detection performance in multiple scenarios while maintaining accuracy under typical meteorological conditions. In response to this question, we introduce a detection framework as HDR-YOLO that jointly trains feature extraction and object detection. Meantime, to solve the problem of visual impairments caused by adverse conditions, we propose a Dynamic Extraction of Environment-Agnostic Features (DEAF) module. Additionally, we joint mean squared error (MSE) loss and Log-Cosh loss as optimization techniques, carefully tailored to further elevate detection performance, especially under adverse meteorological conditions. Extensive empirical findings from the AGVS dataset validate the ability of HDR-YOLO to improve object detection performance in airport ground videos within real-world settings while maintaining precision under typical meteorological conditions, which underscores its innovative capabilities and adaptability in complex and diverse environments.},
  archive      = {J_IJPRAI},
  author       = {Zonglei Lyu and Wei An},
  doi          = {10.1142/S021800142450006X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {5},
  pages        = {2450006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {HDR-YOLO: Adaptive object detection in haze, dark, and rain scenes based on YOLO},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Test method of a rotating-arm axis box considering
suspension parameters. <em>IJPRAI</em>, <em>38</em>(4), 2459003. (<a
href="https://doi.org/10.1142/S0218001424590031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rotating-arm axis box as the research object, we established a test method in the original place of damage of the axis box that can reproduce the suspension parameter conditions of the bogie frame. First, this method establishes a real axis box mechanical model based on the suspension parameters of the axis box assembly conditions and calculates the load distribution relationship of the axis box through this model. Second, through a comparison of test data under different tooling conditions, it was verified that the distribution relationship had a great influence on the strength evaluation of the axis box body. Then, the single-axis box test method was simulated and optimized to determine the distribution of test loads and constraint conditions. The calculation results better restored the axis box test data under in situ conditions and derived a single-axis box test method with high accuracy. The lowest damage coverage was 1.01. The mechanical modeling and test optimization approach not only improves damage-based life assessment but also tunes up the efficiency of axis box testing.},
  archive      = {J_IJPRAI},
  author       = {Hua Zou and Zhen Song and Zhenkun Yin},
  doi          = {10.1142/S0218001424590031},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2459003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Test method of a rotating-arm axis box considering suspension parameters},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast adaptive millimeter-wave radar clustering algorithm.
<em>IJPRAI</em>, <em>38</em>(4), 2458002. (<a
href="https://doi.org/10.1142/S0218001424580023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the intelligent recognition problem of radar detection targets. Aiming at the low accuracy and slow speed of millimeter-wave radar clustering point cloud information, a feature algorithm of millimeter-wave radar suitable for detecting targets is proposed. In the detection of targets by millimeter-wave radar, distance is the biggest factor affecting the number and degree of sparsity. A method that combines the feature information of the point cloud with the KD tree proximity search algorithm and the DBSCAN clustering algorithm is proposed, which can adapt to the problems of uneven target point cloud, small amount of data and slow clustering speed. The improved algorithm can use the KD tree to quickly find adjacent points and calculate the distance between adjacent points. The corresponding number of thresholds is set according to the distance where the target is located, and the radius of the target area reflected by the millimeter-wave radar plus the distance of the last threshold point is used as the neighborhood radius of the improved algorithm. Therefore, fast and adaptive parameter adjustment of the millimeter-wave radar can be realized. Simulation tests show that the improved clustering algorithm has better parameters. The accuracy of the improved algorithm is increased by 4.2%, and it also greatly improves the clustering speed.},
  archive      = {J_IJPRAI},
  author       = {Yingjun Sang and Teng Teng and Qingyuan Yu and Haojie Hong and Feng Jin and Yuanyuan Fan},
  doi          = {10.1142/S0218001424580023},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2458002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A fast adaptive millimeter-wave radar clustering algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A synthesis method of open-chain coupled serial linkage
mechanism fusing trajectory and posture. <em>IJPRAI</em>,
<em>38</em>(4), 2458001. (<a
href="https://doi.org/10.1142/S0218001424580011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to meet the motion characteristics requirements of multi-objective fusion of execution components, a synthesis method of open-chain coupled serial linkage mechanism fusing trajectory and posture is proposed. According to periodic change characteristics of the execution component trajectory and posture of the linkage mechanism, the motion characteristics equation including trajectory and posture information is established by using Fourier series. The harmonic parameters of the link trajectory and posture are calculated according to the principle of discrete Fourier transform. The complex vector theory is applied to determine the functional relationship between the harmonic parameters of the trajectory and posture and the independent variable of the linkage mechanism, and furthermore the motion synthesis equation of the open-chain linkage mechanism fusing trajectory and posture information is established. The linkage mechanism parameters are calculated using Mathcad Prime software. The single-degree-of-freedom open-chain coupled serial linkage mechanism fusing trajectory and posture information is obtained by using a noncircular gear planetary gear train to couple the connection points of the linkage mechanism. The correctness of the method is verified through an example.},
  archive      = {J_IJPRAI},
  author       = {Gongjun Zeng and Lei Wang and Gaohong Yu and Mingfeng Zheng and Guohuan Wu and Bingliang Ye},
  doi          = {10.1142/S0218001424580011},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2458001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A synthesis method of open-chain coupled serial linkage mechanism fusing trajectory and posture},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Face detection framework for accelerated analysis of
high-quality multimedia content. <em>IJPRAI</em>, <em>38</em>(4),
2456001. (<a href="https://doi.org/10.1142/S0218001424560019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern face detection algorithms fail to provide optimal results when they have to deal with larger amounts of data per frame while processing higher quality videos. This paper tackles that problem and offers a solution to deploy commercially used state-of-the-art face detection algorithms to process only the regions of interest in a frame, and discard the rest to decrease the data to be processed. The model maintains the accuracy of the base algorithm while decreasing the processing time per frame, thereby increasing the overall efficiency. The selection of region of interest is dependent on the detection of facial window in the previous frame. Therefore, the choice of base algorithm plays an important role in determining the speed of the framework. The model achieves increased processing speeds of about 69–76% more than the standalone usage of the detection algorithms for analyzed frame rates.},
  archive      = {J_IJPRAI},
  author       = {Akshay Mool and Jeebananda Panda and Kapil Sharma},
  doi          = {10.1142/S0218001424560019},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2456001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Face detection framework for accelerated analysis of high-quality multimedia content},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MMDCP: An image enhancement algorithm incorporating
multi-channel phase activation and multi-constrained dark channel prior.
<em>IJPRAI</em>, <em>38</em>(4), 2454005. (<a
href="https://doi.org/10.1142/S0218001424540053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of visual media is critically impacted by low illumination and the presence of airborne particulates, leading to challenges in brightness balance, color saturation, and texture clarity which are detrimental to various applications in image processing and computer vision. Addressing these challenges, this study introduces a novel image enhancement algorithm that significantly improves the quality of degraded images. Our proposed method, the multi-channel phase activation and multi-constraint dark channel prior (MMDCP), leverages an innovative approach by integrating the phase-adjusted Gaussian kernel function for brightness channel optimization in the Fourier transform frequency domain. This optimization is enhanced through the application of a saturated dark channel prior, achieving simultaneous brightness enhancement and color fidelity. Furthermore, we refine the dark channel prior deblurring algorithm by incorporating intensity, brightness, and color constraints to correct overexposure issues and color offsets in the reconstructed images. The efficacy of the MMDCP algorithm is demonstrated through extensive experimentation, comparing it against six contemporary image enhancement algorithms using two types of objective indicators and subjective assessments across four public datasets. The MMDCP algorithm consistently outperforms the existing methods, with a notable average improvement of 20% in PSNR and 19.6% in SSIM metrics, substantiating its superiority in enhancing brightness, detail, and color accuracy. This study’s results underline the MMDCP algorithm’s robustness and versatility in improving image quality across various conditions, including daytime, nighttime, indoor, and outdoor settings.},
  archive      = {J_IJPRAI},
  author       = {Linliang Zhang and Lianshan Yan and Shuo Li and Saifei Li},
  doi          = {10.1142/S0218001424540053},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2454005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {MMDCP: An image enhancement algorithm incorporating multi-channel phase activation and multi-constrained dark channel prior},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Medical image segmentation with dual-encoding and
multi-level feature adaptive fusion. <em>IJPRAI</em>, <em>38</em>(4),
2454004. (<a href="https://doi.org/10.1142/S0218001424540041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Purpose: Accurate segmentation of medical images is critical for disease diagnosis, surgical planning and prognostic assessment. TransUNet, a hybrid CNN-Transformer-based method, extracts local features using CNN and compensates for the lack of long-range dependencies through a self-attention mechanism. However, the initial focus on extracting local features from specific regions impacts the generation of subsequent global features, thus constraining the model’s capacity to effectively capture a broader range of semantic information. Effective integration of local and global features plays a pivotal role in achieving precise and dense prediction. Therefore, we propose a novel hybrid CNN-Transformer-based method aimed at enhancing medical image segmentation. Approach: In this study, a dual-encoder parallel structure is used to enhance the feature representation of the input image. By introducing a multi-scale adaptive feature fusion module, a fine fusion of local features across perceptual domains is realized in the decoding process. The generalized convolutional block attention module helps to increase cross-channel interactions in layers with more channels, thus enabling the fusion of local features and global representations at different resolutions during the decoding process. Results: The proposed method achieves average DSC scores of 79.98%, 84.83% and 85.78% on the Synapse, ISIC2017 and Pediatric Pyelonephritis datasets, respectively. These scores are 2.5%, 0.56% and 0.42% higher than those of TransUNet. The best performance of 91.66% is observed on the ACDC dataset, representing improvements of 2.46% and 7.24% compared to HiFormer and DAE-Former, respectively. Conclusions: The experimental results show that the proposed model has a significant competitive advantage in terms of ACDC image segmentation performance.},
  archive      = {J_IJPRAI},
  author       = {Shulei Wu and You Yang and Fanghong Zhang},
  doi          = {10.1142/S0218001424540041},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2454004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Medical image segmentation with dual-encoding and multi-level feature adaptive fusion},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The deep hybrid neural network and an application on polyp
detection. <em>IJPRAI</em>, <em>38</em>(4), 2452009. (<a
href="https://doi.org/10.1142/S0218001424520098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical morphology and convolution operators are two different methods to extract the characteristics and structures of images. Over the past decades, Deep Convolutional Neural Networks (DCNN) have been proven to be more powerful than traditional image-processing approaches. In this paper, we propose a novel structure called Deep Hybrid Neural Network (DHNN) by taking advantage of the convolution and morphological neural layers. Its practical application to polyp detection in medical images is illustrated. For experimental completeness, we adopt nine polyp image datasets, including publicly available data and our own collected data. For performance comparisons, we select three backbone models. Experimental results show that our DHNN achieves the best performance in comparisons in terms of computational complexity and accurate performance.},
  archive      = {J_IJPRAI},
  author       = {Yi-Ta Wu and Frank Y. Shih and Cheng-Long Wang and Kuang-Ting Hsiao and You-Cheng Liu and Fu-Chieh Chang and En-Da Yu},
  doi          = {10.1142/S0218001424520098},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2452009},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {The deep hybrid neural network and an application on polyp detection},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CONHyperKGE: Using contrastive learning in hyperbolic space
for knowledge graph embedding. <em>IJPRAI</em>, <em>38</em>(4), 2451005.
(<a href="https://doi.org/10.1142/S0218001424510054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The embedding of Knowledge Graphs (KGs) in hyperbolic space has recently received great attention in the field of deep learning because it can provide more accurate and concise representations of hierarchical structures compared to Euclidean spaces and complex spaces. Although hyperbolic space embeddings have shown significant improvements over Euclidean spaces and complex space embeddings in handling the task of KG embedding, they still face challenges related to the uneven distribution and insufficient alignment of high-dimensional sparse data. To address this issue, we propose the CONHyperKGE model, which leverages contrastive learning to optimize the embedding distribution in hyperbolic space. This approach enables better capture of hierarchical structures, improved handling of symmetry, and enhanced treatment of sparse matrices. Our proposed method is evaluated on four standard KG Embedding (KGE) datasets: WN18RR, FB15k-237, Kinship, and UMLS. After extensive experimental verification, our method has improved its performance on all four datasets. Notably, on the low-dimensional Kinship dataset, our method achieves an average Mean Reciprocal Rank (MRR) improvement of 2% over the original method, while on the high-dimensional WN18RR dataset, an average MRR improvement of 1% is observed compared to the original method.},
  archive      = {J_IJPRAI},
  author       = {Mandeng Gao and Shengwei Tian and Long Yu},
  doi          = {10.1142/S0218001424510054},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2451005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {CONHyperKGE: Using contrastive learning in hyperbolic space for knowledge graph embedding},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection of dense built-up area in low-resolution satellite
images using deep learning and DBSCAN approaches. <em>IJPRAI</em>,
<em>38</em>(4), 2451004. (<a
href="https://doi.org/10.1142/S0218001424510042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in satellite image processing tend to eliminate the need for intensive on-site surveys of urban or rural areas for infrastructure allocation planning. In particular, the detection of buildings in satellite images can significantly aid in rural or urban planning. However, detecting individual buildings in low-resolution satellite images is challenging due to a lack of visual clarity. In order to address this problem, we propose a computer vision-based hybrid framework to detect densely constructed building regions in low resolution satellite images, which can also serve as an assistive framework for automated geo-spatial survey of various sites. Our hybrid framework is comprised of three modules, namely the Mask R-CNN module, an ANN-based refinement module, and a DBSCAN based refinement module. The Mask R-CNN is employed to predict probable clustered building regions in the satellite image, whereas the ANN-based refinement module is applied to remove homogeneous regions (e.g. vegetation area) from the Mask R-CNN-detected clustered building region. Finally, a DBSCAN-based refinement module removes non-congested built-up regions so that densely constructed built-up areas can be identified with better precision. Our experimentation using publicly accessible satellite image datasets (AIRS dataset-Kaggle) establishes the effectiveness of the proposed hybrid framework in identifying densely populated building areas in low-resolution satellite images. The outcomes of the proposed framework demonstrated an approximately 5–10% improvement over various Mask R-CNN and U-Net-based approaches in terms of achieving better precision value of the detection.},
  archive      = {J_IJPRAI},
  author       = {Shambo Chatterjee and Soumya Bhattacharyya and Sourav Saha and Anindya Halder and Priya Ranjan Sinha Mahapatra},
  doi          = {10.1142/S0218001424510042},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2451004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Detection of dense built-up area in low-resolution satellite images using deep learning and DBSCAN approaches},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motion vector-based self-attention for real-time human
activity recognition in compressed videos: The MVViT approach.
<em>IJPRAI</em>, <em>38</em>(4), 2450005. (<a
href="https://doi.org/10.1142/S0218001424500058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Herein, a novel methodology is proposed for real-time recognition of human activity in a compressed domain of videos based on motion vectors and self-attention mechanism using vision transformers, and it is termed as motion vectors and vision transformers (MVViT). The videos in MPEG-4 and H.264 compression formats are considered for this study. Any video source without any prior setup could be considered by adopting the proposed method to the corresponding video codecs and camera settings. Existing algorithms for recognition of human action in a compressed video have some limitations in this regard, such as (i) requirement of keyframes at a fixed interval, (ii) usage of P frames only, and (iii) normally support single codec only. These limitations are overcome in the proposed method by using arbitrary keyframe intervals, using both P and B frames, and supporting MPEG-4 as well as H.264 codecs. The experimentation is carried out using the benchmark datasets, namely, UCF101, HMDB51, and THUMOS14, and the recognition accuracy in a compressed domain is found to be comparable to that observed in raw video data but at reduced cost of computation. The proposed MVViT method has outperformed other recent methods in terms of a lesser (61.0%) number of parameters and (63.7%) Giga Floating Point Operations Per Second (GFLOPS), while significantly improving accuracy by 0.8%, 5.9% and 16.6% for UCF101, HMDB51 and THUMOS14, respectively. Also, it is observed that the speed is increased by 8% in case of UCF101 when compared to the highest speed reported in the literature on the same dataset. The ablation study of the proposed method has been done using MVViT variants for different codecs and the performance analysis is done in comparison with the state-of-the-art network models.},
  archive      = {J_IJPRAI},
  author       = {S. M. Praveenkumar and Prakashgoud Patil and P. S. Hiremath},
  doi          = {10.1142/S0218001424500058},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2450005},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Motion vector-based self-attention for real-time human activity recognition in compressed videos: The MVViT approach},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Medical named entity recognition model based on knowledge
graph enhancement. <em>IJPRAI</em>, <em>38</em>(4), 2450004. (<a
href="https://doi.org/10.1142/S0218001424500046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the recognition ability of clinical named entity recognition (CNER) in a limited number of Chinese electronic medical records, it provides meaningful support for clinical advanced knowledge extraction. In this paper, using CCKS2019 Chinese electronic medical record as an experimental data source, a fusion model enhanced by knowledge graph (KG) is proposed, and the model is applied to specific Chinese CNER tasks. This study consists of three main parts: single-mode model construction and comparison experiment, KG enhancement experiment, and model fusion experiment. The model has achieved good performance in CNER from the results. The accuracy rate, recall rate, and F1 value are 83.825%, 84.705%, and 84.263%, respectively, which is the global optimal, which proves the effectiveness of the model. This provides a good help for further research of medical information.},
  archive      = {J_IJPRAI},
  author       = {Yonghe Lu and Ruijie Zhao and Xiuxian Wen and Xinyu Tong and Dingcheng Xiang and Jinxia Zhang},
  doi          = {10.1142/S0218001424500046},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2450004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Medical named entity recognition model based on knowledge graph enhancement},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Damage analysis of urban comprehensive pipe gallery caused
by internal gas explosion based on HHT. <em>IJPRAI</em>, <em>38</em>(4),
2354008. (<a href="https://doi.org/10.1142/S0218001423540083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the method of embedding piezoelectric ceramic sensors is used to test the damage of the materials and models of the urban comprehensive pipe gallery. The monitoring signal is processed by HHT method, and the frequency and energy changes of the piezoelectric signal before and after the explosion were analyzed, thus the damage characteristics of the urban comprehensive pipe gallery under the internal gas explosion are determined. The results show that in the gas explosion test inside the pipe gallery model, the waveform and peak value of the piezoelectric signal before and after the explosion did not change significantly, indicating that there was no obvious damage to the side wall of the integrated pipe gallery. However, after further time-frequency analysis of the piezoelectric signal by HHT, it is found that the dominant frequency of the piezoelectric signal after explosion has a downward trend, so it is judged that there is a small damage in the pipe gallery after explosion.},
  archive      = {J_IJPRAI},
  author       = {Linna Li and Zhengying Ma and Dongwang Zhong and Tengfei Li and Qi Zhang},
  doi          = {10.1142/S0218001423540083},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {4},
  pages        = {2354008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Damage analysis of urban comprehensive pipe gallery caused by internal gas explosion based on HHT},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pinball-OCSVM for early-stage COVID-19 diagnosis with
limited posteroanterior chest x-ray images. <em>IJPRAI</em>,
<em>38</em>(3), 2457002. (<a
href="https://doi.org/10.1142/S0218001424570027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional way of respiratory coronavirus disease 2019 (COVID-19) diagnosis is reverse transcription polymerase chain reaction (RT-PCR), which is less sensitive during early stages; especially if the patient is asymptomatic, which may further cause more severe pneumonia. In this context, several deep learning models have been proposed to identify pulmonary infections using publicly available chest X-ray (CXR) image datasets for early diagnosis, better treatment and quick cure. In these datasets, the presence of less number of COVID-19 positive samples compared to other classes (normal, pneumonia and Tuberculosis) raises the challenge for unbiased learning of deep learning models. This learning problem can be considered as one-class classification problem where the target class samples are present and other classes are absent or ill-defined. All deep learning models opted class balancing techniques to solve this issue; which however should be avoided in any medical diagnosis process. Moreover, the deep learning models are also data hungry and need massive computation resources. Therefore, for quicker diagnosis, this research proposes a novel pinball loss function based one-class support vector machine (PB-OCSVM), that can work in presence of limited COVID-19 positive CXR samples (target class or class-of-interest (CoI) samples) with objectives to maximize the learning efficiency and to minimize the false predictions. The performance of the proposed model is compared with conventional OCSVM and recent deep learning models, and the experimental results prove that the proposed model outperformed state-of-the-art methods. To validate the robustness of the proposed model, experiments are also performed with noisy CXR images and UCI benchmark datasets.},
  archive      = {J_IJPRAI},
  author       = {Sanjay Kumar Sonbhadra and Sonali Agarwal and P. Nagabhushan},
  doi          = {10.1142/S0218001424570027},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2457002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Pinball-OCSVM for early-stage COVID-19 diagnosis with limited posteroanterior chest X-ray images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UAV target tracking algorithm based on illumination
adaptation and future awareness in low illumination scenes.
<em>IJPRAI</em>, <em>38</em>(3), 2455003. (<a
href="https://doi.org/10.1142/S0218001424550036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at problems such as tracking failure caused by illumination changes often encountered during unmanned aerial vehicle (UAV) tracking, a target tracking algorithm with illumination adaptive and future-aware correlation filters is proposed based on the background-aware correlation filters (BACF) algorithm, which realizes reliable UAV tracking tasks at night. First, the dark scene is recognized, and an efficient image enhancement module is used to enhance the brightness of low illumination images. Then a future-aware module is constructed to train the tracking model using the contextual information of the target in the next frame for better robustness. Finally, the model updating stage involves adaptive filter updating and adaptive learning rate updating to enhance target tracking precision. The results of the comparison experiments with the state-of-the-art algorithms on the UAVDark135, UAVDT, and DTB70 datasets show that the algorithm in this paper outperforms the state-of-the-art tracking methods and has better tracking performance under light changes and fast motion (FM) scenarios. The tracking speed on a single Central processing unit (CPU) reaches 49 FPS, which satisfies the real-time requirement of UAV tracking.},
  archive      = {J_IJPRAI},
  author       = {Yuan-Lian Huo and Bo Chen and Jin-Shi Zhang and Qiao-Sen Zhang},
  doi          = {10.1142/S0218001424550036},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2455003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {UAV target tracking algorithm based on illumination adaptation and future awareness in low illumination scenes},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An analysis of hierarchical routing strategy with advanced
additional sensors in WSNs. <em>IJPRAI</em>, <em>38</em>(3), 2455002.
(<a href="https://doi.org/10.1142/S0218001424550024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two kinds of sensors will be discussed in some sort of wireless sensor networks (WSNs). One is named a normal sensor (called A_nodes) with fixed initial energy, which can get perception data from the surrounding environment and have functions of storage and forwarding. The other is named relay sensor (called B_node) with sufficient energy, which only can store data and forward data. Cluster heads (called A_heads) are chosen among A_nodes by probability mode to create clusters first. Local adjustments would be done inter-cluster. Then the sink is selected as the root and a backbone shortest path tree with hops limited is built dynamically from A_heads, B_Nodes and sink. Inside the backbone shortest path aggregation tree, two steps are done. The first step, select some B_node as cluster head (denoted as B_node) and make local adjustment intra-clusters if it is possible. The second step, adjust the shortest path aggregation tree. By using both particle swarm optimization (PSO) and ant colony optimization (ACO), a traveling salesman problem (TSP) cycle with shorter path length is obtained (this method is noted as TSP_PSO_ACO). This TSP cycle consists of all nodes in the aggregation backbone tree. Along this cycle, energy is offered to nodes except sink. The above strategy would be discussed for its feasibility and time complexity. The experimental results imply that the energy consumption is reduced by using local adjustment. The relative failure rate of nodes can be reduced in the later stage of WSN survival. Offering energy to a small number of nodes several times has no obvious impact on the overall energy consumption and survival time of WSN. The case with some small-sized obstacles in WSN area is also discussed. There are little affections on TSP cycles both from results on theoretical analysis and simulation if there are some obstacles with small size in WSN area.},
  archive      = {J_IJPRAI},
  author       = {Dongmei Xing},
  doi          = {10.1142/S0218001424550024},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2455002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An analysis of hierarchical routing strategy with advanced additional sensors in WSNs},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent classification of metallographic based on
improved deep residual efficiency networks. <em>IJPRAI</em>,
<em>38</em>(3), 2452008. (<a
href="https://doi.org/10.1142/S0218001424520086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition of steel microstructure images plays a crucial role in the metallographic analysis process. Although some progress has been made through the application of artificial intelligence algorithms, several challenges remain. First, existing algorithms exhibit weak nonlinear feature extraction capabilities and noticeable limitations. Second, they overlook the intrinsic noise and redundant interference present in microscopic images. To address these issues, this paper investigates the automatic recognition of metallographic tissues by leveraging residual structures in deep neural networks. An enhanced residual network model based on transfer learning is proposed, which utilizes the pre-trained weights from the ImageNet dataset to facilitate learning with small sample data. This network offers higher classification accuracy and higher F1 scores. In addition, a deep residual shrinkage network model based on an attention mechanism is proposed. This model incorporates an attention sub-network into the original residual module and employs a soft threshold function to eliminate redundant features, including noise. The proposed algorithms are evaluated against various convolutional neural networks using 20 types of metallographic test sets. The experimental results showed that both methods have high accuracy rates of 95% and 94.44%, respectively, and F1 scores of 0.9464 and 0.9419. While maintaining the complexity of the model, there has been a significant improvement in accuracy, and the models exhibit strong generalization capabilities. Our research contributes to enhancing production efficiency, strengthening quality control, and improving material performance through computer vision technology.},
  archive      = {J_IJPRAI},
  author       = {Xiaohong Huang and Yanping Liu and Xueqian Qi and Yue Song},
  doi          = {10.1142/S0218001424520086},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2452008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Intelligent classification of metallographic based on improved deep residual efficiency networks},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing handwritten musical notation recognition using
deep learning: A convolutional neural network-based approach with
improved accuracy. <em>IJPRAI</em>, <em>38</em>(3), 2452007. (<a
href="https://doi.org/10.1142/S0218001424520074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of computers to read musical scores is referred to as optical music recognition (OMR). The recent advancements in artificial intelligence and big data have led to the development of deep learning approaches for recognizing musical notes. Previous research has shown that there is a lot of room for improvement in handwritten musical notation recognition systems due to differences in writing styles and the complex structure of musical symbols. The research described here aims to develop a deep learning-based system for recognizing handwritten musical notation. The system uses a convolutional neural network (CNN) to extract and learn pixel features of musical symbols and achieve a recognition accuracy of over 90%. The CNN model was trained using image samples from the HOMUS dataset and fine-tuned to minimize the loss function and reduce classification errors. The CNN model achieved an accuracy of 96.95% on the test samples, which is a significant improvement over the 86.0% accuracy from previous studies. The performance of the CNN model was also compared to five state-of-the-art deep learning methods, namely, quantum gray Wolf optimization (QGWO) algorithm, nonfully connected network (NFC-Net) classifier, nearest neighbor classifier, data augmentation and ensemble learning, and the CNN model outperformed four of them. However, the CNN model occasionally misclassified musical symbols with similar shapes, indicating that there is still room for improvement in the system’s performance. Future research could focus on improving the model’s performance on similar-shaped symbols. Overall, the research demonstrates the effectiveness of using a CNN model for handwritten musical notation recognition and highlights the potential of deep learning approaches in this area.},
  archive      = {J_IJPRAI},
  author       = {Ee Hern Kheng and Chia Pao Liew and Tianhao Lan and Kim Geok Tan},
  doi          = {10.1142/S0218001424520074},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2452007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Advancing handwritten musical notation recognition using deep learning: A convolutional neural network-based approach with improved accuracy},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Altered handwritten text detection in document images using
deep learning. <em>IJPRAI</em>, <em>38</em>(3), 2452006. (<a
href="https://doi.org/10.1142/S0218001424520062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten documents possess immense significance in domains such as law, history, and administration. However, they are vulnerable to forgery, which can undermine their credibility and reliability. This paper aims to establish a dependable technique for identifying altered text in handwritten document images, even in scenarios with high levels of noise and blur. Our study investigates 10 distinct categories of handwritten text that have been altered through various forgery operations. The suggested approach employs the deep neural architectures VGG16 and Resnet50 as feature extractors. The architecture comprises three parts: Feature extraction using individual models, a feature fusion layer, and a classification layer. Initially, we optimize the training process and feature extraction using VGG16 and ResNet50. The feature vectors obtained from both models are then fused together in the feature fusion layer and input into the classification layer for the classification task. Experiments are conducted on a custom-created dataset as well as benchmark datasets including ICPR FDC, IMEI Forged Number, and Kundu to demonstrate that the proposed method is superior to existing approaches.},
  archive      = {J_IJPRAI},
  author       = {Gayatri Patil and Shivakumara Palaiahnakote and Shivanand S. Gornale and Daniel P. Lopresti},
  doi          = {10.1142/S0218001424520062},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2452006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Altered handwritten text detection in document images using deep learning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rolling bearing composite fault diagnosis method based on
convolutional neural network. <em>IJPRAI</em>, <em>38</em>(3), 2451008.
(<a href="https://doi.org/10.1142/S021800142451008X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling bearing feature extraction and fault identification techniques using deep learning algorithms have been widely adopted in recent years. We proposed a method for diagnosing composite faults in rolling bearings by employing multisensor decision fusion and convolutional neural networks. Different types of bearing faults and eccentricity faults have different fault eigenfrequencies in vibration signals. In the proposed method, vibration and acoustic signals are collected, their characteristics are analyzed, and multisensor data fusion processing is conducted. A neural network is then used to identify the signals containing bearing fault characteristics to diagnose bearing faults at different rotational speeds. We demonstrated the effectiveness of the proposed method by conducting comparative experiments on existing methods.},
  archive      = {J_IJPRAI},
  author       = {Song Chen and Dong-ting Guo and Li-ai Chen and Da-gui Wang},
  doi          = {10.1142/S021800142451008X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2451008},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Rolling bearing composite fault diagnosis method based on convolutional neural network},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot text classification with an efficient prompt tuning
method in meta-learning framework. <em>IJPRAI</em>, <em>38</em>(3),
2451006. (<a href="https://doi.org/10.1142/S0218001424510066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-learning stands as a prevalent framework utilized in few-shot learning methods. Nonetheless, its efficacy hinges on substantial data availability during meta-training. Recent work adeptly tackled this hurdle by synergizing prompt tuning with the meta-learning paradigm, consequently attaining unparalleled performance on four benchmarks (FewRel, HuffPost, Reuters and Amazon). Nonetheless, the implementation efficacy of the previous method leaves room for enhancement, which is especially crucial when tuning larger language models. To this end, we introduce another expedited prompt tuning approach nested within the meta-learning framework. The novel approach normalizes the label information and sample information and uses the regression method to obtain the closed-form solution of each few-shot task, which significantly enhances inference speed, achieving a twofold improvement, while concurrently elevating average accuracy by 1 . 7 ∼ 3 . 0 % on the same benchmarks. Moreover, it demonstrates enhanced stability when faced with limited meta-training data, which is more applicable in many real scenarios where parallel data is rare. The source code is available to reproduce the results (http://github.com/Dr-Lv/EMPT).},
  archive      = {J_IJPRAI},
  author       = {Xiaobao Lv},
  doi          = {10.1142/S0218001424510066},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2451006},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Few-shot text classification with an efficient prompt tuning method in meta-learning framework},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Perspective collaboration for multi-domain fake news
detection. <em>IJPRAI</em>, <em>38</em>(3), 2450003. (<a
href="https://doi.org/10.1142/S0218001424500034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news is widely spread on social media. Much research works have been done on automatic fake news detection in single domain. However, fake news exists in various domains, so the detection model based on single domain is less effective in multiple domain scenes. To improve the detection ability of multi-domain fake news, we propose a perspective collaboration for multi-domain fake news detection (PCMFND) method to detect fake news across multiple domains by combining the powerful feature extraction ability of expert systems. The method extracts features of different perspectives from news content separately, then interactively combines the features of different perspectives, and ultimately achieves fake news detection by adaptively aggregating features of each perspective through domain knowledge. The effectiveness of the proposed method is demonstrated through comparison experiments with traditional multi-domain detection methods on Chinese and English multi-domain datasets.},
  archive      = {J_IJPRAI},
  author       = {Hui Li and Yuanyuan Jiang and Xing Li and Chenxi Wang and Yanyan Chen and Haining Li},
  doi          = {10.1142/S0218001424500034},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2450003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Perspective collaboration for multi-domain fake news detection},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PRLDPC: A heuristics prototype reduction method based on
supervised local density clustering for instance-based classifiers.
<em>IJPRAI</em>, <em>38</em>(3), 2450002. (<a
href="https://doi.org/10.1142/S0218001424500022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prototype reduction (PR) methods, as an important data pre-processing task, can improve instance-based classifiers by removing noise and/or redundant samples. Recently, a series of PR methods with different heuristic strategies have been developed. Among them, clustering-based PR methods have shown competitive performance. Yet, they still suffer from the following issues: (a) most methods heavily rely on parameters; (b) most fail to remove suspicious noisy samples from the training set; (c) almost all fail to handle manifold data with nonspherical distributions effectively; (d) some have a relatively high time complexity. To advance the state of the art of clustering-based PR methods by overcoming the above issues, a novel heuristics PR method based on supervised local density peaks clustering (PRLDPC) is proposed. The main ideas of PRLDPC are concluded as follows: (a) a supervised local density peaks clustering (SLDPC) is first proposed to divide the training set into homogeneous and heterogeneous sub-clusters; (b) SLDPC-based edition method is second proposed to identify and remove noisy samples from heterogeneous sub-clusters; (c) an SLDPC-based condensing method is third proposed to obtain reduced samples from homogeneous sub-clusters and pruned heterogeneous sub-clusters. Intensive experiments have proven that (a) PRLDPC can outperform six state-of-the-art PR methods on extensive UCI and Kaggle data sets in weighing the reduction rate and classification accuracy of three instance-based classifiers; (b) PRLDPC is relatively fast and has a relatively low time complexity O ( n log n ) .},
  archive      = {J_IJPRAI},
  author       = {Xing Huang and Junnan Li},
  doi          = {10.1142/S0218001424500022},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {3},
  pages        = {2450002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {PRLDPC: A heuristics prototype reduction method based on supervised local density clustering for instance-based classifiers},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Head pose estimation based on multi-level feature fusion.
<em>IJPRAI</em>, <em>38</em>(2), 2456002. (<a
href="https://doi.org/10.1142/S0218001424560020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Head Pose Estimation (HPE) has a wide range of applications in computer vision, but still faces challenges: (1) Existing studies commonly use Euler angles or quaternions as pose labels, which may lead to discontinuity problems. (2) HPE does not effectively address regression via rotated matrices. (3) There is a low recognition rate in complex scenes, high computational requirements, etc. This paper presents an improved unconstrained HPE model to address these challenges. First, a rotation matrix form is introduced to solve the problem of unclear rotation labels. Second, a continuous 6D rotation matrix representation is used for efficient and robust direct regression. The RepVGG-A2 lightweight framework is used for feature extraction, and by adding a multi-level feature fusion module and a coordinate attention mechanism with residual connection, to improve the network’s ability to perceive contextual information and pay attention to features. The model’s accuracy was further improved by replacing the network activation function and improving the loss function. Experiments on the BIWI dataset 7:3 dividing the training and test sets show that the average absolute error of HPE for the proposed network model is 2.41. Trained on the dataset 300W_LP and tested on the AFLW2000 and BIWI datasets, the average absolute errors of HPE of the proposed network model are 4.34 and 3.93. The experimental results demonstrate that the improved network has better HPE performance.},
  archive      = {J_IJPRAI},
  author       = {Chunman Yan and Xiao Zhang},
  doi          = {10.1142/S0218001424560020},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2456002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Head pose estimation based on multi-level feature fusion},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on multi-source heterogeneous big data fusion
method based on feature level. <em>IJPRAI</em>, <em>38</em>(2), 2455001.
(<a href="https://doi.org/10.1142/S0218001424550012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of research on multi-modal data fusion and its combination with online data management, the application of multi-modal big data fusion in information management systems is more and more extensive. How to integrate multi-modal big data effectively is the key technology to building an efficient information management system. In this paper, based on the combination of a multi-support vector machine and convolution neural network, the feature-level data fusion of multi-source heterogeneous big data is implemented, and it is applied to the real data set to test the relevant model. Experimental results show that this method can not only realize heterogeneous integration of big data, but also has high accuracy and reliability.},
  archive      = {J_IJPRAI},
  author       = {Yanyan Chen and Chenxi Wang and Yuchen Zhou and Yuhang Zuo and Zixuan Yang and Hui Li and Juan Yang},
  doi          = {10.1142/S0218001424550012},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2455001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Research on multi-source heterogeneous big data fusion method based on feature level},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A domain variable prior based multi-style transfer network
for data augmentation of tidal stream turbine rotor image dataset.
<em>IJPRAI</em>, <em>38</em>(2), 2454003. (<a
href="https://doi.org/10.1142/S021800142454003X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The style of the underwater images varies according to the region of the sea. However, Tidal Stream Turbine (TST) rotor images captured in the laboratory environment cannot reflect the real underwater environment in image style, resulting in poor generalization of image signal-based fault detection algorithms. Due to the fixed capture position of the camera, the TST rotor image dataset has a high semantic similarity between images, resulting in content loss in conventional image-to-image translation networks. Meanwhile, the one-to-one translation feature in other works cannot meet our requirements. In this work, a Domain Variable Prior-based Multi-style Transfer Network (DVP-MSTN) is proposed to achieve TST rotor image style augmentation. First, the backbone network is trained using a public paired dataset to acquire prior knowledge of domain variable (Knowledge Acquiring, KA). Next, a Multi-domain Transfer Unit (MDT unit) is introduced to enable the conversion of style representations in low-dimensional space. Finally, the prior knowledge is shared to train the MDT unit by fixing the parameters of the backbone network optimized from the KA process (Knowledge Sharing, KS). In addition, an algorithm based on the dark channel of the image is proposed to improve the transfer of low-contrast features. Specifically, a discriminator is used to discriminate the image dark channel to guide the MDT unit to generate low-contrast style representation conditionally. Meanwhile, color loss is employed to preserve the color feature of the image. By controlling the weights of the style code, this method enables control over the image style transfer process, thereby expanding the variety of image styles in the dataset for the purpose of data augmentation.},
  archive      = {J_IJPRAI},
  author       = {Guohan Jiang and Tianzhen Wang and Dingding Yang and Jingyi You},
  doi          = {10.1142/S021800142454003X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2454003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A domain variable prior based multi-style transfer network for data augmentation of tidal stream turbine rotor image dataset},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A rate control scheme for VVC intercoding using a linear
model. <em>IJPRAI</em>, <em>38</em>(2), 2454002. (<a
href="https://doi.org/10.1142/S0218001424540028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Versatile video coding (VVC) aims to achieve high compression but also issues like varying content/network conditions. Existing rate control (RC) methods struggle to achieve optimal quality under these complex scenarios. This paper proposes a novel RC scheme for VVC based on a linear model. The Lagrange minimization multiplier is introduced under bit budget constraints, allowing optimized bit allocation. RC optimization is formulated as a convex solution, and is derived into the optimal quantization parameter (QP) for RC. Experimental analysis demonstrates the proposed linear model-based RC algorithm performances are better compared to other state-of-the-art methods due to their use of a linear model and optimal QP determination.},
  archive      = {J_IJPRAI},
  author       = {Heqiang Wang and Xuekai Wei and Weizhi Xian and Jun Luo and Huayan Pu and Zhigang Chu and Xin Wang and Xueyong Xu and Chang Lu and Mingliang Zhou},
  doi          = {10.1142/S0218001424540028},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2454002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A rate control scheme for VVC intercoding using a linear model},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Residual network for image compression artifact reduction.
<em>IJPRAI</em>, <em>38</em>(2), 2454001. (<a
href="https://doi.org/10.1142/S0218001424540016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an image compression algorithm based on Swin Transformer and residual network (STRN), aiming to reduce blurring and distortions in traditionally compressed images. The algorithm utilizes a dual-channel mechanism to remove artifacts from the image, which takes advantage of the complementary features of the transform and residual networks. The Swin Transformer networks address the issue of long-range dependency, leading to an enhanced and improved reconstructed image quality. The residual network is an effective network that mitigates gradient loss and recovers image details during the image compression process. The paper demonstrates that image compression can be achieved by training a convolutional network based on a transformer and residuals network, which significantly reduces artifacts and provides better reconstructed image quality compared to previously used and current mainstream methods based on traditional convolutional neural networks. The proposed approach can remove blocking artifacts by subtracting estimated artifacts from the input image, while still preserving most of the original details. Therefore, our proposed method is highly effective in improving image quality and reducing visual artifacts caused by traditional compression methods. Moreover, this method is useful for enhancing image transmission and storage efficiency in various computer vision systems that employ digital visual codecs.},
  archive      = {J_IJPRAI},
  author       = {Jianhua hu and Guixiang Luo and Bo Wang and Weimei Wu and Jiahui Yang and Jianding Guo},
  doi          = {10.1142/S0218001424540016},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2454001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Residual network for image compression artifact reduction},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DAGAN: A GAN network for image denoising of medical images
using deep learning of residual attention structures. <em>IJPRAI</em>,
<em>38</em>(2), 2452003. (<a
href="https://doi.org/10.1142/S0218001424520037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical images are susceptible to noise and artifacts, so denoising becomes an essential pre-processing technique for further medical image processing stages. We propose a medical image denoising method based on dual-attention mechanism for generative adversarial networks (GANs). The method is based on a GAN model with fused residual structure and introduces a global skip-layer connection structure to balance the learning ability of the shallow and deep networks. The generative network uses a residual module containing channel and spatial attention for efficient extraction of CT image features. The mean square error loss and perceptual loss are introduced to construct a composite loss function to optimize the model loss function, which helps to improve the image generation effect of the model. Experimental results on the LUNA dataset and “the 2016 Low-Dose CT Grand Challenge” dataset show that DAGAN achieves the best results in root mean square error (RMSE), structural similarity (SSIM) and peak signal-to-noise ratio (PSNR) when compared to the state-of-the-art methods. In particular, PSNR reaches 31.2308 dB and 27.5265 dB, SSIM reaches 0.9115 and 0.7895, while RMSE is 0.0082 and 0.0112, respectively. This indicates that our method performs better than the state-of-the-art methods in the task of CT image denoising.},
  archive      = {J_IJPRAI},
  author       = {Guoxiang Tong and Fangning Hu and Hongjun Liu},
  doi          = {10.1142/S0218001424520037},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2452003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {DAGAN: A GAN network for image denoising of medical images using deep learning of residual attention structures},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel multi-data-augmentation and multi-deep-learning
framework for counting small vehicles and crowds. <em>IJPRAI</em>,
<em>38</em>(2), 2452001. (<a
href="https://doi.org/10.1142/S0218001424520013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counting small pixel-sized vehicles and crowds in unmanned aerial vehicles (UAV) images is crucial across diverse fields, including geographic information collection, traffic monitoring, item delivery, communication network relay stations, as well as target segmentation, detection, and tracking. This task poses significant challenges due to factors such as varying view angles, non-fixed drone cameras, small object sizes, changing illumination, object occlusion, and image jitter. In this paper, we introduce a novel multi-data-augmentation and multi-deep-learning framework designed for counting small vehicles and crowds in UAV images. The framework harnesses the strengths of specific deep-learning detection models, coupled with the convolutional block attention module and data augmentation techniques. Additionally, we present a new method for detecting cars, motorcycles, and persons with small pixel sizes. Our proposed method undergoes evaluation on the test dataset v2 of the 2022 AI Cup competition, where we secured the first place on the private leaderboard by achieving the highest harmonic mean. Subsequent experimental results demonstrate that our framework outperforms the existing YOLOv7-E6E model. We also conducted comparative experiments using the publicly available VisDrone datasets, and the results show that our model outperforms the other models with the highest AP50 score of 52%.},
  archive      = {J_IJPRAI},
  author       = {Chun-Ming Tsai and Frank Y. Shih},
  doi          = {10.1142/S0218001424520013},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2452001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel multi-data-augmentation and multi-deep-learning framework for counting small vehicles and crowds},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging sampling schemes on skewed class distribution to
enhance male fertility detection with ensemble AI learners.
<em>IJPRAI</em>, <em>38</em>(2), 2451003. (<a
href="https://doi.org/10.1142/S0218001424510030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing effective AI models becomes a challenge when dealing with imbalanced/skewed class distributions in datasets. Addressing this, re-sampling techniques often come into play as potential solutions. In this investigation, we delve into the male fertility dataset, exploring 14 re-sampling approaches to understand their impact on enhancing predictive model performance. The research employs conventional AI learners to gauge male fertility potential. Notably, five ensemble AI learners are studied, their performances are compared, and their results are evaluated using four measurement indices. Through comprehensive comparative analysis, we identify substantial enhancement in model effectiveness. Our findings showcase that the LightGBM model with SMOTE-ENN re-sampling stands out, achieving an efficacy of 96.66% and an F1-Score of 95.60% through 5-fold cross-validation. Interestingly, the CatBoost model, without re-sampling, exhibits strong performance, achieving an efficacy of 86.99% and an F1-Score of 93.02%. Furthermore, we benchmark our approach against state-of-the-art methods in male fertility prediction, particularly highlighting the use of re-sampling techniques like SMOTE and ESLSMOTE. Consequently, our proposed model emerges as a robust and efficient computational framework, promising accurate male fertility prediction.},
  archive      = {J_IJPRAI},
  author       = {Debasmita GhoshRoy and P. A. Alvi and KC Santosh},
  doi          = {10.1142/S0218001424510030},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2451003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Leveraging sampling schemes on skewed class distribution to enhance male fertility detection with ensemble AI learners},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimized ensemble machine learning approach for emotion
detection from thermal images. <em>IJPRAI</em>, <em>38</em>(2), 2451002.
(<a href="https://doi.org/10.1142/S0218001424510029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotions indicate the feelings of the individual which are linked with personal experiences, moods, and affective states. Detection of emotion can be helpful in many fields like maintaining a patient’s psychological well-being, surveillance, driver monitoring, etc. In this paper, an effective machine learning approach has been put forth for emotion detection where an ensemble of three out of five best-performing classifiers has been formed to enhance the classification accuracy. Two deep learning models (AlexNet and ResNet) have been optimally combined with k -nearest neighbor (KNN). The optimal weights for ensemble weighted averaging of classifiers have been computed with aid of particle swarm optimization (PSO) and genetic algorithm (GA) optimization. The developed framework has been tested on two publicly available datasets. An overall accuracy of above 95% has been achieved on the testing set for both datasets. The best performance was obtained by training the classifiers with segmented images and combining them by using the weights obtained through PSO. The results depicted the efficiency of the optimized ensemble machine learning approach for all performance measures used in this study in comparison to the performance of individual classifiers and majority voting fusion.},
  archive      = {J_IJPRAI},
  author       = {Jayaprakash Katual and Amit Kaul},
  doi          = {10.1142/S0218001424510029},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2451002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimized ensemble machine learning approach for emotion detection from thermal images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identification method of unmanned aerial vehicle graphical
control strategy based on cloud server. <em>IJPRAI</em>, <em>38</em>(2),
2450001. (<a href="https://doi.org/10.1142/S0218001424500010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of unmanned aerial vehicle (UAV) technology, UAV has been widely used in agricultural plant protection, electric power inspection, security patrols, and other fields. However, the control system of the UAV is a complex human–computer interaction system, which requires higher requirements in practical applications. Due to differences in hardware design, software development, and other aspects among different manufacturers, these UAV control systems require high hardware requirements, resulting in a long development cycle. At the same time, in practical applications, due to various reasons, there are equipment failures that are difficult to detect and eliminate in a timely manner. This paper used the UAV graphical control strategy identification method based on cloud server technology, and used the support vector machine (SVM) algorithm to analyze its identification accuracy. The research results showed that when other conditions were the same, the number of researchers and experts who were satisfied with the drone trial effect of the cloud server was 42 and 10, respectively, accounting for 84% and 100%. It indicates that they believe that the cloud server can effectively improve the effectiveness of the drone graphical control strategy recognition method, indicating a positive relationship between the two.},
  archive      = {J_IJPRAI},
  author       = {Zhengyu Liu and Zhenbang Cheng and Yu Liu and Qing Jiang},
  doi          = {10.1142/S0218001424500010},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2450001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Identification method of unmanned aerial vehicle graphical control strategy based on cloud server},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pelican whale optimization enabled deep learning framework
for video steganography using arnold transform-based embedding.
<em>IJPRAI</em>, <em>38</em>(2), 2359026. (<a
href="https://doi.org/10.1142/S0218001423590267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steganography refers to hiding a secret message from various sources, such as images, videos, audio and so on. The advantage of steganography is to avoid data hacking in transmission medium during the transmission of information sources. Video steganography is superior to image steganography since the videos can hide a substantial quantity of secret messages more than the image. Hence, this research introduced the video stereography technique, Arnold Transform with SqueezeNet-based Pelican Whale Optimization Algorithm (AT + SqueezeNet_PWOA), for concealing the secret image on the video. To hide the secret image on the video, the proposed method follows three steps: key frame and feature extraction, pixel prediction and embedding. The extraction of the key frame process is carried out by the Structural Similarity Index Measure (SSIM), and then the neighborhood features and convolutional neural network (CNN) features are extracted from the frame to improve the robustness of the embedding process. Moreover, the pixel prediction is completed by the SqueezeNet model, wherein the learning factors are tuned by the PWOA. In addition, the embedding process is completed by applying the Arnold transform on the predicted pixel, and the transformed regions are combined with the secret image using the embedding function. Likewise, the extraction process extracts the secret image from the embedded video by substituting the predicted pixel and Arnold transform on the embedded video. The proposed method is used to hide chunks of secret data in the form of video sequences and it improves the performance. The Arnold transform used in this work provides security by encrypting the data. The use of SqueezeNet makes the proposed model a simple design and this reduces the computational time. Thus, the AT + SqeezeNet_PWOA attained better correlation coefficient (CC), peak signal-to-noise ratio (PSNR) and mean square error (MSE) of 0.908, 48.66 and 0.001 dB with the Gaussian noise.},
  archive      = {J_IJPRAI},
  author       = {Suresh G and Manikandan G and Bhuvaneswari G and Shanthakumar P},
  doi          = {10.1142/S0218001423590267},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2359026},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Pelican whale optimization enabled deep learning framework for video steganography using arnold transform-based embedding},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Medical image segmentation using grey wolf-based u-net with
bi-directional convolutional LSTM. <em>IJPRAI</em>, <em>38</em>(2),
2354025. (<a href="https://doi.org/10.1142/S0218001423540253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning-based networks have been able to achieve state-of-the-art performance in medical image segmentation. U-Net, one of the currently available networks, has proven to be effective when applied to the segmentation of medical images. A Convolutional Neural Network’s (CNN) performance is heavily dependent on the network’s architecture and associated parameters. There are many layers and parameters that need to be set up in order to manually create a CNN, making it a complex procedure. Designing a network is made more difficult by using a variety of connections to increase the network’s complexity. Evolutionary computation can be used to set the parameters of CNN and/or organize the CNN layers as an optimization strategy. This paper proposes an automatic evolutionary method for detecting an optimal network topology and its parameters for the segmentation of clinical image using Grey Wolf Optimization algorithm. Also, Bi-Directional LSTM integrated in the skip connection to extract dense feature characteristics of image by combining feature maps extracted from encoded and previous decoded path in nonlinear way (MIS-GW-U-Net-BiDCLSTM) is proposed. The experimental results demonstrate that the proposed method attains 98.49% accuracy with minimal parameters, which is much better than that of the other methods.},
  archive      = {J_IJPRAI},
  author       = {G. Tamilmani and Phaneendra Varma CH and V. Brindha Devi and Ramesh Babu G},
  doi          = {10.1142/S0218001423540253},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2354025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Medical image segmentation using grey wolf-based U-net with bi-directional convolutional LSTM},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scale enhancement network for object detection in aerial
images. <em>IJPRAI</em>, <em>38</em>(2), 2354024. (<a
href="https://doi.org/10.1142/S0218001423540241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main challenge for object detection in aerial images is small object detection. Most existing methods use feature fusion strategies to enhance small object features in shallow layers but ignore the problem of inconsistent small object local region responses between feature layers, namely the semantic gap, which may lead to underutilization of small object information in multiple feature layers. To lift the above limitations, we propose a scale enhancement module that adaptively passes valuable small object features in different feature layers to shallow layers to alleviate the semantic gap problem. In particular, the module includes the novel fine-coarse self-attention mechanism, which captures global contextual information by performing strong interaction of pixel-level information at the local scale and weak interaction of region-level information at the global scale. In addition, the anchor assignment strategy based on the Intersection over Union (IoU) metric is not favorable for small objects as the IoU metric for small objects has a lower tolerance for position deviation compared to large ones. For this reason, we design the dynamic anchor assignment strategy with a scale-insensitive metric to assign adequate anchors to small objects. Extensive experiments on three aerial datasets demonstrate the effectiveness and adaptability of our method.},
  archive      = {J_IJPRAI},
  author       = {Shihan Mao and Zhi Wang and Qineng He and Zhangqing Zhu},
  doi          = {10.1142/S0218001423540241},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2354024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Scale enhancement network for object detection in aerial images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective document image rectification via a deep learning
framework. <em>IJPRAI</em>, <em>38</em>(2), 2351023. (<a
href="https://doi.org/10.1142/S0218001423510230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an efficient method for rectifying distorted document images via deep learning, ultimately improving the legibility of graphics and text in documents. The framework comprises two interconnected UNets, working in tandem to predict a 3D coordinate map and a forward map for the input distorted document image, respectively. At the beginning of the process, a page mask is predicted and used as input to both U-Nets to help improve the performance of their tasks. In the last step, the predicted forward map is transformed into a corresponding backward map, which is utilized to rectify the distorted image. The experimental results not only reveal that the predicted page masks and 3D coordinate maps significantly enhance the accuracy of predicting forward maps for subsequent rectification but also demonstrate satisfactory results both globally and locally.},
  archive      = {J_IJPRAI},
  author       = {Hsiau-Wen Lin and Hwei Jen Lin and Yihjia Tsai and Yoshimasa Tokuyama and Chou-Wei Kong},
  doi          = {10.1142/S0218001423510230},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2351023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Effective document image rectification via a deep learning framework},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view high precise 3D human body reconstruction method
for virtual fitting. <em>IJPRAI</em>, <em>38</em>(1), 2392002. (<a
href="https://doi.org/10.1142/S0218001423920027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJPRAI},
  author       = {Shufang Zhang and Yanran Liu and Jiang Liu and Yuhong Liu},
  doi          = {10.1142/S0218001423920027},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2392002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-view high precise 3D human body reconstruction method for virtual fitting},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). M2-YOLOX: A novel method for object detection based on an
improved YOLOX algorithm introducing a global attention mechanism and a
feature enhancement module. <em>IJPRAI</em>, <em>38</em>(1), 2359025.
(<a href="https://doi.org/10.1142/S0218001423590255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based algorithms for detecting objects in remote sensing images have produced excellent results recently. However, the target recognition and classification process of remote sensing images has problems such as dense targets, uneven distribution, large-scale changes and complex backgrounds. In order to improve the effectiveness of existing detection methods, based on the YOLOX algorithm, a remote sensing image object detection algorithm introducing Global Attention Mechanism (GAM) and Feature Enhancement Module (FEM) proposed, named the M 2 -YOLOX(GAM+FEM+YOLOX) algorithm. First, a novel GAM module is developed that employs a sequential channel-space attention mechanism and redesigns the Convolutional Block Attention Module (CBAM), to address the issues of low effective information extraction and weak information representation of the feature map in the backbone network. CBAM is capable of amplifying global dimensional interaction features while reducing information dispersion as well. Second, the goal of the FEM is to improve the target feature extraction capabilities of the backbone feature extraction network by fusing numerous perceptual field features in lower-level feature maps. Then, the Flexible Rectified Linear Unit (FReLU) activation function is introduced under the action of feature fusion and global attention mechanism. Four-way feature map output in Feature Pyramid Networks (FPN) with Non-Maximum Suppression (NMS) and score filtering for object detection and output results. In comparison to the YOLOX algorithm, the experimental results show that the mAP value of the M 2 -YOLOX algorithm is improved by 0.0123, the LAMR value is decreased by 0.0150, the Precision rate value is increased by 0.105450, the Recall value is increased by 0.053250, and the mF1 value is increased by 0.0425.},
  archive      = {J_IJPRAI},
  author       = {Xiaofeng Bai and Kaijun Wu and Chenshuai Bai},
  doi          = {10.1142/S0218001423590255},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2359025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {M2-YOLOX: A novel method for object detection based on an improved YOLOX algorithm introducing a global attention mechanism and a feature enhancement module},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid optimized deep learning-based bacilli segmentation
and infection-level identification of tuberculosis using sputum images.
<em>IJPRAI</em>, <em>38</em>(1), 2357017. (<a
href="https://doi.org/10.1142/S0218001423570173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presently, one of the foremost health issues and an extremely transferrable disease is Tuberculosis which is spreading worldwide. Tuberculosis is generally produced by mycobacterium tuberculosis and can cause death if it is not detected at premature stages. Therefore, a precise and efficient approach is essential for the identification of tuberculosis. The physical analysis of sputum smears through fluorescence microscopy for the detection process and also the treatment process is a subjective and difficult task. Thus, the hybrid optimization-driven deep learning approach is designed in this paper for infection-level identification of severity prediction of tuberculosis. Here, a sputum image is considered for performing tuberculosis detection and it is acquired from a database. For executing bacilli segmentation, the Deep Contour Aware Network (DCAN) model is used. In addition, DCAN is trained by the introduced Fractional Artificial Hummingbird Algorithm (FAHA). Additionally, the LeNet scheme is applied to detect the infection level and severity detection. The LeNet is also trained using Coot-FAHA thereby; the system performance is highly increased. The devised optimization-enabled deep learning method achieved improved performance with precision, F1-score, and recall of 0.9326, 0.9386, and 0.9163, respectively.},
  archive      = {J_IJPRAI},
  author       = {P. Sathish and Preethi D and Clara Shanthi Dominic and G. Kadiravan},
  doi          = {10.1142/S0218001423570173},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2357017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Hybrid optimized deep learning-based bacilli segmentation and infection-level identification of tuberculosis using sputum images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale feature refined network for human pose
estimation. <em>IJPRAI</em>, <em>38</em>(1), 2356022. (<a
href="https://doi.org/10.1142/S0218001423560220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occlusive keypoints has been a challenge for human pose estimation, especially the mutual occlusion of human bodies. One possible solution to this problem is to utilize multi-scale features, where small scale features are capable of identifying keypoints, while large-scale features can capture the relationship between keypoints. Feature fusion among multi-scale features allows for the exchange of information between keypoints, facilitating the inference of occluded keypoints based on the identified keypoints. However, it’s found that there are invalid features in feature fusion which will interfere valid feature. In this paper, we propose multi-scale feature refined network (MSFRNet) based on HRNet and a new attention module namely multi-resolution attention module (MRAM). The proposed MRAM is designed to strengthen the effective information while suppressing redundant information. It has multiple inputs and outputs and can learn the relationships between keypoints while retaining detailed information. The proposed MSFRNet outperforms HRNet, achieving a 1.4 AP improvement on the COCO dataset with only a marginal computational increase of 0.35 GFLOPs. Additionally, it demonstrates superior performance with a 0.9 AP, 0.7 AP, and 1.8 AP improvement on the MPII, CrowdPose and OCHuman datasets, respectively. Furthermore, compared with the latest attention mechanism PSA, the MSFRNet exhibits lower computational cost while maintaining the same pose-estimation accuracy.},
  archive      = {J_IJPRAI},
  author       = {Qiaoning Yang and Xiaodong Ji and Xiuhui Yang},
  doi          = {10.1142/S0218001423560220},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2356022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-scale feature refined network for human pose estimation},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep residual network with pelican cuckoo search for traffic
sign detection. <em>IJPRAI</em>, <em>38</em>(1), 2355017. (<a
href="https://doi.org/10.1142/S0218001423550170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The timely and precise discovery of traffic signs is considered an effective part of modeling automated vehicle driving. However, the dimension of traffic signs accounted for a lower ratio of input pictures which elevated the complexity of discovery. Hence, a new model is devised using faster region-based convolution neural network (faster R-CNN) traffic for detecting traffic signs. The Region of Interest (RoI) extraction and Median filter are executed for discarding the superfluous data from the dataset. The method extracted a Pyramid Histogram of Oriented Gradient (PHoG), local vector pattern (LVP), CNN and ResNet features for generating beneficial information. It is used to lessen the loss of contextual data and the data augmentation is further applied for making the training of the model more stable and time-saving. The traffic sign recognition is executed with faster R-CNN wherein the tuning of hyperparameters such as batch normalization rate, epoch and learning rate is determined by the proposed pelican cuckoo search (PCS). The method revealed improved efficacy without presenting additional computational costs in the model. Moreover, the faster R-CNN is termed the finest technique to enhance the discovery of traffic signs. The proposed PCS-based faster R-CNN outperformed with the highest precision 92.7%, specificity of 93.7% and F -measure of 93.2%.},
  archive      = {J_IJPRAI},
  author       = {T. Kumaravel and P. Natesan},
  doi          = {10.1142/S0218001423550170},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2355017},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Deep residual network with pelican cuckoo search for traffic sign detection},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transformer with a parallel decoder for image captioning.
<em>IJPRAI</em>, <em>38</em>(1), 2354029. (<a
href="https://doi.org/10.1142/S0218001423540290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a parallel decoder and a word group prediction module are proposed to speed up decoding and improve the effect of captions. The features of the image extracted by the encoder are linearly projected to different word groups, and then a unique relaxed mask matrix is designed to improve the decoding speed and the caption effect. First, since image captioning is composed of many words, sentences can also be broken down into word groups or words according to their syntactic structure, and we achieve this function through constituency parsing. Second, we make full use of the extracted features to predict the size of word groups. Then, a new embedding representing the information of the word is proposed based on word embedding. Finally, with the help of word groups, we design a mask matrix to modify the decoding process so that each step of the model can produce one or more words in parallel. Experiments on public datasets demonstrate that our method can reduce the time complexity while maintaining competitive performance.},
  archive      = {J_IJPRAI},
  author       = {Peilang Wei and Xu Liu and Jun Luo and Huayan Pu and Xiaoxu Huang and Shilong Wang and Huajun Cao and Shouhong Yang and Xu Zhuang and Jason Wang and Hong Yue and Cheng Ji and Mingliang Zhou},
  doi          = {10.1142/S0218001423540290},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2354029},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Transformer with a parallel decoder for image captioning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An end-to-end video coding method via adaptive vision
transformer. <em>IJPRAI</em>, <em>38</em>(1), 2354023. (<a
href="https://doi.org/10.1142/S021800142354023X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based video coding methods have demonstrated superior performance compared to classical video coding standards in recent years. The vast majority of the existing deep video coding (DVC) networks are based on convolutional neural networks (CNNs), and their main drawback is that since CNNs are affected by the size of the receptive field, they cannot effectively handle long-range dependencies and local detail recovery. Therefore, how to better capture and process the overall structure as well as local texture information in the video coding task is the core issue. Notably, the transformer employs a self-attention mechanism that captures dependencies between any two positions in the input sequence without being constrained by distance limitations. This is an effective solution to the problem described above. In this paper, we propose end-to-end transformer-based adaptive video coding (TAVC). First, we compress the motion vector and residuals through a compression network built on the vision transformer (ViT) and design the motion compensation network based on ViT. Second, based on the requirement of video coding to adapt to different resolution inputs, we introduce a position encoding generator (PEG) as adaptive position encoding (APE) to maintain its translation invariance across different resolution video coding tasks. The experiment shows that for multiscale structural similarity index measurement (MS-SSIM) metrics, this method exhibits significant performance gaps compared to conventional engineering codecs, such as × 2 6 4 , × 2 6 5 , and VTM-15.2. We also achieved a good performance improvement compared to the CNN-based DVC methods. In the case of peak signal-to-noise ratio (PSNR) evaluation metrics, TAVC also achieves good performance.},
  archive      = {J_IJPRAI},
  author       = {Haoyan Yang and Mingliang Zhou and Zhaowei Shang and Huayan Pu and Jun Luo and Xiaoxu Huang and Shilong Wang and Huajun Cao and Xuekai Wei and Weizhi Xian},
  doi          = {10.1142/S021800142354023X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2354023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An end-to-end video coding method via adaptive vision transformer},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LCSTR: Scene text recognition with large convolutional
kernels. <em>IJPRAI</em>, <em>38</em>(1), 2353004. (<a
href="https://doi.org/10.1142/S021800142353004X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of scene text recognition involves processing information from two modalities: images and text, thereby requiring models to have the ability to extract features from images and model sequences simultaneously. Although linguistic knowledge greatly aids scene text recognition tasks, the extensive use of language models in sequence modeling and model prediction stages in recent years has made model architectures increasingly complex and inefficient. In this paper, we propose LCSTR, a pure convolutional visual model that can complete text recognition without the need for attention mechanisms or language models. This approach applies large kernels to text recognition tasks for the first time, extracting word-level text information through large text-aware blocks, capturing long-range dependencies between characters, and using small text-aware blocks to obtain local features within characters. Experiments show that this model strikes a good trade-off between accuracy and speed, achieving notable results on seven public benchmarks, validating the generalizability and effectiveness of this method. Furthermore, owing to the absence of a language module, this model demonstrates remarkable accuracy even in limited sample scenarios, and the lightweight and low computational overhead features make it suitable for engineering applications.},
  archive      = {J_IJPRAI},
  author       = {Jiale Wang and Lina Yang and Jing Wang and Haoyan Yang and Lin Bai and Patrick Shen-Pei Wang and Xichun Li and Huiwu Luo and Huafu Xu},
  doi          = {10.1142/S021800142353004X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2353004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {LCSTR: Scene text recognition with large convolutional kernels},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial decomposition and aggregation for attention in
convolutional neural networks. <em>IJPRAI</em>, <em>38</em>(1), 2352019.
(<a href="https://doi.org/10.1142/S0218001423520195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Channel attention has been shown to improve the performance of deep convolutional neural networks efficiently. Channel attention adaptively recalibrates the importance of each channel, determining what to attend to. However, channel attention only encodes inter-channel information but neglects the importance of positional information. Positional information is crucial in determining where to attend to. To address this issue, we propose a novel channel-spatial attention method named Spatial-Decomposition-Aggregation Attention (SDAA) method. First, a high-axis spatial direction is decomposed into multiple low-axis spatial directions. Then, a shared transformation sub-unit establishes attention in each low-axis space direction. Next, all the low-axis attention masks are aggregated into a high-axis attention mask. Finally, the generated high-axis attention mask is fused into the input features, thus enhancing the input features. Essentially, our method is a divide-and-conquer process. Experimental results demonstrate that our SDAA method outperforms the existing channel-spatial attention methods.},
  archive      = {J_IJPRAI},
  author       = {Meng Zhu and Weidong Min and Hongyue Xiang and Cheng Zha and Zheng Huang and Longfei Li and Qiyan Fu},
  doi          = {10.1142/S0218001423520195},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2352019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Spatial decomposition and aggregation for attention in convolutional neural networks},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Saliency and depth-aware full reference 360-degree image
quality assessment. <em>IJPRAI</em>, <em>38</em>(1), 2351022. (<a
href="https://doi.org/10.1142/S0218001423510229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of virtual reality and 360-degree video, there is a pressing need for objective metrics to assess quality in this immersive panoramic format reliably. However, existing image quality assessment models developed for traditional fixed-viewpoint content do not fully consider the specific perceptual issues involved in 360-degree viewing. This paper proposes a 360-degree image full-reference quality assessment (FR-IQA) methodology based on a multi-channel architecture. The proposed 360-degree FR-IQA method further optimizes and identifies the distorted image quality using two easily obtained useful saliency and depth-aware image features. The convolutional neural network (CNN) is designed for training. Furthermore, the proposed method accounts for predicting user viewing behaviors within 360-degree images, which will further benefit the multi-channel CNN architecture and enable the weighted average pooling of the predicted FR-IQA scores. The performance is evaluated on publicly available databases to demonstrate the advantages brought by the proposed multi-channel model in performance evaluation and cross-database evaluation experiments, where it outperforms other state-of-the-art ones. Moreover, an ablation study exhibits good generalization ability and robustness.},
  archive      = {J_IJPRAI},
  author       = {Xuekai Wei and Qunyue Huang and Bin Fang and Lei Ouyang and Weizhi Xian and Jun Luo and Huayan Pu and Xueyong Xu and Chang Lu and Hao Nan and Xu Liu and Yachao Li and Mingliang Zhou},
  doi          = {10.1142/S0218001423510229},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2351022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Saliency and depth-aware full reference 360-degree image quality assessment},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A locally weighted linear regression-based approach for
arbitrary moving shaky and nonshaky video classification.
<em>IJPRAI</em>, <em>38</em>(1), 2351019. (<a
href="https://doi.org/10.1142/S0218001423510199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification and identification of objects are complex and challenging in pattern recognition and artificial intelligence if a shaky and nonshaky camera captures the videos at different distances during the day and nighttime. This work presents a model for classifying a given video as a static, uniform, or arbitrarily moving videos so that the complexity of the problem can be reduced. To avoid the threat of different distances between the objects and the camera, the proposed work introduces new steps for estimating the depth of the objects in the video frames. We explore locally weighted linear regression for feature extraction from depth information based on the notion that the regression line fits almost all the points for uniformity and does not fit for arbitrary moving. The extracted features are fed to a random forest classifier to classify static, uniform, or arbitrary moving video. The results on a large dataset, which includes videos captured day and night, show that the proposed method successfully classifies static, uniform and arbitrary videos with 0.86, 1.00 and 0.67 F-measures, respectively. Overall, our method obtains 87% accuracy for classification of static, uniform and arbitrary video, which is superior to the state-of-the-art methods.},
  archive      = {J_IJPRAI},
  author       = {Arnab Halder and Palaiahnakote Shivakumara and Umapada Pal and Michael Blumenstein and Palash Ghosal},
  doi          = {10.1142/S0218001423510199},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2351019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A locally weighted linear regression-based approach for arbitrary moving shaky and nonshaky video classification},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural network-based algorithm for identification of
recaptured images. <em>IJPRAI</em>, <em>38</em>(1), 2350036. (<a
href="https://doi.org/10.1142/S0218001423500362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the improvement of digital image display technology, the “secondary imaging” caused by digital cameras is also gradually popularized, and the quality of the recaptured image formed by this imaging is also getting higher and higher, and this kind of high-quality fake image has caused great threat to digital images security. We propose a neural network-based recaptured image identification algorithm and use the difference between two types of images to build the identification algorithm in the frequency domain. The algorithm uses filtering to obtain the feature images which are the high-frequency and low-frequency filtering images, in order to further distinguish the image differences, the direction of the filtered image obtained from high-frequency images, each direction of the filtered image contains high-frequency information at different angles, and the low-frequency image is downsampled. At the same time, the low-frequency image is downsampled to obtain a multi-scale filtered image. The algorithm extracts the features from previous images as the feature values for classification, and finally uses neural networks for classification to obtain the classification results, and these prove that the algorithm presented is able to differentiate the recaptured images effectively in this paper.},
  archive      = {J_IJPRAI},
  author       = {Changming Liu and Yanjun Sun and Lin Deng and Yan Sun},
  doi          = {10.1142/S0218001423500362},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2350036},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Neural network-based algorithm for identification of recaptured images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). All-day object detection and recognition for blind zones of
vehicles using deep learning. <em>IJPRAI</em>, <em>38</em>(1), 2350035.
(<a href="https://doi.org/10.1142/S0218001423500350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neglect of perception ability to the surrounding traffic conditions has always been the major cause of traffic accidents and the inattention to blind spots is the most important factor during driving. Existing solutions are facing the problems of using expensive equipment, wrong classification of the target object type, not suitable for nighttime, and incorrectly determining if the target object is in the blind zones. This paper aims to improve driving perception ability by developing an all-day object detection and recognition system with more accurate performance for blind zones. The proposed method uses a general-purpose camera as a single input and a two-stage deep network architecture for object detection and recognition. The proposed system is based on a two-stage cascaded network structure. At first, the style conversion process is performed to convert the daytime and nighttime images with different brightness into consistent brightness. Then the objects in the visual blind zones are detected and identified. Therefore, the accuracy of object detection can be significantly improved. Due to the diversity and complexity of Taiwan’s road conditions, the public databases cannot effectively fulfill local application model training needs. Therefore, we have built training data set from available night images. Experimental results show that the proposed method has demonstrated promising performance in all-day object detection and recognition for blind zones.},
  archive      = {J_IJPRAI},
  author       = {Tsorng-Lin Chia and Pei-June Liu and Ping-Sheng Huang},
  doi          = {10.1142/S0218001423500350},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2350035},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {All-day object detection and recognition for blind zones of vehicles using deep learning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boosting multi-label classification performance through
meta-model. <em>IJPRAI</em>, <em>38</em>(1), 2350033. (<a
href="https://doi.org/10.1142/S0218001423500337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification problem, where each instance can be associated with multiple labels, has received considerable attention from machine learning community. To address the inherent challenges of multi-label classification including data imbalance, label dependence, and high dimensionality, ensemble approaches have been developed, gaining popularity across various real-world applications. This paper proposes a novel ensemble method called ConfBoost that addresses these challenges and enhances the generalization ability of learning systems. ConfBoost which is a meta-model based on a weighted stacking paradigm using local confidence, combines heterogeneous and complementary ensembles of multi-label classifiers. The proposed approach achieves two main objectives: Firstly, by focusing on label weights based on their confidence scores, the model can generate more relevant predictions and enhance the accuracy at the base-level by mitigating the impact of irrelevant labels during the stacking process. Moreover, assigning higher weights to certain labels exhibits better discrimination and adaptability to capture complex label relationships. Second, applying adjusted thresholds enables the model to generate predictions adapted to the specific characteristics of each label, effectively addressing imbalanced label distributions. Extensive experiments on publicly available datasets demonstrate that ConfBoost outperforms conventional combination methods and consistently surpasses related state-of-the-art methods. These findings highlight the effectiveness and potential of ConfBoost as an advanced ensemble method for multi-label classification tasks.},
  archive      = {J_IJPRAI},
  author       = {Sonia Guehria and Habiba Belleili and Nabiha Azizi and Djamel Zenakhra},
  doi          = {10.1142/S0218001423500337},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2350033},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Boosting multi-label classification performance through meta-model},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A gaze estimation method based on binocular cameras.
<em>IJPRAI</em>, <em>38</em>(1), 2335001. (<a
href="https://doi.org/10.1142/S0218001423350013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-stream gaze estimation methods have become mainstream, which estimate gaze point by eye picture or combine with facial appearance, have achieved considerable accuracy. However, these methods based on a single camera fail to obtain accurate eye spatial position information. To address this issue, we propose a multi-stream gaze estimation model that incorporates spatial position information. We acquire eye spatial position information using a stereo camera and fuse eye image features with eye spatial position information using a ResNet network with a fused attention mechanism. Additionally, we perform calibration of eye image features using the computed eye spatial position information. Our model demonstrates superior performance on our experimental dataset.},
  archive      = {J_IJPRAI},
  author       = {Zihan Wu and Changyuan Wang and Gang Sun and Zhen Fu},
  doi          = {10.1142/S0218001423350013},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2335001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A gaze estimation method based on binocular cameras},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
