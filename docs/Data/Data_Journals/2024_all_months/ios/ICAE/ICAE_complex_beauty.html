<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ICAE_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="icae---24">ICAE - 24</h2>
<ul>
<li><details>
<summary>
(2024). Combining deep learning methods and rule-based systems for
automatic parking space detection. <em>ICAE</em>, <em>32</em>(1),
95–106. (<a href="https://doi.org/10.3233/ICA-240745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an Automatic Parking Space Detection (APSD) algorithm designed to reduce traffic in cities while offering an information system of available parking zones. The main aim of such a system lies in its ability to identify parking spaces in a distributed manner, achieved by installin g multiple APSD systems across a fleet of vehicles. This fleet, during its regular operations, communicates the availability of parking spaces to a centralized information system. Our methodology employs a rule-based system that seamlessly integrates a variety of neural networks for different specific tasks. These tasks include depth estimation, road segmentation, and vehicle detection. This approach would fall into a modular category instead of an end-to-end solution, using the Málaga Urban Dataset in the experiments. We present a preliminary experiment for parameter settings and an ablation study to quantify each subsystem contribution to the results. The proposed system achieves a parking space detection F1 score of 0.726.},
  archive      = {J_ICAE},
  author       = {De Luelmo, Susana P. and Garcia-Espinosa, Francisco J. and Montemayor, Antonio S. and José Pantrigo, Juan},
  doi          = {10.3233/ICA-240745},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {10},
  number       = {1},
  pages        = {95-106},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Combining deep learning methods and rule-based systems for automatic parking space detection},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A parametric and feature-based CAD dataset to support
human-computer interaction for advanced 3D shape learning.
<em>ICAE</em>, <em>32</em>(1), 73–94. (<a
href="https://doi.org/10.3233/ICA-240744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D shape learning is an important research topic in computer vision, in which the datasets play a critical role. However, most of the existing 3D datasets use voxels, point clouds, mesh, and B-rep, which are not parametric and feature-based. Thus they can not support the generation of real-world en gineering computer-aided design (CAD) models with complicated shape features. Furthermore, they are based on 3D geometry results without human-computer interaction (HCI) history. This work is the first to provide a full parametric and feature-based CAD dataset with a selection mechanism to support HCI in 3D learning. First, unlike existing datasets, mainly composed of simple features (typical sketch and extrude), we devise complicated engineering features, such as fillet, chamfer, mirror, pocket, groove, and revolve. Second, different from the monotonous combination of features, we invent a select mechanism to mimic how human focuses on and selects a particular topological entity. The proposed mechanism establishes the relationships among complicated engineering features, which fully express the design intention and design knowledge of human CAD engineers. Therefore, it can process advanced 3D features for real-world engineering shapes. The experiments show that the proposed dataset outperforms existing CAD datasets in both reconstruction and generation tasks. In quantitative experiment, the proposed dataset demonstrates better prediction accuracy than other parametric datasets. Furthermore, CAD models generated from the proposed dataset comply with semantics of the human CAD engineers and can be edited and redesigned via mainstream industrial CAD software.},
  archive      = {J_ICAE},
  author       = {Fan, Rubin and He, Fazhi and Liu, Yuxin and Song, Yupeng and Fan, Linkun and Yan, Xiaohu},
  doi          = {10.3233/ICA-240744},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {10},
  number       = {1},
  pages        = {73-94},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A parametric and feature-based CAD dataset to support human-computer interaction for advanced 3D shape learning},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A high-level simulator for network-on-chip. <em>ICAE</em>,
<em>32</em>(1), 55–71. (<a
href="https://doi.org/10.3233/ICA-240743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a high-level simulator for Network-on-Chip (NoC), designed for many-core architectures, and integrated with the PlatEMO platform. The motivation for developing this tool arose from the need to evaluate the behavior of application mapping algorithms and the routing, both aspects are essential in the implementation and design of NoC architectures. This analysis underscored the importance of having effective NoC simulators as tools that allow for studying and comparing various network technologies while ensuring a controlled simulation environment. During this investigation and evaluation, some simulators, such as Noxim, NoCTweak, and NoCmap, among others, offered configurable parameters for application traffic, options to synthetically define topology and packet traffic patterns. Additionally, they include mapping options that optimize latency and energy consumption, routing algorithms, technological settings such as the CMOS process, and measurement options for evaluating performance metrics such as throughput and power usage. However, while these simulators meet detailed technical demands, they are mostly restricted to analyzing the low-level elements of the architecture, thus hindering quick and easy under- standing for non-specialists. This insight underscored the challenge in developing a tool that balances detailed analysis with a comprehensive learning perspective, considering the specific restrictions of each simulator analyzed. Experiments demonstrated the proposed simulator efficacy in handling algorithms like GA, PSO, and SA variant, and, surprisingly, revealed limitations of the XY algorithm in Mesh topologies, indicating the need for further investigation to confirm these findings. Future work will expand the simulator functionalities, incorporating a broader range of algorithms and performance metrics, to establish it as an indispensable tool for research and development in NoCs.},
  archive      = {J_ICAE},
  author       = {Paris, Paulo Cesar Donizeti and Pedrino, Emerson Carlos},
  doi          = {10.3233/ICA-240743},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {10},
  number       = {1},
  pages        = {55-71},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A high-level simulator for network-on-chip},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A weakly supervised active learning framework for
non-intrusive load monitoring. <em>ICAE</em>, <em>32</em>(1), 37–54. (<a
href="https://doi.org/10.3233/ICA-240738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy efficiency is at a critical point now with rising energy prices and decarbonisation of the residential sector to meet the global NetZero agenda. Non-Intrusive Load Monitoring is a software-based technique to monitor individual appliances inside a building from a single aggregate meter readin g and recent approaches are based on supervised deep learning. Such approaches are affected by practical constraints related to labelled data collection, particularly when a pre-trained model is deployed in an unknown target environment and needs to be adapted to the new data domain. In this case, transfer learning is usually adopted and the end-user is directly involved in the labelling process. Unlike previous literature, we propose a combined weakly supervised and active learning approach to reduce the quantity of data to be labelled and the end user effort in providing the labels. We demonstrate the efficacy of our method comparing it to a transfer learning approach based on weak supervision. Our method reduces the quantity of weakly annotated data required by up to 82.6–98.5% in four target domains while improving the appliance classification performance.},
  archive      = {J_ICAE},
  author       = {Tanoni, Giulia and Sobot, Tamara and Principi, Emanuele and Stankovic, Vladimir and Stankovic, Lina and Squartini, Stefano},
  doi          = {10.3233/ICA-240738},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {10},
  number       = {1},
  pages        = {37-54},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A weakly supervised active learning framework for non-intrusive load monitoring},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-label classification with imbalanced classes by fuzzy
deep neural networks. <em>ICAE</em>, <em>32</em>(1), 23–36. (<a
href="https://doi.org/10.3233/ICA-240736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification is an advantageous technique for managing uncertainty in classification problems where each data instance is associated with several labels simultaneously. Such situations are frequent in real-world scenarios, where decisions rely on imprecise or noisy data and adaptable classification methods are preferred. However, the problem of class imbalance represents a common characteristic of several multi-label datasets, in which the distribution of samples and their corresponding labels is non-uniform across the data space. In this paper, we propose a multi-label classification approach utilizing fuzzy logic in order to deal with the class imbalance problem. To eliminate the need for an expert to determine the logical rules of inference, deep neural networks are adopted, which have proven to be exceptionally effective for such problems. By combining both fuzzy inference systems and deep neural networks, the strengths and weaknesses of each approach can be mitigated. As a further development, a symbolic representation of time series is put in place to reduce data dimensionality and speed up the training procedure. This allows for more flexibility in model application, in particular with respect to time constraints arising from the causality of observed time series. Tests carried out on a multi-label classification dataset related to the current and voltage profiles of several household appliances show that the proposed model outperforms four baseline models for time series classification.},
  archive      = {J_ICAE},
  author       = {Succetti, Federico and Rosato, Antonello and Panella, Massimo},
  doi          = {10.3233/ICA-240736},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {10},
  number       = {1},
  pages        = {23-36},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Multi-label classification with imbalanced classes by fuzzy deep neural networks},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient surface defect detection in industrial screen
printing with minimized labeling effort. <em>ICAE</em>, <em>32</em>(1),
1–21. (<a href="https://doi.org/10.3233/ICA-240742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As part of the evolving Industry 4.0 landscape, machine learning-based visual inspection plays a key role in enhancing production efficiency. Screen printing, a versatile and cost-effective manufacturing technique, is widely applied in industries like electronics, textiles, and automotive. However, the production of complex multilayered designs is error-prone, resulting in a variety of defect appearances and classes. These defects can be characterized as small in relation to large sample areas and weakly pronounced. Sufficient defect visualization and robust defect detection methods are essential to address these challenges, especially considering the permitted design variability. In this work, we present a novel automatic visual inspection system for surface defect detection on decorated foil plates. Customized optical modalities, integrated into a sequential inspection procedure, enable defect visualization of production-related defect classes. The introduced patch-wise defect detection methods, designed to leverage less labeled data, prove effective for industrial defect detection, meeting the given process requirements. In this context, we propose an industry-applicable and scalable data preprocessing workflow that minimizes the overall labeling effort while maintaining high detection performance, as known in supervised settings. Moreover, the presented methods, not relying on any labeled defective training data, outperformed a state-of-the-art unsupervised anomaly detection method in terms of defect detection performance and inference speed.},
  archive      = {J_ICAE},
  author       = {Krassnig, Paul Josef and Haselmann, Matthias and Kremnitzer, Michael and Gruber, Dieter Paul},
  doi          = {10.3233/ICA-240742},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {10},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Efficient surface defect detection in industrial screen printing with minimized labeling effort},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effectiveness of deep learning techniques in TV programs
classification: A comparative analysis. <em>ICAE</em>, <em>31</em>(4),
439–453. (<a href="https://doi.org/10.3233/ICA-240740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the application areas of streaming, social networks, and video-sharing platforms such as YouTube and Facebook, along with traditional television systems, programs’ classification stands as a pivotal effort in multimedia content management. Despite recent advancements, it remains a scientific challenge for researchers. This paper proposes a novel approach for television monitoring systems and the classification of extended video content. In particular, it presents two distinct techniques for program classification. The first one leverages a framework integrating Structural Similarity Index Measurement and Convolutional Neural Network, which pipelines on stacked frames to classify program initiation, conclusion, and contents. Noteworthy, this versatile method can be seamlessly adapted across various systems. The second analyzed framework implies directly processing optical flow. Building upon a shot-boundary detection technique, it incorporates background subtraction to adaptively discern frame alterations. These alterations are subsequently categorized through the integration of a Transformers network, showcasing a potential advancement in program classification methodology. A comprehensive overview of the promising experimental results yielded by the two techniques is reported. The first technique achieved an accuracy of 95%, while the second one surpassed it with an even higher accuracy of 87% on multiclass classification. These results underscore the effectiveness and reliability of the proposed frameworks, and pave the way for a more efficient and precise content management in the ever-evolving landscape of multimedia platforms and streaming services.},
  archive      = {J_ICAE},
  author       = {Candela, Federico and Giordano, Angelo and Zagaria, Carmen Francesca and Morabito, Francesco Carlo},
  doi          = {10.3233/ICA-240740},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {7},
  number       = {4},
  pages        = {439-453},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Effectiveness of deep learning techniques in TV programs classification: A comparative analysis},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Railway alignment optimization in regions with
densely-distributed obstacles based on semantic topological maps.
<em>ICAE</em>, <em>31</em>(4), 421–437. (<a
href="https://doi.org/10.3233/ICA-240739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway alignment development in a study area with densely-distributed obstacles, in which regions favorable for alignments are isolated (termed an isolated island effect, i.e., IIE), is a computation-intensive and time-consuming task. To enhance search efficiency and solution quality, an environmental suitability analysis is conducted to identify alignment-favorable regions (AFRs), focusing the subsequent alignment search on these areas. Firstly, a density-based clustering algorithm (DBSCAN) and a specific criterion are customized to distinguish AFR distribution patterns: continuously-distributed AFRs, obstructed effects, and IIEs. Secondly, a study area characterized by IIEs is represented with a semantic topological map (STM), integrating between-island and within-island paths. Specifically, between-island paths are derived through a multi-directional scanning strategy, while within-island paths are optimized using a Floyd-Warshall algorithm. To this end, the intricate alignment optimization problem is simplified into a shortest path problem, tackled with conventional shortest path algorithms (of which Dijkstra’s algorithm is adopted in this work). Lastly, the proposed method is applied to a real case in a mountainous region with karst landforms. Numerical results indicate its superior performance in both construction costs and environmental suitability compared to human designers and a prior alignment optimization method.},
  archive      = {J_ICAE},
  author       = {Wan, Xinjie and Pu, Hao and Schonfeld, Paul and Song, Taoran and Li, Wei and Peng, Lihui},
  doi          = {10.3233/ICA-240739},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {7},
  number       = {4},
  pages        = {421-437},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Railway alignment optimization in regions with densely-distributed obstacles based on semantic topological maps},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of thrust bearing’s performance in mixed
lubrication regime. <em>ICAE</em>, <em>31</em>(4), 401–419. (<a
href="https://doi.org/10.3233/ICA-240737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hydrodynamic thrust bearing could be forced to operate in mixed lubrication regime under various circumstances. At this state, the tribological characteristics of the bearing could be affected significantly and the developed phenomena would have a severe impact on the performance of the mechanism . Until recently, researchers were modeling the hydrodynamic lubrication problem of the thrust bearings either with analytical or with numerical solutions. The analytical solutions are very simple and do not provide enough accuracy in describing the actual problem. To add to that, following only computational methodologies, can lead to time consuming and complex algorithms that need to be repeated every time the operating conditions change, in order to draw safe conclusions. Recent technological advances, especially on the field of computer science, have provided tools that enhance and accelerate the modeling of thrust bearings’ operation. The aim of this study is to examine the application of Artificial Neural Networks as Machine Learning models, that are trained to predict the coefficient of friction for lubricated pad thrust bearings in mixed lubrication regime. The hydrodynamic analysis of the thrust bearing is performed by solving the Average 2-D Reynolds equation numerically. In order to describe the roughness of the profiles, both the flow factors suggested by N. Patir and H.S. Cheng (1978) and the model of J.A. Greenwood and J. H. Tripp (1970) are taken into consideration. Three lubricants, the SAE 0W30, the SAE 10W40 and the SAE 10W60, are tested and compared for a variety of operating velocities and applied coatings. The numerical analysis results are used as training datasets for the machine learning algorithms. Four different ML methods are applied in this investigation: Artificial Neural Networks (ANNs), Multi- Variable Quadratic Polynomial Regression, Quadratic SVM and Regression Trees. The coefficient of determination, R2 is calculated and used to determine the most accurate ML method for the current study. The results showed that ANNs provide very good accuracy in the prediction of friction coefficient compared to the rest of the ML models discussed.},
  archive      = {J_ICAE},
  author       = {Katsaros, Konstantinos P. and Nikolakopoulos, Pantelis G.},
  doi          = {10.3233/ICA-240737},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {7},
  number       = {4},
  pages        = {401-419},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Prediction of thrust bearing’s performance in mixed lubrication regime},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An advanced multimodal driver-assistance prototype for
emergency-vehicle detection. <em>ICAE</em>, <em>31</em>(4), 381–399. (<a
href="https://doi.org/10.3233/ICA-240733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the automotive industry, intelligent monitoring systems for advanced human-vehicle interaction aimed at enhancing the safety of drivers and passengers represent a rapidly growing area of research. Safe driving behavior relies on the driver’s awareness of the road context, enabling them to make a ppropriate decisions and act consistently in anomalous circumstances. A potentially dangerous situation can arise when an emergency vehicle rapidly approaches with sirens blaring. In such cases, it is crucial for the driver to perform the correct maneuvers to prioritize the emergency vehicle. For this purpose, an Advanced Driver Assistance System (ADAS) can provide timely alerts to the driver about an approaching emergency vehicle. In this work, we present a driver-assistance prototype that leverages multimodal information from an integrated audio and video monitoring system. In the initial stage, sound analysis technologies based on computational audio processing are employed to recognize the proximity of an emergency vehicle based on the sound of its siren. When such an event occurs, an in-vehicle monitoring system is activated, analyzing the driver’s facial patterns using deep-learning-based algorithms to assess their awareness. This work illustrates the design of such a prototype, presenting the hardware technologies, the software architecture, and the deep-learning algorithms for audio and video data analysis that make the driver-assistance prototype operational in a commercial car. At this initial experimental stage, the algorithms for analyzing the audio and video data have yielded promising results. The area under the precision-recall curve for siren identification stands at 0.92, while the accuracy in evaluating driver gaze orientation reaches 0.97. In conclusion, engaging in research within this field has the potential to significantly improve road safety by increasing driver awareness and facilitating timely and well-informed reactions to crucial situations. This could substantially reduce risks and ultimately protect lives on the road.},
  archive      = {J_ICAE},
  author       = {Gabrielli, Leonardo and Migliorelli, Lucia and Cantarini, Michela and Mancini, Adriano and Squartini, Stefano},
  doi          = {10.3233/ICA-240733},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {7},
  number       = {4},
  pages        = {381-399},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {An advanced multimodal driver-assistance prototype for emergency-vehicle detection},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intuitionistic fuzzy divergence for evaluating the
mechanical stress state of steel plates subject to bi-axial loads.
<em>ICAE</em>, <em>31</em>(4), 363–379. (<a
href="https://doi.org/10.3233/ICA-230730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertainty that characterizes the external mechanical loads to which any connection plate in steel structures is subjected determines the non-uniqueness of the isochoric deformation distributions. Since the eddy currents induced on the plates produce magnetic field maps with a high fuzziness c ontent, similar to those of the isochoric deformations, their use can be exploited to evaluate the extent of the external load that determines a specific induced current map. Starting from an approach known in the literature, according to which the map-external load association is operated through fuzzy similarity computations, in this paper, we generalize this method by reformulating it in terms of intuitionistic fuzzy logic by proposing a classification based on divergence computations. Our approach, acting adaptively on the fuzzification of the maps, results in a better classification percentage, besides significantly reducing the presence of doubtful cases due to the uncertainty of each applied load. Furthermore, a FEM software tool was developed, which turned out to be, to a certain extent, a substitute for the experimental procedure, notoriously more expensive. Even if the procedure was applied on plates subjected to bi-axial loads, it could be used for other types of loads since the classification operator processes the eddy current maps exclusively, regardless of their cause.},
  archive      = {J_ICAE},
  author       = {Versaci, Mario and Angiulli, Giovanni and La Foresta, Fabio and Laganà, Filippo and Palumbo, Annunziata},
  doi          = {10.3233/ICA-230730},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {7},
  number       = {4},
  pages        = {363-379},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Intuitionistic fuzzy divergence for evaluating the mechanical stress state of steel plates subject to bi-axial loads},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Battery parameter identification for unmanned aerial
vehicles with hybrid power system. <em>ICAE</em>, <em>31</em>(4),
341–362. (<a href="https://doi.org/10.3233/ICA-240741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) nowadays are getting soaring importance in many aspects like agricultural and military fields. A hybrid power system is a promising solution toward high energy density and power density demands for UAVs as it integrates power sources like internal combustion engine ( ICE), fuel cell (FC) and lowcapacity lithium-polymer (LIPO) batteries. For robust energy management, accurate state-of-charge (SOC) estimation is indispensable, which necessitates open circuit voltage (OCV) determination and parameter identification of battery. The presented research demonstrates the feasibility of carrying out incremental OCV test and even dynamic stress test (DST) by making use of the hybrid powered UAV system itself. Based on battery relaxation terminal voltage as well as current wave excitation, novel methods for OCV determination and parameter identification are proposed. Results of SOC estimation against DST through adaptive unscented Kalman filter (AUKF) algorithm show that parameters and OCV identified with longer relaxation time don’t yield better SOC estimation accuracy. Besides, it also discloses that OCV played the vital role in affecting SOC estimation accuracy. A detailed analysis is presented showing that mean discharging rate and current wave amplitude are the major factors which affect the quality of OCV identified related to SOC estimation accuracy.},
  archive      = {J_ICAE},
  author       = {He, Zhuoyao and Gómez, David Martín and Peña, Pablo Flores and Hueso, Arturo de la Escalera and Lu, Xingcai and Moreno, José María Armingol},
  doi          = {10.3233/ICA-240741},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {7},
  number       = {4},
  pages        = {341-362},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Battery parameter identification for unmanned aerial vehicles with hybrid power system},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing peak prediction in residential load forecasting
with soft dynamic time wrapping loss functions. <em>ICAE</em>,
<em>31</em>(3), 327–340. (<a
href="https://doi.org/10.3233/ICA-230731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term residential load forecasting plays a crucial role in smart grids, ensuring an optimal match between energy demands and generation. With the inherent volatility of residential load patterns, deep learning has gained attention due to its ability to capture complex nonlinear relationships w ithin hidden layers. However, most existing studies have relied on default loss functions such as mean squared error (MSE) or mean absolute error (MAE) for neural networks. These loss functions, while effective in overall prediction accuracy, lack specialized focus on accurately predicting load peaks. This article presents a comparative analysis of soft-DTW loss function, a smoothed formulation of Dynamic Time Wrapping (DTW), compared to other commonly used loss functions, in order to assess its effectiveness in improving peak prediction accuracy. To evaluate peak performance, we introduce a novel evaluation methodology using confusion matrix and propose new errors for peak position and peak load, tailored specifically for assessing peak performance in short-term load forecasting. Our results demonstrate the superiority of soft-DTW in capturing and predicting load peaks, surpassing other commonly used loss functions. Furthermore, the combination of soft-DTW with other loss functions, such as soft-DTW + MSE, soft-DTW + MAE, and soft-DTW + TDI (Time Distortion Index), also enhances peak prediction. However, the differences between these combined soft-DTW loss functions are not substantial. These findings highlight the significance of utilizing specialized loss functions, like soft-DTW, to improve peak prediction accuracy in short-term load forecasting.},
  archive      = {J_ICAE},
  author       = {Chen, Yuyao and Obrecht, Christian and Kuznik, Frédéric},
  doi          = {10.3233/ICA-230731},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {4},
  number       = {3},
  pages        = {327-340},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Enhancing peak prediction in residential load forecasting with soft dynamic time wrapping loss functions},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing smart home appliance recognition with wavelet and
scalogram analysis using data augmentation. <em>ICAE</em>,
<em>31</em>(3), 307–326. (<a
href="https://doi.org/10.3233/ICA-230726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of smart homes, equipped with devices connected to the Internet of Things (IoT), has opened up new possibilities to monitor and control energy consumption. In this context, non-intrusive load monitoring (NILM) techniques have emerged as a promising solution for the disaggregation of total energy consumption into the consumption of individual appliances. The classification of electrical appliances in a smart home remains a challenging task for machine learning algorithms. In the present study, we propose comparing and evaluating the performance of two different algorithms, namely Multi-Label K-Nearest Neighbors (MLkNN) and Convolutional Neural Networks (CNN), for NILM in two different scenarios: without and with data augmentation (DAUG). Our results show how the classification results can be better interpreted by generating a scalogram image from the power consumption signal data and processing it with CNNs. The results indicate that the CNN model with the proposed data augmentation performed significantly higher, obtaining a mean F1-score of 0.484 (an improvement of + 0.234), better than the other methods. Additionally, after performing the Friedman statistical test, it indicates that it is significantly different from the other methods compared. Our proposed system can potentially reduce energy waste and promote more sustainable energy use in homes and buildings by providing personalized feedback and energy savings tips.},
  archive      = {J_ICAE},
  author       = {Salazar-González, José L. and Luna-Romera, José María and Carranza-García, Manuel and Álvarez-García, Juan A. and Soria-Morillo, Luis M.},
  doi          = {10.3233/ICA-230726},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {4},
  number       = {3},
  pages        = {307-326},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Enhancing smart home appliance recognition with wavelet and scalogram analysis using data augmentation},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural architecture search for radio map reconstruction with
partially labeled data. <em>ICAE</em>, <em>31</em>(3), 285–305. (<a
href="https://doi.org/10.3233/ICA-240732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we tackle the challenging task of reconstructing Received Signal Strength (RSS) maps by harnessing location-dependent radio measurements and augmenting them with supplementary data related to the local environment. This side information includes city plans, terrain elevations, and th e locations of gateways. The quantity of available supplementary data varies, necessitating the utilization of Neural Architecture Search (NAS) to tailor the neural network architecture to the specific characteristics of each setting. Our approach takes advantage of NAS’s adaptability, allowing it to automatically explore and pinpoint the optimal neural network architecture for each unique scenario. This adaptability ensures that the model is finely tuned to extract the most relevant features from the input data, thereby maximizing its ability to accurately reconstruct RSS maps. We demonstrate the effectiveness of our approach using three distinct datasets, each corresponding to a major city. Notably, we observe significant enhancements in areas near the gateways, where fluctuations in the mean received signal power are typically more pronounced. This underscores the importance of NAS-driven architectures in capturing subtle spatial variations. We also illustrate how NAS efficiently identifies the architecture of a Neural Network using both labeled and unlabeled data for Radio Map reconstruction. Our findings emphasize the potential of NAS as a potent tool for improving the precision and applicability of RSS map reconstruction techniques in urban environments.},
  archive      = {J_ICAE},
  author       = {Malkova, Aleksandra and Amini, Massih-Reza and Denis, Benoît and Villien, Christophe},
  doi          = {10.3233/ICA-240732},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {4},
  number       = {3},
  pages        = {285-305},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Neural architecture search for radio map reconstruction with partially labeled data},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Highly compressed image representation for classification
and content retrieval. <em>ICAE</em>, <em>31</em>(3), 267–284. (<a
href="https://doi.org/10.3233/ICA-230729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new method of representing images using highly compressed features for classification and image content retrieval – called PCA-ResFeats . They are obtained by fusing high- and low-level features from the outputs of ResNet-50 residual blocks and applying to them principal component analysis, which leads to a significant reduction in dimensionality. Further on, by applying a floating-point compression, we are able to reduce the memory required to store a single image by up to 1,200 times compared to jpg images and 220 times compared to features obtained by simple output fusion of ResNet-50. As a result, the representation of a single image from the dataset can be as low as 35 bytes on average. In comparison with the classification results on features from fusion of the last ResNet-50 residual block, we achieve a comparable accuracy (no worse than five percentage points), while preserving two orders of magnitude data compression. We also tested our method in the content-based image retrieval task, achieving better results than other known methods using sparse features. Moreover, our method enables the creation of concise summaries of image content, which can find numerous applications in databases.},
  archive      = {J_ICAE},
  author       = {Łażewski, Stanisław and Cyganek, Bogusław},
  doi          = {10.3233/ICA-230729},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {4},
  number       = {3},
  pages        = {267-284},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Highly compressed image representation for classification and content retrieval},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-agent simulation of autonomous industrial vehicle
fleets: Towards dynamic task allocation in V2X cooperation mode.
<em>ICAE</em>, <em>31</em>(3), 249–266. (<a
href="https://doi.org/10.3233/ICA-240735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smart factory leads to a strong digitalization of industrial processes and continuous communication between the systems integrated into the production, storage, and supply chains. One of the research areas in Industry 4.0 is the possibility of using autonomous and/or intelligent industrial vehi cles. The optimization of the management of the tasks allocated to these vehicles with adaptive behaviours, as well as the increase in vehicle-to-everything communications (V2X) make it possible to develop collective and adaptive intelligence for these vehicles, often grouped in fleets. Task allocation and scheduling are often managed centrally. The requirements for flexibility, robustness, and scalability lead to the consideration of decentralized mechanisms to react to unexpected situations. However, before being definitively adopted, decentralization must first be modelled and then simulated. Thus, we use a multi-agent simulation to test the proposed dynamic task (re)allocation process. A set of problematic situations for the circulation of autonomous industrial vehicles in areas such as smart warehouses (obstacles, breakdowns, etc.) has been identified. These problematic situations could disrupt or harm the successful completion of the process of dynamic (re)allocation of tasks. We have therefore defined scenarios involving them in order to demonstrate through simulation that the process remains reliable. The simulation of new problematic situations also allows us to extend the potential of this process, which we discuss at the end of the article.},
  archive      = {J_ICAE},
  author       = {Grosset, J. and Fougères, A.-J. and Djoko-Kouam, M. and Bonnin, J.-M.},
  doi          = {10.3233/ICA-240735},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {4},
  number       = {3},
  pages        = {249-266},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Multi-agent simulation of autonomous industrial vehicle fleets: Towards dynamic task allocation in V2X cooperation mode},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A spatio-temporal fusion deep learning network with
application to lightning nowcasting. <em>ICAE</em>, <em>31</em>(3),
233–247. (<a href="https://doi.org/10.3233/ICA-240734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightning is a rapidly evolving phenomenon, exhibiting both mesoscale and microscale characteristics. Its prediction significantly relies on timely and accurate data observation. With the implementation of new generation weather radar systems and lightning detection networks, radar reflectivity ima ge products, and lightning observation data are becoming increasingly abundant. Research focus has shifted towards lightning nowcasting (prediction of imminent events), utilizing deep learning (DL) methods to extract lightning features from very large data sets. In this paper, we propose a novel spatio-temporal fusion deep learning lightning nowcasting network (STF-LightNet) for lightning nowcasting. The network is based on a 3-dimensional U-Net architecture with encoder-decoder blocks and adopts a structure of multiple branches as well as the main path for the encoder block. To address the challenges of feature extraction and fusion of multi-source data, multiple branches are used to extract different data features independently, and the main path fuses these features. Additionally, a spatial attention (SA) module is added to each branch and the main path to automatically identify lightning areas and enhance their features. The main path fusion is conducted in two steps: the first step fuses features from the branches, and the second fuses features from the previous and current levels of the main path using two different methodsthe weighted summation fusion method and the attention gate fusion method. To overcome the sparsity of lightning observations, we employ an inverse frequency weighted cross-entropy loss function. Finally, STF-LightNet is trained using observations from the previous half hour to predict lightning in the next hour. The outcomes illustrate that the fusion of both the multi-branch and main path structures enhances the network’s ability to effectively integrate features from diverse data sources. Attention mechanisms and fusion modules allow the network to capture more detailed features in the images.},
  archive      = {J_ICAE},
  author       = {Zhou, Changhai and Fan, Ling and Neri, Ferrante},
  doi          = {10.3233/ICA-240734},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {4},
  number       = {3},
  pages        = {233-247},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A spatio-temporal fusion deep learning network with application to lightning nowcasting},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparative deep learning studies for indirect tunnel
monitoring with and without fourier pre-processing. <em>ICAE</em>,
<em>31</em>(2), 213–232. (<a
href="https://doi.org/10.3233/ICA-230709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decades, the majority of the existing infrastructure heritage is approaching the end of its nominal design life mainly due to aging, deterioration, and degradation phenomena, threatening the safety levels of these strategic routes of communications. For civil engineers and researchers d evoted to assessing and monitoring the structural health (SHM) of existing structures, the demand for innovative indirect non-destructive testing (NDT) methods aided with artificial intelligence (AI) is progressively spreading. In the present study, the authors analyzed the exertion of various deep learning models in order to increase the productivity of classifying ground penetrating radar (GPR) images for SHM purposes, especially focusing on road tunnel linings evaluations. Specifically, the authors presented a comparative study employing two convolutional models, i.e. the ResNet-50 and the EfficientNet-B0, and a recent transformer model, i.e. the Vision Transformer (ViT). Precisely, the authors evaluated the effects of training the models with or without pre-processed data through the bi-dimensional Fourier transform. Despite the theoretical advantages envisaged by adopting this kind of pre-processing technique on GPR images, the best classification performances have been still manifested by the classifiers trained without the Fourier pre-processing.},
  archive      = {J_ICAE},
  author       = {Rosso, Marco Martino and Aloisio, Angelo and Randazzo, Vincenzo and Tanzi, Leonardo and Cirrincione, Giansalvo and Marano, Giuseppe Carlo},
  doi          = {10.3233/ICA-230709},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {1},
  number       = {2},
  pages        = {213-232},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Comparative deep learning studies for indirect tunnel monitoring with and without fourier pre-processing},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Look inside 3D point cloud deep neural network by patch-wise
saliency map. <em>ICAE</em>, <em>31</em>(2), 197–212. (<a
href="https://doi.org/10.3233/ICA-230725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 3D point cloud deep neural network (3D DNN) has achieved remarkable success, but its black-box nature hinders its application in many safety-critical domains. The saliency map technique is a key method to look inside the black-box and determine where a 3D DNN focuses when recognizing a point cl oud. Existing point-wise point cloud saliency methods are proposed to illustrate the point-wise saliency for a given 3D DNN. However, the above critical points are alternative and unreliable. The findings are grounded on our experimental results which show that a point becomes critical because it is responsible for representing one specific local structure. However, one local structure does not have to be represented by some specific points, conversely. As a result, discussing the saliency of the local structure (named patch-wise saliency) represented by critical points is more meaningful than discussing the saliency of some specific points. Based on the above motivations, this paper designs a black-box algorithm to generate patch-wise saliency map for point clouds. Our basic idea is to design the Mask Building-Dropping process, which adaptively matches the size of important/unimportant patches by clustering points with close saliency. Experimental results on several typical 3D DNNs show that our patch-wise saliency algorithm can provide better visual guidance, and can detect where a 3D DNN is focusing more efficiently than a point-wise saliency map. Finally, we apply our patch-wise saliency map to adversarial attacks and backdoor defenses. The results show that the improvement is significant.},
  archive      = {J_ICAE},
  author       = {Fan, Linkun and He, Fazhi and Song, Yupeng and Xu, Huangxinxin and Li, Bing},
  doi          = {10.3233/ICA-230725},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {1},
  number       = {2},
  pages        = {197-212},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Look inside 3D point cloud deep neural network by patch-wise saliency map},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient and choreographed quality-of- service management
in dense 6G verticals with high-speed mobility requirements.
<em>ICAE</em>, <em>31</em>(2), 173–195. (<a
href="https://doi.org/10.3233/ICA-230722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future 6G networks are envisioned to support very heterogeneous and extreme applications (known as verticals). Some examples are further-enhanced mobile broadband communications, where bitrates could go above one terabit per second, or extremely reliable and low-latency communications, whose end-to-end delay must be below one hundred microseconds. To achieve that ultra-high Quality-of-Service, 6G networks are commonly provided with redundant resources and intelligent management mechanisms to ensure that all devices get the expected performance. But this approach is not feasible or scalable for all verticals. Specifically, in 6G scenarios, mobile devices are expected to have speeds greater than 500 kilometers per hour, and device density will exceed ten million devices per square kilometer. In those verticals, resources cannot be redundant as, because of such a huge number of devices, Quality-of-Service requirements are pushing the effective performance of technologies at physical level. And, on the other hand, high-speed mobility prevents intelligent mechanisms to be useful, as devices move around and evolve faster than the usual convergence time of those intelligent solutions. New technologies are needed to fill this unexplored gap. Therefore, in this paper we propose a choreographed Quality-of-Service management solution, where 6G base stations predict the evolution of verticals at real-time, and run a lightweight distributed optimization algorithm in advance, so they can manage the resource consumption and ensure all devices get the required Quality-of-Service. Prediction mechanism includes mobility models (Markov, Bayesian, etc.) and models for time-variant communication channels. Besides, a traffic prediction solution is also considered to explore the achieved Quality-of-Service in advance. The optimization algorithm calculates an efficient resource distribution according to the predicted future vertical situation, so devices achieve the expected Quality-of-Service according to the proposed traffic models. An experimental validation based on simulation tools is also provided. Results show that the proposed approach reduces up to 12% of the network resource consumption for a given Quality-of-Service.},
  archive      = {J_ICAE},
  author       = {Bordel, Borja and Alcarria, Ramón and Chung, Joaquin and Kettimuthu, Rajkumar},
  doi          = {10.3233/ICA-230722},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {1},
  number       = {2},
  pages        = {173-195},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Efficient and choreographed quality-of- service management in dense 6G verticals with high-speed mobility requirements},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gap imputation in related multivariate time series through
recurrent neural network-based denoising autoencoder. <em>ICAE</em>,
<em>31</em>(2), 157–172. (<a
href="https://doi.org/10.3233/ICA-230728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technological advances in industry have made it possible to install many connected sensors, generating a great amount of observations at high rate. The advent of Industry 4.0 requires analysis capabilities of heterogeneous data in form of related multivariate time series. However, missing data can degrade processing and lead to bias and misunderstandings or even wrong decision-making. In this paper, a recurrent neural network-based denoising autoencoder is proposed for gap imputation in related multivariate time series, i.e., series that exhibit spatio-temporal correlations. The denoising autoencoder (DAE) is able to reproduce input missing data by learning to remove intentionally added gaps, while the recurrent neural network (RNN) captures temporal patterns and relationships among variables. For that reason, different unidirectional (simple RNN, GRU, LSTM) and bidirectional (BiSRNN, BiGRU, BiLSTM) architectures are compared with each other and to state-of-the-art methods using three different datasets in the experiments. The implementation with BiGRU layers outperforms the others, effectively filling gaps with a low reconstruction error. The use of this approach is appropriate for complex scenarios where several variables contain long gaps. However, extreme scenarios with very short gaps in one variable or no available data should be avoided.},
  archive      = {J_ICAE},
  author       = {Alonso, Serafín and Morán, Antonio and Pérez, Daniel and Prada, Miguel A. and Fuertes, Juan J. and Domínguez, Manuel},
  doi          = {10.3233/ICA-230728},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {1},
  number       = {2},
  pages        = {157-172},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Gap imputation in related multivariate time series through recurrent neural network-based denoising autoencoder},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep deterministic policy gradient with constraints for gait
optimisation of biped robots. <em>ICAE</em>, <em>31</em>(2), 139–156.
(<a href="https://doi.org/10.3233/ICA-230724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel Reinforcement Learning (RL) algorithm for robotic motion control, that is, a constrained Deep Deterministic Policy Gradient (DDPG) deviation learning strategy to assist biped robots in walking safely and accurately. The previous research on this topic highlighted t he limitations in the controller’s ability to accurately track foot placement on discrete terrains and the lack of consideration for safety concerns. In this study, we address these challenges by focusing on ensuring the overall system’s safety. To begin with, we tackle the inverse kinematics problem by introducing constraints to the damping least squares method. This enhancement not only addresses singularity issues but also guarantees safe ranges for joint angles, thus ensuring the stability and reliability of the system. Based on this, we propose the adoption of the constrained DDPG method to correct controller deviations. In constrained DDPG, we incorporate a constraint layer into the Actor network, incorporating joint deviations as state inputs. By conducting offline training within the range of safe angles, it serves as a deviation corrector. Lastly, we validate the effectiveness of our proposed approach by conducting dynamic simulations using the CRANE biped robot. Through comprehensive assessments, including singularity analysis, constraint effectiveness evaluation, and walking experiments on discrete terrains, we demonstrate the superiority and practicality of our approach in enhancing walking performance while ensuring safety. Overall, our research contributes to the advancement of biped robot locomotion by addressing gait optimisation from multiple perspectives, including singularity handling, safety constraints, and deviation learning.},
  archive      = {J_ICAE},
  author       = {Liu, Xingyang and Rong, Haina and Neri, Ferrante and Yue, Peng and Zhang, Gexiang},
  doi          = {10.3233/ICA-230724},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {1},
  number       = {2},
  pages        = {139-156},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Deep deterministic policy gradient with constraints for gait optimisation of biped robots},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vehicle side-slip angle estimation under snowy conditions
using machine learning. <em>ICAE</em>, <em>31</em>(2), 117–137. (<a
href="https://doi.org/10.3233/ICA-230727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adverse weather conditions, such as snow-covered roads, represent a challenge for autonomous vehicle research. This is particularly challenging as it might cause misalignment between the longitudinal axis of the vehicle and the actual direction of travel. In this paper, we extend previous work in the field of autonomous vehicles on snow-covered roads and present a novel approach for side-slip angle estimation that combines perception with a hybrid artificial neural network pushing the prediction horizon beyond existing approaches. We exploited the feature extraction capabilities of convolutional neural networks and the dynamic time series relationship learning capabilities of gated recurrent units and combined them with a motion model to estimate the side-slip angle. Subsequently, we evaluated the model using the 3DCoAutoSim simulation platform, where we designed a suitable simulation environment with snowfall, friction, and car tracks in snow. The results revealed that our approach outperforms the baseline model for prediction horizons ⩾ 2 seconds. This extended prediction horizon has practical implications, by providing drivers and autonomous systems with more time to make informed decisions, thereby enhancing road safety.},
  archive      = {J_ICAE},
  author       = {Novotny, Georg and Liu, Yuzhou and Morales-Alvarez, Walter and Wöber, Wilfried and Olaverri-Monreal, Cristina},
  doi          = {10.3233/ICA-230727},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {1},
  number       = {2},
  pages        = {117-137},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Vehicle side-slip angle estimation under snowy conditions using machine learning},
  volume       = {31},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
