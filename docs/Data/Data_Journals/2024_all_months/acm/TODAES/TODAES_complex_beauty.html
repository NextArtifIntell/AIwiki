<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TODAES_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="todaes---44">TODAES - 44</h2>
<ul>
<li><details>
<summary>
(2024). Deadline and period assignment for guaranteeing timely
response of the cyber-physical system. <em>TODAES</em>, <em>30</em>(1),
1–26. (<a href="https://doi.org/10.1145/3689048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical systems (CPSs) need to respond to each change of each monitored object in time. The entire response process can be divided into two stages: the update stage and the control stage. Tasks in CPSs can thus be divided into two kinds: update tasks and control tasks. Assigning deadlines and periods for tasks to ensure a timely response to each change of each monitored object is an important problem in CPS research. Existing methods can ensure that all changes of all objects can receive timely responses if tasks are schedulable. However, these methods have not made efforts to ensure the schedulability of tasks. Therefore, some tasks that can actually receive services cannot be serviced under these methods. In this article, we study the problem of assigning deadlines and periods for tasks while ensuring timely responses and maximizing the schedulability of tasks. Specifically, we find that the delayed deadline assignment for update tasks is the main factor that causes the low scheduling capability of existing methods. A new deadline and period assignment method is proposed based on an optimized deadline calculation scheme and an advanced deadline determination mechanism. Theoretical analysis proves the correctness and superiority of the proposed method. Experimental results show that the new method can improve 30.02% acceptance ratio and save 98.48% runtime on average, as compared to the state-of-the-art deadline and period assignment method.},
  archive      = {J_TODAES},
  doi          = {10.1145/3689048},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {11},
  number       = {1},
  pages        = {1-26},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Deadline and period assignment for guaranteeing timely response of the cyber-physical system},
  volume       = {30},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Performance analysis of CNN inference/training with
convolution and non-convolution operations on ASIC accelerators.
<em>TODAES</em>, <em>30</em>(1), 1–34. (<a
href="https://doi.org/10.1145/3696665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s performance analysis frameworks for deep learning accelerators suffer from two significant limitations. First, although modern convolutional neural networks (CNNs) consist of many types of layers other than convolution, especially during training, these frameworks largely focus on convolution layers only. Second, these frameworks are generally targeted towards inference and lack support for training operations. This work proposes a novel open-source performance analysis framework, SimDIT, for general ASIC-based systolic hardware accelerator platforms. The modeling effort of SimDIT comprehensively covers convolution and non-convolution operations of both CNN inference and training on a highly parameterizable hardware substrate. SimDIT is integrated with a backend silicon implementation flow and provides detailed end-to-end performance statistics (i.e., data access cost, cycle counts, energy, and power) for executing CNN inference and training workloads. SimDIT-enabled performance analysis reveals that on a 64×64 processing array, non-convolution operations constitute 59.5% of total runtime for ResNet-50 training workload. In addition, by optimally distributing available off-chip DRAM bandwidth and on-chip SRAM resources, SimDIT achieves 18× performance improvement over a generic static resource allocation for ResNet-50 inference.},
  archive      = {J_TODAES},
  doi          = {10.1145/3696665},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {11},
  number       = {1},
  pages        = {1-34},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Performance analysis of CNN Inference/Training with convolution and non-convolution operations on ASIC accelerators},
  volume       = {30},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sensor-aware data imputation for time-series machine
learning on low-power wearable devices. <em>TODAES</em>, <em>30</em>(1),
1–27. (<a href="https://doi.org/10.1145/3698195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable devices that have low-power sensors, processors, and communication capabilities are gaining wide adoption in several health applications. The machine learning algorithms on these devices assume that data from all sensors are available during runtime. However, data from one or more sensors may be unavailable due to energy or communication challenges. This loss of sensor data can result in accuracy degradation of the application. Prior approaches to handle missing data, such as generative models or training multiple classifiers for each combination of missing sensors are not suitable for low-energy wearable devices due to their high overhead at runtime. In contrast to prior approaches, we present an energy-efficient approach, referred to as Sensor-Aware iMputation (SAM), to accurately impute missing data at runtime and recover application accuracy. SAM first uses unsupervised clustering to obtain clusters of similar sensor data patterns. Next, it learns inter-relationship between clusters to obtain imputation patterns for each combination of clusters using a principled sensor-aware search algorithm. Using sensor data for clustering before choosing imputation patterns ensures that the imputation is aware of sensor data observations. Experiments on seven diverse wearable sensor-based time-series datasets demonstrate that SAM is able to maintain accuracy within 5% of the baseline with no missing data when one sensor is missing. We also compare SAM against generative adversarial imputation networks (GAIN), transformers, and k-nearest neighbor methods. Results show that SAM outperforms all three approaches on average by more than 25% when two sensors are missing with negligible overhead compared to the baseline.},
  archive      = {J_TODAES},
  doi          = {10.1145/3698195},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {11},
  number       = {1},
  pages        = {1-27},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Sensor-aware data imputation for time-series machine learning on low-power wearable devices},
  volume       = {30},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Layout congestion prediction based on regression-ViT.
<em>TODAES</em>, <em>30</em>(1), 1–21. (<a
href="https://doi.org/10.1145/3698196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To accelerate the back-end design flow of integrated circuit (IC), numerous studies have made exploratory advancements in machine learning (ML) for electronic design automation (EDA). However, most research works are limited to deep learning (DL) models predominantly based on convolutional neural networks, and the models often suffer from poor generalization due to the scarcity of data. In this study, we propose the Double generative adversarial networks (D-GAN) model to enrich the dataset and propose the Regression Vision Transformer (R-ViT) model to predict layout congestion information. Compared with the baseline model, experimental results show improvements of 3.03% and 2.64% in Receiver Operating Characteristic-Area under Curve (ROC-AUC) and Precision-Recall Curve-Area under Curve (PRC-AUC) respectively. To further enhance the prediction accuracy of the model, an adaptive Huber loss function is designed to optimize the training process, resulting in an improvement of up to 11.03% in ROC-AUC compared with the baseline model. Lastly, extended experiments are conducted to study the effects of parameters and convolutional kernel size on performance, which find a better configuration.},
  archive      = {J_TODAES},
  doi          = {10.1145/3698196},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {11},
  number       = {1},
  pages        = {1-21},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Layout congestion prediction based on regression-ViT},
  volume       = {30},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SHAREDD: Sharing of test data and design-for-testability
logic for transition fault tests under standard scan. <em>TODAES</em>,
<em>30</em>(1), 1–13. (<a
href="https://doi.org/10.1145/3698198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High reliability requirements in certain systems are combined with constraints on test overheads, including test data volume, test application time and design-for-testability ( DFT ) logic. The overheads can be reduced if they are shared among different types of tests and optimized together. Several observations are combined in this article to allow sharing of overheads when the goal is to produce a compact transition fault test set with a high fault coverage and low storage requirements supported by DFT logic under standard scan. Based on these observations, the iterative procedure described in this article optimizes four parameters together: (1) the transition fault coverage, (2) the number of stored tests, (3) the number of applied tests, and (4) the size of the DFT logic. Experimental results for benchmark circuits in an academic environment demonstrate the effectiveness of the procedure.},
  archive      = {J_TODAES},
  doi          = {10.1145/3698198},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {11},
  number       = {1},
  pages        = {1-13},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {SHAREDD: Sharing of test data and design-for-testability logic for transition fault tests under standard scan},
  volume       = {30},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Area-driven boolean bi-decomposition by function
approximation. <em>TODAES</em>, <em>30</em>(1), 1–21. (<a
href="https://doi.org/10.1145/3698879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bi-decomposition rewrites logic functions as the composition of simpler components. It is related to Boolean division, where a given function is rewritten as the product of a divisor and a quotient, but bi-decomposition can be defined for any Boolean operation of two operands. The key questions are how to find a good divisor and then how to compute the quotient. In this article, we select the divisor by approximation of the original function and then characterize by an incompletely specified function the full flexibility of the quotient for each binary operator. We target area-driven exact bi-decomposition, and we apply it to the bi-decomposition of Sum-of-Products (SOP) forms. We report experiments that exhibit significant gains in literals of SOP forms when rewritten as bi-decompositions with respect to the product operator. This suggests the application of this framework to other logic forms and binary operations, both for exact and approximate implementations.},
  archive      = {J_TODAES},
  doi          = {10.1145/3698879},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {11},
  number       = {1},
  pages        = {1-21},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Area-driven boolean bi-decomposition by function approximation},
  volume       = {30},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PROTECTS: Progressive rtl obfuscation with ThrEshold control
technique during architectural synthesis. <em>TODAES</em>,
<em>30</em>(1), 1–34. (<a
href="https://doi.org/10.1145/3701032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the supply chain globalization of the semiconductor industry, securing heterogeneous System-on-Chip (SoC) is becoming necessary. A malicious alteration, inserting Hardware Trojan, infringement, or counterfeiting of design via Reverse Engineering (RE) is the primary reason. As RE allows attackers to uncover proprietary algorithms, design specifications, and other intellectual property, exploiting the design becomes easier. This has a havoc impact on the manufacturer’s revenue as well as erodes consumer trust in the authenticity of the devices. This enforces a robust framework from the topmost design abstraction level to protect against RE attacks. This article proposed a robust, architectural synthesis-driven dual-phase functional obfuscation framework for securing Register Transfer Level design. In this framework, obfuscation is achieved for both the datapath (DP) and control unit (CU) of design. Further, the robustness of obfuscated design is tested against sophisticated DP and CU level attacks. Moreover, to protect the design from brute force attack, a Consecutive Design Mis-Authentication Prevention Mechanism (CDMAP) is proposed. The proposed framework is validated using six standard Hardware Accelerator (HA) benchmarks and evaluated based on design overhead and robustness for different key sizes. A significant improvement is achieved in terms of security (∼1800 times) and (∼5.2 times) and strength of obfuscation (∼1.87 × 10 56 times) and (∼5.94 × 10 33 times) at a lower design cost of around (∼20.4%) and (∼10.4%) compared to two closely related approaches.},
  archive      = {J_TODAES},
  doi          = {10.1145/3701032},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {11},
  number       = {1},
  pages        = {1-34},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {PROTECTS: Progressive rtl obfuscation with ThrEshold control technique during architectural synthesis},
  volume       = {30},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). STCO: Enhancing training efficiency via structured sparse
tensor compilation optimization. <em>TODAES</em>, <em>30</em>(1), 1–22.
(<a href="https://doi.org/10.1145/3701033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network sparsification serves as an effective technique to accelerate Deep Neural Network (DNN) inference. However, existing sparsification techniques often rely on structured sparsity, which yields limited benefits. This is primarily due to the significant memory and computational overhead introduced by numerous sparse storage formats during address generation and gradient updates. Additionally, many of these solutions are tailored solely for the inference phase, neglecting the crucial training phase. In this article, we introduce STCO, a novel Sparse Tensor Compilation Optimization technique that significantly enhances training efficiency through structured sparse tensor compilation. Central to STCO is the Tensorization-aware Index Entity (TIE) format, which effectively represents structured sparse tensors by eliminating redundant indices and minimizing storage overhead. The TIE format plays a pivotal role in the Address-carry flow (AC flow) pass, which optimizes the data layout at the computational graph level. This pass leverages the TIE format to enhance the efficiency of tensor representations, enabling more compact and efficient sparse tensor storage. Meanwhile, a shape inference pass utilizes the AC flow to derive optimized tensor shapes, further refining the performance of sparse tensor operations. Moreover, the Address-Carry TIE Flow dynamically tracks nonzero addresses, extending the benefits of sparse optimization to both forward and backward propagation. This seamless integration into the training pipeline enables a smooth transition to sparse tensor compilation without significant modifications to existing codebases. To further boost training performance, we implement an operator-level AC flow optimization pass tailored for structured sparse tensors. This pass generates efficient addresses, ensuring minimal computational overhead during sparse tensor operations. The flexibility of STCO allows it to be efficiently integrated into various frameworks or compilers, providing a robust solution for enhancing training efficiency with structured sparse tensors. Experiments demonstrated that STCO achieved impressive speedups of 3.64×, 5.43×, 4.89×, and 3.91× when compared to state-of-the-art sparse formats on VGG16, ResNet-18, MobileNetV1, and MobileNetV2, respectively. These findings underscore the efficiency and superiority of our proposed approach in leveraging unstructured sparsity for DNN inference acceleration.},
  archive      = {J_TODAES},
  doi          = {10.1145/3701033},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {11},
  number       = {1},
  pages        = {1-22},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {STCO: Enhancing training efficiency via structured sparse tensor compilation optimization},
  volume       = {30},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing lifetime and performance of MLC NVM caches using
embedded trace buffers. <em>TODAES</em>, <em>29</em>(3), 58:1–24. (<a
href="https://doi.org/10.1145/3659102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large volumes of on-chip and off-chip memory are required by contemporary applications. Emerging non-volatile memory technologies including STT-RAM, PCM, and ReRAM are becoming popular for on-chip and off-chip memories as a result of their desirable properties. Compared to traditional memory technologies such as SRAM and DRAM, they have minimal leakage current and high packing density. Non Volatile Memories (NVM), however, have a low write endurance, a high write latency, and high write energy. Non-volatile Single Level Cell (SLC) memories can store a single bit of data in each memory cell, whereas Multi Level Cells (MLC) can store two or more bits in each memory cell. Although MLC NVMs have substantially higher packing density than SLCs, their lifetime and access speed are key concerns. For a given cache size, MLC caches consume 1.84× less space and 2.62× less leakage power than SLC caches. We propose Trace buffer Assisted Non-volatile Memory Cache (TANC), an approach that increases the lifespan and performance of MLC-based last-level caches using the underutilized Embedded Trace Buffers (ETB). TANC improves the lifetime of MLC LLCs up to 4.36× and decreases average memory access time by 4% compared to SLC NVM LLCs and by 6.41× and 11%, respectively, compared to baseline MLC LLCs.},
  archive      = {J_TODAES},
  author       = {S. Sivakumar and John Jose and Vijaykrishnan Narayanan},
  doi          = {10.1145/3659102},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {5},
  number       = {3},
  pages        = {58:1–24},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Enhancing lifetime and performance of MLC NVM caches using embedded trace buffers},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WCPNet: Jointly predicting wirelength, congestion and power
for FPGA using multi-task learning. <em>TODAES</em>, <em>29</em>(3),
57:1–19. (<a href="https://doi.org/10.1145/3656170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To speed up the design closure and improve the QoR of FPGA, supervised single-task machine learning techniques have been used to predict individual design metric based on placement results. However, the design objective is to achieve optimal performance while considering multiple conflicting metrics. The single-task approaches predict each metric in isolation and neglect the potential correlations or dependencies among them. To address the limitations, this article proposes a multi-task learning approach to jointly predict wirelength, congestion and power. By sharing the common feature representations and adopting the joint optimization strategy, the novel WCPNet models (including WCPNet-HS and WCPNet-SS) cannot only predict the three metrics of different scales simultaneously, but also outperform the majority of single-task models in terms of both prediction performance and time cost, which are demonstrated by the results of the cross design experiment. By adopting the cross-stitch structure in the encoder, WCPNet-SS outperforms WCPNet-HS in prediction performance, but WCPNet-HS is faster because of the simpler parameters sharing structure. The significance of the feature image pinUtilization on predicting power and wirelength are demonstrated by the ablation experiment.},
  archive      = {J_TODAES},
  author       = {Juming Xian and Yan Xing and Shuting Cai and Weijun Li and Xiaoming Xiong and Zhengfa Hu},
  doi          = {10.1145/3656170},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {5},
  number       = {3},
  pages        = {57:1–19},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {WCPNet: Jointly predicting wirelength, congestion and power for FPGA using multi-task learning},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Floorplanning with edge-aware graph attention network and
hindsight experience replay. <em>TODAES</em>, <em>29</em>(3), 56:1–17.
(<a href="https://doi.org/10.1145/3653453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we focus on chip floorplanning, which aims to determine the location and orientation of circuit macros simultaneously, so the chip area and wirelength are minimized. As the highest level of abstraction in hierarchical physical design, floorplanning bridges the gap between the system-level design and the physical synthesis, whose quality directly influences downstream placement and routing. To tackle chip floorplanning, we propose an end-to-end reinforcement learning (RL) methodology with a hindsight experience replay technique. An edge-aware graph attention network (EAGAT) is developed to effectively encode the macro and connection features of the netlist graph. Moreover, we build a hierarchical decoder architecture mainly consisting of transformer and attention pointer mechanism to output floorplan actions. Since the RL agent automatically extracts knowledge about the solution space, the previously learned policy can be quickly transferred to optimize new unseen netlists. Experimental results demonstrate that, compared with state-of-the-art floorplanners, the proposed end-to-end methodology significantly optimizes area and wirelength on public GSRC and MCNC benchmarks.},
  archive      = {J_TODAES},
  author       = {Bo Yang and Qi Xu and Hao Geng and Song Chen and Bei Yu and Yi Kang},
  doi          = {10.1145/3653453},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {5},
  number       = {3},
  pages        = {56:1–17},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Floorplanning with edge-aware graph attention network and hindsight experience replay},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental concolic testing of register-transfer level
designs. <em>TODAES</em>, <em>29</em>(3), 55:1–23. (<a
href="https://doi.org/10.1145/3655621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concolic testing is a scalable solution for automated generation of directed tests for validation of hardware designs. Unfortunately, concolic testing fails to cover complex corner cases such as hard-to-activate branches. In this article, we propose an incremental concolic testing technique to cover hard-to-activate branches in register-transfer level (RTL) models. We show that a complex branch condition can be viewed as a sequence of easy-to-activate events. We map the branch coverage problem to the coverage of a sequence of events. We propose an efficient algorithm to cover the sequence of events using concolic testing. Specifically, the test generated to activate the current event is used as the starting point to activate the next event in the sequence. Experimental results demonstrate that our approach can be used to generate directed tests to cover complex corner cases in RTL models while state-of-the-art methods fail to activate them.},
  archive      = {J_TODAES},
  author       = {Hasini Witharana and Aruna Jayasena and Prabhat Mishra},
  doi          = {10.1145/3655621},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {5},
  number       = {3},
  pages        = {55:1–23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Incremental concolic testing of register-transfer level designs},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep reinforcement learning-based mining task offloading
scheme for intelligent connected vehicles in UAV-aided MEC.
<em>TODAES</em>, <em>29</em>(3), 54:1–29. (<a
href="https://doi.org/10.1145/3653451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convergence of unmanned aerial vehicle (UAV)-aided mobile edge computing (MEC) networks and blockchain transforms the existing mobile networking paradigm. However, in the temporary hotspot scenario for intelligent connected vehicles (ICVs) in UAV-aided MEC networks, deploying blockchain-based services and applications in vehicles is generally impossible due to its high computational resource and storage requirements. One possible solution is to offload part of all the computational tasks to MEC servers wherever possible. Unfortunately, due to the limited availability and high mobility of the vehicles, there is still lacking simple solutions that can support low-latency and higher reliability networking services for ICVs. In this article, we study the task offloading problem of minimizing the total system latency and the optimal task offloading scheme, subject to constraints on the hover position coordinates of the UAV, the fixed bonuses, flexible transaction fees, transaction rates, mining difficulty, costs and battery energy consumption of the UAV. The problem is confirmed to be a challenging linear integer planning problem, we formulate the problem as a constrained Markov decision process. Deep Reinforcement Learning (DRL) has excellently solved sequential decision-making problems in dynamic ICVs environment, therefore, we propose a novel distributed DRL-based P-D3QN approach by using Prioritized Experience Replay strategy and the dueling double deep Q-network (D3QN) algorithm to solve the optimal task offloading policy effectively. Finally, experiment results show that compared with the benchmark scheme, the P-D3QN algorithm can bring about 26.24% latency improvement and increase about 42.26% offloading utility.},
  archive      = {J_TODAES},
  author       = {Chunlin Li and Kun Jiang and Yong Zhang and Lincheng Jiang and Youlong Luo and Shaohua Wan},
  doi          = {10.1145/3653451},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {5},
  number       = {3},
  pages        = {54:1–29},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Deep reinforcement learning-based mining task offloading scheme for intelligent connected vehicles in UAV-aided MEC},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A high-performance accelerator for real-time
super-resolution on edge FPGAs. <em>TODAES</em>, <em>29</em>(3),
53:1–25. (<a href="https://doi.org/10.1145/3652855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital era, the prevalence of low-quality images contrasts with the widespread use of high-definition displays, primarily due to low-resolution cameras and compression technologies. Image super-resolution (SR) techniques, particularly those leveraging deep learning, aim to enhance these images for high-definition presentation. However, real-time execution of deep neural network (DNN)-based SR methods at the edge poses challenges due to their high computational and storage requirements. To address this, field-programmable gate arrays (FPGAs) have emerged as a promising platform, offering flexibility, programmability, and adaptability to evolving models. Previous FPGA-based SR solutions have focused on reducing computational and memory costs through aggressive simplification techniques, often sacrificing the quality of the reconstructed images. This paper introduces a novel SR network specifically designed for edge applications, which maintains reconstruction performance while managing computation costs effectively. Additionally, we propose an architectural design that enables the real-time and end-to-end inference of the proposed SR network on embedded FPGAs. Our key contributions include a tailored SR algorithm optimized for embedded FPGAs, a DSP-enhanced design that achieves a significant four-fold speedup, a novel scalable cache strategy for handling large feature maps, optimization of DSP cascade consumption, and a constraint optimization approach for resource allocation. Experimental results demonstrate that our FPGA-specific accelerator surpasses existing solutions, delivering superior throughput, energy efficiency, and image quality.},
  archive      = {J_TODAES},
  author       = {Hongduo Liu and Yijian Qian and Youqiang Liang and Bin Zhang and Zhaohan Liu and Tao He and Wenqian Zhao and Jiangbo Lu and Bei Yu},
  doi          = {10.1145/3652855},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {5},
  number       = {3},
  pages        = {53:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A high-performance accelerator for real-time super-resolution on edge FPGAs},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SEDONUT: A single event double node upset tolerant SRAM for
terrestrial applications. <em>TODAES</em>, <em>29</em>(3), 52:1–13. (<a
href="https://doi.org/10.1145/3651985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiation and its effect on neighboring nodes are critical not only for space applications but also for terrestrial applications at modern lower-technology nodes. This may cause static random-access memory (SRAM) failures due to single- and multi-node upset. Hence, this article proposes a 14T radiation-hardened-based SRAM cell to overcome soft errors for space and critical terrestrial applications. Simulation results show that the proposed cell can be resilient to any single event upset and single event double node upset at its storage nodes. This cell uses less power than others. The hold, read, and write stability increases compared with most considered cells. The higher critical charge of the proposed SRAM increases radiation resistance. Simulation results demonstrate that out of all compared SRAMs, only DNUSRM and the proposed SRAM show 0% probability of logical flipping. Also, other parameters such as total critical charge, write stability, read stability, hold stability, area, power, sensitive area, write speed, and read speed of the proposed SRAM are improved by –19.1%, 5.22%, 25.7%, –5.46%, 22.5%, 50.6%, 60.0%, 17.91%, and 0.74% compared with DNUSRM SRAM. Hence, the better balance among the parameters makes the proposed cell more suitable for space and critical terrestrial applications. Finally, the post-layout and Monte Carlo simulation validate the efficiency of SRAMs.},
  archive      = {J_TODAES},
  author       = {Govind Prasad and Bipin Mandi and Maifuz Ali},
  doi          = {10.1145/3651985},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {5},
  number       = {3},
  pages        = {52:1–13},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {SEDONUT: A single event double node upset tolerant SRAM for terrestrial applications},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Root-cause analysis with semi-supervised co-training for
integrated systems. <em>TODAES</em>, <em>29</em>(3), 51:1–22. (<a
href="https://doi.org/10.1145/3649313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Root-cause analysis for integrated systems has become increasingly challenging due to their growing complexity. To tackle these challenges, machine learning (ML) has been applied to enhance root-cause analysis. Nonetheless, ML-based root-cause analysis usually requires abundant training data with root causes labeled by human experts, which are difficult or even impossible to obtain. To overcome this drawback, a semi-supervised co-training method is proposed for root-cause analysis in this article, which only requires a small portion of labeled data. First, a random forest is trained with labeled data. Next, we propose a co-training technique to learn from unlabeled data with semi-supervised learning, which pre-labels a subset of these data automatically and then retrains each decision tree in the random forest. In addition, a robust framework is proposed to avoid over-fitting. We further apply initialization by clustering and feature selection to improve the diagnostic performance. With two case studies from industry, the proposed approach shows superior performance against other state-of-the-art methods by saving up to 67% of labeling efforts.},
  archive      = {J_TODAES},
  author       = {Renjian Pan and Xin Li and Krishnendu Chakrabarty},
  doi          = {10.1145/3649313},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {5},
  number       = {3},
  pages        = {51:1–22},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Root-cause analysis with semi-supervised co-training for integrated systems},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security evaluation of state space obfuscation of hardware
IP through a red team-blue team practice. <em>TODAES</em>,
<em>29</em>(3), 50:1–18. (<a
href="https://doi.org/10.1145/3640461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inclination towards a fab-less model of integrated circuit (IC) manufacturing, several untrusted entities get white-box access to the proprietary intellectual property (IP) blocks from diverse vendors. To this end, the untrusted entities pose security-breach threats in the form of piracy, cloning, and reverse-engineering, sometimes threatening national security. Hardware obfuscation is a prominent countermeasure against such issues. Obfuscation allows for preventing the usage of the IP blocks without authorization from the IP owners. Due to finite state machine (FSM) transformation-based hardware obfuscation, the design’s FSM gets transformed to make it difficult for an attacker to reverse-engineer the design. A secret key needs to be applied to make the FSM functional, thus preventing the usage of the IP for unintended purposes. Although several hardware obfuscation techniques have been proposed, due to the inability to analyze the techniques from the attackers’ standpoint, numerous vulnerabilities inherent to the obfuscation methods go undetected unless a true adversary discovers them. In this article, we present a collaborative approach between two entities—one acting as an attacker or red team and another as a defender or blue team , the first systematic approach to replicate the real attacker-defender scenario in the hardware security domain, which in return strengthens the FSM transformation-based obfuscation technique. The blue team transforms the underlying FSM of a gate-level netlist using state space obfuscation. The red team plays the role of an adversary or evaluator and tries to unlock the design by extracting the unlocking key or recovering the obfuscation circuitries. As the key outcome of this red team–blue team effort, a robust state space obfuscation methodology is evolved showing security promises.},
  archive      = {J_TODAES},
  author       = {Md Moshiur Rahman and Jim Geist and Daniel Xing and Yuntao Liu and Ankur Srivastava and Travis Meade and Yier Jin and Swarup Bhunia},
  doi          = {10.1145/3640461},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {5},
  number       = {3},
  pages        = {50:1–18},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Security evaluation of state space obfuscation of hardware IP through a red team-blue team practice},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparative analysis of dynamic power consumption of
parallel prefix adder. <em>TODAES</em>, <em>29</em>(3), 49:1–22. (<a
href="https://doi.org/10.1145/3651984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Newcomb-Benford law, also known as Benford&#39;s law, is the law of anomalous numbers stating that in many real-life numerical datasets, including physical and statistical ones, numbers have a small initial digit. Numbers irregularity observed in nature leads to the question, is the arithmetical-logical unit, responsible for performing calculations in computers, optimal? Are there other architectures, not as regular as commonly used Parallel Prefix Adders, that can perform better, especially when operating on the datasets that are not purely random, but irregular? In this article, structures of a propagate-generate tree are compared including regular and irregular configurations—various structures are examined: regular, irregular, with gray cells only, with both gray and black, and with higher valency cells. Performance is evaluated in terms of energy consumption. The evaluation was performed using the extended power model of static CMOS gates. The model is based on changes of vectors, naturally taking into account spatio-temporal correlations. The energy parameters of the designed cells were calculated on the basis of electrical (Spice) simulation. Designs and simulations were done in the Cadence environment and calculations of the power dissipation were performed in MATLAB. The results clearly show that there are PPA structures that perform much better for a specific type of numerical data. Negligent design can lead to an increase greater than two times of power consumption. The novel architectures of PPA described in this work might find practical applications in specialized adders dealing with numerical datasets, such as, for example, sine functions commonly used in digital signal processing.},
  archive      = {J_TODAES},
  author       = {Ireneusz Brzozowski},
  doi          = {10.1145/3651984},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {4},
  number       = {3},
  pages        = {49:1–22},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Comparative analysis of dynamic power consumption of parallel prefix adder},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Two-dimensional search space for extracting broadside tests
from functional test sequences. <em>TODAES</em>, <em>29</em>(3),
48:1–13. (<a href="https://doi.org/10.1145/3650207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Testing for delay faults after chip manufacturing is critical to correct chip operation. Tests for delay faults are applied using scan chains that provide access to internal memory elements. As a result, a circuit may operate under non-functional operation conditions during test application. This may lead to overtesting. The extraction of broadside tests from functional test sequences ensures that the tests create functional operation conditions. When N functional test sequences of length L +1 are available, the number of broadside tests that can be extracted is N · L . Depending on the source of the functional test sequences, the value of N · L may be large. In this case, it is important to select a subset of n ≤ N sequences and consider only the first l ≤ L clock cycles of every sequence for the extraction of n · l ≪ N · L broadside tests. The two-dimensional N × L search space for broadside tests is the subject of this article. Using a static procedure that considers fixed values of N and l , the article demonstrates that, for the same value of N · L , different circuits benefit from different values of N and l . It also describes a dynamic procedure that matches the parameters N and l to the circuit. The discussion is supported by experimental results for transition faults in benchmark circuits.},
  archive      = {J_TODAES},
  author       = {Irith Pomeranz},
  doi          = {10.1145/3650207},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {4},
  number       = {3},
  pages        = {48:1–13},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Two-dimensional search space for extracting broadside tests from functional test sequences},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). H3D-transformer: A heterogeneous 3D (H3D) computing platform
for transformer model acceleration on edge devices. <em>TODAES</em>,
<em>29</em>(3), 47:1–19. (<a
href="https://doi.org/10.1145/3649219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior hardware accelerator designs primarily focused on single-chip solutions for 10 MB-class computer vision models. The GB-class transformer models for natural language processing (NLP) impose challenges on existing accelerator design due to the massive number of parameters and the diverse matrix multiplication (MatMul) workloads involved. This work proposes a heterogeneous 3D-based accelerator design for transformer models, which adopts an interposer substrate with multiple 3D memory/logic hybrid cubes optimized for accelerating different MatMul workloads. An approximate computing scheme is proposed to take advantage of heterogeneous computing paradigms of mixed-signal compute-in-memory (CIM) and digital tensor processing units (TPU). From the system-level evaluation results, 10 TOPS/W energy efficiency is achieved for the BERT and GPT2 model, which is about 2.6× ∼ 3.1× higher than the baseline with 7 nm TPU and stacked FeFET memory.},
  archive      = {J_TODAES},
  author       = {Yandong Luo and Shimeng Yu},
  doi          = {10.1145/3649219},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {4},
  number       = {3},
  pages        = {47:1–19},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {H3D-transformer: A heterogeneous 3D (H3D) computing platform for transformer model acceleration on edge devices},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VeriGen: A large language model for verilog code generation.
<em>TODAES</em>, <em>29</em>(3), 46:1–31. (<a
href="https://doi.org/10.1145/3643681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we explore the capability of Large Language Models (LLMs) to automate hardware design by automatically completing partial Verilog code, a common language for designing and modeling digital systems. We fine-tune pre-existing LLMs on Verilog datasets compiled from GitHub and Verilog textbooks. We evaluate the functional correctness of the generated Verilog code using a specially designed test suite, featuring a custom problem set and testing benches. Here, our fine-tuned open-source CodeGen-16B model outperforms the commercial state-of-the-art GPT-3.5-turbo model with a 1.1% overall increase. Upon testing with a more diverse and complex problem set, we find that the fine-tuned model shows competitive performance against state-of-the-art gpt-3.5-turbo, excelling in certain scenarios. Notably, it demonstrates a 41% improvement in generating syntactically correct Verilog code across various problem categories compared to its pre-trained counterpart, highlighting the potential of smaller, in-house LLMs in hardware design automation. We release our training/evaluation scripts and LLM checkpoints as open-source contributions.},
  archive      = {J_TODAES},
  author       = {Shailja Thakur and Baleegh Ahmad and Hammond Pearce and Benjamin Tan and Brendan Dolan-Gavitt and Ramesh Karri and Siddharth Garg},
  doi          = {10.1145/3643681},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {4},
  number       = {3},
  pages        = {46:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {VeriGen: A large language model for verilog code generation},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Reduced on-chip storage of seeds for built-in test
generation. <em>TODAES</em>, <em>29</em>(3), 45:1–16. (<a
href="https://doi.org/10.1145/3643810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logic built-in self-test ( LBIST ) approaches use an on-chip logic block for test generation and thus enable in-field testing. Recent reports of silent data corruption underline the importance of in-field testing. In a class of storage-based LBIST approaches, compressed tests are stored on-chip and decompressed by an on-chip decompression logic. The on-chip storage requirements may become a bottleneck when the number of compressed tests is large. In this case, using each compressed test for applying several different tests allows the storage requirements to be reduced. However, producing different tests from each compressed test has a hardware overhead. This article suggests a new on-chip storage scheme for compressed tests that eliminates the additional hardware overhead. Under the new storage scheme, a set of N B -bit compressed tests targeting a set of faults F 0 is translated into a sequence S of N ⋅ B bits. Every B consecutive bits of S are considered as a compressed test. The sequence S thus yields close to N ⋅ B compressed tests, magnifying the test data stored in S almost B times. Taking advantage of the extra tests, the article describes a software procedure that is applied offline to reduce S without losing fault coverage of F 0 . Experimental results for benchmark circuits demonstrate significant reductions in the storage requirements of S and significant increases in the fault coverage of a second set of faults, F 1 .},
  archive      = {J_TODAES},
  author       = {Irith Pomeranz},
  doi          = {10.1145/3643810},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {3},
  number       = {3},
  pages        = {45:1–16},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Reduced on-chip storage of seeds for built-in test generation},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). D3PBO: Dynamic domain decomposition-based parallel bayesian
optimization for large-scale analog circuit sizing. <em>TODAES</em>,
<em>29</em>(3), 44:1–25. (<a
href="https://doi.org/10.1145/3643811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization (BO) is an efficient global optimization method for expensive black-box functions, but the expansion for high-dimensional problems and large sample budgets still remains a severe challenge. In order to extend BO for large-scale analog circuit synthesis, a novel computationally efficient parallel BO method, D 3 PBO, is proposed for high-dimensional problems in this work. We introduce the dynamic domain decomposition method based on maximum variance between clusters. The search space is decomposed into subdomains progressively to limit the maximal number of observations in each domain. The promising domain is explored by multi-trust region-based batch BO with the local Gaussian process (GP) model. As the domain decomposition progresses, the basin-shaped domain is identified using a GP-assisted quadratic regression method and exploited by the local search method BOBYQA to achieve a faster convergence rate. The time complexity of D 3 PBO is constant for each iteration. Experiments demonstrate that D 3 PBO obtains better results with significantly less runtime consumption compared to state-of-the-art methods. For the circuit optimization experiments, D 3 PBO achieves up to 10× runtime speedup compared to TuRBO with better solutions.},
  archive      = {J_TODAES},
  author       = {Aidong Zhao and Tianchen Gu and Zhaori Bi and Fan Yang and Changhao Yan and Xuan Zeng and Zixiao Lin and Wenchuang Hu and Dian Zhou},
  doi          = {10.1145/3643811},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {3},
  number       = {3},
  pages        = {44:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {D3PBO: Dynamic domain decomposition-based parallel bayesian optimization for large-scale analog circuit sizing},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EPHA: An energy-efficient parallel hybrid architecture for
ANNs and SNNs. <em>TODAES</em>, <em>29</em>(3), 43:1–28. (<a
href="https://doi.org/10.1145/3643134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) and spiking neural networks (SNNs) are two general approaches to achieve artificial intelligence (AI). The former have been widely used in academia and industry fields; the latter, SNNs, are more similar to biological neural networks and can realize ultra-low power consumption, thus have received widespread research attention. However, due to their fundamental differences in computation formula and information coding, the two methods often require different and incompatible platforms. Alongside the development of AI, a general platform that can support both ANNs and SNNs is necessary. Moreover, there are some similarities between ANNs and SNNs, which leaves room to deploy different networks on the same architecture. However, there is little related research on this topic. Accordingly, this article presents an energy-efficient, scalable, and non-Von Neumann architecture (EPHA) for ANNs and SNNs. Our study combines device-, circuit-, architecture-, and algorithm-level innovations to achieve a parallel architecture with ultra-low power consumption. We use the compensated ferrimagnet to act as both synapses and neurons to store weights and perform dot-product operations, respectively. Moreover, we propose a novel computing flow to reduce the operations across multiple crossbar arrays, which enables our design to conduct large and complex tasks. On a suite of ANN and SNN workloads, the EPHA is 1.6× more power-efficient than a state-of-the-art design, NEBULA, in the ANN mode. In the SNN mode, our design is 4 orders of magnitude more than the Loihi in power efficiency.},
  archive      = {J_TODAES},
  author       = {Yunping Zhao and Sheng Ma and Hengzhu Liu and Libo Huang},
  doi          = {10.1145/3643134},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {3},
  number       = {3},
  pages        = {43:1–28},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {EPHA: An energy-efficient parallel hybrid architecture for ANNs and SNNs},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient FPGA architecture with turn-restricted switch
boxes. <em>TODAES</em>, <em>29</em>(3), 42:1–18. (<a
href="https://doi.org/10.1145/3643809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Field-Programmable Gate Arrays (FPGAs) employ a large number of SRAM cells to provide a flexible routing architecture which have a significant impact on the FPGA’s area and power consumption. This flexible routing allows for a rather easy realization of the desired functionality, but our evaluations show that the full routing flexibility is not required in many occasions. In this work, we focus on what is actually needed and introduce a new switch-box realization what we call Turn-Restricted Switch-Boxes which supports only a subset of possible turns. The proposed method increases the utilization rate of FPGA switch-boxes by eliminating the unemployed resources. Experimental evaluations confirm that the area and average power consumption can be reduced by 12.8% and 14.1%, on average, respectively and the FPGA routing susceptibility to SEU and MBU can be improved by 18.2%, on average, by imposing negligible performance. 1},
  archive      = {J_TODAES},
  author       = {Fatemeh Serajeh Hassani and Mohammad Sadrosadati and Nezam Rohbani and Sebastian Pointner and Robert Wille and Hamid Sarbazi-Azad},
  doi          = {10.1145/3643809},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {3},
  number       = {3},
  pages        = {42:1–18},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {An efficient FPGA architecture with turn-restricted switch boxes},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting adversarial examples utilizing pixel value
diversity. <em>TODAES</em>, <em>29</em>(3), 41:1–12. (<a
href="https://doi.org/10.1145/3636460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce two novel methods to detect adversarial examples utilizing pixel value diversity. First, we propose the concept of pixel value diversity (which reflects the spread of pixel values in an image) and two independent metrics (UPVR and RPVR) to assess the pixel value diversity separately. Then we propose two methods to detect adversarial examples based on the threshold method and Bayesian method respectively. Experimental results show that compared to an excellent prior method LID, our proposed methods achieve better performances in detecting adversarial examples. We also show the robustness of our proposed work against an adaptive attack method.},
  archive      = {J_TODAES},
  author       = {Jinxin Dong and Pingqiang Zhou},
  doi          = {10.1145/3636460},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {3},
  number       = {3},
  pages        = {41:1–12},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Detecting adversarial examples utilizing pixel value diversity},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security of electrical, optical, and wireless on-chip
interconnects: A survey. <em>TODAES</em>, <em>29</em>(2), 40:1–41. (<a
href="https://doi.org/10.1145/3631117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of manufacturing technologies has enabled the integration of more intellectual property (IP) cores on the same system-on-chip (SoC). Scalable and high throughput on-chip communication architecture has become a vital component in today’s SoCs. Diverse technologies such as electrical, wireless, optical, and hybrid are available for on-chip communication with different architectures supporting them. On-chip communication sub-system is shared across all the IPs and continuously used throughout the lifetime of the SoC. Therefore, the security of the on-chip communication is crucial, because exploiting any vulnerability would be a goldmine for an attacker. In this survey, we provide a comprehensive review of threat models, attacks, and countermeasures over diverse on-chip communication technologies as well as sophisticated architectures.},
  archive      = {J_TODAES},
  author       = {Hansika Weerasena and Prabhat Mishra},
  doi          = {10.1145/3631117},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {40:1–41},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Security of electrical, optical, and wireless on-chip interconnects: A survey},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A module-level configuration methodology for programmable
camouflaged logic. <em>TODAES</em>, <em>29</em>(2), 39:1–31. (<a
href="https://doi.org/10.1145/3640462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logic camouflage is a widely adopted technique that mitigates the threat of intellectual property (IP) piracy and overproduction in the integrated circuit (IC) supply chain. Camouflaged logic achieves functional obfuscation through physical-level ambiguity and post-manufacturing programmability. However, discussions on programmability are confined to the level of logic cells/gates, limiting the broader-scale application of logic camouflage. In this work, we propose a novel module-level configuration methodology for programmable camouflaged logic that can be implemented without additional hardware ports and with negligible resources. We prove theoretically that the configuration of the programmable camouflaged logic cells can be achieved through the inputs and netlist of the original module. Further, we propose a novel lightweight ferroelectric FET (FeFET)-based reconfigurable logic gate (rGate) family and apply it to the proposed methodology. With the flexible replacement and the proposed configuration-aware conversion algorithm, this work is characterized by the input-only programming scheme as well as the combination of high output error rate and point-function-like defense. Evaluations show an average of &gt;95% of the alternative rGate location for camouflage, which is sufficient for the security-aware design. We illustrate the exponential complexity in function state traversal and the enhanced defense capability of locked blackbox against Boolean Satisfiability (SAT) attacks compared with key-based methods. We also preserve an evident output Hamming distance and introduce negligible hardware overheads in both gate-level and module-level evaluations under typical benchmarks.},
  archive      = {J_TODAES},
  author       = {Jianfeng Wang and Zhonghao Chen and Jiahao Zhang and Yixin Xu and Tongguang Yu and Ziheng Zheng and Enze Ye and Sumitha George and Huazhong Yang and Yongpan Liu and Kai Ni and Vijaykrishnan Narayanan and Xueqing Li},
  doi          = {10.1145/3640462},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {39:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A module-level configuration methodology for programmable camouflaged logic},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RGMU: A high-flexibility and low-cost reconfigurable galois
field multiplication unit design approach for CGRCA. <em>TODAES</em>,
<em>29</em>(2), 38:1–24. (<a
href="https://doi.org/10.1145/3639820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finite field multiplication is a non-linear transformation operator that appears in the majority of symmetric cryptographic algorithms. Numerous specified finite field multiplication units have been proposed as a fundamental module in the coarse-grained reconfigurable cipher logic array to support more cryptographic algorithms; however, it will introduce low flexibility and high overhead, resulting in reduced performance of the coarse-grained reconfigurable cipher logic array. In this article, a high-flexibility and low-cost reconfigurable Galois field multiplication unit (RGMU) is proposed to balance the tradeoffs between the function, delay, and area. All the finite field multiplication operations, including maximum distance separable matrix multiplication, parallel update of Fibonacci linear feedback shift register, parallel update of Galois linear feedback shift register, and composite field multiplication, are analyzed and two basic operation components are abstracted. Further, a reconfigurable finite field multiplication computational model is established to demonstrate the efficacy of reconfigurable units and guide the design of RGMU with high performance. Finally, the overall architecture of RGMU and two multiplication circuits are introduced. Experimental results show that the RGMU can not only reduce the hardware overhead and power consumption but also has the unique advantage of satisfying all the finite field multiplication operations in symmetric cryptography algorithms.},
  archive      = {J_TODAES},
  author       = {Danping Jiang and Zibin Dai and Yanjiang Liu and Zongren Zhang},
  doi          = {10.1145/3639820},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {38:1–24},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {RGMU: A high-flexibility and low-cost reconfigurable galois field multiplication unit design approach for CGRCA},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pareto optimization of analog circuits using reinforcement
learning. <em>TODAES</em>, <em>29</em>(2), 37:1–14. (<a
href="https://doi.org/10.1145/3640463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analog circuit optimization and design presents a unique set of challenges in the IC design process. Many applications require the designer to optimize for multiple competing objectives, which poses a crucial challenge. Motivated by these practical aspects, we propose a novel method to tackle multi-objective optimization for analog circuit design in continuous action spaces. In particular, we propose to (i) extrapolate current techniques in Multi-Objective Reinforcement Learning to continuous state and action spaces and (ii) provide for a dynamically tunable trained model to query user defined preferences in multi-objective optimization in the analog circuit design context.},
  archive      = {J_TODAES},
  author       = {Karthik Somayaji NS and Peng Li},
  doi          = {10.1145/3640463},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {37:1–14},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Pareto optimization of analog circuits using reinforcement learning},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mixed integer programming based placement refinement by RSMT
model with movable pins. <em>TODAES</em>, <em>29</em>(2), 36:1–18. (<a
href="https://doi.org/10.1145/3639365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Placement is a critical step in the physical design for digital application specific integrated circuits (ASICs), as it can directly affect the design qualities such as wirelength and timing. For many domain specific designs, the demands for high performance parallel computing result in repetitive hardware instances, such as the processing elements in the neural network accelerators. As these instances can dominate the area of the designs, the runtime of the complete design’s placement can be traded for optimizing and reusing one instance’s placement to achieve higher quality. Therefore, this work proposes a mixed integer programming (MIP)-based placement refinement algorithm for the repetitive instances. By efficiently modeling the rectilinear steiner tree wirelength, the placement can be precisely refined for better quality. Besides, the MIP formulations for timing-driven placement are proposed. A theoretical proof is then provided to show the correctness of the proposed wirelength model. For the instances in various popular fields, the experiments show that given the placement from the commercial placers, the proposed algorithm can perform further placement refinement to reduce 3.76%/3.64% detailed routing wirelength and 1.68%/2.42% critical path delay under wirelength/timing-driven mode, respectively, and also outperforms the state-of-the-art previous work.},
  archive      = {J_TODAES},
  author       = {Ke Tang and Lang Feng and Zhongfeng Wang},
  doi          = {10.1145/3639365},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {36:1–18},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Mixed integer programming based placement refinement by RSMT model with movable pins},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application-level validation of accelerator designs using a
formal software/hardware interface. <em>TODAES</em>, <em>29</em>(2),
35:1–25. (<a href="https://doi.org/10.1145/3639051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ideally, accelerator development should be as easy as software development. Several recent design languages/tools are working toward this goal, but actually testing early designs on real applications end-to-end remains prohibitively difficult due to the costs of building specialized compiler and simulator support. We propose a new first-in-class, mostly automated methodology termed “3LA” to enable end-to-end testing of prototype accelerator designs on unmodified source applications. A key contribution of 3LA is the use of a formal software/hardware interface that specifies an accelerator’s operations and their semantics. Specifically, we leverage the Instruction-level Abstraction (ILA) formal specification for accelerators that has been successfully used thus far for accelerator implementation verification. We show how the ILA for accelerators serves as a software/hardware interface, similar to the Instruction Set Architecture for processors, that can be used for automated development of compilers and instruction-level simulators. Another key contribution of this work is to show how ILA-based accelerator semantics enables extending recent work on equality saturation to auto-generate basic compiler support for prototype accelerators in a technique we term “flexible matching.” By combining flexible matching with simulators auto-generated from ILA specifications, our approach enables end-to-end evaluation with modest engineering effort. We detail several case studies of 3LA, which uncovered an unknown flaw in a recently published accelerator and facilitated its fix.},
  archive      = {J_TODAES},
  author       = {Bo-Yuan Huang and Steven Lyubomirsky and Yi Li and Mike He and Gus Henry Smith and Thierry Tambe and Akash Gaonkar and Vishal Canumalla and Andrew Cheung and Gu-Yeon Wei and Aarti Gupta and Zachary Tatlock and Sharad Malik},
  doi          = {10.1145/3639051},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {35:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Application-level validation of accelerator designs using a formal Software/Hardware interface},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TROP: TRust-aware OPportunistic routing in NoC with hardware
trojans. <em>TODAES</em>, <em>29</em>(2), 34:1–25. (<a
href="https://doi.org/10.1145/3639821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple software and hardware intellectual property (IP) components are combined on a single chip to form Multi-Processor Systems-on-Chips (MPSoCs). Due to the rigid time-to-market constraints, some of the IPs are from outsourced third parties. Due to the supply-chain management of IP blocks being handled by unreliable third-party vendors, security has grown as a crucial design concern in the MPSoC. These IPs may get exposed to certain unwanted practises like the insertion of malicious circuits called Hardware Trojan (HT) leading to security threats and attacks, including sensitive data leakage or integrity violations. A Network-on-Chip (NoC) connects various units of an MPSoC. Since it serves as the interface between various units in an MPSoC, it has complete access to all the data flowing through the system. This makes NoC security a paramount design issue. Our research focuses on a threat model where the NoC is infiltrated by multiple HTs that can corrupt packets. Data integrity verified at the destination’s network interface (NI) triggers re-transmissions of packets if the verification results in an error. In this article, we propose an opportunistic trust-aware routing strategy that efficiently avoids HT while ensuring that the packets arrive at their destination unaltered. Experimental results demonstrate the successful movement of packets through opportunistically selected neighbours along a trust-aware path free from the HT effect. We also observe a significant reduction in the rate of packet re-transmissions and latency at the expense of incurring minimum area and power overhead.},
  archive      = {J_TODAES},
  author       = {Syam Sankar and Ruchika Gupta and John Jose and Sukumar Nandi},
  doi          = {10.1145/3639821},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {34:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {TROP: TRust-aware OPportunistic routing in NoC with hardware trojans},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced real-time scheduling of AVB flows in time-sensitive
networking. <em>TODAES</em>, <em>29</em>(2), 33:1–26. (<a
href="https://doi.org/10.1145/3637878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-Sensitive Networking (TSN) realizes high bandwidth and time determinism for data transmission and thus becomes the crucial communication technology in time-critical systems. The Gate Control List (GCL) is used to control the transmission of different classes of traffic in TSN, including Time-Triggered (TT) flows, Audio-Video-Bridging (AVB) flows, and Best-Effort (BE) flows. Most studies focus on optimizing GCL synthesis by reserving the preceding time slots to serve TT flows with the strict delay requirement, but ignore the deadlines of non-TT flows and cause the large delay. Therefore, this paper proposes a comprehensive scheduling method to enhance the real-time scheduling of AVB flows while guaranteeing the time determinism of TT flows. This method first optimizes GCL synthesis to reserve the preceding time slots for AVB flows, and then introduces the Earliest Deadline First (EDF) method to further improve the transmission of AVB flows by considering their deadlines. Moreover, the worst-case delay (WCD) analysis method is proposed to verify the effectiveness of the proposed method. Experimental results show that the proposed method improves the transmission of AVB flows compared to the state-of-the-art methods.},
  archive      = {J_TODAES},
  author       = {Libing Deng and Gang Zeng and Ryo Kurachi and Hiroaki Takada and Xiongren Xiao and Renfa Li and Guoqi Xie},
  doi          = {10.1145/3637878},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {33:1–26},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Enhanced real-time scheduling of AVB flows in time-sensitive networking},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GAN-place: Advancing open source placers to
commercial-quality using generative adversarial networks and transfer
learning. <em>TODAES</em>, <em>29</em>(2), 32:1–17. (<a
href="https://doi.org/10.1145/3636461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, GPU-accelerated placers such as DREAMPlace and Xplace have demonstrated their superiority over traditional CPU-reliant placers by achieving orders of magnitude speed up in placement runtime. However, due to their limited focus in placement objectives (e.g., wirelength and density), the placement quality achieved by DREAMPlace or Xplace is not comparable to that of commercial tools. In this article, to bridge the gap between open source and commercial placers, we present a novel placement optimization framework named GAN-Place that employs generative adversarial learning to transfer the placement quality of the industry-leading commercial placer, Synopsys ICC2, to existing open source GPU-accelerated placers (DREAMPlace and Xplace). Without the knowledge of the underlying proprietary algorithms or constraints used by the commercial tools, our framework facilitates transfer learning to directly enhance the open source placers by optimizing the proposed differentiable loss that denotes the “similarity” between DREAMPlace- or Xplace-generated placements and those in commercial databases. Experimental results on seven industrial designs not only show that our GAN-Place immediately improves the Power, Performance, and Area metrics at the placement stage but also demonstrates that these improvements last firmly to the post-route stage, where we observe improvements by up to 8.3% in wirelength, 7.4% in power, and 37.6% in Total Negative Slack on a commercial CPU benchmark.},
  archive      = {J_TODAES},
  author       = {Yi-Chen Lu and Haoxing Ren and Hao-Hsiang Hsiao and Sung Kyu Lim},
  doi          = {10.1145/3636461},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {32:1–17},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {GAN-place: Advancing open source placers to commercial-quality using generative adversarial networks and transfer learning},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable and accelerated self-healing control circuit using
evolvable hardware. <em>TODAES</em>, <em>29</em>(2), 31:1–29. (<a
href="https://doi.org/10.1145/3634682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controllers are mission-critical components of any electronic design. By sending control signals, they decide which and when other data path elements must operate. Faults, especially Single Event Upset (SEU) occurrence in these components, can lead to functional/mission failure of the system when deployed in harsh environments. Hence, competence to self-heal from SEU is highly required in the control path of the digital system. Reconfiguration is critical for recovering from a faulty state to a non-faulty state. Compared to native reconfiguration, the Virtual Reconfigurable Circuit (VRC) is an FPGA-generic reconfiguration mechanism. The non-partial reconfiguration in VRC and extensive architecture are considered hindrances in extending the VRC-based Evolvable Hardware (EHW) to real-time fault mitigation. To confront this challenge, we have proposed an intrinsic constrained evolution to improve the scalability and accelerate the evolution process for VRC-based fault mitigation in mission-critical applications. Experimentation is conducted on complex ACM/SIGDA benchmark circuits and real-time circuits used in space missions, which are not included in related works. In addition, a comparative study is made between existing and proposed methodologies for brushless DC motor control circuits. The hardware utilization in the multiplexer has been significantly reduced, resulting in up to a 77% reduction in the existing VRC architecture. The proposed methodology employs a fault localization approach to narrow the search space effectively. This approach has yielded an 87% improvement on average in convergence speed, as measured by the evolution time, compared to the existing work.},
  archive      = {J_TODAES},
  author       = {Deepanjali S. and Noor Mahammad SK},
  doi          = {10.1145/3634682},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {31:1–29},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Scalable and accelerated self-healing control circuit using evolvable hardware},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeepFlow: A cross-stack pathfinding framework for
distributed AI systems. <em>TODAES</em>, <em>29</em>(2), 30:1–20. (<a
href="https://doi.org/10.1145/3635867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, machine learning model complexity has grown at an extraordinary rate, as has the scale of the systems training such large models. However, there is an alarmingly low hardware utilization (5–20%) in large scale AI systems. The low system utilization is a cumulative effect of minor losses across different layers of the stack, exacerbated by the disconnect between engineers designing different layers spanning across different industries. To address this challenge, in this work we designed a cross-stack performance modelling and design space exploration framework. First, we introduce CrossFlow, a novel framework that enables cross-layer analysis all the way from the technology layer to the algorithmic layer. Next, we introduce DeepFlow (built on top of CrossFlow using machine learning techniques) to automate the design space exploration and co-optimization across different layers of the stack. We have validated CrossFlow’s accuracy with distributed training on real commercial hardware and showcase several DeepFlow case studies demonstrating pitfalls of not optimizing across the technology-hardware-software stack for what is likely the most important workload driving large development investments in all aspects of computing stack.},
  archive      = {J_TODAES},
  author       = {Newsha Ardalani and Saptadeep Pal and Puneet Gupta},
  doi          = {10.1145/3635867},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {30:1–20},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {DeepFlow: A cross-stack pathfinding framework for distributed AI systems},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy-constrained scheduling for weakly hard real-time
systems using standby-sparing. <em>TODAES</em>, <em>29</em>(2), 29:1–35.
(<a href="https://doi.org/10.1145/3631587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For real-time embedded systems, QoS (Quality of Service), fault tolerance, and energy budget constraint are among the primary design concerns. In this research, we investigate the problem of energy constrained standby-sparing for both periodic and aperiodic tasks in a weakly hard real-time environment. The standby-sparing systems adopt a primary processor and a spare processor to provide fault tolerance for both permanent and transient faults. For such kind of systems, we firstly propose several novel standby-sparing schemes for the periodic tasks which can ensure the system feasibility under tighter energy budget constraint than the traditional ones. Then based on them integrated approachs for both periodic and aperiodic tasks are proposed to minimize the aperiodic response time whilst achieving better energy and QoS performance under the given energy budget constraint. The evaluation results demonstrated that the proposed techniques significantly outperformed the existing state-of-the-art approaches in terms of feasibility and system performance while ensuring QoS and fault tolerance under the given energy budget constraint.},
  archive      = {J_TODAES},
  author       = {Linwei Niu and Danda B. Rawat and Jonathan Musselwhite and Zonghua Gu and Qingxu Deng},
  doi          = {10.1145/3631587},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {29:1–35},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Energy-constrained scheduling for weakly hard real-time systems using standby-sparing},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal model partitioning with low-overhead profiling on
the PIM-based platform for deep learning inference. <em>TODAES</em>,
<em>29</em>(2), 28:1–22. (<a
href="https://doi.org/10.1145/3628599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently Processing-in-Memory (PIM) has become a promising solution to achieve energy-efficient computation in data-intensive applications by placing computation near or inside the memory. In most Deep Learning (DL) frameworks, a user manually partitions a model’s computational graph (CG) onto the computing devices by considering the devices’ capability and the data transfer. The Deep Neural Network (DNN) models become increasingly complex for improving accuracy; thus, it is exceptionally challenging to partition the execution to achieve the best performance, especially on a PIM-based platform requiring frequent offloading of large amounts of data. This article proposes two novel algorithms for DL inference to resolve the challenge: low-overhead profiling and optimal model partitioning. First, we reconstruct CG by considering the devices’ capability to represent all the possible scheduling paths. Second, we develop a profiling algorithm to find the required minimum profiling paths to measure all the node and edge costs of the reconstructed CG. Finally, we devise the model partitioning algorithm to get the optimal minimum execution time using the dynamic programming technique with the profiled data. We evaluated our work by executing the BERT, RoBERTa, and GPT-2 models on the ARM multicores with the PIM-modeled FPGA platform with various sequence lengths. For three computing devices in the platform, i.e., CPU serial/parallel and PIM executions, we could find all the costs only in four profile runs, three for node costs and one for edge costs. Also, our model partitioning algorithm achieved the highest performance in all the experiments over the execution with manually assigned device priority and the state-of-the-art greedy approach.},
  archive      = {J_TODAES},
  author       = {Seok Young Kim and Jaewook Lee and Yoonah Paik and Chang Hyun Kim and Won Jun Lee and Seon Wook Kim},
  doi          = {10.1145/3628599},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {2},
  number       = {2},
  pages        = {28:1–22},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Optimal model partitioning with low-overhead profiling on the PIM-based platform for deep learning inference},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RSPP: Restricted static pseudo-partitioning for mitigation
of cross-core covert channel attacks. <em>TODAES</em>, <em>29</em>(2),
27:1–22. (<a href="https://doi.org/10.1145/3637222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cache timing channel attacks exploit the inherent properties of cache memories: hit and miss time along with the shared nature of the cache to leak secret information. The side channel and covert channel are the two well-known cache timing channel attacks. In this article, we propose Restricted Static Pseudo-Partitioning (RSPP), an effective partition-based mitigation mechanism that restricts the cache access of only the adversaries involved in the attack. It has an insignificant impact of only 1% in performance, as the benign processes have access to the full cache and restrictions are limited only to the suspicious processes and cache sets. It can be implemented with a maximum storage overhead of 1.45% of the total Last-Level Cache (LLC) size. This article presents three variations of the proposed attack mitigation mechanism: RSPP, simplified-RSPP (S-RSPP) and corewise-RSPP (C-RSPP) with different hardware overheads. A full system simulator is used for evaluating the performance impact of RSPP. A detailed experimental analysis with different LLC and attack parameters is also discussed. RSPP is also compared with the existing defense mechanisms effective against cross-core covert channel attacks.},
  archive      = {J_TODAES},
  author       = {Jaspinder Kaur and Shirshendu Das},
  doi          = {10.1145/3637222},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {1},
  number       = {2},
  pages        = {27:1–22},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {RSPP: Restricted static pseudo-partitioning for mitigation of cross-core covert channel attacks},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SparGD: A sparse GEMM accelerator with dynamic dataflow.
<em>TODAES</em>, <em>29</em>(2), 26:1–32. (<a
href="https://doi.org/10.1145/3634703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has become a highly popular research field, and previously deep learning algorithms ran primarily on CPUs and GPUs. However, with the rapid development of deep learning, it was discovered that existing processors could not meet the specific large-scale computing requirements of deep learning, and custom deep learning accelerators have become popular. The majority of the primary workloads in deep learning are general matrix-matrix multiplications (GEMMs), and emerging GEMMs are highly sparse and irregular. The TPU and SIGMA are typical GEMM accelerators in recent years, but the TPU does not support sparsity, and both the TPU and SIGMA have insufficient utilization rates of the Processing Element (PE). We design and implement SparGD, a sparse GEMM accelerator with dynamic dataflow. SparGD has specific PE structures, flexible distribution networks and reduction networks, and a simple dataflow switching module. When running sparse and irregular GEMMs, SparGD can maintain high PE utilization while utilizing sparsity, and can switch to the optimal dataflow according to the computing environment. For sparse, irregular GEMMs, our experimental results show that SparGD outperforms systolic arrays by 30 times and SIGMA by 3.6 times.},
  archive      = {J_TODAES},
  author       = {Bo Wang and Sheng Ma and Shengbai Luo and Lizhou Wu and Jianmin Zhang and Chunyuan Zhang and Tiejun Li},
  doi          = {10.1145/3634703},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {1},
  number       = {2},
  pages        = {26:1–32},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {SparGD: A sparse GEMM accelerator with dynamic dataflow},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient reinforcement learning based framework for
exploring logic synthesis. <em>TODAES</em>, <em>29</em>(2), 25:1–33. (<a
href="https://doi.org/10.1145/3632174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logic synthesis is a crucial step in electronic design automation tools. The rapid developments of reinforcement learning (RL) have enabled the automated exploration of logic synthesis. Existing RL based methods may lead to data inefficiency, and the exploration approaches for FPGA and ASIC technology mapping in recent works lack the flexibility of the learning process. This work proposes ESE, a reinforcement learning based framework to efficiently learn the logic synthesis process. The framework supports the modeling of logic optimization and technology mapping for FPGA and ASIC. The optimization for the execution time of the synthesis script is also considered. For the modeling of FPGA mapping, the logic optimization and technology mapping are combined to be learned in a flexible way. For the modeling of ASIC mapping, the standard cell based optimization and LUT optimization operations are incorporated into the ASIC synthesis flow. To improve the utilization of samples, the Proximal Policy Optimization model is adopted. Furthermore, the framework is enhanced by supporting MIG based synthesis exploration. Experiments show that for FPGA technology mapping on the VTR benchmark, the average LUT-Level-Product and script runtime are improved by more than 18.3% and 12.4% respectively than previous works. For ASIC mapping on the EPFL benchmark, the average Area-Delay-Product is improved by 14.5%.},
  archive      = {J_TODAES},
  author       = {Yu Qian and Xuegong Zhou and Hao Zhou and Lingli Wang},
  doi          = {10.1145/3632174},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {1},
  number       = {2},
  pages        = {25:1–33},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {An efficient reinforcement learning based framework for exploring logic synthesis},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic adaptation using deep reinforcement learning for
digital microfluidic biochips. <em>TODAES</em>, <em>29</em>(2), 24:1–24.
(<a href="https://doi.org/10.1145/3633458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe an exciting new application domain for deep reinforcement learning (RL): droplet routing on digital microfluidic biochips (DMFBs). A DMFB consists of a two-dimensional electrode array, and it manipulates droplets of liquid to automatically execute biochemical protocols for clinical chemistry. However, a major problem with DMFBs is that electrodes can degrade over time. The transportation of droplet transportation over these degraded electrodes can fail, thereby adversely impacting the integrity of the bioassay outcome. We demonstrated that the formulation of droplet transportation as an RL problem enables the training of deep neural network policies that can adapt to the underlying health conditions of electrodes and ensure reliable fluidic operations. We describe an RL-based droplet routing solution that can be used for various sizes of DMFBs. We highlight the reliable execution of an epigenetic bioassay with the RL droplet router on a fabricated DMFB. We show that the use of the RL approach on a simple micro-computer (Raspberry Pi 4) leads to acceptable performance for time-critical bioassays. We present a simulation environment based on the OpenAI Gym Interface for RL-guided droplet routing problems on DMFBs. We present results on our study of electrode degradation using fabricated DMFBs. The study supports the degradation model used in the simulator.},
  archive      = {J_TODAES},
  author       = {Tung-Che Liang and Yi-Chen Chang and Zhanwei Zhong and Yaas Bigdeli and Tsung-Yi Ho and Krishnendu Chakrabarty and Richard Fair},
  doi          = {10.1145/3633458},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {1},
  number       = {2},
  pages        = {24:1–24},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Dynamic adaptation using deep reinforcement learning for digital microfluidic biochips},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on approximate multiplier designs for energy
efficiency: From algorithms to circuits. <em>TODAES</em>,
<em>29</em>(1), 23:1–37. (<a
href="https://doi.org/10.1145/3610291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the stringent requirements of energy efficiency for Internet-of-Things edge devices, approximate multipliers, as a basic component of many processors and accelerators, have been constantly proposed and studied for decades, especially in error-resilient applications. The computation error and energy efficiency largely depend on how and where the approximation is introduced into a design. Thus, this article aims to provide a comprehensive review of the approximation techniques in multiplier designs ranging from algorithms and architectures to circuits. We have implemented representative approximate multiplier designs in each category to understand the impact of the design techniques on accuracy and efficiency. The designs can then be effectively deployed in high-level applications, such as machine learning, to gain energy efficiency at the cost of slight accuracy loss.},
  archive      = {J_TODAES},
  author       = {Ying Wu and Chuangtao Chen and Weihua Xiao and Xuan Wang and Chenyi Wen and Jie Han and Xunzhao Yin and Weikang Qian and Cheng Zhuo},
  doi          = {10.1145/3610291},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  month        = {1},
  number       = {1},
  pages        = {23:1–37},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A survey on approximate multiplier designs for energy efficiency: From algorithms to circuits},
  volume       = {29},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
