<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TIST_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tist---135">TIST - 135</h2>
<ul>
<li><details>
<summary>
(2024). Robust recommender systems with rating flip noise.
<em>TIST</em>, <em>16</em>(1), 1–19. (<a
href="https://doi.org/10.1145/3641285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have become important tools in the daily life of human beings since they are powerful to address information overload, and discover relevant and useful items for users. The success of recommender systems largely relies on the interaction history between users and items, which is expected to accurately reflect the preferences of users on items. However, the expectation is easily broken in practice, due to the corruptions made in the interaction history, resulting in unreliable and untrusted recommender systems. Previous works either ignore this issue (assume that the interaction history is precise) or are limited to handling additive noise. Motivated by this, in this paper, we study rating flip noise which widely exists in the interaction history of recommender systems and combat it by modelling the noise generation process. Specifically, the rating flip noise allows a rating to be flipped to any other ratings within the given rating set, which reflects various real-world situations of rating corruption, e.g., a user may randomly click a rating from the rating set and then submit it. The noise generation process is modelled by the noise transition matrix that denotes the probabilities of a clean rating flip into a noisy rating. A statistically consistent algorithm is afterwards applied with the estimated transition matrix to learn a robust recommender system against rating flip noise. Comprehensive experiments on multiple benchmarks confirm the superiority of our method.},
  archive      = {J_TIST},
  doi          = {10.1145/3641285},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Robust recommender systems with rating flip noise},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mitigating the impact of inaccurate feedback in dynamic
learning-to-rank: A study of overlooked interesting items.
<em>TIST</em>, <em>16</em>(1), 1–26. (<a
href="https://doi.org/10.1145/3653983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Learning-to-Rank (DLTR) is a method of updating a ranking policy in real time based on user feedback, which may not always be accurate. Although previous DLTR work has achieved fair and unbiased DLTR under inaccurate feedback, they face the tradeoff between fairness and user utility and also have limitations in the setting of feeding items. Existing DLTR works improve ranking utility by eliminating bias from inaccurate feedback on observed items, but the impact of another pervasive form of inaccurate feedback, overlooked or ignored interesting items, remains unclear. For example, users may browse the rankings too quickly to catch interesting items or miss interesting items because the snippets are not optimized enough. This phenomenon raises two questions: (i) Will overlooked interesting items affect the ranking results? and (ii) Is it possible to improve utility without sacrificing fairness if these effects are eliminated? These questions are particularly relevant for small and medium-sized retailers who are just starting out and may have limited data, leading to the use of inaccurate feedback to update their models. In this article, we find that inaccurate feedback in the form of overlooked interesting items has a negative impact on DLTR performance in terms of utility. To address this, we treat the overlooked interesting items as noise and propose a novel DLTR method, the Co-teaching Rank (CoTeR), that has good utility and fairness performance when inaccurate feedback is present in the form of overlooked interesting items. Our solution incorporates a co-teaching-based component with a customized loss function and data sampling strategy, as well as a mean pooling strategy to further accommodate newly added products without historical data. Through experiments, we demonstrate that CoTeR not only enhances utilities but also preserves ranking fairness and can smoothly handle newly introduced items.},
  archive      = {J_TIST},
  doi          = {10.1145/3653983},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {1},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Mitigating the impact of inaccurate feedback in dynamic learning-to-rank: A study of overlooked interesting items},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving faithfulness and factuality with contrastive
learning in explainable recommendation. <em>TIST</em>, <em>16</em>(1),
1–23. (<a href="https://doi.org/10.1145/3653984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have become increasingly important in navigating the vast amount of information and options available in various domains. By tailoring and personalizing recommendations to user preferences and interests, these systems improve the user experience, efficiency, and satisfaction. With a growing demand for transparency and understanding of recommendation outputs, explainable recommender systems have gained growing attention in recent years. Additionally, as user reviews could be considered the rationales behind why the user likes (or dislikes) the products, generating informative and reliable reviews alongside recommendations has thus emerged as a research focus in explainable recommendation. However, the model-generated reviews might contain factually inconsistent contents (i.e., the hallucination issue), which would thus compromise the recommendation rationales. To address this issue, we propose a contrastive learning framework to improve the faithfulness and factuality in explainable recommendation in this article. We further develop different strategies of generating positive and negative examples for contrastive learning, such as back-translation or synonym substitution for positive examples, and editing positive examples or utilizing model-generated texts for negative examples. Our proposed method optimizes the model to distinguish faithful explanations (i.e., positive examples) and unfaithful ones with factual errors (i.e., negative examples), which thus drives the model to generate faithful reviews as explanations while avoiding inconsistent contents. Extensive experiments and analysis on three benchmark datasets show that our proposed model outperforms other review generation baselines in faithfulness and factuality. In addition, the proposed contrastive learning component could be easily incorporated into other explainable recommender systems in a plug-and-play manner.},
  archive      = {J_TIST},
  doi          = {10.1145/3653984},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Improving faithfulness and factuality with contrastive learning in explainable recommendation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Popularity bias in correlation graph-based API
recommendation for mashup creation. <em>TIST</em>, <em>16</em>(1), 1–18.
(<a href="https://doi.org/10.1145/3654445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosive growth of the Application Programming Interfaces (APIs) economy in recent years has led to a dramatic increase in available APIs. Mashup development, a dominant approach for creating data-centric applications based on APIs, has experienced a surge in popularity. However, the vast array of choices poses a challenge for mashup developers when selecting appropriate API compositions to meet specific business requirements. Correlation graph-based recommendation approaches have been designed to assist developers in discovering related and compatible API compositions for mashup creation. Unfortunately, these approaches often suffer from popularity bias issues, leading to an inequality in API usage and potential disruptions to the entire API ecosystem. To address these challenges, our research begins with a theoretical analysis of the popularity bias introduced by correlation graph-based API recommendation approaches. Subsequently, we empirically validate the presence of popularity bias in API recommendations through a data-driven study. Finally, we introduce the p opularity b ias aware w eb A PI r ecommendation ( PB-WAR ) approach to mitigate popularity bias in correlation graph-based API recommendations. Experimental results over a real-world dataset demonstrate that PB-WAR offers the optimal tradeoff between accuracy and debiasing performance compared to other competitive methods.},
  archive      = {J_TIST},
  doi          = {10.1145/3654445},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Popularity bias in correlation graph-based API recommendation for mashup creation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GNNUERS: Fairness explanation in GNNs for recommendation via
counterfactual reasoning. <em>TIST</em>, <em>16</em>(1), 1–26. (<a
href="https://doi.org/10.1145/3655631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, research into personalization has been focusing on explainability and fairness. Several approaches proposed in recent works are able to explain individual recommendations in a post-hoc manner or by explanation paths. However, explainability techniques applied to unfairness in recommendation have been limited to finding user/item features mostly related to biased recommendations. In this article, we devised a novel algorithm that leverages counterfactuality methods to discover user unfairness explanations in the form of user-item interactions. In our counterfactual framework, interactions are represented as edges in a bipartite graph, with users and items as nodes. Our bipartite graph explainer perturbs the topological structure to find an altered version that minimizes the disparity in utility between the protected and unprotected demographic groups. Experiments on four real-world graphs coming from various domains showed that our method can systematically explain user unfairness on three state-of-the-art GNN-based recommendation models. Moreover, an empirical evaluation of the perturbed network uncovered relevant patterns that justify the nature of the unfairness discovered by the generated explanations. The source code and the preprocessed data sets are available at https://github.com/jackmedda/RS-BGExplainer .},
  archive      = {J_TIST},
  doi          = {10.1145/3655631},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {1},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {GNNUERS: Fairness explanation in GNNs for recommendation via counterfactual reasoning},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A trustworthy and responsible decision-making framework for
resource management in food–energy–water nexus: A control-theoretical
approach. <em>TIST</em>, <em>16</em>(1), 1–29. (<a
href="https://doi.org/10.1145/3660640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a hybrid framework for trustworthy and responsible natural resource management, aimed at building bottom-up trust to enhance cooperation among decision-makers in the food, energy, and water sectors. Cooperation is highly critical for the adoption and application of resource management alternatives (solutions), including those generated by AI-based recommender systems, in communities due to significant impact of these sectors on the environment and the economic productivity of affected communities. While algorithms can recommend solutions, effectively communicating and gaining community acceptance of these solutions is crucial. Our research stands out by emphasizing the collaboration between humans and machines, which is essential for addressing broader challenges related to climate change and the need for expert tradeoff handling in the management of natural resources. To support future decision-making, we propose a successful control-theory model based on previous decision-making and actor behavior. We utilize control theory to depict how community decisions can be affected by how much individuals trust and accept proposed solutions on irrigation water rights and crop operations in an iterative and interactive decision support environment. This model interacts with stakeholders to collect their feedback on the acceptability of solutions, while also examining the influence of consensus levels, trust sensitivities, and the number of decision-making rounds on the acceptance of proposed solutions. Furthermore, we investigate a system of multiple decision-making and explore the impact of learning actors who adjust their trust sensitivities based on solution acceptance and the number of decision-making rounds. Additionally, our approach can be employed to evaluate and refine potential policy modifications. Although we assess potential outcomes using hypothetical actions by individuals, it is essential to emphasize our primary objective of developing a tool that accurately captures real human behavior and fosters improved collaboration in community decision-making. Ultimately, our aim is to enhance the harmony between AI-based recommender systems and human values, promoting a deeper understanding and integration between the two.},
  archive      = {J_TIST},
  doi          = {10.1145/3660640},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {1},
  pages        = {1-29},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A trustworthy and responsible decision-making framework for resource management in Food–Energy–Water nexus: A control-theoretical approach},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fair projections as a means toward balanced recommendations.
<em>TIST</em>, <em>16</em>(1), 1–32. (<a
href="https://doi.org/10.1145/3664929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of recommender systems is to provide to users suggestions that match their interests, with the eventual goal of increasing their satisfaction, as measured by the number of transactions (clicks, purchases, and so forth). Often, this leads to providing recommendations that are of a particular type. For some contexts (e.g., browsing videos for information) this may be undesirable, as it may enforce the creation of filter bubbles. This is because of the existence of underlying bias in the input data of prior user actions. Reducing hidden bias in the data and ensuring fairness in algorithmic data analysis has recently received significant attention. In this article, we consider both the densest subgraph and the \(k\) -clustering problem, two primitives that are being used by some recommender systems. We are given a coloring on the nodes, respectively the points, and aim to compute a fair solution \(S\) , consisting of a subgraph or a clustering, such that none of the colors is disparately impacted by the solution. Unfortunately, introducing fair solutions typically makes these problems substantially more difficult. Unlike the unconstrained densest subgraph problem, which is solvable in polynomial time, the fair densest subgraph problem is NP-hard even to approximate, which means that with the standard computational model it is probably impossible to solve (or even approximate it sufficiently well) in polynomial time. For \(k\) -clustering, the fairness constraints make the problem very similar to capacitated clustering, which is a notoriously hard problem to even approximate. Despite such negative premises, we are able to provide positive results in important use cases. In particular, we are able to prove that a suitable spectral embedding allows recovery of an almost optimal, fair, dense subgraph hidden in the input data, whenever one is present, a result that is further supported by experimental evidence. We also show a polynomial-time, \(2\) -approximation algorithm to the problem of fair densest subgraph, assuming that there exist only two colors and both colors occur equally often in the graph. This result turns out to be optimal assuming the small set expansion hypothesis. For fair \(k\) -clustering, we show that we can recover high quality fair clusterings effectively and efficiently. For the special case of \(k\) -median and \(k\) -center, we offer additional, fast and simple approximation algorithms as well as new hardness results. The above theoretical findings drive the design of heuristics, which we experimentally evaluate on a scenario based on real data, in which our aim is to strike a good balance between diversity and highly correlated items from Amazon co-purchasing graphs and Facebook contacts. We additionally evaluated our algorithmic solutions for the fair \(k\) -median problem through experiments on various real-world datasets.},
  archive      = {J_TIST},
  doi          = {10.1145/3664929},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {1},
  pages        = {1-32},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Fair projections as a means toward balanced recommendations},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A federated social recommendation approach with enhanced
hypergraph neural network. <em>TIST</em>, <em>16</em>(1), 1–23. (<a
href="https://doi.org/10.1145/3665931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the development of online social network platforms has led to increased research efforts in social recommendation systems. Unlike traditional recommendation systems, social recommendation systems utilize both user-item interactions and user-user social relations to recommend relevant items, taking into account social homophily and social influence. Graph neural network (GNN)-based social recommendation methods have been proposed to model these item interactions and social relations effectively. However, existing GNN-based methods rely on centralized training, which raises privacy concerns and faces challenges in data collection due to regulations and privacy restrictions. Federated learning has emerged as a privacy-preserving alternative. Combining federated learning with GNN-based methods for social recommendation can leverage their respective advantages, but it also introduces new challenges: (1) existing federated recommendation systems often lack the capability to process heterogeneous data, such as user-item interactions and social relations; (2) due to the sparsity of data distributed across different clients, capturing the higher-order relationship information among users becomes challenging and is often overlooked by most federated recommendation systems. To overcome these challenges, we propose a federated social recommendation approach with enhanced hypergraph neural network (HGNN). We introduce HGNN to learn user and item embeddings in federated recommendation systems, leveraging the hypergraph structure to address the heterogeneity of data. Based on carefully crafted triangular motifs, we merge user and item nodes to construct hypergraphs on local clients, capturing specific triangular relations. Multiple HGNN channels are used to encode different categories of high-order relations, and an attention mechanism is applied to aggregate the embedded information from these channels. Our experiments on real-world social recommendation datasets demonstrate the effectiveness of the proposed approach. Extensive experiment results on three publicly available datasets validate the effectiveness of the proposed method.},
  archive      = {J_TIST},
  doi          = {10.1145/3665931},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A federated social recommendation approach with enhanced hypergraph neural network},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeepSneak: User GPS trajectory reconstruction from federated
route recommendation models. <em>TIST</em>, <em>16</em>(1), 1–22. (<a
href="https://doi.org/10.1145/3670412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized machine learning, such as Federated Learning (FL), is widely adopted in many application domains. Especially in domains like recommendation systems, sharing gradients instead of private data has recently caught the research community’s attention. Personalized travel route recommendation utilizes users’ location data to recommend optimal travel routes. Location data is extremely privacy sensitive, presenting increased risks of exposing behavioral patterns and demographic attributes. FL for route recommendation can mitigate the sharing of location data. However, this article shows that an adversary can recover the user trajectories used to train the federated recommendation models with high proximity accuracy. To this effect, we propose a novel attack called DeepSneak, which uses shared gradients obtained from global model training in FL to reconstruct private user trajectories. We formulate the attack as a regression problem and train a generative model by minimizing the distance between gradients. We validate the success of DeepSneak on two real-world trajectory datasets. The results show that we can recover the location trajectories of users with reasonable spatial and semantic accuracy.},
  archive      = {J_TIST},
  doi          = {10.1145/3670412},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {DeepSneak: User GPS trajectory reconstruction from federated route recommendation models},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Special issue on responsible recommender systems part 2.
<em>TIST</em>, <em>16</em>(1), 1–3. (<a
href="https://doi.org/10.1145/3689367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TIST},
  doi          = {10.1145/3689367},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {1},
  pages        = {1-3},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Special issue on responsible recommender systems part 2},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring dataset bias and scaling techniques in
multi-source gait biomechanics: An explainable machine learning
approach. <em>TIST</em>, <em>16</em>(1), 1–19. (<a
href="https://doi.org/10.1145/3702646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has become increasingly important in biomechanics. It allows to unveil hidden patterns from large and complex data, which leads to a more comprehensive understanding of biomechanical processes and deeper insights into human movement. However, machine learning models are often trained on a single dataset with a limited number of participants, which negatively affects their robustness and generalizability. Combining data from multiple existing sources provides an opportunity to overcome these limitations without spending more time on recruiting participants and recording new data. It is furthermore an opportunity for researchers who lack the financial requirements or laboratory equipment to conduct expensive motion capture studies themselves. At the same time, subtle interlaboratory differences can be problematic in an analysis due to the bias that they introduce. In our study, we investigated differences in motion capture datasets in the context of machine learning, for which we combined overground walking trials from four existing studies. Specifically, our goal was to examine whether a machine learning model was able to predict the original data source based on marker and GRF trajectories of single strides and how different scaling methods and pooling procedures affected the outcome. Layer-wise relevance propagation was applied to understand which factors were influential to distinguish the original data sources. We found that the model could predict the original data source with a very high accuracy (up to \({\gt}\) 99%), which decreased by about 15 percentage points when we scaled every dataset individually prior to pooling. However, none of the proposed scaling methods could fully remove the dataset bias. Layer-wise relevance propagation revealed that there was not only one single factor that differed between all datasets. Instead, every dataset had its unique characteristics that were picked up by the model. These variables differed between the scaling and pooling approaches but were mostly consistent between trials belonging to the same dataset. Our results show that motion capture data is sensitive even to small deviations in marker placement and experimental setup and that small inter-group differences should not be overinterpreted during data analysis, especially when the data was collected in different labs. Furthermore, we recommend scaling datasets individually prior to pooling them which led to the lowest accuracy. We want to raise awareness that differences in datasets always exist and are recognizable by machine learning models. Researchers should thus think about how these differences might affect their results when combining data from different studies.},
  archive      = {J_TIST},
  doi          = {10.1145/3702646},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Exploring dataset bias and scaling techniques in multi-source gait biomechanics: An explainable machine learning approach},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adversarial missingness attacks on causal structure
learning. <em>TIST</em>, <em>15</em>(6), 1–60. (<a
href="https://doi.org/10.1145/3682065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality-informed machine learning has been proposed as an avenue for achieving many of the goals of modern machine learning, from ensuring generalization under domain shifts to attaining fairness, robustness, and interpretability. A key component of causal machine learning is the inference of causal structures from observational data; in practice, this data may be incompletely observed. Prior work has demonstrated that adversarial perturbations of completely observed training data may be used to force the learning of inaccurate structural causal models (SCMs). However, when the data can be audited for correctness (e.g., it is cryptographically signed by its source), this adversarial mechanism is invalidated. This work introduces a novel attack methodology wherein the adversary deceptively omits a portion of the true training data to bias the learned causal structures in a desired manner (under strong signed sample input validation, this behavior seems to be the only strategy available to the adversary). Under this model, theoretically sound attack mechanisms are derived for the case of arbitrary SCMs, and a sample-efficient learning-based heuristic is given. Experimental validation of these approaches on real and synthetic datasets, across a range of SCMs from the family of additive noise models (linear Gaussian, linear non-Gaussian, and non-linear Gaussian), demonstrates the effectiveness of adversarial missingness attacks at deceiving popular causal structure learning algorithms.},
  archive      = {J_TIST},
  doi          = {10.1145/3682065},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {6},
  pages        = {1-60},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Adversarial missingness attacks on causal structure learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FastRx: Exploring fastformer and memory-augmented graph
neural networks for personalized medication recommendations.
<em>TIST</em>, <em>15</em>(6), 1–21. (<a
href="https://doi.org/10.1145/3696111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized medication recommendations aim to suggest a set of medications based on the clinical conditions of a patient. Not only should the patient’s diagnosis, procedure, and medication history be considered, but drug-drug interactions (DDIs) must also be taken into account to prevent adverse drug reactions. Although recent studies on medication recommendation have considered DDIs and patient history, personalized disease progression and prescription have not been explicitly modeled. In this work, we proposed FastRx, a Fastformer-based medication recommendation model to capture longitudinality in patient history, in combination with Graph Convolutional Networks (GCNs) to handle DDIs and co-prescribed medications in Electronic Health Records (EHRs). Our extensive experiments on the MIMIC-III dataset demonstrated superior performance of the proposed FastRx over existing state-of-the-art models for medication recommendation. The source code and data used in the experiments are available at https://github.com/pnmthaoct/FastRx.},
  archive      = {J_TIST},
  doi          = {10.1145/3696111},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {6},
  pages        = {1-21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {FastRx: Exploring fastformer and memory-augmented graph neural networks for personalized medication recommendations},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). User opinion-focused abstractive summarization using
explainable artificial intelligence. <em>TIST</em>, <em>15</em>(6),
1–20. (<a href="https://doi.org/10.1145/3696456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent methodologies have achieved good performance in objectively summarizing important information from fact-based datasets such as Extreme Summarization and CNN Daily Mail. These methodologies involve abstractive summarization, extracting the core content from an input text and transforming it into natural sentences. Unlike fact-based documents, opinion-based documents require a thorough analysis of sentiment and understanding of the writer’s intention. However, existing models do not explicitly consider these factors. Therefore, in this study, we propose a novel text summarization model that is specifically designed for opinion-based documents. Specifically, we identify the sentiment distribution of the entire document and train the summarization model to focus on major opinions that conform to the intended message while randomly masking minor opinions. Experimental results show that the proposed model outperforms existing summarization models in summarizing opinion-based documents, effectively capturing and highlighting the main opinions in the generated abstractive summaries.},
  archive      = {J_TIST},
  doi          = {10.1145/3696456},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {6},
  pages        = {1-20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {User opinion-focused abstractive summarization using explainable artificial intelligence},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few images, many insights: Illicit content detection using a
limited number of images. <em>TIST</em>, <em>15</em>(6), 1–26. (<a
href="https://doi.org/10.1145/3696458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The anonymity and untraceability benefits of the dark web increased its popularity exponentially. The cost of these technical benefits is that such anonymity has created a suitable womb for illicit activity. Hence—in collaboration with cybersecurity practitioners and law-enforcement agencies—the research community provided approaches for recognizing and classifying illicit activities. Most of these approaches exploit textual content from dark web markets, whereas few used images that originated from them. This article investigates alternative techniques for recognizing illegal activities from images. The significant contributions of our work are threefold: (a) We investigate label-agnostic learning techniques like One-Shot and Few-Shot learning that use Siamese Neural Networks. Our approach manages to handle small-scale datasets with promising accuracy. In particular, the Siamese Neural Network approach reaches 90.9% on 5-Shot experiments over a 10-class dataset. (b) This study’s satisfactory findings facilitate the creation of potent tools to assist authorities in identifying illicit content on the Web. Moreover, our proof-of-concept approach demonstrated the ability to recognize illegal images using a limited number of files, reducing the time constraint in collecting illegal images. (c) We provide a complete labeled dataset of 3,570 images from 55 different categories from dark web markets that can be used for future research activities.},
  archive      = {J_TIST},
  doi          = {10.1145/3696458},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {6},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Few images, many insights: Illicit content detection using a limited number of images},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple-instance learning from pairwise comparison bags.
<em>TIST</em>, <em>15</em>(6), 1–22. (<a
href="https://doi.org/10.1145/3696460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple-instance learning (MIL) is a significant weakly supervised learning problem, where the training data consist of bags containing multiple instances and bag-level labels. Most previous MIL research required fully labeled bags. However, collecting such data is challenging due to the labeling costs or privacy concerns. Fortunately, we can easily collect pairwise comparison information, indicating one bag is more likely to be positive than the other. Therefore, we investigate a novel MIL problem about learning a bag-level binary classifier only from pairwise comparison bags. To solve this problem, we display the data generation process and provide a baseline method to train an instance-level classifier based on unlabeled-unlabeled learning. To achieve better performance, we propose a convex formulation to train a bag-level classifier and give a generalization error bound. Comprehensive experiments show that both the baseline method and the convex formulation achieve satisfactory performance, while the convex formulation performs better. 1},
  archive      = {J_TIST},
  doi          = {10.1145/3696460},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {6},
  pages        = {1-22},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Multiple-instance learning from pairwise comparison bags},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Question-attentive review-level explanation for neural
rating regression. <em>TIST</em>, <em>15</em>(6), 1–25. (<a
href="https://doi.org/10.1145/3699516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation explanations help to improve their acceptance by end users. Explanations come in many different forms. One that is of interest here is presenting an existing review of the recommended item as the explanation. The challenge is in selecting a suitable review, which is customarily addressed by assessing the relative importance or “attention” of each review to the recommendation objective. Our focus is improving review-level explanation by leveraging additional information in the form of questions and answers (QA). The proposed framework employs QA in an attention mechanism that aligns reviews to various QAs of an item and assesses their contribution jointly to the recommendation objective. The benefits are two-fold. For one, QA aids in selecting more useful reviews. For another, QA itself could accompany a well-aligned review in an expanded form of explanation. Experiments on datasets of 10 product categories showcase the efficacies of our method as compared to comparable baselines in identifying useful reviews and QAs, while maintaining parity in recommendation performance.},
  archive      = {J_TIST},
  doi          = {10.1145/3699516},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {6},
  pages        = {1-25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Question-attentive review-level explanation for neural rating regression},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OptiRet-net: An optimized low-light image enhancement
technique for CV-based applications in resource-constrained
environments. <em>TIST</em>, <em>15</em>(6), 1–30. (<a
href="https://doi.org/10.1145/3700136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The illumination of images can significantly impact computer-vision applications such as image classification, multiple object detection, and tracking, leading to a significant decline in detection and tracking accuracy. Recent advancements in deep learning techniques have been applied to Low-Light Image Enhancement (LLIE) to combat this issue. Retinex theory-based methods following a decomposition-adjustment pipeline for LLIE have performed well in various aspects. Despite their success, current research on Retinex-based deep learning still needs to improve in terms of optimization techniques and complicated convolution connections, which can be computationally intensive for end-device deployment. We propose an Optimized Retinex-Based CNN (OptiRet-Net) deep learning framework to address these challenges for the LLIE problem. Our results demonstrate that the proposed method outperforms existing state-of-the-art models in terms of full reference metrics with a PSNR of 21.87, SSIM of 0.80, LPIPS of 0.16, and zero reference metrics with a NIQE of 3.4 and PIQE of 56.6. Additionally, we validate our approach using a comprehensive evaluation comprising five datasets and nine prior methods. Furthermore, we assess the efficacy of our proposed model combining low-light multiple object tracking applications using YOLOX and ByteTrack in Versatile Video Coding (VVC/H.266) across various quantization parameters. Our findings reveal that LLIE-enhanced frames surpass their tracking results with a MOTA of 80.6% and a remarkable precision rate of 96%. Our model also achieves minimal file sizes by effectively compressing the enhanced low-light images while maintaining their quality, making it suitable for resource-constrained environments where storage or bandwidth limitations are a concern.},
  archive      = {J_TIST},
  doi          = {10.1145/3700136},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {6},
  pages        = {1-30},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {OptiRet-net: An optimized low-light image enhancement technique for CV-based applications in resource-constrained environments},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An unbiased risk estimator for partial label learning with
augmented classes. <em>TIST</em>, <em>15</em>(6), 1–22. (<a
href="https://doi.org/10.1145/3700137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Label Learning (PLL) is a typical weakly supervised learning task, which assumes each training instance is annotated with a set of candidate labels containing the ground-truth label. Recent PLL methods adopt identification-based disambiguation to alleviate the influence of false positive labels and achieve promising performance. However, they require all classes in the test set to have appeared in the training set, ignoring the fact that new classes will keep emerging in real applications. To address this issue, in this article, we focus on the problem of Partial Label Learning with Augmented Class (PLLAC), where one or more augmented classes are not visible in the training stage but appear in the inference stage. Specifically, we propose an unbiased risk estimator with theoretical guarantees for PLLAC, which estimates the distribution of augmented classes by differentiating the distribution of known classes from unlabeled data and can be equipped with arbitrary PLL loss functions. Besides, we provide a theoretical analysis of the estimation error bound of the estimator, which guarantees the convergence of the empirical risk minimizer to the true risk minimizer as the number of training data tends to infinity. Furthermore, we add a risk-penalty regularization term in the optimization objective to alleviate the influence of the over-fitting issue caused by negative empirical risk. Extensive experiments on benchmark, UCI, and real-world datasets demonstrate the effectiveness of the proposed approach.},
  archive      = {J_TIST},
  doi          = {10.1145/3700137},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {6},
  pages        = {1-22},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {An unbiased risk estimator for partial label learning with augmented classes},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing privacy, utility, and efficiency in a constrained
multi-objective federated learning framework. <em>TIST</em>,
<em>15</em>(6), 1–33. (<a
href="https://doi.org/10.1145/3701039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventionally, federated learning aims to optimize a single objective, typically the utility. However, for a federated learning system to be trustworthy, it needs to simultaneously satisfy multiple objectives, such as maximizing model performance, minimizing privacy leakage and training costs, and being robust to malicious attacks. Multi-Objective Optimization (MOO) aiming to optimize multiple conflicting objectives simultaneously is quite suitable for solving the optimization problem of Trustworthy Federated Learning (TFL). In this article, we unify MOO and TFL by formulating the problem of constrained multi-objective federated learning (CMOFL). Under this formulation, existing MOO algorithms can be adapted to TFL straightforwardly. Different from existing CMOFL algorithms focusing on utility, efficiency, fairness, and robustness, we consider optimizing privacy leakage along with utility loss and training cost, the three primary objectives of a TFL system. We develop two improved CMOFL algorithms based on NSGA-II and PSL, respectively, to effectively and efficiently find Pareto optimal solutions and provide theoretical analysis on their convergence. We design quantitative measurements of privacy leakage, utility loss, and training cost for three privacy protection mechanisms: Randomization, BatchCrypt (an efficient homomorphic encryption), and Sparsification. Empirical experiments conducted under the three protection mechanisms demonstrate the effectiveness of our proposed algorithms.},
  archive      = {J_TIST},
  doi          = {10.1145/3701039},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {6},
  pages        = {1-33},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Optimizing privacy, utility, and efficiency in a constrained multi-objective federated learning framework},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proposal semantic relationship graph network for temporal
action detection. <em>TIST</em>, <em>15</em>(6), 1–24. (<a
href="https://doi.org/10.1145/3702233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal action detection, a critical task in video activity understanding, is typically divided into two stages: proposal generation and classification. However, most existing methods overlook the importance of information transfer among proposals during classification, often treating each proposal in isolation, which hampers accurate label prediction. In this article, we propose a novel method for inferring semantic relationships both within and between action proposals, guiding the fusion of action proposal features accordingly. Building on this approach, we introduce the Proposal Semantic Relationship Graph Network (PSRGN), an end-to-end model that leverages intra-proposal semantic relationship graphs to extract cross-scale temporal context and an inter-proposal semantic relationship graph to incorporate complementary neighboring information, significantly improving proposal feature quality and overall detection performance. This is the first method to apply graph structure learning in temporal action detection, adaptively constructing the inter-proposal semantic graph. Extensive experiments on two datasets demonstrate the effectiveness of our approach, achieving state-of-the-art (SOTA). Code and results are available at http://github.com/Riiick2011/PSRGN .},
  archive      = {J_TIST},
  doi          = {10.1145/3702233},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {12},
  number       = {6},
  pages        = {1-24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Proposal semantic relationship graph network for temporal action detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated learning survey: A multi-level taxonomy of
aggregation techniques, experimental insights, and future frontiers.
<em>TIST</em>, <em>15</em>(6), 1–69. (<a
href="https://doi.org/10.1145/3678182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging integration of Internet of Things (IoT) and AI has unlocked numerous opportunities for innovation across diverse industries. However, growing privacy concerns and data isolation issues have inhibited this promising advancement. Unfortunately, traditional centralized Machine Learning (ML) methods have demonstrated their limitations in addressing these hurdles. In response to this ever-evolving landscape, Federated Learning (FL) has surfaced as a cutting-edge ML paradigm, enabling collaborative training across decentralized devices. FL allows users to jointly construct AI models without sharing their local raw data, ensuring data privacy, network scalability, and minimal data transfer. One essential aspect of FL revolves around proficient knowledge aggregation within a heterogeneous environment. Yet, the inherent characteristics of FL have amplified the complexity of its practical implementation compared to centralized ML. This survey delves into three prominent clusters of FL research contributions: personalization, optimization, and robustness. The objective is to provide a well-structured and fine-grained classification scheme related to these research areas through a unique methodology for selecting related work. Unlike other survey papers, we employed a hybrid approach that amalgamates bibliometric analysis and systematic scrutinizing to find the most influential work in the literature. Therefore, we examine challenges and contemporary techniques related to heterogeneity, efficiency, security, and privacy. Another valuable asset of this study is its comprehensive coverage of FL aggregation strategies, encompassing architectural features, synchronization methods, and several federation motivations. To further enrich our investigation, we provide practical insights into evaluating novel FL proposals and conduct experiments to assess and compare aggregation methods under IID and non-IID data distributions. Finally, we present a compelling set of research avenues that call for further exploration to open up a treasure of advancement.},
  archive      = {J_TIST},
  doi          = {10.1145/3678182},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-69},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Federated learning survey: A multi-level taxonomy of aggregation techniques, experimental insights, and future frontiers},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward ubiquitous interaction-attentive and extreme-aware
crowd activity level prediction. <em>TIST</em>, <em>15</em>(6), 1–26.
(<a href="https://doi.org/10.1145/3682063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of citywide crowd activity levels (CALs), i.e., the numbers of participants of citywide crowd activities under different venue categories at certain time and locations, is essential for the city management, the personal service applications, and the entrepreneurs in commercial strategic planning. Existing studies have not thoroughly taken into account the complex spatial and temporal interactions among different categories of CALs and their extreme occurrences, leading to lowered adaptivity and accuracy of their models. To address above concerns, we have proposed IE-CALP , a novel spatio-temporal I nteractive attention-based and E xtreme-aware model for C rowd A ctivity L evel P rediction. The tasks of IE-CALP consist of (a) forecasting the spatial distributions of various CALs at different city regions (spatial CALs), and (b) predicting the number of participants per category of the CALs (categorical CALs). To realize above, we have designed a novel spatial CAL-POI interaction-attentive learning component in IE-CALP to model the spatial interactions across different CAL categories, as well as those among the spatial urban regions and CALs. In addition, IE-CALP incorporate the multi-level trends (e.g., daily and weekly levels of temporal granularity) of CALs through a multi-level temporal feature learning component. Furthermore, to enhance the model adaptivity to extreme CALs (e.g., during extreme urban events or weather conditions), we further take into account the extreme value theory and model the impacts of historical CALs upon the occurrences of extreme CALs. Extensive experiments upon a total of 738,715 CAL records and 246,660 POIs in New York City (NYC), Los Angeles (LA), and Tokyo have further validated the accuracy, adaptivity, and effectiveness of IE-CALP ’s interaction-attentive and extreme-aware CAL predictions.},
  archive      = {J_TIST},
  doi          = {10.1145/3682063},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Toward ubiquitous interaction-attentive and extreme-aware crowd activity level prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified framework for analyzing textual context and intent
in social media. <em>TIST</em>, <em>15</em>(6), 1–25. (<a
href="https://doi.org/10.1145/3682064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of natural language processing, tasks like emotion recognition, irony detection, hate speech detection, offensive language identification, and stance detection are pivotal for understanding user-generated content. While several task-specific and multitask learning models have been proposed, there remains a need for a unified framework that can effectively address these tasks simultaneously. This research introduces a novel unified framework designed to tackle multiple NLP tasks concurrently, aiming to outperform existing task-specific and multitask models in terms of accuracy, F1-score, and AUC-ROC. We compared our proposed framework against several baseline models, including task-specific models like SVM, RF, LSTM, CNN, and BERT, as well as multitask learning frameworks such as Hard Parameter Sharing, Soft Parameter Sharing, Cross-stitch Networks, MMoE, and T5. The performance was evaluated across various tasks, and statistical significance was assessed using the Wilcoxon signed-rank test. Additionally, an ablation study was conducted to determine the contribution of individual components within our proposed method. The proposed framework consistently outperformed other models across all tasks. For instance, in emotion recognition, our model achieved an accuracy of 0.899, F1-score of 0.883, and AUC-ROC of 0.971, surpassing all baseline models. The Wilcoxon signed-rank test further confirmed the statistical superiority of our model over the baselines across all datasets.},
  archive      = {J_TIST},
  doi          = {10.1145/3682064},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A unified framework for analyzing textual context and intent in social media},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intermediary-generated bridge network for RGB-d cross-modal
re-identification. <em>TIST</em>, <em>15</em>(6), 1–25. (<a
href="https://doi.org/10.1145/3682066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D cross-modal person re-identification (re-id) targets at retrieving the person of interest across RGB and depth image modalities. To cope with the modal discrepancy, some existing methods generate an auxiliary mode with either inherent properties of input modes or extra deep networks. However, such useful intermediary role included in generated mode is often overlooked in these approaches, leading to insufficient exploitation of crucial bridge knowledge. By contrast, in this article, we propose a novel approach that constructs an intermediary mode through the constraints of self-supervised intermediary learning, which is freedom from modal prior knowledge and additional module parameters. We then design a bridge network to fully mine the intermediary role of generated modality through carrying out multi-modal integration and decomposition. For one thing, this network leverages a multi-modal transformer to integrate the information of three modes via fully exploiting their heterogeneous relations with the intermediary mode as the bridge. It conducts the identification consistency constraint to promote cross-modal associations. For another, it employs circle contrastive learning to decompose the cross-modal constraint process into several subprocedures, which provides the intermediate relay during pulling two original modalities closer. Experiments on two public datasets demonstrate that the proposed method exceeds the state-of-the-arts. The effectiveness of each component in this method is verified through numerous ablation studies. Additionally, we have demonstrated the generalization ability of the proposed method through experiments.},
  archive      = {J_TIST},
  doi          = {10.1145/3682066},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Intermediary-generated bridge network for RGB-D cross-modal re-identification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficiently gluing pre-trained language and vision models
for image captioning. <em>TIST</em>, <em>15</em>(6), 1–16. (<a
href="https://doi.org/10.1145/3682067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-and-language pre-training models have achieved impressive performance for image captioning. But most of them are trained with millions of paired image-text data and require huge memory and computing overhead. To alleviate this, we try to stand on the shoulders of large-scale pre-trained language models (PLM) and pre-trained vision models (PVM) and efficiently connect them for image captioning. There are two major challenges: one is that language and vision modalities have different semantic granularity (e.g., a noun may cover many pixels), and the other is that the semantic gap still exists between the pre-trained language and vision models. To this end, we design a lightweight and efficient connector to glue PVM and PLM, which holds a criterion of selection-then-transformation . Specifically, in the selection phase, we treat each image as a set of patches instead of pixels. We select salient image patches and cluster them into visual regions to align with text. Then, to effectively reduce the semantic gap, we propose to map the selected image patches into text space through spatial and channel transformations. With training on image captioning datasets, the connector learns to bridge the semantic granularity and semantic gap via backpropagation, preparing for the PLM to generate descriptions. Experimental results on the MSCOCO and Flickr30k datasets demonstrate that our method yields comparable performance to existing works. By solely training the small connector, we achieve a CIDEr performance of 132.2% on the MSCOCO Karpathy test split. Moreover, our findings reveal that fine-tuning the PLM can further enhance performance potential, resulting in a CIDEr score of 140.6%. Code and models are available at https://github.com/YuanEZhou/PrefixCap .},
  archive      = {J_TIST},
  doi          = {10.1145/3682067},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-16},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Efficiently gluing pre-trained language and vision models for image captioning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Surveying more than two decades of music information
retrieval research on playlists. <em>TIST</em>, <em>15</em>(6), 1–68.
(<a href="https://doi.org/10.1145/3688398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present an extensive survey of music information retrieval (MIR) research into music playlists. Our survey spans more than 20 years, and includes around 300 papers about playlists, with over 70 supporting sources. It is the first survey that is self-contained in the sense that it combines all the different MIR research into playlists. It embraces topics such as algorithms for automatic generation, for automatic continuation, for assisting with manual generation, for tagging and for captioning. It looks at manually constructed playlists, both those that are constructed for and by individuals and those constructed in collaboration with others. It covers ground-breaking research into enhancing playlists by cross-fading consecutive songs and by interleaving consecutive songs with speech, similar to what happens on a radio show. Most significantly, it is the first survey that can fully incorporate the paradigm shift that has taken place in the way people consume recorded music: the shift from physical media to music streaming. This has wrought profound changes in the size of music collections available to listeners and thus the algorithms that support the construction, curation and presentation of playlists and the methods adopted by users when they also construct, curate and listen to playlists.},
  archive      = {J_TIST},
  doi          = {10.1145/3688398},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-68},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Surveying more than two decades of music information retrieval research on playlists},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relation constrained capsule graph neural networks for
non-rigid shape correspondence. <em>TIST</em>, <em>15</em>(6), 1–26. (<a
href="https://doi.org/10.1145/3688851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-rigid 3D shape correspondence aims to establish dense correspondences between two non-rigidly deformed 3D shapes. However, the variability and symmetry of non-rigid shapes usually lead to mismatches due to shape deformation, topological changes, or data with severe noise. To finding an accurate correspondence between 3D dynamic shapes for the local deformation complexity, this article proposes a Relation Constrained Capsule Graph Network (RC-CGNet), which combines global and local features by encouraging the relation constraints between the embedding feature space and the input shape space based on the functional maps framework. Specifically, we design a Diffusion Graph Attention Network (DGANet) to segment the surface into parts with correct edge boundary between two regions. The Minimum Spanning Tree (MST) of geodesic curves among the singularities obtained from the segmented parts is added as relation constraints, which can compute isometric correspondences in both direct and symmetric directions. Besides that, the relation-and-attention constrained neural networks are designed to learn the shape correspondence via attention-aware CapsNet and functional maps under relation constraints. To improve the convergence speed and matching accuracy, we propose an optimized residual network structure based on the Nesterov Accelerated Gradient (NAG) to extract local features, and use graph convolution structure to extract global features. Moreover, a lightweight Gated Attention Module (GAM) is designed to fuse global and local features to obtain a richer feature representation. Since the capsule network has better spatial reasoning ability than the traditional convolutional neural network, our novel network architecture is a dual-route capsule network based on Routing Attention Fusion Block (RAFB), filtering low-discriminative capsules from a holistic view by exploiting geometric hierarchical relationships of semantic parts. Experiments on open datasets show that our method has excellent accuracy and wide adaptability.},
  archive      = {J_TIST},
  doi          = {10.1145/3688851},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Relation constrained capsule graph neural networks for non-rigid shape correspondence},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gradient-based adversarial training on transformer networks
for detecting check-worthy factual claims. <em>TIST</em>,
<em>15</em>(6), 1–25. (<a
href="https://doi.org/10.1145/3689212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents the latest developments to ClaimBuster’s claim-spotting model, which tackles the critical task of identifying check-worthy claims from large streams of information. We introduce the first adversarially regularized, transformer-based claim-spotting model, which achieves state-of-the-art results on several benchmark datasets. In addition to analyzing model performance metrics, we also quantitatively and qualitatively analyze the impact of ClaimBuster’s real-world deployment. Moreover, to help facilitate reproducibility and community engagement, we publicly release our codebase, dataset, data curation platform, API, Google Colab notebooks, and various ClaimBuster-based demo systems, at claimbuster.org .},
  archive      = {J_TIST},
  doi          = {10.1145/3689212},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Gradient-based adversarial training on transformer networks for detecting check-worthy factual claims},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient federated learning using dynamic update and
adaptive pruning with momentum on shared server data. <em>TIST</em>,
<em>15</em>(6), 1–28. (<a
href="https://doi.org/10.1145/3690648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite achieving remarkable performance, Federated Learning (FL) encounters two important problems, i.e., low training efficiency and limited computational resources. In this article, we propose a new FL framework, i.e., FedDUMAP, with three original contributions, to leverage the shared insensitive data on the server in addition to the distributed data in edge devices so as to efficiently train a global model. First, we propose a simple dynamic server update algorithm, which takes advantage of the shared insensitive data on the server while dynamically adjusting the update steps on the server in order to speed up the convergence and improve the accuracy. Second, we propose an adaptive optimization method with the dynamic server update algorithm to exploit the global momentum on the server and each local device for superior accuracy. Third, we develop a layer-adaptive model pruning method to carry out specific pruning operations, which is adapted to the diverse features of each layer so as to attain an excellent tradeoff between effectiveness and efficiency. Our proposed FL model, FedDUMAP, combines the three original techniques and has a significantly better performance compared with baseline approaches in terms of efficiency (up to 16.9 times faster), accuracy (up to 20.4% higher), and computational cost (up to 62.6% smaller).},
  archive      = {J_TIST},
  doi          = {10.1145/3690648},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-28},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Efficient federated learning using dynamic update and adaptive pruning with momentum on shared server data},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RCCNet: A spatial-temporal neural network model for
logistics delivery timely rate prediction. <em>TIST</em>,
<em>15</em>(6), 1–21. (<a
href="https://doi.org/10.1145/3690649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In logistics service, the delivery timely rate is a key experience indicator, which is highly essential to the competitive advantage of express companies. Prediction on it enables intervention on couriers with low predicted results in advance, thus ensuring employee productivity and customer satisfaction. Currently, few related works focus on couriers’ level delivery timely rate prediction, and there are complex spatial correlations between couriers and road districts in the express scenario, which makes traditional real-time prediction approaches hard to utilize. To deal with this, we propose a deep spatial-temporal neural network, RCCNet to model spatial-temporal correlations. Specifically, we adopt Node2vec, which can encode the road network-based graph directly to capture spatial correlations between road districts. Further, we calculate couriers’ historical time-series similarity to build a graph and employ graph convolutional networks to capture the correlation between couriers. We also leverage historical sequential information with long short-term memory networks. We conduct experiments with real-world express datasets. Compared with other competitive baseline methods widely used in industry, the experiment results demonstrate its superior performance over multiple baselines.},
  archive      = {J_TIST},
  doi          = {10.1145/3690649},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {RCCNet: A spatial-temporal neural network model for logistics delivery timely rate prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KGDA: A knowledge graph driven decomposition approach for
cellular traffic prediction. <em>TIST</em>, <em>15</em>(6), 1–22. (<a
href="https://doi.org/10.1145/3690650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding and accurately predicting cellular traffic data is vital for communication operators and device users, as it facilitates efficient resource allocation and ensures superior service quality. However, large-scale cellular traffic data forecasting remains challenging due to intricate temporal variations and complex spatial relationships. This article proposes a Knowledge Graph Driven Decomposition Approach (KGDA) for precise cellular traffic prediction. The KGDA breaks down the impact of static environmental factors and dynamic autocorrelations of cellular traffic time series, enabling the capture of overall traffic changes and understanding of traffic dependence on past values. Specifically, we propose an urban knowledge graph to capture the static environmental context of base stations, mapping these entities into the same latent space while retaining static environmental knowledge. The cellular traffic is divided into a regular pattern and fluctuating residual components, with the KGDA comprising four modules: a Knowledge Graph Representation Learning model, a traffic regular pattern prediction module, a traffic residual dynamic prediction module, and an attentional fusion module. The first leverages graph neural networks to extract spatial contexts and predict regular patterns, the second utilizes the Bi-directional Long Short-Term Memory (Bi-LSTM) model to capture autocorrelations of traffic time series, and the final module integrates the patterns and residuals to produce the final prediction result. Comprehensive experiments demonstrate that our proposed model outperforms state-of-the-art models by more than 10% in forecasting cellular traffic.},
  archive      = {J_TIST},
  doi          = {10.1145/3690650},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-22},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {KGDA: A knowledge graph driven decomposition approach for cellular traffic prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adapting to my user, engaging with my robot: An adaptive
affective architecture for a social assistive robot. <em>TIST</em>,
<em>15</em>(6), 1–28. (<a
href="https://doi.org/10.1145/3691348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affective feedback from social robots is a useful technique for communicating to people whether they are interacting “well” with the robot or not. However, some users, such as people with physical or cognitive difficulties, may not be able to interact in all the desired ways. In these cases, affective feedback from the robot could be excessively negative—an “unhappy” robot, leading to an unrewarding experience for the user. This article presents a motivation-based architecture for an autonomous multimodal social robot, that incorporates an affective feedback mechanism which generates an affective state by combining the internal needs of the robot and the social interaction quality. The balance between these two factors can dynamically change, allowing the robot to adapt its affective feedback to the user&#39;s interaction style and capabilities. We have implemented this architecture in a simulation and in a MiRo social robot, and report experiments examining the behavior of the system in interactions with different experimental user profiles. The results show that the adaptive mechanism allows the robot to change its affective feedback to give more positive encouragement to users than in non-adaptive cases.},
  archive      = {J_TIST},
  doi          = {10.1145/3691348},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-28},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Adapting to my user, engaging with my robot: An adaptive affective architecture for a social assistive robot},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantum informative analysis in smart power distribution.
<em>TIST</em>, <em>15</em>(6), 1–18. (<a
href="https://doi.org/10.1145/3691350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in the Internet of Things (IoT) paradigm have greatly improved the quality of services in the electricity industry through the integration of smart energy distribution and dependable electric devices. Conspicuously, the current research introduces a method for managing electricity consumption in smart residences using IoT-Fog technology, focusing on efficient energy allocation and real-time energy needs. The study specifically examines the effectiveness of electricity grid sub-stations in distributing energy using fog computing technology. By utilizing a quantum computing-assisted approach, optimal energy distribution is achieved by calculating a novel Electricity Usage Measure (EUM) based on actual energy usage patterns of smart homes. Furthermore, the Quantumized Neural Network (QiM-NN) technique is developed to forecast the electricity distribution over grid substations. For performance assessment, 4-month data are collected using four smart houses. Comparative analysis with existing data assessment techniques illustrates the effectiveness in terms of Temporal Delay (6.33 ms), Optimization Performance (Specificity (93.00%), Sensitivity (90.86%), Precision (96.66%), Coverage (96.66 %), Reliability (93.76%), and Stability (71%).},
  archive      = {J_TIST},
  doi          = {10.1145/3691350},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {6},
  pages        = {1-18},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Quantum informative analysis in smart power distribution},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of trustworthy federated learning: Issues,
solutions, and challenges. <em>TIST</em>, <em>15</em>(6), 1–47. (<a
href="https://doi.org/10.1145/3678181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trustworthy artificial intelligence (TAI) has proven invaluable in curbing potential negative repercussions tied to AI applications. Within the TAI spectrum, federated learning (FL) emerges as a promising solution to safeguard personal information in distributed settings across a multitude of practical contexts. However, the realm of FL is not without its challenges. Especially worrisome are adversarial attacks targeting its algorithmic robustness and systemic confidentiality. Moreover, the presence of biases and opacity in prediction outcomes further complicates FL’s broader adoption. Consequently, there is a growing expectation for FL to instill trust. To address this, we chart out a comprehensive road-map for Trustworthy Federated Learning (TFL) and provide an overview of existing efforts across four pivotal dimensions: Privacy and Security , Robustness , Fairness , and Explainability . For each dimension, we identify potential pitfalls that might undermine TFL and present a curated selection of defensive strategies, enriched by a discourse on technical solutions tailored for TFL. Furthermore, we present potential challenges and future directions to be explored for in-depth TFL research with broader impacts.},
  archive      = {J_TIST},
  doi          = {10.1145/3678181},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {10},
  number       = {6},
  pages        = {1-47},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A survey of trustworthy federated learning: Issues, solutions, and challenges},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-agnostic adaptive testing for intelligent education
systems via meta-learned gradient embeddings. <em>TIST</em>,
<em>15</em>(5), 1–26. (<a
href="https://doi.org/10.1145/3660642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of education has undergone a significant revolution with the advent of intelligent systems and technology, which aim to personalize the learning experience, catering to the unique needs and abilities of individual learners. In this pursuit, a fundamental challenge is designing proper test for assessing the students’ cognitive status on knowledge and skills accurately and efficiently. One promising approach, referred to as Computerized Adaptive Testing (CAT), is to administrate computer-automated tests that alternately select the next item for each examinee and estimate their cognitive states given their responses to the selected items. Nevertheless, existing CAT systems suffer from inflexibility in item selection and ineffectiveness in cognitive state estimation, respectively. In this article, we propose a Model-Agnostic adaptive testing framework via Meta-leaned Gradient Embeddings, MAMGE for short, improving both item selection and cognitive state estimation simultaneously. For item selection, we design a Gradient Embedding-based Item Selector (GEIS) which incorporates the concept of gradient embeddings to represent items and selects the best ones that are both informative and representative. For cognitive state estimation, we propose a Meta-learned Cognitive State Estimator (MCSE) to automatically control the estimation process by learning to learn a proper initialization and dynamically inferred updates. Both MCSE and GEIS are inherently model-agnostic, and the two modules have an ingenious connection via meta-learned gradient embeddings. Finally, extensive experiments evaluate the effectiveness and flexibility of MAMGE.},
  archive      = {J_TIST},
  doi          = {10.1145/3660642},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Model-agnostic adaptive testing for intelligent education systems via meta-learned gradient embeddings},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analyzing robustness of automatic scientific claim
verification tools against adversarial rephrasing attacks.
<em>TIST</em>, <em>15</em>(5), 1–32. (<a
href="https://doi.org/10.1145/3663481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus pandemic has fostered an explosion of misinformation about the disease, including the risk and effectiveness of vaccination. AI tools for automatic Scientific Claim Verification (SCV) can be crucial to defeat misinformation campaigns spreading through social media channels. However, over the past years, many concerns have been raised about the robustness of AI to adversarial attacks, and the field of automatic SCV is not exempt. The risk is that such SCV tools may reinforce and legitimize the spread of fake scientific claims rather than refute them. This article investigates the problem of generating adversarial attacks for SCV tools and shows that it is far more difficult than the generic NLP adversarial attack problem. The current NLP adversarial attack generators, when applied to SCV, often generate modified claims with entirely different meaning from the original. Even when the meaning is preserved, the modification of the generated claim is too simplistic (only a single word is changed), leaving many weaknesses of the SCV tools undiscovered. We propose T5-ParEvo, an iterative evolutionary attack generator, that is able to generate more complex and creative attacks while better preserving the semantics of the original claim. Using detailed quantitative and qualitative analyses, we demonstrate the efficacy of T5-ParEvo in comparison with existing attack generators.},
  archive      = {J_TIST},
  doi          = {10.1145/3663481},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-32},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Analyzing robustness of automatic scientific claim verification tools against adversarial rephrasing attacks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Addressing data challenges to drive the transformation of
smart cities. <em>TIST</em>, <em>15</em>(5), 1–65. (<a
href="https://doi.org/10.1145/3663482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cities serve as vital hubs of economic activity and knowledge generation and dissemination. As such, cities bear a significant responsibility to uphold environmental protection measures while promoting the welfare and living comfort of their residents. There are diverse views on the development of smart cities, from integrating Information and Communication Technologies into urban environments for better operational decisions to supporting sustainability, wealth, and comfort of people. However, for all these cases, data are the key ingredient and enabler for the vision and realization of smart cities. This article explores the challenges associated with smart city data. We start with gaining an understanding of the concept of a smart city, how to measure that the city is a smart one, and what architectures and platforms exist to develop one. Afterwards, we research the challenges associated with the data of the cities, including availability, heterogeneity, management, analysis, privacy, and security. Finally, we discuss ethical issues. This article aims to serve as a “one-stop shop” covering data-related issues of smart cities with references for diving deeper into particular topics of interest.},
  archive      = {J_TIST},
  doi          = {10.1145/3663482},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-65},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Addressing data challenges to drive the transformation of smart cities},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fine-grained courier delivery behavior recovery with a
digital twin based iterative calibration framework. <em>TIST</em>,
<em>15</em>(5), 1–25. (<a
href="https://doi.org/10.1145/3663484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recovering the fine-grained working process of couriers is becoming one of the essential problems for improving the express delivery systems because knowing the detailed process of how couriers accomplish their daily work facilitates the analyzing, understanding, and optimizing of the working procedure. Although coarse-grained courier trajectories and waybill delivery time data can be collected, this problem is still challenging due to noisy data with spatio-temporal biases, lacking ground truth of couriers’ fine-grained behaviors, and complex correlations between behaviors. Existing works typically focus on a single dimension of the process such as inferring the delivery time and can only yield results of low spatio-temporal resolution, which cannot address the problem well. To bridge the gap, we propose a digital-twin-based iterative calibration system (DTRec) for fine-grained courier working process recovery. We first propose a spatio-temporal bias correction algorithm, which systematically improves existing methods in correcting waybill addresses and trajectory stay points. Second, to model the complex correlations among behaviors and inherent physical constraints, we propose an agent-based model to build the digital twin of couriers. Third, to further improve recovery performance, we design a digital-twin-based iterative calibration framework, which leverages the inconsistency between the deduction results of the digital twin and the recovery results from real-world data to improve both the agent-based model and the recovery results. Experiments show that DTRec outperforms state-of-the-art baselines by 10.8% in terms of fine-grained accuracy on real-world datasets. The system is deployed in the industrial practices in JD Logistics with promising applications. The code is available at https://github.com/tsinghua-fib-lab/Courier-DTRec .},
  archive      = {J_TIST},
  doi          = {10.1145/3663484},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Fine-grained courier delivery behavior recovery with a digital twin based iterative calibration framework},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PerFedRec++: Enhancing personalized federated recommendation
with self-supervised pre-training. <em>TIST</em>, <em>15</em>(5), 1–24.
(<a href="https://doi.org/10.1145/3664927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated recommendation systems employ federated learning techniques to safeguard user privacy by transmitting model parameters instead of raw user data between user devices and the central server. Nevertheless, the current federated recommender system faces three significant challenges: (1) data heterogeneity: the heterogeneity of users’ attributes and local data necessitates the acquisition of personalized models to improve the performance of federated recommendation; (2) model performance degradation: the privacy-preserving protocol design in the federated recommendation, such as pseudo item labeling and differential privacy, would deteriorate the model performance; (3) communication bottleneck: the standard federated recommendation algorithm can have a high communication overhead. Previous studies have attempted to address these issues, but none have been able to solve them simultaneously. In this article, we propose a novel framework, named PerFedRec++ , to enhance the personalized federated recommendation with self-supervised pre-training. Specifically, we utilize the privacy-preserving mechanism of federated recommender systems to generate two augmented graph views, which are used as contrastive tasks in self-supervised graph learning to pre-train the model. Pre-training enhances the performance of federated models by improving the uniformity of representation learning. Also, by providing a better initial state for federated training, pre-training makes the overall training converge faster, thus alleviating the heavy communication burden. We then construct a collaborative graph to learn the client representation through a federated graph neural network. Based on these learned representations, we cluster users into different user groups and learn personalized models for each cluster. Each user learns a personalized model by combining the global federated model, the cluster-level federated model, and its own fine-tuned local model. Experiments on three real-world datasets show that our proposed method achieves superior performance over existing methods.},
  archive      = {J_TIST},
  doi          = {10.1145/3664927},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {PerFedRec++: Enhancing personalized federated recommendation with self-supervised pre-training},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DNSRF: Deep network-based semi-NMF representation framework.
<em>TIST</em>, <em>15</em>(5), 1–20. (<a
href="https://doi.org/10.1145/3670408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning is an important topic in machine learning, pattern recognition, and data mining research. Among many representation learning approaches, semi-nonnegative matrix factorization (SNMF) is a frequently-used one. However, a typical problem of SNMF is that usually there is no learning rate guidance during the optimization process, which often leads to a poor representation ability. To overcome this limitation, we propose a very general representation learning framework (DNSRF) that is based on a deep neural net. Essentially, the parameters of the deep net used to construct the DNSRF algorithms are obtained by matrix element update. In combination with different activation functions, DNSRF can be implemented in various ways. In our experiments, we tested nine instances of our DNSRF framework on six benchmark datasets. In comparison with other state-of-the-art methods, the results demonstrate the superior performance of our framework, which is thus shown to have a great representation ability.},
  archive      = {J_TIST},
  doi          = {10.1145/3670408},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {DNSRF: Deep network-based semi-NMF representation framework},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy-preserving and diversity-aware trust-based team
formation in online social networks. <em>TIST</em>, <em>15</em>(5),
1–32. (<a href="https://doi.org/10.1145/3670411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As online social networks (OSNs) become more prevalent, a new paradigm for problem-solving through crowd-sourcing has emerged. By leveraging the OSN platforms, users can post a problem to be solved and then form a team to collaborate and solve the problem. A common concern in OSNs is how to form effective collaborative teams, as various tasks are completed through online collaborative networks. A team’s diversity in expertise has received high attention to producing high team performance in developing team formation (TF) algorithms. However, the effect of team diversity on performance under different types of tasks has not been extensively studied. Another important issue is how to balance the need to preserve individuals’ privacy with the need to maximize performance through active collaboration, as these two goals may conflict with each other. This research has not been actively studied in the literature. In this work, we develop a TF algorithm in the context of OSNs that can maximize team performance and preserve team members’ privacy under different types of tasks. Our proposed PRivAcy-Diversity-Aware TF framework, called PRADA-TF , is based on trust relationships between users in OSNs where trust is measured based on a user’s expertise and privacy preference levels. The PRADA-TF algorithm considers the team members’ domain expertise, privacy preferences, and the team’s expertise diversity in the process of TF. Our approach employs game-theoretic principles Mechanism Design to motivate self-interested individuals within a TF context, positioning the mechanism designer as the pivotal team leader responsible for assembling the team. We use two real-world datasets (i.e., Netscience and IMDb) to generate different semi-synthetic datasets for constructing trust networks using a belief model (i.e., Subjective Logic) and identifying trustworthy users as candidate team members. We evaluate the effectiveness of our proposed PRADA-TF scheme in four variants against three baseline methods in the literature. Our analysis focuses on three performance metrics for studying OSNs: social welfare, privacy loss, and team diversity.},
  archive      = {J_TIST},
  doi          = {10.1145/3670411},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-32},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Privacy-preserving and diversity-aware trust-based team formation in online social networks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond text: Multimodal credibility assessment approaches
for online user-generated content. <em>TIST</em>, <em>15</em>(5), 1–33.
(<a href="https://doi.org/10.1145/3673236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User-generated content (UGC) is increasingly becoming prevalent on various digital platforms. The content generated on social media, review forums, and question–answer platforms impacts a larger audience and influences their political, social, and other cognitive abilities. Traditional credibility assessment mechanisms involve assessing the credibility of the source and the text. However, with the increase in how user content can be generated and shared (audio, video, and images), multimodal representation of UGC has become increasingly popular. This article reviews the credibility assessment of UGC in various domains, particularly identifying fake news, suspicious profiles, and fake reviews and testimonials, focusing on both textual content and the source of the content creator. Next, the concept of multimodal credibility assessment is presented, which also includes audio, video, and images in addition to text. After that, the article presents a systematic review and comprehensive analysis of work done in the credibility assessment of UGC considering multimodal features. Additionally, the article provides extensive details on the publicly available multimodal datasets for the credibility assessment of UGC. In the end, the research gaps, challenges, and future directions in assessing the credibility of multimodal UGC are presented.},
  archive      = {J_TIST},
  doi          = {10.1145/3673236},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-33},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Beyond text: Multimodal credibility assessment approaches for online user-generated content},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DESIGN: Online device selection and edge association for
federated synergy learning-enabled AIoT. <em>TIST</em>, <em>15</em>(5),
1–28. (<a href="https://doi.org/10.1145/3673237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial intelligence of things (AIoT) is an emerging technology that enables numerous AIoT devices to participate in big data analytics and machine learning (ML) model training, providing various customized intelligent services for industry manufacturing. Federated learning (FL) empowers AIoT applications with privacy-preserving distributed model training without sharing raw data. However, due to IoT devices’ limited computing and memory resources, existing FL approaches for AIoT applications cannot support efficient large-scale model training. Federated synergy learning (FSyL) is a promising collaborative paradigm that alleviates the computation and communication overhead on resource-constrained AIoT devices via offloading part of the ML model to the edge server for end-to-edge collaborative training. Existing FSyL works neither efficiently address the inter-round device selection to improve model diversity nor determine the intra-round edge association to reduce the training cost, which hinders the applications of FSyL-enable AIoT. Motivated by this issue, this article first investigates the bottlenecks of executing FSyL in AIoT. It builds an optimization model of joint inter-round device selection and intra-round edge association for balancing model diversity and training cost. To tackle the intractable coupling problem, we present a framework named Online DEvice SelectIon and EdGe AssociatioN for Cost-Diversity Tradeoffs FSyL (DESIGN). First, the edge association subproblem is extracted from the original problem, and game theory determines the optimal association decision for an arbitrary device selection. Then, based on the optimal association decision, device selection is modeled as a combinatorial multi-armed bandit (CMAB) problem. Finally, we propose an online mechanism to obtain joint DESIGN decisions. The performance of DESIGN is theoretically analyzed and experimentally evaluated on real-world datasets. The results show that DESIGN can achieve up to \(84.3\%\) in cost-saving with an accuracy improvement of \(23.6\%\) compared with the state-of-the-art.},
  archive      = {J_TIST},
  doi          = {10.1145/3673237},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-28},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {DESIGN: Online device selection and edge association for federated synergy learning-enabled AIoT},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid prompt learning for generating justifications of
security risks in automation rules. <em>TIST</em>, <em>15</em>(5), 1–26.
(<a href="https://doi.org/10.1145/3675401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trigger-action platforms (TAPs) enable users without programming experience to personalize the behavior of Internet of Things applications and services through IF-THEN rules. Unfortunately, the arbitrary connection of smart devices and online services, even with simple rules, such as “IF the entrance Netatmo Wheather Station detects a temperature above 30 \({}^{\circ}C\) ( \(86^{\circ}F\) ) THEN open the shutters in the living room,” might expose users to potential security and privacy risks (e.g., the execution of the previous rule might provide an easy entry point for thieves, especially during the summer vacation period). The goal of our research is to make the users capable of understanding and mitigating the threats and risks associated with the execution of IF-THEN rules. To this end, we define a new challenging task, namely generating post hoc justifications of privacy and security risks associated with automation rules, and propose a novel natural language generation strategy based on hybrid prompt learning producing justifications in the form of real-life threat scenarios. The proposed strategy allows for prompt customization with task-specific information, providing contextual details enabling to grasp the nuances and subtleties of the domain language, resulting in more coherent justifications. The experiments conducted on the if-this-then-that (IFTTT) platform show that our method produces effective justifications, improving the explainability of discrete and hybrid prompting methods up to 27% in BLEURT score. The code of the software is publicly available on GitHub 1 .},
  archive      = {J_TIST},
  doi          = {10.1145/3675401},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Hybrid prompt learning for generating justifications of security risks in automation rules},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fair and efficient ridesharing: A dynamic programming-based
relocation approach. <em>TIST</em>, <em>15</em>(5), 1–30. (<a
href="https://doi.org/10.1145/3675403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommending routes by their probability of having a rider has long been the goal of conventional route recommendation systems. While this maximizes the platform-specific criteria of efficiency, it results in sub-optimal outcomes with the disparity among the income of drivers who work for similar time frames. Pioneer studies on fairness in ridesharing platforms have focused on algorithms that match drivers and riders. However, these studies do not consider the time schedules of different riders sharing a ride in the ridesharing mode. To overcome this shortcoming, we present the first route recommendation system for ridesharing networks that explicitly considers fairness as an evaluation criterion. In particular, we design a routing mechanism that reduces the inequality among drivers and provides them with routes that have a similar probability of finding riders over a period of time. However, while optimizing fairness the efficiency of the platform should not be affected as both of these goals are important for the long-term sustainability of the system. In order to jointly optimize fairness and efficiency we consider repositioning drivers with low income to the areas that have a higher probability of finding riders in future. While applying driver repositioning, we design a future-aware policy and allocate the areas to the drivers considering the destination of requests in the corresponding area. Extensive simulations on real-world datasets of Washington DC and New York demonstrate superior performance by our proposed system in comparison to the existing baselines.},
  archive      = {J_TIST},
  doi          = {10.1145/3675403},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-30},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Fair and efficient ridesharing: A dynamic programming-based relocation approach},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Libby-novick beta-liouville distribution for enhanced
anomaly detection in proportional data. <em>TIST</em>, <em>15</em>(5),
1–26. (<a href="https://doi.org/10.1145/3675405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of anomaly detection in proportional data by investigating the Libby-Novick Beta-Liouville distribution, a novel distribution merging the salient characteristics of Liouville and Libby-Novick Beta distributions. Its main benefit, compared to the typical distributions dedicated to proportional data such as Dirichlet and Beta-Liouville, is its adaptability and explanatory power when dealing with this kind of data. Our goal is to exploit this appropriateness for modeling proportional data to achieve great performance in the anomaly detection task. First, we develop generative models, namely finite mixture models of Libby-Novick Beta-Liouville distributions. Then, we propose two discriminative techniques: Normality scores based on selecting the given distribution to approximate the softmax output vector of a deep classifier and an improved version of Support Vector Machine (SVM) by suggesting a feature mapping approach. We demonstrate the benefits of the presented approaches through a variety of experiments on both image and non-image datasets. The results demonstrate that the proposed anomaly detectors based on the Libby-Novick Beta-Liouville distribution outperform the classical distributions as well as the baseline techniques.},
  archive      = {J_TIST},
  doi          = {10.1145/3675405},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Libby-novick beta-liouville distribution for enhanced anomaly detection in proportional data},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised text style transfer using cycle-consistent
adversarial networks. <em>TIST</em>, <em>15</em>(5), 1–38. (<a
href="https://doi.org/10.1145/3678179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text Style Transfer (TST) is a relevant branch of natural language processing that aims to control the style attributes of a piece of text while preserving its original content. To address TST in the absence of parallel data, Cycle-consistent Generative Adversarial Networks (CycleGANs) have recently emerged as promising solutions. Existing CycleGAN-based TST approaches suffer from the following limitations: (1) They apply self-supervision, based on the cycle-consistency principle, in the latent space. This approach turns out to be less robust to mixed-style inputs, i.e., when the source text is partly in the original and partly in the target style; (2) Generators and discriminators rely on recurrent networks, which are exposed to known issues with long-term text dependencies; (3) The target style is weakly enforced, as the discriminator distinguishes real from fake sentences without explicitly accounting for the generated text&#39;s style. We propose a new CycleGAN-based TST approach that applies self-supervision directly at the sequence level to effectively handle mixed-style inputs and employs Transformers to leverage the attention mechanism for both text encoding and decoding. We also employ a pre-trained style classifier to guide the generation of text in the target style while maintaining the original content&#39;s meaning. The experimental results achieved on the formality and sentiment transfer tasks show that our approach outperforms existing ones, both CycleGAN-based and not (including an open-source Large Language Model), on benchmark data and shows better robustness to mixed-style inputs.},
  archive      = {J_TIST},
  doi          = {10.1145/3678179},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-38},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Self-supervised text style transfer using cycle-consistent adversarial networks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online spatial-temporal EV charging scheduling with
incentive promotion. <em>TIST</em>, <em>15</em>(5), 1–26. (<a
href="https://doi.org/10.1145/3678180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing adoption of electric vehicles (EVs) has resulted in an increased demand for public EV charging infrastructure. Currently, the collaboration between these stations has become vital for efficient charging scheduling and cost reduction. However, most existing scheduling methods primarily focus on recommending charging stations without considering users’ charging preferences. Adopting these strategies may require considerable modifications to how people charge their EVs, which could lead to a reluctance to follow the scheduling plan from charging services in real-world situations. To address these challenges, we propose the POSKID framework in this article. It focuses on spatial-temporal charging scheduling, aiming to recommend a feasible charging arrangement, including a charging station and a charging time slot, to each EV user while minimizing overall operating costs and ensuring users’ charging satisfaction. The framework adopts an online charging mechanism that provides recommendations without prior knowledge of future electricity information or charging requests. To enhance users’ willingness to accept the recommendations, POSKID incorporates an incentive strategy and a novel embedding method combined with Bayesian personalized analysis. These techniques reveal users’ implicit charging preferences, enhancing the success probability of the charging scheduling task. Furthermore, POSKID integrates an online candidate arrangement selection and an explore-exploit strategy to improve the charging arrangement recommendations based on users’ feedback. Experimental results using real-world datasets validate the effectiveness of POSKID in optimizing charging management, surpassing other strategies. The results demonstrate that POSKID benefits each charging station while ensuring user charging satisfaction.},
  archive      = {J_TIST},
  doi          = {10.1145/3678180},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {11},
  number       = {5},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Online spatial-temporal EV charging scheduling with incentive promotion},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural methods for data-to-text generation. <em>TIST</em>,
<em>15</em>(5), 1–46. (<a
href="https://doi.org/10.1145/3660639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neural boom that has sparked natural language processing (NLP) research throughout the last decade has similarly led to significant innovations in data-to-text (D2T) generation. This survey offers a consolidated view into the neural D2T paradigm with a structured examination of the approaches, benchmark datasets, and evaluation protocols. This survey draws boundaries separating D2T from the rest of the natural language generation (NLG) landscape, encompassing an up-to-date synthesis of the literature, and highlighting the stages of technological adoption from within and outside the greater NLG umbrella. With this holistic view, we highlight promising avenues for D2T research that focus not only on the design of linguistically capable systems but also on systems that exhibit fairness and accountability.},
  archive      = {J_TIST},
  doi          = {10.1145/3660639},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {10},
  number       = {5},
  pages        = {1-46},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Neural methods for data-to-text generation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Teacher-student framework for polyphonic semi-supervised
sound event detection: Survey and empirical analysis. <em>TIST</em>,
<em>15</em>(5), 1–44. (<a
href="https://doi.org/10.1145/3660641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polyphonic sound event detection refers to the task of automatically identifying sound events occurring simultaneously in an auditory scene. Due to the inherent complexity and variability of real-world auditory scenes, building robust detectors for polyphonic sound event detection poses a significant challenge. The task becomes furthermore challenging without sufficient annotated data to develop sound event detection systems under a supervised learning regime. In this article, we explore the recent developments in polyphonic sound event detection, with a particular emphasis on the application of Teacher-Student techniques within the semi-supervised learning paradigm. Unlike previous works, we have consolidated and organized the fragmented literature on Teacher-Student techniques for polyphonic sound event detection. By examining the latest research, categorizing Teacher-Student approaches, and conducting an empirical study to assess the performance of each approach, this survey offers valuable insights and practical guidance for researchers and practitioners in the field. Our findings highlight the potential benefits of utilizing multiple learners, ensuring consistent predictions, and making thoughtful choices regarding perturbation strategies.},
  archive      = {J_TIST},
  doi          = {10.1145/3660641},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {10},
  number       = {5},
  pages        = {1-44},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Teacher-student framework for polyphonic semi-supervised sound event detection: Survey and empirical analysis},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DIRECT: Dual interpretable recommendation with multi-aspect
word attribution. <em>TIST</em>, <em>15</em>(5), 1–21. (<a
href="https://doi.org/10.1145/3663483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommending products to users with intuitive explanations helps improve the system in transparency, persuasiveness, and satisfaction. Existing interpretation techniques include post hoc methods and interpretable modeling. The former category could quantitatively analyze input contribution to model prediction but has limited interpretation faithfulness, while the latter could explain model internal mechanisms but may not directly attribute model predictions to input features. In this study, we propose a novel Dual Interpretable Recommendation model called DIRECT, which integrates ideas of the two interpretation categories to inherit their advantages and avoid limitations. Specifically, DIRECT makes use of item descriptions as explainable evidence for recommendation. First, similar to the post hoc interpretation, DIRECT could attribute the prediction of a user preference score to textual words of the item descriptions. The attribution of each word is related to its sentiment polarity and word importance, where a word is important if it corresponds to an item aspect that the user is interested in. Second, to improve the interpretability of embedding space, we propose to extract high-level concepts from embeddings, where each concept corresponds to an item aspect. To learn discriminative concepts, we employ a concept bottleneck layer and maximize the coding rate reduction on word-aspect embeddings by leveraging a word–word affinity graph extracted from a pre-trained language model. In this way, DIRECT simultaneously achieves faithful attribution and usable interpretation of embedding space. We also show that DIRECT achieves linear inference time complexity regarding the length of item reviews. We conduct experiments including ablation studies on five real-world datasets. Quantitative analysis, visualizations, and case studies verify the interpretability of DIRECT. Our code is available at: https://github.com/JacksonWuxs/DIRECT .},
  archive      = {J_TIST},
  doi          = {10.1145/3663483},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {10},
  number       = {5},
  pages        = {1-21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {DIRECT: Dual interpretable recommendation with multi-aspect word attribution},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bibliometric review of large language models research from
2017 to 2023. <em>TIST</em>, <em>15</em>(5), 1–25. (<a
href="https://doi.org/10.1145/3664930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs), such as OpenAI&#39;s Generative Pre-trained Transformer (GPT), are a class of language models that have demonstrated outstanding performance across a range of natural language processing (NLP) tasks. LLMs have become a highly sought-after research area because of their ability to generate human-like language and their potential to revolutionize science and technology. In this study, we conduct bibliometric and discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000 publications, this article serves as a roadmap for researchers, practitioners, and policymakers to navigate the current landscape of LLMs research. We present the research trends from 2017 to early 2023, identifying patterns in research paradigms and collaborations. We start with analyzing the core algorithm developments and NLP tasks that are fundamental in LLMs research. We then investigate the applications of LLMs in various fields and domains, including medicine, engineering, social science, and humanities. Our review also reveals the dynamic, fast-paced evolution of LLMs research. Overall, this article offers valuable insights into the current state, impact, and potential of LLMs research and its applications.},
  archive      = {J_TIST},
  doi          = {10.1145/3664930},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {10},
  number       = {5},
  pages        = {1-25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A bibliometric review of large language models research from 2017 to 2023},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mitigating recommendation biases via group-alignment and
global-uniformity in representation learning. <em>TIST</em>,
<em>15</em>(5), 1–27. (<a
href="https://doi.org/10.1145/3664931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative Filtering (CF) plays a crucial role in modern recommender systems, leveraging historical user-item interactions to provide personalized suggestions. However, CF-based methods often encounter biases due to imbalances in training data. This phenomenon makes CF-based methods tend to prioritize recommending popular items and performing unsatisfactorily on inactive users. Existing works address this issue by rebalancing training samples, reranking recommendation results, or making the modeling process robust to the bias. Despite their effectiveness, these approaches can compromise accuracy or be sensitive to weighting strategies, making them challenging to train. Therefore, exploring how to mitigate these biases remains in urgent demand. In this article, we deeply analyze the causes and effects of the biases and propose a framework to alleviate biases in recommendation from the perspective of representation distribution, namely Group-Alignment and Global-Uniformity Enhanced Representation Learning for Debiasing Recommendation (AURL). Specifically, we identify two significant problems in the representation distribution of users and items, namely group-discrepancy and global-collapse. These two problems directly lead to biases in the recommendation results. To this end, we propose two simple but effective regularizers in the representation space, respectively named group-alignment and global-uniformity. The goal of group-alignment is to bring the representation distribution of long-tail entities closer to that of popular entities, while global-uniformity aims to preserve the information of entities as much as possible by evenly distributing representations. Our method directly optimizes both the group-alignment and global-uniformity regularization terms to mitigate recommendation biases. Please note that AURL applies to arbitrary CF-based recommendation backbones. Extensive experiments on three real datasets and various recommendation backbones verify the superiority of our proposed framework. The results show that AURL not only outperforms existing debiasing models in mitigating biases but also improves recommendation performance to some extent.},
  archive      = {J_TIST},
  doi          = {10.1145/3664931},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {10},
  number       = {5},
  pages        = {1-27},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Mitigating recommendation biases via group-alignment and global-uniformity in representation learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ranking the transferability of adversarial examples.
<em>TIST</em>, <em>15</em>(5), 1–21. (<a
href="https://doi.org/10.1145/3670409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial transferability in blackbox scenarios presents a unique challenge: while attackers can employ surrogate models to craft adversarial examples, they lack assurance on whether these examples will successfully compromise the target model. Until now, the prevalent method to ascertain success has been trial and error—testing crafted samples directly on the victim model. This approach, however, risks detection with every attempt, forcing attackers to either perfect their first try or face exposure. Our article introduces a ranking strategy that refines the transfer attack process, enabling the attacker to estimate the likelihood of success without repeated trials on the victim’s system. By leveraging a set of diverse surrogate models, our method can predict transferability of adversarial examples. This strategy can be used to either select the best sample to use in an attack or the best perturbation to apply to a specific sample. Using our strategy, we were able to raise the transferability of adversarial examples from a mere 20%—akin to random selection—up to near upper-bound levels, with some scenarios even witnessing a 100% success rate. This substantial improvement not only sheds light on the shared susceptibilities across diverse architectures but also demonstrates that attackers can forego the detectable trial-and-error tactics raising increasing the threat of surrogate-based attacks.},
  archive      = {J_TIST},
  doi          = {10.1145/3670409},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {10},
  number       = {5},
  pages        = {1-21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Ranking the transferability of adversarial examples},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physics-based abnormal trajectory gap detection.
<em>TIST</em>, <em>15</em>(5), 1–31. (<a
href="https://doi.org/10.1145/3673235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given trajectories with gaps (i.e., missing data), we investigate algorithms to identify abnormal gaps in trajectories which occur when a given moving object did not report its location, but other moving objects in the same geographic region periodically did. The problem is important due to its societal applications, such as improving maritime safety and regulatory enforcement for global security concerns, such as illegal fishing, illegal oil transfers, and trans-shipments. The problem is challenging due to the difficulty of bounding the possible locations of the moving object during a trajectory gap, and the very high computational cost of detecting gaps in such a large volume of location data. The current literature on anomalous trajectory detection assumes linear interpolation within gaps, which may not be able to detect abnormal gaps since objects within a given region may have traveled away from their shortest path. In preliminary work, we introduced an abnormal gap measure that uses a classical space-time prism model to bound an object&#39;s possible movement during the trajectory gap and provided a scalable memoized gap detection algorithm (Memo-AGD). In this article, we propose a space time-aware gap detection (STAGD) approach to leverage space-time indexing and merging of trajectory gaps. We also incorporate a dynamic region merge-based (DRM) approach to efficiently compute gap abnormality scores. We provide theoretical proofs that both algorithms are correct and complete and also provide analysis of asymptotic time complexity. Experimental results on synthetic and real-world maritime trajectory data show that the proposed approach substantially improves computation time over the baseline technique.},
  archive      = {J_TIST},
  doi          = {10.1145/3673235},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {10},
  number       = {5},
  pages        = {1-31},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Physics-based abnormal trajectory gap detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). M2SKD: Multi-to-single knowledge distillation of real-time
epileptic seizure detection for low-power wearable systems.
<em>TIST</em>, <em>15</em>(5), 1–31. (<a
href="https://doi.org/10.1145/3675402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating low-power wearable systems into routine health monitoring is an ongoing challenge. Recent advances in the computation capabilities of wearables make it possible to target complex scenarios by exploiting multiple biosignals and using high-performance algorithms, such as Deep Neural Networks (DNNs). However, there is a tradeoff between the algorithms’ performance and the low-power requirements of platforms with limited resources. Besides, physically larger and multi-biosignal-based wearables bring significant discomfort to the patients. Consequently, reducing power consumption and discomfort is necessary for patients to use wearable devices continuously during everyday life. To overcome these challenges, in the context of epileptic seizure detection, we propose the Multi-to-Single Knowledge Distillation (M2SKD) approach targeting single-biosignal processing in wearable systems. The starting point is to train a highly-accurate multi-biosignal DNN, then apply M2SKD to develop a single-biosignal DNN solution for wearable systems that achieves an accuracy comparable to the original multi-biosignal DNN. To assess the practicality of our approach to real-life scenarios, we perform a comprehensive simulation experiment analysis on several edge computing platforms.},
  archive      = {J_TIST},
  doi          = {10.1145/3675402},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {10},
  number       = {5},
  pages        = {1-31},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {M2SKD: Multi-to-single knowledge distillation of real-time epileptic seizure detection for low-power wearable systems},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MedNER: Enhanced named entity recognition in medical corpus
via optimized balanced and deep active learning. <em>TIST</em>,
<em>15</em>(5), 1–24. (<a
href="https://doi.org/10.1145/3678178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ever-growing electronic medical corpora provide unprecedented opportunities for researchers to analyze patient conditions and drug effects. Meanwhile, severe challenges emerged in the large-scale electronic medical records process phase. Primarily, emerging words for medical terms, including informal descriptions, are difficult to recognize. Moreover, although deep models can help in entity extraction on medical texts, they require large-scale labels, which are time-intensive to obtain and not always available in the medical domain. However, when encountering a situation where massive unseen concepts appear or labeled data is insufficient, the performance of existing algorithms will suffer an intolerable decline. In this article, we propose a balanced and deep active learning framework for Medical Named Entity Recognition (MedNER) to alleviate the above problems. Specifically, to describe our selection strategy precisely, we first define the uncertainty of a medical sentence as a labeling loss predicted by a loss-prediction module and define diversity as the least text distance between pairs of sentences in a sample batch computed based on word-morpheme embeddings. Furthermore, aiming to make a trade-off between uncertainty and diversity, we formulate a Distinct-K optimization problem to maximize the slightest uncertainty and diversity of chosen sentences. Finally, we propose a threshold-based approximation selection algorithm, Distinct-K Filter , which selects the most beneficial training samples by balancing diversity and uncertainty. Extensive experimental results on real datasets demonstrate that MedNER significantly outperforms existing approaches.},
  archive      = {J_TIST},
  doi          = {10.1145/3678178},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {10},
  number       = {5},
  pages        = {1-24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {MedNER: Enhanced named entity recognition in medical corpus via optimized balanced and deep active learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WC-SBERT: Zero-shot topic classification using SBERT and
light self-training on wikipedia categories. <em>TIST</em>,
<em>15</em>(5), 1–18. (<a
href="https://doi.org/10.1145/3678183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In natural language processing (NLP), zero-shot topic classification requires machines to understand the contextual meanings of texts in a downstream task without using the corresponding labeled texts for training, which is highly desirable for various applications. In this article, we propose a novel approach to construct a zero-shot task-specific model called WC-SBERT with satisfactory performance. The proposed approach is highly efficient since it uses light self-training requiring target labels (target class names of downstream tasks) only, which is distinct from other research that uses both the target labels and the unlabeled texts for training. In particular, during the pre-training stage, WC-SBERT uses contrastive learning with multiple negative ranking losses to construct the pre-trained model based on the similarity between Wiki categories. For the self-training stage, online contrastive loss is utilized to reduce the distance between a target label and Wiki categories of similar Wiki pages to the label. Experimental results indicate that compared to existing self-training models, WC-SBERT achieves rapid inference on approximately 6.45 million Wiki text entries by utilizing pre-stored Wikipedia text embeddings, significantly reducing inference time per sample by a factor of 2,746 to 16,746. During the fine-tuning step, the time required for each sample is reduced by a factor of 23–67. Overall, the total training time shows a maximum reduction of 27.5 times across different datasets. Most importantly, our model has achieved state-of-the-art (SOTA) accuracy on two of the three commonly used datasets for evaluating zero-shot classification, namely the AG News (0.84) and Yahoo! Answers (0.64) datasets. The code for WC-SBERT is publicly available on GitHub, 1 and the dataset can also be accessed on Hugging Face. 2},
  archive      = {J_TIST},
  doi          = {10.1145/3678183},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {10},
  number       = {5},
  pages        = {1-18},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {WC-SBERT: Zero-shot topic classification using SBERT and light self-training on wikipedia categories},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Special issue on responsible recommender systems part 1.
<em>TIST</em>, <em>15</em>(4), 1–3. (<a
href="https://doi.org/10.1145/3663528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TIST},
  doi          = {10.1145/3663528},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {8},
  number       = {4},
  pages        = {1-3},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Special issue on responsible recommender systems part 1},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy-preserving point-of-interest recommendation based on
simplified graph convolutional network for geological traveling.
<em>TIST</em>, <em>15</em>(4), 1–17. (<a
href="https://doi.org/10.1145/3620677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The provision of privacy-preserving recommendations for geological tourist attractions is an important research area. The historical check-in data collected from location-based social networks (LBSNs) can be utilized to mine their preferences, thereby facilitating the promotion of the geological tourism industry. However, such check-ins often contain sensitive user information that poses privacy leakage risks. To address this issue, some methods have been proposed to develop privacy-preserving point-of-interest (POI) recommendation systems. These methods commonly rely on either perturbation-based or federated learning techniques to protect users’ privacy. However, the former can hinder preference capture, while the latter remains vulnerable to privacy breaches during the parameter-sharing process. To overcome these challenges, we propose a novel privacy-preserving POI recommendation model that incorporates users’ privacy preferences based on a simplified graph convolutional neural network. Specifically, we employ a generative model to create a subset of POIs that reflect users’ preferences but do not reveal their private information, and then we design a simplified graph convolutional network to analyze the high-order connectivity between users and POIs that are privacy-preserving. The resulting model enables efficient POI recommendation under strict privacy protection, which is particularly relevant to geological tourism. Experimental results on two public datasets demonstrate the effectiveness of our proposed approach.},
  archive      = {J_TIST},
  doi          = {10.1145/3620677},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Privacy-preserving point-of-interest recommendation based on simplified graph convolutional network for geological traveling},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MHANER: A multi-source heterogeneous graph attention network
for explainable recommendation in online games. <em>TIST</em>,
<em>15</em>(4), 1–23. (<a
href="https://doi.org/10.1145/3626243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender system helps address information overload problem and satisfy consumers’ personalized requirement in many applications such as e-commerce, social networks, and in-game store. However, existing approaches mainly focus on improving the accuracy of recommendation tasks but usually ignore how to improve the interpretability of recommendation, which is still a challenging and crucial task, especially for some complicated scenarios such as large-scale online games. A few previous attempts on explainable recommendation mostly depend on a large amount of a priori knowledge or user-provided review corpus, which is labor consuming as well as often suffers from data deficiency. To relieve this issue, we propose a Multi-source Heterogeneous Graph Attention Network for Explainable Recommendation (MHANER) for the case without enough a priori knowledge or corpus of user comments. Specifically, MHANER employs the attention mechanism to model players’ preference to in-game store items as the support for the explanation of recommendation. Then a graph neural network–based method is designed to model players’ multi-source heterogeneous information, including the players’ historical behavior data, historical purchase data, and attributes of the player-controlled character, which is leveraged to recommend possible items for players to buy. Finally, the multi-level subgraph pattern mining is adopted to combine the characteristics of a recommendation list to generate corresponding explanations of items. Extensive experiments on three real-world datasets, two collected from JD and one from NetEase game, demonstrate that the proposed model MHANER outperforms state-of-the-art baselines. Moreover, the generated explanations are verified by human encoding comprised of hard-core game players and endorsed by experts from game developers.},
  archive      = {J_TIST},
  doi          = {10.1145/3626243},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {MHANER: A multi-source heterogeneous graph attention network for explainable recommendation in online games},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trustworthy recommender systems. <em>TIST</em>,
<em>15</em>(4), 1–20. (<a
href="https://doi.org/10.1145/3627826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems (RSs) aim at helping users to effectively retrieve items of their interests from a large catalogue. For a quite long time, researchers and practitioners have been focusing on developing accurate RSs. Recent years have witnessed an increasing number of threats to RSs, coming from attacks, system and user generated noise, and various types of biases. As a result, it has become clear that the focus on RS accuracy is too narrow, and the research must consider other important factors, particularly trustworthiness. A trustworthy recommender system (TRS) should not only be accurate but also transparent, unbiased, fair, and robust to noise and attacks. These observations actually led to a paradigm shift of the research on RSs: from accuracy-oriented RSs to TRSs. However, there is a lack of a systematic overview and discussion of the literature in this novel and fast-developing field of TRSs. To this end, in this article, we provide an overview of TRSs, including a discussion of the motivation and basic concepts of TRSs, a presentation of the challenges in building TRSs, and a perspective on the future directions in this area. We also provide a novel conceptual framework to support the construction of TRSs.},
  archive      = {J_TIST},
  doi          = {10.1145/3627826},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Trustworthy recommender systems},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Responsible recommendation services with blockchain
empowered asynchronous federated learning. <em>TIST</em>,
<em>15</em>(4), 1–24. (<a
href="https://doi.org/10.1145/3633520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy and trust are highly demanding in practical recommendation engines. Although Federated Learning (FL) has significantly addressed privacy concerns, commercial operators are still worried about several technical challenges while bringing FL into production. In addition, classical FL has several intrinsic operational limitations such as single-point failure, data and model tampering, and heterogenic clients participating in the FL process. To address these challenges in practical recommenders, we propose a responsible recommendation generation framework based on blockchain-empowered asynchronous FL that can be adopted for any model-based recommender system. In standard FL settings, we build an additional aggregation layer in which multiple trusted nodes guided by a mediator component perform gradient aggregation to achieve an optimal model locally in a parallel fashion. The mediator partitions users into K clusters, and each cluster is represented by a cluster head. Once a cluster gets semi-global convergence, the cluster head transmits model gradients to the FL server for global aggregation. In addition the trusted cluster heads are responsible to submit the converged semi-global model to a blockchain to ensure tamper resilience. In our settings, an additional mediator component works like an independent observer that monitors the performance of each cluster head, updates a reward score, and records it into a digital ledger. Finally, evaluation results on three diversified benchmarks illustrate that the recommendation performance on selected measures is considerably comparable with the standard and federated version of a well-known neural collaborative filtering recommender.},
  archive      = {J_TIST},
  doi          = {10.1145/3633520},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Responsible recommendation services with blockchain empowered asynchronous federated learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explicit knowledge graph reasoning for conversational
recommendation. <em>TIST</em>, <em>15</em>(4), 1–21. (<a
href="https://doi.org/10.1145/3637216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommender systems estimate user preference on items purely based on historical interaction records, thus failing to capture fine-grained yet dynamic user interests and letting users receive recommendation only passively. Recent conversational recommender systems (CRSs) tackle those limitations by enabling recommender systems to interact with the user to obtain her/his current preference through a sequence of clarifying questions. Recently, there has been a rise of using knowledge graphs (KGs) for CRSs, where the core motivation is to incorporate the abundant side information carried by a KG into both the recommendation and conversation processes. However, existing KG-based CRSs are subject to two defects: (1) there is a semantic gap between the learned representations of utterances and KG entities, hindering the retrieval of relevant KG information; (2) the reasoning over KG is mostly performed with the implicitly learned user interests, overlooking the explicit signals from the entities actually mentioned in the conversation. To address these drawbacks, we propose a new CRS framework, namely, the Knowledge Enhanced Conversational Reasoning (KECR) model. As a user can reflect her/his preferences via both attribute- and item-level expressions, KECR jointly embeds the structured knowledge from two levels in the KG. A mutual information maximization constraint is further proposed for semantic alignment between the embedding spaces of utterances and KG entities. Meanwhile, KECR utilizes the connectivity within the KG to conduct explicit reasoning of the user demand, making the model less dependent on the user’s feedback to clarifying questions. As such, the semantic alignment and explicit KG reasoning can jointly facilitate accurate recommendation and quality dialogue generation. By comparing with strong baselines on two real-world datasets, we demonstrate that KECR obtains state-of-the-art recommendation effectiveness, as well as competitive dialogue generation performance.},
  archive      = {J_TIST},
  doi          = {10.1145/3637216},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Explicit knowledge graph reasoning for conversational recommendation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Personalized fashion recommendations for diverse body shapes
with contrastive multimodal cross-attention network. <em>TIST</em>,
<em>15</em>(4), 1–21. (<a
href="https://doi.org/10.1145/3637217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fashion recommendation has become a prominent focus in the realm of online shopping, with various tasks being explored to enhance the customer experience. Recent research has particularly emphasized fashion recommendation based on body shapes, yet a critical aspect of incorporating multimodal data relevance has been overlooked. In this paper, we present the Contrastive Multimodal Cross-Attention Network, a novel approach specifically designed for fashion recommendation catering to diverse body shapes. By incorporating multimodal representation learning and leveraging contrastive learning techniques, our method effectively captures both inter- and intra-sample relationships, resulting in improved accuracy in fashion recommendations tailored to individual body types. Additionally, we propose a locality-aware cross-attention module to align and understand the local preferences between body shapes and clothing items, thus enhancing the matching process. Experimental results conducted on a diverse dataset demonstrate the state-of-the-art performance achieved by our approach, reinforcing its potential to significantly enhance the personalized online shopping experience for consumers with varying body shapes and preferences.},
  archive      = {J_TIST},
  doi          = {10.1145/3637217},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Personalized fashion recommendations for diverse body shapes with contrastive multimodal cross-attention network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AMT-CDR: A deep adversarial multi-channel transfer network
for cross-domain recommendation. <em>TIST</em>, <em>15</em>(4), 1–26.
(<a href="https://doi.org/10.1145/3641286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are one of the most successful applications of using AI for providing personalized e-services to customers. However, data sparsity is presenting enormous challenges that are hindering the further development of advanced recommender systems. Although cross-domain recommendation partly overcomes data sparsity by transferring knowledge from a source domain with relatively dense data to augment data in the target domain, the current methods do not handle heterogeneous data very well. For example, using today’s cross-domain transfer learning schemes with data comprising clicks, ratings, user reviews, item metadata, and knowledge graphs will likely result in a poorly performing model. User preferences will not be comprehensively profiled, and accurate recommendations will not be generated. To solve these three challenges—handling heterogeneous data, avoiding negative transfer, and dealing with data sparsity—we designed a new end-to-end deep A dversarial M ulti-channel T ransfer network for C ross- D omain R ecommendation named AMT-CDR . Heterogeneous data is handled by constructing a cross-domain graph based on real-world knowledge graphs—we used Freebase and YAGO. Negative transfer is prevented through an adversarial learning strategy that maintains consistency across the different data channels. Data sparsity is addressed with an end-to-end neural network that considers data across multiple channels and generates accurate recommendations by leveraging knowledge from both the source and target domains. Extensive experiments on three dual-target cross-domain recommendation tasks demonstrate the superiority of AMT-CDR compared to eight state-of-the-art methods. All source code is available at https://github.com/bjtu-lucas-nlp/AMT-CDR .},
  archive      = {J_TIST},
  doi          = {10.1145/3641286},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {AMT-CDR: A deep adversarial multi-channel transfer network for cross-domain recommendation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decentralized federated recommendation with privacy-aware
structured client-level graph. <em>TIST</em>, <em>15</em>(4), 1–23. (<a
href="https://doi.org/10.1145/3641287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation models are deployed in a variety of commercial applications to provide personalized services for users. However, most of them rely on the users’ original rating records that are often collected by a centralized server for model training, which may cause privacy issues. Recently, some centralized federated recommendation models are proposed for the protection of users’ privacy, which however requires a server for coordination in the whole process of model training. As a response, we propose a novel privacy-aware decentralized federated recommendation (DFedRec) model, which is lossless compared with the traditional model in recommendation performance and is thus more accurate than other models in this line. Specifically, we design a privacy-aware structured client-level graph for the sharing of the model parameters in the process of model training, which is a one-stone-two-bird strategy, i.e., it protects users’ privacy via some randomly sampled fake entries and reduces the communication cost by sharing the model parameters only with the related neighboring users. With the help of the privacy-aware structured client-level graph, we propose two novel collaborative training mechanisms in the setting without a server, including a batch algorithm DFedRec(b) and a stochastic one DFedRec(s), where the former requires the anonymity mechanism while the latter does not. They are both equivalent to probabilistic matrix factorization trained in a centralized server and are thus lossless. We then provide formal analysis of privacy guarantee of our methods and conduct extensive empirical studies on three public datasets with explicit feedback, which show the effectiveness of our DFedRec, i.e., it is privacy aware, communication efficient, and lossless.},
  archive      = {J_TIST},
  doi          = {10.1145/3641287},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Decentralized federated recommendation with privacy-aware structured client-level graph},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge graph enhanced contextualized attention-based
network for responsible user-specific recommendation. <em>TIST</em>,
<em>15</em>(4), 1–24. (<a
href="https://doi.org/10.1145/3641288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With ever-increasing dataset size and data storage capacity, there is a strong need to build systems that can effectively utilize these vast datasets to extract valuable information. Large datasets often exhibit sparsity and pose cold start problems, necessitating the development of responsible recommender systems. Knowledge graphs have utility in responsibly representing information related to recommendation scenarios. However, many studies overlook explicitly encoding contextual information, which is crucial for reducing the bias of multi-layer propagation. Additionally, existing methods stack multiple layers to encode high-order neighbor information while disregarding the relational information between items and entities. This oversight hampers their ability to capture the collaborative signal latent in user-item interactions. This is particularly important in health informatics, where knowledge graphs consist of various entities connected to items through different relations. Ignoring the relational information renders them insufficient for modeling user preferences. This work presents an end-to-end recommendation framework named KGCAN (Knowledge Graph Enhanced Contextualized Attention-Based Network), which explicitly encodes both relational and contextual information of entities to preserve the original entity information. Furthermore, a user-specific attention mechanism is employed to capture personalized recommendations. The proposed model is validated on three benchmark datasets through extensive experiments. The experimental results demonstrate that KGCAN outperforms existing knowledge graph based recommendation models. Additionally, a case study from the healthcare domain is discussed, highlighting the importance of attention mechanisms and high-order connectivity in the responsible recommendation system for health informatics.},
  archive      = {J_TIST},
  doi          = {10.1145/3641288},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Knowledge graph enhanced contextualized attention-based network for responsible user-specific recommendation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overcoming diverse undesired effects in recommender systems:
A deontological approach. <em>TIST</em>, <em>15</em>(4), 1–23. (<a
href="https://doi.org/10.1145/3643857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s digital landscape, recommender systems have gained ubiquity as a means of directing users toward personalized products, services, and content. However, despite their widespread adoption and a long track of research, these systems are not immune to shortcomings. A significant challenge faced by recommender systems is the presence of biases, which produces various undesirable effects, prominently the popularity bias. This bias hampers the diversity of recommended items, thus restricting users’ exposure to less popular or niche content. Furthermore, this issue is compounded when multiple stakeholders are considered, requiring the balance of multiple, potentially conflicting objectives. In this article, we present a new approach to address a wide range of undesired consequences in recommender systems that involve various stakeholders. Instead of adopting a consequentialist perspective that aims to mitigate the repercussions of a recommendation policy, we propose a deontological approach centered around a minimal set of ethical principles. More precisely, we introduce two distinct principles aimed at avoiding overconfidence in predictions and accurately modeling the genuine interests of users. The proposed approach circumvents the need for defining a multi-objective system, which has been identified as one of the main limitations when developing complex recommenders. Through extensive experimentation, we show the efficacy of our approach in mitigating the adverse impact of the recommender from both user and item perspectives, ultimately enhancing various beyond accuracy metrics. This study underscores the significance of responsible and equitable recommendations and proposes a strategy that can be easily deployed in real-world scenarios.},
  archive      = {J_TIST},
  doi          = {10.1145/3643857},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Overcoming diverse undesired effects in recommender systems: A deontological approach},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel blockchain-based responsible recommendation system
for service process creation and recommendation. <em>TIST</em>,
<em>15</em>(4), 1–24. (<a
href="https://doi.org/10.1145/3643858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Service composition platforms play a crucial role in creating personalized service processes. Challenges, including the risk of tampering with service data during service invocation and the potential single point of failure in centralized service registration centers, hinder the efficient and responsible creation of service processes. This paper presents a novel framework called Context-Aware Responsible Service Process Creation and Recommendation (SPCR-CA), which incorporates blockchain, Recurrent Neural Networks (RNNs), and a Skip-Gram model holistically to enhance the security, efficiency, and quality of service process creation and recommendation. Specifically, the blockchain establishes a trusted service provision environment, ensuring transparent and secure transactions between services and mitigating the risk of tampering. The RNN trains responsible service processes, contextualizing service components and producing coherent recommendations of linkage components. The Skip-Gram model trains responsible user-service process records, generating semantic vectors that facilitate the recommendation of similar service processes to users. Experiments using the Programmable-Web dataset demonstrate the superiority of the SPCR-CA framework to existing benchmarks in precision and recall. The proposed framework enhances the reliability, efficiency, and quality of service process creation and recommendation, enabling users to create responsible and tailored service processes. The SPCR-CA framework offers promising potential to provide users with secure and user-centric service creation and recommendation capabilities.},
  archive      = {J_TIST},
  doi          = {10.1145/3643858},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A novel blockchain-based responsible recommendation system for service process creation and recommendation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boosting healthiness exposure in category-constrained meal
recommendation using nutritional standards. <em>TIST</em>,
<em>15</em>(4), 1–28. (<a
href="https://doi.org/10.1145/3643859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food computing, a newly emerging topic, is closely linked to human life through computational methodologies. Meal recommendation, a food-related study about human health, aims to provide users a meal with courses constrained from specific categories (e.g., appetizers, main dishes) that can be enjoyed as a service. Historical interaction data, important user information, is often used by existing models to learn user preferences. However, if a user’s preferences favor less healthy meals, the model will follow that preference and make similar recommendations, potentially negatively impacting the user’s long-term health. This emphasizes the necessity for health-oriented and responsible meal recommendation systems. In this article, we propose a healthiness-aware and category-wise meal recommendation model called CateRec, which boosts healthiness exposure by using nutritional standards as knowledge to guide the model training. Two fundamental questions are raised and answered: (1) How can the healthiness of meals be evaluated? Two well-known nutritional standards from the World Health Organization and the United Kingdom Food Standards Agency are used to calculate the healthiness score of the meal. (2) How can the model training be guided in a health-oriented manner? We construct category-wise personalization partial rankings and category-wise healthiness partial rankings, and theoretically analyze that they meet the necessary properties and assumptions required to be trained by the maximum posterior estimator under Bayesian probability. The data analysis confirms the existence of user preferences leaning towards less healthy meals in two public datasets. A comprehensive experiment demonstrates that our CateRec effectively boosts healthiness exposure in terms of mean healthiness score and ranking exposure while being comparable to the state-of-the-art model in terms of recommendation accuracy.},
  archive      = {J_TIST},
  doi          = {10.1145/3643859},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-28},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Boosting healthiness exposure in category-constrained meal recommendation using nutritional standards},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FEIR: Quantifying and reducing envy and inferiority for fair
recommendation of limited resources. <em>TIST</em>, <em>15</em>(4),
1–24. (<a href="https://doi.org/10.1145/3643891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation in settings such as e-recruitment and online dating involves distributing limited opportunities, which differs from recommending practically unlimited goods such as in e-commerce or music recommendation. This setting calls for novel approaches to quantify and enforce fairness. Indeed, typical recommender systems recommend each user their top relevant items, such that desirable items may be recommended simultaneously to more and to less qualified individuals. This is arguably unfair to the latter. Indeed, when they pursue such a desirable recommendation (e.g., by applying for a job), they are unlikely to be successful. To quantify fairness in such settings, we introduce inferiority : a novel (un)fairness measure that quantifies the competitive disadvantage of a user for their recommended items. Inferiority is complementary to envy : a previously-proposed fairness notion that quantifies the extent to which a user prefers other users’ recommendations over their own. We propose to use both inferiority and envy in combination with an accuracy-related measure called utility : the aggregated relevancy scores of the recommended items. Unfortunately, none of these three measures are differentiable, making it hard to optimize them, and restricting their immediate use to evaluation only. To remedy this, we reformulate them in the context of a probabilistic interpretation of recommender systems, resulting in differentiable versions. We show how these loss functions can be combined in a multi-objective optimization problem that we call FEIR (Fairness through Envy and Inferiority Reduction), used as a post-processing of the scores from any standard recommender system. Experiments on synthetic and real-world data show that the proposed approach effectively improves the trade-offs between inferiority, envy and utility, compared to the naive recommendation and the state-of-the-art method for the related problem of congestion alleviation in job recommendation. We discuss and enhance the practical impact of our findings on a wide range of real-world recommendation scenarios, and we offer implementations of visualization tools to render the envy and inferiority metrics more accessible.},
  archive      = {J_TIST},
  doi          = {10.1145/3643891},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {FEIR: Quantifying and reducing envy and inferiority for fair recommendation of limited resources},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Balanced quality score: Measuring popularity debiasing in
recommendation. <em>TIST</em>, <em>15</em>(4), 1–27. (<a
href="https://doi.org/10.1145/3650043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Popularity bias is the tendency of recommender systems to further suggest popular items while disregarding niche ones, hence giving no chance for items with low popularity to emerge. Although the literature is rich in debiasing techniques, it still lacks quality measures that effectively enable their analyses and comparisons. In this article, we first introduce a formal, data-driven, and parameter-free strategy for classifying items into low, medium, and high popularity categories. Then we introduce Balanced Quality Score (BQS) , a quality measure that rewards the debiasing techniques that successfully push a recommender system to suggest niche items, without losing points in its predictive capability in terms of global accuracy. We conduct tests of BQS on three distinct baseline collaborative filtering frameworks: one based on history-embedding and two on user/item-embedding modeling. These evaluations are performed on multiple benchmark datasets and against various state-of-the-art competitors, demonstrating the effectiveness of BQS.},
  archive      = {J_TIST},
  doi          = {10.1145/3650043},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-27},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Balanced quality score: Measuring popularity debiasing in recommendation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Break out of a pigeonhole: A unified framework for examining
miscalibration, bias, and stereotype in recommender systems.
<em>TIST</em>, <em>15</em>(4), 1–20. (<a
href="https://doi.org/10.1145/3650044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the benefits of personalizing items and information tailored to users’ needs, it has been found that recommender systems tend to introduce biases that favor popular items or certain categories of items and dominant user groups. In this study, we aim to characterize the systematic errors of a recommendation system and how they manifest in various accountability issues, such as stereotypes, biases, and miscalibration. We propose a unified framework that distinguishes the sources of prediction errors into a set of key measures that quantify the various types of system-induced effects, at both the individual and collective levels. Based on our measuring framework, we examine the most widely adopted algorithms in the context of movie recommendation. Our research reveals three important findings: (1) Differences between algorithms: recommendations generated by simpler algorithms tend to be more stereotypical but less biased than those generated by more complex algorithms. (2) Disparate impact on groups and individuals: system-induced biases and stereotypes have a disproportionate effect on atypical users and minority groups (e.g., women and older users). (3) Mitigation opportunity: using structural equation modeling, we identify the interactions between user characteristics (typicality and diversity), system-induced effects, and miscalibration. We further investigate the possibility of mitigating system-induced effects by oversampling underrepresented groups and individuals, which was found to be effective in reducing stereotypes and improving recommendation quality. Our research is the first systematic examination of not only system-induced effects and miscalibration but also the stereotyping issue in recommender systems.},
  archive      = {J_TIST},
  doi          = {10.1145/3650044},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Break out of a pigeonhole: A unified framework for examining miscalibration, bias, and stereotype in recommender systems},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental data drifting: Evaluation metrics, data
generation, and approach comparison. <em>TIST</em>, <em>15</em>(4),
1–26. (<a href="https://doi.org/10.1145/3655630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incremental data drifting is a common problem when employing a machine-learning model in industrial applications. The underlying data distribution evolves gradually, e.g., users change their buying preferences on an E-commerce website over time. The problem needs to be addressed to obtain high performance. Right now, studies regarding incremental data drifting suffer from several issues. For one thing, there is a lack of clear-defined incremental drift datasets for examination. Existing efforts use either collected real datasets or synthetic datasets that show two obvious limitations. One is in particular when and of which type of drifts the distribution undergoes is unknown, and the other is that a simple synthesized dataset cannot reflect the complex representation we would normally face in the real world. For another, there lacks a well-defined protocol to evaluate a learner’s knowledge transfer capability on an incremental drift dataset. To provide a holistic discussion on these issues, we create approaches to generate datasets with specific drift types, and define a novel protocol for evaluation. Besides, we investigate recent advances in the transfer learning field, including Domain Adaptation and Lifelong Learning, and examine how they perform in the presence of incremental data drifting. The results unfold the relationships among drift types, knowledge preservation, and learning approaches.},
  archive      = {J_TIST},
  doi          = {10.1145/3655630},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {7},
  number       = {4},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Incremental data drifting: Evaluation metrics, data generation, and approach comparison},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discovering expert-level air combat knowledge via deep
excitatory-inhibitory factorized reinforcement learning. <em>TIST</em>,
<em>15</em>(4), 1–28. (<a
href="https://doi.org/10.1145/3653979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) has achieved a wide range of successes in autonomous air combat decision-making recently. Previous research demonstrated that AI-enabled air combat approaches could even acquire beyond human-level capabilities. However, there remains a lack of evidence regarding two major difficulties. First, the existing methods with fixed decision intervals are mostly devoted to solving what to act but merely pay attention to when to act, which occasionally misses optimal decision opportunities. Second, the method of an expert-crafted finite maneuver library leads to a lack of tactics diversity, which is vulnerable to an opponent equipped with new tactics. In view of this, we propose a novel Deep Reinforcement Learning (DRL) and prior knowledge hybrid autonomous air combat tactics discovering algorithm, namely deep E xcitatory-i N hibitory f ACT or I zed maneu VE r ( ENACTIVE ) learning. The algorithm consists of two key modules, i.e., ENHANCE and FACTIVE. Specifically, ENHANCE learns to adjust the air combat decision-making intervals and appropriately seize key opportunities. FACTIVE factorizes maneuvers and then jointly optimizes them with significant tactics diversity increments. Extensive experimental results reveal that the proposed method outperforms state-of-the-art algorithms with a 62% winning rate and further obtains a margin of a 2.85-fold increase in terms of global tactic space coverage. It also demonstrates that a variety of discovered air combat tactics are comparable to human experts’ knowledge.},
  archive      = {J_TIST},
  doi          = {10.1145/3653979},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {6},
  number       = {4},
  pages        = {1-28},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Discovering expert-level air combat knowledge via deep excitatory-inhibitory factorized reinforcement learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable finite mixture of mixtures of bounded asymmetric
generalized gaussian and uniform distributions learning for energy
demand management. <em>TIST</em>, <em>15</em>(4), 1–26. (<a
href="https://doi.org/10.1145/3653980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a mixture of mixtures of bounded asymmetric generalized Gaussian and uniform distributions. Based on this framework, we propose model-based classification and model-based clustering algorithms. We develop an objective function for the minimum message length (MML) model selection criterion to discover the optimal number of clusters for the unsupervised approach of our proposed model. Given the crucial attention received by Explainable AI (XAI) in recent years, we introduce a method to interpret the predictions obtained from the proposed model in both learning settings by defining their boundaries in terms of the crucial features. Integrating Explainability within our proposed algorithm increases the credibility of the algorithm’s predictions since it would be explainable to the user’s perspective through simple If-Then statements using a small binary decision tree. In this paper, the proposed algorithm proves its reliability and superiority to several state-of-the-art machine learning algorithms within the following real-world applications: fault detection and diagnosis (FDD) in chillers, occupancy estimation and categorization of residential energy consumers.},
  archive      = {J_TIST},
  doi          = {10.1145/3653980},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {6},
  number       = {4},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Explainable finite mixture of mixtures of bounded asymmetric generalized gaussian and uniform distributions learning for energy demand management},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated momentum contrastive clustering. <em>TIST</em>,
<em>15</em>(4), 1–19. (<a
href="https://doi.org/10.1145/3653981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised representation learning and deep clustering are mutually beneficial to learn high-quality representations and cluster data simultaneously in centralized settings. However, it is not always feasible to gather large amounts of data at a central entity, considering data privacy requirements and computational resources. Federated Learning (FL) has been developed successfully to aggregate a global model while training on distributed local data, respecting the data privacy of edge devices. However, most FL research effort focuses on supervised learning algorithms. A fully unsupervised federated clustering scheme has not been considered in the existing literature. We present federated momentum contrastive clustering (FedMCC), a generic federated clustering framework that can not only cluster data automatically but also extract discriminative representations training from distributed local data over multiple users. In FedMCC, we demonstrate a two-stage federated learning paradigm where the first stage aims to learn differentiable instance embeddings and the second stage accounts for clustering data automatically. The experimental results show that FedMCC not only achieves superior clustering performance but also outperforms several existing federated self-supervised methods for linear evaluation and semi-supervised learning tasks. Additionally, FedMCC can easily be adapted to ordinary centralized clustering through what we call momentum contrastive clustering (MCC). We show that MCC achieves state-of-the-art clustering accuracy results in certain datasets such as STL-10 and ImageNet-10. We also present a method to reduce the memory footprint of our clustering schemes.},
  archive      = {J_TIST},
  doi          = {10.1145/3653981},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {6},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Federated momentum contrastive clustering},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep causal reasoning for recommendations. <em>TIST</em>,
<em>15</em>(4), 1–25. (<a
href="https://doi.org/10.1145/3653985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommender systems aim to estimate a user’s rating to an item based on observed ratings from the population. As with all observational studies, hidden confounders, which are factors that affect both item exposures and user ratings, lead to a systematic bias in the estimation. Consequently, causal inference has been introduced in recommendations to address the influence of unobserved confounders. Observing that confounders in recommendations are usually shared among items and are therefore multi-cause confounders, we model the recommendation as a multi-cause multi-outcome (MCMO) inference problem. Specifically, to remedy the confounding bias, we estimate user-specific latent variables that render the item exposures independent Bernoulli trials. The generative distribution is parameterized by a DNN with factorized logistic likelihood and the intractable posteriors are estimated by variational inference. Controlling these factors as substitute confounders, under mild assumptions, can eliminate the bias incurred by multi-cause confounders. Furthermore, we show that MCMO modeling may lead to high variance due to scarce observations associated with the high-dimensional treatment space. Therefore, we theoretically demonstrate that controlling user features as pre-treatment variables can substantially improve sample efficiency and alleviate overfitting. Empirical studies on both simulated and real-world datasets demonstrate that the proposed deep causal recommender shows more robustness to unobserved confounders than state-of-the-art causal recommenders. Codes and datasets are released at https://github.com/yaochenzhu/Deep-Deconf.},
  archive      = {J_TIST},
  doi          = {10.1145/3653985},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {6},
  number       = {4},
  pages        = {1-25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Deep causal reasoning for recommendations},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust structure-aware graph-based semi-supervised learning:
Batch and recursive processing. <em>TIST</em>, <em>15</em>(4), 1–25. (<a
href="https://doi.org/10.1145/3653986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based semi-supervised learning plays an important role in large scale image classification tasks. However, the problem becomes very challenging in the presence of noisy labels and outliers. Moreover, traditional robust semi-supervised learning solutions suffers from prohibitive computational burdens thus cannot be computed for streaming data. Motivated by that, we present a novel unified framework robust structure-aware semi-supervised learning called Unified RSSL (URSSL) for batch processing and recursive processing robust to both outliers and noisy labels. Particularly, URSSL applies joint semi-supervised dimensionality reduction with robust estimators and network sparse regularization simultaneously on the graph Laplacian matrix iteratively to preserve the intrinsic graph structure and ensure robustness to the compound noise. First, in order to relieve the influence from outliers, a novel semi-supervised robust dimensionality reduction is applied relying on robust estimators to suppress outliers. Meanwhile, to tackle noisy labels, the denoised graph similarity information is encoded into the network regularization. Moreover, by identifying strong relevance of dimensionality reduction and network regularization in the context of robust semi-supervised learning (RSSL), a two-step alternative optimization is derived to compute optimal solutions with guaranteed convergence. We further derive our framework to adapt to large scale semi-supervised learning particularly suitable for large scale image classification and demonstrate the model robustness under different adversarial attacks. For recursive processing, we rely on reparameterization to transform the formulation to unlock the challenging problem of robust streaming-based semi-supervised learning. Last but not least, we extend our solution into distributed solutions to resolve the challenging issue of distributed robust semi-supervised learning when images are captured by multiple cameras at different locations. Extensive experimental results demonstrate the promising performance of this framework when applied to multiple benchmark datasets with respect to state-of-the-art approaches for important applications in the areas of image classification and spam data analysis.},
  archive      = {J_TIST},
  doi          = {10.1145/3653986},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {6},
  number       = {4},
  pages        = {1-25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Robust structure-aware graph-based semi-supervised learning: Batch and recursive processing},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counterfactual graph convolutional learning for personalized
recommendation. <em>TIST</em>, <em>15</em>(4), 1–20. (<a
href="https://doi.org/10.1145/3655632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, recommender systems have witnessed the fast evolution of Internet services. However, it suffers hugely from inherent bias and sparsity issues in interactions. The conventional uniform embedding learning policies fail to utilize the imbalanced interaction clue and produce suboptimal representations to users and items for recommendation. Towards the issue, this work is dedicated to bias-aware embedding learning in a decomposed manner and proposes a counterfactual graph convolutional learning (CGCL) model for personalized recommendation. Instead of debiasing with uniform interaction sampling, we follow the natural interaction bias to model users’ interests with a counterfactual hypothesis. CGCL introduces bias-aware counterfactual masking on interactions to distinguish the effects between majority and minority causes on the counterfactual gap. It forms multiple counterfactual worlds to extract users’ interests in minority causes compared to the factual world. Concretely, users and items are represented with a causal decomposed embedding of majority and minority interests for recommendation. Experiments show that the proposed CGCL is superior to the state-of-the-art baselines. The performance illustrates the rationality of the counterfactual hypothesis in bias-aware embedding learning for personalized recommendation.},
  archive      = {J_TIST},
  doi          = {10.1145/3655632},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {6},
  number       = {4},
  pages        = {1-20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Counterfactual graph convolutional learning for personalized recommendation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An explore–exploit workload-bounded strategy for rare event
detection in massive energy sensor time series. <em>TIST</em>,
<em>15</em>(4), 1–25. (<a
href="https://doi.org/10.1145/3657641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of Internet-of-Things devices, the analysis of sensor-generated energy time series data has become increasingly important. This is especially crucial for detecting rare events like unusual electricity usage or water leakages in residential and commercial buildings, which is essential for optimizing energy efficiency and reducing costs. However, existing detection methods on large-scale data may fail to correctly detect rare events when they do not behave significantly differently from standard events or when their attributes are non-stationary. Additionally, the capacity of computational resources to analyze all time series data generated by an increasing number of sensors becomes a challenge. This situation creates an emergent demand for a workload-bounded strategy. To ensure both effectiveness and efficiency in detecting rare events in massive energy time series, we propose a heuristic-based framework called HALE . This framework utilizes an explore–exploit selection process that is specifically designed to recognize potential features of rare events in energy time series. HALE involves constructing an attribute-aware graph to preserve the attribute information of rare events. A heuristic-based random walk is then derived based on partial labels received at each time period to discover the non-stationarity of rare events. Potential rare event data are selected from the attribute-aware graph, and existing detection models are applied for final confirmation. Our study, which was conducted on three actual energy datasets, demonstrates that the HALE framework is both effective and efficient in its detection capabilities. This underscores its practicality in delivering cost-effective energy monitoring services.},
  archive      = {J_TIST},
  doi          = {10.1145/3657641},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {6},
  number       = {4},
  pages        = {1-25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {An Explore–Exploit workload-bounded strategy for rare event detection in massive energy sensor time series},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CGKPN: Cross-graph knowledge propagation network with
adaptive connection for reasoning-based machine reading comprehension.
<em>TIST</em>, <em>15</em>(4), 1–24. (<a
href="https://doi.org/10.1145/3658673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of machine reading comprehension (MRC) is to enable machine to read and understand a piece of text and then answer the corresponding question correctly. This task requires machine to not only be able to perform semantic understanding but also possess logical reasoning capabilities. Just like human reading, it involves thinking about the text from two interacting perspectives of semantics and logic. However, previous methods based on reading comprehension either consider only the logical structure of the text or only the semantic structure of the text and cannot simultaneously balance semantic understanding and logical reasoning. This single form of reasoning cannot make the machine fully understand the meaning of the text. Additionally, the issue of sparsity in composition presents a significant challenge for models that rely on graph-based reasoning. To this end, a cross-graph knowledge propagation network (CGKPN) with adaptive connection is presented to address the above issues. The model first performs self-view node embedding on the constructed logical graph and semantic graph to update the representations of the graphs. Specifically, a relevance matrix between nodes is introduced to adaptively adjust node connections in response to the challenge posed by sparse graph. Subsequently, CGKPN conducts cross-graph knowledge propagation on nodes that are identical in both graphs, effectively resolving conflicts arising from identical nodes in different views, and enabling the model to better integrate the logical and semantic relationships of the text through efficient interaction. Experiments on the two MRC datasets ReClor and LogiQA indicate the superior performance of our proposed model CGKPN compared to other existing baselines.},
  archive      = {J_TIST},
  doi          = {10.1145/3658673},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {6},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {CGKPN: Cross-graph knowledge propagation network with adaptive connection for reasoning-based machine reading comprehension},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysing utterances in LLM-based user simulation for
conversational search. <em>TIST</em>, <em>15</em>(3), 62:1–22. (<a
href="https://doi.org/10.1145/3650041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clarifying underlying user information needs by asking clarifying questions is an important feature of modern conversational search systems. However, evaluation of such systems through answering prompted clarifying questions requires significant human effort, which can be time-consuming and expensive. In our recent work, we proposed an approach to tackle these issues with a user simulator, USi . Given a description of an information need, USi is capable of automatically answering clarifying questions about the topic throughout the search session. However, while the answers generated by USi are both in line with the underlying information need and in natural language, a deeper understanding of such utterances is lacking. Thus, in this work, we explore utterance formulation of large language model (LLM)–based user simulators. To this end, we first analyze the differences between USi , based on GPT-2, and the next generation of generative LLMs, such as GPT-3. Then, to gain a deeper understanding of LLM-based utterance generation, we compare the generated answers to the recently proposed set of patterns of human-based query reformulations. Finally, we discuss potential applications as well as limitations of LLM-based user simulators and outline promising directions for future work on the topic.},
  archive      = {J_TIST},
  author       = {Ivan Sekulić and Mohammad Alinannejadi and Fabio Crestani},
  doi          = {10.1145/3650041},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {5},
  number       = {3},
  pages        = {62:1–22},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Analysing utterances in LLM-based user simulation for conversational search},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quintuple-based representation learning for bipartite
heterogeneous networks. <em>TIST</em>, <em>15</em>(3), 61:1–19. (<a
href="https://doi.org/10.1145/3653978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen rapid progress in network representation learning, which removes the need for burdensome feature engineering and facilitates downstream network-based tasks. In reality, networks often exhibit heterogeneity, which means there may exist multiple types of nodes and interactions. Heterogeneous networks raise new challenges to representation learning, as the awareness of node and edge types is required. In this article, we study a basic building block of general heterogeneous networks, the heterogeneous networks with two types of nodes. Many problems can be solved by decomposing general heterogeneous networks into multiple bipartite ones. Recently, to overcome the demerits of non-metric measures used in the embedding space, metric learning-based approaches have been leveraged to tackle heterogeneous network representation learning. These approaches first generate triplets of samples, in which an anchor node, a positive counterpart, and a negative one co-exist, and then try to pull closer positive samples and push away negative ones. However, when dealing with heterogeneous networks, even the simplest two-typed ones, triplets cannot simultaneously involve both positive and negative samples from different parts of networks. To address this incompatibility of triplet-based metric learning, in this article, we propose a novel quintuple-based method for learning node representations in bipartite heterogeneous networks. Specifically, we generate quintuples that contain positive and negative samples from two different parts of networks. And we formulate two learning objectives that accommodate quintuple-based learning samples, a proximity-based loss that models the relations in quintuples by sigmoid probabilities and an angular loss that more robustly maintains similarity structures. In addition, we also parameterize feature learning by using one-dimensional convolution operators around nodes’ neighborhoods. Compared with eight methods, extensive experiments on two downstream tasks manifest the effectiveness of our approach.},
  archive      = {J_TIST},
  author       = {Cangqi Zhou and Hui Chen and Jing Zhang and Qianmu Li and Dianming Hu},
  doi          = {10.1145/3653978},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {5},
  number       = {3},
  pages        = {61:1–19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Quintuple-based representation learning for bipartite heterogeneous networks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HydraGAN: A cooperative agent model for multi-objective data
generation. <em>TIST</em>, <em>15</em>(3), 60:1–21. (<a
href="https://doi.org/10.1145/3653982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks have become a de facto approach to generate synthetic data points that resemble their real counterparts. We tackle the situation where the realism of individual samples is not the sole criterion for synthetic data generation. Additional constraints such as privacy preservation, distribution realism, and diversity promotion may also be essential to optimize. To address this challenge, we introduce HydraGAN , a multi-agent network that performs multi-objective synthetic data generation. We theoretically verify that training the HydraGAN system, containing a single generator and an arbitrary number of discriminators, leads to a Nash equilibrium. Experimental results for six datasets indicate that HydraGAN consistently outperforms prior methods in maximizing the Area under the Radar Chart, balancing a combination of cooperative or competitive data generation goals.},
  archive      = {J_TIST},
  author       = {Chance DeSmet and Diane Cook},
  doi          = {10.1145/3653982},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {5},
  number       = {3},
  pages        = {60:1–21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {HydraGAN: A cooperative agent model for multi-objective data generation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Score-based graph learning for urban flow prediction.
<em>TIST</em>, <em>15</em>(3), 59:1–25. (<a
href="https://doi.org/10.1145/3655629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate urban flow prediction (UFP) is crucial for a range of smart city applications such as traffic management, urban planning, and risk assessment. To capture the intrinsic characteristics of urban flow, recent efforts have utilized spatial and temporal graph neural networks to deal with the complex dependence between the traffic in adjacent areas. However, existing graph neural network based approaches suffer from several critical drawbacks, including improper graph representation of urban traffic data, lack of semantic correlation modeling among graph nodes, and coarse-grained exploitation of external factors. To address these issues, we propose DiffUFP , a novel probabilistic graph-based framework for UFP. DiffUFP consists of two key designs: (1) a semantic region dynamic extraction method that effectively captures the underlying traffic network topology, and (2) a conditional denoising score-based adjacency matrix generator that takes spatial, temporal, and external factors into account when constructing the adjacency matrix rather than simply concatenation in existing studies. Extensive experiments conducted on real-world datasets demonstrate the superiority of DiffUFP over the state-of-the-art UFP models and the effect of the two specific modules.},
  archive      = {J_TIST},
  author       = {Pengyu Wang and Xuechen Luo and Wenxin Tai and Kunpeng Zhang and Goce Trajcevsky and Fan Zhou},
  doi          = {10.1145/3655629},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {5},
  number       = {3},
  pages        = {59:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Score-based graph learning for urban flow prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Perceiving actions via temporal video frame pairs.
<em>TIST</em>, <em>15</em>(3), 58:1–20. (<a
href="https://doi.org/10.1145/3652611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video action recognition aims at classifying the action category in given videos. In general, semantic-relevant video frame pairs reflect significant action patterns such as object appearance variation and abstract temporal concepts like speed, rhythm, and so on. However, existing action recognition approaches tend to holistically extract spatiotemporal features. Though effective, there is still a risk of neglecting the crucial action features occurring across frames with a long-term temporal span. Motivated by this, in this article, we propose to perceive actions via frame pairs directly and devise a novel Nest Structure with frame pairs as basic units. Specifically, we decompose a video sequence into all possible frame pairs and hierarchically organize them according to temporal frequency and order, thus transforming the original video sequence into a Nest Structure. Through naturally decomposing actions, the proposed structure can flexibly adapt to diverse action variations such as speed or rhythm changes. Next, we devise a Temporal Pair Analysis module (TPA) to extract discriminative action patterns based on the proposed Nest Structure. The designed TPA module consists of a pair calculation part to calculate the pair features and a pair fusion part to hierarchically fuse the pair features for recognizing actions. The proposed TPA can be flexibly integrated into existing backbones, serving as a side branch to capture various action patterns from multi-level features. Extensive experiments show that the proposed TPA module can achieve consistent improvements over several typical backbones, reaching or updating CNN-based SOTA results on several challenging action recognition benchmarks.},
  archive      = {J_TIST},
  author       = {Rongchang Li and Tianyang Xu and Xiao-Jun Wu and Zhongwei Shen and Josef Kittler},
  doi          = {10.1145/3652611},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {5},
  number       = {3},
  pages        = {58:1–20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Perceiving actions via temporal video frame pairs},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedCMD: A federated cross-modal knowledge distillation for
drivers’ emotion recognition. <em>TIST</em>, <em>15</em>(3), 57:1–27.
(<a href="https://doi.org/10.1145/3650040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition has attracted a lot of interest in recent years in various application areas such as healthcare and autonomous driving. Existing approaches to emotion recognition are based on visual, speech, or psychophysiological signals. However, recent studies are looking at multimodal techniques that combine different modalities for emotion recognition. In this work, we address the problem of recognizing the user’s emotion as a driver from unlabeled videos using multimodal techniques. We propose a collaborative training method based on cross-modal distillation, i.e., “FedCMD” (Federated Cross-Modal Distillation). Federated Learning (FL) is an emerging collaborative decentralized learning technique that allows each participant to train their model locally to build a better generalized global model without sharing their data. The main advantage of FL is that only local data is used for training, thus maintaining privacy and providing a secure and efficient emotion recognition system. The local model in FL is trained for each vehicle device with unlabeled video data by using sensor data as a proxy. Specifically, for each local model, we show how driver emotional annotations can be transferred from the sensor domain to the visual domain by using cross-modal distillation. The key idea is based on the observation that a driver’s emotional state indicated by a sensor correlates with facial expressions shown in videos. The proposed “FedCMD” approach is tested on the multimodal dataset “BioVid Emo DB” and achieves state-of-the-art performance. Experimental results show that our approach is robust to non-identically distributed data, achieving 96.67% and 90.83% accuracy in classifying five different emotions with IID (independently and identically distributed) and non-IID data, respectively. Moreover, our model is much more robust to overfitting, resulting in better generalization than the other existing methods.},
  archive      = {J_TIST},
  author       = {Saira Bano and Nicola Tonellotto and Pietro Cassarà and Alberto Gotta},
  doi          = {10.1145/3650040},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {5},
  number       = {3},
  pages        = {57:1–27},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {FedCMD: A federated cross-modal knowledge distillation for drivers’ emotion recognition},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ensuring fairness and gradient privacy in personalized
heterogeneous federated learning. <em>TIST</em>, <em>15</em>(3),
56:1–30. (<a href="https://doi.org/10.1145/3652613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing tension between conflicting requirements of the availability of large amounts of data for effective machine learning-based analysis, and for ensuring their privacy, the paradigm of federated learning has emerged, a distributed machine learning setting where the clients provide only the machine learning model updates to the server rather than the actual data for decision making. However, the distributed nature of federated learning raises specific challenges related to fairness in a heterogeneous setting. This motivates the focus of our article, on the heterogeneity of client devices having different computational capabilities and their impact on fairness in federated learning. Furthermore, our aim is to achieve fairness in heterogeneity while ensuring privacy. As far as we are aware there are no existing works that address all three aspects of fairness, device heterogeneity, and privacy simultaneously in federated learning. In this article, we propose a novel federated learning algorithm with personalization in the context of heterogeneous devices while maintaining compatibility with the gradient privacy preservation techniques of secure aggregation. We analyze the proposed federated learning algorithm under different environments with different datasets and show that it achieves performance close to or greater than the state-of-the-art in heterogeneous device personalized federated learning. We also provide theoretical proofs for the fairness and convergence properties of our proposed algorithm.},
  archive      = {J_TIST},
  author       = {Cody Lewis and Vijay Varadharajan and Nasimul Noman and Uday Tupakula},
  doi          = {10.1145/3652613},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {5},
  number       = {3},
  pages        = {56:1–30},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Ensuring fairness and gradient privacy in personalized heterogeneous federated learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A meta-learning framework for tuning parameters of
protection mechanisms in trustworthy federated learning. <em>TIST</em>,
<em>15</em>(3), 55:1–36. (<a
href="https://doi.org/10.1145/3652612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trustworthy federated learning typically leverages protection mechanisms to guarantee privacy. However, protection mechanisms inevitably introduce utility loss or efficiency reduction while protecting data privacy. Therefore, protection mechanisms and their parameters should be carefully chosen to strike an optimal tradeoff among privacy leakage , utility loss , and efficiency reduction . To this end, federated learning practitioners need tools to measure the three factors and optimize the tradeoff between them to choose the protection mechanism that is most appropriate to the application at hand. Motivated by this requirement, we propose a framework that (1) formulates trustworthy federated learning as a problem of finding a protection mechanism to optimize the tradeoff among privacy leakage, utility loss, and efficiency reduction and (2) formally defines bounded measurements of the three factors. We then propose a meta-learning algorithm to approximate this optimization problem and find optimal protection parameters for representative protection mechanisms, including randomization, homomorphic encryption, secret sharing, and compression. We further design estimation algorithms to quantify these found optimal protection parameters in a practical horizontal federated learning setting and provide a theoretical analysis of the estimation error.},
  archive      = {J_TIST},
  author       = {Xiaojin Zhang and Yan Kang and Lixin Fan and Kai Chen and Qiang Yang},
  doi          = {10.1145/3652612},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {5},
  number       = {3},
  pages        = {55:1–36},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A meta-learning framework for tuning parameters of protection mechanisms in trustworthy federated learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Empowering predictive modeling by GAN-based causal
information learning. <em>TIST</em>, <em>15</em>(3), 54:1–19. (<a
href="https://doi.org/10.1145/3652610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generally speaking, we can easily specify many causal relationships in the prediction tasks of ubiquitous computing, such as human activity prediction, mobility prediction, and health prediction. However, most of the existing methods in these fields failed to take advantage of this prior causal knowledge. They typically make predictions only based on correlations in the data, which hinders the prediction performance in real-world scenarios, because a distribution shift between training data and testing data generally exists. To fill in this gap, we proposed a Generative Adversarial Network (GAN)-based Causal Information Learning prediction framework, which can effectively leverage causal information to improve the prediction performance of existing ubiquitous computing deep learning models. Specifically, faced with a unique challenge that the treatment variable, referring to the intervention that influences the target in a causal relationship, is generally continuous in ubiquitous computing, the framework employs a representation learning approach with a GAN-based deep learning model. By projecting all variables except the treatment into a latent space, it effectively minimizes confounding bias and leverages the learned latent representation for accurate predictions. In this way, it deals with the continuous treatment challenge, and in the meantime, it can be easily integrated with existing deep learning models to lift their prediction performance in practical scenarios with causal information. Extensive experiments on two large-scale real-world datasets demonstrate its superior performance over multiple state-of-the-art baselines. We also propose an analytical framework together with extensive experiments to empirically show that our framework achieves better performance gain under two conditions: when the distribution differences between the training data and the testing data are more significant and when the treatment effects are larger. Overall, this work suggests that learning causal information is a promising way to improve the prediction performance of ubiquitous computing tasks. We open both our dataset and code 1 and call for more research attention in this area.},
  archive      = {J_TIST},
  author       = {Jinwei Zeng and Guozhen Zhang and Jian Yuan and Yong Li and Depeng Jin},
  doi          = {10.1145/3652610},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {5},
  number       = {3},
  pages        = {54:1–19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Empowering predictive modeling by GAN-based causal information learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised bipartite graph representation learning: A
dirichlet max-margin matrix factorization approach. <em>TIST</em>,
<em>15</em>(3), 53:1–24. (<a
href="https://doi.org/10.1145/3645098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipartite graph representation learning aims to obtain node embeddings by compressing sparse vectorized representations of interactions between two types of nodes, e.g., users and items. Incorporating structural attributes among homogeneous nodes, such as user communities, improves the identification of similar interaction preferences, namely, user/item embeddings, for downstream tasks. However, existing methods often fail to proactively discover and fully utilize these latent structural attributes. Moreover, the manual collection and labeling of structural attributes is always costly. In this article, we propose a novel approach called Dirichlet Max-margin Matrix Factorization (DM3F), which adopts a self-supervised strategy to discover latent structural attributes and model discriminative node representations. Specifically, in self-supervised learning, our approach generates pseudo group labels (i.e., structural attributes) as a supervised signal using the Dirichlet process without relying on manual collection and labeling, and employs them in a max-margin classification. Additionally, we introduce a Variational Markov Chain Monte Carlo algorithm (Variational MCMC) to effectively update the parameters. The experimental results on six real datasets demonstrate that, in the majority of cases, the proposed method outperforms existing approaches based on matrix factorization and neural networks. Furthermore, the modularity analysis confirms the effectiveness of our model in capturing structural attributes to produce high-quality user embeddings.},
  archive      = {J_TIST},
  author       = {Shenghai Zhong and Shu Guo and Jing Liu and Hongren Huang and Lihong Wang and Jianxin Li and Chen Li and Yiming Hei},
  doi          = {10.1145/3645098},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {5},
  number       = {3},
  pages        = {53:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Self-supervised bipartite graph representation learning: A dirichlet max-margin matrix factorization approach},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A game-theoretic framework for privacy-preserving federated
learning. <em>TIST</em>, <em>15</em>(3), 52:1–35. (<a
href="https://doi.org/10.1145/3656049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated learning, benign participants aim to optimize a global model collaboratively. However, the risk of privacy leakage cannot be ignored in the presence of semi-honest adversaries. Existing research has focused either on designing protection mechanisms or on inventing attacking mechanisms. While the battle between defenders and attackers seems never-ending, we are concerned with one critical question: Is it possible to prevent potential attacks in advance? To address this, we propose the first game-theoretic framework that considers both FL defenders and attackers in terms of their respective payoffs, which include computational costs, FL model utilities, and privacy leakage risks. We name this game the federated learning privacy game (FLPG), in which neither defenders nor attackers are aware of all participants’ payoffs. To handle the incomplete information inherent in this situation, we propose associating the FLPG with an oracle that has two primary responsibilities. First, the oracle provides lower and upper bounds of the payoffs for the players. Second, the oracle acts as a correlation device, privately providing suggested actions to each player. With this novel framework, we analyze the optimal strategies of defenders and attackers. Furthermore, we derive and demonstrate conditions under which the attacker, as a rational decision-maker, should always follow the oracle’s suggestion not to attack .},
  archive      = {J_TIST},
  author       = {Xiaojin Zhang and Lixin Fan and Siwei Wang and Wenjie Li and Kai Chen and Qiang Yang},
  doi          = {10.1145/3656049},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {5},
  number       = {3},
  pages        = {52:1–35},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A game-theoretic framework for privacy-preserving federated learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MHGCN+: Multiplex heterogeneous graph convolutional network.
<em>TIST</em>, <em>15</em>(3), 51:1–25. (<a
href="https://doi.org/10.1145/3650046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graph convolutional networks have gained great popularity in tackling various network analytical tasks on heterogeneous graph data, ranging from link prediction to node classification. However, most existing works ignore the relation heterogeneity with multiplex networks between multi-typed nodes and the different importance of relations in meta-paths for node embedding, which can hardly capture the heterogeneous structure signals across different relations. To tackle this challenge, this work proposes a M ultiplex H eterogeneous G raph C onvolutional N etwork (MHGCN+) for multiplex heterogeneous network embedding. Our MHGCN+ can automatically learn the useful heterogeneous meta-path interactions of different lengths with different importance in multiplex heterogeneous networks through multi-layer convolution aggregation. Additionally, we effectively integrate both multi-relation structural signals and attribute semantics into the learned node embeddings with both unsupervised and semi-supervised learning paradigms. Extensive experiments on seven real-world datasets with various network analytical tasks demonstrate the significant superiority of MHGCN+ against state-of-the-art embedding baselines in terms of all evaluation metrics. The source code of our method is available at: https://github.com/FuChF/MHGCN-plus .},
  archive      = {J_TIST},
  author       = {Chaofan Fu and Pengyang Yu and Yanwei Yu and Chao Huang and Zhongying Zhao and Junyu Dong},
  doi          = {10.1145/3650046},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {4},
  number       = {3},
  pages        = {51:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {MHGCN+: Multiplex heterogeneous graph convolutional network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deconfounded cross-modal matching for content-based
micro-video background music recommendation. <em>TIST</em>,
<em>15</em>(3), 50:1–25. (<a
href="https://doi.org/10.1145/3650042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object-oriented micro-video background music recommendation is a complicated task where the matching degree between videos and background music is a major issue. However, music selections in user-generated content (UGC) are prone to selection bias caused by historical preferences of uploaders. Since historical preferences are not fully reliable and may reflect obsolete behaviors, over-reliance on them should be avoided as knowledge and interests dynamically evolve. In this article, we propose a Deconfounded Cross-Modal matching model to mitigate such bias. Specifically, uploaders’ personal preferences of music genres are identified as confounders that spuriously correlate music embeddings and background music selections, causing the learned system to over-recommend music from majority groups. To resolve such confounders, backdoor adjustment is utilized to deconfound the spurious correlation between music embeddings and prediction scores. We further utilize Monte Carlo estimator with batch-level average as the approximations to avoid integrating the entire confounder space calculated by the adjustment. Furthermore, we design a teacher–student network to utilize the matching of music videos, which is professionally generated content (PGC) with specialized matching, to better recommend content-matching background music. The PGC data are modeled by a teacher network to guide the matching of uploader-selected UGC data of student network by Kullback–Leibler–based knowledge transfer. Extensive experiments on the TT-150k-genre dataset demonstrate the effectiveness of the proposed method. The code is publicly available on https://github.com/jing-1/DecCM},
  archive      = {J_TIST},
  author       = {Jing Yi and Zhenzhong Chen},
  doi          = {10.1145/3650042},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {4},
  number       = {3},
  pages        = {50:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Deconfounded cross-modal matching for content-based micro-video background music recommendation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tapestry of time and actions: Modeling human activity
sequences using temporal point process flows. <em>TIST</em>,
<em>15</em>(3), 49:1–27. (<a
href="https://doi.org/10.1145/3650045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human beings always engage in a vast range of activities and tasks that demonstrate their ability to adapt to different scenarios. These activities can range from the simplest daily routines, like walking and sitting, to multi-level complex endeavors such as cooking a four-course meal. Any human activity can be represented as a temporal sequence of actions performed to achieve a certain goal. Unlike the time series datasets extracted from electronics or machines, these action sequences are highly disparate in their nature—the time to finish a sequence of actions can vary between different persons. Therefore, understanding the dynamics of these sequences is essential for many downstream tasks such as activity length prediction, goal prediction, and next action recommendation. Existing neural network based approaches that learn a continuous-time activity sequence are limited to the presence of only visual data or are designed specifically for a particular task (i.e., limited to next action or goal prediction). In this article, we present ProActive , a neural marked temporal point process framework for modeling the continuous-time distribution of actions in an activity sequence while simultaneously addressing three high-impact problems: next action prediction, sequence goal prediction, and end-to-end sequence generation. Specifically, we utilize a self-attention module with temporal normalizing flows to model the influence and the inter-arrival times between actions in a sequence. Moreover, for time-sensitive prediction, we perform an early detection of sequence goal via a constrained margin-based optimization procedure. This in turn allows ProActive to predict the sequence goal using a limited number of actions. In addition, we propose a novel addition over the ProActive model, called ProActive++ , that can handle variations in the order of actions (i.e., different methods of achieving a given goal). We demonstrate that this variant can learn the order in which the person or actor prefers to do their actions. Extensive experiments on sequences derived from three activity recognition datasets show the significant accuracy boost of our ProActive and ProActive++ over the state of the art in terms of action and goal prediction, and the first-ever application of end-to-end action sequence generation.},
  archive      = {J_TIST},
  author       = {Vinayak Gupta and Srikanta Bedathur},
  doi          = {10.1145/3650045},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {4},
  number       = {3},
  pages        = {49:1–27},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Tapestry of time and actions: Modeling human activity sequences using temporal point process flows},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning cross-modality interaction for robust depth
perception of autonomous driving. <em>TIST</em>, <em>15</em>(3),
48:1–26. (<a href="https://doi.org/10.1145/3650039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the fundamental tasks of autonomous driving, depth perception aims to perceive physical objects in three dimensions and to judge their distances away from the ego vehicle. Although great efforts have been made for depth perception, LiDAR-based and camera-based solutions have limitations with low accuracy and poor robustness for noise input. With the integration of monocular cameras and LiDAR sensors in autonomous vehicles, in this article, we introduce a two-stream architecture to learn the modality interaction representation under the guidance of an image reconstruction task to compensate for the deficiencies of each modality in a parallel manner. Specifically, in the two-stream architecture, the multi-scale cross-modality interactions are preserved via a cascading interaction network under the guidance of the reconstruction task. Next, the shared representation of modality interaction is integrated to infer the dense depth map due to the complementarity and heterogeneity of the two modalities. We evaluated the proposed solution on the KITTI dataset and CALAR synthetic dataset. Our experimental results show that learning the coupled interaction of modalities under the guidance of an auxiliary task can lead to significant performance improvements. Furthermore, our approach is competitive against the state-of-the-art models and robust against the noisy input. The source code is available at https://github.com/tonyFengye/Code/tree/master .},
  archive      = {J_TIST},
  author       = {Yunji Liang and Nengzhen Chen and Zhiwen Yu and Lei Tang and Hongkai Yu and Bin Guo and Daniel Dajun Zeng},
  doi          = {10.1145/3650039},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {4},
  number       = {3},
  pages        = {48:1–26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Learning cross-modality interaction for robust depth perception of autonomous driving},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing attribution-based neural network explainability
through relative absolute magnitude layer-wise relevance propagation and
multi-component evaluation. <em>TIST</em>, <em>15</em>(3), 47:1–30. (<a
href="https://doi.org/10.1145/3649458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancement in deep-neural network performance led to the development of new state-of-the-art approaches in numerous areas. However, the black-box nature of neural networks often prohibits their use in areas where model explainability and model transparency are crucial. Over the years, researchers proposed many algorithms to aid neural network understanding and provide additional information to the human expert. One of the most popular methods being Layer-Wise Relevance Propagation (LRP). This method assigns local relevance based on the pixel-wise decomposition of nonlinear classifiers. With the rise of attribution method research, there has emerged a pressing need to assess and evaluate their performance. Numerous metrics have been proposed, each assessing an individual property of attribution methods such as faithfulness, robustness, or localization. Unfortunately, no single metric is deemed optimal for every case, and researchers often use several metrics to test the quality of the attribution maps. In this work, we address the shortcomings of the current LRP formulations and introduce a novel method for determining the relevance of input neurons through layer-wise relevance propagation. Furthermore, we apply this approach to the recently developed Vision Transformer architecture and evaluate its performance against existing methods on two image classification datasets, namely ImageNet and PascalVOC. Our results clearly demonstrate the advantage of our proposed method. Furthermore, we discuss the insufficiencies of current evaluation metrics for attribution-based explainability and propose a new evaluation metric that combines the notions of faithfulness, robustness, and contrastiveness. We utilize this new metric to evaluate the performance of various attribution-based methods. Our code is available at: https://github.com/davor10105/relative-absolute-magnitude-propagation},
  archive      = {J_TIST},
  author       = {Davor Vukadin and Petar Afrić and Marin Šilić and Goran Delač},
  doi          = {10.1145/3649458},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {4},
  number       = {3},
  pages        = {47:1–30},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Advancing attribution-based neural network explainability through relative absolute magnitude layer-wise relevance propagation and multi-component evaluation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CACTUS: A comprehensive abstraction and classification tool
for uncovering structures. <em>TIST</em>, <em>15</em>(3), 46:1–23. (<a
href="https://doi.org/10.1145/3649459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of large datasets is providing the impetus for driving many current artificial intelligent developments. However, specific challenges arise in developing solutions that exploit small datasets, mainly due to practical and cost-effective deployment issues, as well as the opacity of deep learning models. To address this, the Comprehensive Abstraction and Classification Tool for Uncovering Structures (CACTUS) is presented as a means of improving secure analytics by effectively employing explainable artificial intelligence. CACTUS achieves this by providing additional support for categorical attributes, preserving their original meaning, optimising memory usage, and speeding up the computation through parallelisation. It exposes to the user the frequency of the attributes in each class and ranks them by their discriminative power. Performance is assessed by applying it to various domains, including Wisconsin Diagnostic Breast Cancer, Thyroid0387, Mushroom, Cleveland Heart Disease, and Adult Income datasets.},
  archive      = {J_TIST},
  author       = {Luca Gherardini and Varun Ravi Varma and Karol Capała and Roger Woods and Jose Sousa},
  doi          = {10.1145/3649459},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {4},
  number       = {3},
  pages        = {46:1–23},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {CACTUS: A comprehensive abstraction and classification tool for uncovering structures},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal dialogue systems via capturing context-aware
dependencies and ordinal information of semantic elements.
<em>TIST</em>, <em>15</em>(3), 45:1–25. (<a
href="https://doi.org/10.1145/3645099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The topic of multimodal conversation systems has recently garnered significant attention across various industries, including travel and retail, among others. While pioneering works in this field have shown promising performance, they often focus solely on context information at the utterance level, overlooking the context-aware dependencies of multimodal semantic elements like words and images. Furthermore, the ordinal information of images, which indicates the relevance between visual context and users’ demands, remains underutilized during the integration of visual content. Additionally, the exploration of how to effectively utilize corresponding attributes provided by users when searching for desired products is still largely unexplored. To address these challenges, we propose PMATE, a P osition-aware M ultimodal di A logue system with seman T ic E lements. Specifically, to obtain semantic representations at the element level, we first unfold the multimodal historical utterances and devise a position-aware multimodal element-level encoder. This component considers all images that may be relevant to the current turn and introduces a novel position-aware image selector to choose related images before fusing the information from the two modalities. Finally, we present a knowledge-aware two-stage decoder and an attribute-enhanced image searcher for the tasks of generating textual responses and selecting image responses, respectively. We extensively evaluate our model on two large-scale multimodal dialogue datasets, and the results of our experiments demonstrate that our approach outperforms several baseline methods.},
  archive      = {J_TIST},
  author       = {Weidong He and Zhi Li and Hao Wang and Tong Xu and Zhefeng Wang and Baoxing Huai and Nicholas Jing Yuan and Enhong Chen},
  doi          = {10.1145/3645099},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {4},
  number       = {3},
  pages        = {45:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Multimodal dialogue systems via capturing context-aware dependencies and ordinal information of semantic elements},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guidelines for the regularization of gammas in batch
normalization for deep residual networks. <em>TIST</em>, <em>15</em>(3),
44:1–20. (<a href="https://doi.org/10.1145/3643860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {L 2 regularization for weights in neural networks is widely used as a standard training trick. In addition to weights, the use of batch normalization involves an additional trainable parameter γ, which acts as a scaling factor. However, L 2 regularization for γ remains an undiscussed mystery and is applied in different ways depending on the library and practitioner. In this article, we study whether L 2 regularization for γ is valid. To explore this issue, we consider two approaches: (1) variance control to make the residual network behave like an identity mapping and (2) stable optimization through the improvement of effective learning rate. Through two analyses, we specify the desirable and undesirable γ to apply L 2 regularization and propose four guidelines for managing them. In several experiments, we observed that applying L 2 regularization to applicable γ increased 1% to 4% classification accuracy, whereas applying L 2 regularization to inapplicable γ decreased 1% to 3% classification accuracy, which is consistent with our four guidelines. Our proposed guidelines were further validated through various tasks and architectures, including variants of residual networks and transformers.},
  archive      = {J_TIST},
  author       = {Bum Jun Kim and Hyeyeon Choi and Hyeonah Jang and Sang Woo Kim},
  doi          = {10.1145/3643860},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {3},
  pages        = {44:1–20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Guidelines for the regularization of gammas in batch normalization for deep residual networks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Internal rehearsals for a reconfigurable robot to improve
area coverage performance. <em>TIST</em>, <em>15</em>(3), 43:1–17. (<a
href="https://doi.org/10.1145/3643854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconfigurable robots are deployed for applications demanding area coverage, such as cleaning and inspections. Reconfiguration per context, considering beyond a small set of predefined shapes, is crucial for area coverage performance. However, the existing area coverage methods of reconfigurable robots are not always effective and require improvements for ascertaining the intended goal. Therefore, this article proposes a novel coverage strategy based on internal rehearsals to improve the area coverage performance of a reconfigurable robot. In this regard, a reconfigurable robot is embodied with the cognitive ability to predict the outcomes of its actions before executing them. A genetic algorithm uses the results of the internal rehearsals to determine a set of the robot’s coverage parameters, including positioning, heading, and reconfiguration, to maximize coverage in an obstacle cluster encountered by the robot. The experimental results confirm that the proposed method can significantly improve the area coverage performance of a reconfigurable robot.},
  archive      = {J_TIST},
  author       = {S. M. Bhagya P. Samarakoon and M. A. Viraj J. Muthugala and Mohan Rajesh Elara},
  doi          = {10.1145/3643854},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {3},
  pages        = {43:1–17},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Internal rehearsals for a reconfigurable robot to improve area coverage performance},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian strategy networks based soft actor-critic learning.
<em>TIST</em>, <em>15</em>(3), 42:1–24. (<a
href="https://doi.org/10.1145/3643862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A strategy refers to the rules that the agent chooses the available actions to achieve goals. Adopting reasonable strategies is challenging but crucial for an intelligent agent with limited resources working in hazardous, unstructured, and dynamic environments to improve the system’s utility, decrease the overall cost, and increase mission success probability. This article proposes a novel hierarchical strategy decomposition approach based on Bayesian chaining to separate an intricate policy into several simple sub-policies and organize their relationships as Bayesian strategy networks (BSN). We integrate this approach into the state-of-the-art DRL method—soft actor-critic (SAC), and build the corresponding Bayesian soft actor-critic (BSAC) model by organizing several sub-policies as a joint policy. Our method achieves the state-of-the-art performance on the standard continuous control benchmarks in the OpenAI Gym environment. The results demonstrate that the promising potential of the BSAC method significantly improves training efficiency. Furthermore, we extend the topic to the Multi-Agent systems (MAS), discussing the potential research fields and directions.},
  archive      = {J_TIST},
  author       = {Qin Yang and Ramviyas Parasuraman},
  doi          = {10.1145/3643862},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {3},
  pages        = {42:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Bayesian strategy networks based soft actor-critic learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MGRR-net: Multi-level graph relational reasoning network for
facial action unit detection. <em>TIST</em>, <em>15</em>(3), 41:1–20.
(<a href="https://doi.org/10.1145/3643863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Facial Action Coding System (FACS) encodes the action units (AUs) in facial images, which has attracted extensive research attention due to its wide use in facial expression analysis. Many methods that perform well on automatic facial action unit (AU) detection primarily focus on modeling various AU relations between corresponding local muscle areas or mining global attention–aware facial features; however, they neglect the dynamic interactions among local-global features. We argue that encoding AU features just from one perspective may not capture the rich contextual information between regional and global face features, as well as the detailed variability across AUs, because of the diversity in expression and individual characteristics. In this article, we propose a novel Multi-level Graph Relational Reasoning Network (termed MGRR-Net ) for facial AU detection. Each layer of MGRR-Net performs a multi-level (i.e., region-level, pixel-wise, and channel-wise level) feature learning. On the one hand, the region-level feature learning from the local face patch features via graph neural network can encode the correlation across different AUs. On the other hand, pixel-wise and channel-wise feature learning via graph attention networks (GAT) enhance the discrimination ability of AU features by adaptively recalibrating feature responses of pixels and channels from global face features. The hierarchical fusion strategy combines features from the three levels with gated fusion cells to improve AU discriminative ability. Extensive experiments on DISFA and BP4D AU datasets show that the proposed approach achieves superior performance than the state-of-the-art methods.},
  archive      = {J_TIST},
  author       = {Xuri Ge and Joemon M. Jose and Songpei Xu and Xiao Liu and Hu Han},
  doi          = {10.1145/3643863},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {3},
  pages        = {41:1–20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {MGRR-net: Multi-level graph relational reasoning network for facial action unit detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning in single-cell analysis. <em>TIST</em>,
<em>15</em>(3), 40:1–62. (<a
href="https://doi.org/10.1145/3641284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell technologies are revolutionizing the entire field of biology. The large volumes of data generated by single-cell technologies are high dimensional, sparse, and heterogeneous and have complicated dependency structures, making analyses using conventional machine learning approaches challenging and impractical. In tackling these challenges, deep learning often demonstrates superior performance compared to traditional machine learning methods. In this work, we give a comprehensive survey on deep learning in single-cell analysis. We first introduce background on single-cell technologies and their development, as well as fundamental concepts of deep learning including the most popular deep architectures. We present an overview of the single-cell analytic pipeline pursued in research applications while noting divergences due to data sources or specific applications. We then review seven popular tasks spanning different stages of the single-cell analysis pipeline, including multimodal integration, imputation, clustering, spatial domain identification, cell-type deconvolution, cell segmentation, and cell-type annotation. Under each task, we describe the most recent developments in classical and deep learning methods and discuss their advantages and disadvantages. Deep learning tools and benchmark datasets are also summarized for each task. Finally, we discuss the future directions and the most recent challenges. This survey will serve as a reference for biologists and computer scientists, encouraging collaborations.},
  archive      = {J_TIST},
  author       = {Dylan Molho and Jiayuan Ding and Wenzhuo Tang and Zhaoheng Li and Hongzhi Wen and Yixin Wang and Julian Venegas and Wei Jin and Renming Liu and Runze Su and Patrick Danaher and Robert Yang and Yu Leo Lei and Yuying Xie and Jiliang Tang},
  doi          = {10.1145/3641284},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {3},
  pages        = {40:1–62},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Deep learning in single-cell analysis},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on evaluation of large language models.
<em>TIST</em>, <em>15</em>(3), 39:1–45. (<a
href="https://doi.org/10.1145/3641289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate , where to evaluate , and how to evaluate . Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey},
  archive      = {J_TIST},
  author       = {Yupeng Chang and Xu Wang and Jindong Wang and Yuan Wu and Linyi Yang and Kaijie Zhu and Hao Chen and Xiaoyuan Yi and Cunxiang Wang and Yidong Wang and Wei Ye and Yue Zhang and Yi Chang and Philip S. Yu and Qiang Yang and Xing Xie},
  doi          = {10.1145/3641289},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {3},
  pages        = {39:1–45},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A survey on evaluation of large language models},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal implicit multimodal networks for investment and
risk management. <em>TIST</em>, <em>15</em>(2), 38:1–25. (<a
href="https://doi.org/10.1145/3643855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many deep learning works on financial time-series forecasting focus on predicting future prices/returns of individual assets with numerical price-related information for trading, and hence propose models designed for univariate, single-task, and/or unimodal settings. Forecasting for investment and risk management involves multiple tasks in multivariate settings: forecasts of expected returns and risks of assets in portfolios, and correlations between these assets. As different sources/types of time-series influence future returns, risks, and correlations of assets in different ways, it is also important to capture time-series from different modalities. Hence, this article addresses financial time-series forecasting for investment and risk management in a multivariate, multitask, and multimodal setting. Financial time-series forecasting, however, is challenging due to the low signal-to-noise ratios typical in financial time-series, and as intra-series and inter-series relationships of assets evolve across time. To address these challenges, our proposed Temporal Implicit Multimodal Network (TIME) model learns implicit inter-series relationship networks between assets from multimodal financial time-series at multiple time-steps adaptively. TIME then uses dynamic network and temporal encoding modules to jointly capture such evolving relationships, multimodal financial time-series, and temporal representations. Our experiments show that TIME outperforms other state-of-the-art models on multiple forecasting tasks and investment and risk management applications.},
  archive      = {J_TIST},
  author       = {Gary Ang and Ee-Peng Lim},
  doi          = {10.1145/3643855},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {2},
  pages        = {38:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Temporal implicit multimodal networks for investment and risk management},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SiG: A siamese-based graph convolutional network to align
knowledge in autonomous transportation systems. <em>TIST</em>,
<em>15</em>(2), 37:1–20. (<a
href="https://doi.org/10.1145/3643861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain knowledge is gradually renovating its attributes to exhibit distinct features in autonomy, propelled by the shift of modern transportation systems (TS) toward autonomous TS (ATS) comprising three progressive generations. The knowledge graph (KG) and its corresponding versions can help depict the evolving TS. Given that KG versions exhibit asymmetry primarily due to variations in evolved knowledge, it is imperative to harmonize the evolved knowledge embodied by the entity across disparate KG versions. Hence, this article proposes a siamese-based graph convolutional network (GCN) model, namely SiG , to address unresolved issues of low accuracy, efficiency, and effectiveness in aligning asymmetric KGs. SiG can optimize entity alignment in ATS and support the analysis of future-stage ATS development. Such a goal is attained through (a) generating unified KGs to enhance data quality, (b) defining graph split to facilitate entire-graph computation, (c) enhancing a GCN to extract intrinsic features, and (d) designing a siamese network to train asymmetric KGs. The evaluation results suggest that SiG surpasses other commonly employed models, resulting in average improvements of 23.90% and 37.89% in accuracy and efficiency, respectively. These findings have significant implications for TS evolution analysis and offer a novel perspective for research on complex systems limited by continuously updated knowledge.},
  archive      = {J_TIST},
  author       = {Mai Hao and Ming Cai and Minghui Fang and Linlin You},
  doi          = {10.1145/3643861},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {2},
  pages        = {37:1–20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {SiG: A siamese-based graph convolutional network to align knowledge in autonomous transportation systems},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal treatment strategies for critical patients with deep
reinforcement learning. <em>TIST</em>, <em>15</em>(2), 36:1–22. (<a
href="https://doi.org/10.1145/3643856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized clinical decision support systems are increasingly being adopted due to the emergence of data-driven technologies, with this approach now gaining recognition in critical care. The task of incorporating diverse patient conditions and treatment procedures into critical care decision-making can be challenging due to the heterogeneous nature of medical data. Advances in Artificial Intelligence (AI), particularly Reinforcement Learning (RL) techniques, enables the development of personalized treatment strategies for severe illnesses by using a learning agent to recommend optimal policies. In this study, we propose a Deep Reinforcement Learning (DRL) model with a tailored reward function and an LSTM-GRU-derived state representation to formulate optimal treatment policies for vasopressor administration in stabilizing patient physiological states in critical care settings. Using an ICU dataset and the Medical Information Mart for Intensive Care (MIMIC-III) dataset, we focus on patients with Acute Respiratory Distress Syndrome (ARDS) that has led to Sepsis, to derive optimal policies that can prioritize patient recovery over patient survival. Both the DDQN ( RepDRL-DDQN ) and Dueling DDQN ( RepDRL-DDDQN ) versions of the DRL model surpass the baseline performance, with the proposed model’s learning agent achieving an optimal learning process across our performance measuring schemes. The robust state representation served as the foundation for enhancing the model’s performance, ultimately providing an optimal treatment policy focused on rapid patient recovery.},
  archive      = {J_TIST},
  author       = {Simi Job and Xiaohui Tao and Lin Li and Haoran Xie and Taotao Cai and Jianming Yong and Qing Li},
  doi          = {10.1145/3643856},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {2},
  pages        = {36:1–22},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Optimal treatment strategies for critical patients with deep reinforcement learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Credit card fraud detection via intelligent sampling and
self-supervised learning. <em>TIST</em>, <em>15</em>(2), 35:1–29. (<a
href="https://doi.org/10.1145/3641283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant increase in credit card transactions can be attributed to the rapid growth of online shopping and digital payments, particularly during the COVID-19 pandemic. To safeguard cardholders, e-commerce companies, and financial institutions, the implementation of an effective and real-time fraud detection method using modern artificial intelligence techniques is imperative. However, the development of machine-learning-based approaches for fraud detection faces challenges such as inadequate transaction representation, noise labels, and data imbalance. Additionally, practical considerations like dynamic thresholds, concept drift, and verification latency need to be appropriately addressed. In this study, we designed a fraud detection method that accurately extracts a series of spatial and temporal representative features to precisely describe credit card transactions. Furthermore, several auxiliary self-supervised objectives were developed to model cardholders’ behavior sequences. By employing intelligent sampling strategies, potential noise labels were eliminated, thereby reducing the level of data imbalance. The developed method encompasses various innovative functions that cater to practical usage requirements. We applied this method to two real-world datasets, and the results indicated a higher F1 score compared to the most commonly used online fraud detection methods.},
  archive      = {J_TIST},
  author       = {Chiao-Ting Chen and Chi Lee and Szu-Hao Huang and Wen-Chih Peng},
  doi          = {10.1145/3641283},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {2},
  pages        = {35:1–29},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Credit card fraud detection via intelligent sampling and self-supervised learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VesNet: A vessel network for jointly learning route pattern
and future trajectory. <em>TIST</em>, <em>15</em>(2), 34:1–25. (<a
href="https://doi.org/10.1145/3639370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vessel trajectory prediction is the key to maritime applications such as traffic surveillance, collision avoidance, anomaly detection, and so on. Making predictions more precisely requires a better understanding of the moving trend for a particular vessel since the movement is affected by multiple factors like marine environment, vessel type, and vessel behavior. In this paper, we propose a model named VesNet, based on the attentional seq2seq framework, to predict vessel future movement sequence by observing the current trajectory. Firstly, we extract the route patterns from the raw AIS data during preprocessing. Then, we design a multi-task learning structure to learn how to implement route pattern classification and vessel trajectory prediction simultaneously. By comparing with representative baseline models, we find that our VesNet has the best performance in terms of long-term prediction precision. Additionally, VesNet can recognize the route pattern by capturing the implicit moving characteristics. The experimental results prove that the proposed multi-task learning assists the vessel trajectory prediction mission.},
  archive      = {J_TIST},
  author       = {Fenyu Jiang and Huandong Wang and Yong Li},
  doi          = {10.1145/3639370},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {2},
  pages        = {34:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {VesNet: A vessel network for jointly learning route pattern and future trajectory},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolving knowledge graph representation learning with
multiple attention strategies for citation recommendation system.
<em>TIST</em>, <em>15</em>(2), 33:1–26. (<a
href="https://doi.org/10.1145/3635273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing number of publications in the field of artificial intelligence highlights the need for researchers to enhance their efficiency in searching for relevant articles. Most paper recommendation models either rely on simplistic citation relationships among papers or focus on content-based approaches, both of which overlook interactions within academic networks. To address the aforementioned problem, knowledge graph embedding (KGE) methods have been used for citation recommendations because recent research proves that graph representations can effectively improve recommendation model accuracy. However, academic networks are dynamic, leading to changes in the representations of users and items over time. The majority of KGE-based citation recommendations are primarily designed for static graphs, thus failing to capture the evolution of dynamic knowledge graph (DKG) structures. To address these challenges, we introduced the evolving knowledge graph embedding (EKGE) method. In this methodology, evolving knowledge graphs are input into time-series models to learn the patterns of structural evolution. The model has the capability to generate embeddings for each entity at various time points, thereby overcoming limitation of static models that require retraining to acquire embeddings at each specific time point. To enhance the efficiency of feature extraction, we employed a multiple attention strategy. This helped the model find recommendation lists that are closely related to a user’s needs, leading to improved recommendation accuracy. Various experiments conducted on a citation recommendation dataset revealed that the EKGE model exhibits a 1.13% increase in prediction accuracy compared to other KGE methods. Moreover, the model’s accuracy can be further increased by an additional 0.84% through the incorporation of an attention mechanism.},
  archive      = {J_TIST},
  author       = {Jhih-Chen Liu and Chiao-Ting Chen and Chi Lee and Szu-Hao Huang},
  doi          = {10.1145/3635273},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {2},
  pages        = {33:1–26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Evolving knowledge graph representation learning with multiple attention strategies for citation recommendation system},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning for solving multiple vehicle routing
problem with time window. <em>TIST</em>, <em>15</em>(2), 32:1–19. (<a
href="https://doi.org/10.1145/3625232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle routing problem with time window (VRPTW) is of great importance for a wide spectrum of services and real-life applications, such as online take-out and car-hailing platforms. A promising method should generate high-qualified solutions within limited inference time, and there are three major challenges: (a) directly optimizing the goal with several practical constraints; (b) efficiently handling individual time-window limits; and (c) modeling the cooperation among the vehicle fleet. In this article, we present an end-to-end reinforcement learning framework to solve VRPTW. First, we propose an agent model that encodes constraints into features as the input and conducts harsh policy on the output when generating deterministic results. Second, we design a time penalty augmented reward to model the time-window limits during gradient propagation. Third, we design a task handler to enable the cooperation among different vehicles. We perform extensive experiments on two real-world datasets and one public benchmark dataset. Results demonstrate that our solution improves the performance by up to 11.7% compared to other RL baselines and could generate solutions for instances within seconds, while existing heuristic baselines take for minutes as well as maintain the quality of solutions. Moreover, our solution is thoroughly analyzed with meaningful implications due to the real-time response ability.},
  archive      = {J_TIST},
  author       = {Zefang Zong and Xia Tong and Meng Zheng and Yong Li},
  doi          = {10.1145/3625232},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {3},
  number       = {2},
  pages        = {32:1–19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Reinforcement learning for solving multiple vehicle routing problem with time window},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RANGO: A novel deep learning approach to detect drones
disguising from video surveillance systems. <em>TIST</em>,
<em>15</em>(2), 31:1–21. (<a
href="https://doi.org/10.1145/3641282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video surveillance systems provide means to detect the presence of potentially malicious drones in the surroundings of critical infrastructures. In particular, these systems collect images and feed them to a deep-learning classifier able to detect the presence of a drone in the input image. However, current classifiers are not efficient in identifying drones that disguise themselves with the image background, e.g., hiding in front of a tree. Furthermore, video-based detection systems heavily rely on the image’s brightness, where darkness imposes significant challenges in detecting drones. Both these phenomena increase the possibilities for attackers to get close to critical infrastructures without being spotted and hence be able to gather sensitive information or cause physical damages, possibly leading to safety threats. In this article, we propose RANGO, a drone detection arithmetic able to detect drones in challenging images where the target is difficult to distinguish from the background. RANGO is based on a deep learning architecture that exploits a Preconditioning Operation (PREP) that highlights the target by the difference between the target gradient and the background gradient. The idea is to highlight features that will be useful for classification. After PREP, RANGO uses multiple convolution kernels to make the final decision on the presence of the drone. We test RANGO on a drone image dataset composed of multiple already-existing datasets to which we add samples of birds and planes. We then compare RANGO with multiple currently existing approaches to show its superiority. When tested on images with disguising drones, RANGO attains an increase of 6.6% mean Average Precision (mAP) compared to YOLOv5 solution. When tested on the conventional dataset, RANGO improves the mAP by approximately 2.2%, thus confirming its effectiveness also in the general scenario.},
  archive      = {J_TIST},
  author       = {Jin Han and Yun-Feng Ren and Alessandro Brighente and Mauro Conti},
  doi          = {10.1145/3641282},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {2},
  pages        = {31:1–21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {RANGO: A novel deep learning approach to detect drones disguising from video surveillance systems},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strengthening cooperative consensus in multi-robot
confrontation. <em>TIST</em>, <em>15</em>(2), 30:1–27. (<a
href="https://doi.org/10.1145/3639371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning (MARL) has proven effective in training multi-robot confrontation, such as StarCraft and robot soccer games. However, the current joint action policies utilized in MARL have been unsuccessful in recognizing and preventing actions that often lead to failures on our side. This exacerbates the cooperation dilemma, ultimately resulting in our agents acting independently and being defeated individually by their opponents. To tackle this challenge, we propose a novel joint action policy, referred to as the consensus action policy (CAP). Specifically, CAP records the number of times each joint action has caused our side to fail in the past and computes a cooperation tendency, which is integrated with each agent’s Q -value and Nash bargaining solution to determine a joint action. The cooperation tendency promotes team cooperation by selecting joint actions that have a high tendency of cooperation and avoiding actions that may lead to team failure. Moreover, the proposed CAP policy can be extended to partially observable scenarios by combining it with Deep Q network or actor-critic–based methods. We conducted extensive experiments to compare the proposed method with seven existing joint action policies, including four commonly used methods and three state-of-the-art methods, in terms of episode rewards, winning rates, and other metrics. Our results demonstrate that this approach holds great promise for multi-robot confrontation scenarios.},
  archive      = {J_TIST},
  author       = {Meng Xu and Xinhong Chen and Yechao She and Yang Jin and Guanyi Zhao and Jianping Wang},
  doi          = {10.1145/3639371},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {2},
  pages        = {30:1–27},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Strengthening cooperative consensus in multi-robot confrontation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generating daily activities with need dynamics.
<em>TIST</em>, <em>15</em>(2), 29:1–28. (<a
href="https://doi.org/10.1145/3637493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Daily activity data recording individuals’ various activities in daily life are widely used in many applications such as activity scheduling, activity recommendation, and policymaking. Though with high value, its accessibility is limited due to high collection costs and potential privacy issues. Therefore, simulating human activities to produce massive high-quality data is of great importance. However, existing solutions, including rule-based methods with simplified behavior assumptions and data-driven methods directly fitting real-world data, both cannot fully qualify for matching reality. In this article, motivated by the classic psychological theory, Maslow’s need theory describing human motivation, we propose a knowledge-driven simulation framework based on generative adversarial imitation learning. Our core idea is to model the evolution of human needs as the underlying mechanism that drives activity generation in the simulation model. Specifically, a hierarchical model structure that disentangles different need levels and the use of neural stochastic differential equations successfully capture the piecewise-continuous characteristics of need dynamics. Extensive experiments demonstrate that our framework outperforms the state-of-the-art baselines regarding data fidelity and utility. We also present the insightful interpretability of the need modeling. Moreover, privacy preservation evaluations validate that the generated data does not leak individual privacy. The code is available at https://github.com/tsinghua-fib-lab/Activity-Simulation-SAND .},
  archive      = {J_TIST},
  author       = {Yuan Yuan and Jingtao Ding and Huandong Wang and Depeng Jin},
  doi          = {10.1145/3637493},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {2},
  pages        = {29:1–28},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Generating daily activities with need dynamics},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the distributed knowledge congruence in
proxy-data-free federated distillation. <em>TIST</em>, <em>15</em>(2),
28:1–34. (<a href="https://doi.org/10.1145/3639369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a privacy-preserving machine learning paradigm in which the server periodically aggregates local model parameters from cli ents without assembling their private data. Constrained communication and personalization requirements pose severe challenges to FL. Federated distillation (FD) is proposed to simultaneously address the above two problems, which exchanges knowledge between the server and clients, supporting heterogeneous local models while significantly reducing communication overhead. However, most existing FD methods require a proxy dataset, which is often unavailable in reality. A few recent proxy-data-free FD approaches can eliminate the need for additional public data, but suffer from remarkable discrepancy among local knowledge due to client-side model heterogeneity, leading to ambiguous representation on the server and inevitable accuracy degradation. To tackle this issue, we propose a proxy-data-free FD algorithm based on distributed knowledge congruence (FedDKC). FedDKC leverages well-designed refinement strategies to narrow local knowledge differences into an acceptable upper bound, so as to mitigate the negative effects of knowledge incongruence. Specifically, from perspectives of peak probability and Shannon entropy of local knowledge, we design kernel-based knowledge refinement (KKR) and searching-based knowledge refinement (SKR) respectively, and theoretically guarantee that the refined-local knowledge can satisfy an approximately-similar distribution and be regarded as congruent. Extensive experiments conducted on three common datasets demonstrate that our proposed FedDKC significantly outperforms the state-of-the-art on various heterogeneous settings while evidently improving the convergence speed.},
  archive      = {J_TIST},
  author       = {Zhiyuan Wu and Sheng Sun and Yuwei Wang and Min Liu and Quyang Pan and Junbo Zhang and Zeju Li and Qingxiang Liu},
  doi          = {10.1145/3639369},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {2},
  pages        = {28:1–34},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Exploring the distributed knowledge congruence in proxy-data-free federated distillation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fairness-driven private collaborative machine learning.
<em>TIST</em>, <em>15</em>(2), 27:1–30. (<a
href="https://doi.org/10.1145/3639368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of machine learning algorithms can be considerably improved when trained over larger datasets. In many domains, such as medicine and finance, larger datasets can be obtained if several parties, each having access to limited amounts of data, collaborate and share their data. However, such data sharing introduces significant privacy challenges. While multiple recent studies have investigated methods for private collaborative machine learning, the fairness of such collaborative algorithms has been overlooked. In this work, we suggest a feasible privacy-preserving pre-process mechanism for enhancing fairness of collaborative machine learning algorithms. An extensive evaluation of the proposed method shows that it is able to enhance fairness considerably with only a minor compromise in accuracy.},
  archive      = {J_TIST},
  author       = {Dana Pessach and Tamir Tassa and Erez Shmueli},
  doi          = {10.1145/3639368},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {2},
  pages        = {27:1–30},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Fairness-driven private collaborative machine learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EMG-based automatic gesture recognition using
lipschitz-regularized neural networks. <em>TIST</em>, <em>15</em>(2),
26:1–25. (<a href="https://doi.org/10.1145/3635159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a novel approach for building a robust Automatic Gesture Recognition system based on Surface Electromyographic (sEMG) signals, acquired at the forearm level. Our main contribution is to propose new constrained learning strategies that ensure robustness against adversarial perturbations by controlling the Lipschitz constant of the classifier. We focus on nonnegative neural networks for which accurate Lipschitz bounds can be derived, and we propose different spectral norm constraints offering robustness guarantees from a theoretical viewpoint. Experimental results on four publicly available datasets highlight that a good tradeoff in terms of accuracy and performance is achieved. We then demonstrate the robustness of our models, compared with standard trained classifiers in four scenarios, considering both white-box and black-box attacks.},
  archive      = {J_TIST},
  author       = {Ana Neacşu and Jean-Christophe Pesquet and Corneliu Burileanu},
  doi          = {10.1145/3635159},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {2},
  pages        = {26:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {EMG-based automatic gesture recognition using lipschitz-regularized neural networks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable product classification for customs.
<em>TIST</em>, <em>15</em>(2), 25:1–24. (<a
href="https://doi.org/10.1145/3635158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of assigning internationally accepted commodity codes (aka HS codes) to traded goods is a critical function of customs offices. Like court decisions made by judges, this task follows the doctrine of precedent and can be nontrivial even for experienced officers. Together with the Korea Customs Service (KCS), we propose a first-ever explainable decision supporting model that suggests the most likely subheadings (i.e., the first six digits) of the HS code. The model also provides reasoning for its suggestion in the form of a document that is interpretable by customs officers. We evaluated the model using 5,000 cases that recently received a classification request. The results showed that the top-3 suggestions made by our model had an accuracy of 93.9% when classifying 925 challenging subheadings. A user study with 32 customs experts further confirmed that our algorithmic suggestions accompanied by explainable reasonings, can substantially reduce the time and effort taken by customs officers for classification reviews.},
  archive      = {J_TIST},
  author       = {Eunji Lee and Sihyeon Kim and Sundong Kim and Soyeon Jung and Heeja Kim and Meeyoung Cha},
  doi          = {10.1145/3635158},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {2},
  pages        = {25:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Explainable product classification for customs},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TS-fastformer: Fast transformer for time-series forecasting.
<em>TIST</em>, <em>15</em>(2), 24:1–20. (<a
href="https://doi.org/10.1145/3630637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world applications require precise and fast time-series forecasting. Recent trends in time-series forecasting models are shifting from LSTM-based models to Transformer-based models. However, the Transformer-based model has a limited ability to represent sequential relationships in time-series data. In addition, the transformer-based model suffers from slow training and inference speed due to the bottleneck incurred by a deep encoder and step-by-step decoder inference. To address these problems, we propose a time-series forecasting optimized Transformer model, called TS-Fastformer. TS-Fastformer introduces three new optimizations: First, we propose a Sub Window Tokenizer for compressing input in a simple manner. The Sub Window Tokenizer reduces the length of input sequences to mitigate the complexity of self-attention and enables both single and multi-sequence learning. Second, we propose Time-series Pre-trained Encoder to extract effective representations through pre-training. This optimization enables TS-Fastformer to capture both seasonal and trend representations as well as to mitigate bottlenecks of conventional transformer models. Third, we propose the Past Attention Decoder to forecast target by incorporating past long short-term dependency patterns. Furthermore, Past Attention Decoder achieves high performance improvement by removing a trend distribution that changes over a long period. We evaluate the efficiency of our model with extensive experiments using seven real-world datasets and compare our model to six representative time-series forecasting approaches. The results show that the proposed TS-Fastformer reduces MSE by 10.1% compared to state-of-the-art model and demonstrates 21.6% faster training time compared to the existing fastest transformer, respectively.},
  archive      = {J_TIST},
  author       = {Sangwon Lee and Junho Hong and Ling Liu and Wonik Choi},
  doi          = {10.1145/3630637},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {2},
  pages        = {24:1–20},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {TS-fastformer: Fast transformer for time-series forecasting},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). T-distributed stochastic neighbor embedding for
co-representation learning. <em>TIST</em>, <em>15</em>(2), 23:1–18. (<a
href="https://doi.org/10.1145/3627823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-clustering is the simultaneous clustering of the samples and attributes of a data matrix that provides deeper insight into data than traditional clustering. However, there is a lack of representation learning algorithms that serve this mechanism of co-clustering, and the current representation learning algorithms are limited to the sample perspective and lack the use of information in the attribute perspective. To solve this problem, in this article, ctSNE , a co-representation learning model based on t-distributed stochastic neighbor embedding, is proposed for unsupervised co-clustering, where ctSNE makes the dataset representation outputted more discriminative of row and column clusters (i.e. co-discrimination). On the basis of t-distributed stochastic neighbor embedding retaining the sample data distribution and local data structure, the philosophy of collaboration is introduced (i.e., row and column hidden relationship information) so that the ctSNE model is equipped with co-representation learning capability, which can effectively improve the performance of co-clustering. To prove the effectiveness of the ctSNE model, several classic co-clustering algorithms are used to check the co-representation performance of ctSNE, and a novel internal index based on an internal clustering index, known as total inertia, is proposed to demonstrate the effect of co-clustering. The numerous experimental results show that ctSNE has tremendous co-representation capability and can significantly improve the performance of co-clustering algorithms.},
  archive      = {J_TIST},
  author       = {Wei Chen and Hongjun Wang and Yinghui Zhang and Ping Deng and Zhipeng Luo and Tianrui Li},
  doi          = {10.1145/3627823},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {2},
  pages        = {23:1–18},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {T-distributed stochastic neighbor embedding for co-representation learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Labeling chaos to learning harmony: Federated learning with
noisy labels. <em>TIST</em>, <em>15</em>(2), 22:1–26. (<a
href="https://doi.org/10.1145/3626242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a distributed machine learning paradigm that enables learning models from decentralized private datasets where the labeling effort is entrusted to the clients. While most existing FL approaches assume high-quality labels are readily available on users’ devices, in reality, label noise can naturally occur in FL and is closely related to clients’ characteristics. Due to scarcity of available data and significant label noise variations among clients in FL, existing state-of-the-art centralized approaches exhibit unsatisfactory performance, whereas prior FL studies rely on excessive on-device computational schemes or additional clean data available on the server. We propose FedLN , a framework to deal with label noise across different FL training stages, namely FL initialization, on-device model training, and server model aggregation, able to accommodate the diverse computational capabilities of devices in an FL system. Specifically, FedLN computes per-client noise level estimation in a single federated round and improves the models’ performance by either correcting or mitigating the effect of noisy samples. Our evaluation on various publicly available vision and audio datasets demonstrates a 22% improvement on average compared to other existing methods for a label noise level of 60%. We further validate the efficiency of FedLN in human-annotated real-world noisy datasets and report a 4.8% increase on average in models’ recognition performance, highlighting that FedLN can be useful for improving FL services provided to everyday users.},
  archive      = {J_TIST},
  author       = {Vasileios Tsouvalas and Aaqib Saeed and Tanir Ozcelebi and Nirvana Meratnia},
  doi          = {10.1145/3626242},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {2},
  pages        = {22:1–26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Labeling chaos to learning harmony: Federated learning with noisy labels},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Demand-driven urban facility visit prediction.
<em>TIST</em>, <em>15</em>(2), 21:1–24. (<a
href="https://doi.org/10.1145/3625233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting citizens’ visiting behaviors to urban facilities is instrumental for city governors and planners to detect inequalities in urban opportunities and optimize the distribution of facilities and resources. Previous works predict facility visits simply using observed visit behavior, yet citizens’ intrinsic demands for facilities are not characterized explicitly, causing potential incorrect learned relations in the prediction results. In this article, to make up for this deficiency, we present a demand-driven urban facility visit prediction method that decomposes citizens’ visits to facilities into their unobservable demands and their capability to fulfill them. Demands are expressed as the function of regional demographic attributes by a neural network, and the fulfillment capability is determined by the urban region’s spatial accessibility to facilities. Extensive evaluations of datasets of three large cities confirm the efficiency and rationality of our model. Our method outperforms the best state-of-the-art model by 8.28% on average in facility visit prediction tasks. Further analyses demonstrate the reasonableness of recovered facility demands and their relationship with citizen demographics. For instance, senior citizens tend to have higher medical demands but lower shopping demands. Meanwhile, estimated capabilities and accessibilities provide deeper insights into the decaying accessibility with respect to spatial distance and facilities’ diverse functions in the urban environment. Our findings shed light on demand-driven urban data mining and demand-based urban facility planning.},
  archive      = {J_TIST},
  author       = {Yunke Zhang and Tong Li and Yuan Yuan and Fengli Xu and Fan Yang and Funing Sun and Yong Li},
  doi          = {10.1145/3625233},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {2},
  pages        = {21:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Demand-driven urban facility visit prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainability for large language models: A survey.
<em>TIST</em>, <em>15</em>(2), 20:1–38. (<a
href="https://doi.org/10.1145/3639372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this article, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional deep learning models.},
  archive      = {J_TIST},
  author       = {Haiyan Zhao and Hanjie Chen and Fan Yang and Ninghao Liu and Huiqi Deng and Hengyi Cai and Shuaiqiang Wang and Dawei Yin and Mengnan Du},
  doi          = {10.1145/3639372},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {2},
  pages        = {20:1–38},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Explainability for large language models: A survey},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on graph representation learning methods.
<em>TIST</em>, <em>15</em>(1), 19:1–55. (<a
href="https://doi.org/10.1145/3633518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning has been a very active research area in recent years. The goal of graph representation learning is to generate graph representation vectors that capture the structure and features of large graphs accurately. This is especially important because the quality of the graph representation vectors will affect the performance of these vectors in downstream tasks such as node classification, link prediction and anomaly detection. Many techniques have been proposed for generating effective graph representation vectors, which generally fall into two categories: traditional graph embedding methods and graph neural network (GNN)–based methods. These methods can be applied to both static and dynamic graphs. A static graph is a single fixed graph, whereas a dynamic graph evolves over time and its nodes and edges can be added or deleted from the graph. In this survey, we review the graph-embedding methods in both traditional and GNN-based categories for both static and dynamic graphs and include the recent papers published until the time of submission. In addition, we summarize a number of limitations of GNNs and the proposed solutions to these limitations. Such a summary has not been provided in previous surveys. Finally, we explore some open and ongoing research directions for future work.},
  archive      = {J_TIST},
  author       = {Shima Khoshraftar and Aijun An},
  doi          = {10.1145/3633518},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {19:1–55},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {A survey on graph representation learning methods},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nationwide air pollution forecasting with heterogeneous
graph neural networks. <em>TIST</em>, <em>15</em>(1), 18:1–19. (<a
href="https://doi.org/10.1145/3637492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, air pollution is one of the most relevant environmental problems in most urban settings. Due to the utility in operational terms of anticipating certain pollution levels, several predictors based on Graph Neural Networks (GNN) have been proposed for the last years. Most of these solutions usually encode the relationships among stations in terms of their spatial distance, but they fail when it comes to capturing other spatial and feature-based contextual factors. Besides, they assume a homogeneous setting where all the stations are able to capture the same pollutants. However, large-scale settings frequently comprise different types of stations, each one with different measurement capabilities. For that reason, the present article introduces a novel GNN framework able to capture the similarities among stations related to the land use of their locations and their primary source of pollution. Furthermore, we define a methodology to deal with heterogeneous settings on the top of the GNN architecture. Finally, the proposal has been tested with a nation-wide Spanish air-pollution dataset with very promising results.},
  archive      = {J_TIST},
  author       = {Fernando Terroso-Saenz and Juan Morales-García and Andres Muñoz},
  doi          = {10.1145/3637492},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {18:1–19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Nationwide air pollution forecasting with heterogeneous graph neural networks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reconstructing turbulent flows using spatio-temporal
physical dynamics. <em>TIST</em>, <em>15</em>(1), 17:1–18. (<a
href="https://doi.org/10.1145/3637491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate simulation of turbulent flows is of crucial importance in many branches of science and engineering. Direct numerical simulation (DNS) provides the highest fidelity means of capturing all intricate physics of turbulent transport. However, the method is computationally expensive because of the wide range of turbulence scales that must be accounted for in such simulations. Large eddy simulation (LES) provides an alternative. In such simulations, the large scales of the flow are resolved, and the effects of small scales are modelled. Reconstruction of the DNS field from the low-resolution LES is needed for a wide variety of applications. Thus the construction of super-resolution methodologies that can provide this reconstruction has become an area of active research. In this work, a new physics-guided neural network is developed for such a reconstruction. The method leverages the partial differential equation that underlies the flow dynamics in the design of spatio-temporal model architecture. A degradation-based refinement method is also developed to enforce physical constraints and to further reduce the accumulated reconstruction errors over long periods. Detailed DNS data on two turbulent flow configurations are used to assess the performance of the model.},
  archive      = {J_TIST},
  author       = {Shengyu Chen and Tianshu Bao and Peyman Givi and Can Zheng and Xiaowei Jia},
  doi          = {10.1145/3637491},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {17:1–18},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Reconstructing turbulent flows using spatio-temporal physical dynamics},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). E2Storyline: Visualizing the relationship with triplet
entities and event discovery. <em>TIST</em>, <em>15</em>(1), 16:1–26.
(<a href="https://doi.org/10.1145/3633519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The narrative progression of events, evolving into a cohesive story, relies on the entity-entity relationships. Among the plethora of visualization techniques, storyline visualization has gained significant recognition for its effectiveness in offering an overview of story trends, revealing entity relationships, and facilitating visual communication. However, existing methods for storyline visualization often fall short in accurately depicting the specific relationships between entities. In this study, we present E 2 Storyline, a novel approach that emphasizes simplicity and aesthetics of layout while effectively conveying entity-entity relationships to users. To achieve this, we begin by extracting entity-entity relationships from textual data and representing them as subject-predicate-object (SPO) triplets, thereby obtaining structured data. By considering three types of design requirements, we establish new optimization objectives and model the layout problem using multi-objective optimization (MOO) techniques. The aforementioned SPO triplets, together with time and event information, are incorporated into the optimization model to ensure a straightforward and easily comprehensible storyline layout. Through a qualitative user study, we determine that a pixel-based view is the most suitable method for displaying the relationships between entities. Finally, we apply E 2 Storyline to real-world data, including movie synopses and live text commentaries. Through comprehensive case studies, we demonstrate that E 2 Storyline enables users to better extract information from stories and comprehend the relationships between entities.},
  archive      = {J_TIST},
  author       = {Yunchao Wang and Guodao Sun and Zihao Zhu and Tong Li and Ling Chen and Ronghua Liang},
  doi          = {10.1145/3633519},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {16:1–26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {E2Storyline: Visualizing the relationship with triplet entities and event discovery},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical pruning of deep ensembles with focal diversity.
<em>TIST</em>, <em>15</em>(1), 15:1–24. (<a
href="https://doi.org/10.1145/3633286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network ensembles combine the wisdom of multiple deep neural networks to improve the generalizability and robustness over individual networks. It has gained increasing popularity to study and apply deep ensemble techniques in the deep learning community. Some mission-critical applications utilize a large number of deep neural networks to form deep ensembles to achieve desired accuracy and resilience, which introduces high time and space costs for ensemble execution. However, it still remains a critical challenge whether a small subset of the entire deep ensemble can achieve the same or better generalizability and how to effectively identify these small deep ensembles for improving the space and time efficiency of ensemble execution. This article presents a novel deep ensemble pruning approach, which can efficiently identify smaller deep ensembles and provide higher ensemble accuracy than the entire deep ensemble of a large number of member networks. Our hierarchical ensemble pruning approach (HQ) leverages three novel ensemble pruning techniques. First, we show that the focal ensemble diversity metrics can accurately capture the complementary capacity of the member networks of an ensemble team, which can guide ensemble pruning. Second, we design a focal ensemble diversity based hierarchical pruning approach, which will iteratively find high quality deep ensembles with low cost and high accuracy. Third, we develop a focal diversity consensus method to integrate multiple focal diversity metrics to refine ensemble pruning results, where smaller deep ensembles can be effectively identified to offer high accuracy, high robustness and high ensemble execution efficiency. Evaluated using popular benchmark datasets, we demonstrate that the proposed hierarchical ensemble pruning approach can effectively identify high quality deep ensembles with better classification generalizability while being more time and space efficient in ensemble decision making. We have released the source codes on GitHub at https://github.com/git-disl/HQ-Ensemble .},
  archive      = {J_TIST},
  author       = {Yanzhao Wu and Ka-Ho Chow and Wenqi Wei and Ling Liu},
  doi          = {10.1145/3633286},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {15:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Hierarchical pruning of deep ensembles with focal diversity},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring structure incentive domain adversarial learning
for generalizable sleep stage classification. <em>TIST</em>,
<em>15</em>(1), 14:1–30. (<a
href="https://doi.org/10.1145/3625238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep stage classification is crucial for sleep state monitoring and health interventions. In accordance with the standards prescribed by the American Academy of Sleep Medicine, a sleep episode follows a specific structure comprising five distinctive sleep stages that collectively form a sleep cycle. Typically, this cycle repeats about five times, providing an insightful portrayal of the subject’s physiological attributes. The progress of deep learning and advanced domain generalization methods allows automatic and even adaptive sleep stage classification. However, applying models trained with visible subject data to invisible subject data remains challenging due to significant individual differences among subjects. Motivated by the periodic category-complete structure of sleep stage classification, we propose a Structure Incentive Domain Adversarial learning (SIDA) method that combines the sleep stage classification method with domain generalization to enable cross-subject sleep stage classification. SIDA includes individual domain discriminators for each sleep stage category to decouple subject dependence differences among different categories and fine-grained learning of domain-invariant features. Furthermore, SIDA directly connects the label classifier and domain discriminators to promote the training process. Experiments on three benchmark sleep stage classification datasets demonstrate that the proposed SIDA method outperforms other state-of-the-art sleep stage classification and domain generalization methods and achieves the best cross-subject sleep stage classification results.},
  archive      = {J_TIST},
  author       = {Shuo Ma and Yingwei Zhang and Yiqiang Chen and Tao Xie and Shuchao Song and Ziyu Jia},
  doi          = {10.1145/3625238},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {14:1–30},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Exploring structure incentive domain adversarial learning for generalizable sleep stage classification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enabling graph neural networks for semi-supervised risk
prediction in online credit loan services. <em>TIST</em>,
<em>15</em>(1), 13:1–24. (<a
href="https://doi.org/10.1145/3623401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are playing exciting roles in the application scenarios where features are hidden in information associations. Fraud prediction of online credit loan services (OCLSs) is such a typical scenario. But it has another rather critical challenge, i.e., the scarcity of data labels. Fortunately, GNNs can also cope with this problem due to their good ability of semi-supervised learning by mining structure and feature information within graphs. Nevertheless, the gain of internal information is often too limited to help GNNs handle the extreme deficiency of labels with high performance beyond the basic requirement of fraud prediction in OCLSs. Therefore, adding labels from the experts, such as manually adding labels through rules, has become a logical practice. However, the existing rule engines for OCLSs have the confliction problem among continuously accumulated rules. To address this issue, we propose a Snorkel-based Semi-Supervised GNN (S3GNN). Under S3GNN, we specially design an upgraded version of the rule engines, called Graph-Oriented Snorkel (GOS), a graph-specific extension of Snorkel, a widely used weakly supervised learning framework, to design rules by subject matter experts (SMEs) and resolve confliction. In particular, in the graph of an anti-fraud scenario, each node pair may have multiple different types of edges, so we propose the Multiple Edge-Types Based Attention mechanism. In general, for the heterogeneous information and multiple relations in the graph, we first obtain the embedding of applicant nodes by aggregating the representation of attribute nodes, and then use the attention mechanism to aggregate neighbor nodes on multiple meta-paths to get ultimate applicant node embedding. We conduct experiments over the real-life data of a large financial platform. The results demonstrate that S3GNN can outperform the state-of-the-art methods, including the method of pilot platform.},
  archive      = {J_TIST},
  author       = {Hao Tang and Cheng Wang and Jianguo Zheng and Changjun Jiang},
  doi          = {10.1145/3623401},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {13:1–24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Enabling graph neural networks for semi-supervised risk prediction in online credit loan services},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inferring real mobility in presence of fake check-ins data.
<em>TIST</em>, <em>15</em>(1), 12:1–25. (<a
href="https://doi.org/10.1145/3604941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding human mobility has become an important aspect of location-based services in tasks such as personalized recommendation and individual moving pattern recognition, enabled by the large volumes of data from geo-tagged social media (GTSM). Prior studies mainly focus on analyzing human historical footprints collected by GTSM and assuming the veracity of the data, which need not hold when some users are not willing to share their real footprints due to privacy concerns—thereby affecting reliability/authenticity. In this study, we address the problem of Inferring Real Mobility (IRMo) of users, from their unreliable historical traces. Tackling IRMo is a non-trivial task due to the: (1) sparsity of check-in data; (2) suspicious counterfeit check-in behaviors; and (3) unobserved dependencies in human trajectories. To address these issues, we develop a novel Graph-enhanced Attention model called IRMoGA , which attempts to capture underlying mobility patterns and check-in correlations by exploiting the unreliable spatio-temporal data. Specifically, we incorporate the attention mechanism (rather than solely relying on traditional recursive models) to understand the regularity of human mobility, while employing a graph neural network to understand the mutual interactions from human historical check-ins and leveraging prior knowledge to alleviate the inferring bias. Our experiments conducted on four real-world datasets demonstrate the superior performance of IRMoGA over several state-of-the-art baselines, e.g., up to 39.16% improvement regarding the Recall score on Foursquare.},
  archive      = {J_TIST},
  author       = {Qiang Gao and Hongzhu Fu and Kunpeng Zhang and Goce Trajcevski and Xu Teng and Fan Zhou},
  doi          = {10.1145/3604941},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {12:1–25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Inferring real mobility in presence of fake check-ins data},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
