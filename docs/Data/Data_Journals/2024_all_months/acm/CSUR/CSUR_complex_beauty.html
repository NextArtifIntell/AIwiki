<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CSUR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="csur---295">CSUR - 295</h2>
<ul>
<li><details>
<summary>
(2024). A survey of machine learning for urban decision making:
Applications in planning, transportation, and healthcare. <em>CSUR</em>,
<em>57</em>(4), 1–41. (<a
href="https://doi.org/10.1145/3695986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing smart cities is vital for ensuring sustainable development and improving human well-being. One critical aspect of building smart cities is designing intelligent methods to address various decision-making problems that arise in urban areas. As machine learning techniques continue to advance rapidly, a growing body of research has been focused on utilizing these methods to achieve intelligent urban decision-making. In this survey, we conduct a systematic literature review on the application of machine learning methods in urban decision-making, with a focus on planning, transportation, and healthcare. First, we provide a taxonomy based on typical applications of machine learning methods for urban decision-making. We then present background knowledge on these tasks and the machine learning techniques that have been adopted to solve them. Next, we examine the challenges and advantages of applying machine learning in urban decision-making, including issues related to urban complexity, urban heterogeneity, and computational cost. Afterward and primarily, we elaborate on the existing machine learning methods that aim at solving urban decision-making tasks in planning, transportation, and healthcare, highlighting their strengths and limitations. Finally, we discuss open problems and the future directions of applying machine learning to enable intelligent urban decision-making, such as developing foundation models and combining reinforcement learning algorithms with human feedback. We hope this survey can help researchers in related fields understand the recent progress made in existing works, and inspire novel applications of machine learning in smart cities.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695986},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of machine learning for urban decision making: Applications in planning, transportation, and healthcare},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cybersecurity in electric and flying vehicles: Threats,
challenges, AI solutions &amp; future directions. <em>CSUR</em>,
<em>57</em>(4), 1–34. (<a
href="https://doi.org/10.1145/3697830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric and Flying Vehicles (EnFVs) represent a transformative shift in transportation, promising enhanced efficiency and reduced environmental impact. However, their integration into interconnected digital ecosystems poses significant cybersecurity challenges, including cyber-physical threats, privacy vulnerabilities, and supply chain risks. This article comprehensively explores these challenges and investigates artificial intelligence (AI)-driven solutions to bolster EnFV cybersecurity. The study begins with an overview of EnFV cybersecurity issues, emphasizing the increasing complexity of threats in digital transportation systems. Methodologically, the article reviews existing literature to identify gaps and assesses recent advancements in AI for cybersecurity applications. Key methodologies include AI-powered intrusion detection, threat analysis leveraging machine learning algorithms, predictive maintenance strategies, and enhanced authentication protocols. Results underscore the effectiveness of AI technologies in mitigating EnFV cybersecurity risks, demonstrating improved threat detection and response capabilities. The study concludes by outlining future research directions, highlighting the need for continued innovation in AI, quantum computing resilience, blockchain applications, and ethical considerations. These findings contribute to a clearer understanding of EnFV cybersecurity dynamics and provide a roadmap for enhancing the security and reliability of future transportation systems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3697830},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Cybersecurity in electric and flying vehicles: Threats, challenges, AI solutions &amp; future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on IoT programming platforms: A business-domain
experts perspective. <em>CSUR</em>, <em>57</em>(4), 1–37. (<a
href="https://doi.org/10.1145/3699954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vast growth and digitalization potential offered by the Internet of Things (IoT) is hindered by substantial barriers in accessibility, interoperability, and complexity, mainly affecting small organizations and non-technical entities. This survey article provides a detailed overview of the landscape of IoT programming platforms, focusing specifically on the development support they offer for varying end user profiles, ranging from developers with IoT expertise to business experts willing to take advantage of IoT solutions to automate their organization processes. The survey examines a range of IoT platforms, classified according to their programming approach between general-purpose programming solutions, model-driven programming, mashups, and end-user programming. Necessary IoT and programming backgrounds are described to empower non-technical readers with a comprehensive field summary. In addition, the article compares the features of the most representative platforms and provides decision insights and guidelines to support end users in selecting appropriate IoT platforms for their use cases. This work contributes to narrowing the knowledge gap between IoT specialists and end users, breaking accessibility barriers and further promoting the integration of IoT technologies in various domains. 1},
  archive      = {J_CSUR},
  doi          = {10.1145/3699954},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on IoT programming platforms: A business-domain experts perspective},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Taxonomy and survey of collaborative intrusion detection
system using federated learning. <em>CSUR</em>, <em>57</em>(4), 1–36.
(<a href="https://doi.org/10.1145/3701724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review article looks at recent research on Federated Learning (FL) for Collaborative Intrusion Detection Systems (CIDS) to establish a taxonomy and survey. The motivation behind this review comes from the difficulty of detecting coordinated cyberattacks in large-scale distributed networks. Collaborative anomalies are one of the network anomalies that need to be detected through robust collaborative learning methods. FL is promising collaborative learning method in recent research. This review aims to offer insights and lesson learn for creating a taxonomy of collaborative anomaly detection in CIDS using FL as a collaborative learning method. Our findings suggest that a taxonomy is required to map the discussion area, including an algorithm for training the learning model, the dataset, global aggregation model, system architecture, security, and privacy. Our results indicate that FL is a promising approach for collaborative anomaly detection in CIDS, and the proposed taxonomy could be useful for future research in this area. Overall, this review contributes to the growing knowledge of FL for CIDS, providing insights and lessons for researchers and practitioners. This research also concludes significant challenges, opportunities, and future directions in CIDS based on collaborative anomaly detection using FL.},
  archive      = {J_CSUR},
  doi          = {10.1145/3701724},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Taxonomy and survey of collaborative intrusion detection system using federated learning},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fog computing technology research: A retrospective overview
and bibliometric analysis. <em>CSUR</em>, <em>57</em>(4), 1–32. (<a
href="https://doi.org/10.1145/3702313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers’ interest in Fog Computing and its application in different sectors has been increasing since the last decade. To discover the emerging trends inherent to this architecture, we analyzed the scientific literature indexed in Scopus through a bibliometric study. Exposing trends in areas of development will allow researchers to understand the changes and evolution over time. For analysis purposes, we used three approaches: performance analysis, science mapping, and literature clustering. Analysis results revealed promising investigation areas in the Fog Computing architecture from 2012 to 2021, which emphasizes that Fog Computing will continue to be an interesting field of research in the future.},
  archive      = {J_CSUR},
  doi          = {10.1145/3702313},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Fog computing technology research: A retrospective overview and bibliometric analysis},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation methodologies in software protection research.
<em>CSUR</em>, <em>57</em>(4), 1–41. (<a
href="https://doi.org/10.1145/3702314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Man-at-the-end (MATE) attackers have full control over the system on which the attacked software runs, and try to break the confidentiality or integrity of assets embedded in the software. Both companies and malware authors want to prevent such attacks. This has driven an arms race between attackers and defenders, resulting in a plethora of different protection and analysis methods. However, it remains difficult to measure the strength of protections because MATE attackers can reach their goals in many different ways and a universally accepted evaluation methodology does not exist. This survey systematically reviews the evaluation methodologies of papers on obfuscation, a major class of protections against MATE attacks. For 571 papers, we collected 113 aspects of their evaluation methodologies, ranging from sample set types and sizes, over sample treatment, to performed measurements. We provide detailed insights into how the academic state of the art evaluates both the protections and analyses thereon. In summary, there is a clear need for better evaluation methodologies. We identify nine challenges for software protection evaluations, which represent threats to the validity, reproducibility, and interpretation of research results in the context of MATE attacks and formulate a number of concrete recommendations for improving the evaluations reported in future research papers.},
  archive      = {J_CSUR},
  doi          = {10.1145/3702314},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Evaluation methodologies in software protection research},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on emerging trends and applications of 5G and 6G to
healthcare environments. <em>CSUR</em>, <em>57</em>(4), 1–36. (<a
href="https://doi.org/10.1145/3703154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A delay, interruption, or failure in the wireless connection has a significant impact on the performance of wirelessly connected medical equipment. Researchers presented the fastest technological innovations and industrial changes to address these problems and improve the applications of information and communication technology. The development of the 6G communication infrastructure was greatly aided by the use of Block-chain technology, artificial intelligence (AI), virtual reality (VR), and the Internet of Things (IoT). In this article, we comprehensively discuss 6G technologies enhancement, its fundamental architecture, difficulties, and other issues associated with it. In addition, the outcomes of our research help make 6G technology more applicable to real-world medical environments. The most important thing that this study has contributed is an explanation of the path that future research will take and the current state-of-the-art. This study might serve as a jumping-off point for future researchers in the academic world who are interested in investigating the possibilities of 6G technological developments.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703154},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on emerging trends and applications of 5G and 6G to healthcare environments},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Private and secure distributed deep learning: A survey.
<em>CSUR</em>, <em>57</em>(4), 1–43. (<a
href="https://doi.org/10.1145/3703452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, deep learning practitioners would bring data into a central repository for model training and inference. Recent developments in distributed learning, such as federated learning and deep learning as a service (DLaaS), do not require centralized data and instead push computing to where the distributed datasets reside. These decentralized training schemes, however, introduce additional security and privacy challenges. This survey first structures the field of distributed learning into two main paradigms and then provides an overview of the recently published protective measures for each. This work highlights both secure training methods as well as private inference measures. Our analyses show that recent publications, while being highly dependent on the problem definition, report progress in terms of security, privacy, and efficiency. Nevertheless, we also identify several current issues within the private and secure distributed deep learning (PSDDL) field that require more research. We discuss these issues and provide a general overview of how they might be resolved.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703452},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-43},
  shortjournal = {ACM Comput. Surv.},
  title        = {Private and secure distributed deep learning: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Acceleration for deep reinforcement learning using parallel
and distributed computing: A survey. <em>CSUR</em>, <em>57</em>(4),
1–35. (<a href="https://doi.org/10.1145/3703453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has led to dramatic breakthroughs in the field of artificial intelligence for the past few years. As the amount of rollout experience data and the size of neural networks for deep reinforcement learning have grown continuously, handling the training process and reducing the time consumption using parallel and distributed computing is becoming an urgent and essential desire. In this article, we perform a broad and thorough investigation on training acceleration methodologies for deep reinforcement learning based on parallel and distributed computing, providing a comprehensive survey in this field with state-of-the-art methods and pointers to core references. In particular, a taxonomy of literature is provided, along with a discussion of emerging topics and open issues. This incorporates learning system architectures, simulation parallelism, computing parallelism, distributed synchronization mechanisms, and deep evolutionary reinforcement learning. Furthermore, we compare 16 current open-source libraries and platforms with criteria of facilitating rapid development. Finally, we extrapolate future directions that deserve further research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703453},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Acceleration for deep reinforcement learning using parallel and distributed computing: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Open-ethical AI: Advancements in open-source human-centric
neural language models. <em>CSUR</em>, <em>57</em>(4), 1–47. (<a
href="https://doi.org/10.1145/3703454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey summarises the most recent methods for building and assessing helpful, honest, and harmless neural language models, considering small, medium, and large-size models. Pointers to open-source resources that help to align pre-trained models are given, including methods that use parameter-efficient techniques, specialized prompting frameworks, adapter modules, case-specific knowledge injection, and adversarially robust training techniques. Special care is given to evidencing recent progress on value alignment, commonsense reasoning, factuality enhancement, and abstract reasoning of language models. Most reviewed works in this survey publicly shared their code and related data and were accepted in world-leading Machine Learning venues. This work aims at helping researchers and practitioners accelerate their entrance into the field of human-centric neural language models, which might be a cornerstone of the contemporary and near-future industrial and societal revolution.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703454},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-47},
  shortjournal = {ACM Comput. Surv.},
  title        = {Open-ethical AI: Advancements in open-source human-centric neural language models},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security and privacy on generative data in AIGC: A survey.
<em>CSUR</em>, <em>57</em>(4), 1–34. (<a
href="https://doi.org/10.1145/3703626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of artificial intelligence-generated content (AIGC) represents a pivotal moment in the evolution of information technology. With AIGC, it can be effortless to generate high-quality data that is challenging for the public to distinguish. Nevertheless, the proliferation of generative data across cyberspace brings security and privacy issues, including privacy leakages of individuals and media forgery for fraudulent purposes. Consequently, both academia and industry begin to emphasize the trustworthiness of generative data, successively providing a series of countermeasures for security and privacy. In this survey, we systematically review the security and privacy on generative data in AIGC, particularly for the first time analyzing them from the perspective of information security properties. Specifically, we reveal the successful experiences of state-of-the-art countermeasures in terms of the foundational properties of privacy, controllability, authenticity, and compliance, respectively. Finally, we show some representative benchmarks, present a statistical analysis, and summarize the potential exploration directions from each of these properties.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703626},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security and privacy on generative data in AIGC: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). When SDN meets low-rate threats: A survey of attacks and
countermeasures in programmable networks. <em>CSUR</em>, <em>57</em>(4),
1–32. (<a href="https://doi.org/10.1145/3704434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rate threats are a class of attack vectors that are disruptive and stealthy, typically crafted for security vulnerabilities. They have been the significant concern for cyber security, impacting both conventional IP-based networks and emerging Software-Defined Networking (SDN). SDN is a revolutionary architecture that separates the control and data planes, offering advantages such as enhanced manageability, flexibility, and network programmability, as well as the ability to introduce new solutions to address security threats. However, its innovative design also poses new vulnerabilities and threats, especially susceptibility to low-rate threats. To this end, this article presents a comprehensive overview of low-rate threats in programmable networks. It explores low-rate threats and countermeasures within the SDN architecture, encompassing the data plane, control plane, control channel, and application plane, together with traditional low-rate threats and countermeasures in SDN. Furthermore, the article offers detailed insight into threats and countermeasures against low-rate attacks exploiting SDN vulnerabilities and low-rate attacks related to the programmable data plane. Additionally, it presents a comparative analysis and discussion of low-rate attacks versus high-volume attacks, along with suggestions for enhancing SDN security. This thorough review aims to assist researchers in developing more resilient and dependable countermeasures against low-rate threats in programmable networks.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704434},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {When SDN meets low-rate threats: A survey of attacks and countermeasures in programmable networks},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tool learning with foundation models. <em>CSUR</em>,
<em>57</em>(4), 1–40. (<a
href="https://doi.org/10.1145/3704435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans possess an extraordinary ability to create and utilize tools. With the advent of foundation models, artificial intelligence systems have the potential to be equally adept in tool use as humans. This paradigm, which is dubbed as tool learning with foundation models , combines the strengths of tools and foundation models to achieve enhanced accuracy, efficiency, and automation in problem-solving. This article presents a systematic investigation and comprehensive review of tool learning. We first introduce the background of tool learning, including its cognitive origins, the paradigm shift of foundation models, and the complementary roles of tools and models. Then we recapitulate existing tool learning research and formulate a general framework: starting from understanding the user instruction, models should learn to decompose a complex task into several subtasks, dynamically adjust their plan through reasoning, and effectively conquer each sub-task by selecting appropriate tools. We also discuss how to train models for improved tool-use capabilities and facilitate generalization in tool learning. Finally, we discuss several open problems that require further investigation, such as ensuring trustworthy tool use, enabling tool creation with foundation models, and addressing personalization challenges. Overall, we hope this article could inspire future research in integrating tools with foundation models.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704435},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Tool learning with foundation models},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Democratizing container live migration for enhanced future
networks - a survey. <em>CSUR</em>, <em>57</em>(4), 1–37. (<a
href="https://doi.org/10.1145/3704436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging cloud-centric networks span from edge clouds to large-scale datacenters with shared infrastructure among multiple tenants and applications with high availability, isolation, fault tolerance, security, and energy efficiency demands. Live migration (LiMi) plays an increasingly critical role in these environments by enabling seamless application mobility covering the edge-to-cloud continuum and maintaining these requirements. This paper presents a comprehensive survey of recent advancements that democratize LiMi, making it more applicable to a broader range of scenarios and network environments both for virtual machines (VMs) and containers, and analyzes LiMi’s technical underpinnings and optimization techniques. It also delves into the issue of connections handover, presenting a taxonomy to categorize methods of traffic redirection synthesized from the existing literature. Finally, it identifies technical challenges and paves the way for future research directions in this key technology.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704436},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Democratizing container live migration for enhanced future networks - A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Systematic review of generative modelling tools and utility
metrics for fully synthetic tabular data. <em>CSUR</em>, <em>57</em>(4),
1–38. (<a href="https://doi.org/10.1145/3704437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sharing data with third parties is essential for advancing science, but it is becoming more and more difficult with the rise of data protection regulations, ethical restrictions, and growing fear of misuse. Fully synthetic data, which transcends anonymisation, may be the key to unlocking valuable untapped insights stored away in secured data vaults. This review examines current synthetic data generation methods and their utility measurement. We found that more traditional generative models such as Classification and Regression Tree models alongside Bayesian Networks remain highly relevant and are still capable of surpassing deep learning alternatives like Generative Adversarial Networks. However, our findings also display the same lack of agreement on metrics for evaluation, uncovered in earlier reviews, posing a persistent obstacle to advancing the field. We propose a tool for evaluating the utility of synthetic data and illustrate how it can be applied to three synthetic data generation models. By streamlining evaluation and promoting agreement on metrics, researchers can explore novel methods and generate compelling results that will convince data curators and lawmakers to embrace synthetic data. Our review emphasises the potential of synthetic data and highlights the need for greater collaboration and standardisation to unlock its full potential.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704437},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Systematic review of generative modelling tools and utility metrics for fully synthetic tabular data},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Membership inference attacks and defenses in federated
learning: A survey. <em>CSUR</em>, <em>57</em>(4), 1–35. (<a
href="https://doi.org/10.1145/3704633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a decentralized machine learning approach where clients train models locally and share model updates to develop a global model. This enables low-resource devices to collaboratively build a high-quality model without requiring direct access to the raw training data. However, despite only sharing model updates, federated learning still faces several privacy vulnerabilities. One of the key threats is membership inference attacks, which target clients’ privacy by determining whether a specific example is part of the training set. These attacks can compromise sensitive information in real-world applications, such as medical diagnoses within a healthcare system. Although there has been extensive research on membership inference attacks, a comprehensive and up-to-date survey specifically focused on it within federated learning is still absent. To fill this gap, we categorize and summarize membership inference attacks and their corresponding defense strategies based on their characteristics in this setting. We introduce a unique taxonomy of existing attack research and provide a systematic overview of various countermeasures. For these studies, we thoroughly analyze the strengths and weaknesses of different approaches. Finally, we identify and discuss key future research directions for readers interested in advancing the field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704633},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Membership inference attacks and defenses in federated learning: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Backdoor attacks and defenses targeting multi-domain AI
models: A comprehensive review. <em>CSUR</em>, <em>57</em>(4), 1–35. (<a
href="https://doi.org/10.1145/3704725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the emergence of security concerns in artificial intelligence (AI), there has been significant attention devoted to the examination of backdoor attacks. Attackers can utilize backdoor attacks to manipulate model predictions, leading to significant potential harm. However, current research on backdoor attacks and defenses in both theoretical and practical fields still has many shortcomings. To systematically analyze these shortcomings and address the lack of comprehensive reviews, this article presents a comprehensive and systematic summary of both backdoor attacks and defenses targeting multi-domain AI models. Simultaneously, based on the design principles and shared characteristics of triggers in different domains and the implementation stages of backdoor defense, this article proposes a new classification method for backdoor attacks and defenses. We use this method to extensively review backdoor attacks in the fields of computer vision and natural language processing, and we also examine the current applications of backdoor attacks in audio recognition, video action recognition, multimodal tasks, time series tasks, generative learning, and reinforcement learning, while critically analyzing the open problems of various backdoor attack techniques and defense strategies. Finally, this article builds upon the analysis of the current state of AI security to further explore potential future research directions for backdoor attacks and defenses.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704725},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Backdoor attacks and defenses targeting multi-domain AI models: A comprehensive review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motivations, challenges, best practices, and benefits for
bots and conversational agents in software engineering: A multivocal
literature review. <em>CSUR</em>, <em>57</em>(4), 1–37. (<a
href="https://doi.org/10.1145/3704806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bots are software systems designed to support users by automating specific processes, tasks, or activities. When these systems implement a conversational component to interact with users, they are also known as conversational agents or chatbots . Bots—particularly in their conversation-oriented version and AI-powered—have seen increased adoption over time for software development and engineering purposes. Despite their exciting potential, which has been further enhanced by the advent of Generative AI and Large Language Models, bots still face challenges in terms of development and integration into the development cycle, as practitioners report that bots can add difficulties rather than provide improvements. In this work, we aim to provide a taxonomy for characterizing bots, as well as a series of challenges for their adoption in software engineering, accompanied by potential mitigation strategies. To achieve our objectives, we conducted a multivocal literature review , examining both research and practitioner literature. Through such an approach, we hope to contribute to both researchers and practitioners by providing (i) a series of future research directions to pursue, (ii) a list of strategies to adopt for improving the use of bots for software engineering purposes, and (iii) fostering technology and knowledge transfer from the research field to practice—one of the primary goals of multivocal literature reviews.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704806},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Motivations, challenges, best practices, and benefits for bots and conversational agents in software engineering: A multivocal literature review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative distributed machine learning. <em>CSUR</em>,
<em>57</em>(4), 1–36. (<a
href="https://doi.org/10.1145/3704807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various collaborative distributed machine learning (CDML) systems, including federated learning systems and swarm learning systems, with different key traits were developed to leverage resources for the development and use of machine learning models in a confidentiality-preserving way. To meet use case requirements, suitable CDML systems need to be selected. However, comparison between CDML systems to assess their suitability for use cases is often difficult. To support comparison of CDML systems and introduce scientific and practical audiences to the principal functioning and key traits of CDML systems, this work presents a CDML system conceptualization and CDML archetypes.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704807},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Collaborative distributed machine learning},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Racial bias within face recognition: A survey.
<em>CSUR</em>, <em>57</em>(4), 1–39. (<a
href="https://doi.org/10.1145/3705295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial recognition is one of the most academically studied and industrially developed areas within computer vision where we readily find associated applications deployed globally. This widespread adoption has uncovered significant performance variation across subjects of different racial profiles leading to focused research attention on racial bias within face recognition spanning both current causation and future potential solutions. In support, this study provides an extensive taxonomic review of research on racial bias within face recognition exploring every aspect and stage of the associated facial processing pipeline. Firstly, we discuss the problem definition of racial bias, starting with race definition, grouping strategies, and the societal implications of using race or race-related groupings. Secondly, we divide the common face recognition processing pipeline into four stages: image acquisition, face localisation, face representation, face verification and identification, and review the relevant corresponding literature associated with each stage. The overall aim is to provide comprehensive coverage of the racial bias problem with respect to each and every stage of the face recognition processing pipeline whilst also highlighting the potential pitfalls and limitations of contemporary mitigation strategies that need to be considered within future research endeavours or commercial applications alike.},
  archive      = {J_CSUR},
  doi          = {10.1145/3705295},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Racial bias within face recognition: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-powered fraud detection in decentralized finance: A
project life cycle perspective. <em>CSUR</em>, <em>57</em>(4), 1–38. (<a
href="https://doi.org/10.1145/3705296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized finance (DeFi) represents a novel financial system but faces significant fraud challenges, leading to substantial losses. Recent advancements in artificial intelligence (AI) show potential for complex fraud detection. Despite growing interest, a systematic review of these methods is lacking. This survey correlates fraud types with DeFi project stages, presenting a taxonomy based on the project life cycle. We evaluate AI techniques, revealing notable findings, such as the superiority of tree-based and graph-related models. Based on these insights, we offer recommendations and outline future research directions to aid researchers, practitioners, and regulators in enhancing DeFi security.},
  archive      = {J_CSUR},
  doi          = {10.1145/3705296},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {AI-powered fraud detection in decentralized finance: A project life cycle perspective},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causal discovery from temporal data: An overview and new
perspectives. <em>CSUR</em>, <em>57</em>(4), 1–38. (<a
href="https://doi.org/10.1145/3705297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal data, representing chronological observations of complex systems, has always been a typical data structure that can be widely generated by many domains, such as industry, finance, healthcare, and climatology. Analyzing the underlying structures, i.e., the causal relations, could be extremely valuable for various applications. Recently, causal discovery from temporal data has been considered as an interesting yet critical task and attracted much research attention. According to the nature and structure of temporal data, existing causal discovery works can be divided into two highly correlated categories i.e., multivariate time series causal discovery, and event sequence causal discovery. However, most previous surveys are only focused on the multivariate time series causal discovery but ignore the second category. In this article, we specify the similarity between the two categories and provide an overview of existing solutions. Furthermore, we provide public datasets, evaluation metrics, and new perspectives for temporal data causal discovery.},
  archive      = {J_CSUR},
  doi          = {10.1145/3705297},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Causal discovery from temporal data: An overview and new perspectives},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable artificial intelligence: Importance, use
domains, stages, output shapes, and challenges. <em>CSUR</em>,
<em>57</em>(4), 1–36. (<a
href="https://doi.org/10.1145/3705724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an urgent need in many application areas for eXplainable ArtificiaI Intelligence (XAI) approaches to boost people’s confidence and trust in Artificial Intelligence methods. Current works concentrate on specific aspects of XAI and avoid a comprehensive perspective. This study undertakes a systematic survey of importance, approaches, methods, and application domains to address this gap and provide a comprehensive understanding of the XAI domain. Applying the Systematic Literature Review approach has resulted in finding and discussing 155 papers, allowing a wide discussion on the strengths, limitations, and challenges of XAI methods and future research directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3705724},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Explainable artificial intelligence: Importance, use domains, stages, output shapes, and challenges},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). SoK: Access control policy generation from high-level
natural language requirements. <em>CSUR</em>, <em>57</em>(4), 1–37. (<a
href="https://doi.org/10.1145/3706057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Administrator-centered access control failures can cause data breaches, putting organizations at risk of financial loss and reputation damage. Existing graphical policy configuration tools and automated policy generation frameworks attempt to help administrators configure and generate access control policies by avoiding such failures. However, graphical policy configuration tools are prone to human errors, making them unusable. On the other hand, automated policy generation frameworks are prone to erroneous predictions, making them unreliable. Therefore, to find ways to improve their usability and reliability, we conducted a Systematic Literature Review analyzing 49 publications. The thematic analysis of the publications revealed that graphical policy configuration tools are developed to write and visualize policies manually. Moreover, automated policy generation frameworks are developed using machine learning (ML) and natural language processing (NLP) techniques to automatically generate access control policies from high-level requirement specifications. Despite their utility in the access control domain, limitations of these tools, such as the lack of flexibility, and limitations of frameworks, such as the lack of domain adaptation, negatively affect their usability and reliability, respectively. Our study offers recommendations to address these limitations through real-world applications and recent advancements in the NLP domain, paving the way for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3706057},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {SoK: Access control policy generation from high-level natural language requirements},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Object selection and manipulation in VR headsets: Research
challenges, solutions, and success measurements. <em>CSUR</em>,
<em>57</em>(4), 1–34. (<a
href="https://doi.org/10.1145/3706417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object selection and manipulation are the foundation of VR interactions. With the rapid development of VR technology and the field of virtual object selection and manipulation, the literature demands a structured understanding of the core research challenges and a critical reflection of the current practices. To provide such understanding and reflections, we systematically reviewed 106 papers. We identified classic and emerging topics, categorized existing solutions, and evaluated how success was measured in these publications. Based on our analysis, we discuss future research directions and propose a framework for developing and determining appropriate solutions for different application scenarios.},
  archive      = {J_CSUR},
  doi          = {10.1145/3706417},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Object selection and manipulation in VR headsets: Research challenges, solutions, and success measurements},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security challenges, mitigation strategies, and future
trends in wireless sensor networks: A review. <em>CSUR</em>,
<em>57</em>(4), 1–29. (<a
href="https://doi.org/10.1145/3706583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor Networks (WSNs) represent an innovative technology that integrates compact, energy-efficient sensors with wireless communication functionalities, facilitating instantaneous surveillance and data gathering from the surrounding environment. WSNs are utilized across diverse domains, such as environmental monitoring, industrial automation, healthcare, smart agriculture, home automation, and beyond. Due to the inherent characteristics of WSNs they face many security challenges ranging from resource-based attacks, such as energy depletion or computational overload, to eavesdropping, interception, and tampering. Moreover, the dynamic and often ad hoc deployment of sensors in varying environments increases their vulnerability to physical intrusion attacks, the distributed and collaborative nature of WSNs raises concerns about data integrity, as compromised nodes can potentially propagate misleading or malicious information throughout the network. In this article, we categorize WSN attacks, identifying vulnerabilities and corresponding mitigation strategies. We also explore current research directions in WSN security, emphasizing the challenges in addressing these issues.},
  archive      = {J_CSUR},
  doi          = {10.1145/3706583},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-29},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security challenges, mitigation strategies, and future trends in wireless sensor networks: A review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LiDAR-based place recognition for autonomous driving: A
survey. <em>CSUR</em>, <em>57</em>(4), 1–36. (<a
href="https://doi.org/10.1145/3707446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LiDAR has gained popularity in autonomous driving due to advantages like long measurement distance, rich three-dimensional information, and stability in harsh environments. Place Recognition (PR) enables vehicles to identify previously visited locations despite variations in appearance, weather, and viewpoints, even determining their global location within prior maps. This capability is crucial for accurate localization in autonomous driving. Consequently, LiDAR-based Place Recognition (LPR) has emerged as a research hotspot in robotics. However, existing reviews predominantly concentrate on Visual Place Recognition, leaving a gap in systematic reviews on LPR. This article bridges this gap by providing a comprehensive review of LPR methods, thus facilitating and encouraging further research. We commence by exploring the relationship between PR and autonomous driving components. Then, we delve into the problem formulation of LPR, challenges, and relations to previous surveys. Subsequently, we conduct an in-depth review of related research, which offers detailed classifications, strengths and weaknesses, and architectures. Finally, we summarize existing datasets and evaluation metrics and envision promising future directions. This article can serve as a valuable tutorial for newcomers entering the field of place recognition. We plan to maintain an up-to-date project on https://github.com/ShiPC-AI/LPR-Survey .},
  archive      = {J_CSUR},
  doi          = {10.1145/3707446},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {LiDAR-based place recognition for autonomous driving: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on deep clustering: Taxonomy,
challenges, and future directions. <em>CSUR</em>, <em>57</em>(3), 1–38.
(<a href="https://doi.org/10.1145/3689036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a fundamental machine learning task, which aim at assigning instances into groups so that similar samples belong to the same cluster while dissimilar samples belong to different clusters. Shallow clustering methods usually assume that data are collected and expressed as feature vectors within which clustering is performed. However, clustering high-dimensional data, such as images, texts, videos, and graphs, poses significant challenges for clustering tasks, such as indiscriminate representation and intricate relationships among instances. Over the past decades, deep learning has achieved remarkable success in effective representation learning and modeling complex relationships. Motivated by these advancements, Deep Clustering seeks to improve clustering outcomes through deep learning techniques, garnering considerable interest from both academia and industry. Despite many contributions to this vibrant area of research, the lack of systematic analysis and a comprehensive taxonomy has hindered progress in this field. In this survey, we first explore how deep learning can be integrated into deep clustering and identify two fundamental components: the representation learning module and the clustering module. Then, we summarize and analyze the representative design of these two modules. Furthermore, we introduce a novel taxonomy of deep clustering based on how these two modules interact, specifically through multistage, generative, iterative, and simultaneous approaches. In addition, we present well-known benchmark datasets, evaluation metrics, and open-source tools to clearly demonstrate different experimental approaches. Finally, we examine the practical applications of deep clustering and propose challenging areas for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3689036},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on deep clustering: Taxonomy, challenges, and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The gap between trustworthy AI research and trustworthy
software research: A tertiary study. <em>CSUR</em>, <em>57</em>(3),
1–40. (<a href="https://doi.org/10.1145/3694964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing application and complexity of Artificial Intelligence (AI) systems, the trustworthiness of AI has garnered widespread attention across various fields. An AI system is a specific type of software system with unique trustworthiness requirements due to its distinctive characteristics in data and algorithms. Our objective is to investigate the state-of-the-art in trustworthy AI and trustworthy software separately and to analyze the connections and gaps between them. To this end, we conducted a tertiary study, which is a systematic literature review of existing secondary studies. These secondary studies are divided into two groups: one focuses on trustworthy AI and the other on trustworthy software. We developed frameworks for both trustworthy AI and trustworthy software, summarized the definitions of quality attributes in a structured format, and analyzed the similarities of these attributes between the two areas. Additionally, we created a swimlane diagram illustrating trustworthy practices throughout the development life-cycle and in relation to specific quality attributes. Researchers in these two areas originate from distinct research communities, leading to a significant gap between the trustworthiness of AI and software. However, we believe that existing research on trustworthy software can effectively address some gaps in trustworthy AI research, and we have identified evidence of connections between the two areas.},
  archive      = {J_CSUR},
  doi          = {10.1145/3694964},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {The gap between trustworthy AI research and trustworthy software research: A tertiary study},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning aided intelligent reflective surfaces for 6G:
A survey. <em>CSUR</em>, <em>57</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3696414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The envisioned sixth-generation (6G) networks anticipate robust support for diverse applications, including massive machine-type communications, ultra-reliable low-latency communications, and enhanced mobile broadband. Intelligent Reflecting surface (IRS) have emerged as a key technology capable of intelligently reconfiguring wireless propagation environments, thereby enhancing overall network performance. Traditional optimization techniques face limitations in meeting the stringent performance requirements of 6G networks due to the intricate and dynamic nature of the wireless environment. Consequently, deep learning (DL) techniques are employed within the IRS framework to optimize wireless system performance. This article provides a comprehensive survey of the latest research in DL-aided IRS models, covering optimal beamforming, resource allocation control, channel estimation and prediction, signal detection, and system deployment. The focus is on presenting promising solutions within the constraints of different hardware configurations. The survey explores challenges, opportunities, and open research issues in DL-aided IRS, considering emerging technologies such as digital twins, computer vision, blockchain, network function virtualization, integrated sensing and communication, software-defined networking, mobile edge computing, unmanned aerial vehicles, and non-orthogonal multiple access. Practical design issues associated with these enabling technologies are also discussed, providing valuable insights into the current state and future directions of this evolving field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696414},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning aided intelligent reflective surfaces for 6G: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modal misinformation detection: Approaches, challenges
and opportunities. <em>CSUR</em>, <em>57</em>(3), 1–29. (<a
href="https://doi.org/10.1145/3697349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As social media platforms evolve from text-based forums into multi-modal environments, the nature of misinformation in social media is also transforming accordingly. Taking advantage of the fact that visual modalities such as images and videos are more favorable and attractive to users, and textual content is sometimes skimmed carelessly, misinformation spreaders have recently targeted contextual connections between the modalities, e.g., text and image. Hence, many researchers have developed automatic techniques for detecting possible cross-modal discordance in web-based content. We analyze, categorize, and identify existing approaches in addition to the challenges and shortcomings they face to unearth new research opportunities in the field of multi-modal misinformation detection.},
  archive      = {J_CSUR},
  doi          = {10.1145/3697349},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-29},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multi-modal misinformation detection: Approaches, challenges and opportunities},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The role of multi-agents in digital twin implementation:
Short survey. <em>CSUR</em>, <em>57</em>(3), 1–15. (<a
href="https://doi.org/10.1145/3697350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Digital Twin (DT) technology has emerged as a significant technological advancement. A digital twin is a digital representation of a physical asset that mirrors its data model, behaviour, and interactions with other physical assets. Digital Twin aims at achieving adaptability, seamless data integration, modelling, simulation, automation, and real-time data management. The primary goal of this article is to explore the role of agents in DT implementations, seeking to understand their predominant usage scenarios and purposes. From our perspective, agents serving as intelligent entities play a role in realising the features of DTs. This article also discusses the gaps in DT, highlights future directions, and analyses various technologies integrated with multi-agent systems technologies in DT implementations. Finally, the article briefly discusses an overview of an architecture to implement a DT for smart agriculture with multi-agents.},
  archive      = {J_CSUR},
  doi          = {10.1145/3697350},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-15},
  shortjournal = {ACM Comput. Surv.},
  title        = {The role of multi-agents in digital twin implementation: Short survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning-based artificial intelligence artwork: Methodology
taxonomy and quality evaluation. <em>CSUR</em>, <em>57</em>(3), 1–37.
(<a href="https://doi.org/10.1145/3698105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the theory and technology of computer science, machine or computer painting is increasingly being explored in the creation of art. Machine-made works are referred to as artificial intelligence (AI) artworks. Early methods of AI artwork generation have been classified as non-photorealistic rendering, and, latterly, neural style transfer methods have also been investigated. As technology advances, the variety of machine-generated artworks and the methods used to create them have proliferated. However, there is no unified and comprehensive system to classify and evaluate these works. To date, no work has generalized methods of creating AI artwork including learning-based methods for painting or drawing. Moreover, the taxonomy, evaluation, and development of AI artwork methods face many challenges. This article is motivated by these considerations. We first investigate current learning-based methods for making AI artworks and classify the methods according to art styles. Furthermore, we propose a consistent evaluation system for AI artworks and conduct a user study to evaluate the proposed system on different AI artworks. This evaluation system uses six criteria: beauty, color, texture, content detail, line, and style. The user study demonstrates that the six-dimensional evaluation index is effective for different types of AI artworks.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698105},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Learning-based artificial intelligence artwork: Methodology taxonomy and quality evaluation},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Green IN artificial intelligence from a software
perspective: State-of-the-art and green decalogue. <em>CSUR</em>,
<em>57</em>(3), 1–30. (<a
href="https://doi.org/10.1145/3698111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a structured view of the state-of-the-art research on Artificial Intelligence (AI), from the point of view of efficiency and reduction of the energy consumption of AI software. We analysed the current research on energy consumption of AI algorithms and its improvements, which gave us a starting literature corpus of 2,688 papers that we identified as Green AI with a software perspective. We structure this corpus into Green IN AI and Green BY AI, which led us to discover that only 36 of them could be considered Green IN AI. After some quick insights about Green BY AI, we then introduce our main contribution: a systematic mapping of Green IN AI. We provide an in-depth analysis of the AI models that we observed during the mapping, and what solutions have been proposed for improving their energy efficiency. We also analyse the energy evaluation methodologies employed in Green IN AI, discovering that most papers opt for a software-based energy estimation approach and 27% of all papers do not document their methodology. We finish by synthetising our insights from the mapping into a Decalogue of Good Practices for Green AI.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698111},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Green IN artificial intelligence from a software perspective: State-of-the-art and green decalogue},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge editing for large language models: A survey.
<em>CSUR</em>, <em>57</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3698590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have recently transformed both the academic and industrial landscapes due to their remarkable capacity to understand, analyze, and generate texts based on their vast knowledge and reasoning ability. Nevertheless, one major drawback of LLMs is their substantial computational cost for pre-training due to their unprecedented amounts of parameters. The disadvantage is exacerbated when new knowledge frequently needs to be introduced into the pre-trained model. Therefore, it is imperative to develop effective and efficient techniques to update pre-trained LLMs. Traditional methods encode new knowledge in pre-trained LLMs through direct fine-tuning. However, naively re-training LLMs can be computationally intensive and risks degenerating valuable pre-trained knowledge irrelevant to the update in the model. Recently, Knowledge-based Model Editing (KME), also known as Knowledge Editing or Model Editing , has attracted increasing attention, which aims at precisely modifying the LLMs to incorporate specific knowledge, without negatively influencing other irrelevant knowledge. In this survey, we aim at providing a comprehensive and in-depth overview of recent advances in the field of KME. We first introduce a general formulation of KME to encompass different KME strategies. Afterward, we provide an innovative taxonomy of KME techniques based on how the new knowledge is introduced into pre-trained LLMs, and investigate existing KME strategies while analyzing key insights, advantages, and limitations of methods from each category. Moreover, representative metrics, datasets, and applications of KME are introduced accordingly. Finally, we provide an in-depth analysis regarding the practicality and remaining challenges of KME and suggest promising research directions for further advancement in this field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698590},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Knowledge editing for large language models: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Early-exit deep neural network - a comprehensive survey.
<em>CSUR</em>, <em>57</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3698767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) typically have a single exit point that makes predictions by running the entire stack of neural layers. Since not all inputs require the same amount of computation to reach a confident prediction, recent research has focused on incorporating multiple “exits” into the conventional DNN architecture. Early-exit DNNs are multi-exit neural networks that attach many side branches to the conventional DNN, enabling inference to stop early at intermediate points. This approach offers several advantages, including speeding up the inference process, mitigating the vanishing gradients problems, reducing overfitting and overthinking tendencies. It also supports DNN partitioning across devices and is ideal for multi-tier computation platforms such as edge computing. This article decomposes the early-exit DNN architecture and reviews the recent advances in the field. The study explores its benefits, designs, training strategies, and adaptive inference mechanisms. Various design challenges, application scenarios, and future directions are also extensively discussed.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698767},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Early-exit deep neural network - A comprehensive survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge-based cyber physical security at smart home: A
review. <em>CSUR</em>, <em>57</em>(3), 1–36. (<a
href="https://doi.org/10.1145/3698768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart-home systems represent the future of modern building infrastructure as they integrate numerous devices and applications to improve the overall quality of life. These systems establish connectivity among smart devices, leveraging network technologies and algorithmic controls to monitor and manage physical environments. However, ensuring robust security in smart homes, along with securing smart devices, presents a formidable challenge. A substantial number of security solutions for smart homes rely on data-driven approaches (e.g., machine/deep learning) to identify and mitigate potential threats. These approaches involve training models on extensive datasets, which distinguishes them from knowledge-driven methods. In this review, we examine the role of knowledge within smart homes, focusing on understanding and reasoning regarding various events and their utility toward securing smart homes. We propose a taxonomy to characterize the categorization of decision-making approaches. By specifying the most common vulnerabilities, attacks, and threats, we can analyze and assess the countermeasures against them. We also examine how smart homes have been evaluated in the reviewed literature. Furthermore, we explore the challenges inherent in smart homes and investigate existing solutions that aim at overcoming these limitations. Finally, we examine the key gaps in smart-home-security research and define future research directions for knowledge-driven schemes.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698768},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Knowledge-based cyber physical security at smart home: A review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deepfake detection: A comprehensive survey from the
reliability perspective. <em>CSUR</em>, <em>57</em>(3), 1–35. (<a
href="https://doi.org/10.1145/3699710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mushroomed Deepfake synthetic materials circulated on the internet have raised a profound social impact on politicians, celebrities, and individuals worldwide. In this survey, we provide a thorough review of the existing Deepfake detection studies from the reliability perspective. We identify three reliability-oriented research challenges in the current Deepfake detection domain: transferability, interpretability, and robustness. Moreover, while solutions have been frequently addressed regarding the three challenges, the general reliability of a detection model has been barely considered, leading to the lack of reliable evidence in real-life usages and even for prosecutions on Deepfake-related cases in court. We, therefore, introduce a model reliability study metric using statistical random sampling knowledge and the publicly available benchmark datasets to review the reliability of the existing detection models on arbitrary Deepfake candidate suspects. Case studies are further executed to justify the real-life Deepfake cases including different groups of victims with the help of the reliably qualified detection models as reviewed in this survey. Reviews and experiments on the existing approaches provide informative discussions and future research directions for Deepfake detection.},
  archive      = {J_CSUR},
  doi          = {10.1145/3699710},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deepfake detection: A comprehensive survey from the reliability perspective},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic literature review on automated software
vulnerability detection using machine learning. <em>CSUR</em>,
<em>57</em>(3), 1–36. (<a
href="https://doi.org/10.1145/3699711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, numerous Machine Learning (ML) models, including Deep Learning (DL) and classic ML models, have been developed to detect software vulnerabilities. However, there is a notable lack of comprehensive and systematic surveys that summarize, classify, and analyze the applications of these ML models in software vulnerability detection. This absence may lead to critical research areas being overlooked or under-represented, resulting in a skewed understanding of the current state of the art in software vulnerability detection. To close this gap, we propose a comprehensive and systematic literature review that characterizes the different properties of ML-based software vulnerability detection systems using six major Research Questions (RQs). Using a custom web scraper, our systematic approach involves extracting a set of studies from four widely used online digital libraries: ACM Digital Library, IEEE Xplore, ScienceDirect, and Google Scholar. We manually analyzed the extracted studies to filter out irrelevant work unrelated to software vulnerability detection, followed by creating taxonomies and addressing RQs. Our analysis indicates a significant upward trend in applying ML techniques for software vulnerability detection over the past few years, with many studies published in recent years. Prominent conference venues include the International Conference on Software Engineering (ICSE), the International Symposium on Software Reliability Engineering (ISSRE), the Mining Software Repositories (MSR) conference, and the ACM International Conference on the Foundations of Software Engineering (FSE), whereas Information and Software Technology (IST), Computers &amp; Security (C&amp;S), and Journal of Systems and Software (JSS) are the leading journal venues. Our results reveal that 39.1% of the subject studies use hybrid sources, whereas 37.6% of the subject studies utilize benchmark data for software vulnerability detection. Code-based data are the most commonly used data type among subject studies, with source code being the predominant subtype. Graph-based and token-based input representations are the most popular techniques, accounting for 57.2% and 24.6% of the subject studies, respectively. Among the input embedding techniques, graph embedding and token vector embedding are the most frequently used techniques, accounting for 32.6% and 29.7% of the subject studies. Additionally, 88.4% of the subject studies use DL models, with recurrent neural networks and graph neural networks being the most popular subcategories, whereas only 7.2% use classic ML models. Among the vulnerability types covered by the subject studies, CWE-119, CWE-20, and CWE-190 are the most frequent ones. In terms of tools used for software vulnerability detection, Keras with TensorFlow backend and PyTorch libraries are the most frequently used model-building tools, accounting for 42 studies for each. In addition, Joern is the most popular tool used for code representation, accounting for 24 studies. Finally, we summarize the challenges and future directions in the context of software vulnerability detection, providing valuable insights for researchers and practitioners in the field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3699711},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on automated software vulnerability detection using machine learning},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence to support the training and
assessment of professionals: A systematic literature review.
<em>CSUR</em>, <em>57</em>(3), 1–29. (<a
href="https://doi.org/10.1145/3699712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in Artificial Intelligence (AI) and sensors are significantly impacting multiple areas, including education and workplaces. Following the PRISMA methodology, this review explores the current status of using AI to support the training and assessment of professionals. We examined 83 research papers, analyzing (1) the targeted professionals, (2) the skills assessed, (3) the AI algorithms utilized, (4) the data and devices employed, (5) data fusion techniques utilized, (6) the architecture of the proposed platforms, (7) the management of ethics and privacy, and (8) validations of the proposals. The review highlights a trend in evaluating healthcare professionals (especially surgeons) motivated by the critical role of hands-on training in these professions. Besides, the review reveals that data fusion techniques and certain technologies, like transfer learning and explainable AI, are not widely utilized despite their huge potential. Finally, the review underscores that most proposals remain within the research domain, lacking the integration and maturity needed for sustained use in real-world environments. Therefore, most of the proposals are not currently available to support the training of professionals. The insights of this review can guide researchers aiming to improve the training of professionals and, consequently, their education.},
  archive      = {J_CSUR},
  doi          = {10.1145/3699712},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-29},
  shortjournal = {ACM Comput. Surv.},
  title        = {Artificial intelligence to support the training and assessment of professionals: A systematic literature review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey of studies on predicting anatomical
therapeutic chemical classes of drugs. <em>CSUR</em>, <em>57</em>(3),
1–31. (<a href="https://doi.org/10.1145/3699713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug classification plays a crucial role in contemporary drug discovery, design, and development. Determining the Anatomical Therapeutic Chemical (ATC) classes for new drugs is a laborious, costly, and intricate process, often requiring multiple clinical trial phases. Computational models offer significant benefits by accelerating drug evaluation, reducing complexity, and lowering costs; however, challenges persist in the drug classification system. To address this, a literature survey of computational models used for predicting ATC classes was conducted, covering research from 2008 to 2024. This study reviews numerous research articles on drug classification, focusing on drug descriptors, data sources, tasks, computational methods, model performance, and challenges in predicting ATC classes. It also examines the evolution of computational techniques and their application in identifying ATC classes. Finally, the study highlights open problems and research gaps, suggesting areas for further investigation in ATC class prediction.},
  archive      = {J_CSUR},
  doi          = {10.1145/3699713},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-31},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey of studies on predicting anatomical therapeutic chemical classes of drugs},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mathematical information retrieval: A review. <em>CSUR</em>,
<em>57</em>(3), 1–34. (<a
href="https://doi.org/10.1145/3699953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical formulas are commonly used to demonstrate theories and basic fundamentals in the Science, Technology, Engineering, and Mathematics (STEM) domain. The burgeoning research in the STEM domain results in the mass production of scientific documents that contain both textual and mathematical terms. In scientific information, the definition of mathematical formulas is expressed through context and symbolic structure that adheres to strong domain-specific notions. Whereas the retrieval of textual information is well-researched, and numerous text-based search engines are present. However, textual information retrieval systems are inadequate for searching scientific information containing mathematical formulas, including simple symbols to complicated mathematical structures. The retrieval of mathematical information is in its infancy, and it requires the inclusion of new technologies and tools to promote the retrieval of scientific information and the management of digital libraries. This article provides a comprehensive study of mathematical information retrieval and highlights their challenges and future opportunities.},
  archive      = {J_CSUR},
  doi          = {10.1145/3699953},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Mathematical information retrieval: A review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on rare event prediction.
<em>CSUR</em>, <em>57</em>(3), 1–39. (<a
href="https://doi.org/10.1145/3699955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rare event prediction involves identifying and forecasting events with a low probability using machine learning (ML) and data analysis. Due to the imbalanced data distributions, where the frequency of common events vastly outweighs that of rare events, it requires using specialized methods within each step of the ML pipeline, that is, from data processing to algorithms to evaluation protocols. Predicting the occurrences of rare events is important for real-world applications, such as Industry 4.0, and is an active research area in statistical and ML. This article comprehensively reviews the current approaches for rare event prediction along four dimensions: rare event data, data processing, algorithmic approaches, and evaluation approaches. Specifically, we consider 73 datasets from different modalities (i.e., numerical, image, text, and audio), four major categories of data processing, five major algorithmic groupings, and two broader evaluation approaches. This article aims to identify gaps in the current literature and highlight the challenges of predicting rare events. It also suggests potential research directions, which can help guide practitioners and researchers.},
  archive      = {J_CSUR},
  doi          = {10.1145/3699955},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on rare event prediction},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On efficient training of large-scale deep learning models.
<em>CSUR</em>, <em>57</em>(3), 1–36. (<a
href="https://doi.org/10.1145/3700439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of deep learning has witnessed significant progress in recent times, particularly in areas such as computer vision (CV), natural language processing (NLP), and speech. The use of large-scale models trained on vast amounts of data holds immense promise for practical applications, enhancing industrial productivity and facilitating social development. However, it suffers extremely from the unstable training process and stringent requirements of computational resources. With the increasing demands on the adaption of computational capacity, though numerous studies have explored the efficient training field to a certain extent, a comprehensive summarization/guideline on those general acceleration techniques of training large-scale deep learning models is still much anticipated. In this survey, we present a detailed review of the general techniques for training acceleration. We consider the fundamental update formulation and split its basic components into five main perspectives: (1) “data-centric,” including dataset regularization, data sampling, and data-centric curriculum learning techniques, which can significantly reduce the computational complexity of the data samples; (2) “model-centric,” including acceleration of basic modules, compression training, model initialization, and model-centric curriculum learning techniques, which focus on accelerating the training via reducing the calculations on parameters and providing better initialization; (3) “optimization-centric,” including the selection of learning rate, the employment of large batch size, the designs of efficient objectives, and model average techniques, which pay attention to the training policy and improving the generality for the large-scale models; (4) “budgeted training,” including some distinctive acceleration methods on source-constrained situations, e.g., for limitation on the total iterations; and (5) “system-centric,” including some efficient distributed frameworks and open source libraries that provide adequate hardware support for the implementation of the above-mentioned acceleration algorithms. By presenting this comprehensive taxonomy, our survey presents a comprehensive review to understand the general mechanisms within each component and their joint interaction. Meanwhile, we further provide a detailed analysis and discussion of future works on the development of general acceleration techniques, which could inspire us to re-think and design novel efficient paradigms. Overall, we hope that this survey will serve as a valuable guideline for general efficient training.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700439},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {On efficient training of large-scale deep learning models},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic literature review on multi-robot task
allocation. <em>CSUR</em>, <em>57</em>(3), 1–28. (<a
href="https://doi.org/10.1145/3700591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Muti-Robot system is gaining attention and is one of the critical areas of research when it comes to robotics. Coordination among multiple robots and how different tasks are allocated to different system agents are being studied. The objective of this Systematic Literature Review (SLR) is to provide insights on the recent advancement in Multi-Robot Task Allocation (MRTA) problems emphasizing promising approaches for task allocation. In this study, we collected scientific papers from five different databases for MRTA. We outline the different approaches for task allocation algorithms, classifying them according to the methods, and emphasizing recent advances. In addition, we discuss the function of uncertainty in task allocation and typical coordination techniques utilized in task allocation to identify gaps in the literature and suggest the most promising ones.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700591},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-28},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on multi-robot task allocation},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single-document abstractive text summarization: A systematic
literature review. <em>CSUR</em>, <em>57</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3700639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstractive text summarization is a task in natural language processing that automatically generates the summary from the source document in a human-written form with minimal loss of information. Research in text summarization has shifted towards abstractive text summarization due to its challenging aspects. This study provides a broad systematic literature review of abstractive text summarization on single-document summarization to gain insights into the challenges, widely used datasets, evaluation metrics, approaches, and methods. This study reviews research articles published between 2011 and 2023 from popular electronic databases. In total, 226 journal and conference publications were included in this review. The in-depth analysis of these papers helps researchers understand the challenges, widely used datasets, evaluation metrics, approaches, and methods. This article identifies and discusses potential opportunities and directions along with a generic conceptual framework and guidelines on abstractive summarization models and techniques for research in abstractive text summarization.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700639},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Single-document abstractive text summarization: A systematic literature review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security and reliability of internet of underwater things:
Architecture, challenges, and opportunities. <em>CSUR</em>,
<em>57</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3700640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Underwater Things (IoUT) pertains to a system that utilizes technology of Internet of Things (IoT) for data collection, communication, and control in the underwater environment. The monitoring and management of various parameters in the underwater domain are gathered through the deployment of underwater sensors, communication devices, and controllers. It is crucial in emerging ocean engineering. However, due to the instability of the underwater environment and the particularity of the underwater communication transmission medium, it is vulnerable to security threats, which may damage the system or cause data errors. In this survey, we will discuss the challenges, solutions, and future directions of IoUT from security and reliability, respectively. To ensure the normal operation of IoUT, we analyze the underwater security problems and solutions of the IoUT. Then, we discuss the reliability issue and improved strategies of IoUT system in detail. Finally, we come up with our views about the theories, challenges, and future prospects of IoUT security after the comparative analysis.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700640},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security and reliability of internet of underwater things: Architecture, challenges, and opportunities},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review on blockchain technology, current challenges, and
AI-driven solutions. <em>CSUR</em>, <em>57</em>(3), 1–39. (<a
href="https://doi.org/10.1145/3700641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain provides several advantages, including decentralization, data integrity, traceability, and immutability. However, despite its advantages, blockchain suffers from significant limitations, including scalability, resource greediness, governance complexity, and some security related issues. These limitations prevent its adoption in mainstream applications. Artificial Intelligence (AI) can help addressing some of these limitations. This survey provides a detailed overview of the different blockchain AI-based optimization and improvement approaches, tools and methodologies proposed to meet the needs of existing systems and applications with their benefits and drawbacks. Afterward, the focus is on suggesting AI-based directions where to address some of the fundamental limitations of blockchain.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700641},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review on blockchain technology, current challenges, and AI-driven solutions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modality deep-learning frameworks for fake news detection on
social networks: A systematic literature review. <em>CSUR</em>,
<em>57</em>(3), 1–50. (<a
href="https://doi.org/10.1145/3700748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news on social networks is a challenging problem due to the rapid dissemination and volume of information, as well as the ease of creating and sharing content anonymously. Fake news stories are problematic not only for the credibility of online journalism, but also due to their detrimental real-world consequences. The primary research objective of this study is to identify recent state-of-the-art deep learning methods used to detect fake news in social networks. This article presents a systematic literature review of deep learning-based fake news detection models in social networks. The methodology followed a rigorous approach, including predefined criteria for study selection of deep learning modalities. This study focuses on the types of deep learning modalities: unimodal (refers to the use of a single model for analysis or modeling purposes) and multimodal models (refers to the integration of multiple models). The results of this review reveal the strengths and weaknesses of modalities approaches, as well as the limitations of low-resource languages datasets. Furthermore, it provides insights into future directions for deep learning models and different fact-checking techniques. At the end of this study, we discuss the problem of fake news detection in the era of large language models in terms of advantages, drawbacks, and challenges.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700748},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-50},
  shortjournal = {ACM Comput. Surv.},
  title        = {Modality deep-learning frameworks for fake news detection on social networks: A systematic literature review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on advanced persistent threat detection: A unified
framework, challenges, and countermeasures. <em>CSUR</em>,
<em>57</em>(3), 1–36. (<a
href="https://doi.org/10.1145/3700749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, frequent Advanced Persistent Threat (APT) attacks have caused disastrous damage to critical facilities, leading to severe information leakages, economic losses, and even social disruptions. Via sophisticated, long-term, and stealthy network intrusions, APT attacks are often beyond the capabilities of traditional intrusion detection methods. Existing methods employ various techniques to enhance APT detection at different stages, but this makes it difficult to fairly and objectively evaluate the capability, value, and orthogonality of available techniques. Overly focusing on hardening specific APT detection stages cannot address some essential challenges from a global perspective, which would result in severe consequences. To holistically tackle this problem and explore effective solutions, we abstract a unified framework that covers the complete process of APT attack detection, with standardized summaries of state-of-the-art solutions and analysis of feasible techniques. Further, we provide an in-depth discussion of the challenges and countermeasures faced by each component of the detection framework. In addition, we comparatively analyze public datasets and outline the capability criteria to provide a reference for standardized evaluations. Finally, we discuss insights into potential areas for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700749},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on advanced persistent threat detection: A unified framework, challenges, and countermeasures},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic mapping study on quantum and quantum-inspired
algorithms in operations research. <em>CSUR</em>, <em>57</em>(3), 1–35.
(<a href="https://doi.org/10.1145/3700874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum and quantum-inspired algorithms have not yet been systematically classified in the context of potential Operations Research (OR) applications. Our systematic mapping is designed for quick consultation and shows which algorithms have been significantly explored in the context of OR, as well as which algorithms have been vaguely addressed in the same context. The study provides rapid access to OR professionals, both practitioners and researchers, who are interested in applying and/or further developing these algorithms in their respective contexts. We prepared a replicable protocol as a backbone of this systematic mapping study, specifying research questions, establishing effective search and selection methods, defining quality metrics for assessment, and guiding the analysis of the selected studies. A total of more than 2,000 studies were found, of which 149 were analyzed in detail. Readers can have an interactive hands-on experience with the collected data on an open-source repository with a website. An international standard was used as part of our classification, enabling professionals and researchers from across the world to readily identify which algorithms have been applied in any industry sector. Our effort also culminated in a rich set of takeaways that can help the reader identify potential paths for future work.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700874},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic mapping study on quantum and quantum-inspired algorithms in operations research},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cold start latency in serverless computing: A systematic
review, taxonomy, and future directions. <em>CSUR</em>, <em>57</em>(3),
1–36. (<a href="https://doi.org/10.1145/3700875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, academics and the corporate sector have paid attention to serverless computing, which enables dynamic scalability and an economic model. In serverless computing, users only pay for the time they actually use resources, enabling zero scaling to optimise cost and resource utilisation. However, this approach also introduces the serverless cold start problem. Researchers have developed various solutions to address the cold start problem, yet it remains an unresolved research area. In this article, we propose a systematic literature review on cold start latency in serverless computing. Furthermore, we create a detailed taxonomy of approaches to cold start latency, which we use to investigate existing techniques for reducing the cold start time and frequency. We have classified the current studies on cold start latency into several categories such as caching and application-level optimisation-based solutions, as well as Artificial Intelligence/Machine Learning-based solutions. Moreover, we have analyzed the impact of cold start latency on quality of service, explored current cold start latency mitigation methods, datasets, and implementation platforms, and classified them into categories based on their common characteristics and features. Finally, we outline the open challenges and highlight the possible future directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700875},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Cold start latency in serverless computing: A systematic review, taxonomy, and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Backdoor attacks against voice recognition systems: A
survey. <em>CSUR</em>, <em>57</em>(3), 1–35. (<a
href="https://doi.org/10.1145/3701985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voice Recognition Systems (VRSs) employ deep learning for speech recognition and speaker recognition. They have been widely deployed in various real-world applications, from intelligent voice assistance to telephony surveillance and biometric authentication. However, prior research has revealed the vulnerability of VRSs to backdoor attacks, which pose a significant threat to the security and privacy of VRSs. Unfortunately, existing literature lacks a thorough review on this topic. This paper fills this research gap by conducting a comprehensive survey on backdoor attacks against VRSs. We first present an overview of VRSs and backdoor attacks, elucidating their basic knowledge. Then we propose a set of evaluation criteria to assess the performance of backdoor attack methods. Next, we present a comprehensive taxonomy of backdoor attacks against VRSs from different perspectives and analyze the characteristic of different categories. After that, we comprehensively review existing attack methods and analyze their pros and cons based on the proposed criteria. Furthermore, we review classic backdoor defense methods and generic audio defense techniques. Then we discuss the feasibility of deploying them on VRSs. Finally, we figure out several open issues and further suggest future research directions to motivate the research of VRSs security.},
  archive      = {J_CSUR},
  doi          = {10.1145/3701985},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Backdoor attacks against voice recognition systems: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey on adversarial attack and defense for medical image
analysis: Methods and challenges. <em>CSUR</em>, <em>57</em>(3), 1–38.
(<a href="https://doi.org/10.1145/3702638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning techniques have achieved superior performance in computer-aided medical image analysis, yet they are still vulnerable to imperceptible adversarial attacks, resulting in potential misdiagnosis in clinical practice. Oppositely, recent years have also witnessed remarkable progress in defense against these tailored adversarial examples in deep medical diagnosis systems. In this exposition, we present a comprehensive survey on recent advances in adversarial attacks and defenses for medical image analysis with a systematic taxonomy in terms of the application scenario. We also provide a unified framework for different types of adversarial attack and defense methods in the context of medical image analysis. For a fair comparison, we establish a new benchmark for adversarially robust medical diagnosis models obtained by adversarial training under various scenarios. To the best of our knowledge, this is the first survey article that provides a thorough evaluation of adversarially robust medical diagnosis models. By analyzing qualitative and quantitative results, we conclude this survey with a detailed discussion of current challenges for adversarial attack and defense in medical image analysis systems to shed light on future research directions. Code is available on GitHub .},
  archive      = {J_CSUR},
  doi          = {10.1145/3702638},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on adversarial attack and defense for medical image analysis: Methods and challenges},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on security of UAV swarm networks: Attacks and
countermeasures. <em>CSUR</em>, <em>57</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3703625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing popularity of Unmanned Aerial Vehicle (UAV) swarms is attributed to their ability to generate substantial returns for various industries at a low cost. Additionally, in the future landscape of wireless networks, UAV swarms can serve as airborne base stations, alleviating the scarcity of communication resources. However, UAV swarm networks are vulnerable to various security threats that attackers can exploit with unpredictable consequences. Against this background, this article provides a comprehensive review on security of UAV swarm networks. We begin by briefly introducing the dominant UAV swarm technologies, followed by their civilian and military applications. We then present and categorize various potential attacks that UAV swarm networks may encounter, such as denial-of-service attacks, man-in-the-middle attacks, and attacks against Machine Learning (ML) models. After that, we introduce security technologies that can be utilized to address these attacks, including cryptography, physical layer security techniques, blockchain, ML, and intrusion detection. Additionally, we investigate and summarize mitigation strategies addressing different security threats in UAV swarm networks. Finally, some research directions and challenges are discussed.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703625},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on security of UAV swarm networks: Attacks and countermeasures},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancements in federated learning: Models, methods, and
privacy. <em>CSUR</em>, <em>57</em>(2), 1–39. (<a
href="https://doi.org/10.1145/3664650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a promising technique for resolving the rising privacy and security concerns. Its main ingredient is to cooperatively learn the model among the distributed clients without uploading any sensitive data. In this article, we conducted a thorough review of the related works, following the development context and deeply mining the key technologies behind FL from the perspectives of theory and application. Specifically, we first classify the existing works in FL architecture based on the network topology of FL systems with detailed analysis and summarization. Next, we abstract the current application problems, summarize the general techniques, and frame the application problems into the general paradigm of FL base models. Moreover, we provide our proposed solutions for model training via FL. We have summarized and analyzed the existing FedOpt algorithms, and deeply revealed the algorithmic development principles of many first-order algorithms in depth, proposing a more generalized algorithm design framework. With the instantiation of these frameworks, FedOpt algorithms can be simply developed. As privacy and security are the fundamental requirements in FL, we provide the existing attack scenarios and the defense methods. To the best of our knowledge, we are among the first tier to review the theoretical methodology and propose our strategies since there are very few works surveying the theoretical approaches. Our survey targets motivating the development of high-performance, privacy-preserving, and secure methods to integrate FL into real-world applications.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664650},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Advancements in federated learning: Models, methods, and privacy},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A practical tutorial on explainable AI techniques.
<em>CSUR</em>, <em>57</em>(2), 1–44. (<a
href="https://doi.org/10.1145/3670685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past years have been characterized by an upsurge in opaque automatic decision support systems, such as Deep Neural Networks (DNNs). Although DNNs have great generalization and prediction abilities, it is difficult to obtain detailed explanations for their behavior. As opaque Machine Learning models are increasingly being employed to make important predictions in critical domains, there is a danger of creating and using decisions that are not justifiable or legitimate. Therefore, there is a general agreement on the importance of endowing DNNs with explainability. EXplainable Artificial Intelligence (XAI) techniques can serve to verify and certify model outputs and enhance them with desirable notions such as trustworthiness, accountability, transparency, and fairness. This guide is intended to be the go-to handbook for anyone with a computer science background aiming to obtain an intuitive insight from Machine Learning models accompanied by explanations out-of-the-box. The article aims to rectify the lack of a practical XAI guide by applying XAI techniques, in particular, day-to-day models, datasets and use-cases. In each chapter, the reader will find a description of the proposed method as well as one or several examples of use with Python notebooks. These can be easily modified to be applied to specific applications. We also explain what the prerequisites are for using each technique, what the user will learn about them, and which tasks they are aimed at.},
  archive      = {J_CSUR},
  doi          = {10.1145/3670685},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-44},
  shortjournal = {ACM Comput. Surv.},
  title        = {A practical tutorial on explainable AI techniques},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of text watermarking in the era of large language
models. <em>CSUR</em>, <em>57</em>(2), 1–36. (<a
href="https://doi.org/10.1145/3691626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text watermarking algorithms are crucial for protecting the copyright of textual content. Historically, their capabilities and application scenarios were limited. However, recent advancements in large language models (LLMs) have revolutionized these techniques. LLMs not only enhance text watermarking algorithms with their advanced abilities but also create a need for employing these algorithms to protect their own copyrights or prevent potential misuse. This work conducts a comprehensive survey of the current state of text watermarking technology, covering four main aspects: (1) an overview and comparison of different text watermarking techniques; (2) evaluation methods for text watermarking algorithms, including their detectability, impact on text or LLM quality, and robustness under target or untargeted attacks; (3) potential application scenarios for text watermarking technology; and (4) current challenges and future directions for text watermarking. This survey aims to provide researchers with a thorough understanding of text watermarking technology in the era of LLMs, thereby promoting its further advancement.},
  archive      = {J_CSUR},
  doi          = {10.1145/3691626},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of text watermarking in the era of large language models},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approaches to conflict-free replicated data types.
<em>CSUR</em>, <em>57</em>(2), 1–36. (<a
href="https://doi.org/10.1145/3695249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conflict-free Replicated Data Types (CRDTs) allow optimistic replication in a principled way. Different replicas can proceed independently, being available even under network partitions and always converging deterministically: Replicas that have received the same updates will have equivalent state, even if received in different orders. After a historical tour of the evolution from sequential data types to CRDTs, we present in detail the two main approaches to CRDTs, operation-based and state-based, including two important variations, the pure operation-based and the delta-state based. Intended for prospective CRDT researchers and designers, this article provides solid coverage of the essential concepts, clarifying some misconceptions that frequently occur, but also presents some novel insights gained from considerable experience in designing both specific CRDTs and approaches to CRDTs.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695249},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Approaches to conflict-free replicated data types},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Alert prioritisation in security operations centres: A
systematic survey on criteria and methods. <em>CSUR</em>,
<em>57</em>(2), 1–36. (<a
href="https://doi.org/10.1145/3695462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security Operations Centres (SOCs) are specialised facilities where security analysts leverage advanced technologies to monitor, detect and respond to cyber incidents. However, the increasing volume of security incidents has overwhelmed security analysts, leading to alert fatigue. Effective alert prioritisation (AP) becomes crucial to address this problem through the utilisation of proper criteria and methods. Human–AI teaming (HAT) has the potential to significantly enhance AP by combining the complementary strengths of humans and AI. AI excels in processing large volumes of alert data, identifying anomalies, uncovering hidden patterns, and prioritising alerts at scale, all at machine speed. Human analysts can leverage their expertise to investigate prioritised alerts, re-prioritise them based on additional context and provide valuable feedback to the AI system, reducing false positives and ensuring critical alerts are prioritised. This work provides a comprehensive review of the criteria and methods for AP in SOC. We analyse the advantages and disadvantages of the different categories of AP criteria and methods based on HAT, specifically considering automation, augmentation and collaboration. We also identify several areas for future research. We anticipate that our findings will contribute to the advancement of AP techniques, fostering more effective security incident response in SOCs.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695462},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Alert prioritisation in security operations centres: A systematic survey on criteria and methods},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causal representation learning through higher-level
information extraction. <em>CSUR</em>, <em>57</em>(2), 1–37. (<a
href="https://doi.org/10.1145/3696412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large gap between the generalization level of state-of-the-art machine learning and human learning systems calls for the development of artificial intelligence (AI) models that are truly inspired by human cognition. In tasks related to image analysis, searching for pixel-level regularities has reached a power of information extraction still far from what humans capture with image-based observations. This leads to poor generalization when even small shifts occur at the level of the observations. We explore a perspective on this problem that is directed to learning the generative process with causality-related foundations, using models capable of combining symbolic manipulation, probabilistic reasoning, and pattern recognition abilities. We briefly review and explore connections of research from machine learning, cognitive science, and related fields of human behavior to support our perspective for the direction to more robust and human-like artificial learning systems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696412},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Causal representation learning through higher-level information extraction},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph and sequential neural networks in session-based
recommendation: A survey. <em>CSUR</em>, <em>57</em>(2), 1–37. (<a
href="https://doi.org/10.1145/3696413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the remarkable success of recommendation systems (RSs) in alleviating the information overload problem. As a new paradigm of RSs, session-based recommendation (SR) specializes in users’ short-term preferences and aims at providing a more dynamic and timely recommendation based on ongoing interactions. This survey presents a comprehensive overview of the recent works on SR. First, we clarify the key definitions within SR and compare the characteristics of SR against other recommendation tasks. Then, we summarize the existing methods in two categories: sequential neural network based methods and graph neural network (GNN) based methods. The relevant frameworks and technical details are further introduced. Finally, we discuss the challenges of SR and new research directions in this area.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696413},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Graph and sequential neural networks in session-based recommendation: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on video diffusion models. <em>CSUR</em>,
<em>57</em>(2), 1–42. (<a
href="https://doi.org/10.1145/3696415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent wave of AI-generated content (AIGC) has witnessed substantial success in computer vision, with the diffusion model playing a crucial role in this achievement. Due to their impressive generative capabilities, diffusion models are gradually superseding methods based on GANs and auto-regressive Transformers, demonstrating exceptional performance not only in image generation and editing, but also in the realm of video-related research. However, existing surveys mainly focus on diffusion models in the context of image generation, with few up-to-date reviews on their application in the video domain. To address this gap, this article presents a comprehensive review of video diffusion models in the AIGC era. Specifically, we begin with a concise introduction to the fundamentals and evolution of diffusion models. Subsequently, we present an overview of research on diffusion models in the video domain, categorizing the work into three key areas: video generation, video editing, and other video understanding tasks. We conduct a thorough review of the literature in these three key areas, including further categorization and practical contributions in the field. Finally, we discuss the challenges faced by research in this domain and outline potential future developmental trends. A comprehensive list of video diffusion models studied in this survey is available at https://github.com/ChenHsing/Awesome-Video-Diffusion-Models .},
  archive      = {J_CSUR},
  doi          = {10.1145/3696415},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on video diffusion models},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Challenges and opportunities in mobile network security for
vertical applications: A survey. <em>CSUR</em>, <em>57</em>(2), 1–36.
(<a href="https://doi.org/10.1145/3696446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the security of vertical applications in fifth-generation (5G) mobile communication systems and previous generations is crucial. These systems must prioritize maintaining the confidentiality, integrity, and availability of services and data. Examples of vertical applications include smart cities, smart transportation, public services, Industry 4.0, smart grids, smart health, and smart agriculture. Each vertical application has specific security requirements and faces unique threats within the mobile network environment. Thus, it is essential to implement comprehensive and robust security measures. This approach helps minimize the attack surface and effectively manage risks. This survey thoroughly examines mobile networks and their security challenges in vertical applications, shedding light on associated threats and potential solutions. Our study considers the interplay between security considerations in 5G, legacy networks, and vertical applications. We emphasize the challenges, opportunities, and promising directions for future research in this field and the importance of securing vertical applications in the evolving landscape of mobile technology.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696446},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Challenges and opportunities in mobile network security for vertical applications: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review of privacy policy literature.
<em>CSUR</em>, <em>57</em>(2), 1–43. (<a
href="https://doi.org/10.1145/3698393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An organization’s privacy policy states how it collects, stores, processes, and shares its users’ personal information. The growing number of data protection laws and regulations, as well as the numerous sectors where the organizations are collecting user information, has led to the investigation of privacy policies with regards to their accessibility, readability, completeness, comparison with organization’s actual data practices, use of machine learning/natural language processing for automated analysis, and comprehension/perception/concerns of end-users via summarization/visualization tools and user studies. However, there is limited work on systematically reviewing the existing research on this topic. We address this gap by conducting a systematic review of the existing privacy policy literature. To this end, we compiled and analyzed 202 papers (published till 31st December, 2023) that investigated privacy policies. Our work advances the field of privacy policies by summarizing the analysis techniques that have been used to study them, the data protection laws/regulations explored, and the sectors to which these policies pertain. We provide actionable insights for organizations to achieve better end-user privacy.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698393},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-43},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic review of privacy policy literature},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Empowering agrifood system with artificial intelligence: A
survey of the progress, challenges and opportunities. <em>CSUR</em>,
<em>57</em>(2), 1–37. (<a
href="https://doi.org/10.1145/3698589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the world population rapidly increasing, transforming our agrifood systems to be more productive, efficient, safe, and sustainable is crucial to mitigate potential food shortages. Recently, artificial intelligence (AI) techniques such as deep learning (DL) have demonstrated their strong abilities in various areas, including language, vision, remote sensing (RS), and agrifood systems applications. However, the overall impact of AI on agrifood systems remains unclear. In this article, we thoroughly review how AI techniques can transform agrifood systems and contribute to the modern agrifood industry. First, we summarize the data acquisition methods in agrifood systems, including acquisition, storage, and processing techniques. Second, we present a progress review of AI methods in agrifood systems, specifically in agriculture, animal husbandry, and fishery, covering topics such as agrifood classification, growth monitoring, yield prediction, and quality assessment. Furthermore, we highlight potential challenges and promising research opportunities for transforming modern agrifood systems with AI. We hope this survey can offer an overall picture to newcomers in the field and serve as a starting point for their further research. The project website is https://github.com/Frenkie14/Agrifood-Survey.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698589},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Empowering agrifood system with artificial intelligence: A survey of the progress, challenges and opportunities},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Co-clustering: A survey of the main methods, recent trends,
and open problems. <em>CSUR</em>, <em>57</em>(2), 1–33. (<a
href="https://doi.org/10.1145/3698875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since its early formulations, co-clustering has gained popularity and interest both within and outside the machine learning community as a powerful learning paradigm for clustering high-dimensional data with good explainability properties. The simultaneous partitioning of all the modes of the input data tensors (rows and columns in a data matrix) is both a method for improving clustering on one mode while performing dimensionality reduction on the other mode(s), and a tool for providing an actionable interpretation of the clusters in the main mode as summaries of the features in each other mode(s). Hence, it is useful in many complex decision systems and data science applications. In this article, we survey the the co-clustering literature by reviewing the main co-clustering methods, with a special focus on the work done in the past 25 years. We identify, describe, and compare the main algorithmic categories and provide a practical characterization with respect to similar unsupervised techniques. Additionally, we try to explain why it is still a powerful tool despite the apparent recent decreasing interest shown by the machine learning community. To this purpose, we review the most recent trends in co-clustering research and outline the open problems and promising future research perspectives.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698875},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Co-clustering: A survey of the main methods, recent trends, and open problems},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A partial offline payment system for connecting the
unconnected using internet of things: A survey. <em>CSUR</em>,
<em>57</em>(2), 1–35. (<a
href="https://doi.org/10.1145/3687132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digital revolution in finance has bypassed many in rural areas due to limited access to technology and infrastructure. While real-time Internet banking is not feasible, a new approach is needed to create a secure, low-cost banking ecosystem for these unconnected populations. Existing offline payment mechanisms, prevalent in countries like India, offer some solutions but may still be expensive for rural communities. Researchers are exploring cost-effective solutions based on the Internet of Things (IoT). This study explores various IoT and non-IoT-based offline digital banking solutions to identify potential ways to provide digital payment options for the unconnected rural population.},
  archive      = {J_CSUR},
  doi          = {10.1145/3687132},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A partial offline payment system for connecting the unconnected using internet of things: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on deep learning for design and generation of
virtual architecture. <em>CSUR</em>, <em>57</em>(2), 1–41. (<a
href="https://doi.org/10.1145/3688569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) shape generation techniques leveraging deep learning have garnered significant interest from both computer vision and architectural design communities, promising to enrich the content in the virtual environment. However, research on virtual architectural design remains limited, particularly regarding designer-AI collaboration and deep learning-assisted design. In our survey, we reviewed 149 related articles (81.2% of articles published between 2019 and 2023) covering architectural design, 3D shape techniques, and virtual environments. Through scrutinizing the literature, we first identify the principles of virtual architecture and illuminate its current production challenges, including datasets, multimodality, design intuition, and generative frameworks. We then introduce the latest approaches to designing and generating virtual buildings leveraging 3D shape generation and summarize four characteristics of various approaches to virtual architecture. Based on our analysis, we expound on four research agendas, including agency, communication, user consideration, and integrating tools. Additionally, we highlight four important enablers of ubiquitous interaction with immersive systems in deep learning-assisted architectural generation. Our work contributes to fostering understanding between designers and deep learning techniques, broadening access to designer-AI collaboration. We advocate for interdisciplinary efforts to address this timely research topic, facilitating content designing and generation in the virtual environment.},
  archive      = {J_CSUR},
  doi          = {10.1145/3688569},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on deep learning for design and generation of virtual architecture},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image steganography approaches and their detection
strategies: A survey. <em>CSUR</em>, <em>57</em>(2), 1–40. (<a
href="https://doi.org/10.1145/3694965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steganography is the art and science of hidden (or covered) communication. In digital steganography, the bits of image, video, audio and text files are tweaked to represent the information to hide. This article covers the current methods for hiding information in images, alongside steganalysis methods that aim to detect the presence of steganography. By reviewing 456 references, this article discusses the different approaches that can be taken toward steganography and its much less widely studied counterpart. Currently in research older steganography approaches are more widely used than newer methods even though these show greater potential. New methods do have flaws; therefore, more research is needed to make these practically applicable. For steganalysis one of the greatest challenges is the generalisability. Often one scheme can detect the presence of one specific hiding method. More research is needed to combine current schemes and/or create new generalisable schemes. To allow readers to compare results between different papers in our work, performance indications of all steganalysis methods are outlined and a comparison of performance is included. This comparison is given using ‘topological sorting’ graphs, which compares detection results from all papers (as stated in the papers themselves) on different steganographic schemes.},
  archive      = {J_CSUR},
  doi          = {10.1145/3694965},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Image steganography approaches and their detection strategies: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of distributed graph algorithms on massive graphs.
<em>CSUR</em>, <em>57</em>(2), 1–39. (<a
href="https://doi.org/10.1145/3694966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed processing of large-scale graph data has many practical applications and has been widely studied. In recent years, a lot of distributed graph processing frameworks and algorithms have been proposed. While many efforts have been devoted to analyzing these, with most analyzing them based on programming models, less research focuses on understanding their challenges in distributed environments. Applying graph tasks to distributed environments is not easy, often facing numerous challenges through our analysis, including parallelism, load balancing, communication overhead, and bandwidth. In this article, we provide an extensive overview of the current state-of-the-art in this field by outlining the challenges and solutions of distributed graph algorithms. We first conduct a systematic analysis of the inherent challenges in distributed graph processing, followed by presenting an overview of existing general solutions. Subsequently, we survey the challenges highlighted in recent distributed graph processing papers and the strategies adopted to address them. Finally, we discuss the current research trends and identify potential future opportunities.},
  archive      = {J_CSUR},
  doi          = {10.1145/3694966},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of distributed graph algorithms on massive graphs},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time-sensitive networking (TSN) for industrial automation:
Current advances and future directions. <em>CSUR</em>, <em>57</em>(2),
1–38. (<a href="https://doi.org/10.1145/3695248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the introduction of Cyber-Physical Systems (CPS) and Internet of Things (IoT) technologies, the automation industry is undergoing significant changes, particularly in improving production efficiency and reducing maintenance costs. Industrial automation applications often need to transmit time- and safety-critical data to closely monitor and control industrial processes. Several Ethernet-based fieldbus solutions, such as PROFINET IRT, EtherNet/IP, and EtherCAT, are widely used to ensure real-time communications in industrial automation systems. These solutions, however, commonly incorporate additional mechanisms to provide latency guarantees, making their interoperability a grand challenge. The IEEE 802.1 Time-Sensitive Networking (TSN) task group was formed to enhance and optimize IEEE 802.1 network standards, particularly for Ethernet-based networks. These solutions can be evolved and adapted for cross-industry scenarios, such as large-scale distributed industrial plants requiring multiple industrial entities to work collaboratively. This paper provides a comprehensive review of current advances in TSN standards for industrial automation. It presents the state-of-the-art IEEE TSN standards and discusses the opportunities and challenges of integrating TSN into the automation industry. Some promising research directions are also highlighted for applying TSN technologies to industrial automation applications.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695248},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Time-sensitive networking (TSN) for industrial automation: Current advances and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal recommender systems: A survey. <em>CSUR</em>,
<em>57</em>(2), 1–17. (<a
href="https://doi.org/10.1145/3695461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recommender system (RS) has been an integral toolkit of online services. They are equipped with various deep learning techniques to model user preference based on identifier and attribute information. With the emergence of multimedia services, such as short videos, news, and and so on, understanding these contents while recommending becomes critical. Besides, multimodal features are also helpful in alleviating the problem of data sparsity in RS. Thus, M ultimodal R ecommender S ystem (MRS) has attracted much attention from both academia and industry recently. In this article, we will give a comprehensive survey of the MRS models, mainly from technical views. First, we conclude the general procedures and major challenges for MRS. Then, we introduce the existing MRS models according to four categories, i.e., Modality Encoder , Feature Interaction , Feature Enhancement , and Model Optimization . Besides, to make it convenient for those who want to research this field, we also summarize the dataset and code resources. Finally, we discuss some promising future directions of MRS and conclude this article. To access more details of the surveyed articles, such as implementation code, we open source a repository. 1},
  archive      = {J_CSUR},
  doi          = {10.1145/3695461},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-17},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multimodal recommender systems: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State of the art and potentialities of graph-level learning.
<em>CSUR</em>, <em>57</em>(2), 1–40. (<a
href="https://doi.org/10.1145/3695863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs have a superior ability to represent relational data, such as chemical compounds, proteins, and social networks. Hence, graph-level learning, which takes a set of graphs as input, has been applied to many tasks, including comparison, regression, classification, and more. Traditional approaches to learning a set of graphs heavily rely on hand-crafted features, such as substructures. While these methods benefit from good interpretability, they often suffer from computational bottlenecks, as they cannot skirt the graph isomorphism problem. Conversely, deep learning has helped graph-level learning adapt to the growing scale of graphs by extracting features automatically and encoding graphs into low-dimensional representations. As a result, these deep graph learning methods have been responsible for many successes. Yet, no comprehensive survey reviews graph-level learning starting with traditional learning and moving through to the deep learning approaches. This article fills this gap and frames the representative algorithms into a systematic taxonomy covering traditional learning, graph-level deep neural networks, graph-level graph neural networks, and graph pooling. In addition, the evolution and interaction between methods from these four branches within their developments are examined to provide an in-depth analysis. This is followed by a brief review of the benchmark datasets, evaluation metrics, and common downstream applications. Finally, the survey concludes with an in-depth discussion of 12 current and future directions in this booming field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695863},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {State of the art and potentialities of graph-level learning},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey on quality assurance of smart contracts.
<em>CSUR</em>, <em>57</em>(2), 1–36. (<a
href="https://doi.org/10.1145/3695864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As blockchain technology continues to advance, the secure deployment of smart contracts has become increasingly prevalent, underscoring the critical need for robust security measures. This surge in usage has led to a rise in security breaches, often resulting in substantial financial losses for users. This article presents a comprehensive survey of smart contract quality assurance, from understanding vulnerabilities to evaluating the effectiveness of detection tools. Our work is notable for its innovative classification of 40 smart contract vulnerabilities, mapping them to established attack patterns. We further examine nine defense mechanisms, assessing their efficacy in mitigating smart contract attacks. Furthermore, we develop a labeled dataset as a benchmark encompassing 10 common vulnerability types, which serves as a critical resource for future research. We also conduct comprehensive experiments to evaluate 14 vulnerability detection tools, providing a comparative analysis that highlights their strengths and limitations. In summary, this survey synthesizes state-of-the-art knowledge in smart contract security, offering practical recommendations to guide future research and foster the development of robust security practices in the field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695864},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on quality assurance of smart contracts},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of mix-based data augmentation: Taxonomy, methods,
applications, and explainability. <em>CSUR</em>, <em>57</em>(2), 1–38.
(<a href="https://doi.org/10.1145/3696206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation (DA) is indispensable in modern machine learning and deep neural networks. The basic idea of DA is to construct new training data to improve the model’s generalization by adding slightly disturbed versions of existing data or synthesizing new data. This survey comprehensively reviews a crucial subset of DA techniques, namely Mix-based Data Augmentation (MixDA), which generates novel samples by combining multiple examples. In contrast to traditional DA approaches that operate on single samples or entire datasets, MixDA stands out due to its effectiveness, simplicity, computational efficiency, theoretical foundation, and broad applicability. We begin by introducing a novel taxonomy that categorizes MixDA into Mixup-based, Cutmix-based, and mixture approaches based on a hierarchical perspective of the data mixing operation. Subsequently, we provide an in-depth review of various MixDA techniques, focusing on their underlying motivations. Owing to its versatility, MixDA has penetrated a wide range of applications, which we also thoroughly investigate in this survey. Moreover, we delve into the underlying mechanisms of MixDA’s effectiveness by examining its impact on model generalization and calibration while providing insights into the model’s behavior by analyzing the inherent properties of MixDA. Finally, we recapitulate the critical findings and fundamental challenges of current MixDA studies while outlining the potential directions for future works. Different from previous related surveys that focus on DA approaches in specific domains (e.g., computer vision and natural language processing) or only review a limited subset of MixDA studies, we are the first to provide a systematical survey of MixDA, covering its taxonomy, methodology, application, and explainability. Furthermore, we provide promising directions for researchers interested in this exciting area.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696206},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of mix-based data augmentation: Taxonomy, methods, applications, and explainability},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning for actionable warning identification: A
comprehensive survey. <em>CSUR</em>, <em>57</em>(2), 1–35. (<a
href="https://doi.org/10.1145/3696352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Actionable Warning Identification (AWI) plays a crucial role in improving the usability of static code analyzers. With recent advances in Machine Learning (ML), various approaches have been proposed to incorporate ML techniques into AWI. These ML-based AWI approaches, benefiting from ML’s strong ability to learn subtle and previously unseen patterns from historical data, have demonstrated superior performance. However, a comprehensive overview of these approaches is missing, which could hinder researchers and practitioners from understanding the current process and discovering potential for future improvement in the ML-based AWI community. In this article, we systematically review the state-of-the-art ML-based AWI approaches. First, we employ a meticulous survey methodology and gather 51 primary studies from January 1, 2000 to January 9, 2023. Then, we outline a typical ML-based AWI workflow, including warning dataset preparation, preprocessing, AWI model construction, and evaluation stages. In such a workflow, we categorize ML-based AWI approaches based on the warning output format. In addition, we analyze the key techniques used in each stage, along with their strengths, weaknesses, and distribution. Finally, we provide practical research directions for future ML-based AWI approaches, focusing on aspects such as data improvement (e.g., enhancing the warning labeling strategy) and model exploration (e.g., exploring large language models for AWI).},
  archive      = {J_CSUR},
  doi          = {10.1145/3696352},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Machine learning for actionable warning identification: A comprehensive survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review on graph neural network-based methods
for stock market forecasting. <em>CSUR</em>, <em>57</em>(2), 1–38. (<a
href="https://doi.org/10.1145/3696411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial technology (FinTech) is a field that uses artificial intelligence to automate financial services. One area of FinTech is stock analysis, which aims to predict future stock prices to develop investment strategies that maximize profits. Traditional methods of stock market prediction, such as time series analysis and machine learning, struggle to handle the non-linear, chaotic, and sudden changes in stock data and may not consider the interdependence between stocks. Recently, graph neural networks (GNNs) have been used in stock market forecasting to improve prediction accuracy by incorporating the interconnectedness of the market. GNNs can process non-Euclidean data in the form of a knowledge graph. However, financial knowledge graphs can have dynamic and complex interactions, which can be challenging for graph modeling technologies. This work presents a systematic review of graph-based approaches for stock market forecasting. This review covers different types of stock analysis tasks (classification, regression, and stock recommendation), a generalized framework for solving these tasks, and a review of various features, datasets, graph models, and evaluation metrics used in the stock market. The results of various studies are analyzed, and future directions for research are highlighted.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696411},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic review on graph neural network-based methods for stock market forecasting},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolving paradigms in automated program repair: Taxonomy,
challenges, and opportunities. <em>CSUR</em>, <em>57</em>(2), 1–43. (<a
href="https://doi.org/10.1145/3696450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development and large-scale popularity of program software, modern society increasingly relies on software systems. However, the problems exposed by software have also come to the fore. The software bug has become an important factor troubling developers. In this context, Automated Program Repair (APR) techniques have emerged, aiming to automatically fix software bug problems and reduce manual debugging work. In particular, benefiting from the advances in deep learning, numerous learning-based APR techniques have emerged in recent years, which also bring new opportunities for APR research. To give researchers a quick overview of APR techniques’ complete development and future opportunities, we review the evolution of APR techniques and discuss in depth the latest advances in APR research. In this article, the development of APR techniques is introduced in terms of four different patch generation schemes: search-based, constraint-based, template-based, and learning-based. Moreover, we propose a uniform set of criteria to review and compare each APR tool and then discuss the current state of APR development. Finally, we analyze current challenges and future directions, especially highlighting the critical opportunities that large language models bring to APR research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696450},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-43},
  shortjournal = {ACM Comput. Surv.},
  title        = {Evolving paradigms in automated program repair: Taxonomy, challenges, and opportunities},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatio-temporal predictive modeling techniques for different
domains: A survey. <em>CSUR</em>, <em>57</em>(2), 1–42. (<a
href="https://doi.org/10.1145/3696661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal prediction tasks play a crucial role in facilitating informed decision-making through anticipatory insights. By accurately predicting future outcomes, the ability to strategize, preemptively address risks, and minimize their potential impact is enhanced. The precision in forecasting spatial and temporal patterns holds significant potential for optimizing resource allocation, land utilization, and infrastructure development. While existing review and survey papers predominantly focus on specific forecasting domains such as intelligent transportation, urban planning, pandemics, disease prediction, climate and weather forecasting, environmental data prediction, and agricultural yield projection, limited attention has been devoted to comprehensive surveys encompassing multiple objects concurrently. This article addresses this gap by comprehensively analyzing techniques employed in traffic, pandemics, disease forecasting, climate and weather prediction, agricultural yield estimation, and environmental data prediction. Furthermore, it elucidates challenges inherent in spatio-temporal forecasting and outlines potential avenues for future research exploration.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696661},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Spatio-temporal predictive modeling techniques for different domains: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of protocol fuzzing. <em>CSUR</em>, <em>57</em>(2),
1–36. (<a href="https://doi.org/10.1145/3696788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication protocols form the bedrock of our interconnected world, yet vulnerabilities within their implementations pose significant security threats. Recent developments have seen a surge in fuzzing-based research dedicated to uncovering these vulnerabilities within protocol implementations. However, there still lacks a systematic overview of protocol fuzzing for answering the essential questions such as what the unique challenges are, how existing works solve them, and so on. To bridge this gap, we conducted a comprehensive investigation of related works from both academia and industry. Our study includes a detailed summary of the specific challenges in protocol fuzzing and provides a systematic categorization and overview of existing research efforts. Furthermore, we explore and discuss potential future research directions in protocol fuzzing.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696788},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of protocol fuzzing},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of 3D space path-planning methods and algorithms.
<em>CSUR</em>, <em>57</em>(1), 1–32. (<a
href="https://doi.org/10.1145/3673896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their agility, cost-effectiveness, and high maneuverability, Unmanned Aerial Vehicles (UAVs) have attracted considerable attention from researchers and investors alike. Path planning is one of the practical subsets of motion planning for UAVs. It prevents collisions and ensures complete coverage of an area. This study provides a structured review of applicable algorithms and coverage path planning solutions in Three-Dimensional (3D) space, presenting state-of-the-art technologies related to heuristic decomposition approaches for UAVs and the forefront challenges. Additionally, it introduces a comprehensive and novel classification of practical methods and representational techniques for path-planning algorithms. This depends on environmental characteristics and optimal parameters in the real world. The first category presents a classification of semi-accurate decomposition approaches as the most practical decomposition method, along with the data structure of these practices, categorized by phases. The second category illustrates path-planning processes based on symbolic techniques in 3D space. Additionally, it provides a critical analysis of crucial influential approaches based on their importance in path quality and researchers’ attention, highlighting their limitations and research gaps. Furthermore, it will provide the most pertinent recommendations for future work for researchers. The studies demonstrate an apparent inclination among experimenters toward using the semi-accurate cellular decomposition approach to improve 3D path planning.},
  archive      = {J_CSUR},
  doi          = {10.1145/3673896},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of 3D space path-planning methods and algorithms},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Manipulating recommender systems: A survey of poisoning
attacks and countermeasures. <em>CSUR</em>, <em>57</em>(1), 1–39. (<a
href="https://doi.org/10.1145/3677328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have become an integral part of online services due to their ability to help users locate specific information in a sea of data. However, existing studies show that some recommender systems are vulnerable to poisoning attacks, particularly those that involve learning schemes. A poisoning attack is where an adversary injects carefully crafted data into the process of training a model with the goal of manipulating the system’s final recommendations. Based on recent advancements in artificial intelligence (AI), such attacks have gained importance recently. At present, we do not have a full and clear picture of why adversaries mount such attacks, nor do we have comprehensive knowledge of the full capacity to which such attacks can undermine a model or the impacts that might have. While numerous countermeasures to poisoning attacks have been developed, they have not yet been systematically linked to the properties of the attacks. Consequently, assessing the respective risks and potential success of mitigation strategies is difficult, if not impossible. This survey aims to fill this gap by primarily focusing on poisoning attacks and their countermeasures. This is in contrast to prior surveys that mainly focus on attacks and their detection methods. Through an exhaustive literature review, we provide a novel taxonomy for poisoning attacks, formalise its dimensions, and accordingly organise 31 attacks described in the literature. Further, we review 43 countermeasures to detect and/or prevent poisoning attacks, evaluating their effectiveness against specific types of attacks. This comprehensive survey should serve as a point of reference for protecting recommender systems against poisoning attacks. The article concludes with a discussion on open issues in the field and impactful directions for future research. A rich repository of resources associated with poisoning attacks is available at https://github.com/tamlhp/awesome-recsys-poisoning .},
  archive      = {J_CSUR},
  doi          = {10.1145/3677328},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Manipulating recommender systems: A survey of poisoning attacks and countermeasures},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enabling technologies and techniques for floor
identification. <em>CSUR</em>, <em>57</em>(1), 1–48. (<a
href="https://doi.org/10.1145/3678878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location information has initiated a multitude of applications such as location-based services, health care, emergency response and rescue operations, and assets tracking. A plethora of techniques and technologies have been presented to ensure enhanced location accuracy, both horizontal and vertical. Despite many surveys covering horizontal localization technologies, the literature lacks a comprehensive survey incorporating up-to-date vertical localization approaches. This article provides a detailed survey of different vertical localization techniques such as path loss models, time of arrival, received signal strength, reference signal received power, fingerprinting utilized by WiFi, radio-frequency identification (RFID), global system for mobile communications (GSM), long-term evolution (LTE), barometer, inertial measurement unit (IMU) sensors, and geomagnetic field. The article primarily aims at human localization in indoor environments using smartphones in essence. Besides the localization accuracy, the presented approaches are evaluated in terms of cost, infrastructure dependence, deployment complexity, and sensitivity. We highlight the pros and cons of these approaches and outline future research directions to enhance the accuracy to meet the future needs of floor identification standards set by the Federal Communications Commission.},
  archive      = {J_CSUR},
  doi          = {10.1145/3678878},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-48},
  shortjournal = {ACM Comput. Surv.},
  title        = {Enabling technologies and techniques for floor identification},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How to improve video analytics with action recognition: A
survey. <em>CSUR</em>, <em>57</em>(1), 1–36. (<a
href="https://doi.org/10.1145/3679011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition refers to the process of categorizing a video by identifying and classifying the specific actions it encompasses. Videos originate from several domains, and within each domain of video analysis, comprehending actions holds paramount significance. The primary aim of this research is to assist scholars in understanding, comparing, and using action recognition models within the several fields of video analysis. This article provides a comprehensive analysis of action recognition models, comparing their performance and computational requirements. Additionally, it presents a detailed overview of benchmark datasets, which can aid in selecting the most suitable action recognition model. This review additionally examines the diverse applications of action recognition, the datasets available, the research that has been undertaken, potential future prospects, and the challenges encountered.},
  archive      = {J_CSUR},
  doi          = {10.1145/3679011},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {How to improve video analytics with action recognition: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on federated unlearning: Challenges, methods, and
future directions. <em>CSUR</em>, <em>57</em>(1), 1–38. (<a
href="https://doi.org/10.1145/3679014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the notion of “the right to be forgotten” (RTBF) has become a crucial aspect of data privacy for digital trust and AI safety, requiring the provision of mechanisms that support the removal of personal data of individuals upon their requests. Consequently, machine unlearning (MU) has gained considerable attention which allows an ML model to selectively eliminate identifiable information. Evolving from MU, federated unlearning (FU) has emerged to confront the challenge of data erasure within federated learning (FL) settings, which empowers the FL model to unlearn an FL client or identifiable information pertaining to the client. Nevertheless, the distinctive attributes of federated learning introduce specific challenges for FU techniques. These challenges necessitate a tailored design when developing FU algorithms. While various concepts and numerous federated unlearning schemes exist in this field, the unified workflow and tailored design of FU are not yet well understood. Therefore, this comprehensive survey delves into the techniques and methodologies in FU providing an overview of fundamental concepts and principles, evaluating existing federated unlearning algorithms, and reviewing optimizations tailored to federated learning. Additionally, it discusses practical applications and assesses their limitations. Finally, it outlines promising directions for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3679014},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on federated unlearning: Challenges, methods, and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on edge data integrity verification:
Fundamentals and future trends. <em>CSUR</em>, <em>57</em>(1), 1–34. (<a
href="https://doi.org/10.1145/3680277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in edge computing (EC) have pushed cloud-based data caching services to edge; however, such emerging edge storage comes with numerous challenging and unique security issues. One of them is the problem of edge data integrity verification (EDIV), which coordinates multiple participants (e.g., data owners and edge nodes) to inspect whether data cached on edge is authentic. To date, various solutions have been proposed to address the EDIV problem, while there is no systematic review. Thus, we offer a comprehensive survey for the first time, aiming to show current research status, open problems, and potentially promising insights for readers to further investigate this under-explored field. Specifically, we begin by stating the significance of the EDIV problem, the integrity verification difference between data cached on cloud and edge, and three typical system models with corresponding inspection processes. To thoroughly assess prior research efforts, we synthesize a universal criteria framework that an effective verification approach should satisfy. On top of it, a schematic development timeline is developed to reveal the research advance on EDIV in a sequential manner, followed by a detailed review of the existing EDIV solutions. Finally, we highlight intriguing research challenges and possible directions for future work, along with a discussion on how forthcoming technology, e.g., machine learning and context-aware security, can augment security in EC. Given our findings, some major observations are: there is a noticeable trend to equip EDIV solutions with various functions and diversify study scenarios; completing EDIV within two types of participants (i.e., data owner and edge nodes) is garnering escalating interest among researchers; although the majority of existing methods rely on cryptography, emerging technology is being explored to handle the EDIV problem.},
  archive      = {J_CSUR},
  doi          = {10.1145/3680277},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on edge data integrity verification: Fundamentals and future trends},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An interdisciplinary survey on origin-destination flows
modeling: Theory and techniques. <em>CSUR</em>, <em>57</em>(1), 1–49.
(<a href="https://doi.org/10.1145/3682058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Origin-destination (OD) flow modeling is an extensively researched subject across multiple disciplines, such as the investigation of travel demand in transportation and spatial interaction modeling in geography. However, researchers from different fields tend to employ their own unique research paradigms and lack interdisciplinary communication, preventing the cross-fertilization of knowledge and the development of novel solutions to challenges. This article presents a systematic interdisciplinary survey that comprehensively and holistically scrutinizes OD flows from utilizing fundamental theory to studying the mechanism of population mobility and solving practical problems with engineering techniques, such as computational models. Specifically, regional economics, urban geography, and sociophysics are adept at employing theoretical research methods to explore the underlying mechanisms of OD flows. They have developed three influential theoretical models: the gravity model, the intervening opportunities model, and the radiation model. These models specifically focus on examining the fundamental influences of distance, opportunities, and population on OD flows, respectively. In the meantime, fields such as transportation, urban planning, and computer science primarily focus on addressing four practical problems: OD prediction, OD construction, OD estimation, and OD forecasting. Advanced computational models, such as deep learning models, have gradually been introduced to address these problems more effectively. We have constructed the benchmarks for these four problems at https://github.com/tsinghua-fib-lab/OD_benckmark. Finally, based on the existing research, this survey summarizes current challenges and outlines future directions for this topic. Through this survey, we aim to break down the barriers between disciplines in OD flow related research, fostering interdisciplinary perspectives and modes of thinking.},
  archive      = {J_CSUR},
  doi          = {10.1145/3682058},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-49},
  shortjournal = {ACM Comput. Surv.},
  title        = {An interdisciplinary survey on origin-destination flows modeling: Theory and techniques},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review on the use of physiological signals for assessing
postoperative pain. <em>CSUR</em>, <em>57</em>(1), 1–39. (<a
href="https://doi.org/10.1145/3685674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of pain intensity after surgery is important for guiding pain management. Due to the limitations of current pain evaluation tools, there is increasing interest in using objective methods to assess pain in clinical settings. This literature review aims to provide an overview of physiological methods for postoperative pain evaluation. The Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA) guidelines were followed to perform a literature search on the Scopus database from 2002 to March 2024. Sixty-one studies were included in this review investigating parameters derived from six physiological signals, including Electrocardiogram (ECG), Photoplethysmogram (PPG), Skin Conductance (SC), Electroencephalogram (EEG), Electromyogram (EMG), and pupil size and reflexes. Parameters extracted from ECG, PPG, and SC signals were the most commonly studied. While there is evidence to support the use of physiological parameters as measures for postoperative pain evaluation, further research is needed to establish the reliability and generalizability of these parameters to develop an indicator that can be consistently applied across various clinical settings. For this purpose, this review describes current research findings and identifies limitations and directions for future work that should be considered in upcoming research on postoperative pain assessment.},
  archive      = {J_CSUR},
  doi          = {10.1145/3685674},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review on the use of physiological signals for assessing postoperative pain},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Digital food sensing and ingredient analysis techniques to
facilitate human-food interface designs. <em>CSUR</em>, <em>57</em>(1),
1–39. (<a href="https://doi.org/10.1145/3685675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive technologies that shape the traditional human-food experiences are being explored under the emerging field of Human-Food Interaction (HFI). A key challenge in developing HFI technologies is the digital sensing of food, beverages, and their ingredients, commonly known as digital food sensing. Digital food sensing involves recognizing different food and beverages and their internal attributes, such as volume and ingredients (e.g., salt and sugar content). Contemporary research on interactive food applications, such as dietary assessment, primarily employs Computer Vision (CV) techniques to identify food; however, they are ineffective when (1) identifying food’s internal attributes, (2) discriminating visually similar food and beverages, and (3) seamlessly integrating with people’s natural interactions while consuming food. Thus, this article reviews potential food and beverage sensing technologies that can facilitate novel Human-Food Interfaces, primarily focusing on non-disruptive sensing techniques to analyze food and beverages during consumption. First, we review ten different digital food sensing techniques and their applications in four categories. Then, we discuss three main aspects to consider when adopting these food-sensing techniques for human-food interface designs. Finally, we suggest the future research requirements in digital food sensing methodologies, followed by potential applications of digital food sensing in future developments of Human-Food Interfaces.},
  archive      = {J_CSUR},
  doi          = {10.1145/3685675},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Digital food sensing and ingredient analysis techniques to facilitate human-food interface designs},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). COVID-19 modeling: A review. <em>CSUR</em>, <em>57</em>(1),
1–42. (<a href="https://doi.org/10.1145/3686150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The SARS-CoV-2 viruses and their triggered COVID-19 pandemic have fundamentally reshaped the world in almost every aspect, their evolution and influences remain. While over a million of literature have been produced on these unprecedented, overwhelming global disaster, one critical question is open: How has COVID-19 been quantified globally? This further inspires many other questions: What COVID-19 problems have been modeled? How have modeling methods in areas such as epidemiology, artificial intelligence (AI), data science, machine learning, deep learning, mathematics and social science played their roles in characterizing COVID-19? Where are the gaps and issues of these COVID-19 modeling studies? What are the lessons for quantifying future disasters? Answering these questions involves the analysis of a very broad spectrum of literature across different disciplines and domains. Distinguishing from specific efforts, this review takes the first attempt to generate a systematic, structured and contrastive landscape and taxonomy of global COVID-19 modeling. First, the surveyed problems span over a full range of COVID-19, including epidemic transmission processes, case identification and tracing, infection diagnosis and medical treatments, non-pharmaceutical interventions and their influence, drug and vaccine development, psychological, economic and social influence and impact, and misinformation, and so on. Second, the reviewed modeling methods traverse all relevant disciplines, from statistic modeling to epidemic modeling, medical analysis, biomedical analysis, AI, deep and machine learning, analytics, and simulation. Critical analyses further identify significant issues and gaps, for example, simple techniques and similar problems have been overwhelmingly addressed everywhere, while intrinsic and foundational issues and deep insights have been overlooked. The review discloses significant opportunities for more deeply, effectively and uniquely quantifying COVID-19-like global disasters from their intrinsic working mechanisms, interactions and dynamics.},
  archive      = {J_CSUR},
  doi          = {10.1145/3686150},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {COVID-19 modeling: A review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey on federated learning for intrusion detection system:
Concept, architectures, aggregation strategies, challenges, and future
directions. <em>CSUR</em>, <em>57</em>(1), 1–38. (<a
href="https://doi.org/10.1145/3687124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion Detection Systems (IDS) are essential for securing computer networks by identifying and mitigating potential threats. However, traditional IDS face challenges related to scalability, privacy, and computational demands as network data complexity increases. Federated Learning (FL) has emerged as a promising solution, enabling collaborative model training on decentralized data sources while preserving data privacy. Each participant retains local data repositories, ensuring data sovereignty and precluding data sharing. Leveraging the FL framework, participants locally train machine learning models on their respective datasets, subsequently transmitting model updates to a central server for aggregation. The central server then disseminates the aggregated model updates to individual participants, collectively striving to bolster intrusion detection capabilities. This article presents a comprehensive survey of FL applications in IDS, covering core concepts, architectural approaches, and aggregation strategies. We evaluate the strengths and limitations of various FL methodologies for IDS, addressing privacy and security concerns and exploring privacy-preserving techniques and security protocols. Our examination of aggregation strategies within the FL framework for IDS aims to highlight their effectiveness, limitations, and potential enhancements.},
  archive      = {J_CSUR},
  doi          = {10.1145/3687124},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on federated learning for intrusion detection system: Concept, architectures, aggregation strategies, challenges, and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Presentation attack detection: A systematic literature
review. <em>CSUR</em>, <em>57</em>(1), 1–32. (<a
href="https://doi.org/10.1145/3687264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identity authentication is the process of verifying one’s identity. Many identity authentication methods have been developed, from the conventional username-password systems to the recent electroencephalography-based authentication. Among them, biometric authentication shows particular importance due to its convenience and wide application in real-world scenarios. Face recognition is one of the most widely used biometric authentication methods, but simultaneously it receives various attacks. To overcome attacks, face presentation attack detection has been intensively studied in the last two decades regarding diverse domains of datasets, evaluation methods, and attack types. In this systematic literature review, we identify and categorise the state-of-the-art approaches in each domain to cover the challenges and solutions in a single place. We provide comparisons of representative methods on widely used datasets, discuss their pros and cons, and hope our insights can inspire future works.},
  archive      = {J_CSUR},
  doi          = {10.1145/3687264},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Presentation attack detection: A systematic literature review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic literature review on the influence of enhanced
developer experience on developers’ productivity: Factors, practices,
and recommendations. <em>CSUR</em>, <em>57</em>(1), 1–46. (<a
href="https://doi.org/10.1145/3687299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context and Motivation – Developer eXperience (Dev-X) is a recent research area that focuses on developers perceptions, feelings, and values with respect to software development and software quality. Research suggests that factors and practices related to Dev-X can have a substantial impact on developer productivity (Dev-P). However, despite a large and diverse body of literature on factors that can impact Dev-P in general, there is no coherent and comprehensive characterization of how Dev-X-specific insights can influence developer productivity. Aims – In the presented research, we aim to provide a coherent, comprehensive characterization of factors and practices related to Dev-X, with a particular focus on those factors and practices that potentially affect Dev-P. Method – To this end, we performed a systematic literature review and identified 218 relevant papers in this area. We characterize the papers based on the related frameworks and concepts common to Dev-X and Dev-P as presented in the existing literature. Dev-X factors such as “work fragmentation” and practices such as “collaboration with owner-developer” are identified using a grounded-in-the-literature, content-analysis method, guided by the theory. For each Dev-X factor, we identify attributes that might be used to assess/ measure the current status (of an organization or project) regarding that factor and how that factor and its effects on productivity have been evidenced in the literature (mentioned vs. considered in questionnaires vs. substantiated with a more positivist evaluation). Results – We identify 33 Dev-X-related factors and 41 Dev-X-related practices, which are organized into 10 themes to summarize their influence. The results suggest that the availability of required resources, relevant expertise re the allocated tasks, and fewer interruptions are among the top positively impacting factors. Conversely, factors such as code complexity, heterogeneous contexts of tasks, and non-adherence to standardization harm Dev-X and Dev-P. Top industrial practices employed to mitigate the negative influence of factors include characterization-based task assignments, mental model support, and the timely evolution of technologies. Conclusions – Overall, this research suggests that organizations can influence Dev-P through improved Dev-X, incorporating suitable practices to mediate relevant factors in their context. Important in this regard are practices such as fragmenting large tasks, highlighting the utility of proposed tasks/changes to the developers, and promoting (developer) ownership of artefacts. Finally, our results point to areas where further research seems appropriate, i.e., where Dev-X factors/practices have been proposed as being impactful on Dev-P but not yet fully substantiated or explored as such (factors like “Nature of Activity” and practices like choosing practices/protocols appropriately).},
  archive      = {J_CSUR},
  doi          = {10.1145/3687299},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-46},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on the influence of enhanced developer experience on developers&#39; productivity: Factors, practices, and recommendations},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MITRE ATT&amp;CK: State of the art and way forward.
<em>CSUR</em>, <em>57</em>(1), 1–37. (<a
href="https://doi.org/10.1145/3687300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MITRE ATT&amp;CK is a comprehensive framework of adversary tactics, techniques, and procedures based on real-world observations. It has been used as a foundation for threat modeling in different sectors, such as government, academia, and industry. To the best of our knowledge, no previous work has been devoted to the comprehensive collection, study, and investigation of the current state of the art leveraging the MITRE ATT&amp;CK framework. We select and inspect more than 50 major research contributions, while conducting a detailed analysis of their methodology and objectives in relation to the MITRE ATT&amp;CK framework. We provide a categorization of the identified papers according to different criteria such as use cases, application scenarios, adopted methodologies, and the use of additional data. Finally, we discuss open issues and future research directions involving not only the MITRE ATT&amp;CK framework but also the fields of threat analysis, threat modeling, and in general cyber-threat intelligence.},
  archive      = {J_CSUR},
  doi          = {10.1145/3687300},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {MITRE ATT&amp;CK: State of the art and way forward},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data mesh: A systematic gray literature review.
<em>CSUR</em>, <em>57</em>(1), 1–36. (<a
href="https://doi.org/10.1145/3687301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data mesh is an emerging domain-driven decentralized data architecture that aims to minimize or avoid operational bottlenecks associated with centralized, monolithic data architectures in enterprises. The topic has piqued the practitioners’ interest, and considerable gray literature exists. At the same time, we observe a lack of academic attempts at defining and building upon the concept. Hence, in this article, we aim to start from the foundations and characterize the data mesh architecture regarding its design principles, architectural components, capabilities, and organizational roles. We systematically collected, analyzed, and synthesized 114 industrial gray literature articles. The resulting review provides insights into practitioners’ perspectives on the four key principles of data mesh: data as a product, domain ownership of data, self-serve data platform, and federated computational governance. Moreover, due to the comparability of data mesh and SOA (service-oriented architecture), we mapped the findings from the gray literature into the reference architectures from the SOA academic literature to create the reference architectures for describing three key dimensions of data mesh: organization of capabilities and roles, development, and runtime. Finally, we discuss open research issues in data mesh, partially based on the findings from the gray literature.},
  archive      = {J_CSUR},
  doi          = {10.1145/3687301},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Data mesh: A systematic gray literature review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physics-informed computer vision: A review and perspectives.
<em>CSUR</em>, <em>57</em>(1), 1–38. (<a
href="https://doi.org/10.1145/3689037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incorporation of physical information in machine learning frameworks is opening and transforming many application domains. Here the learning process is augmented through the induction of fundamental knowledge and governing physical laws. In this work, we explore their utility for computer vision tasks in interpreting and understanding visual data. We present a systematic literature review of more than 250 papers on formulation and approaches to computer vision tasks guided by physical laws. We begin by decomposing the popular computer vision pipeline into a taxonomy of stages and investigate approaches to incorporate governing physical equations in each stage. Existing approaches are analyzed in terms of modeling and formulation of governing physical processes, including modifying input data (observation bias), network architectures (inductive bias), and training losses (learning bias). The taxonomy offers a unified view of the application of the physics-informed capability, highlighting where physics-informed learning has been conducted and where the gaps and opportunities are. Finally, we highlight open problems and challenges to inform future research. While still in its early days, the study of physics-informed computer vision has the promise to develop better computer vision models that can improve physical plausibility, accuracy, data efficiency, and generalization in increasingly realistic applications.},
  archive      = {J_CSUR},
  doi          = {10.1145/3689037},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Physics-informed computer vision: A review and perspectives},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Competence awareness for humans and machines: A survey and
future research directions from psychology. <em>CSUR</em>,
<em>57</em>(1), 1–26. (<a
href="https://doi.org/10.1145/3689626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning researchers are beginning to understand the need for machines to be able to self-assess their competence and express it in a human understandable form. However, current machine learning algorithms do not yet have the range or complexity of competence awareness measures present in humans. This review first describes progress towards competence awareness in machines, and then examines the psychology literature on competence awareness and competence motivation to identify the limitations of current competence awareness algorithms. The article concludes with a discussion of the necessary and promising future research directions for creating competence-aware machines.},
  archive      = {J_CSUR},
  doi          = {10.1145/3689626},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-26},
  shortjournal = {ACM Comput. Surv.},
  title        = {Competence awareness for humans and machines: A survey and future research directions from psychology},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-class imbalanced data handling with concept drift in
fog computing: A taxonomy, review, and future directions. <em>CSUR</em>,
<em>57</em>(1), 1–48. (<a
href="https://doi.org/10.1145/3689627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A network of actual physical objects or “IoT components” linked to the internet and equipped with sensors, electronics, software, and network connectivity is known as the Internet of Things (IoT). This ability of the IoT components to gather and share data is made possible by this network connectivity. Many IoT devices are currently operating, which generate a lot of data. When these IoT devices started collecting data, the cloud was the only place to analyze, filter, pre-process, and aggregate it. However, when it comes to IoT, the cloud has restrictions regarding latency and a more centralized method of distributing programs. A new form of computing called Fog computing has been proposed to address the shortcomings of current cloud computing. In an IoT context, sensors regularly communicate signal information, and edge devices process the data obtained from these sensors using Fog computing. The sensors’ internal or external problems, security breaches, or the integration of heterogeneous equipment contribute to the imbalanced data, i.e., comparatively speaking, one class has more instances than the other. As a result of this data, the pattern extraction is imbalanced . Recent attempts have concentrated heavily on binary-class imbalanced concerns with exactly two classes. However, the classification of multi-class imbalanced data is an issue that needs to be fixed in Fog computing, even if it is widespread in other fields, including text categorization, human activity detection, and medical diagnosis. The study intends to deal with this problem. It presents a systematic, thorough, and in-depth comparative analysis of several binary-class and multi-class imbalanced data handling strategies for batch and streaming data in IoT networks and Fog computing. There are five major objectives in this study. First, reviewing the Fog computing concept. Second, outlining the optimization metric used in Fog computing. Third, focusing on binary and multi-class batch data handling for IoT networks and Fog computing. Fourth, reviewing and comparing the current imbalanced data handling methodologies for multi-class data streams. Fifth, explaining how to cope with the concept drift, including novel and recurring classes, targeted optimization measures, and evaluation tools. Finally, the best performance metrics and tools for concept drift, binary-class (batch and stream) data, and multi-class (batch and stream) data are highlighted.},
  archive      = {J_CSUR},
  doi          = {10.1145/3689627},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-48},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multi-class imbalanced data handling with concept drift in fog computing: A taxonomy, review, and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for time series anomaly detection: A survey.
<em>CSUR</em>, <em>57</em>(1), 1–42. (<a
href="https://doi.org/10.1145/3691338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is important for a wide range of research fields and applications, including financial markets, economics, earth sciences, manufacturing, and healthcare. The presence of anomalies can indicate novel or unexpected events, such as production faults, system defects, and heart palpitations, and is therefore of particular interest. The large size and complexity of patterns in time series data have led researchers to develop specialised deep learning models for detecting anomalous patterns. This survey provides a structured and comprehensive overview of state-of-the-art deep learning for time series anomaly detection. It provides a taxonomy based on anomaly detection strategies and deep learning models. Aside from describing the basic anomaly detection techniques in each category, their advantages and limitations are also discussed. Furthermore, this study includes examples of deep anomaly detection in time series across various application domains in recent years. Finally, it summarises open issues in research and challenges faced while adopting deep anomaly detection models to time series data.},
  archive      = {J_CSUR},
  doi          = {10.1145/3691338},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for time series anomaly detection: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on stability of learning with limited labelled data
and its sensitivity to the effects of randomness. <em>CSUR</em>,
<em>57</em>(1), 1–40. (<a
href="https://doi.org/10.1145/3691339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning with limited labelled data, such as prompting, in-context learning, fine-tuning, meta-learning, or few-shot learning, aims to effectively train a model using only a small amount of labelled samples. However, these approaches have been observed to be excessively sensitive to the effects of uncontrolled randomness caused by non-determinism in the training process. The randomness negatively affects the stability of the models, leading to large variances in results across training runs. When such sensitivity is disregarded, it can unintentionally, but unfortunately also intentionally, create an imaginary perception of research progress. Recently, this area started to attract research attention and the number of relevant studies is continuously growing. In this survey, we provide a comprehensive overview of 415 papers addressing the effects of randomness on the stability of learning with limited labelled data. We distinguish between four main tasks addressed in the papers (investigate/evaluate, determine, mitigate, benchmark/compare/report randomness effects), providing findings for each one. Furthermore, we identify and discuss seven challenges and open problems together with possible directions to facilitate further research. The ultimate goal of this survey is to emphasise the importance of this growing research area, which so far has not received an appropriate level of attention, and reveal impactful directions for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3691339},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on stability of learning with limited labelled data and its sensitivity to the effects of randomness},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ransomware reloaded: Re-examining its trend, research and
mitigation in the era of data exfiltration. <em>CSUR</em>,
<em>57</em>(1), 1–40. (<a
href="https://doi.org/10.1145/3691340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ransomware has grown to be a dominant cybersecurity threat by exfiltrating, encrypting, or destroying valuable user data and causing numerous disruptions to victims. The severity of the ransomware endemic has generated research interest from both the academia and the industry. However, many studies held stereotypical assumptions about ransomware, used unverified, outdated, and limited self-collected ransomware samples, and did not consider government strategies, industry guidelines, or cyber intelligence. We observed that ransomware no longer exists simply as an executable file or limits to encrypting files (data loss); data exfiltration (data breach) is the new norm, espionage is an emerging theme, and the industry is shifting focus from technical advancements to cyber governance and resilience. We created a ransomware innovation adoption curve, critically evaluated 212 academic studies published during 2020 and 2023, and cross-verified them against various government strategies, industry reports, and cyber intelligence on ransomware. We concluded that many studies were becoming irrelevant to the contemporary ransomware reality and called for the redirection of ransomware research to align with the continuous ransomware evolution in the industry. We proposed to address data exfiltration as priority over data encryption, to consider ransomware in a business-practical manner, and recommended research collaboration with the industry.},
  archive      = {J_CSUR},
  doi          = {10.1145/3691340},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Ransomware reloaded: Re-examining its trend, research and mitigation in the era of data exfiltration},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Eco-friendly route planning algorithms: Taxonomies,
literature review and future directions. <em>CSUR</em>, <em>57</em>(1),
1–42. (<a href="https://doi.org/10.1145/3691624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eco-friendly navigation (a.k.a. eco-routing) finds a route from A to B in a road network that minimizes the greenhouse gas (GHG) emission or fuel/energy consumption of the traveling vehicle. As road transport is a major contributor to GHG emissions, eco-routing has received considerable research attention in the past decade, mainly on two research themes: (1) developing models to estimate emissions or fuel/energy consumption of vehicles; and (2) developing algorithms to find eco-friendly routes for a vehicle. There are some excellent literature reviews that cover the existing estimation models. However, there is no literature review on eco-friendly route-planning algorithms. This article fills this gap and provides a systematic literature review in this area. From mainstream online databases, we obtained 2,494 articles and shortlisted 76 articles using our exclusion criteria. Accordingly, we establish a holistic view of eco-routing systems and define five taxonomies of estimation models, eco-routing problems and algorithms, vehicle types, traffic, and road network characteristics. Concerning the taxonomies, we categorize and review the shortlisted articles. Finally, we highlight research challenges and outline future directions in this important area.},
  archive      = {J_CSUR},
  doi          = {10.1145/3691624},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Eco-friendly route planning algorithms: Taxonomies, literature review and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adversarial attacks and countermeasures on image
classification-based deep learning models in autonomous driving systems:
A systematic review. <em>CSUR</em>, <em>57</em>(1), 1–52. (<a
href="https://doi.org/10.1145/3691625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of artificial intelligence (AI) and breakthroughs in Internet of Things (IoT) technologies have driven the innovation of advanced autonomous driving systems (ADSs). Image classification deep learning (DL) algorithms immensely contribute to the decision-making process in ADSs, showcasing their capabilities in handling complex real-world driving scenarios, surpassing human driving intelligence. However, these algorithms are vulnerable to adversarial attacks, which aim to fool them in real-time decision-making and compromise the reliability of the autonomous driving functions. This systematic review offers a comprehensive overview of the most recent literature on adversarial attacks and countermeasures on image classification DL models in ADSs. The review highlights the current challenges in applying successful countermeasures to mitigating these vulnerabilities. We also introduce taxonomies for categorizing adversarial attacks and countermeasures and provide recommendations and guidelines to help researchers design and evaluate countermeasures. We suggest interesting future research directions to improve the robustness of image classification DL models against adversarial attacks in autonomous driving scenarios.},
  archive      = {J_CSUR},
  doi          = {10.1145/3691625},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-52},
  shortjournal = {ACM Comput. Surv.},
  title        = {Adversarial attacks and countermeasures on image classification-based deep learning models in autonomous driving systems: A systematic review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vulnerabilities and security patches detection in OSS: A
survey. <em>CSUR</em>, <em>57</em>(1), 1–37. (<a
href="https://doi.org/10.1145/3694782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, Open Source Software (OSS) has experienced rapid growth and widespread adoption, attributed to its openness and editability. However, this expansion has also brought significant security challenges, particularly introducing and propagating software vulnerabilities. Despite the use of machine learning and formal methods to tackle these issues, there remains a notable gap in comprehensive surveys that summarize and analyze both Vulnerability Detection (VD) and Security Patch Detection (SPD) in OSS. This article seeks to bridge this gap through an extensive survey that evaluates 127 technical studies published between 2014 and 2023, structured around the Vulnerability-Patch lifecycle. We begin by delineating the six critical events that constitute the Vulnerability-Patch lifecycle, leading to an in-depth exploration of the Vulnerability-Patch ecosystem. We then systematically review the databases commonly used in VD and SPD, and analyze their characteristics. Subsequently, we examine existing VD methods, focusing on traditional and deep learning based approaches. Additionally, we organize current security patch identification methods by kernel type and discuss techniques for detecting the presence of security patches. Based on our comprehensive review, we identify open research questions and propose future research directions that merit further exploration.},
  archive      = {J_CSUR},
  doi          = {10.1145/3694782},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Vulnerabilities and security patches detection in OSS: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of techniques for ageing detection and monitoring
on embedded systems. <em>CSUR</em>, <em>57</em>(1), 1–34. (<a
href="https://doi.org/10.1145/3695247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedded digital devices are progressively deployed in dependable or safety-critical systems. These devices undergo significant hardware ageing, particularly in harsh environments. This increases their likelihood of failure. It is crucial to understand ageing processes and to detect hardware degradation early for guaranteeing system dependability. In this survey, we review the core ageing mechanisms, and identify and categorize general working principles of ageing detection and monitoring techniques for Commercial-Off-the-Shelf (COTS) components that are prevalent in embedded systems: Field Programmable Gate Arrays (FPGAs), microcontrollers, Systems-on-Chips (SoCs), and their power supplies. From our review, we find that online techniques are more widely applied on FPGAs than on other components, and see a rising trend towards machine learning application for analysing hardware ageing. Based on the reviewed literature, we identify research opportunities and potential directions of interest in the field. With this work, we intend to facilitate future research by systematically presenting all main approaches in a concise way.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695247},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review of techniques for ageing detection and monitoring on embedded systems},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale simulation of complex systems: A perspective of
integrating knowledge and data. <em>CSUR</em>, <em>56</em>(12), 1–38.
(<a href="https://doi.org/10.1145/3654662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex system simulation has been playing an irreplaceable role in understanding, predicting, and controlling diverse complex systems. In the past few decades, the multi-scale simulation technique has drawn increasing attention for its remarkable ability to overcome the challenges of complex system simulation with unknown mechanisms and expensive computational costs. In this survey, we will systematically review the literature on multi-scale simulation of complex systems from the perspective of knowledge and data. First, we will present background knowledge about simulating complex systems and the scales in complex systems. Then, we divide the main objectives of multi-scale modeling and simulation into five categories by considering scenarios with clear scale and scenarios with unclear scale, respectively. After summarizing the general methods for multi-scale simulation based on the clues of knowledge and data, we introduce the adopted methods to achieve different objectives. Finally, we introduce the applications of multi-scale simulation in typical matter systems and social systems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3654662},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multi-scale simulation of complex systems: A perspective of integrating knowledge and data},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for table detection and structure recognition:
A survey. <em>CSUR</em>, <em>56</em>(12), 1–41. (<a
href="https://doi.org/10.1145/3657281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tables are everywhere, from scientific journals, articles, websites, and newspapers all the way to items we buy at the supermarket. Detecting them is thus of utmost importance to automatically understanding the content of a document. The performance of table detection has substantially increased thanks to the rapid development of deep learning networks. The goals of this survey are to provide a profound comprehension of the major developments in the field of Table Detection, offer insight into the different methodologies, and provide a systematic taxonomy of the different approaches. Furthermore, we provide an analysis of both classic and new applications in the field. Lastly, the datasets and source code of the existing models are organized to provide the reader with a compass on this vast literature. Finally, we go over the architecture of utilizing various object detection and table structure recognition methods to create an effective and efficient system, as well as a set of development trends to keep up with state-of-the-art algorithms and future research. We have also set up a public GitHub repository where we will be updating the most recent publications, open data, and source code. The GitHub repository is available at https://github.com/abdoelsayed2016/table-detection-structure-recognition.},
  archive      = {J_CSUR},
  doi          = {10.1145/3657281},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for table detection and structure recognition: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Qualitative approaches to voice UX. <em>CSUR</em>,
<em>56</em>(12), 1–34. (<a
href="https://doi.org/10.1145/3658666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voice is a natural mode of expression offered by modern computer-based systems. Qualitative perspectives on voice-based user experiences (voice UX) offer rich descriptions of complex interactions that numbers alone cannot fully represent. We conducted a systematic review of the literature on qualitative approaches to voice UX, capturing the nature of this body of work in a systematic map and offering a qualitative synthesis of findings. We highlight the benefits of qualitative methods for voice UX research, identify opportunities for increasing rigour in methods and outcomes, and distill patterns of experience across a diversity of devices and modes of qualitative praxis.},
  archive      = {J_CSUR},
  doi          = {10.1145/3658666},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Qualitative approaches to voice UX},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mix-zones as an effective privacy enhancing technique in
mobile and vehicular ad-hoc networks. <em>CSUR</em>, <em>56</em>(12),
1–33. (<a href="https://doi.org/10.1145/3659576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent Transportation Systems (ITS) promise significant increases in throughput and reductions in trip delay. ITS makes extensive use of Connected and Autonomous Vehicles (CAV) frequently broadcasting location, speed, and intention information. However, with such extensive communication comes the risk to privacy. Preserving privacy while still exchanging vehicle state information has been recognized as an important problem. Mix zones have emerged as a potentially effective way of protecting user privacy in ITS. CAVs are assigned pseudonyms to mask their identity; a mix zone is an area where CAVs can change their pseudonyms to resist being tracked. In order to be effective, mix zone placement must take account of traffic flows. Also, since a mix zone can degrade throughput, mix zones must be used sparingly. Determining the number and placement of mix zones is a difficult dynamic optimization problem. This paper outlines the various approaches recently taken by researchers to deal with this problem.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659576},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Mix-zones as an effective privacy enhancing technique in mobile and vehicular ad-hoc networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on resilience in information sharing on networks:
Taxonomy and applied techniques. <em>CSUR</em>, <em>56</em>(12), 1–36.
(<a href="https://doi.org/10.1145/3659944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information sharing is vital in any communication network environment to enable network operating services take decisions based on the information collected by several deployed computing devices. The various networks that compose cyberspace, as Internet-of-Things (IoT) ecosystems, have significantly increased the need to constantly share information, which is often subject to disturbances. In this sense, the damage of anomalous operations boosted researches aimed at improving resilience to information sharing. Hence, in this survey, we present a systematization of knowledge about scientific efforts for achieving resilience to information sharing on networks. First, we introduce a taxonomy to organize the strategies applied to attain resilience to information sharing on networks, offering brief concepts about network anomalies and connectivity services. Then, we detail the taxonomy in the face of malicious threats, network disruptions, and performance issues, discussing the presented solutions. Next, we analyze the techniques existing in the literature to foster resilience to information exchanged on communication networks to verify their benefits and constraints. Throughout the text, we highlight and argue issues that restrain the use of these techniques during the design and runtime.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659944},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on resilience in information sharing on networks: Taxonomy and applied techniques},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A meta-study of software-change intentions. <em>CSUR</em>,
<em>56</em>(12), 1–41. (<a
href="https://doi.org/10.1145/3661484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every software system undergoes changes, for example, to add new features, fix bugs, or refactor code. The importance of understanding software changes has been widely recognized, resulting in various techniques and studies, for instance, on change-impact analysis or classifying developers’ activities. Since changes are triggered by developers’ intentions—something they plan or want to change in the system—many researchers have studied intentions behind changes. While there appears to be a consensus among software-engineering researchers and practitioners that knowing the intentions behind software changes is important, it is not clear how developers can actually benefit from this knowledge. In fact, there is no consolidated, recent overview of the state of the art on software-change intentions (SCIs) and their relevance for software engineering. We present a meta-study of 122 publications, which we used to derive a categorization of SCIs and to discuss motivations, evidence, and techniques relating to SCIs. Unfortunately, we found that individual pieces of research are often disconnected from each other, because a common understanding is missing. Similarly, some publications showcase the potential of knowing SCIs, but more substantial research to understand the practical benefits of knowing SCIs is needed. Our contributions can help researchers and practitioners improve their understanding of SCIs and how SCIs can aid software engineering tasks.},
  archive      = {J_CSUR},
  doi          = {10.1145/3661484},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A meta-study of software-change intentions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NLOS identification and mitigation for time-based indoor
localization systems: Survey and future research directions.
<em>CSUR</em>, <em>56</em>(12), 1–41. (<a
href="https://doi.org/10.1145/3663473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One hurdle to accurate indoor localization using time-based networks is the presence of Non-Line-Of-Sight (NLOS) and multipath signals, affecting the accuracy of ranging in indoor environments. NLOS identification and mitigation have been studied over the years and applied to different time-based networks, with most works considering NLOS links with WiFi and UWB channels. In this article, we discuss the effects and challenges of NLOS conditions on indoor localization and present current state-of-the-art approaches to NLOS identification and mitigation in literature. We survey these approaches and classify them under different categories together with their merits and demerits. We further categorize approaches to tackle NLOS effects into single and hybrid measurement-based approaches in this work. Lessons learnt from the survey with future directions are also presented in this article.},
  archive      = {J_CSUR},
  doi          = {10.1145/3663473},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {NLOS identification and mitigation for time-based indoor localization systems: Survey and future research directions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Natural language reasoning, a survey. <em>CSUR</em>,
<em>56</em>(12), 1–39. (<a
href="https://doi.org/10.1145/3664194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey article proposes a clearer view of Natural Language Reasoning (NLR) in the field of Natural Language Processing (NLP) , both conceptually and practically. Conceptually, we provide a distinct definition for NLR in NLP, based on both philosophy and NLP scenarios; discuss what types of tasks require reasoning; and introduce a taxonomy of reasoning. Practically, we conduct a comprehensive literature review on NLR in NLP, mainly covering classical logical reasoning, Natural Language Inference (NLI) , multi-hop question answering, and commonsense reasoning. The article also identifies and views backward reasoning, a powerful paradigm for multi-step reasoning, and introduces defeasible reasoning as one of the most important future directions in NLR research. We focus on single-modality unstructured natural language text, excluding neuro-symbolic research and mathematical reasoning. 1},
  archive      = {J_CSUR},
  doi          = {10.1145/3664194},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Natural language reasoning, a survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An overview of privacy-enhancing technologies in biometric
recognition. <em>CSUR</em>, <em>56</em>(12), 1–28. (<a
href="https://doi.org/10.1145/3664596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy-enhancing technologies are technologies that implement fundamental data protection principles. With respect to biometric recognition, different types of privacy-enhancing technologies have been introduced for protecting stored biometric data, which are generally classified as sensitive. In this regard, various taxonomies and conceptual categorizations have been proposed and standardisation activities have been carried out. However, these efforts have mainly been devoted to certain sub-categories of privacy-enhancing technologies and therefore lack generalization. This work provides an overview of concepts of privacy-enhancing technologies for biometric recognition in a unified framework. Key properties and differences between existing concepts are highlighted in detail at each processing step. Fundamental characteristics and limitations of existing technologies are discussed and related to data protection techniques and principles. Moreover, scenarios and methods for the assessment of privacy-enhancing technologies for biometric recognition are presented. This article is meant as a point of entry to the field of data protection for biometric recognition applications and is directed toward experienced researchers as well as non-experts.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664596},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-28},
  shortjournal = {ACM Comput. Surv.},
  title        = {An overview of privacy-enhancing technologies in biometric recognition},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for code intelligence: Survey, benchmark and
toolkit. <em>CSUR</em>, <em>56</em>(12), 1–41. (<a
href="https://doi.org/10.1145/3664597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code intelligence leverages machine learning techniques to extract knowledge from extensive code corpora, with the aim of developing intelligent tools to improve the quality and productivity of computer programming. Currently, there is already a thriving research community focusing on code intelligence, with efforts ranging from software engineering, machine learning, data mining, natural language processing, and programming languages. In this paper, we conduct a comprehensive literature review on deep learning for code intelligence, from the aspects of code representation learning, deep learning techniques, and application tasks. We also benchmark several state-of-the-art neural models for code intelligence, and provide an open-source toolkit tailored for the rapid prototyping of deep-learning-based code intelligence models. In particular, we inspect the existing code intelligence models under the basis of code representation learning, and provide a comprehensive overview to enhance comprehension of the present state of code intelligence. Furthermore, we publicly release the source code and data resources to provide the community with a ready-to-use benchmark, which can facilitate the evaluation and comparison of existing and future code intelligence models (https://xcodemind.github.io). At last, we also point out several challenging and promising directions for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664597},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for code intelligence: Survey, benchmark and toolkit},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified review of deep learning for automated medical
coding. <em>CSUR</em>, <em>56</em>(12), 1–41. (<a
href="https://doi.org/10.1145/3664615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated medical coding, an essential task for healthcare operation and delivery, makes unstructured data manageable by predicting medical codes from clinical documents. Recent advances in deep learning and natural language processing have been widely applied to this task. However, deep learning–based medical coding lacks a unified view of the design of neural network architectures. This review proposes a unified framework to provide a general understanding of the building blocks of medical coding models and summarizes recent advanced models under the proposed framework. Our unified framework decomposes medical coding into four main components, i.e., encoder modules for text feature extraction, mechanisms for building deep encoder architectures, decoder modules for transforming hidden representations into medical codes, and the usage of auxiliary information. Finally, we introduce the benchmarks and real-world usage and discuss key research challenges and future directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664615},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A unified review of deep learning for automated medical coding},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of hardware improvements to secure program
execution. <em>CSUR</em>, <em>56</em>(12), 1–37. (<a
href="https://doi.org/10.1145/3672392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hardware has been constantly augmented for security considerations since the advent of computers. There is also a common perception among computer users that hardware does a relatively better job on security assurance compared with software. Yet, the community has long lacked a comprehensive study to answer questions such as how hardware security support contributes to security, what kind of improvements have been introduced to improve such support and what its advantages/disadvantages are. By generalizing various security goals, we taxonomize hardware security features and their security properties that can aid in securing program execution, considered as three aspects, i.e., state correctness, runtime protection and input/output protection. Based on this taxonomy, the survey systematically examines (1) the roles: how hardware is applied to achieve security; and (2) the problems: how reported attacks have exploited certain defects in hardware. We see that hardware’s unique advantages and problems co-exist and it highly depends on the desired security purpose as to which type to use. Among the survey findings are also that code as part of hardware (aka. firmware) should be treated differently to ensure security by design; and how research proposals have driven the advancement of commodity hardware features.},
  archive      = {J_CSUR},
  doi          = {10.1145/3672392},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of hardware improvements to secure program execution},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on biclustering-based collaborative
filtering. <em>CSUR</em>, <em>56</em>(12), 1–32. (<a
href="https://doi.org/10.1145/3674723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative Filtering (CF) is achieving a plateau of high popularity. Still, recommendation success is challenged by the diversity of user preferences, structural sparsity of user-item ratings, and inherent subjectivity of rating scales. The increasing user base and item dimensionality of e-commerce and e-entertainment platforms creates opportunities, while further raising generalization and scalability needs. Moved by the need to answer these challenges, user-based and item-based clustering approaches for CF became pervasive. However, classic clustering approaches assess user (item) rating similarity across all items (users), neglecting the rich diversity of item and user profiles. Instead, as preferences are generally simultaneously correlated on subsets of users and items, biclustering approaches provide a natural alternative, being successfully applied to CF for nearly two decades and synergistically integrated with emerging deep learning CF stances. Notwithstanding, biclustering-based CF principles are dispersed, causing state-of-the-art approaches to show accentuated behavioral differences. This work offers a structured view on how biclustering aspects impact recommendation success, coverage, and efficiency. To this end, we introduce a taxonomy to categorize contributions in this field and comprehensively survey state-of-the-art biclustering approaches to CF, highlighting their limitations and potentialities.},
  archive      = {J_CSUR},
  doi          = {10.1145/3674723},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on biclustering-based collaborative filtering},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). SoK: Fully homomorphic encryption accelerators.
<em>CSUR</em>, <em>56</em>(12), 1–32. (<a
href="https://doi.org/10.1145/3676955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully Homomorphic Encryption (FHE) is a key technology enabling privacy-preserving computing. However, the fundamental challenge of FHE is its inefficiency, due primarily to the underlying polynomial computations with high computation complexity and extremely time-consuming ciphertext maintenance operations. To tackle this challenge, various FHE accelerators have recently been proposed by both research and industrial communities. This article takes the first initiative to conduct a systematic study on the 14 FHE accelerators: cuHE/cuFHE, nuFHE, HEAT, HEAX, HEXL, HEXL-FPGA, 100×, F1, CraterLake, BTS, ARK, Poseidon, FAB, and TensorFHE. We first make our observations on the evolution trajectory of these existing FHE accelerators to establish a qualitative connection between them. Then, we perform testbed evaluations of representative open-source FHE accelerators to provide a quantitative comparison on them. Finally, with the insights learned from both qualitative and quantitative studies, we discuss potential directions to inform the future design and implementation for FHE accelerators.},
  archive      = {J_CSUR},
  doi          = {10.1145/3676955},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {SoK: Fully homomorphic encryption accelerators},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An overview of FPGA-inspired obfuscation techniques.
<em>CSUR</em>, <em>56</em>(12), 1–35. (<a
href="https://doi.org/10.1145/3677118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building and maintaining a silicon foundry is a costly endeavor that requires substantial financial investment. From this scenario, the semiconductor business has largely shifted to a fabless model where the Integrated Circuit (IC) supply chain is globalized but potentially untrusted. In recent years, several hardware obfuscation techniques have emerged to thwart hardware security threats related to untrusted IC fabrication. Reconfigurable-based obfuscation schemes have shown great promise of security against state-of-the-art attacks—these are techniques that rely on the transformation of static logic configurable elements such as Look Up Tables (LUTs). This survey provides a comprehensive analysis of reconfigurable-based obfuscation techniques, evaluating their overheads and enumerating their effectiveness against all known attacks. The techniques are also classified based on different factors, including the technology used, element type, and IP type. Additionally, we present a discussion on the advantages of reconfigurable-based obfuscation techniques when compared to Logic Locking techniques and the challenges associated with evaluating these techniques on hardware, primarily due to the lack of tapeouts. The survey’s findings are essential for researchers interested in hardware obfuscation and future trends in this area.},
  archive      = {J_CSUR},
  doi          = {10.1145/3677118},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {An overview of FPGA-inspired obfuscation techniques},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counterfactual explanations and algorithmic recourses for
machine learning: A review. <em>CSUR</em>, <em>56</em>(12), 1–42. (<a
href="https://doi.org/10.1145/3677119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning plays a role in many deployed decision systems, often in ways that are difficult or impossible to understand by human stakeholders. Explaining, in a human-understandable way, the relationship between the input and output of machine learning models is essential to the development of trustworthy machine learning based systems. A burgeoning body of research seeks to define the goals and methods of explainability in machine learning. In this article, we seek to review and categorize research on counterfactual explanations , a specific class of explanation that provides a link between what could have happened had input to a model been changed in a particular way. Modern approaches to counterfactual explainability in machine learning draw connections to the established legal doctrine in many countries, making them appealing to fielded systems in high-impact areas such as finance and healthcare. Thus, we design a rubric with desirable properties of counterfactual explanation algorithms and comprehensively evaluate all currently proposed algorithms against that rubric. Our rubric provides easy comparison and comprehension of the advantages and disadvantages of different approaches and serves as an introduction to major research themes in this field. We also identify gaps and discuss promising research directions in the space of counterfactual explainability.},
  archive      = {J_CSUR},
  doi          = {10.1145/3677119},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Counterfactual explanations and algorithmic recourses for machine learning: A review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-based depth estimation methods from monocular
image and videos: A comprehensive survey. <em>CSUR</em>,
<em>56</em>(12), 1–51. (<a
href="https://doi.org/10.1145/3677327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating depth from single RGB images and videos is of widespread interest due to its applications in many areas, including autonomous driving, 3D reconstruction, digital entertainment, and robotics. More than 500 deep learning-based papers have been published in the past 10 years, which indicates the growing interest in the task. This paper presents a comprehensive survey of the existing deep learning-based methods, the challenges they address, and how they have evolved in their architecture and supervision methods. It provides a taxonomy for classifying the current work based on their input and output modalities, network architectures, and learning methods. It also discusses the major milestones in the history of monocular depth estimation, and different pipelines, datasets, and evaluation metrics used in existing methods.},
  archive      = {J_CSUR},
  doi          = {10.1145/3677327},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-51},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning-based depth estimation methods from monocular image and videos: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive analysis of explainable AI for malware
hunting. <em>CSUR</em>, <em>56</em>(12), 1–40. (<a
href="https://doi.org/10.1145/3677374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decade, the number of malware variants has increased rapidly. Many researchers have proposed to detect malware using intelligent techniques, such as Machine Learning (ML) and Deep Learning (DL), which have high accuracy and precision. These methods, however, suffer from being opaque in the decision-making process. Therefore, we need Artificial Intelligence (AI)-based models to be explainable, interpretable, and transparent to be reliable and trustworthy. In this survey, we reviewed articles related to Explainable AI (XAI) and their application to the significant scope of malware detection. The article encompasses a comprehensive examination of various XAI algorithms employed in malware analysis. Moreover, we have addressed the characteristics, challenges, and requirements in malware analysis that cannot be accommodated by standard XAI methods. We discussed that even though Explainable Malware Detection (EMD) models provide explainability, they make an AI-based model more vulnerable to adversarial attacks. We also propose a framework that assigns a level of explainability to each XAI malware analysis model, based on the security features involved in each method. In summary, the proposed project focuses on combining XAI and malware analysis to apply XAI models for scrutinizing the opaque nature of AI systems and their applications to malware analysis.},
  archive      = {J_CSUR},
  doi          = {10.1145/3677374},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive analysis of explainable AI for malware hunting},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Video unsupervised domain adaptation with deep learning: A
comprehensive survey. <em>CSUR</em>, <em>56</em>(12), 1–36. (<a
href="https://doi.org/10.1145/3679010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video analysis tasks such as action recognition have received increasing research interest with growing applications in fields such as smart healthcare, thanks to the introduction of large-scale datasets and deep learning based representations. However, video models trained on existing datasets suffer from significant performance degradation when deployed directly to real-world applications due to domain shifts between the training public video datasets (source video domains) and real-world videos (target video domains). Further, with the high cost of video annotation, it is more practical to use unlabeled videos for training. To tackle performance degradation and address concerns in high video annotation cost uniformly, video unsupervised domain adaptation (VUDA) is introduced to adapt video models from the labeled source domain to the unlabeled target domain by alleviating video domain shift, improving the generalizability and portability of video models. This article surveys recent progress in VUDA with deep learning. We begin with the motivation of VUDA, followed by its definition, and recent progress of methods for both closed-set VUDA and VUDA under different scenarios, and current benchmark datasets for VUDA research. Eventually, future directions are provided to promote further VUDA research. The repository of this survey is provided at https://github.com/xuyu0010/awesome-video-domain-adaptation .},
  archive      = {J_CSUR},
  doi          = {10.1145/3679010},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Video unsupervised domain adaptation with deep learning: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review and benchmark of feature importance methods for
neural networks. <em>CSUR</em>, <em>56</em>(12), 1–30. (<a
href="https://doi.org/10.1145/3679012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature attribution methods (AMs) are a simple means to provide explanations for the predictions of black-box models such as neural networks. Due to their conceptual differences, the numerous different methods, however, yield ambiguous explanations. While this allows for obtaining different insights into the model, it also complicates the decision regarding which method to adopt. This article summarizes the current state of the art regarding AMs, which includes the requirements and desiderata of the methods themselves as well as the properties of their explanations. Based on a survey of existing methods, a representative subset consisting of the δ-sensitivity index, permutation feature importance, variance-based feature importance in artificial neural networks and DeepSHAP, is described in greater detail and, for the first time, benchmarked in a regression context. Specifically for this purpose, a new verification strategy for model-specific AMs is proposed. As expected, the explanations’ agreement with the intuition and among each other clearly depends on the AMs’ properties. This has two implications. First, careful reasoning about the selection of an AM is required. Second, it is recommended to apply multiple AMs and combine their insights in order to reduce the model’s opacity even further.},
  archive      = {J_CSUR},
  doi          = {10.1145/3679012},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-30},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review and benchmark of feature importance methods for neural networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). When federated learning meets privacy-preserving
computation. <em>CSUR</em>, <em>56</em>(12), 1–36. (<a
href="https://doi.org/10.1145/3679013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, with the development of artificial intelligence (AI), privacy issues attract wide attention from society and individuals. It is desirable to make the data available but invisible, i.e., to realize data analysis and calculation without disclosing the data to unauthorized entities. Federated learning (FL) has emerged as a promising privacy-preserving computation method for AI. However, new privacy issues have arisen in FL-based application, because various inference attacks can still infer relevant information about the raw data from local models or gradients. This will directly lead to the privacy disclosure. Therefore, it is critical to resist these attacks to achieve complete privacy-preserving computation. In light of the overwhelming variety and a multitude of privacy-preserving computation protocols, we survey these protocols from a series of perspectives to supply better comprehension for researchers and scholars. Concretely, the classification of attacks is discussed, including four kinds of inference attacks as well as malicious server and poisoning attack. Besides, this article systematically captures the state-of-the-art of privacy-preserving computation protocols by analyzing the design rationale, reproducing the experiment of classic schemes, and evaluating all discussed protocols in terms of efficiency and security properties. Finally, this survey identifies a number of interesting future directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3679013},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {When federated learning meets privacy-preserving computation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual tuning. <em>CSUR</em>, <em>56</em>(12), 1–38. (<a
href="https://doi.org/10.1145/3657632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-tuning visual models has been widely shown promising performance on many downstream visual tasks. With the surprising development of pre-trained visual foundation models, visual tuning jumped out of the standard modus operandi that fine-tunes the whole pre-trained model or just the fully connected layer. Instead, recent advances can achieve superior performance than full-tuning the whole pre-trained parameters by updating far fewer parameters, enabling edge devices and downstream applications to reuse the increasingly large foundation models deployed on the cloud. With the aim of helping researchers get the full picture and future directions of visual tuning, this survey characterizes a large and thoughtful selection of recent works, providing a systematic and comprehensive overview of existing work and models. Specifically, it provides a detailed background of visual tuning and categorizes recent visual tuning techniques into five groups: fine-tuning, prompt tuning, adapter tuning, parameter tuning, and remapping tuning. Meanwhile, it offers some exciting research directions for prospective pre-training and various interactions in visual tuning.},
  archive      = {J_CSUR},
  doi          = {10.1145/3657632},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Visual tuning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-learning approaches for few-shot learning: A survey of
recent advances. <em>CSUR</em>, <em>56</em>(12), 1–41. (<a
href="https://doi.org/10.1145/3659943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite its astounding success in learning deeper multi-dimensional data, the performance of deep learning declines on new unseen tasks mainly due to its focus on same-distribution prediction. Moreover, deep learning is notorious for poor generalization from few samples. Meta-learning is a promising approach that addresses these issues by adapting to new tasks with few-shot datasets. This survey first briefly introduces meta-learning and then investigates state-of-the-art meta-learning methods and recent advances in: (i) metric-based, (ii) memory-based, (iii), and learning-based methods. Finally, current challenges and insights for future researches are discussed.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659943},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Meta-learning approaches for few-shot learning: A survey of recent advances},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-task learning in natural language processing: An
overview. <em>CSUR</em>, <em>56</em>(12), 1–32. (<a
href="https://doi.org/10.1145/3663363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning approaches have achieved great success in the field of Natural Language Processing (NLP). However, directly training deep neural models often suffer from overfitting and data scarcity problems that are pervasive in NLP tasks. In recent years, Multi-Task Learning (MTL), which can leverage useful information of related tasks to achieve simultaneous performance improvement on these tasks, has been used to handle these problems. In this article, we give an overview of the use of MTL in NLP tasks. We first review MTL architectures used in NLP tasks and categorize them into four classes, including parallel architecture, hierarchical architecture, modular architecture, and generative adversarial architecture. Then we present optimization techniques on loss construction, gradient regularization, data sampling, and task scheduling to properly train a multi-task model. After presenting applications of MTL in a variety of NLP tasks, we introduce some benchmark datasets. Finally, we make a conclusion and discuss several possible research directions in this field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3663363},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multi-task learning in natural language processing: An overview},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recent advances for aerial object detection: A survey.
<em>CSUR</em>, <em>56</em>(12), 1–36. (<a
href="https://doi.org/10.1145/3664598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aerial object detection, as object detection in aerial images captured from an overhead perspective, has been widely applied in urban management, industrial inspection, and other aspects. However, the performance of existing aerial object detection algorithms is hindered by variations in object scales and orientations attributed to the aerial perspective. This survey presents a comprehensive review of recent advances in aerial object detection. We start with some basic concepts of aerial object detection and then summarize the five imbalance problems of aerial object detection, including scale imbalance, spatial imbalance, objective imbalance, semantic imbalance, and class imbalance. Moreover, we classify and analyze relevant methods and especially introduce the applications of aerial object detection in practical scenarios. Finally, the performance evaluation is presented on two popular aerial object detection datasets VisDrone-DET and DOTA, and we discuss several future directions that could facilitate the development of aerial object detection.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664598},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Recent advances for aerial object detection: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On identity, transaction, and smart contract privacy on
permissioned and permissionless blockchain: A comprehensive survey.
<em>CSUR</em>, <em>56</em>(12), 1–35. (<a
href="https://doi.org/10.1145/3676164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain is a decentralized distributed ledger that combines multiple technologies, including chain data structures, P2P networks, consensus algorithms, cryptography, and smart contracts. This gives the blockchain the characteristics of decentralization, immutability, and traceability. However, blockchain stores smart contracts and transactions in blocks publicly, which poses the risk of data leakage and misuse. For example, by mining and analyzing blockchain transaction information, attackers can correlate transactions with user information, resulting in the disclosure of user privacy. Many current reviews focus on the privacy of permissionless blockchains or cryptocurrencies, requiring more in-depth investigations and detailed categorical analysis. To fill this gap, this work comprehensively reviews the latest and traditional methods related to identity, transaction, and smart contract privacy within permissioned and permissionless blockchains. Additionally, we summarize the existing problems, threats, and challenges of data management in different blockchain architectures. Last, we discuss future research directions for blockchain privacy protection technology, which can offer feasible ideas for researchers to explore further.},
  archive      = {J_CSUR},
  doi          = {10.1145/3676164},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {On identity, transaction, and smart contract privacy on permissioned and permissionless blockchain: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The first principles: Setting the context for a safe and
secure metaverse. <em>CSUR</em>, <em>56</em>(11), 1–29. (<a
href="https://doi.org/10.1145/3665495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The metaverse delivered through converged and amalgamated technologies holds promise. No wonder technology heavyweights, large corporates, research organizations and businesses cutting across industry verticals are racing to put in place a metaverse-first strategy. The bets on consumers rapidly migrating from traditional social networks and collaborative applications to more immersive digital experiences have been placed. However, the transition is not expected to be seamless. Privacy, safety and security concerns abound in the early versions of the metaverse. Increased regulatory oversight and diverse national laws threaten to derail the hype around the metaverse. It is increasingly clear that the final iteration of the metaverse will need to assuage the concerns of individual users while addressing complex legal and regulatory requirements. Thus, a multi-perspective approach needs to be adopted to help set the agenda for the evolution of the metaverse. This research paper examines the different aspects and challenges which the future metaverse will need to address. A set of “first principles” are formulated, which if implemented will lead to the development of an equitable, inclusive, safe and secure metaverse.},
  archive      = {J_CSUR},
  doi          = {10.1145/3665495},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-29},
  shortjournal = {ACM Comput. Surv.},
  title        = {The first principles: Setting the context for a safe and secure metaverse},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Databases in edge and fog environments: A survey.
<em>CSUR</em>, <em>56</em>(11), 1–40. (<a
href="https://doi.org/10.1145/3666001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While a significant number of databases are deployed in cloud environments, pushing part or all data storage and querying planes closer to their sources (i.e., to the edge) can provide advantages in latency, connectivity, privacy, energy, and scalability. This article dissects the advantages provided by databases in edge and fog environments by surveying application domains and discussing the key drivers for pushing database systems to the edge. At the same time, it also identifies the main challenges faced by developers in this new environment and analyzes the mechanisms employed to deal with them. By providing an overview of the current state of edge and fog databases, this survey provides valuable insights into future research directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3666001},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Databases in edge and fog environments: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research progress of EEG-based emotion recognition: A
survey. <em>CSUR</em>, <em>56</em>(11), 1–49. (<a
href="https://doi.org/10.1145/3666002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition based on electroencephalography (EEG) signals has emerged as a prominent research field, facilitating objective evaluation of diseases like depression and motion detection for heathy people. Starting from the basic concepts of temporal-frequency-spatial features in EEG and the methods for cross-domain feature fusion, this survey then extends the overfitting challenge of EEG single-modal to the problem of heterogeneous modality modeling in multimodal conditions. It explores issues such as feature selection, sample scarcity, cross-subject emotional transfer, physiological knowledge discovery, multimodal fusion methods, and modality missing. These findings provide clues for researchers to further investigate emotion recognition based on EEG signals.},
  archive      = {J_CSUR},
  doi          = {10.1145/3666002},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-49},
  shortjournal = {ACM Comput. Surv.},
  title        = {Research progress of EEG-based emotion recognition: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An introduction to the compute express link (CXL)
interconnect. <em>CSUR</em>, <em>56</em>(11), 1–37. (<a
href="https://doi.org/10.1145/3669900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Compute Express Link (CXL) is an open industry-standard interconnect between processors and devices such as accelerators, memory buffers, smart network interfaces, persistent memory, and solid-state drives. CXL offers coherency and memory semantics with bandwidth that scales with PCIe bandwidth while achieving significantly lower latency than PCIe. All major CPU vendors, device vendors, and datacenter operators have adopted CXL as a common standard. This enables an inter-operable ecosystem that supports key computing use cases including highly efficient accelerators, server memory bandwidth and capacity expansion, multi-server resource pooling and sharing, and efficient peer-to-peer communication. This survey provides an introduction to CXL covering the standards CXL 1.0, CXL 2.0, and CXL 3.0. We further survey CXL implementations, discuss CXL&#39;s impact on the datacenter landscape, and future directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3669900},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {An introduction to the compute express link (CXL) interconnect},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-based affective music generation systems: A review of
methods and challenges. <em>CSUR</em>, <em>56</em>(11), 1–34. (<a
href="https://doi.org/10.1145/3672554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music is a powerful medium for altering the emotional state of the listener. In recent years, with significant advancements in computing capabilities, artificial intelligence-based (AI-based) approaches have become popular for creating affective music generation (AMG) systems. Entertainment, healthcare, and sensor-integrated interactive system design are a few of the areas in which AI-based affective music generation (AI-AMG) systems may have a significant impact. Given the surge of interest in this topic, this article aims to provide a comprehensive review of controllable AI-AMG systems. The main building blocks of an AI-AMG system are discussed and existing systems are formally categorized based on the core algorithm used for music generation. In addition, this article discusses the main musical features employed to compose affective music, along with the respective AI-based approaches used for tailoring them. Lastly, the main challenges and open questions in this field, as well as their potential solutions, are presented to guide future research. We hope that this review will be useful for readers seeking to understand the state-of-the-art in AI-AMG systems and gain an overview of the methods used for developing them, thereby helping them explore this field in the future.},
  archive      = {J_CSUR},
  doi          = {10.1145/3672554},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {AI-based affective music generation systems: A review of methods and challenges},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secure UAV (drone) and the great promise of AI.
<em>CSUR</em>, <em>56</em>(11), 1–37. (<a
href="https://doi.org/10.1145/3673225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {UAVs have found their applications in numerous applications from recreational activities to business in addition to military and strategic fields. However, research on UAVs is not going on as quickly as the technology. Especially, when it comes to the security of these devices, the academia is lagging behind the industry. This gap motivates our work in this article as a stepping stone for future research in this area. A comprehensive survey on the security of UAVs and UAV-based systems can help the research community keep pace with, or even lead the industry. Although there are several reviews on UAVs or related areas, there is no recent survey broadly covering various aspects of security. Moreover, none of the existing surveys highlights current and future trends with a focus on the role of an omnipresent technology such as AI. This article endeavors to overcome these shortcomings. We conduct a comprehensive review on security challenges of UAVs as well as the related security controls. Then we develop a future roadmap for research in this area with a focus on the role of AI. The future roadmap is established based on the identified current trends, under-researched topics, and a future look-ahead.},
  archive      = {J_CSUR},
  doi          = {10.1145/3673225},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Secure UAV (Drone) and the great promise of AI},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on relation extraction: Recent
advances and new frontiers. <em>CSUR</em>, <em>56</em>(11), 1–39. (<a
href="https://doi.org/10.1145/3674501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction (RE) involves identifying the relations between entities from underlying content. RE serves as the foundation for many natural language processing (NLP) and information retrieval applications, such as knowledge graph completion and question answering. In recent years, deep neural networks have dominated the field of RE and made noticeable progress. Subsequently, the large pre-trained language models (PLMs) have taken the state-of-the-art RE to a new level. This survey provides a comprehensive review of existing deep learning techniques for RE. First, we introduce RE resources, including datasets and evaluation metrics. Second, we propose a new taxonomy to categorize existing works from three perspectives, i.e., text representation, context encoding, and triplet prediction. Third, we discuss several important challenges faced by RE and summarize potential techniques to tackle these challenges. Finally, we outline some promising future directions and prospects in this field. This survey is expected to facilitate researchers’ collaborative efforts to address the challenges of real-world RE systems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3674501},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on relation extraction: Recent advances and new frontiers},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The landscape of user-centered misinformation interventions
- a systematic literature review. <em>CSUR</em>, <em>56</em>(11), 1–36.
(<a href="https://doi.org/10.1145/3674724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Misinformation is one of the key challenges facing society today. User-centered misinformation interventions as digital countermeasures that exert a direct influence on users represent a promising means to deal with the large amounts of information available. While an extensive body of research on this topic exists, researchers are confronted with a diverse research landscape spanning multiple disciplines. This review systematizes the landscape of user-centered misinformation interventions to facilitate knowledge transfer, identify trends, and enable informed decision-making. Over 6,000 scholarly publications were screened, and a systematic literature review ( N=172 ) was conducted. A taxonomy was derived regarding intervention design (e.g., labels, showing indicators of misinformation, corrections, removal, or visibility reduction of content), user interaction (active or passive), and timing (e.g., pre or post exposure to misinformation or on request of the user). We provide a structured overview of approaches across multiple disciplines and derive six overarching challenges for future research regarding transferability of approaches to (1) novel platforms and (2) emerging video- and image-based misinformation, the sensible combination of automated mechanisms with (3) human experts and (4) user-centered feedback to facilitate comprehensibility, (5) encouraging media literacy without misinformation exposure, and (6) adequately addressing particularly vulnerable users such as older people or adolescents.},
  archive      = {J_CSUR},
  doi          = {10.1145/3674724},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {The landscape of user-centered misinformation interventions - A systematic literature review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of multi-modal knowledge graphs: Technologies and
trends. <em>CSUR</em>, <em>56</em>(11), 1–41. (<a
href="https://doi.org/10.1145/3656579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Knowledge Graphs (KGs) have played a crucial role in the development of advanced knowledge-intensive applications, such as recommender systems and semantic search. However, the human sensory system is inherently multi-modal, as objects around us are often represented by a combination of multiple signals, such as visual and textual. Consequently, Multi-modal Knowledge Graphs (MMKGs), which combine structured knowledge representation with multiple modalities, represent a powerful extension of KGs. Although MMKGs can handle certain types of tasks (e.g., visual query answering) or queries that standard KGs cannot process, and they can effectively tackle some standard problems (e.g., entity alignment), we lack a widely accepted definition of MMKG. In this survey, we provide a rigorous definition of MMKGs along with a classification scheme based on how existing approaches address four fundamental challenges: representation, fusion, alignment, and translation, which are crucial to improving an MMKG. Our classification scheme is flexible and allows for easy incorporation of new approaches, as well as a comparison of two approaches in terms of how they address one of the fundamental challenges mentioned above. As the first comprehensive survey of MMKG, this article aims at inspiring and provide a reference for relevant researchers in the field of Artificial Intelligence.},
  archive      = {J_CSUR},
  doi          = {10.1145/3656579},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of multi-modal knowledge graphs: Technologies and trends},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic literature review on reasons and approaches for
accurate effort estimations in agile. <em>CSUR</em>, <em>56</em>(11),
1–37. (<a href="https://doi.org/10.1145/3663365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Accurate effort estimation is crucial for planning in Agile iterative development. Agile estimation generally relies on consensus-based methods like planning poker, which require less time and information than other formal methods (e.g., COSMIC) but are prone to inaccuracies. Understanding the common reasons for inaccurate estimations and how proposed approaches can assist practitioners is essential. However, prior systematic literature reviews (SLR) only focus on the estimation practices (e.g., References [ 26 , 127 ]) and the effort estimation approaches (e.g., Reference [ 6 ]). Aim: We aim at identifing themes of reasons for inaccurate estimations and classify approaches to improve effort estimation. Method: We conducted an SLR and identified the key themes and a taxonomy. Results: The reasons for inaccurate estimation are related to information quality, team, estimation practice, project management, and business influences. The effort estimation approaches were the most investigated in the literature, while only a few aim to support the effort estimation process. Yet, few automated approaches are at risk of data leakage and indirect validation scenarios. Recommendations: Practitioners should enhance the quality of information for effort estimation, potentially by adopting an automated approach. Future research should aim at improving the information quality, while avoiding data leakage and indirect validation scenarios.},
  archive      = {J_CSUR},
  doi          = {10.1145/3663365},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on reasons and approaches for accurate effort estimations in agile},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of symbolic, subsymbolic and hybrid methods for
sequential decision making. <em>CSUR</em>, <em>56</em>(11), 1–36. (<a
href="https://doi.org/10.1145/3663366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of Sequential Decision Making (SDM), two paradigms have historically vied for supremacy: Automated Planning (AP) and Reinforcement Learning (RL). In the spirit of reconciliation, this article reviews AP, RL and hybrid methods (e.g., novel learn to plan techniques) for solving Sequential Decision Processes (SDPs), focusing on their knowledge representation: symbolic, subsymbolic, or a combination. Additionally, it also covers methods for learning the SDP structure. Finally, we compare the advantages and drawbacks of the existing methods and conclude that neurosymbolic AI poses a promising approach for SDM, since it combines AP and RL with a hybrid knowledge representation.},
  archive      = {J_CSUR},
  doi          = {10.1145/3663366},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review of symbolic, subsymbolic and hybrid methods for sequential decision making},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey on redundancy based-fault tolerance methods for
processors and hardware accelerators - trends in quantum computing,
heterogeneous systems and reliability. <em>CSUR</em>, <em>56</em>(11),
1–76. (<a href="https://doi.org/10.1145/3663672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid progress in CMOS technology since the late 1990s has increased the vulnerability of processors toward faults. Subsequently, the focus of computer architects has shifted toward designing fault-tolerance methods for processor architectures. Concurrently, chip designers have encountered high-order challenges for designing fault-tolerant processor architectures. For processor cores, redundancy-based fault-tolerance methods for fault detection at the core, micro-architectural, thread, and software levels are discussed. Similar applicable redundancy-based fault-tolerance methods for cache memory and hardware accelerators are also presented in the article. Recent trends in fault-tolerant quantum computing and quantum error correction are also discussed. The classification of state-of-the-art techniques presented will help researchers organize their work on established lines.},
  archive      = {J_CSUR},
  doi          = {10.1145/3663672},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-76},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on redundancy based-fault tolerance methods for processors and hardware accelerators - Trends in quantum computing, heterogeneous systems and reliability},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synthetic data for deep learning in computer vision &amp;
medical imaging: A means to reduce data bias. <em>CSUR</em>,
<em>56</em>(11), 1–37. (<a
href="https://doi.org/10.1145/3663759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-learning (DL) performs well in computer-vision and medical-imaging automated decision-making applications. A bottleneck of DL stems from the large amount of labelled data required to train accurate models that generalise well. Data scarcity and imbalance are common problems in imaging applications that can lead DL models towards biased decision making. A solution to this problem is synthetic data. Synthetic data is an inexpensive substitute to real data for improved accuracy and generalisability of DL models. This survey reviews the recent methods published in relation to the creation and use of synthetic data for computer-vision and medical-imaging DL applications. The focus will be on applications that utilised synthetic data to improve DL models by either incorporating an increased diversity of data that is difficult to obtain in real life, or by reducing a bias caused by class imbalance. Computer-graphics software and generative networks are the most popular data generation techniques encountered in the literature. We highlight their suitability for typical computer-vision and medical-imaging applications, and present promising avenues for research to overcome their computational and theoretical limitations.},
  archive      = {J_CSUR},
  doi          = {10.1145/3663759},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Synthetic data for deep learning in computer vision &amp; medical imaging: A means to reduce data bias},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Creativity and machine learning: A survey. <em>CSUR</em>,
<em>56</em>(11), 1–41. (<a
href="https://doi.org/10.1145/3664595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing interest in the area of machine learning and creativity. This survey presents an overview of the history and the state of the art of computational creativity theories, key machine learning techniques (including generative deep learning), and corresponding automatic evaluation methods. After presenting a critical discussion of the key contributions in this area, we outline the current research challenges and emerging opportunities in this field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664595},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Creativity and machine learning: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of explainable fashion compatibility modeling
methods. <em>CSUR</em>, <em>56</em>(11), 1–29. (<a
href="https://doi.org/10.1145/3664614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper reviews methods used in the fashion compatibility recommendation domain. We select methods based on reproducibility, explainability, and novelty aspects and then organize them chronologically and thematically. We presented general characteristics of publicly available datasets that are related to the fashion compatibility recommendation task. Finally, we analyzed the representation bias of datasets, fashion-based algorithms’ sustainability, and explainable model assessment. The paper describes practical problem explanations, methodologies, and published datasets that may serve as an inspiration for further research. The proposed structure of the survey organizes knowledge in the fashion recommendation domain and will be beneficial for those who want to learn the topic from scratch, expand their knowledge, or find a new field for research. Furthermore, the information included in this paper could contribute to developing an effective and ethical fashion-based recommendation system.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664614},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-29},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review of explainable fashion compatibility modeling methods},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on malware detection with graph representation
learning. <em>CSUR</em>, <em>56</em>(11), 1–36. (<a
href="https://doi.org/10.1145/3664649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malware detection has become a major concern due to the increasing number and complexity of malware. Traditional detection methods based on signatures and heuristics are used for malware detection, but unfortunately, they suffer from poor generalization to unknown attacks and can be easily circumvented using obfuscation techniques. In recent years, Machine Learning (ML) and notably Deep Learning (DL) achieved impressive results in malware detection by learning useful representations from data and have become a solution preferred over traditional methods. Recently, the application of Graph Representation Learning (GRL) techniques on graph-structured data has demonstrated impressive capabilities in malware detection. This success benefits notably from the robust structure of graphs, which are challenging for attackers to alter, and their intrinsic explainability capabilities. In this survey, we provide an in-depth literature review to summarize and unify existing works under the common approaches and architectures. We notably demonstrate that Graph Neural Networks (GNNs) reach competitive results in learning robust embeddings from malware represented as expressive graph structures such as Function Call Graphs (FCGs) and Control Flow Graphs (CFGs). This study also discusses the robustness of GRL-based methods to adversarial attacks, contrasts their effectiveness with other ML/DL approaches, and outlines future research for practical deployment.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664649},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on malware detection with graph representation learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient automation of neural network design: A survey on
differentiable neural architecture search. <em>CSUR</em>,
<em>56</em>(11), 1–36. (<a
href="https://doi.org/10.1145/3665138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few years, Differentiable Neural Architecture Search (DNAS) rapidly imposed itself as the trending approach to automate the discovery of deep neural network architectures. This rise is mainly due to the popularity of DARTS (Differentiable ARchitecTure Search), one of the first major DNAS methods. In contrast with previous works based on Reinforcement Learning or Evolutionary Algorithms, DNAS is faster by several orders of magnitude and uses fewer computational resources. In this comprehensive survey, we focused specifically on DNAS and reviewed recent approaches in this field. Furthermore, we proposed a novel challenge-based taxonomy to classify DNAS methods. We also discussed the contributions brought to DNAS in the past few years and its impact on the global NAS field. Finally, we concluded by giving some insights into future research directions for the DNAS field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3665138},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Efficient automation of neural network design: A survey on differentiable neural architecture search},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of olfactory display designs for virtual reality
environments. <em>CSUR</em>, <em>56</em>(11), 1–35. (<a
href="https://doi.org/10.1145/3665243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Virtual Reality continues to evolve to provide an ever-greater sense of immersion to the user. However, VR experiences are still primarily constrained through the human senses of vision and audition, with some interest in haptic (mainly vibrotactile) applications. Only recently have olfactory displays—technologies that generate and deliver scent stimuli—been examined to provide the sense of smell to the human olfactory organ in virtual environments. This article presents a classification and review of olfactory-enhanced virtual reality systems, particularly those that deployed a Head-mounted Display or Cave Automatic Virtual Environment system. In addition, the article provides a discussion of the various technological and design challenges for developing an olfactory display suitable for enhancing virtual reality experiences. Finally, the article proposes future perspectives on the field and includes a table summarizing the characteristics and features of the reviewed systems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3665243},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review of olfactory display designs for virtual reality environments},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human image generation: A comprehensive survey.
<em>CSUR</em>, <em>56</em>(11), 1–39. (<a
href="https://doi.org/10.1145/3665869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image and video synthesis has become a blooming topic in computer vision and machine learning communities along with the developments of deep generative models, due to its great academic and application value. Many researchers have been devoted to synthesizing high-fidelity human images as one of the most commonly seen object categories in daily lives, where a large number of studies are performed based on various models, task settings, and applications. Thus, it is necessary to give a comprehensive overview on these variant methods on human image generation. In this article, we divide human image generation techniques into three paradigms, i.e., data-driven methods, knowledge-guided methods, and hybrid methods. For each paradigm, the most representative models and the corresponding variants are presented, where the advantages and characteristics of different methods are summarized in terms of model architectures. The main public human image datasets and evaluation metrics in the literature are also summarized. Furthermore, due to the wide application potential, the typical downstream usages of synthesized human images are covered. Finally, the challenges and potential opportunities of human image generation are discussed to shed light on future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3665869},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Human image generation: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning with confidential computing: A
systematization of knowledge. <em>CSUR</em>, <em>56</em>(11), 1–40. (<a
href="https://doi.org/10.1145/3670007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy and security challenges in Machine Learning (ML) have become increasingly severe, along with ML’s pervasive development and the recent demonstration of large attack surfaces. As a mature system-oriented approach, Confidential Computing has been utilized in both academia and industry to mitigate privacy and security issues in various ML scenarios. In this article, the conjunction between ML and Confidential Computing is investigated. We systematize the prior work on Confidential Computing-assisted ML techniques that provide (i ) confidentiality guarantees and (ii ) integrity assurances and discuss their advanced features and drawbacks. Key challenges are further identified, and we provide dedicated analyses of the limitations in existing Trusted Execution Environment (TEE) systems for ML use cases. Finally, prospective works are discussed, including grounded privacy definitions for closed-loop protection, partitioned executions of efficient ML, dedicated TEE-assisted designs for ML, TEE-aware ML, and ML full pipeline guarantees. By providing these potential solutions in our systematization of knowledge, we aim to build the bridge to help achieve a much stronger TEE-enabled ML for privacy guarantees without introducing computation and system costs.},
  archive      = {J_CSUR},
  doi          = {10.1145/3670007},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Machine learning with confidential computing: A systematization of knowledge},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). “Are you feeling sick?” – a systematic literature review of
cybersickness in virtual reality. <em>CSUR</em>, <em>56</em>(11), 1–38.
(<a href="https://doi.org/10.1145/3670008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cybersickness (CS), also known as visually induced motion sickness (VIMS), is a condition that can affect individuals when they interact with virtual reality (VR) technology. This condition is characterized by symptoms such as nausea, dizziness, headaches, eye fatigue, and so on, and can be caused by a variety of factors. Finding a feasible solution to reduce the impact of CS is extremely important as it will greatly enhance the overall user experience and make VR more appealing to a wider range of people. We have carefully compiled a list of 223 highly pertinent studies to review the current state of research on the most essential aspects of CS. We have provided a novel taxonomy that encapsulates various aspects of CS measurement techniques found in the literature. We have proposed a set of CS mitigation guidelines for both developers and users. We have also discussed various CS-inducing factors and provided a taxonomy that tries to capture the same. Overall, our work provides a comprehensive overview of the current state of research in CS with a particular emphasis on different measurement techniques and CS mitigation strategies, identifies research gaps in the literature, and provides recommendations for future research in the field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3670008},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {“Are you feeling sick?” – a systematic literature review of cybersickness in virtual reality},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain adaptation and generalization of functional medical
data: A systematic survey of brain data. <em>CSUR</em>, <em>56</em>(10),
1–39. (<a href="https://doi.org/10.1145/3654664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the excellent capabilities of machine learning algorithms, their performance deteriorates when the distribution of test data differs from the distribution of training data. In medical data research, this problem is exacerbated by its connection to human health, expensive equipment, and meticulous setups. Consequently, achieving domain generalizations and domain adaptations under distribution shifts is an essential step in the analysis of medical data. As the first systematic review of domain generalization and domain adaptation on functional brain signals, the article discusses and categorizes various methods, tasks, and datasets in this field. Moreover, it discusses relevant directions for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3654664},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Domain adaptation and generalization of functional medical data: A systematic survey of brain data},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security, privacy, and decentralized trust management in
VANETs: A review of current research and future directions.
<em>CSUR</em>, <em>56</em>(10), 1–39. (<a
href="https://doi.org/10.1145/3656166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular Ad Hoc Networks (VANETs) are powerful platforms for vehicular data services and applications. The increasing number of vehicles has made the vehicular network diverse, dynamic, and large-scale, making it difficult to meet the 5G network’s demanding requirements. Decentralized systems are interesting and provide attractive services because they are publicly available (transparency), have an append-only ledger (robust integrity protection), remove single points of failure, and enable distributed key management and communication in a peer-to-peer network. Researchers dedicated substantial efforts to advancing vehicle communications, however conventional cryptographic mechanisms are insufficient which enabled us to look at decentralized technologies. Therefore, we revisit decentralized approaches with VANETs. Endpoint devices hold a wallet which may incorporate threshold key management methods like MPC wallets, HD Wallets, or multi-party threshold ECDSA/EdDSA/BLS. We also discuss trust management approaches and demonstrate how decentralization can improve integrity, security, privacy, and resilience to single points of failure. We also conduct a comprehensive review, comparing them with current requirements, and the latest authentication and secure communication architectures, which require the involvement of trusted but non-transparent authorities in certificate issuance/revocation. We highlight the limitations of these schemes from PKI deployment and recommend future research, particularly in the realm of quantum cryptography.},
  archive      = {J_CSUR},
  doi          = {10.1145/3656166},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security, privacy, and decentralized trust management in VANETs: A review of current research and future directions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Foundations &amp; trends in multimodal machine learning:
Principles, challenges, and open questions. <em>CSUR</em>,
<em>56</em>(10), 1–42. (<a
href="https://doi.org/10.1145/3656580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal machine learning is a vibrant multi-disciplinary research field that aims to design computer agents with intelligent capabilities such as understanding, reasoning, and learning through integrating multiple communicative modalities, including linguistic, acoustic, visual, tactile, and physiological messages. With the recent interest in video understanding, embodied autonomous agents, text-to-image generation, and multisensor fusion in application domains such as healthcare and robotics, multimodal machine learning has brought unique computational and theoretical challenges to the machine learning community given the heterogeneity of data sources and the interconnections often found between modalities. However, the breadth of progress in multimodal research has made it difficult to identify the common themes and open questions in the field. By synthesizing a broad range of application domains and theoretical frameworks from both historical and recent perspectives, this article is designed to provide an overview of the computational and theoretical foundations of multimodal machine learning. We start by defining three key principles of modality heterogeneity , connections , and interactions that have driven subsequent innovations, and propose a taxonomy of six core technical challenges: representation , alignment , reasoning , generation , transference , and quantification covering historical and recent trends. Recent technical achievements will be presented through the lens of this taxonomy, allowing researchers to understand the similarities and differences across new approaches. We end by motivating several open problems for future research as identified by our taxonomy.},
  archive      = {J_CSUR},
  doi          = {10.1145/3656580},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Foundations &amp; trends in multimodal machine learning: Principles, challenges, and open questions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lightweight deep learning for resource-constrained
environments: A survey. <em>CSUR</em>, <em>56</em>(10), 1–42. (<a
href="https://doi.org/10.1145/3657282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, the dominance of deep learning has prevailed across various domains of artificial intelligence, including natural language processing, computer vision, and biomedical signal processing. While there have been remarkable improvements in model accuracy, deploying these models on lightweight devices, such as mobile phones and microcontrollers, is constrained by limited resources. In this survey, we provide comprehensive design guidance tailored for these devices, detailing the meticulous design of lightweight models, compression methods, and hardware acceleration strategies. The principal goal of this work is to explore methods and concepts for getting around hardware constraints without compromising the model’s accuracy. Additionally, we explore two notable paths for lightweight deep learning in the future: deployment techniques for TinyML and Large Language Models. Although these paths undoubtedly have potential, they also present significant challenges, encouraging research into unexplored areas.},
  archive      = {J_CSUR},
  doi          = {10.1145/3657282},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Lightweight deep learning for resource-constrained environments: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From detection to application: Recent advances in
understanding scientific tables and figures. <em>CSUR</em>,
<em>56</em>(10), 1–39. (<a
href="https://doi.org/10.1145/3657285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tables and figures are usually used to present information in a structured and visual way in scientific documents. Understanding the tables and figures in scientific documents is significant for a series of downstream tasks, such as academic search, scientific knowledge graphs, and so on. Existing studies mainly focus on detecting figures and tables from scientific documents, interpreting their semantics, and integrating them into downstream tasks. However, a systematic and comprehensive literature review on the mining and application of tables and figures in academic papers is still missing. In this article, we introduce the research framework and the whole pipeline for understanding tables and figures, including detection, structural analysis, interpretation, and application. We deliver a thorough analysis of benchmark datasets, recent techniques, and their pros and cons. Additionally, a quantitative analysis of the effectiveness of different models on popular benchmarks is presented. We further outline several important applications that exploit the semantics of scientific tables and figures. Finally, we highlight the challenges and some potential directions for future research. We believe this is the first comprehensive survey in understanding scientific tables and figures that covers the landscape from detection to application.},
  archive      = {J_CSUR},
  doi          = {10.1145/3657285},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {From detection to application: Recent advances in understanding scientific tables and figures},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on the applications of semi-supervised learning to
cyber-security. <em>CSUR</em>, <em>56</em>(10), 1–41. (<a
href="https://doi.org/10.1145/3657647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning’s widespread application owes to its ability to develop accurate and scalable models. In cyber-security, where labeled data is scarce, Semi-Supervised Learning (SSL) emerges as a potential solution. SSL excels at tasks challenging traditional supervised and unsupervised algorithms by leveraging limited labeled data alongside abundant unlabeled data. This article presents a comprehensive survey of SSL in cyber-security, focusing on countering diverse cybercrimes, particularly intrusion detection. Despite its potential, a notable research gap persists, with few recent studies comprehensively reviewing SSL’s application in cyber-security. This study examines state-of-the-art SSL techniques tailored for cyber-security to address this gap. Relevant methods are identified, and their effectiveness is evaluated to empower researchers and practitioners with insights to enhance cyber-security measures. This work sheds light on SSL’s potential in addressing data scarcity in cyber-security domains in addition to outlining new research directions to advance this crucial field. By bridging this research gap, this manuscript paves the way for enhanced cyber-threat detection and mitigation in an increasingly interconnected world.},
  archive      = {J_CSUR},
  doi          = {10.1145/3657647},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on the applications of semi-supervised learning to cyber-security},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maintenance operations on cloud, edge, and IoT environments:
Taxonomy, survey, and research challenges. <em>CSUR</em>,
<em>56</em>(10), 1–38. (<a
href="https://doi.org/10.1145/3659097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of the Internet of Things (IoT) introduced new classes of applications whose latency and bandwidth requirements could not be satisfied by the traditional Cloud Computing model. Consequently, the Internet Technology community promoted the cooperation of two paradigms, Cloud Computing and Edge Computing, combining large-scale computing power and real-time processing capabilities. A significant management challenge in such complex infrastructure concerns the development of efficient maintenance strategies to preserve the environment’s performance and security. While the abundant resources from the academic literature could support the design of novel maintenance solutions, extracting actionable insights from the existing approaches is challenging, given the massive number of published papers. Furthermore, existing review papers, which could help summarize the state-of-the-art, scope their investigations to the maintenance of certain components in particular scenarios. This work fills this gap with a broader literature analysis that covers maintenance strategies targeting physical and logical components in cloud, edge, and IoT environments. First, we introduce a taxonomy that organizes existing solutions according to several characteristics. Then, we review the literature following the taxonomy structure to facilitate the understanding of the research landscape and the comparison between existing works. Finally, we shed light on open challenges that represent promising research directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659097},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Maintenance operations on cloud, edge, and IoT environments: Taxonomy, survey, and research challenges},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Systems interoperability types: A tertiary study.
<em>CSUR</em>, <em>56</em>(10), 1–37. (<a
href="https://doi.org/10.1145/3659098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interoperability has been a focus of attention over at least four decades, with the emergence of several interoperability types (or levels), diverse models, frameworks, and solutions, also as a result of a continuous effort from different domains. The current heterogeneity in technologies such as blockchain, IoT and new application domains such as Industry 4.0 brings not only new interaction possibilities but also challenges for interoperability. Moreover, confusion and ambiguity in the current understanding of interoperability types exist, hampering stakeholders’ communication and decision-making. This work presents an updated panorama of software-intensive systems interoperability with particular attention to its types. For this, we conducted a tertiary study that scrutinized 37 secondary studies published from 2012 to 2023, from which we found 36 interoperability types associated with 117 different definitions, besides 13 interoperability models and six frameworks in various domains. This panorama reveals that the concern with interoperability has migrated from technical to social-technical issues going beyond the software systems’ boundary and still requiring solving many open issues. We also address the urgent actions and also potential research opportunities to leverage interoperability as a multidisciplinary research field to achieve low-coupled, cost-effective, and interoperable systems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659098},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Systems interoperability types: A tertiary study},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchained federated learning for internet of things: A
comprehensive survey. <em>CSUR</em>, <em>56</em>(10), 1–37. (<a
href="https://doi.org/10.1145/3659099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for intelligent industries and smart services based on big data is rising rapidly with the increasing digitization and intelligence of the modern world. This survey comprehensively reviews Blockchained Federated Learning (BlockFL) that joins the benefits of both Blockchain and Federated Learning to provide a secure and efficient solution for the demand. We compare the existing BlockFL models in four Internet-of-Things (IoT) application scenarios: Personal IoT (PIoT), Industrial IoT (IIoT), Internet of Vehicles (IoV), and Internet of Health Things (IoHT), with a focus on security and privacy, trust and reliability, efficiency, and data diversity. Our analysis shows that the features of decentralization and transparency make BlockFL a secure and effective solution for distributed model training, while the overhead and compatibility still need further study. It also reveals the unique challenges of each domain presents unique challenges, e.g., the requirement of accommodating dynamic environments in IoV and the high demands of identity and permission management in IoHT, in addition to some common challenges identified, such as privacy, resource constraints, and data heterogeneity. Furthermore, we examine the existing technologies that can benefit BlockFL, thereby helping researchers and practitioners to make informed decisions about the selection and development of BlockFL for various IoT application scenarios.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659099},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Blockchained federated learning for internet of things: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Topology-aware federated learning in edge computing: A
comprehensive survey. <em>CSUR</em>, <em>56</em>(10), 1–41. (<a
href="https://doi.org/10.1145/3659205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultra-low latency requirements of 5G/6G applications and privacy constraints call for distributed machine learning systems to be deployed at the edge. With its simple yet effective approach, federated learning (FL) is a natural solution for massive user-owned devices in edge computing with distributed and private training data. FL methods based on FedAvg typically follow a naive star topology, ignoring the heterogeneity and hierarchy of the volatile edge computing architectures and topologies in reality. Several other network topologies exist and can address the limitations and bottlenecks of the star topology. This motivates us to survey network topology-related FL solutions. In this paper, we conduct a comprehensive survey of the existing FL works focusing on network topologies. After a brief overview of FL and edge computing networks, we discuss various edge network topologies as well as their advantages and disadvantages. Lastly, we discuss the remaining challenges and future works for applying FL to topology-specific edge networks.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659205},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Topology-aware federated learning in edge computing: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Applying generative machine learning to intrusion detection:
A systematic mapping study and review. <em>CSUR</em>, <em>56</em>(10),
1–33. (<a href="https://doi.org/10.1145/3659575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion Detection Systems (IDSs) are an essential element of modern cyber defense, alerting users to when and where cyber-attacks occur. Machine learning can enable IDSs to further distinguish between benign and malicious behaviors, but it comes with several challenges, including lack of quality training data and high false-positive rates. Generative Machine Learning Models (GMLMs) can help overcome these challenges. This article offers an in-depth exploration of GMLMs’ application to intrusion detection. It gives (1) a systematic mapping study of research at the intersection of GMLMs and IDSs, and (2) a detailed review providing insights and directions for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659575},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Applying generative machine learning to intrusion detection: A systematic mapping study and review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A challenge-based survey of e-recruitment recommendation
systems. <em>CSUR</em>, <em>56</em>(10), 1–33. (<a
href="https://doi.org/10.1145/3659942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-recruitment recommendation systems recommend jobs to job seekers and job seekers to recruiters. The recommendations are generated based on the suitability of job seekers for positions and on job seekers’ and recruiters’ preferences. Therefore, e-recruitment recommendation systems may greatly impact people’s careers. Moreover, by affecting the hiring processes of the companies, e-recruitment recommendation systems play an important role in shaping the competitive edge of companies. Hence, it seems prudent to consider what (unique) challenges there are for recommendation systems in e-recruitment. Existing surveys on this topic discuss past studies from the algorithmic perspective, e.g., by categorizing them into collaborative filtering, content-based, and hybrid methods. This survey, instead, takes a complementary, challenge-based approach. We believe this is more practical for developers facing a concrete e-recruitment design task with a specific set of challenges, and also for researchers that look for impactful research projects in this domain. In this survey, we first identify the main challenges in the e-recruitment recommendation research. Next, we discuss how those challenges have been studied in the literature. Finally, we provide future research directions that we consider most promising in the e-recruitment recommendation domain.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659942},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-33},
  shortjournal = {ACM Comput. Surv.},
  title        = {A challenge-based survey of E-recruitment recommendation systems},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review on the emerging technology of TinyML.
<em>CSUR</em>, <em>56</em>(10), 1–37. (<a
href="https://doi.org/10.1145/3661820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tiny Machine Learning (TinyML) is an emerging technology proposed by the scientific community for developing autonomous and secure devices that can gather, process, and provide results without transferring data to external entities. The technology aims to democratize AI by making it available to more sectors and contribute to the digital revolution of intelligent devices. In this work, a classification of the most common optimization techniques for Neural Network compression is conducted. Additionally, a review of the development boards and TinyML software is presented. Furthermore, the work provides educational resources, a classification of the technology applications, and future directions and concludes with the challenges and considerations.},
  archive      = {J_CSUR},
  doi          = {10.1145/3661820},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review on the emerging technology of TinyML},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of graph neural networks for social recommender
systems. <em>CSUR</em>, <em>56</em>(10), 1–34. (<a
href="https://doi.org/10.1145/3661821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommender systems (SocialRS) simultaneously leverage the user-to-item interactions as well as the user-to-user social relations for the task of generating item recommendations to users. Additionally exploiting social relations is clearly effective in understanding users’ tastes due to the effects of homophily and social influence. For this reason, SocialRS has increasingly attracted attention. In particular, with the advance of graph neural networks (GNN), many GNN-based SocialRS methods have been developed recently. Therefore, we conduct a comprehensive and systematic review of the literature on GNN-based SocialRS. In this survey, we first identify 84 papers on GNN-based SocialRS after annotating 2,151 papers by following the PRISMA framework (preferred reporting items for systematic reviews and meta-analyses). Then, we comprehensively review them in terms of their inputs and architectures to propose a novel taxonomy: (1) input taxonomy includes five groups of input type notations and seven groups of input representation notations; (2) architecture taxonomy includes eight groups of GNN encoder notations, two groups of decoder notations, and 12 groups of loss function notations. We classify the GNN-based SocialRS methods into several categories as per the taxonomy and describe their details. Furthermore, we summarize benchmark datasets and metrics widely used to evaluate the GNN-based SocialRS methods. Finally, we conclude this survey by presenting some future research directions. GitHub repository with the curated list of papers are available at https://github.com/claws-lab/awesome-GNN-social-recsys},
  archive      = {J_CSUR},
  doi          = {10.1145/3661821},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of graph neural networks for social recommender systems},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review on the impact of data representation on model
explainability. <em>CSUR</em>, <em>56</em>(10), 1–21. (<a
href="https://doi.org/10.1145/3662178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, advanced machine learning and artificial intelligence techniques have gained popularity due to their ability to solve problems across various domains with high performance and quality. However, these techniques are often so complex that they fail to provide simple and understandable explanations for the outputs they generate. To address this issue, the field of explainable artificial intelligence has recently emerged. However, most data generated in different domains are inherently structural; that is, they consist of parts and relationships among them. Such data can be represented using either a simple data-structure or form , such as a vector , or a complex data-structure, such as a graph . The effect of this representation form on the explainability and interpretability of machine learning models is not extensively discussed in the literature. In this survey article, we review efficient algorithms proposed for learning from inherently structured data, emphasizing how their representation form affects the explainability of learning models. A conclusion of our literature review is that using complex forms or data-structures for data representation improves not only the learning performance but also the explainability and transparency of the model.},
  archive      = {J_CSUR},
  doi          = {10.1145/3662178},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-21},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review on the impact of data representation on model explainability},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on privacy of personal and non-personal data in
B5G/6G networks. <em>CSUR</em>, <em>56</em>(10), 1–37. (<a
href="https://doi.org/10.1145/3662179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The upcoming Beyond 5G (B5G) and 6G networks are expected to provide enhanced capabilities such as ultra-high data rates, dense connectivity, and high scalability. It opens many possibilities for a new generation of services driven by Artificial Intelligence (AI) and billions of interconnected smart devices. However, with this expected massive upgrade, the privacy of people, organisations, and states is becoming a rising concern. The recent introduction of privacy laws and regulations for personal and non-personal data signals that global awareness is emerging in the current privacy landscape. Yet, many gaps need to be identified in the case of two data types. If not detected, then they can lead to significant privacy leakages and attacks that will affect billions of people and organisations who utilise B5G/6G. This survey is a comprehensive study of personal and non-personal data privacy in B5G/6G to identify the current progress and future directions to ensure data privacy. We provide a detailed comparison of the two data types and a set of related privacy goals for B5G/6G. Next, we bring data privacy issues with possible solutions. This article also provides future directions to preserve personal and non-personal data privacy in future networks.},
  archive      = {J_CSUR},
  doi          = {10.1145/3662179},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on privacy of personal and non-personal data in B5G/6G networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on variational autoencoders in recommender systems.
<em>CSUR</em>, <em>56</em>(10), 1–40. (<a
href="https://doi.org/10.1145/3663364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have become an important instrument to connect people to information. Sparse, complex, and rapidly growing data presents new challenges to traditional recommendation algorithms. To overcome these challenges, various deep learning-based recommendation algorithms have been proposed. Among these, Variational AutoEncoder (VAE) -based recommendation methods stand out. VAEs are based on a flexible probabilistic framework, which is robust for data sparsity and compatible with other deep learning-based models for dealing with multimodal data. In addition, the deep generative structure of VAEs helps to perform Bayesian inference in an efficient manner. VAE-based recommendation algorithms have given rise to many novel graphical models, and they have achieved promising performance. In this article, we conduct a survey to systematically summarize recent VAE-based recommendation algorithms. Four frequently used characteristics of VAE-based recommendation algorithms are summarized, and a taxonomy of VAE-based recommendation algorithms is proposed. We also identify future research directions for, advanced perspectives on, and the application of VAEs in recommendation algorithms, to inspire future work on VAEs for recommender systems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3663364},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {10},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on variational autoencoders in recommender systems},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on automatic generation of figurative language:
From rule-based systems to large language models. <em>CSUR</em>,
<em>56</em>(10), 1–34. (<a
href="https://doi.org/10.1145/3654795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Figurative language generation (FLG) is the task of reformulating a given text to include a desired figure of speech, such as a hyperbole, a simile, and several others, while still being faithful to the original context. This is a fundamental, yet challenging task in Natural Language Processing (NLP), which has recently received increased attention due to the promising performance brought by pre-trained language models. Our survey provides a systematic overview of the development of FLG, mostly in English, starting with the description of some common figures of speech, their corresponding generation tasks, and datasets. We then focus on various modelling approaches and assessment strategies, leading us to discussing some challenges in this field, and suggesting some potential directions for future research. To the best of our knowledge, this is the first survey that summarizes the progress of FLG including the most recent development in NLP. We also organize corresponding resources, e.g., article lists and datasets, and make them accessible in an open repository. We hope this survey can help researchers in NLP and related fields to easily track the academic frontier, providing them with a landscape and a roadmap of this area.},
  archive      = {J_CSUR},
  doi          = {10.1145/3654795},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {10},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on automatic generation of figurative language: From rule-based systems to large language models},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neuromorphic perception and navigation for mobile robots: A
review. <em>CSUR</em>, <em>56</em>(10), 1–37. (<a
href="https://doi.org/10.1145/3656469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the fast and unstoppable evolution of robotics and artificial intelligence, effective autonomous navigation in real-world scenarios has become one of the most pressing challenges in the literature. However, demanding requirements, such as real-time operation, energy and computational efficiency, robustness, and reliability, make most current solutions unsuitable for real-world challenges. Thus, researchers are fostered to seek innovative approaches, such as bio-inspired solutions. Indeed, animals have the intrinsic ability to efficiently perceive, understand, and navigate their unstructured surroundings. To do so, they exploit self-motion cues, proprioception, and visual flow in a cognitive process to map their environment and locate themselves within it. Computational neuroscientists aim to answer “how” and “why” such cognitive processes occur in the brain, to design novel neuromorphic sensors and methods that imitate biological processing. This survey aims to comprehensively review the application of brain-inspired strategies to autonomous navigation. The paper delves into areas such as neuromorphic perception, asynchronous event processing, energy-efficient and adaptive learning, and the emulation of brain regions vital for navigation, such as the hippocampus and entorhinal cortex.},
  archive      = {J_CSUR},
  doi          = {10.1145/3656469},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {10},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Neuromorphic perception and navigation for mobile robots: A review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adapting neural networks at runtime: Current trends in
at-runtime optimizations for deep learning. <em>CSUR</em>,
<em>56</em>(10), 1–40. (<a
href="https://doi.org/10.1145/3657283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive optimization methods for deep learning adjust the inference task to the current circumstances at runtime to improve the resource footprint while maintaining the model’s performance. These methods are essential for the widespread adoption of deep learning, as they offer a way to reduce the resource footprint of the inference task while also having access to additional information about the current environment. This survey covers the state-of-the-art at-runtime optimization methods, provides guidance for readers to choose the best method for their specific use-case, and also highlights current research gaps in this field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3657283},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {10},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Adapting neural networks at runtime: Current trends in at-runtime optimizations for deep learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence for web 3.0: A comprehensive survey.
<em>CSUR</em>, <em>56</em>(10), 1–39. (<a
href="https://doi.org/10.1145/3657284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web 3.0 is the next generation of the Internet built on decentralized technologies such as blockchain and cryptography. It is born to solve the problems faced by the previous generation of the Internet such as imbalanced distribution of interests, monopoly of platform resources, and leakage of personal privacy. In this survey, we discuss the latest development status of Web 3.0 and the application of emerging AI technologies in it. First, we investigate the current successful practices of Web 3.0 and various components in the current Web 3.0 ecosystem and thus propose the hierarchical architecture of the Web 3.0 ecosystem from the perspective of application scenarios. The architecture we proposed contains four layers: data management, value circulation, ecological governance, and application scenarios. We dive into the current state of development and the main challenges and issues present in each layer. In this context, we find that AI technology will have great potential. We first briefly introduce the role that artificial intelligence technology may play in the development of Web 3.0. Then, we conduct an in-depth analysis of the current application status of artificial intelligence technology in the four layers of Web 3.0 and provide some insights into its potential future development directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3657284},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {10},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Artificial intelligence for web 3.0: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic literature review of novelty detection in data
streams: Challenges and opportunities. <em>CSUR</em>, <em>56</em>(10),
1–37. (<a href="https://doi.org/10.1145/3657286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novelty detection in data streams is the task of detecting concepts that were not known prior, in streams of data. Many machine learning algorithms have been proposed to detect these novelties, as well as integrate them. This study provides a systematic literature review of the state of novelty detection in data streams, including its advancement in recent years, its main challenges and solutions, an updated taxonomy for the classification of the proposed frameworks, and a comparative analysis of different key algorithms in this field. Additionally, we highlight ongoing challenges and future research directions that could be tackled moving forward.},
  archive      = {J_CSUR},
  doi          = {10.1145/3657286},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {10},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review of novelty detection in data streams: Challenges and opportunities},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UAV-assisted IoT applications, QoS requirements and
challenges with future research directions. <em>CSUR</em>,
<em>56</em>(10), 1–35. (<a
href="https://doi.org/10.1145/3657287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV)-assisted Internet of Things application communication is an emerging concept that effectuates the foreknowledge of innovative technologies. With the accelerated advancements in IoT applications, the importance of this technology became more impactful and persistent. Moreover, this technology has demonstrated useful contributions across various domains, ranging from general to specific applications. Examples include wildfire monitoring, coastal area monitoring, deforestation monitoring, and sensitive military operations, where human access is limited or not feasible. These examples underscore the technology’s importance in scenarios where direct human involvement is challenging or impossible. Although this technology offers numerous benefits, it is essential to note that it also faces several challenges. Among these, Quality of Service (QoS) is a key concern, which limits its useability in various applications. Unfortunately, most researchers in the present literature have overlooked this important factor without giving it considerable attention. To fill this gap, we are presenting a systematic review of the present literature associated with the QoS metrics of this emerging technology from 2015 to 2023 to highlight their contributions and limitations. Based on the systematic review, we highlight the open challenges of this technology to set a roadmap for futuristic research. Finally, we compared each portion of this work with the previously published review articles to confirm the essence of this work, along with an explanation of why this survey is needed and in-time.},
  archive      = {J_CSUR},
  doi          = {10.1145/3657287},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {10},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {UAV-assisted IoT applications, QoS requirements and challenges with future research directions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic survey of deep learning-based single-image
super-resolution. <em>CSUR</em>, <em>56</em>(10), 1–40. (<a
href="https://doi.org/10.1145/3659100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-image super-resolution (SISR) is an important task in image processing, which aims to enhance the resolution of imaging systems. Recently, SISR has made a huge leap and has achieved promising results with the help of deep learning (DL). In this survey, we give an overview of DL-based SISR methods and group them according to their design targets. Specifically, we first introduce the problem definition, research background, and the significance of SISR. Secondly, we introduce some related works, including benchmark datasets, upsampling methods, optimization objectives, and image quality assessment methods. Thirdly, we provide a detailed investigation of SISR and give some domain-specific applications of it. Fourthly, we present the reconstruction results of some classic SISR methods to intuitively know their performance. Finally, we discuss some issues that still exist in SISR and summarize some new trends and future directions. This is an exhaustive survey of SISR, which can help researchers better understand SISR and inspire more exciting research in this field. An investigation project for SISR is provided at https://github.com/CV-JunchengLi/SISR-Survey.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659100},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {10},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic survey of deep learning-based single-image super-resolution},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deceived by immersion: A systematic analysis of deceptive
design in extended reality. <em>CSUR</em>, <em>56</em>(10), 1–25. (<a
href="https://doi.org/10.1145/3659945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The well-established deceptive design literature has focused on conventional user interfaces. With the rise of extended reality (XR), understanding deceptive design’s unique manifestations in this immersive domain is crucial. However, existing research lacks a full, cross-disciplinary analysis that analyzes how XR technologies enable new forms of deceptive design. Our study reviews the literature on deceptive design in XR environments. We use thematic synthesis to identify key themes. We found that XR’s immersive capabilities and extensive data collection enable subtle and powerful manipulation strategies. We identified eight themes outlining these strategies and discussed existing countermeasures. Our findings show the unique risks of deceptive design in XR, highlighting implications for researchers, designers, and policymakers. We propose future research directions that explore unintentional deceptive design, data-driven manipulation solutions, user education, and the link between ethical design and policy regulations.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659945},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {10},
  pages        = {1-25},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deceived by immersion: A systematic analysis of deceptive design in extended reality},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integration of sensing, communication, and computing for
metaverse: A survey. <em>CSUR</em>, <em>56</em>(10), 1–38. (<a
href="https://doi.org/10.1145/3659946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The metaverse is an Artificial Intelligence (AI) -generated virtual world, in which people can game, work, learn, and socialize. The realization of metaverse not only requires a large amount of computing resources to realize the rendering of the virtual world, but also requires communication resources to realize real-time transmission of massive data to ensure a good user experience. The metaverse is currently moving from fiction to reality with the development of advanced technologies represented by AI, blockchain, extended reality, and Digital Twins (DT) . However, due to the shortage of communication as well as computing resources, how to realize secure and efficient data interaction between the virtual and the real is an important issue for the metaverse. In this article, we first discuss the characteristics and architecture of the metaverse and introduce its enabling technologies. To cope with the conflict between limited resources and user demands, the article next introduces an Integrated Sensing, Communication, and Computing (SCC) technology and describes its basic principles and related characteristics of SCC. After that, solutions based on SCC in the metaverse scenarios are summarized and relevant lessons are summarized. Finally, we discuss some research challenges and open issues.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659946},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {10},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Integration of sensing, communication, and computing for metaverse: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring blockchain technology through a modular lens: A
survey. <em>CSUR</em>, <em>56</em>(9), 242:1–39. (<a
href="https://doi.org/10.1145/3657288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain has attracted significant attention in recent years due to its potential to revolutionize various industries by providing trustlessness. To comprehensively examine blockchain systems, this article presents both a macro-level overview on the most popular blockchain systems, and a micro-level analysis on a general blockchain framework and its crucial components. The macro-level exploration provides a big picture on the endeavors made by blockchain professionals over the years to enhance the blockchain performance while the micro-level investigation details the blockchain building blocks for deep technology comprehension. More specifically, this article introduces a general modular blockchain analytic framework that decomposes a blockchain system into interacting modules and then examines the major modules to cover the essential blockchain components of network, consensus, and distributed ledger at the micro-level. The framework as well as the modular analysis jointly build a foundation for designing scalable, flexible, and application-adaptive blockchains that can meet diverse requirements. Additionally, this article explores popular technologies that can be integrated with blockchain to expand functionality and highlights major challenges. Such a study provides critical insights to overcome the obstacles in designing novel blockchain systems and facilitates the further development of blockchain as a digital infrastructure to service new applications.},
  archive      = {J_CSUR},
  author       = {Minghui Xu and Yihao Guo and Chunchi Liu and Qin Hu and Dongxiao Yu and Zehui Xiong and Dusit (Tao) Niyato and Xiuzhen Cheng},
  doi          = {10.1145/3657288},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {9},
  pages        = {242:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Exploring blockchain technology through a modular lens: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computational politeness in natural language processing: A
survey. <em>CSUR</em>, <em>56</em>(9), 241:1–42. (<a
href="https://doi.org/10.1145/3654660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational approach to politeness is the task of automatically predicting and/or generating politeness in text. This is a pivotal task for conversational analysis, given the ubiquity and challenges of politeness in interactions. The computational approach to politeness has witnessed great interest from the conversational analysis community. This article is a compilation of past works in computational politeness in natural language processing. We view four milestones in the research so far, viz. supervised and weakly supervised feature extraction to identify and induce politeness in a given text, incorporation of context beyond the target text, study of politeness across different social factors, and study the relationship between politeness and various socio-linguistic cues. In this article, we describe the datasets, approaches, trends, and issues in computational politeness research. We also discuss representative performance values and provide pointers to future works, as given in the prior works. In terms of resources to understand the state of the art, this survey presents several valuable illustrations—most prominently, a table summarizing the past papers along different dimensions, such as the types of features, annotation techniques, and datasets used.},
  archive      = {J_CSUR},
  author       = {Priyanshu Priya and Mauajama Firdaus and Asif Ekbal},
  doi          = {10.1145/3654660},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {9},
  pages        = {241:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Computational politeness in natural language processing: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Horizontal federated recommender system: A survey.
<em>CSUR</em>, <em>56</em>(9), 240:1–42. (<a
href="https://doi.org/10.1145/3656165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to underlying privacy-sensitive information in user-item interaction data, the risk of privacy leakage exists in the centralized-training recommender system (RecSys). To this issue, federated learning, a privacy-oriented distributed computing paradigm, is introduced and promotes the crossing field “Federated Recommender System (FedRec).” Regarding data distribution characteristics, there are horizontal, vertical, and transfer variants, where horizontal FedRec (HFedRec) occupies a dominant position. User devices can personally participate in the horizontal federated architecture, making user-level privacy feasible. Therefore, we target the horizontal point and summarize existing works more elaborately than existing FedRec surveys. First, from the model perspective, we group them into different learning paradigms (e.g., deep learning and meta learning). Second, from the privacy perspective, privacy-preserving techniques are systematically organized (e.g., homomorphic encryption and differential privacy). Third, from the federated perspective, fundamental issues (e.g., communication and fairness) are discussed. Fourth, each perspective has detailed subcategories, and we specifically state their unique challenges with the observation of current progress. Finally, we figure out potential issues and promising directions for future research.},
  archive      = {J_CSUR},
  author       = {Lingyun Wang and Hanlin Zhou and Yinwei Bao and Xiaoran Yan and Guojiang Shen and Xiangjie Kong},
  doi          = {10.1145/3656165},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {9},
  pages        = {240:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Horizontal federated recommender system: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interactive question answering systems: Literature review.
<em>CSUR</em>, <em>56</em>(9), 239:1–38. (<a
href="https://doi.org/10.1145/3657631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question-answering systems are recognized as popular and frequently effective means of information seeking on the web. In such systems, information seekers can receive a concise response to their queries by presenting their questions in natural language. Interactive question answering is a recently proposed and increasingly popular solution that resides at the intersection of question answering and dialogue systems . On the one hand, the user can ask questions in normal language and locate the actual response to her inquiry; on the other hand, the system can prolong the question-answering session into a dialogue if there are multiple probable replies, very few, or ambiguities in the initial request. By permitting the user to ask more questions, interactive question answering enables users to interact with the system and receive more precise results dynamically. This survey offers a detailed overview of the interactive question-answering methods that are prevalent in current literature. It begins by explaining the foundational principles of question-answering systems, hence defining new notations and taxonomies to combine all identified works inside a unified framework. The reviewed published work on interactive question-answering systems is then presented and examined in terms of its proposed methodology, evaluation approaches, and dataset/application domain. We also describe trends surrounding specific tasks and issues raised by the community, so shedding light on the future interests of scholars. Our work is further supported by a GitHub page synthesizing all the major topics covered in this literature study. https://sisinflab.github.io/interactive-question-answering-systems-survey/},
  archive      = {J_CSUR},
  author       = {Giovanni Maria Biancofiore and Yashar Deldjoo and Tommaso Di Noia and Eugenio Di Sciascio and Fedelucio Narducci},
  doi          = {10.1145/3657631},
  journal      = {ACM Computing Surveys},
  month        = {5},
  number       = {9},
  pages        = {239:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Interactive question answering systems: Literature review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intel TDX demystified: A top-down approach. <em>CSUR</em>,
<em>56</em>(9), 238:1–33. (<a
href="https://doi.org/10.1145/3652597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intel Trust Domain Extensions (TDX) is an architectural extension in the 4th Generation Intel Xeon Scalable Processor that supports confidential computing. TDX allows the deployment of virtual machines in the Secure-Arbitration Mode (SEAM) with encrypted CPU state and memory, integrity protection, and remote attestation. TDX aims at enforcing hardware-assisted isolation for virtual machines and minimize the attack surface exposed to host platforms, which are considered to be untrustworthy or adversarial in the confidential computing’s new threat model. TDX can be leveraged by regulated industries or sensitive data holders to outsource their computations and data with end-to-end protection in public cloud infrastructures. This article aims at providing a comprehensive understanding of TDX to potential adopters, domain experts, and security researchers looking to leverage the technology for their own purposes. We adopt a top-down approach, starting with high-level security principles and moving to low-level technical details of TDX. Our analysis is based on publicly available documentation and source code, offering insights from security researchers outside of Intel.},
  archive      = {J_CSUR},
  author       = {Pau-Chen Cheng and Wojciech Ozga and Enriquillo Valdez and Salman Ahmed and Zhongshu Gu and Hani Jamjoom and Hubertus Franke and James Bottomley},
  doi          = {10.1145/3652597},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {238:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Intel TDX demystified: A top-down approach},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extended reality (XR) toward building immersive solutions:
The key to unlocking industry 4.0. <em>CSUR</em>, <em>56</em>(9),
237:1–38. (<a href="https://doi.org/10.1145/3652595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When developing XR applications for Industry 4.0, it is important to consider the integration of visual displays, hardware components, and multimodal interaction techniques that are compatible with the entire system. The potential use of multimodal interactions in industrial applications has been recognized as a significant factor in enhancing humans’ ability to perform tasks and make informed decisions. To offer a comprehensive analysis of the current advancements in industrial XR, this review presents a structured tutorial that provides answers to the following research questions: (R.Q.1) What are the similarities and differences between XR technologies, including augmented reality (AR), mixed reality (MR), Augmented Virtuality (AV), and virtual reality (VR) under Industry 4.0 consideration? (R.Q.2) What types of visual displays and hardware devices are needed to present XR for Industry 4.0? (R.Q.3) How did the multimodal interaction in XR perceive and relate to Industry 4.0? (R.Q.4) How have modern adaptations of XR technologies dealt with the theme of Industry 4.0? (R.Q.5) How can XR technologies in Industry 4.0 develop their services and usages to be more solution-inclusive? This review showcases various instances that demonstrate XR’s potential to transform how humans interact with the physical world in Industry 4.0. These advancements can increase productivity, reduce costs, and enhance safety.},
  archive      = {J_CSUR},
  author       = {A’aeshah Alhakamy},
  doi          = {10.1145/3652595},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {237:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Extended reality (XR) toward building immersive solutions: The key to unlocking industry 4.0},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tutorial on matching-based causal analysis of human
behaviors using smartphone sensor data. <em>CSUR</em>, <em>56</em>(9),
236:1–33. (<a href="https://doi.org/10.1145/3648356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smartphones can unobtrusively capture human behavior and contextual data such as user interaction and mobility. Thus far, smartphone sensor data have primarily been used to gain behavioral insights through correlation analysis. This article provides a tutorial on the causal analysis of human behavior using smartphone sensor data by reviewing well-known matching methods. The key steps of the causal inference pipeline employing matching methods are illustrated using a concrete scenario involving the identification of a causal relationship between phone usage and physical activity. Several practical considerations for conducting causal inferences about human behaviors using smartphone sensor data are also discussed.},
  archive      = {J_CSUR},
  author       = {Gyuwon Jung and Sangjun Park and Eun-Yeol Ma and Heeyoung Kim and Uichin Lee},
  doi          = {10.1145/3648356},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {236:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Tutorial on matching-based causal analysis of human behaviors using smartphone sensor data},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing with attractor: A tutorial. <em>CSUR</em>,
<em>56</em>(9), 235:1–41. (<a
href="https://doi.org/10.1145/3648354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This tutorial presents a novel search system—the Attractor-Based Search System (ABSS)—that can solve the Traveling Salesman Problem very efficiently with optimality guarantee. From the perspective of dynamical systems, a heuristic local search algorithm for an NP-complete combinatorial problem is a discrete dynamical system. In a local search system, an attractor drives the search trajectories into the vicinity of a globally optimal point in the solution space, and the convergence of local search trajectories makes the search system become a global and deterministic system. The attractor contains a small set of the most promising solutions to the problem. The attractor can reduce the problem size exponentially, and thus make the exhaustive search feasible. Therefore, this new search paradigm is called optimizing with attractor. The ABSS consists of two search phases: local search phase and exhaustive search phase. The local search process is used to quickly construct the attractor in the solution space, and the exhaustive search process is used to completely search the attractor to identify the optimal solution. Therefore, the exact optimal solution can be found quickly by combining local search and exhaustive search. This tutorial introduces the concept of an attractor in a local search system, and describes the process of optimizing with the attractor, using the Traveling Salesman Problem as the study platform.},
  archive      = {J_CSUR},
  author       = {Weiqi Li},
  doi          = {10.1145/3648354},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {235:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Optimizing with attractor: A tutorial},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent edge-powered data reduction: A systematic
literature review. <em>CSUR</em>, <em>56</em>(9), 234:1–39. (<a
href="https://doi.org/10.1145/3656338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of the Internet of Things (IoT) paradigm and its significant spread as an affordable data source has brought many challenges when pursuing efficient data collection, distribution, and storage. Since such hierarchical logical architecture can be inefficient and costly in many cases, Data Reduction (DR) solutions have arisen to allow data preprocessing before actual transmission. To increase DR performance, researchers are using Artificial Intelligence (AI) techniques and models toward reducing sensed data volume. AI for DR on the edge is investigated in this study in the form of a Systematic Literature Review (SLR) encompassing major issues such as data heterogeneity and AI-based techniques to reduce data, architectures, and contexts of usage. An SLR is conducted to map the state of the art in this area, highlighting the most common challenges and potential research trends in addition to a proposed taxonomy.},
  archive      = {J_CSUR},
  author       = {Laércio Pioli and Douglas D. J. de Macedo and Daniel G. Costa and Mario A. R. Dantas},
  doi          = {10.1145/3656338},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {234:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Intelligent edge-powered data reduction: A systematic literature review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep dive into robot vision - an integrative systematic
literature review methodologies and research endeavor practices.
<em>CSUR</em>, <em>56</em>(9), 233:1–33. (<a
href="https://doi.org/10.1145/3648357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel technological swarm and industry 4.0 mold the recent Robot vision research into innovative discovery. To enhance technological paradigm Deep Learning offers remarkable pace to move towards diversified advancement. This research considers the most topical, recent, related and state-of-the-art research reviews that revolve around Robot vision, and shapes the research into Systematic Literature Survey SLR. The SLR considers a combination of more than 100 reviews and empirical studies to perform a critical categorical study and shapes findings against research questions. The research study contribution spans over multiple categories of Robot vision and is tinted along with technical limitations and future research endeavors. Previously multiple research studies have been observed to leverage Robotic vision techniques. Yet, there is none like SLR summarizing recent vision techniques for all targeted Robotic fields. This research SLR could be a precious milestone in Robot vision for each glimpse of Robotics.},
  archive      = {J_CSUR},
  author       = {Saima Sultana and Muhammad Mansoor Alam and Mazliham Mohd Su’ud and Jawahir Che Mustapha and Mukesh Prasad},
  doi          = {10.1145/3648357},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {233:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {A deep dive into robot vision - An integrative systematic literature review methodologies and research endeavor practices},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local interpretations for explainable natural language
processing: A survey. <em>CSUR</em>, <em>56</em>(9), 232:1–36. (<a
href="https://doi.org/10.1145/3649450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the use of deep learning techniques has grown across various fields over the past decade, complaints about the opaqueness of the black-box models have increased, resulting in an increased focus on transparency in deep learning models. This work investigates various methods to improve the interpretability of deep neural networks for Natural Language Processing (NLP) tasks, including machine translation and sentiment analysis. We provide a comprehensive discussion on the definition of the term interpretability and its various aspects at the beginning of this work. The methods collected and summarised in this survey are only associated with local interpretation and are specifically divided into three categories: (1) interpreting the model’s predictions through related input features; (2) interpreting through natural language explanation; (3) probing the hidden states of models and word representations.},
  archive      = {J_CSUR},
  author       = {Siwen Luo and Hamish Ivison and Soyeon Caren Han and Josiah Poon},
  doi          = {10.1145/3649450},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {232:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Local interpretations for explainable natural language processing: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DevOps metrics and KPIs: A multivocal literature review.
<em>CSUR</em>, <em>56</em>(9), 231:1–41. (<a
href="https://doi.org/10.1145/3652508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context: Information Technology organizations are aiming to implement DevOps capabilities to fulfill market, customer, and internal needs. While many are successful with DevOps implementation, others still have difficulty measuring DevOps success in their organization. As a result, the effectiveness of assessing DevOps remains erratic. This emphasizes the need to withstand management in measuring the implementation process with suitable DevOps Metrics. But what are these metrics? Objective: This research seeks to provide relevant DevOps Metrics to facilitate the efficiency of DevOps adoption and better analyze DevOps performance in enterprises. Method: A Multivocal Literature Review (MLR) is conducted, with 139 documents gathered and thoroughly examined from throughout the community, including books, scientific articles, white papers, conferences, among others. Results: This article conducts an extensive and rigorous MLR, contributing with a definition of DevOps Metrics, 22 main metrics, their definitions, importance, and categorization in sets of Key Performance Indicators, as well as exposing clear indicators on how to improve them. It is also discussed how metrics could be put into practice and what constitutes a change in the context of DevOps Metrics. The study’s outcomes will assist researchers and practitioners understand DevOps Metrics and how to better implement them.},
  archive      = {J_CSUR},
  author       = {Ricardo Amaro and Rúben Pereira and Miguel Mira da Silva},
  doi          = {10.1145/3652508},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {231:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {DevOps metrics and KPIs: A multivocal literature review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pre-trained language models for text generation: A survey.
<em>CSUR</em>, <em>56</em>(9), 230:1–39. (<a
href="https://doi.org/10.1145/3649449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text Generation aims to produce plausible and readable text in human language from input data. The resurgence of deep learning has greatly advanced this field, in particular, with the help of neural generation models based on pre-trained language models (PLMs). Text generation based on PLMs is viewed as a promising approach in both academia and industry. In this article, we provide a survey on the utilization of PLMs in text generation. We begin with introducing two key aspects of applying PLMs to text generation: (1) how to design an effective PLM to serve as the generation model; and (2) how to effectively optimize PLMs given the reference text and to ensure that the generated texts satisfy special text properties. Then, we show the major challenges that have arisen in these aspects, as well as possible solutions for them. We also include a summary of various useful resources and typical text generation applications based on PLMs. Finally, we highlight the future research directions which will further improve these PLMs for text generation. This comprehensive survey is intended to help researchers interested in text generation problems to learn the core concepts, the main techniques and the latest developments in this area based on PLMs.},
  archive      = {J_CSUR},
  author       = {Junyi Li and Tianyi Tang and Wayne Xin Zhao and Jian-Yun Nie and Ji-Rong Wen},
  doi          = {10.1145/3649449},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {230:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Pre-trained language models for text generation: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Warm-starting and quantum computing: A systematic mapping
study. <em>CSUR</em>, <em>56</em>(9), 229:1–31. (<a
href="https://doi.org/10.1145/3652510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to low numbers of qubits and their error-proneness, Noisy Intermediate-Scale Quantum (NISQ) computers impose constraints on the size of quantum algorithms they can successfully execute. State-of-the-art research introduces various techniques addressing these limitations by utilizing known or inexpensively generated approximations, solutions, or models as a starting point to approach a task instead of starting from scratch. These so-called warm-starting techniques aim to reduce quantum resource consumption, thus facilitating the design of algorithms suiting the capabilities of NISQ computers. In this work, we collect and analyze scientific literature on warm-starting techniques in the quantum computing domain. In particular, we (i) create a systematic map of state-of-the-art research on warm-starting techniques using established guidelines for systematic mapping studies, (ii) identify relevant properties of such techniques, and (iii) based on these properties classify the techniques identified in the literature in an extensible classification scheme. Our results provide insights into the research field and aim to help quantum software engineers to categorize warm-starting techniques and apply them in practice. Moreover, our contributions may serve as a starting point for further research on the warm-starting topic since they provide an overview of existing work and facilitate the identification of research gaps.},
  archive      = {J_CSUR},
  author       = {Felix Truger and Johanna Barzen and Marvin Bechtold and Martin Beisel and Frank Leymann and Alexander Mandl and Vladimir Yussupov},
  doi          = {10.1145/3652510},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {229:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {Warm-starting and quantum computing: A systematic mapping study},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Controllable data generation by deep learning: A review.
<em>CSUR</em>, <em>56</em>(9), 228:1–38. (<a
href="https://doi.org/10.1145/3648609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing and generating new data under targeted properties has been attracting various critical applications such as molecule design, image editing and speech synthesis. Traditional hand-crafted approaches heavily rely on expertise experience and intensive human efforts, yet still suffer from the insufficiency of scientific knowledge and low throughput to support effective and efficient data generation. Recently, the advancement of deep learning has created the opportunity for expressive methods to learn the underlying representation and properties of data. Such capability provides new ways of determining the mutual relationship between the structural patterns and functional properties of the data and leveraging such relationships to generate structural data, given the desired properties. This article is a systematic review that explains this promising research area, commonly known as controllable deep data generation. First, the article raises the potential challenges and provides preliminaries. Then the article formally defines controllable deep data generation, proposes a taxonomy on various techniques and summarizes the evaluation metrics in this specific domain. After that, the article introduces exciting applications of controllable deep data generation, experimentally analyzes and compares existing works. Finally, this article highlights the promising future directions of controllable deep data generation and identifies five potential challenges.},
  archive      = {J_CSUR},
  author       = {Shiyu Wang and Yuanqi Du and Xiaojie Guo and Bo Pan and Zhaohui Qin and Liang Zhao},
  doi          = {10.1145/3648609},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {228:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Controllable data generation by deep learning: A review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of cutting-edge multimodal sentiment analysis.
<em>CSUR</em>, <em>56</em>(9), 227:1–38. (<a
href="https://doi.org/10.1145/3652149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of the internet has reached the fourth generation, i.e., web 4.0, which supports Sentiment Analysis (SA) in many applications such as social media, marketing, risk management, healthcare, businesses, websites, data mining, e-learning, psychology, and many more. Sentiment analysis is a powerful tool for governments, businesses, and researchers to analyse users’ emotions and mental states in order to generate opinions and reviews about products, services, and daily activities. In the past years, several SA techniques based on Machine Learning (ML), Deep Learning (DL), and other soft computing approaches were proposed. However, growing data size, subjectivity, and diversity pose a significant challenge to enhancing the efficiency of existing techniques and incorporating current development trends, such as Multimodal Sentiment Analysis (MSA) and fusion techniques. With the aim of assisting the enthusiastic researcher to navigating the current trend, this article presents a comprehensive study of various literature to handle different aspects of SA, including current trends and techniques across multiple domains. In order to clarify the future prospects of MSA, this article also highlights open issues and research directions that lead to a number of unresolved challenges.},
  archive      = {J_CSUR},
  author       = {Upendra Singh and Kumar Abhishek and Hiteshwar Kumar Azad},
  doi          = {10.1145/3652149},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {227:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of cutting-edge multimodal sentiment analysis},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contactless diseases diagnoses using wireless communication
sensing: Methods and challenges survey. <em>CSUR</em>, <em>56</em>(9),
226:1–29. (<a href="https://doi.org/10.1145/3648352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Respiratory illness diagnosis and continuous monitoring are becoming popular as sensitive markers of chronic diseases. This interest has motivated the increased development of respiratory illness diagnosis by exploiting wireless communication as a sensing system. Several methods for diagnosing a respiratory illness are based on multiple sensors and techniques. Depending on whether the device embeds the sensor in contact with the body or not, these techniques are commonly categorized as contact based or contactless. Contactless methods have gained increasing popularity due to their ubiquitous nature, non-intrusiveness, and low cost. However, contactless methods are difficult to implement, with several challenges such as dynamic wireless communication environments. This article comprehensively reviews all contactless respiratory illnesses using wireless communication sensing methods, their associated challenges, and issues. In addition, applications of respiratory illness diagnosis methods using wireless communication are provided to investigate each method&#39;s potential development and applicability. Continuous and accurate diagnosis of respiratory illness using wireless communication sensing systems can assist caregivers in enhancing the care quality and bestowing patients with more freedom for both inpatients and outpatients. Furthermore, wireless communication monitoring systems could lead to treatment plans remotely more effectively, decrease the duration of patient stays in medical facilities, and reduce overall treatment costs.},
  archive      = {J_CSUR},
  author       = {Najah Abed Abu Ali and Mubashir Rehman and Shahid Mumtaz and Muhammad Bilal Khan and Mohammad Hayajneh and Farman Ullah and Raza Ali Shah},
  doi          = {10.1145/3648352},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {226:1–29},
  shortjournal = {ACM Comput. Surv.},
  title        = {Contactless diseases diagnoses using wireless communication sensing: Methods and challenges survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards hybrid-optimization video coding. <em>CSUR</em>,
<em>56</em>(9), 225:1–36. (<a
href="https://doi.org/10.1145/3652148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video coding that pursues the highest compression efficiency is the art of computing for rate-distortion optimization. The optimization has been approached in different ways, exemplified by two typical frameworks: block-based hybrid video coding and end-to-end learned video coding. The block-based hybrid framework encompasses more and more coding modes that are available at the decoder side; an encoder tries to search for the optimal coding mode for each block to be coded. This is an online, discrete, search-based optimization strategy. The end-to-end learned framework embraces more and more sophisticated neural networks; the network parameters are learned from a collection of videos, typically using gradient descent-based methods. This is an offline, continuous, numerical optimization strategy. Having analyzed these two strategies, both conceptually and with concrete schemes, this paper suggests investigating hybrid -optimization video coding, that is to combine online and offline, discrete and continuous, search-based and numerical optimization. For instance, we propose a hybrid-optimization video coding scheme, where the decoder consists of trained neural networks and supports several coding modes, and the encoder adopts both numerical and search-based algorithms for the online optimization. Our scheme achieves promising compression efficiency on par with H.265/HM for the random-access configuration.},
  archive      = {J_CSUR},
  author       = {Shuai Huo and Dong Liu and Haotian Zhang and Li Li and Siwei Ma and Feng Wu and Wen Gao},
  doi          = {10.1145/3652148},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {225:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Towards hybrid-optimization video coding},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Resilient machine learning: Advancement, barriers, and
opportunities in the nuclear industry. <em>CSUR</em>, <em>56</em>(9),
224:1–29. (<a href="https://doi.org/10.1145/3648608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption and success of Machine Learning (ML) technologies depend on thorough testing of the resilience and robustness to adversarial attacks. The testing should focus on both the model and the data. It is necessary to build robust and resilient systems to withstand disruptions and remain functional despite the action of adversaries, specifically in the security-sensitive Nuclear Industry (NI), where consequences can be fatal in terms of both human lives and assets. We analyse ML-based research works that have investigated adversaries and defence strategies in the NI . We then present the progress in the adoption of ML techniques, identify use cases where adversaries can threaten the ML-enabled systems, and finally identify the progress on building Resilient Machine Learning (rML) systems entirely focusing on the NI domain.},
  archive      = {J_CSUR},
  author       = {Anita Khadka and Saurav Sthapit and Gregory Epiphaniou and Carsten Maple},
  doi          = {10.1145/3648608},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {224:1–29},
  shortjournal = {ACM Comput. Surv.},
  title        = {Resilient machine learning: Advancement, barriers, and opportunities in the nuclear industry},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for iris recognition: A survey. <em>CSUR</em>,
<em>56</em>(9), 223:1–35. (<a
href="https://doi.org/10.1145/3651306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this survey, we provide a comprehensive review of more than 200 articles, technical reports, and GitHub repositories published over the last 10 years on the recent developments of deep learning techniques for iris recognition, covering broad topics on algorithm designs, open-source tools, open challenges, and emerging research. First, we conduct a comprehensive analysis of deep learning techniques developed for two main sub-tasks in iris biometrics: segmentation and recognition. Second, we focus on deep learning techniques for the robustness of iris recognition systems against presentation attacks and via human-machine pairing. Third, we delve deep into deep learning techniques for forensic application, especially in post-mortem iris recognition. Fourth, we review open-source resources and tools in deep learning techniques for iris recognition. Finally, we highlight the technical challenges, emerging research trends, and outlook for the future of deep learning in iris recognition.},
  archive      = {J_CSUR},
  author       = {Kien Nguyen and Hugo Proença and Fernando Alonso-Fernandez},
  doi          = {10.1145/3651306},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {223:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for iris recognition: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzers for stateful systems: Survey and research
directions. <em>CSUR</em>, <em>56</em>(9), 222:1–23. (<a
href="https://doi.org/10.1145/3648468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzing is a very effective testing methodology to find bugs. In a nutshell, a fuzzer sends many slightly malformed messages to the software under test, hoping for crashes or incorrect system behaviour. The methodology is relatively simple, although applications that keep internal states are challenging to fuzz. The research community has responded to this challenge by developing fuzzers tailored to stateful systems, but a clear understanding of the variety of strategies is still missing. In this paper, we present the first taxonomy of fuzzers for stateful systems and provide a systematic comparison and classification of these fuzzers.},
  archive      = {J_CSUR},
  author       = {Cristian Daniele and Seyed Behnam Andarzian and Erik Poll},
  doi          = {10.1145/3648468},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {222:1–23},
  shortjournal = {ACM Comput. Surv.},
  title        = {Fuzzers for stateful systems: Survey and research directions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-invasive techniques for muscle fatigue monitoring: A
comprehensive survey. <em>CSUR</em>, <em>56</em>(9), 221:1–40. (<a
href="https://doi.org/10.1145/3648679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Muscle fatigue represents a complex physiological and psychological phenomenon that impairs physical performance and increases the risks of injury. It is important to continuously monitor fatigue levels for early detection and management of fatigue. The detection and classification of muscle fatigue also provide important information in human-computer interactions (HMI), sports injuries and performance, ergonomics, and prosthetic control. With this purpose in mind, this review first provides an overview of the mechanisms of muscle fatigue and its biomarkers and further enumerates various non-invasive techniques commonly used for muscle fatigue monitoring and detection in the literature, including electromyogram (EMG), which records the muscle electrical activity during muscle contractions, mechanomyogram (MMG), which records vibration signals of muscle fibers, near-infrared spectroscopy (NIRS), which measures the amount of oxygen in the muscle, ultrasound (US), which records signals of muscle deformation during muscle contractions. This review also introduces the principle and mechanism, parameters used for fatigue detection, application in fatigue detection, and advantages and disadvantages of each technology in detail. To conclude, the limitations/challenges that need to be addressed for future research in this area are presented.},
  archive      = {J_CSUR},
  author       = {Na Li and Rui Zhou and Bharath Krishna and Ashirbad Pradhan and Hyowon Lee and Jiayuan He and Ning Jiang},
  doi          = {10.1145/3648679},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {221:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Non-invasive techniques for muscle fatigue monitoring: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Financial sentiment analysis: Techniques and applications.
<em>CSUR</em>, <em>56</em>(9), 220:1–42. (<a
href="https://doi.org/10.1145/3649451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial Sentiment Analysis (FSA) is an important domain application of sentiment analysis that has gained increasing attention in the past decade. FSA research falls into two main streams. The first stream focuses on defining tasks and developing techniques for FSA, and its main objective is to improve the performances of various FSA tasks by advancing methods and using/curating human-annotated datasets. The second stream of research focuses on using financial sentiment, implicitly or explicitly, for downstream applications on financial markets, which has received more research efforts. The main objective is to discover appropriate market applications for existing techniques. More specifically, the application of FSA mainly includes hypothesis testing and predictive modeling in financial markets. This survey conducts a comprehensive review of FSA research in both the technique and application areas and proposes several frameworks to help understand the two areas’ interactive relationship. This article defines a clearer scope for FSA studies and conceptualizes the FSA-investor sentiment-market sentiment relationship. Major findings, challenges, and future research directions for both FSA techniques and applications have also been summarized and discussed.},
  archive      = {J_CSUR},
  author       = {Kelvin Du and Frank Xing and Rui Mao and Erik Cambria},
  doi          = {10.1145/3649451},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {220:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Financial sentiment analysis: Techniques and applications},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Redefining counterfactual explanations for reinforcement
learning: Overview, challenges and opportunities. <em>CSUR</em>,
<em>56</em>(9), 219:1–33. (<a
href="https://doi.org/10.1145/3648472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While AI algorithms have shown remarkable success in various fields, their lack of transparency hinders their application to real-life tasks. Although explanations targeted at non-experts are necessary for user trust and human-AI collaboration, the majority of explanation methods for AI are focused on developers and expert users. Counterfactual explanations are local explanations that offer users advice on what can be changed in the input for the output of the black-box model to change. Counterfactuals are user-friendly and provide actionable advice for achieving the desired output from the AI system. While extensively researched in supervised learning, there are few methods applying them to reinforcement learning (RL). In this work, we explore the reasons for the underrepresentation of a powerful explanation method in RL. We start by reviewing the current work in counterfactual explanations in supervised learning. Additionally, we explore the differences between counterfactual explanations in supervised learning and RL and identify the main challenges that prevent the adoption of methods from supervised in reinforcement learning. Finally, we redefine counterfactuals for RL and propose research directions for implementing counterfactuals in RL.},
  archive      = {J_CSUR},
  author       = {Jasmina Gajcin and Ivana Dusparic},
  doi          = {10.1145/3648472},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {219:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Redefining counterfactual explanations for reinforcement learning: Overview, challenges and opportunities},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SoK: Security in real-time systems. <em>CSUR</em>,
<em>56</em>(9), 218:1–31. (<a
href="https://doi.org/10.1145/3649499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security is an increasing concern for real-time systems (RTS). Over the last decade or so, researchers have demonstrated attacks and defenses aimed at such systems. In this article, we identify , classify and measure the effectiveness of the security research in this domain. We provide a high-level summary [ identification ] and a taxonomy [ classification ] of this existing body of work. Furthermore, we carry out an in-depth analysis [ measurement ] of scheduler-based security techniques — the most common class of real-time security mechanisms. For this purpose, we developed a common metric, “ attacker’s burden ” , used to measure the effectiveness of (existing as well as future) scheduler-based real-time security measures. This metric, built on the concept of “work factor” [ 1 ], is adapted for, and normalized across, various scheduler-based real-time security techniques.},
  archive      = {J_CSUR},
  author       = {Monowar Hasan and Ashish Kashinath and Chien-Ying Chen and Sibin Mohan},
  doi          = {10.1145/3649499},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {218:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {SoK: Security in real-time systems},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for time series classification and extrinsic
regression: A current survey. <em>CSUR</em>, <em>56</em>(9), 217:1–45.
(<a href="https://doi.org/10.1145/3649448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time Series Classification and Extrinsic Regression are important and challenging machine learning tasks. Deep learning has revolutionized natural language processing and computer vision and holds great promise in other fields such as time series analysis where the relevant features must often be abstracted from the raw data but are not known a priori. This article surveys the current state of the art in the fast-moving field of deep learning for time series classification and extrinsic regression. We review different network architectures and training methods used for these tasks and discuss the challenges and opportunities when applying deep learning to time series data. We also summarize two critical applications of time series classification and extrinsic regression, human activity recognition and satellite earth observation.},
  archive      = {J_CSUR},
  author       = {Navid Mohammadi Foumani and Lynn Miller and Chang Wei Tan and Geoffrey I. Webb and Germain Forestier and Mahsa Salehi},
  doi          = {10.1145/3649448},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {217:1–45},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for time series classification and extrinsic regression: A current survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep multimodal data fusion. <em>CSUR</em>, <em>56</em>(9),
216:1–36. (<a href="https://doi.org/10.1145/3649447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Artificial Intelligence (Multimodal AI), in general, involves various types of data (e.g., images, texts, or data collected from different sensors), feature engineering (e.g., extraction, combination/fusion), and decision-making (e.g., majority vote). As architectures become more and more sophisticated, multimodal neural networks can integrate feature extraction, feature fusion, and decision-making processes into one single model. The boundaries between those processes are increasingly blurred. The conventional multimodal data fusion taxonomy (e.g., early/late fusion), based on which the fusion occurs in, is no longer suitable for the modern deep learning era. Therefore, based on the main-stream techniques used, we propose a new fine-grained taxonomy grouping the state-of-the-art (SOTA) models into five classes: Encoder-Decoder methods, Attention Mechanism methods, Graph Neural Network methods, Generative Neural Network methods, and other Constraint-based methods. Most existing surveys on multimodal data fusion are only focused on one specific task with a combination of two specific modalities. Unlike those, this survey covers a broader combination of modalities, including Vision + Language (e.g., videos, texts), Vision + Sensors (e.g., images, LiDAR), and so on, and their corresponding tasks (e.g., video captioning, object detection). Moreover, a comparison among these methods is provided, as well as challenges and future directions in this area.},
  archive      = {J_CSUR},
  author       = {Fei Zhao and Chengcui Zhang and Baocheng Geng},
  doi          = {10.1145/3649447},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {9},
  pages        = {216:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep multimodal data fusion},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning in metaverse security: Current solutions
and future challenges. <em>CSUR</em>, <em>56</em>(8), 215:1–36. (<a
href="https://doi.org/10.1145/3654663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Metaverse, positioned as the next frontier of the Internet, has the ambition to forge a virtual shared realm characterized by immersion, hyper-spatiotemporal dynamics, and self-sustainability. Recent technological strides in AI, Extended Reality, 6G, and blockchain propel the Metaverse closer to realization, gradually transforming it from science fiction into an imminent reality. Nevertheless, the extensive deployment of the Metaverse faces substantial obstacles, primarily stemming from its potential to infringe on privacy and be susceptible to security breaches, whether inherent in its underlying technologies or arising from the evolving digital landscape. Metaverse security provisioning is poised to confront various foundational challenges owing to its distinctive attributes, encompassing immersive realism, hyper-spatiotemporally, sustainability, and heterogeneity. This article undertakes a comprehensive study of the security and privacy challenges facing the Metaverse, leveraging machine learning models for this purpose. In particular, our focus centers on an innovative distributed Metaverse architecture characterized by interactions across 3D worlds. Subsequently, we conduct a thorough review of the existing cutting-edge measures designed for Metaverse systems while also delving into the discourse surrounding security and privacy threats. As we contemplate the future of Metaverse systems, we outline directions for open research pursuits in this evolving landscape.},
  archive      = {J_CSUR},
  author       = {Yazan Otoum and Navya Gottimukkala and Neeraj Kumar and Amiya Nayak},
  doi          = {10.1145/3654663},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {215:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Machine learning in metaverse security: Current solutions and future challenges},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How many FIDO protocols are needed? Analysing the
technology, security and compliance. <em>CSUR</em>, <em>56</em>(8),
214:1–51. (<a href="https://doi.org/10.1145/3654661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome the security vulnerabilities caused by weak passwords, thus bridge the gap between user friendly interfaces and advanced security features, the Fast IDentity Online (FIDO) alliance defined a number of authentication protocols. The existing literature leverages all versions of the FIDO protocols, without indicating the reasons behind the choice of each individual FIDO protocol (i.e., U2F, UAF, FIDO2). Inevitably, the question “which protocol is more suitable per case” becomes significant. To provide an answer to the previous question, this article performs a thorough comparative analysis on the different protocol specifications and their technological and market support, to identify whether any protocol has become obsolete. To reach to a conclusion, the proposed approach (i) explores the existing literature, (ii) analyses the specifications released by the FIDO Alliance, elaborating on the security characteristics, (iii) inspects the technical adoption by the industry and (iv) investigates the compliance of the FIDO with standards, regulations and other identity verification protocols. Our results indicate that FIDO2 is the most widely adopted solution; however, U2F remains supported by numerous web services as a two-factor authentication (2FA) choice, while UAF continues to be utilised in mobile clients seeking to offer the Transaction Confirmation feature.},
  archive      = {J_CSUR},
  author       = {Anna Angelogianni and Ilias Politis and Christos Xenakis},
  doi          = {10.1145/3654661},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {214:1–51},
  shortjournal = {ACM Comput. Surv.},
  title        = {How many FIDO protocols are needed? analysing the technology, security and compliance},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FairSNA: Algorithmic fairness in social network analysis.
<em>CSUR</em>, <em>56</em>(8), 213:1–45. (<a
href="https://doi.org/10.1145/3653711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, designing fairness-aware methods has received much attention in various domains, including machine learning, natural language processing, and information retrieval. However, in social network analysis (SNA), designing fairness-aware methods for various research problems by considering structural bias and inequalities of large-scale social networks has not received much attention. In this work, we highlight how the structural bias of social networks impacts the fairness of different SNA methods. We further discuss fairness aspects that should be considered while proposing network structure-based solutions for different SNA problems, such as link prediction, influence maximization, centrality ranking, and community detection. This survey-cum-vision clearly highlights that very few works have considered fairness and bias while proposing solutions; even these works are mainly focused on some research topics, such as link prediction, influence maximization, and PageRank. However, fairness has not yet been addressed for other research topics, such as influence blocking and community detection. We review the state of the art for different research topics in SNA, including the considered fairness constraints, their limitations, and our vision. This survey also covers evaluation metrics, available datasets and synthetic network generating models used in such studies. Finally, we highlight various open research directions that require researchers’ attention to bridge the gap between fairness and SNA.},
  archive      = {J_CSUR},
  author       = {Akrati Saxena and George Fletcher and Mykola Pechenizkiy},
  doi          = {10.1145/3653711},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {213:1–45},
  shortjournal = {ACM Comput. Surv.},
  title        = {FairSNA: Algorithmic fairness in social network analysis},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying authorship in malicious binaries: Features,
challenges &amp; datasets. <em>CSUR</em>, <em>56</em>(8), 212:1–36. (<a
href="https://doi.org/10.1145/3653973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributing a piece of malware to its creator typically requires threat intelligence. Binary attribution increases the level of difficulty as it mostly relies upon the ability to disassemble binaries to obtain authorship-related features. We perform a systematic analysis of works in the area of malware authorship attribution. We identify key findings and some shortcomings of current approaches and explore the open research challenges. To mitigate the lack of ground-truth datasets in this domain, we publish alongside this survey the largest and most diverse meta-information dataset of 17,513 malware labeled to 275 threat actor groups.},
  archive      = {J_CSUR},
  author       = {Jason Gray and Daniele Sgandurra and Lorenzo Cavallaro and Jorge Blasco Alis},
  doi          = {10.1145/3653973},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {212:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Identifying authorship in malicious binaries: Features, challenges &amp; datasets},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recovery from adversarial attacks in cyber-physical systems:
Shallow, deep, and exploratory works. <em>CSUR</em>, <em>56</em>(8),
211:1–31. (<a href="https://doi.org/10.1145/3653974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical systems (CPS) have experienced rapid growth in recent decades. However, like any other computer-based systems, malicious attacks evolve mutually, driving CPS to undesirable physical states, and potentially causing catastrophes. Although the current state-of-the-art is well aware of this issue, the majority of researchers have not focused on CPS recovery, the procedure we defined as restoring a CPS’s physical state back to a target condition under adversarial attacks. To call for attention on CPS recovery and identify existing efforts, we have surveyed a total of 30 relevant papers. We identify a major partition of the proposed recovery strategies: shallow recovery vs. deep recovery, where the former does not use a dedicated recovery controller while the latter does. Additionally, we surveyed exploratory research on topics that facilitate recovery. From these publications, we discuss the current state-of-the-art of CPS recovery, with respect to applications, attack type, attack surfaces, and system dynamics. Then, we identify untouched sub-domains in this field and suggest possible future directions for researchers.},
  archive      = {J_CSUR},
  author       = {Pengyuan Lu and Lin Zhang and Mengyu Liu and Kaustubh Sridhar and Oleg Sokolsky and Fanxin Kong and Insup Lee},
  doi          = {10.1145/3653974},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {211:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {Recovery from adversarial attacks in cyber-physical systems: Shallow, deep, and exploratory works},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From conventional to programmable matter systems: A review
of design, materials, and technologies. <em>CSUR</em>, <em>56</em>(8),
210:1–26. (<a href="https://doi.org/10.1145/3653671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programmable matter represents a system of elements whose interactions can be programmed for a certain behavior to emerge (e.g., color, shape) upon suitable commands (e.g., instruction, stimuli) by altering its physical characteristics. Even though its appellation may refer to a morphable physical material, programmable matter has been represented through several approaches from different perspectives (e.g., robots, smart materials) that seek the same objective: controllable behavior such as smart shape alteration. Researchers, engineers, and artists have expressed interest in the development of smart modeling clay as a novel alternative to conventional matter and classical means of prototyping. Henceforth, users will be able to do/undo/redo forms based on computed data (CAD) or interactions (sensors), which will help them unlock more features and increase the usefulness of their products. However, with such a promising technology, many challenges need to be addressed, as programmable matter relies on energy consumption, data transmission, stimuli control, and shape formation mechanisms. Furthermore, numerous devices and technologies are created under the name of programmable matter, which may pose ambiguity to the control strategies. In this study, we determine the basic operations required to form a shape, then review different realizations using the shape shifting ability of programmable matter and their fitting classifications, and finally discuss potential challenges.},
  archive      = {J_CSUR},
  author       = {Ahmed Amine Chafik and Jaafar Gaber and Souad Tayane and Mohamed Ennaji and Julien Bourgeois and Tarek El Ghazawi},
  doi          = {10.1145/3653671},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {210:1–26},
  shortjournal = {ACM Comput. Surv.},
  title        = {From conventional to programmable matter systems: A review of design, materials, and technologies},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic data integration and querying: A survey and
challenges. <em>CSUR</em>, <em>56</em>(8), 209:1–35. (<a
href="https://doi.org/10.1145/3653317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital revolution produces massive, heterogeneous and isolated data. These latter remain underutilized, unsuitable for integrated querying and knowledge discovering. Hence the importance of this survey on data integration which identifies challenging issues and trends. First, an overview of the different generations and basics of data integration is given. Then, semantic data integration is focused, since it semantically links data allowing wider insights and decision-making. More than thirty works are reviewed. The goal is to help analysts to identify relevant criteria to compare then choose among semantic data integration approaches, focusing on the category (materialized, virtual or hybrid) and querying techniques.},
  archive      = {J_CSUR},
  author       = {Maroua Masmoudi and Sana Ben Abdallah Ben Lamine and Mohamed Hedi Karray and Bernard Archimede and Hajer Baazaoui Zghal},
  doi          = {10.1145/3653317},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {209:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Semantic data integration and querying: A survey and challenges},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on the densest subgraph problem and its variants.
<em>CSUR</em>, <em>56</em>(8), 208:1–40. (<a
href="https://doi.org/10.1145/3653298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Densest Subgraph Problem requires us to find, in a given graph, a subset of vertices whose induced subgraph maximizes a measure of density. The problem has received a great deal of attention in the algorithmic literature since the early 1970s, with many variants proposed and many applications built on top of this basic definition. Recent years have witnessed a revival of research interest in this problem with several important contributions, including some groundbreaking results, published in 2022 and 2023. This survey provides a deep overview of the fundamental results and an exhaustive coverage of the many variants proposed in the literature, with a special attention to the most recent results. The survey also presents a comprehensive overview of applications and discusses some interesting open problems for this evergreen research topic.},
  archive      = {J_CSUR},
  author       = {Tommaso Lanciano and Atsushi Miyauchi and Adriano Fazzone and Francesco Bonchi},
  doi          = {10.1145/3653298},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {208:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on the densest subgraph problem and its variants},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A taxonomy and survey on grid-based routing protocols
designed for wireless sensor networks. <em>CSUR</em>, <em>56</em>(8),
207:1–41. (<a href="https://doi.org/10.1145/3653315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimization of energy consumption is the main attention of researchers while developing a routing protocol for wireless sensor networks, as sensor nodes are equipped with limited power supply. Virtual topology is an integral part of routing, and grid-based routing protocols are quite popular due to their simplified and efficient virtual grid topology construction. Although a list of surveys exists that either focus on routing protocols in a broader way or on other virtual topologies, none of these surveys are concerned about grid topology and grid-based routing protocols. Having this motivation in mind and considering the impact of these routing protocols on controlling and managing the energy consumption of wireless sensor networks, this article provides an expansive assessment of grid-based routing protocols based on their methodology. In this survey, the existing grid-based routing protocols are classified into two categories from the perspective of sink mobility: static sink and mobile sink. A phase-wise comprehensive overview of these routing protocols is provided in chronological order, along with their comparative analysis. Furthermore, the characteristics, design issues, and challenges of grid-based routing protocols are also provided.},
  archive      = {J_CSUR},
  author       = {Shubhra Jain and Rahul Kumar Verma},
  doi          = {10.1145/3653315},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {207:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A taxonomy and survey on grid-based routing protocols designed for wireless sensor networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rearrangement distance problems: An updated survey.
<em>CSUR</em>, <em>56</em>(8), 206:1–27. (<a
href="https://doi.org/10.1145/3653295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the challenges in the Comparative Genomics field is to infer how close two organisms are based on the similarities and differences between their genetic materials. Recent advances in DNA sequencing have made complete genomes increasingly available. That said, several new algorithms trying to infer the distance between two organisms based on genome rearrangements have been proposed in the literature. However, given the diversity of approaches, the diversity of genome rearrangement events, or even how each work models the genomes and what assumptions are made by each of them, finding the ideal algorithm for each situation or simply knowing the range of applicable approaches can be challenging. In this work, we review these approaches having the algorithmic and combinatorial advances since 2010 as our main focus. This survey aims to organize the recently published papers using a concise notation and to indicate the gaps filled by each of them in the literature. This makes it easier to understand what still needs to be done and what has room for enhancement.},
  archive      = {J_CSUR},
  author       = {Andre Rodrigues Oliveira and Klairton Lima Brito and Alexsandro Oliveira Alexandrino and Gabriel Siqueira and Ulisses Dias and Zanoni Dias},
  doi          = {10.1145/3653295},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {206:1–27},
  shortjournal = {ACM Comput. Surv.},
  title        = {Rearrangement distance problems: An updated survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on software vulnerability exploitability
assessment. <em>CSUR</em>, <em>56</em>(8), 205:1–41. (<a
href="https://doi.org/10.1145/3648610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowing the exploitability and severity of software vulnerabilities helps practitioners prioritize vulnerability mitigation efforts. Researchers have proposed and evaluated many different exploitability assessment methods. The goal of this research is to assist practitioners and researchers in understanding existing methods for assessing vulnerability exploitability through a survey of exploitability assessment literature. We identify three exploitability assessment approaches: assessments based on original, manual Common Vulnerability Scoring System, automated Deterministic assessments, and automated Probabilistic assessments. Other than the original Common Vulnerability Scoring System, the two most common sub-categories are Deterministic, Program State based, and Probabilistic learning model assessments.},
  archive      = {J_CSUR},
  author       = {Sarah Elder and Md Rayhanur Rahman and Gage Fringer and Kunal Kapoor and Laurie Williams},
  doi          = {10.1145/3648610},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {205:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on software vulnerability exploitability assessment},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy preservation of electronic health records in the
modern era: A systematic survey. <em>CSUR</em>, <em>56</em>(8),
204:1–37. (<a href="https://doi.org/10.1145/3653297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building a secure and privacy-preserving health data sharing framework is a topic of great interest in the healthcare sector, but its success is subject to ensuring the privacy of user data. We clarified the definitions of privacy, confidentiality and security (PCS) because these three terms have been used interchangeably in the literature. We found that researchers and developers must address the differences of these three terms when developing electronic health record (EHR) solutions. We surveyed 130 studies on EHRs, privacy-preserving techniques, and tools that were published between 2012 and 2022, aiming to preserve the privacy of EHRs. The observations and findings were summarized with the help of the identified studies framed along the survey questions addressed in the literature review. Our findings suggested that the usage of access control, blockchain, cloud-based, and cryptography techniques is common for EHR data sharing. We summarized the commonly used strategies for preserving privacy that are implemented by various EHR tools. Additionally, we collated a comprehensive list of differences and similarities between PCS. Finally, we summarized the findings in a tabular form for all EHR tools and techniques and proposed a fusion of techniques to better preserve the PCS of EHRs.},
  archive      = {J_CSUR},
  author       = {Raza Nowrozy and Khandakar Ahmed and A. S. M. Kayes and Hua Wang and Timothy R. McIntosh},
  doi          = {10.1145/3653297},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {204:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Privacy preservation of electronic health records in the modern era: A systematic survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Epidemic model-based network influential node ranking
methods: A ranking rationality perspective. <em>CSUR</em>,
<em>56</em>(8), 203:1–39. (<a
href="https://doi.org/10.1145/3653296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing surveys and reviews on Influential Node Ranking Methods (INRMs) have primarily focused on technical details, neglecting thorough research on verifying the actual influence of these nodes in a network. This oversight may result in erroneous rankings. In this survey, we address this gap by conducting an extensive analysis of 82 primary studies related to INRMs based on the epidemic model over the past 20 years. We statistically analyze and categorize benchmark networks into four types, and conclude that high-quality networks with complete information are insufficient and most INRMs only focus on undirected and unweighted networks, which encourages collaboration between industry and academia to provide optimized networks. Additionally, we categorize and discuss the strengths, weaknesses, and optimized crafts of seven categories of INRMs, helping engineers and researchers narrow down their choices when selecting appropriate INRMs for their specific needs. Furthermore, we define the Capability and Correctness metrics and utilize their usage frequency and functionality to assist engineers and researchers in prioritizing and selecting suitable metrics for different INRMs and networks. To our knowledge, this is the first survey that systematically summarizes the Capability and Correctness of INRMs, providing insights for the complex network community and aiding INRM selection and evaluation.},
  archive      = {J_CSUR},
  author       = {Bing Zhang and Xuyang Zhao and Jiangtian Nie and Jianhang Tang and Yuling Chen and Yang Zhang and Dusit Niyato},
  doi          = {10.1145/3653296},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {203:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Epidemic model-based network influential node ranking methods: A ranking rationality perspective},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on cyber-resilience approaches for cyber-physical
systems. <em>CSUR</em>, <em>56</em>(8), 202:1–37. (<a
href="https://doi.org/10.1145/3652953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concerns for the resilience of Cyber-Physical Systems (CPS)s in critical infrastructure are growing. CPS integrate sensing, computation, control, and networking into physical objects and mission-critical services, connecting traditional infrastructure to internet technologies. While this integration increases service efficiency, it has to face the possibility of new threats posed by the new functionalities. This leads to cyber-threats, such as denial-of-service, modification of data, information leakage, spreading of malware, and many others. Cyber-resilience refers to the ability of a CPS to prepare, absorb, recover, and adapt to the adverse effects associated with cyber-threats, e.g., physical degradation of the CPS performance resulting from a cyber-attack. Cyber-resilience aims at ensuring CPS survival by keeping the core functionalities of the CPS in case of extreme events. The literature on cyber-resilience is rapidly increasing, leading to a broad variety of research works addressing this new topic. In this article, we create a systematization of knowledge about existing scientific efforts of making CPSs cyber-resilient. We systematically survey recent literature addressing cyber-resilience with a focus on techniques that may be used on CPSs. We first provide preliminaries and background on CPSs and threats, and subsequently survey state-of-the-art approaches that have been proposed by recent research work applicable to CPSs. In particular, we aim at differentiating research work from traditional risk management approaches based on the general acceptance that it is unfeasible to prevent and mitigate all possible risks threatening a CPS. We also discuss questions and research challenges, with a focus on the practical aspects of cyber-resilience, such as the use of metrics and evaluation methods as well as testing and validation environments.},
  archive      = {J_CSUR},
  author       = {Mariana Segovia-Ferreira and Jose Rubio-Hernan and Ana Cavalli and Joaquin Garcia-Alfaro},
  doi          = {10.1145/3652953},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {202:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on cyber-resilience approaches for cyber-physical systems},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mobile near-infrared sensing—a systematic review on devices,
data, modeling, and applications. <em>CSUR</em>, <em>56</em>(8),
201:1–36. (<a href="https://doi.org/10.1145/3652596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile near-infrared sensing is becoming an increasingly important method in many research and industrial areas. To help consolidate progress in this area, we use the PRISMA guidelines to conduct a systematic review of mobile near-infrared sensing, including (1) existing prototypes and commercial products, (2) data collection techniques, (3) machine learning methods, and (4) relevant application areas. Our work measures historical and current trends and identifies current challenges and future directions for this emerging topic.},
  archive      = {J_CSUR},
  author       = {Weiwei Jiang and Jorge Goncalves and Vassilis Kostakos},
  doi          = {10.1145/3652596},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {201:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Mobile near-infrared Sensing—A systematic review on devices, data, modeling, and applications},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive review and new taxonomy on superpixel
segmentation. <em>CSUR</em>, <em>56</em>(8), 200:1–39. (<a
href="https://doi.org/10.1145/3652509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Superpixel segmentation consists of partitioning images into regions composed of similar and connected pixels. Its methods have been widely used in many computer vision applications, since it allows for reducing the workload, removing redundant information, and preserving regions with meaningful features. Due to the rapid progress in this area, the literature fails to catch up on more recent works among the compared ones and to categorize the methods according to all existing strategies. This work fills this gap by presenting a comprehensive review with a new taxonomy for superpixel segmentation, in which methods are classified according to their processing steps and processing levels of image features. We revisit the recent and popular literature according to our taxonomy and evaluate 23 strategies and a grid segmentation baseline based on nine criteria: connectivity, compactness, delineation, control over the number of superpixels, color homogeneity, robustness, running time, stability, and visual quality. Our experiments show the trends of each approach in superpixel segmentation and discuss individual trade-offs. Finally, we provide a new benchmark for superpixel assessment, available at https://github.com/IMScience-PPGINF-PucMinas/superpixel-benchmark .},
  archive      = {J_CSUR},
  author       = {Isabela Borlido Barcelos and Felipe De Castro Belém and Leonardo De Melo João and Zenilton K. G. Do Patrocínio and Alexandre Xavier Falcão and Silvio Jamil Ferzoli Guimarães},
  doi          = {10.1145/3652509},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {200:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive review and new taxonomy on superpixel segmentation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scenario-based adaptations of differential privacy: A
technical survey. <em>CSUR</em>, <em>56</em>(8), 199:1–39. (<a
href="https://doi.org/10.1145/3651153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy has been a de facto privacy standard in defining privacy and handling privacy preservation. It has had great success in scenarios of local data privacy and statistical dataset privacy. As a primitive definition, standard differential privacy has been adapted to a wide range of practical scenarios. In this work, we summarize differential privacy adaptations in specific scenarios and analyze the correlations between data characteristics and differential privacy design. We mainly present them in two lines including differential privacy adaptations in local data privacy and differential privacy adaptations in statistical dataset privacy. With a focus on differential privacy design, this survey targets providing guiding rules in differential privacy design for scenarios, together with identifying potential opportunities to adaptively apply differential privacy in more emerging technologies and further improve differential privacy itself with the assistance of cryptographic primitives.},
  archive      = {J_CSUR},
  author       = {Ying Zhao and Jia Tina Du and Jinjun Chen},
  doi          = {10.1145/3651153},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {199:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Scenario-based adaptations of differential privacy: A technical survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on content retrieval on the decentralised web.
<em>CSUR</em>, <em>56</em>(8), 198:1–39. (<a
href="https://doi.org/10.1145/3649132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control, governance, and management of the web have become increasingly centralised, resulting in security, privacy, and censorship concerns. Decentralised initiatives have emerged to address these issues, beginning with decentralised file systems. These systems have gained popularity, with major platforms serving millions of content requests daily. Complementing the file systems are decentralised search engines and name-registry infrastructures, together forming the basis of a decentralised web . This survey article analyses research trends and emerging technologies for content retrieval on the decentralised web, encompassing both academic literature and industrial projects. Several challenges hinder the realisation of a fully decentralised web. Achieving comparable performance to centralised systems without compromising decentralisation is a key challenge. Hybrid infrastructures, blending centralised components with verifiability mechanisms, show promise to improve decentralised initiatives. While decentralised file systems have seen more mature deployments, they still face challenges such as usability, performance, privacy, and content moderation. Integrating these systems with decentralised name-registries offers a potential for improved usability with human-readable and persistent names for content. Further research is needed to address security concerns in decentralised name-registries and enhance governance and crypto-economic incentive mechanisms.},
  archive      = {J_CSUR},
  author       = {Navin Keizer and Onur Ascigil and Michal Król and Dirk Kutscher and George Pavlou},
  doi          = {10.1145/3649132},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {198:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on content retrieval on the decentralised web},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computational techniques in PET/CT image processing for
breast cancer: A systematic mapping review. <em>CSUR</em>,
<em>56</em>(8), 197:1–38. (<a
href="https://doi.org/10.1145/3648359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem arises from the lack of sufficient and comprehensive information about the necessary computer techniques. These techniques are crucial for developing information systems that assist doctors in diagnosing breast cancer, especially those related to positron emission tomography and computed tomography (PET/CT). Despite global efforts in breast cancer prevention and control, the scarcity of literature poses an obstacle to a complete understanding in this area of interest. The methodologies studied were systematic mapping and systematic literature review. For each article, the journal, conference, year of publication, dataset, breast cancer characteristics, PET/CT processing techniques, metrics and diagnostic yield results were identified. Sixty-four articles were analyzed, 44 (68.75%) belong to journals and 20 (31.25%) belong to the conference category. A total of 102 techniques were identified, which were distributed in preprocessing with 7 (6.86%), segmentation with 15 (14.71%), feature extraction with 15 (14.71%), and classification with 65 (63.73%). The techniques with the highest incidence identified in each stage are: Gaussian Filter, SLIC, Local Binary Pattern, and Support Vector Machine with 4, 2, 7, and 35 occurrences, respectively. Support Vector Machine is the predominant technique in the classification stage, due to the fact that Artificial Intelligence is emerging in medical image processing and health care to make expert systems increasingly intelligent and obtain favorable results.},
  archive      = {J_CSUR},
  author       = {Karen Carrasco and Lenin Tomalá and Eileen Ramírez Meza and Doris Meza Bolaños and Washington Ramírez Montalvan},
  doi          = {10.1145/3648359},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {197:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Computational techniques in PET/CT image processing for breast cancer: A systematic mapping review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on cyber resilience: Key strategies, research
challenges, and future directions. <em>CSUR</em>, <em>56</em>(8),
196:1–48. (<a href="https://doi.org/10.1145/3649218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber resilience has become a major concern for both academia and industry due to the increasing number of data breaches caused by the expanding attack surface of existing IT infrastructure. Cyber resilience refers to an organisation’s ability to prepare for, absorb, recover from, and adapt to adverse effects typically caused by cyber-attacks that affect business operations. In this survey, we aim to identify the significant domains of cyber resilience and measure their effectiveness. We have selected these domains based on a literature review of frameworks, strategies, applications, tools, and technologies. We have outlined the cyber resilience requirements for each domain and explored solutions related to each requirement in detail. We have also compared and analysed different studies in each domain to find other ways of enhancing cyber resilience. Furthermore, we have compared cyber resilience frameworks and strategies based on technical requirements for various applications. We have also elaborated on techniques for improving cyber resilience. In the supplementary section, we have presented applications that have implemented cyber resilience. This survey comprehensively compares various popular cyber resilience tools to help researchers, practitioners, and organisations choose the best practices for enhancing cyber resilience. Finally, we have shared key findings, limitations, problems, and future directions.},
  archive      = {J_CSUR},
  author       = {Saleh Mohamed Alhidaifi and Muhammad Rizwan Asghar and Imran Shafique Ansari},
  doi          = {10.1145/3649218},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {196:1–48},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on cyber resilience: Key strategies, research challenges, and future directions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on robotic prosthetics: Neuroprosthetics, soft
actuators, and control strategies. <em>CSUR</em>, <em>56</em>(8),
195:1–44. (<a href="https://doi.org/10.1145/3648355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of robotics is a quickly evolving feat of technology that accepts contributions from various genres of science. Neuroscience, Physiology, Chemistry, Material science, Computer science, and the wide umbrella of mechatronics have all simultaneously contributed to many innovations in the prosthetic applications of robotics. This review begins with a discussion of the scope of the term robotic prosthetics and discusses the evolving domain of Neuroprosthetics. The discussion is then constrained to focus on various actuation and control strategies for robotic prosthetic limbs. This review discusses various soft robotic actuators such as EAP, SMA, FFA, and so on, and the merits of such actuators over conventional hard robotic actuators. Options in control strategies for robotic prosthetics, that are in various states of research and development, are reviewed. This article concludes the discussion with an analysis regarding the prospective direction in which this field of robotic prosthetics is evolving in terms of actuation, control, and other features relevant to artificial limbs. This article intends to review some of the emerging research and development trends in the field of robotic prosthetics and summarize many tangents that are represented under this broad domain in an approachable manner.},
  archive      = {J_CSUR},
  author       = {K. J. Jyothish and Subhankar Mishra},
  doi          = {10.1145/3648355},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {195:1–44},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on robotic prosthetics: Neuroprosthetics, soft actuators, and control strategies},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey on haptic feedback through sensory illusions in
interactive systems. <em>CSUR</em>, <em>56</em>(8), 194:1–39. (<a
href="https://doi.org/10.1145/3648353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing body of work in human-computer interaction (HCI), particularly work on haptic feedback and haptic displays, relies on sensory illusions, which is a phenomenon investigated in perception research. However, an overview of which illusions are prevalent in HCI for generating haptic feedback in computing systems and which remain underrepresented, as well as the rationales and possible undiscovered potentials therein, have not yet been provided. Existing surveys on human-computer interfaces using sensory illusions are not only outdated but, more importantly, they do not consider literature across disciplines, namely, perception research and HCI. This article provides a systematic literature review of haptic feedback generated by sensory illusions. By reporting and discussing the findings of 90 publications, we provide an overview of how sensory illusions can be used and adapted to produce haptic feedback and how they are implemented and evaluated in HCI. We moreover identify current trends and research gaps and discuss ideas for possible research directions worth investigating.},
  archive      = {J_CSUR},
  author       = {Marco Kurzweg and Yannick Weiss and Marc O. Ernst and Albrecht Schmidt and Katrin Wolf},
  doi          = {10.1145/3648353},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {194:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on haptic feedback through sensory illusions in interactive systems},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic literature review on maintenance of software
containers. <em>CSUR</em>, <em>56</em>(8), 193:1–38. (<a
href="https://doi.org/10.1145/3645092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, cloud computing is gaining tremendous attention to deliver information via the internet. Virtualization plays a major role in cloud computing as it deploys multiple virtual machines on the same physical machine and thus results in improving resource utilization. Hypervisor-based virtualization and containerization are two commonly used approaches in operating system virtualization. In this article, we provide a systematic literature review on various phases in maintenance of containers including container image detection, container scheduling, container security measures, and performance evaluation of containers. We have selected 145 primary studies out of which 24% of studies are related to container performance evaluation, 42% of studies are related to container scheduling techniques, 22% of studies are related to container security measures, and 12% of studies are related to container image detection process. A few studies are related to container image detection process and evaluation of container security measures. Resource utilization is the most considered performance objective in almost all container scheduling techniques. We conclude that there is a need to introduce new tagging approaches, smell detection approaches, and also new approaches to detect and resolve threat issues in containers so that we can maintain the security of containers.},
  archive      = {J_CSUR},
  author       = {Ruchika Malhotra and Anjali Bansal and Marouane Kessentini},
  doi          = {10.1145/3645092},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {193:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on maintenance of software containers},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Social network analysis: A survey on process, tools, and
application. <em>CSUR</em>, <em>56</em>(8), 192:1–39. (<a
href="https://doi.org/10.1145/3648470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the explosive rise of online social networks, social network analysis (SNA) has emerged as a significant academic field in recent years. Understanding and examining social relationships in networks through network analysis opens up numerous research avenues in sociology, literature, media, biology, computer science, sports, and more. Therefore, certain studies review and discuss some research verticals of SNA, such as viral marketing, information diffusion, clustering, link prediction, and so on, to provide background knowledge and understanding. These studies still lack the SNA process, tools, and practical aspects in multidisciplinary applications. Inspired by these facts, we have discussed the background, process, tools, and application of SNA. First, we have presented a detailed description of the SNA process. Thereafter, we presented a comparative analysis of SNA tools and languages. Finally, we have discussed the various applications corresponding to SNA research verticals.},
  archive      = {J_CSUR},
  author       = {Shashank Sheshar Singh and Samya Muhuri and Shivansh Mishra and Divya Srivastava and Harish Kumar Shakya and Neeraj Kumar},
  doi          = {10.1145/3648470},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {192:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Social network analysis: A survey on process, tools, and application},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed graph neural network training: A survey.
<em>CSUR</em>, <em>56</em>(8), 191:1–39. (<a
href="https://doi.org/10.1145/3648358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are a type of deep learning models that are trained on graphs and have been successfully applied in various domains. Despite the effectiveness of GNNs, it is still challenging for GNNs to efficiently scale to large graphs. As a remedy, distributed computing becomes a promising solution of training large-scale GNNs, since it is able to provide abundant computing resources. However, the dependency of graph structure increases the difficulty of achieving high-efficiency distributed GNN training, which suffers from the massive communication and workload imbalance. In recent years, many efforts have been made on distributed GNN training, and an array of training algorithms and systems have been proposed. Yet, there is a lack of systematic review of the optimization techniques for the distributed execution of GNN training. In this survey, we analyze three major challenges in distributed GNN training: massive feature communication, the loss of model accuracy, and workload imbalance. Then, we introduce a new taxonomy for the optimization techniques in distributed GNN training that address the above challenges. The new taxonomy classifies existing techniques into four categories: GNN data partition, GNN batch generation, GNN execution model, and GNN communication protocol. We carefully discuss the techniques in each category. In the conclusion, we summarize existing distributed GNN systems for multi–graphics processing units (GPUs), GPU-clusters and central processing unit (CPU)-clusters, respectively, and present a discussion about the future direction of distributed GNN training.},
  archive      = {J_CSUR},
  author       = {Yingxia Shao and Hongzheng Li and Xizhi Gu and Hongbo Yin and Yawen Li and Xupeng Miao and Wentao Zhang and Bin Cui and Lei Chen},
  doi          = {10.1145/3648358},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {8},
  pages        = {191:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Distributed graph neural network training: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent wearable systems: Opportunities and challenges
in health and sports. <em>CSUR</em>, <em>56</em>(7), 190:1–42. (<a
href="https://doi.org/10.1145/3648469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable devices, or wearables, designed to be attached to the human body, can gather personalized real-time data and continuously monitor an individual’s health status and physiological disposition in a non-invasive manner. Intelligent wearables integrate advanced machine learning algorithms to process complex data patterns and provide accurate insights. As a result, intelligent wearables have emerged as a ground-breaking innovation in the fields of sports and health, introducing a new paradigm in kinematic analysis and patient data evaluation. For example, virtual coaches offer feedback on athletes’ performance, whereas virtual physicians assist in customizing medication for patients. This article provides an overview of various types of intelligent wearables and their applications in health and sports, categorizes machine learning algorithms, and introduces the wireless body area sensor network (WBASN) used for communication in wearable sensors. Additionally, we discuss potential challenges and development directions that could shape the future of intelligent wearables and propose effective solutions for their continued enhancement. This article offers valuable insights into the exciting potential of intelligent wearables to transform healthcare and sports.},
  archive      = {J_CSUR},
  author       = {Luyao Yang and Osama Amin and Basem Shihada},
  doi          = {10.1145/3648469},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {190:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Intelligent wearable systems: Opportunities and challenges in health and sports},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized video anomaly event detection: Systematic
taxonomy and comparison of deep models. <em>CSUR</em>, <em>56</em>(7),
189:1–38. (<a href="https://doi.org/10.1145/3645101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video Anomaly Detection (VAD) serves as a pivotal technology in the intelligent surveillance systems, enabling the temporal or spatial identification of anomalous events within videos. While existing reviews predominantly concentrate on conventional unsupervised methods, they often overlook the emergence of weakly-supervised and fully-unsupervised approaches. To address this gap, this survey extends the conventional scope of VAD beyond unsupervised methods, encompassing a broader spectrum termed Generalized Video Anomaly Event Detection (GVAED). By skillfully incorporating recent advancements rooted in diverse assumptions and learning frameworks, this survey introduces an intuitive taxonomy that seamlessly navigates through unsupervised, weakly-supervised, supervised and fully-unsupervised VAD methodologies, elucidating the distinctions and interconnections within these research trajectories. In addition, this survey facilitates prospective researchers by assembling a compilation of research resources, including public datasets, available codebases, programming tools, and pertinent literature. Furthermore, this survey quantitatively assesses model performance, delves into research challenges and directions, and outlines potential avenues for future exploration.},
  archive      = {J_CSUR},
  author       = {Yang Liu and Dingkang Yang and Yan Wang and Jing Liu and Jun Liu and Azzedine Boukerche and Peng Sun and Liang Song},
  doi          = {10.1145/3645101},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {189:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Generalized video anomaly event detection: Systematic taxonomy and comparison of deep models},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Going beyond XAI: A systematic survey for explanation-guided
learning. <em>CSUR</em>, <em>56</em>(7), 188:1–39. (<a
href="https://doi.org/10.1145/3644073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the societal impact of Deep Neural Networks (DNNs) grows, the goals for advancing DNNs become more complex and diverse, ranging from improving a conventional model accuracy metric to infusing advanced human virtues such as fairness, accountability, transparency, and unbiasedness. Recently, techniques in Explainable Artificial Intelligence (XAI) have been attracting considerable attention and have tremendously helped Machine Learning (ML) engineers in understand AI models. However, at the same time, we started to witness the emerging need beyond XAI among AI communities; based on the insights learned from XAI, how can we better empower ML engineers in steering their DNNs so that the model’s reasonableness and performance can be improved as intended? This article provides a timely and extensive literature overview of the field Explanation-Guided Learning (EGL), a domain of techniques that steer the DNNs’ reasoning process by adding regularization, supervision, or intervention on model explanations. In doing so, we first provide a formal definition of EGL and its general learning paradigm. Second, an overview of the key factors for EGL evaluation, as well as summarization and categorization of existing evaluation procedures and metrics for EGL are provided. Finally, the current and potential future application areas and directions of EGL are discussed, and an extensive experimental study is presented aiming at providing comprehensive comparative studies among existing EGL models in various popular application domains, such as Computer Vision and Natural Language Processing domains. Additional resources related to event prediction are included in the article website: https://kugaoyang.github.io/EGL/},
  archive      = {J_CSUR},
  author       = {Yuyang Gao and Siyi Gu and Junji Jiang and Sungsoo Ray Hong and Dazhou Yu and Liang Zhao},
  doi          = {10.1145/3644073},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {188:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Going beyond XAI: A systematic survey for explanation-guided learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey and an empirical evaluation of multi-view
clustering approaches. <em>CSUR</em>, <em>56</em>(7), 187:1–38. (<a
href="https://doi.org/10.1145/3645108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) holds a significant role in domains like machine learning, data mining, and pattern recognition. Despite the development of numerous new MVC approaches employing various techniques, there remains a gap in comprehensive studies evaluating the characteristics and performance of these approaches. This gap hinders the in-depth understanding and rational utilization of the recently developed MVC techniques. This study formalizes the basic concepts of MVC and analyzes their techniques. It then introduces a novel taxonomy for MVC approaches and presents the working mechanisms and characteristics of representative MVC approaches developed in recent years. Moreover, it summarizes representative datasets and performance metrics commonly employed for evaluating MVC approaches. Furthermore, we have meticulously chosen 35 representative MVC approaches to conduct an empirical evaluation across seven real-world benchmark datasets, offering valuable insights into the realm of MVC approaches.},
  archive      = {J_CSUR},
  author       = {Lihua Zhou and Guowang Du and Kevin Lü and Lizheng Wang and Jingwei Du},
  doi          = {10.1145/3645108},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {187:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey and an empirical evaluation of multi-view clustering approaches},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An all-inclusive taxonomy and critical review of
blockchain-assisted authentication and session key generation protocols
for IoT. <em>CSUR</em>, <em>56</em>(7), 186:1–38. (<a
href="https://doi.org/10.1145/3645087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Authentication and Session Key Generation Protocols (SKGPs) play an essential role in securing the communication channels of connected Internet of Things (IoT) devices. Recently, through blockchain integration, scholars have tried to enhance the security and applicability of SKGPs. In brief, blockchain is a distributed ledger technology that can provide interesting features such as immutability, transparency, and accountability without any need for the active participation of trusted parties. This survey presents a comprehensive critical review of blockchain-assisted authentication and SKGPs, suggested for different IoT domains, including Internet of Vehicles, Internet of Drones, and Industrial IoT. Our survey categorizes existing schemes based on several criteria, including IoT application domains, security aspects, and blockchain components. By presenting an unbiased critical review and taxonomy of protocols, we aim to clarify the key challenges. Our review will specifically indicate what properties authors gained or lost through the integration of blockchain. To our best knowledge, this survey is the only one that offers all prerequisites for interested readers in blockchain-integrated SKGPs, such as security features and attacks, attack models, verification tools, blockchain types, blockchain platforms, and consensus mechanisms. Further, our survey elaborates existing research gaps in blockchain-assisted SKGPs. In doing so, we aim to guide future research in this field and provide researchers with the essential information they require.},
  archive      = {J_CSUR},
  author       = {Ali Shahidinejad and Jemal Abawajy},
  doi          = {10.1145/3645087},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {186:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {An all-inclusive taxonomy and critical review of blockchain-assisted authentication and session key generation protocols for IoT},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Utilizing BERT for information retrieval: Survey,
applications, resources, and challenges. <em>CSUR</em>, <em>56</em>(7),
185:1–33. (<a href="https://doi.org/10.1145/3648471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed a substantial increase in the use of deep learning to solve various natural language processing (NLP) problems. Early deep learning models were constrained by their sequential or unidirectional nature, such that they struggled to capture the contextual relationships across text inputs. The introduction of bidirectional encoder representations from transformers (BERT) leads to a robust encoder for the transformer model that can understand the broader context and deliver state-of-the-art performance across various NLP tasks. This has inspired researchers and practitioners to apply BERT to practical problems, such as information retrieval (IR). A survey that focuses on a comprehensive analysis of prevalent approaches that apply pretrained transformer encoders like BERT to IR can thus be useful for academia and the industry. In light of this, we revisit a variety of BERT-based methods in this survey, cover a wide range of techniques of IR, and group them into six high-level categories: (i) handling long documents, (ii) integrating semantic information, (iii) balancing effectiveness and efficiency, (iv) predicting the weights of terms, (v) query expansion, and (vi) document expansion. We also provide links to resources, including datasets and toolkits, for BERT-based IR systems. Additionally, we highlight the advantages of employing encoder-based BERT models in contrast to recent large language models like ChatGPT, which are decoder-based and demand extensive computational resources. Finally, we summarize the comprehensive outcomes of the survey and suggest directions for future research in the area.},
  archive      = {J_CSUR},
  author       = {Jiajia Wang and Jimmy Xiangji Huang and Xinhui Tu and Junmei Wang and Angela Jennifer Huang and Md Tahmid Rahman Laskar and Amran Bhuiyan},
  doi          = {10.1145/3648471},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {185:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Utilizing BERT for information retrieval: Survey, applications, resources, and challenges},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Who’s in charge here? A survey on trustworthy AI in variable
autonomy robotic systems. <em>CSUR</em>, <em>56</em>(7), 184:1–32. (<a
href="https://doi.org/10.1145/3645090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article surveys the Variable Autonomy (VA) robotics literature that considers two contributory elements to Trustworthy AI: transparency and explainability. These elements should play a crucial role when designing and adopting robotic systems, especially in VA where poor or untimely adjustments of the system’s level of autonomy can lead to errors, control conflicts, user frustration, and ultimate disuse of the system. Despite this need, transparency and explainability is, to the best of our knowledge, mostly overlooked in VA robotics literature or is not considered explicitly. In this article, we aim to present and examine the most recent contributions to the VA literature concerning transparency and explainability. In addition, we propose a way of thinking about VA by breaking these two concepts down based on: the mission of the human-robot team; who the stakeholder is; what needs to be made transparent or explained; why they need it; and how it can be achieved. Last, we provide insights and propose ways to move VA research forward. Our goal with this article is to raise awareness and inter-community discussions among the Trustworthy AI and the VA robotics communities.},
  archive      = {J_CSUR},
  author       = {Leila Methnani and Manolis Chiou and Virginia Dignum and Andreas Theodorou},
  doi          = {10.1145/3645090},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {184:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Who’s in charge here? a survey on trustworthy AI in variable autonomy robotic systems},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wearable activity trackers: A survey on utility, privacy,
and security. <em>CSUR</em>, <em>56</em>(7), 183:1–40. (<a
href="https://doi.org/10.1145/3645091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, wearable activity trackers (WATs) have become increasingly popular. However, despite many research studies in different fields (e.g. psychology, health, and design), few have sought to jointly examine the critical aspects of utility (i.e., benefits brought by these devices), privacy, and security (i.e., risks and vulnerabilities associated with them). To fill this gap, we reviewed 236 studies that researched the benefits of using WATs, the implications for the privacy of users of WATs, and the security vulnerabilities of these devices. Our survey revealed that these devices expose users to several threats. For example, WAT data can be mined to infer private information, such as the personality traits of the user. Whereas many works propose empirical findings about users’ privacy perceptions and their behaviors in relation to privacy, we found relatively few studies researching technologies to better protect users’ privacy with these devices. This survey contributes to systematizing knowledge on the utility, privacy, and security of WATs, shedding light on the state-of-the-art approaches with these devices, and discussing open research opportunities.},
  archive      = {J_CSUR},
  author       = {Kavous Salehzadeh Niksirat and Lev Velykoivanenko and Noé Zufferey and Mauro Cherubini and Kévin Huguenin and Mathias Humbert},
  doi          = {10.1145/3645091},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {183:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Wearable activity trackers: A survey on utility, privacy, and security},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic mapping study on social network privacy:
Threats and solutions. <em>CSUR</em>, <em>56</em>(7), 182:1–29. (<a
href="https://doi.org/10.1145/3645086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online Social Networks (OSNs) are becoming pervasive in today’s world. Millions of people worldwide are involved in different forms of online networking. However, this ease of use of OSNs comes with a cost in terms of privacy. Users of OSNs become victims of identity theft, cyberstalking, and information leakage, which are real threats to privacy. These threats can obtain a user’s personal information and disclose it for malicious purposes. To understand how researchers are addressing this question, the state of the art of the existing privacy threats in OSNs described in the literature and the existing academic research-based solutions to address such threats were reviewed. To this end, we performed a systematic mapping study to identify, classify and analyze them. From the initial set of 1,117 papers, we selected and extracted 45 publications reporting different threats and solutions. Based on this, this is the first systematic mapping study, to provide: a) well-defined categories of specific privacy threats in the OSN domain; and b) the available academic solutions for preventing these threats. Our results serve as a guide for researchers and analysts in academia and industry to understand the most important privacy threats in OSNs and make moves towards mitigating them.},
  archive      = {J_CSUR},
  author       = {Andrey Rodrigues and Maria Lúcia Villela and Eduardo Feitosa},
  doi          = {10.1145/3645086},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {182:1–29},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic mapping study on social network privacy: Threats and solutions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient high-resolution deep learning: A survey.
<em>CSUR</em>, <em>56</em>(7), 181:1–35. (<a
href="https://doi.org/10.1145/3645107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cameras in modern devices such as smartphones, satellites and medical equipment are capable of capturing very high resolution images and videos. Such high-resolution data often need to be processed by deep learning models for cancer detection, automated road navigation, weather prediction, surveillance, optimizing agricultural processes and many other applications. Using high-resolution images and videos as direct inputs for deep learning models creates many challenges due to their high number of parameters, computation cost, inference latency and GPU memory consumption. Simple approaches such as resizing the images to a lower resolution are common in the literature, however, they typically significantly decrease accuracy. Several works in the literature propose better alternatives in order to deal with the challenges of high-resolution data and improve accuracy and speed while complying with hardware limitations and time restrictions. This survey describes such efficient high-resolution deep learning methods, summarizes real-world applications of high-resolution deep learning, and provides comprehensive information about available high-resolution datasets.},
  archive      = {J_CSUR},
  author       = {Arian Bakhtiarnia and Qi Zhang and Alexandros Iosifidis},
  doi          = {10.1145/3645107},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {181:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Efficient high-resolution deep learning: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on reversible data hiding for uncompressed images.
<em>CSUR</em>, <em>56</em>(7), 180:1–33. (<a
href="https://doi.org/10.1145/3645105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reversible data hiding (RDH) has developed various theories and algorithms since the early 1990s. The existing works involve a large amount of specialized knowledge, making it difficult for researchers, especially primary learners, to have a good grounding in the basic ideas. In this survey, we will review the mainstream RDH algorithms in uncompressed images and analyze their unique features to provide readers with an introduction to basic topics in RDH. We analyze the most effective RDH frameworks and their common extensions. The classic techniques, including lossless compression-based RDH, difference expansion, integer transform, histogram shifting, prediction-error expansion (PEE), and their extensions, will be reviewed first. Then, three currently popular investigated schemes, i.e., multiple histograms modification, pairwise PEE, and pixel-value-ordering, are presented in detail. Four aspects of these mainstream techniques are reviewed and analyzed, including the evolution of embedding frameworks, detailed technological features, extensions, and the current state of the art. Furthermore, we look forward the possible future research based on early-age motivations.},
  archive      = {J_CSUR},
  author       = {Cheng Zhang and Bo Ou and Fei Peng and Yao Zhao and Keqin Li},
  doi          = {10.1145/3645105},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {180:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on reversible data hiding for uncompressed images},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchain data storage optimisations: A comprehensive
survey. <em>CSUR</em>, <em>56</em>(7), 179:1–27. (<a
href="https://doi.org/10.1145/3645104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain offers immutability, transparency, and security in a decentralised way for many applications, including finance, supply chain, and the Internet of Things (IoT). Due to its popularity and widespread adoption, it has started to process an enormous number of transactions, placing an ever-growing demand for storage. As the technology gains more popularity, the storage requirements of blockchain will increase, necessitating storage optimisation solutions. Proposed solutions for blockchain storage efficiency range from reducing the degree of data replication to redacting or compressing data. Each of these storage optimisation categories involves a complex interplay with the timing of blockchain data processing and mining, yet no existing survey analyses these dimensions. This article surveys the state-of-the-art blockchain storage optimisations and categorises them into replication-based, redaction-based, and content-based optimisations. Replication-based optimisations focus on reducing duplication of blockchain data shared among participants after committing data on the blockchain ledger. Redaction-based optimisations allow users to modify or delete data already committed on the ledger in various ways, while content-based optimisations compress data before or after committing it to the ledger. We analyse and evaluate these solutions in the aspects of security, decentralisation, and scalability. We present the advantages and disadvantages of the existing blockchain storage optimisations and comprehensively compare them. Additionally, we discuss the opportunities and challenges for future work to optimise blockchain storage.},
  archive      = {J_CSUR},
  author       = {Jun Wook Heo and Gowri Sankar Ramachandran and Ali Dorri and Raja Jurdak},
  doi          = {10.1145/3645104},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {179:1–27},
  shortjournal = {ACM Comput. Surv.},
  title        = {Blockchain data storage optimisations: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Timing side-channel attacks and countermeasures in CPU
microarchitectures. <em>CSUR</em>, <em>56</em>(7), 178:1–40. (<a
href="https://doi.org/10.1145/3645109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microarchitectural vulnerabilities, such as Meltdown and Spectre, exploit subtle microarchitecture state to steal the user’s secret data and even compromise the operating systems. In recent years, considerable discussion lies in understanding the attack-defense mechanisms and exploitability of such vulnerabilities. Unfortunately, there have been few investigations into a systematic elaboration of threat models, attack scenarios and requirements, and defense targets of the resulting attacks. In this article, we fill this gap and make the following contributions. We first propose two sets of taxonomies for classifying microarchitectural timing side-channel attacks and their countermeasures according to various attack conditions. Based on the taxonomies proposed, we then review published attacks and existing defenses and systematically analyze their internals. In particular, we also provide a comprehensive analysis of the similarities and differences among those attacks, uncovering the corresponding practicality and severity by identifying the attack targets/platforms and the security boundaries that can be bypassed to reveal information. We further examine the scalability of those defenses through specifying expected defense goals and costs. We also discuss corresponding detection methods based on different classifications. Finally, we propose several key challenges of existing countermeasures and the attack trends, and discuss directions for future research.},
  archive      = {J_CSUR},
  author       = {Jiliang Zhang and Congcong Chen and Jinhua Cui and Keqin Li},
  doi          = {10.1145/3645109},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {178:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Timing side-channel attacks and countermeasures in CPU microarchitectures},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review of cross-lingual sentiment analysis:
Tasks, strategies, and prospects. <em>CSUR</em>, <em>56</em>(7),
177:1–37. (<a href="https://doi.org/10.1145/3645106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods for sentiment analysis, when applied in a monolingual context, often yield less than optimal results in multilingual settings. This underscores the need for a more thorough exploration of cross-lingual sentiment analysis (CLSA) methodologies to improve analytical effectiveness. CLSA, confronted with obstacles such as linguistic disparities and a lack of resources, seeks to evaluate sentiments across a range of languages. First, the research background, challenges, existing solution ideas, and evaluation tasks of CLSA are summarized. Subsequently, new perspectives including different granularity levels, machine translation support, and sentiment transfer strategies perspectives are highlighted. Finally, potential avenues for future research are discussed.},
  archive      = {J_CSUR},
  author       = {Chuanjun Zhao and Meiling Wu and Xinyi Yang and Wenyue Zhang and Shaoxia Zhang and Suge Wang and Deyu Li},
  doi          = {10.1145/3645106},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {177:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic review of cross-lingual sentiment analysis: Tasks, strategies, and prospects},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence for safety-critical systems in
industrial and transportation domains: A survey. <em>CSUR</em>,
<em>56</em>(7), 176:1–40. (<a
href="https://doi.org/10.1145/3626314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) can enable the development of next-generation autonomous safety-critical systems in which Machine Learning (ML) algorithms learn optimized and safe solutions. AI can also support and assist human safety engineers in developing safety-critical systems. However, reconciling both cutting-edge and state-of-the-art AI technology with safety engineering processes and safety standards is an open challenge that must be addressed before AI can be fully embraced in safety-critical systems. Many works already address this challenge, resulting in a vast and fragmented literature. Focusing on the industrial and transportation domains, this survey structures and analyzes challenges, techniques, and methods for developing AI-based safety-critical systems, from traditional functional safety systems to autonomous systems. AI trustworthiness spans several dimensions, such as engineering, ethics and legal, and this survey focuses on the safety engineering dimension.},
  archive      = {J_CSUR},
  author       = {Jon Perez-Cerrolaza and Jaume Abella and Markus Borg and Carlo Donzella and Jesús Cerquides and Francisco J. Cazorla and Cristofer Englund and Markus Tauber and George Nikolakopoulos and Jose Luis Flores},
  doi          = {10.1145/3626314},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {176:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Artificial intelligence for safety-critical systems in industrial and transportation domains: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The path to defence: A roadmap to characterising data
poisoning attacks on victim models. <em>CSUR</em>, <em>56</em>(7),
175:1–39. (<a href="https://doi.org/10.1145/3627536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data Poisoning Attacks (DPA) represent a sophisticated technique aimed at distorting the training data of machine learning models, thereby manipulating their behavior. This process is not only technically intricate but also frequently dependent on the characteristics of the victim (target) model. To protect the victim model, the vast number of DPAs and their variants make defenders rely on trial and error techniques to find the ultimate defence solution which is exhausting and very time-consuming. This paper comprehensively summarises the latest research on DPAs and defences, proposes a DPA characterizing model to help investigate adversary attacks dependency on the victim model, and builds a DPA roadmap as the path navigating to defence. Having the roadmap as an applied framework that contains DPA families sharing the same features and mathematical computations will equip the defenders with a powerful tool to quickly find the ultimate defences, away from the exhausting trial and error methodology. The roadmap validated by use cases has been made available as an open access platform, enabling other researchers to add in new DPAs and update the map continuously.},
  archive      = {J_CSUR},
  author       = {Tarek Chaalan and Shaoning Pang and Joarder Kamruzzaman and Iqbal Gondal and Xuyun Zhang},
  doi          = {10.1145/3627536},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {175:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {The path to defence: A roadmap to characterising data poisoning attacks on victim models},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). It is all about data: A survey on the effects of data on
adversarial robustness. <em>CSUR</em>, <em>56</em>(7), 174:1–41. (<a
href="https://doi.org/10.1145/3627817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to confuse the model into making a mistake. Such examples pose a serious threat to the applicability of machine learning-based systems, especially in life- and safety-critical domains. To address this problem, the area of adversarial robustness investigates mechanisms behind adversarial attacks and defenses against these attacks. This survey reviews a particular subset of this literature that focuses on investigating properties of training data in the context of model robustness under evasion attacks. It first summarizes the main properties of data leading to adversarial vulnerability. It then discusses guidelines and techniques for improving adversarial robustness by enhancing the data representation and learning procedures, as well as techniques for estimating robustness guarantees given particular data. Finally, it discusses gaps of knowledge and promising future research directions in this area.},
  archive      = {J_CSUR},
  author       = {Peiyu Xiong and Michael Tegegn and Jaskeerat Singh Sarin and Shubhraneel Pal and Julia Rubin},
  doi          = {10.1145/3627817},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {174:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {It is all about data: A survey on the effects of data on adversarial robustness},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Responsible AI pattern catalogue: A collection of best
practices for AI governance and engineering. <em>CSUR</em>,
<em>56</em>(7), 173:1–35. (<a
href="https://doi.org/10.1145/3626234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Responsible Artificial Intelligence (RAI) is widely considered as one of the greatest scientific challenges of our time and is key to increase the adoption of Artificial Intelligence (AI). Recently, a number of AI ethics principles frameworks have been published. However, without further guidance on best practices, practitioners are left with nothing much beyond truisms. In addition, significant efforts have been placed at algorithm level rather than system level, mainly focusing on a subset of mathematics-amenable ethical principles, such as fairness. Nevertheless, ethical issues can arise at any step of the development lifecycle, cutting across many AI and non-AI components of systems beyond AI algorithms and models. To operationalize RAI from a system perspective, in this article, we present an RAI Pattern Catalogue based on the results of a multivocal literature review. Rather than staying at the principle or algorithm level, we focus on patterns that AI system stakeholders can undertake in practice to ensure that the developed AI systems are responsible throughout the entire governance and engineering lifecycle. The RAI Pattern Catalogue classifies the patterns into three groups: multi-level governance patterns, trustworthy process patterns, and RAI-by-design product patterns. These patterns provide systematic and actionable guidance for stakeholders to implement RAI.},
  archive      = {J_CSUR},
  author       = {Qinghua Lu and Liming Zhu and Xiwei Xu and Jon Whittle and Didar Zowghi and Aurelie Jacquet},
  doi          = {10.1145/3626234},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {173:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Responsible AI pattern catalogue: A collection of best practices for AI governance and engineering},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of dataset refinement for problems in computer
vision datasets. <em>CSUR</em>, <em>56</em>(7), 172:1–34. (<a
href="https://doi.org/10.1145/3627157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale datasets have played a crucial role in the advancement of computer vision. However, they often suffer from problems such as class imbalance, noisy labels, dataset bias, or high resource costs, which can inhibit model performance and reduce trustworthiness. With the advocacy of data-centric research, various data-centric solutions have been proposed to solve the dataset problems mentioned above. They improve the quality of datasets by re-organizing them, which we call dataset refinement. In this survey, we provide a comprehensive and structured overview of recent advances in dataset refinement for problematic computer vision datasets. 1 Firstly, we summarize and analyze the various problems encountered in large-scale computer vision datasets. Then, we classify the dataset refinement algorithms into three categories based on the refinement process: data sampling, data subset selection, and active learning. In addition, we organize these dataset refinement methods according to the addressed data problems and provide a systematic comparative description. We point out that these three types of dataset refinement have distinct advantages and disadvantages for dataset problems, which informs the choice of the data-centric method appropriate to a particular research objective. Finally, we summarize the current literature and propose potential future research topics.},
  archive      = {J_CSUR},
  author       = {Zhijing Wan and Zhixiang Wang and Cheukting Chung and Zheng Wang},
  doi          = {10.1145/3627157},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {172:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of dataset refinement for problems in computer vision datasets},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on graph counterfactual explanations: Definitions,
methods, evaluation, and research challenges. <em>CSUR</em>,
<em>56</em>(7), 171:1–37. (<a
href="https://doi.org/10.1145/3618105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) perform well in community detection and molecule classification. Counterfactual Explanations (CE) provide counter-examples to overcome the transparency limitations of black-box models. Due to the growing attention in graph learning, we focus on the concepts of CE for GNNs. We analysed the SoA to provide a taxonomy, a uniform notation, and the benchmarking datasets and evaluation metrics. We discuss fourteen methods, their evaluation protocols, twenty-two datasets, and nineteen metrics. We integrated the majority of methods into the GRETEL library to conduct an empirical evaluation to understand their strengths and pitfalls. We highlight open challenges and future work.},
  archive      = {J_CSUR},
  author       = {Mario Alfonso Prado-Romero and Bardh Prenkaj and Giovanni Stilo and Fosca Giannotti},
  doi          = {10.1145/3618105},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {171:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on graph counterfactual explanations: Definitions, methods, evaluation, and research challenges},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secure and trustworthy artificial intelligence-extended
reality (AI-XR) for metaverses. <em>CSUR</em>, <em>56</em>(7), 170:1–38.
(<a href="https://doi.org/10.1145/3614426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaverse is expected to emerge as a new paradigm for the next-generation Internet, providing fully immersive and personalized experiences to socialize, work, and play in self-sustaining and hyper-spatio-temporal virtual world(s). The advancements in different technologies such as augmented reality, virtual reality, extended reality (XR), artificial intelligence (AI), and 5G/6G communication will be the key enablers behind the realization of AI-XR metaverse applications. While AI itself has many potential applications in the aforementioned technologies (e.g., avatar generation, network optimization), ensuring the security of AI in critical applications like AI-XR metaverse applications is profoundly crucial to avoid undesirable actions that could undermine users’ privacy and safety, consequently putting their lives in danger. To this end, we attempt to analyze the security, privacy, and trustworthiness aspects associated with the use of various AI techniques in AI-XR metaverse applications. Specifically, we discuss numerous such challenges and present a taxonomy of potential solutions that could be leveraged to develop secure, private, robust, and trustworthy AI-XR applications. To highlight the real implications of AI-associated adversarial threats, we designed a metaverse-specific case study and analyzed it through the adversarial lens. Finally, we elaborate upon various open issues that require further research interest from the community.},
  archive      = {J_CSUR},
  author       = {Adnan Qayyum and Muhammad Atif Butt and Hassan Ali and Muhammad Usman and Osama Halabi and Ala Al-Fuqaha and Qammer H. Abbasi and Muhammad Ali Imran and Junaid Qadir},
  doi          = {10.1145/3614426},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {170:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Secure and trustworthy artificial intelligence-extended reality (AI-XR) for metaverses},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Byzantine machine learning: A primer. <em>CSUR</em>,
<em>56</em>(7), 169:1–39. (<a
href="https://doi.org/10.1145/3616537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of Byzantine resilience in distributed machine learning, a.k.a. Byzantine machine learning , consists of designing distributed algorithms that can train an accurate model despite the presence of Byzantine nodes—that is, nodes with corrupt data or machines that can misbehave arbitrarily. By now, many solutions to this important problem have been proposed, most of which build upon the classical stochastic gradient descent scheme. Yet, the literature lacks a unified structure of this emerging field. Consequently, the general understanding on the principles of Byzantine machine learning remains poor. This article addresses this issue by presenting a primer on Byzantine machine learning. In particular, we introduce three pillars of Byzantine machine learning, namely the concepts of breakdown point , robustness , and gradient complexity , to curate the efficacy of a solution. The introduced systematization enables us to (i) bring forth the merits and limitations of the state-of-the-art solutions, and (ii) pave a clear path for future advancements in this field.},
  archive      = {J_CSUR},
  author       = {Rachid Guerraoui and Nirupam Gupta and Rafael Pinot},
  doi          = {10.1145/3616537},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {169:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Byzantine machine learning: A primer},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable reinforcement learning: A survey and comparative
review. <em>CSUR</em>, <em>56</em>(7), 168:1–36. (<a
href="https://doi.org/10.1145/3616864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable reinforcement learning (XRL) is an emerging subfield of explainable machine learning that has attracted considerable attention in recent years. The goal of XRL is to elucidate the decision-making process of reinforcement learning (RL) agents in sequential decision-making settings. Equipped with this information, practitioners can better understand important questions about RL agents (especially those deployed in the real world), such as what the agents will do and why. Despite increased interest, there exists a gap in the literature for organizing the plethora of papers—especially in a way that centers the sequential decision-making nature of the problem. In this survey, we propose a novel taxonomy for organizing the XRL literature that prioritizes the RL setting. We propose three high-level categories: feature importance, learning process and Markov decision process, and policy-level. We overview techniques according to this taxonomy, highlighting challenges and opportunities for future work. We conclude by using these gaps to motivate and outline a roadmap for future work.},
  archive      = {J_CSUR},
  author       = {Stephanie Milani and Nicholay Topin and Manuela Veloso and Fei Fang},
  doi          = {10.1145/3616864},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {168:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Explainable reinforcement learning: A survey and comparative review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trusting my predictions: On the value of instance-level
analysis. <em>CSUR</em>, <em>56</em>(7), 167:1–28. (<a
href="https://doi.org/10.1145/3615354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning solutions have spread along many domains, including critical applications. The development of such models usually relies on a dataset containing labeled data. This dataset is then split into training and test sets and the accuracy of the models in replicating the test labels is assessed. This process is often iterated in a cross-validation procedure for obtaining average performance estimates. But is the average of the predictive performance on test sets enough for assessing the trustfulness of a Machine Learning model? This paper discusses the importance of knowing which individual observations of a dataset are more challenging than others and how this characteristic can be measured and used in order to improve classification performance and trustfulness. A set of strategies for measuring the hardness level of the instances of a dataset is surveyed and a Python package containing their implementation is provided.},
  archive      = {J_CSUR},
  author       = {Ana C. Lorena and Pedro Y. A. Paiva and Ricardo B. C. Prudêncio},
  doi          = {10.1145/3615354},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {167:1–28},
  shortjournal = {ACM Comput. Surv.},
  title        = {Trusting my predictions: On the value of instance-level analysis},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fairness in machine learning: A survey. <em>CSUR</em>,
<em>56</em>(7), 166:1–38. (<a
href="https://doi.org/10.1145/3616865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When Machine Learning technologies are used in contexts that affect citizens, companies as well as researchers need to be confident that there will not be any unexpected social implications, such as bias towards gender, ethnicity, and/or people with disabilities. There is significant literature on approaches to mitigate bias and promote fairness, yet the area is complex and hard to penetrate for newcomers to the domain. This article seeks to provide an overview of the different schools of thought and approaches that aim to increase the fairness of Machine Learning. It organizes approaches into the widely accepted framework of pre-processing, in-processing, and post-processing methods, subcategorizing into a further 11 method areas. Although much of the literature emphasizes binary classification, a discussion of fairness in regression, recommender systems, and unsupervised learning is also provided along with a selection of currently available open source libraries. The article concludes by summarizing open challenges articulated as five dilemmas for fairness research.},
  archive      = {J_CSUR},
  author       = {Simon Caton and Christian Haas},
  doi          = {10.1145/3616865},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {166:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Fairness in machine learning: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-imaging medical data synthesis for trustworthy AI: A
comprehensive survey. <em>CSUR</em>, <em>56</em>(7), 165:1–35. (<a
href="https://doi.org/10.1145/3614425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data quality is a key factor in the development of trustworthy AI in healthcare. A large volume of curated datasets with controlled confounding factors can improve the accuracy, robustness, and privacy of downstream AI algorithms. However, access to high-quality datasets is limited by the technical difficulties of data acquisition, and large-scale sharing of healthcare data is hindered by strict ethical restrictions. Data synthesis algorithms, which generate data with distributions similar to real clinical data, can serve as a potential solution to address the scarcity of good quality data during the development of trustworthy AI. However, state-of-the-art data synthesis algorithms, especially deep learning algorithms, focus more on imaging data while neglecting the synthesis of non-imaging healthcare data, including clinical measurements, medical signals and waveforms, and electronic healthcare records (EHRs). Therefore, in this article, we will review synthesis algorithms, particularly for non-imaging medical data, with the aim of providing trustworthy AI in this domain. This tutorial-style review article will provide comprehensive descriptions of non-imaging medical data synthesis, covering aspects such as algorithms, evaluations, limitations, and future research directions.},
  archive      = {J_CSUR},
  author       = {Xiaodan Xing and Huanjun Wu and Lichao Wang and Iain Stenson and May Yong and Javier Del Ser and Simon Walsh and Guang Yang},
  doi          = {10.1145/3614425},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {165:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Non-imaging medical data synthesis for trustworthy AI: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of algorithmic methods for competency
self-assessments in human-autonomy teaming. <em>CSUR</em>,
<em>56</em>(7), 164:1–31. (<a
href="https://doi.org/10.1145/3616010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans working with autonomous artificially intelligent systems may not be experts in the inner workings of their machine teammates, but need to understand when to employ, trust, and rely on the system. A critical challenge is to develop machine agents with the capacity to understand their own capabilities and limitations, and the ability to communicate this information to human partners. Self-assessment is an emerging field that tackles this challenge through the development of algorithms that enable autonomous agents to understand and communicate their competency. These methods can engender appropriate trust and align human expectations with autonomous assistant abilities. However, current research in self-assessment is dispersed across many fields, including artificial intelligence, robotics, and human factors. This survey connects work from these disparate areas and reviews state-of-the-art methods for algorithmic self-assessments that enable autonomous agents to estimate, understand, and communicate valuable information pertaining to their competency, with focus on methods that can improve interactions within human-machine teams. To better understand the landscape of self-assessment approaches, we present a framework for categorizing work in self-assessment based on underlying algorithm type: test-based , learning-based , or knowledge-based . We synthesize common features across these approaches and discuss relevant future directions for research in this emerging space.},
  archive      = {J_CSUR},
  author       = {Nicholas Conlon and Nisar R. Ahmed and Daniel Szafir},
  doi          = {10.1145/3616010},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {164:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of algorithmic methods for competency self-assessments in human-autonomy teaming},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting blockchain to make AI trustworthy: A software
development lifecycle view. <em>CSUR</em>, <em>56</em>(7), 163:1–31. (<a
href="https://doi.org/10.1145/3614424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) is a very powerful technology and can be a potential disrupter and essential enabler. As AI expands into almost every aspect of our lives, people raise serious concerns about AI misbehaving and misuse. To address this concern, international organizations have put forward ethics guidelines for constructing trustworthy AI (TAI), including privacy, transparency, fairness, robustness, accountability, and so on. However, because of the black-box characteristics and complex models of AI systems, it is challenging to translate these guiding principles and aspirations into AI systems. Blockchain, an important decentralized technology, can provide the capabilities of transparency, traceability, immutability, and secure sharing and hence can be used to make AI trustworthy. In this paper, we survey studies on blockchain-based TAI (BTAI) from a software development lifecycle view. We classify the lifecycle of BTAI into four stages: Planning, data collection, model development, and system deployment/use. Particularly, we investigate and summarize the trustworthy issues that blockchain can achieve in the latter three stages, including (1) data transparency, privacy, and accountability; (2) model transparency, privacy, robustness, and fairness; and (3) robustness, privacy, transparency, and fairness of system deployment/use. Finally, we present essential open research issues and future work on developing BTAI systems.},
  archive      = {J_CSUR},
  author       = {Peiyun Zhang and Song Ding and Qinglin Zhao},
  doi          = {10.1145/3614424},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {163:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {Exploiting blockchain to make AI trustworthy: A software development lifecycle view},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Introduction to special issue on trustworthy artificial
intelligence. <em>CSUR</em>, <em>56</em>(7), 162:1–3. (<a
href="https://doi.org/10.1145/3649452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CSUR},
  author       = {Roberta Calegari and Fosca Giannotti and Francesca Pratesi and Michela Milano},
  doi          = {10.1145/3649452},
  journal      = {ACM Computing Surveys},
  month        = {4},
  number       = {7},
  pages        = {162:1–3},
  shortjournal = {ACM Comput. Surv.},
  title        = {Introduction to special issue on trustworthy artificial intelligence},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Symbolic knowledge extraction and injection with
sub-symbolic predictors: A systematic literature review. <em>CSUR</em>,
<em>56</em>(6), 161:1–35. (<a
href="https://doi.org/10.1145/3645103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we focus on the opacity issue of sub-symbolic machine learning predictors by promoting two complementary activities— symbolic knowledge extraction (SKE) and symbolic knowledge injection (SKI)—from and into sub-symbolic predictors. We consider as symbolic any language being intelligible and interpretable for both humans and computers. Accordingly, we propose general meta-models for both SKE and SKI, along with two taxonomies for the classification of SKE and SKI methods. By adopting an explainable artificial intelligence (XAI) perspective, we highlight how such methods can be exploited to mitigate the aforementioned opacity issue. Our taxonomies are attained by surveying and classifying existing methods from the literature, following a systematic approach, and by generalising the results of previous surveys targeting specific sub-topics of either SKE or SKI alone. More precisely, we analyse 132 methods for SKE and 117 methods for SKI, and we categorise them according to their purpose, operation, expected input/output data and predictor types. For each method, we also indicate the presence/lack of runnable software implementations. Our work may be of interest for data scientists aiming at selecting the most adequate SKE/SKI method for their needs, and may also work as suggestions for researchers interested in filling the gaps of the current state-of-the-art as well as for developers willing to implement SKE/SKI-based technologies.},
  archive      = {J_CSUR},
  author       = {Giovanni Ciatto and Federico Sabbatini and Andrea Agiollo and Matteo Magnini and Andrea Omicini},
  doi          = {10.1145/3645103},
  journal      = {ACM Computing Surveys},
  month        = {3},
  number       = {6},
  pages        = {161:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Symbolic knowledge extraction and injection with sub-symbolic predictors: A systematic literature review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On trust recommendations in the social internet of things –
a survey. <em>CSUR</em>, <em>56</em>(6), 160:1–35. (<a
href="https://doi.org/10.1145/3645100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novel paradigm Social Internet of Things (SIoT) improves the network navigability, identifies suitable service providers, and addresses scalability concerns. Ensuring trustworthy collaborations among devices is a key aspect in SIoT and can be realized through trust recommendations. However, the outcome of trust recommendations depends on multiple factors related to the context-dependent nature of SIoT and practical constraints brought by the devices and networks embedded in the SIoT. While the existing literature has proposed numerous trust recommendation models to assess the trustworthiness of devices in various scenarios, researchers have not sufficiently examined the required features for trust recommendations in the SIoT. Consequently, trust recommendation models may inaccurately assess the true risk of device interactions. In this literature survey, we investigate the context-dependent features and recommendation methods used for the SIoT using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodology. We propose a novel taxonomy to categorize trust recommendation models according to their input features and design. Our findings reveal limited attention is given to the context-dependent features, constraints of the information environment, and limited inference capabilities that impede more precise trust recommendations. Finally, we present the research gaps and outline future directions to enable trustworthy inter-domain operations within the SIoT.},
  archive      = {J_CSUR},
  author       = {Marius Becherer and Omar Khadeer Hussain and Yu Zhang and Frank den Hartog and Elizabeth Chang},
  doi          = {10.1145/3645100},
  journal      = {ACM Computing Surveys},
  month        = {3},
  number       = {6},
  pages        = {160:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {On trust recommendations in the social internet of things – a survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge graph embedding: A survey from the perspective of
representation spaces. <em>CSUR</em>, <em>56</em>(6), 159:1–42. (<a
href="https://doi.org/10.1145/3643806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding (KGE) is an increasingly popular technique that aims to represent entities and relations of knowledge graphs into low-dimensional semantic spaces for a wide spectrum of applications such as link prediction, knowledge reasoning and knowledge completion. In this article, we provide a systematic review of existing KGE techniques based on representation spaces. Particularly, we build a fine-grained classification to categorise the models based on three mathematical perspectives of the representation spaces: (1) algebraic perspective, (2) geometric perspective and (3) analytical perspective. We introduce the rigorous definitions of fundamental mathematical spaces before diving into KGE models and their mathematical properties. We further discuss different KGE methods over the three categories, as well as summarise how spatial advantages work over different embedding needs. By collating the experimental results from downstream tasks, we also explore the advantages of mathematical space in different scenarios and the reasons behind them. We further state some promising research directions from a representation space perspective, with which we hope to inspire researchers to design their KGE models as well as their related applications with more consideration of their mathematical space properties.},
  archive      = {J_CSUR},
  author       = {Jiahang Cao and Jinyuan Fang and Zaiqiao Meng and Shangsong Liang},
  doi          = {10.1145/3643806},
  journal      = {ACM Computing Surveys},
  month        = {3},
  number       = {6},
  pages        = {159:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Knowledge graph embedding: A survey from the perspective of representation spaces},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Drug–drug interaction relation extraction based on deep
learning: A review. <em>CSUR</em>, <em>56</em>(6), 158:1–33. (<a
href="https://doi.org/10.1145/3645089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug–drug interaction (DDI) is an important part of drug development and pharmacovigilance. At the same time, DDI is an important factor in treatment planning, monitoring effects of medicine and patient safety, and has a significant impact on public health. Therefore, using deep learning technology to extract DDI from scientific literature has become a valuable research direction to researchers. In existing DDI datasets, the number of positive instances is relatively small. This makes it difficult for existing deep learning models to obtain sufficient feature information directly from text data. Therefore, existing deep learning models mainly rely on multiple feature supplementation methods to collect sufficient feature information from different types of data. In this study, the general process of DDI relation extraction based on deep learning is introduced first for comprehensive analysis. Next, we summarize the various feature supplement methods and analyze their merits and demerits. We then review the state-of-the-art literature related to DDI extraction from the deep neural network perspective. Finally, all the feature supplement methods are compared, and some suggestions are given to approach the current problems and future research directions. The purpose of this article is to give researchers a more complete understanding of the feature complementation methods used in DDI extraction to be able to rapidly design and implement custom DDI relation extraction methods.},
  archive      = {J_CSUR},
  author       = {Mingliang Dou and Jijun Tang and Prayag Tiwari and Yijie Ding and Fei Guo},
  doi          = {10.1145/3645089},
  journal      = {ACM Computing Surveys},
  month        = {3},
  number       = {6},
  pages        = {158:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Drug–Drug interaction relation extraction based on deep learning: A review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-based trustworthiness evaluation of autonomous
cyber-physical production systems: A systematic mapping study.
<em>CSUR</em>, <em>56</em>(6), 157:1–28. (<a
href="https://doi.org/10.1145/3640314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fourth industrial revolution, i.e., Industry 4.0, is associated with Cyber-Physical Systems (CPS), which are entities integrating hardware (e.g., smart sensors and actuators connected through the Industrial Internet of Things) together with control and analytics software used to drive and support decisions at several levels. The latest developments in Artificial Intelligence (AI) and Machine Learning (ML) have enabled increased autonomy and closer human-robot cooperation in the production and manufacturing industry, thus leading to Autonomous Cyber-Physical Production Systems (ACPPS) and paving the way to the fifth industrial revolution (i.e., Industry 5.0). ACPPS are increasingly critical due to the possible consequences of their malfunctions on human co-workers, and therefore, evaluating their trustworthiness is essential. This article reviews research trends, relevant attributes, modeling languages, and tools related to the model-based trustworthiness evaluation of ACPPS. As in many other engineering disciplines and domains, model-based approaches, including stochastic and formal analysis tools, are essential to master the increasing complexity and criticality of ACPPS and to prove relevant attributes such as system safety in the presence of intelligent behaviors and uncertainties.},
  archive      = {J_CSUR},
  author       = {Maryam Zahid and Alessio Bucaioni and Francesco Flammini},
  doi          = {10.1145/3640314},
  journal      = {ACM Computing Surveys},
  month        = {2},
  number       = {6},
  pages        = {157:1–28},
  shortjournal = {ACM Comput. Surv.},
  title        = {Model-based trustworthiness evaluation of autonomous cyber-physical production systems: A systematic mapping study},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning for refining knowledge graphs: A survey.
<em>CSUR</em>, <em>56</em>(6), 156:1–38. (<a
href="https://doi.org/10.1145/3640313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) refinement refers to the process of filling in missing information, removing redundancies, and resolving inconsistencies in KGs. With the growing popularity of KG in various domains, many techniques involving machine learning have been applied, but there is no survey dedicated to machine learning-based KG refinement yet. Based on a novel framework following the KG refinement process, this article presents a survey of machine learning approaches to KG refinement according to the kind of operations in KG refinement, the training datasets, mode of learning, and process multiplicity. Furthermore, the survey aims to provide broad practical insights into the development of fully automated KG refinement.},
  archive      = {J_CSUR},
  author       = {Budhitama Subagdja and D. Shanthoshigaa and Zhaoxia Wang and Ah-Hwee Tan},
  doi          = {10.1145/3640313},
  journal      = {ACM Computing Surveys},
  month        = {2},
  number       = {6},
  pages        = {156:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Machine learning for refining knowledge graphs: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The art of cybercrime community research. <em>CSUR</em>,
<em>56</em>(6), 155:1–26. (<a
href="https://doi.org/10.1145/3639362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, cybercrime has risen considerably. One key factor is the proliferation of online cybercrime communities, where actors trade products and services, and also learn from each other. Accordingly, understanding the operation and behavior of these communities is of great interest, and they have been explored across multiple disciplines with different, often quite novel, approaches. This survey explores the challenges inherent to the field and the methodological approaches researchers used to understand this space. We note that, in many cases, cybercrime research is more of an art than a science. We highlight the good practices and propose a list of recommendations for future cybercrime community scholars, including taking steps to verify and validate results, establishing privacy and ethical research practices, and mitigating the challenge of ground truth data.},
  archive      = {J_CSUR},
  author       = {Jack Hughes and Sergio Pastrana and Alice Hutchings and Sadia Afroz and Sagar Samtani and Weifeng Li and Ericsson Santana Marin},
  doi          = {10.1145/3639362},
  journal      = {ACM Computing Surveys},
  month        = {2},
  number       = {6},
  pages        = {155:1–26},
  shortjournal = {ACM Comput. Surv.},
  title        = {The art of cybercrime community research},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mouse dynamics behavioral biometrics: A survey.
<em>CSUR</em>, <em>56</em>(6), 154:1–33. (<a
href="https://doi.org/10.1145/3640311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utilization of the Internet in our everyday lives has made us vulnerable in terms of privacy and security of our data and systems. Therefore, there is a pressing need to protect our data and systems by improving authentication mechanisms, which are expected to be low cost, unobtrusive, and ideally ubiquitous in nature. Behavioral biometric modalities such as mouse dynamics (mouse behaviors on a graphical user interface (GUI)) and widget interactions (another modality closely related to mouse dynamics that also considers the target (widget) of a GUI interaction, such as links, buttons, and combo-boxes) can bolster the security of existing authentication systems because of their ability to distinguish individuals based on their unique features. As a result, it can be difficult for an imposter to impersonate these behavioral biometrics, making them suitable for authentication. In this article, we survey the literature on mouse dynamics and widget interactions dated from 1897 to 2023. We begin our survey with an account of the psychological perspectives on behavioral biometrics. We then analyze the literature along the following dimensions: tasks and experimental settings for data collection, taxonomy of raw attributes, feature extractions and mathematical definitions, publicly available datasets, algorithms (statistical, machine learning, and deep learning), data fusion, performance, and limitations. We end the paper with presenting challenges and promising research opportunities.},
  archive      = {J_CSUR},
  author       = {Simon Khan and Charles Devlen and Michael Manno and Daqing Hou},
  doi          = {10.1145/3640311},
  journal      = {ACM Computing Surveys},
  month        = {2},
  number       = {6},
  pages        = {154:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Mouse dynamics behavioral biometrics: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for plant identification and disease
classification from leaf images: Multi-prediction approaches.
<em>CSUR</em>, <em>56</em>(6), 153:1–37. (<a
href="https://doi.org/10.1145/3639816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) plays an important role in modern agriculture, especially in plant pathology using leaf images where convolutional neural networks (CNN) are attracting a lot of attention. While numerous reviews have explored the applications of DL within this research domain, there remains a notable absence of an empirical study to offer insightful comparisons due to the employment of varied datasets in the evaluation. Furthermore, a majority of these approaches tend to address the problem as a singular prediction task, overlooking the multifaceted nature of predicting various aspects of plant species and disease types. Lastly, there is an evident need for a more profound consideration of the semantic relationships that underlie plant species and disease types. In this article, we start our study by surveying current DL approaches for plant identification and disease classification. We categorise the approaches into multi-model, multi-label, multi-output, and multi-task, in which different backbone CNNs can be employed. Furthermore, based on the survey of existing approaches in plant pathology and the study of available approaches in machine learning, we propose a new model named Generalised Stacking Multi-output CNN (GSMo-CNN). To investigate the effectiveness of different backbone CNNs and learning approaches, we conduct an intensive experiment on three benchmark datasets Plant Village, Plant Leaves, and PlantDoc. The experimental results demonstrate that InceptionV3 can be a good choice for a backbone CNN as its performance is better than AlexNet, VGG16, ResNet101, EfficientNet, MobileNet, and a custom CNN developed by us. Interestingly, there is empirical evidence to support the hypothesis that using a single model for both tasks can be comparable or better than using two models, one for each task. Finally, we show that the proposed GSMo-CNN achieves state-of-the-art performance on three benchmark datasets.},
  archive      = {J_CSUR},
  author       = {Jianping Yao and Son N. Tran and Saurabh Garg and Samantha Sawyer},
  doi          = {10.1145/3639816},
  journal      = {ACM Computing Surveys},
  month        = {2},
  number       = {6},
  pages        = {153:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for plant identification and disease classification from leaf images: Multi-prediction approaches},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security and privacy issues in deep reinforcement learning:
Threats and countermeasures. <em>CSUR</em>, <em>56</em>(6), 152:1–39.
(<a href="https://doi.org/10.1145/3640312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning (DRL) is an essential subfield of Artificial Intelligence (AI), where agents interact with environments to learn policies for solving complex tasks. In recent years, DRL has achieved remarkable breakthroughs in various tasks, including video games, robotic control, quantitative trading, and autonomous driving. Despite its accomplishments, security and privacy-related issues still prevent us from deploying trustworthy DRL applications. For example, by manipulating the environment, an attacker can influence an agent’s actions, misleading it to behave abnormally. Additionally, an attacker can infer private training data and environmental information by maliciously interacting with DRL models, causing a privacy breach. In this survey, we systematically investigate the recent progress of security and privacy issues in the context of DRL. First, we present a holistic review of security-related attacks within DRL systems from the perspectives of single-agent and multi-agent systems and review privacy-related attacks. Second, we review and classify defense methods used to address security-related challenges, including robust learning, anomaly detection, and game theory approaches. Third, we review and classify privacy-preserving technologies, including encryption, differential privacy, and policy confusion. We conclude the survey by discussing open issues and possible directions for future research in this field.},
  archive      = {J_CSUR},
  author       = {Kanghua Mo and Peigen Ye and Xiaojun Ren and Shaowei Wang and Wenjun Li and Jin Li},
  doi          = {10.1145/3640312},
  journal      = {ACM Computing Surveys},
  month        = {2},
  number       = {6},
  pages        = {152:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security and privacy issues in deep reinforcement learning: Threats and countermeasures},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security for machine learning-based software systems: A
survey of threats, practices, and challenges. <em>CSUR</em>,
<em>56</em>(6), 151:1–38. (<a
href="https://doi.org/10.1145/3638531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Machine Learning (ML) has demonstrated superior performance in many areas, such as computer vision and video and speech recognition. It has now been increasingly leveraged in software systems to automate the core tasks. However, how to securely develop the machine learning-based modern software systems (MLBSS) remains a big challenge, for which the insufficient consideration will largely limit its application in safety-critical domains. One concern is that the present MLBSS development tends to be rushed, and the latent vulnerabilities and privacy issues exposed to external users and attackers will be largely neglected and hard to be identified. Additionally, machine learning-based software systems exhibit different liabilities towards novel vulnerabilities at different development stages from requirement analysis to system maintenance, due to its inherent limitations from the model and data and the external adversary capabilities. The successful generation of such intelligent systems will thus solicit dedicated efforts jointly from different research areas, i.e., software engineering, system security, and machine learning. Most of the recent works regarding the security issues for ML have a strong focus on the data and models, which has brought adversarial attacks into consideration. In this work, we consider that security for machine learning-based software systems may arise from inherent system defects or external adversarial attacks, and the secure development practices should be taken throughout the whole lifecycle. While machine learning has become a new threat domain for existing software engineering practices, there is no such review work covering the topic. Overall, we present a holistic review regarding the security for MLBSS, which covers a systematic understanding from a structure review of three distinct aspects in terms of security threats. Moreover, it provides a thorough state-of-the-practice for MLBSS secure development. Finally, we summarize the literature for system security assurance and motivate the future research directions with open challenges. We anticipate this work provides sufficient discussion and novel insights to incorporate system security engineering for future exploration.},
  archive      = {J_CSUR},
  author       = {Huaming Chen and M. Ali Babar},
  doi          = {10.1145/3638531},
  journal      = {ACM Computing Surveys},
  month        = {2},
  number       = {6},
  pages        = {151:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security for machine learning-based software systems: A survey of threats, practices, and challenges},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Completeness, recall, and negation in open-world knowledge
bases: A survey. <em>CSUR</em>, <em>56</em>(6), 150:1–42. (<a
href="https://doi.org/10.1145/3639563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {General-purpose knowledge bases (KBs) are a cornerstone of knowledge-centric AI. Many of them are constructed pragmatically from web sources and are thus far from complete. This poses challenges for the consumption as well as the curation of their content. While several surveys target the problem of completing incomplete KBs, the first problem is arguably to know whether and where the KB is incomplete in the first place, and to which degree. In this survey, we discuss how knowledge about completeness, recall, and negation in KBs can be expressed, extracted, and inferred. We cover (i) the logical foundations of knowledge representation and querying under partial closed-world semantics; (ii) the estimation of this information via statistical patterns; (iii) the extraction of information about recall from KBs and text; (iv) the identification of interesting negative statements; and (v) relaxed notions of relative recall. This survey is targeted at two types of audiences: (1) practitioners who are interested in tracking KB quality, focusing extraction efforts, and building quality-aware downstream applications; and (2) data management, knowledge base, and semantic web researchers who wish to understand the state-of-the-art of knowledge bases beyond the open-world assumption. Consequently, our survey presents both fundamental methodologies and the results that they have produced, and gives practice-oriented recommendations on how to choose between different approaches for a problem at hand.},
  archive      = {J_CSUR},
  author       = {Simon Razniewski and Hiba Arnaout and Shrestha Ghosh and Fabian Suchanek},
  doi          = {10.1145/3639563},
  journal      = {ACM Computing Surveys},
  month        = {2},
  number       = {6},
  pages        = {150:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Completeness, recall, and negation in open-world knowledge bases: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey on recommender systems for biomedical items in life
and health sciences. <em>CSUR</em>, <em>56</em>(6), 149:1–32. (<a
href="https://doi.org/10.1145/3639047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation of biomedical data is of such magnitude that its retrieval and analysis have posed several challenges. A survey of recommender system (RS) approaches in biomedical fields is provided in this analysis, along with a discussion of existing challenges related to large-scale biomedical information retrieval systems. We collect original studies, identify entities and models, and discuss how knowledge graphs (KGs) can improve results. As a result, most of the papers used model-based collaborative filtering algorithms, most of the available datasets did not follow the standard format , and regarding qualitative evaluations of RSs use mainly classification metrics. Finally, we have assembled and coded a unique dataset of 60 papers — Sur-RS4BioT, available for download at DOI:10.34740/kaggle/ds/2346894},
  archive      = {J_CSUR},
  author       = {Matilde Pato and Márcia Barros and Francisco M. Couto},
  doi          = {10.1145/3639047},
  journal      = {ACM Computing Surveys},
  month        = {2},
  number       = {6},
  pages        = {149:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on recommender systems for biomedical items in life and health sciences},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Malware detection with artificial intelligence: A systematic
literature review. <em>CSUR</em>, <em>56</em>(6), 148:1–33. (<a
href="https://doi.org/10.1145/3638552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this survey, we review the key developments in the field of malware detection using AI and analyze core challenges. We systematically survey state-of-the-art methods across five critical aspects of building an accurate and robust AI-powered malware-detection model: malware sophistication, analysis techniques, malware repositories, feature selection, and machine learning vs. deep learning. The effectiveness of an AI model is dependent on the quality of the features it is trained with. In turn, the quality and authenticity of these features is dependent on the quality of the dataset and the suitability of the analysis tool. Static analysis is fast but is limited by the widespread use of obfuscation. Dynamic analysis is not impacted by obfuscation but is defeated by ubiquitous anti-analysis techniques and requires more computational power. Sophisticated and evasive malware is challenging to extract authentic discriminatory features from and, combined with poor quality datasets, this can lead to a situation where a model achieves high accuracy with only one specific dataset.},
  archive      = {J_CSUR},
  author       = {Matthew G. Gaber and Mohiuddin Ahmed and Helge Janicke},
  doi          = {10.1145/3638552},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {148:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Malware detection with artificial intelligence: A systematic literature review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of generative adversarial networks for synthesizing
structured electronic health records. <em>CSUR</em>, <em>56</em>(6),
147:1–34. (<a href="https://doi.org/10.1145/3636424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic Health Records (EHRs) are a valuable asset to facilitate clinical research and point of care applications; however, many challenges such as data privacy concerns impede its optimal utilization. Deep generative models, particularly Generative Adversarial Networks (GANs), show great promise in generating synthetic EHR data by learning underlying data distributions while achieving excellent performance and addressing these challenges. This work aims to survey the major developments in various applications of GANs for EHRs and provides an overview of the proposed methodologies. For this purpose, we combine perspectives from healthcare applications and machine learning techniques in terms of source datasets and the fidelity and privacy evaluation of the generated synthetic datasets. We also compile a list of the metrics and datasets used by the reviewed works, which can be utilized as benchmarks for future research in the field. We conclude by discussing challenges in GANs for EHRs development and proposing recommended practices. We hope that this work motivates novel research development directions in the intersection of healthcare and machine learning.},
  archive      = {J_CSUR},
  author       = {Ghadeer O. Ghosheh and Jin Li and Tingting Zhu},
  doi          = {10.1145/3636424},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {147:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of generative adversarial networks for synthesizing structured electronic health records},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning workload scheduling in GPU datacenters: A
survey. <em>CSUR</em>, <em>56</em>(6), 146:1–38. (<a
href="https://doi.org/10.1145/3638757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) has demonstrated its remarkable success in a wide variety of fields. The development of a DL model is a time-consuming and resource-intensive procedure. Hence, dedicated GPU accelerators have been collectively constructed into a GPU datacenter. An efficient scheduler design for a GPU datacenter is crucially important to reduce operational cost and improve resource utilization. However, traditional approaches designed for big data or high-performance computing workloads can not support DL workloads to fully utilize the GPU resources. Recently, many schedulers are proposed to tailor for DL workloads in GPU datacenters. This article surveys existing research efforts for both training and inference workloads. We primarily present how existing schedulers facilitate the respective workloads from the scheduling objectives and resource utilization manner . Finally, we discuss several promising future research directions including emerging DL workloads, advanced scheduling decision making, and underlying hardware resources. A more detailed summary of the surveyed paper and code links can be found at our project website: https://github.com/S-Lab-System-Group/Awesome-DL-Scheduling-Papers},
  archive      = {J_CSUR},
  author       = {Zhisheng Ye and Wei Gao and Qinghao Hu and Peng Sun and Xiaolin Wang and Yingwei Luo and Tianwei Zhang and Yonggang Wen},
  doi          = {10.1145/3638757},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {146:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning workload scheduling in GPU datacenters: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of recent advances in deep learning models for
detecting malware in desktop and mobile platforms. <em>CSUR</em>,
<em>56</em>(6), 145:1–41. (<a
href="https://doi.org/10.1145/3638240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malware is one of the most common and severe cyber threats today. Malware infects millions of devices and can perform several malicious activities including compromising sensitive data, encrypting data, crippling system performance, and many more. Hence, malware detection is crucial to protect our computers and mobile devices from malware attacks. Recently, Deep Learning (DL) has emerged as one of the promising technologies for detecting malware. The recent high production of malware variants against desktop and mobile platforms makes DL algorithms powerful approaches for building scalable and advanced malware detection models as they can handle big datasets. This work explores current deep learning technologies for detecting malware attacks on Windows, Linux, and Android platforms. Specifically, we present different categories of DL algorithms, network optimizers, and regularization methods. Different loss functions, activation functions, and frameworks for implementing DL models are discussed. We also present feature extraction approaches and a review of DL-based models for detecting malware attacks on the above platforms. Furthermore, this work presents major research issues on DL-based malware detection including future research directions to further advance knowledge and research in this field.},
  archive      = {J_CSUR},
  author       = {Pascal Maniriho and Abdun Naser Mahmood and Mohammad Jabed Morshed Chowdhury},
  doi          = {10.1145/3638240},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {145:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of recent advances in deep learning models for detecting malware in desktop and mobile platforms},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Key distribution and authentication protocols in wireless
sensor networks: A survey. <em>CSUR</em>, <em>56</em>(6), 144:1–31. (<a
href="https://doi.org/10.1145/3638043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We use sensor technologies in many areas of everyday life. We use sensors to check and study various phenomena and to improve our lives. Hence, the sensors are used in medicine, industry, sports, and many other aspects of everyday life. Interconnected sensors and other wireless devices and servers form Wireless Sensor Networks. During communication between the nodes of such networks, we often send private and sensitive data. These data should be properly secured. Securing communication in a Wireless Sensor Network mainly affects the reconciliation and distribution of session keys and authentication. Specially designed protocols must protect both methods. In turn, the protocols may be exposed to dishonest users of such networks and thus exposed to various attacks (for example, replay attacks and smart card stolen attacks). This article surveys the existing session key negotiation, distribution, and authentication protocols. We will explain the security problems and threats to which the sensor networks are exposed. We will discuss the security levels implemented by the protocols currently used in sensor networks. We will analyze the challenges and requirements faced by the newly designed protocols.},
  archive      = {J_CSUR},
  author       = {Sabina Szymoniak},
  doi          = {10.1145/3638043},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {144:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {Key distribution and authentication protocols in wireless sensor networks: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Surveying emerging network approaches for military command
and control systems. <em>CSUR</em>, <em>56</em>(6), 143:1–38. (<a
href="https://doi.org/10.1145/3626090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey paper examines emerging network approaches for military Command and Control (C2) systems. An extensive literature review is provided along the text on network-centric C2 systems. Also, it provides a comprehensive analysis of the paradigm based on C2 concepts, mapping the significant requirements of networked C2 systems to emerging approaches. Likewise, the paper explores ways to simulate networked battle scenarios realistically, leveraging the support of multi-agent systems and network simulations. The article offers a trend analysis of combining network approaches to design innovative solutions and a promising usage of multi-agent systems for realistic simulations. In conclusion, it discusses future implementations emphasizing advanced networking solutions to integrate different technologies and to drive technology boundaries to improve the effectiveness of networked military C2 systems.},
  archive      = {J_CSUR},
  author       = {João Eduardo Costa Gomes and Ricardo Rodrigues Ehlert and Rodrigo Murillo Boesche and Vinicius Santosde Lima and Jorgito Matiuzzi Stocchero and Dante A. C. Barone and JulianoAraujo Wickboldt and Edison Pignaton de Freitas and Julio C. S. dos Anjos and Ricardo Queiroz de Araujo Fernandes},
  doi          = {10.1145/3626090},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {143:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Surveying emerging network approaches for military command and control systems},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-chain smart contract invocations: A systematic
multi-vocal literature review. <em>CSUR</em>, <em>56</em>(6), 142:1–38.
(<a href="https://doi.org/10.1145/3638045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction of smart contracts has expanded the applicability of blockchains to many domains beyond finance and cryptocurrencies. Moreover, different blockchain technologies have evolved that target special requirements. As a result, in practice, often a combination of different blockchain systems is required to achieve an overall goal. However, due to the heterogeneity of blockchain protocols, the execution of distributed business transactions that span several blockchains leads to multiple interoperability and integration challenges. Therefore, in this article, we examine the domain of Cross-Chain Smart Contract Invocations (CCSCIs), which are distributed transactions that involve the invocation of smart contracts hosted on two or more blockchain systems. We conduct a systematic multi-vocal literature review to get an overview of the available CCSCI approaches. We select 20 formal literature studies and 13 high-quality gray literature studies, extract data from them, and analyze it to derive the CCSCI Classification Framework. With the help of the framework, we group the approaches into two categories and eight subcategories. The approaches differ in multiple characteristics, e.g., the mechanisms they follow, and the capabilities and transaction processing semantics they offer. Our analysis indicates that all approaches suffer from obstacles that complicate real-world adoption, such as the low support for handling heterogeneity and the need for trusted third parties.},
  archive      = {J_CSUR},
  author       = {Ghareeb Falazi and Uwe Breitenbücher and Frank Leymann and Stefan Schulte},
  doi          = {10.1145/3638045},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {142:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Cross-chain smart contract invocations: A systematic multi-vocal literature review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic literature review on hardware reliability
assessment methods for deep neural networks. <em>CSUR</em>,
<em>56</em>(6), 141:1–39. (<a
href="https://doi.org/10.1145/3638242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) and, in particular, Machine Learning (ML), have emerged to be utilized in various applications due to their capability to learn how to solve complex problems. Over the past decade, rapid advances in ML have presented Deep Neural Networks (DNNs) consisting of a large number of neurons and layers. DNN Hardware Accelerators (DHAs) are leveraged to deploy DNNs in the target applications. Safety-critical applications, where hardware faults/errors would result in catastrophic consequences, also benefit from DHAs. Therefore, the reliability of DNNs is an essential subject of research. In recent years, several studies have been published accordingly to assess the reliability of DNNs. In this regard, various reliability assessment methods have been proposed on a variety of platforms and applications. Hence, there is a need to summarize the state-of-the-art to identify the gaps in the study of the reliability of DNNs. In this work, we conduct a Systematic Literature Review (SLR) on the reliability assessment methods of DNNs to collect relevant research works as much as possible, present a categorization of them, and address the open challenges. Through this SLR, three kinds of methods for reliability assessment of DNNs are identified, including Fault Injection (FI), Analytical, and Hybrid methods. Since the majority of works assess the DNN reliability by FI, we characterize different approaches and platforms of the FI method comprehensively. Moreover, Analytical and Hybrid methods are propounded. Thus, different reliability assessment methods for DNNs have been elaborated on their conducted DNN platforms and reliability evaluation metrics. Finally, we highlight the advantages and disadvantages of the identified methods and address the open challenges in the research area. We have concluded that Analytical and Hybrid methods are light-weight yet sufficiently accurate and have the potential to be extended in future research and to be utilized in establishing novel DNN reliability assessment frameworks.},
  archive      = {J_CSUR},
  author       = {Mohammad Hasan Ahmadilivani and Mahdi Taheri and Jaan Raik and Masoud Daneshtalab and Maksim Jenihhin},
  doi          = {10.1145/3638242},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {141:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on hardware reliability assessment methods for deep neural networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on fashion image retrieval. <em>CSUR</em>,
<em>56</em>(6), 140:1–25. (<a
href="https://doi.org/10.1145/3636552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fashion is the manner in which we introduce ourselves to the world and has become perhaps the biggest industry on the planet. In recent years, fashion-related research has received a lot of attention from computer vision researchers as a result of the growing demand by the fashion industry. Fashion image retrieval (FIR) is a difficult initiative and requires finding the right items from a huge collection of fashion items based on an image query. FIR has been applied successfully to clothing and footwear. Despite ongoing advances, FIR still suffers from limitations when applied to real-world visual endeavors. However, research on complex design items, for example, ornaments, has received less attention due to the complex nature of similarity and the unavailability of suitable datasets. This article presents a review of FIR and evaluation systems from different design datasets. The motivation behind this review is, to sum up the state-of-the-art procedures for retrieving fashion images for a given query image. In addition, we highlight promising directions for future research.},
  archive      = {J_CSUR},
  author       = {Sk Maidul Islam and Subhankar Joardar and Arif Ahmed Sekh*},
  doi          = {10.1145/3636552},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {140:1–25},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on fashion image retrieval},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scaling blockchains with error correction codes: A survey on
coded blockchains. <em>CSUR</em>, <em>56</em>(6), 139:1–33. (<a
href="https://doi.org/10.1145/3637224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental issue in blockchain systems is their scalability in terms of data storage, computation, communication, and security. To resolve this issue, a promising research direction is coding theory, which is widely used for distributed storage, recovery from erasures or channel errors and/or to reduce communication cost. To this end, this article provides the first comprehensive survey of approaches that employ coding theory to scale blockchain systems. It shows how the use of coded symbols or shards allow participants to only store a fraction of the total blockchain, protect against malicious nodes or erasures, ensure data availability in order to promote transparency, and scale the security of sharded blockchains. Further, coded symbols help reduce communication cost when disseminating blocks, which help bootstrap new nodes and speed up consensus of blocks. For each category of solutions, we highlight problems and issues that motivated their designs and use of coding. Moreover, we provide a qualitative analysis of their storage, communication, and computation costs.},
  archive      = {J_CSUR},
  author       = {Changlin Yang and Kwan-Wu Chin and Jiguang Wang and Xiaodong Wang and Ying Liu and Zibin Zheng},
  doi          = {10.1145/3637224},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {139:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Scaling blockchains with error correction codes: A survey on coded blockchains},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of robustness and safety of 2D and 3D deep learning
models against adversarial attacks. <em>CSUR</em>, <em>56</em>(6),
138:1–37. (<a href="https://doi.org/10.1145/3636551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the rapid development of deep learning, 2D and 3D computer vision applications are deployed in many safe-critical systems, such as autopilot and identity authentication. However, deep learning models are not trustworthy enough because of their limited robustness against adversarial attacks. The physically realizable adversarial attacks further pose fatal threats to the application and human safety. Lots of papers have emerged to investigate the robustness and safety of deep learning models against adversarial attacks. To lead to trustworthy AI, we first construct a general threat model from different perspectives and then comprehensively review the latest progress of both 2D and 3D adversarial attacks. We extend the concept of adversarial examples beyond imperceptive perturbations and collate over 170 papers to give an overview of deep learning model robustness against various adversarial attacks. To the best of our knowledge, we are the first to systematically investigate adversarial attacks for 3D models, a flourishing field applied to many real-world applications. In addition, we examine physical adversarial attacks that lead to safety violations. Last but not least, we summarize present popular topics, give insights on challenges, and shed light on future research on trustworthy AI.},
  archive      = {J_CSUR},
  author       = {Yanjie Li and Bin Xie and Songtao Guo and Yuanyuan Yang and Bin Xiao},
  doi          = {10.1145/3636551},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {138:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of robustness and safety of 2D and 3D deep learning models against adversarial attacks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3D brain and heart volume generative models: A survey.
<em>CSUR</em>, <em>56</em>(6), 137:1–37. (<a
href="https://doi.org/10.1145/3638044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models such as generative adversarial networks and autoencoders have gained a great deal of attention in the medical field due to their excellent data generation capability. This article provides a comprehensive survey of generative models for 3D volumes, focusing on the brain and heart. A new and elaborate taxonomy of unconditional and conditional generative models is proposed to cover diverse medical tasks for the brain and heart: unconditional synthesis, classification, conditional synthesis, segmentation, denoising, detection, and registration. We provide relevant background, examine each task, and also suggest potential future directions. A list of the latest publications will be updated on GitHub to keep up with the rapid influx of papers at https://github.com/csyanbin/3D-Medical-Generative-Survey .},
  archive      = {J_CSUR},
  author       = {Yanbin Liu and Girish Dwivedi and Farid Boussaid and Mohammed Bennamoun},
  doi          = {10.1145/3638044},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {137:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {3D brain and heart volume generative models: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-hop and mesh for LoRa networks: Recent advancements,
issues, and recommended applications. <em>CSUR</em>, <em>56</em>(6),
136:1–43. (<a href="https://doi.org/10.1145/3638241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A comprehensive review is presented on the latest approaches to solutions focusing on multi-hop and mesh LoRa networks through the evaluation of simulations and real-world experiments, based on papers published between 2015 and 2023. The approaches are systematically classified into four (4) aspects: energy awareness, concurrent access and duty cycle regulations, routing protocols, and security. The first aspect encompasses parameter selection, distance, and clustering. The second aspect focuses on network segregation and time synchronisation. The third aspect covers proactive, reactive, and hybrid routing protocols. The aspect of security includes privacy and Denial-of-Service (DoS). Findings show a consensus that multi-hop networks and adherence to radio duty cycle are able to lower average power consumption. Concurrent access method can improve network performance, but more research is needed due to different conclusions. Reactive protocols have a slight advantage over proactive protocols in terms of node deployment scalability and lower power consumption due to less frequent routing table updates. Hybrid protocols are only beneficial in specific topology deployments. Security is still a major concern for LoRa networks, particularly on attacks such as Man-In-The-Middle (MITM), spoofing, wormholes, flooding, packet replay, and information disclosure. The upcoming trend of implementing machine learning algorithms to multi-hop and mesh LoRa networks opens up a wide range of possibilities, ranging from airspace efficiency, efficient route selection, and improving data throughput. A detailed discussion of the aspects’ issues and recommended industry applications that will benefit from multi-hop and mesh LoRa networks are also provided.},
  archive      = {J_CSUR},
  author       = {Andrew Wei-Loong Wong and Say Leng Goh and Mohammad Kamrul Hasan and Salmah Fattah},
  doi          = {10.1145/3638241},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {136:1–43},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multi-hop and mesh for LoRa networks: Recent advancements, issues, and recommended applications},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review on security attacks and countermeasures
in automotive ethernet. <em>CSUR</em>, <em>56</em>(6), 135:1–38. (<a
href="https://doi.org/10.1145/3637059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past years, the automotive industry has experienced a technological revolution driven by the increasing demand of connectivity and data to develop driver-assistance systems and autonomous vehicles, and improve the mobility experience. To provide higher bandwidth in in-vehicle communication networks, carmakers are choosing Ethernet technology, which becomes Automotive Ethernet (AE) when applied in in-vehicle communication networks. However, with the rise of vehicle connectivity, the cybersecurity of vehicle systems has become a primary concern for the automotive industry. To address this issue, we conducted a systematic review, deeply analyzing the impact of AE on security and safety, and comparing it with the current in-vehicle communication solutions like Controller Area Network protocol. We retrieved the key security attacks and mitigations proposed in the current literature to highlight their significance, including a mapping between the regulation UNECE WP.29 R155 and the retrieved answers. We found that the industry has only implemented some automotive-dedicated Ethernet solutions to date. In the near future, the vehicle and road ecosystems may require more exclusive automotive solutions to meet specific constraints such as low latency. Our results can provide a comprehensive baseline, both for industry and academia, for the current and future development of AE.},
  archive      = {J_CSUR},
  author       = {Marco De Vincenzi and Gianpiero Costantino and Ilaria Matteucci and Florian Fenzl and Christian Plappert and Roland Rieke and Daniel Zelle},
  doi          = {10.1145/3637059},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {6},
  pages        = {135:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic review on security attacks and countermeasures in automotive ethernet},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reaching consensus in the byzantine empire: A comprehensive
review of BFT consensus algorithms. <em>CSUR</em>, <em>56</em>(5),
134:1–41. (<a href="https://doi.org/10.1145/3636553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Byzantine fault-tolerant (BFT) consensus algorithms are at the core of providing safety and liveness guarantees for distributed systems that must operate in the presence of arbitrary failures. Recently, numerous new BFT algorithms have been proposed, not least due to the traction blockchain technologies have garnered in the search for consensus solutions that offer high throughput, low latency, and robust system designs. In this article, we conduct a systematic survey of selected and distinguished BFT algorithms that have received extensive attention in academia and industry alike. We perform a qualitative comparison among all algorithms we review considering message and time complexities. Furthermore, we provide a comprehensive, step-by-step description of each surveyed algorithm by decomposing them into constituent subprotocols with intuitive figures to illustrate the message-passing pattern. We also elaborate on the strengths and weaknesses of each algorithm compared to the other state-of-the-art approaches.},
  archive      = {J_CSUR},
  author       = {Gengrui Zhang and Fei Pan and Yunhao Mao and Sofia Tijanic and Michael Dang’ana and Shashank Motepalli and Shiquan Zhang and Hans-Arno Jacobsen},
  doi          = {10.1145/3636553},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {134:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Reaching consensus in the byzantine empire: A comprehensive review of BFT consensus algorithms},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated learning for mobility applications. <em>CSUR</em>,
<em>56</em>(5), 133:1–28. (<a
href="https://doi.org/10.1145/3637868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing concern for privacy and the use of machine learning on personal data has led researchers to introduce new approaches to machine learning. Federated learning is one such a novel privacy-preserving machine learning approach that “brings code to data,” unlike traditional machine learning approaches that “bring data to code.” In addition to improving privacy, federated learning is beneficial for latency-sensitive mobility applications by providing local models. To the best of our knowledge, this article is the first ever to survey mobility-related federated learning solutions, such as traffic-flow prediction, next-location prediction, and point-of-interest recommendation. Our categorization is based on three main questions: Why use federated learning? to identify the motivation to use federated learning; What problems are being addressed? to examine problems that surface with federated learning and how they are solved; and How is federated learning implemented? to account for the solutions implemented by the authors surveyed The selected papers are peer reviewed and published in journals and conferences; they all adopt federated learning as their core approach. We introduce our conceptual model to characterize federated learning solutions and to compare them. In our conceptual model, we define three abstract roles: data generator, learner, and aggregator. We also explain how the work in the selected papers fits into our conceptual model.},
  archive      = {J_CSUR},
  author       = {Melike Gecer and Benoit Garbinato},
  doi          = {10.1145/3637868},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {133:1–28},
  shortjournal = {ACM Comput. Surv.},
  title        = {Federated learning for mobility applications},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Directed test generation for hardware validation: A survey.
<em>CSUR</em>, <em>56</em>(5), 132:1–36. (<a
href="https://doi.org/10.1145/3638046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of hardware designs has increased over the years due to the rapid advancement of technology coupled with the need to support diverse and complex features. The increasing design complexity directly translates to difficulty in verifying functional behaviors as well as non-functional requirements. Simulation is the most widely used form of validation using both random and constrained-random test patterns. The random nature of test sequences can cover a vast majority of scenarios, however, it can introduce unacceptable overhead to cover all possible functional and non-functional scenarios. Directed tests are promising to cover the remaining corner cases and hard-to-detect scenarios. Manual development of directed tests can be time-consuming and error-prone. A promising avenue is to perform automated generation of directed tests. In this article, we provide a comprehensive survey of directed test generation techniques for hardware validation. Specifically, we first introduce the complexity of hardware verification to highlight the need for directed test generation. Next, we describe directed test generation using various automated techniques, including formal methods, concolic testing, and machine learning. Finally, we discuss how to effectively utilize the generated test patterns in different validation scenarios, including pre-silicon functional validation, post-silicon debug, as well as validation of non-functional requirements.},
  archive      = {J_CSUR},
  author       = {Aruna Jayasena and Prabhat Mishra},
  doi          = {10.1145/3638046},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {132:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Directed test generation for hardware validation: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Industrial internet of things ecosystems security and
digital forensics: Achievements, open challenges, and future directions.
<em>CSUR</em>, <em>56</em>(5), 131:1–37. (<a
href="https://doi.org/10.1145/3635030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Industrial Internet of Things (IIoT) has been positioned as a key pillar of the Industry 4.0 revolution, which is projected to continue accelerating and realizing digital transformations. The IIoT is becoming indispensable, providing the means through which modern communication is conducted across industries and offering improved efficiency, scalability, and robustness. However, the structural and dynamic complexity introduced by the continuous integration of the IIoT has widened the scope for cyber-threats, as the processes and data generated by this integration are susceptible and vulnerable to attacks. This article presents an in-depth analysis of the state-of-the-art in the IIoT ecosystem from security and digital forensics perspectives. The dimensions of this study are twofold: first, we present an overview of the cutting-edge security of IIoT ecosystems, and second, we survey the literature on digital forensics. The key achievements, open challenges, and future directions are identified in each case. The challenges and directions for future studies that we identify will provide important guidance for cybersecurity researchers and practitioners.},
  archive      = {J_CSUR},
  author       = {Victor R. Kebande and Ali Ismail Awad},
  doi          = {10.1145/3635030},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {131:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Industrial internet of things ecosystems security and digital forensics: Achievements, open challenges, and future directions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Embedding compression in recommender systems: A survey.
<em>CSUR</em>, <em>56</em>(5), 130:1–21. (<a
href="https://doi.org/10.1145/3637841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To alleviate the problem of information explosion, recommender systems are widely deployed to provide personalized information filtering services. Usually, embedding tables are employed in recommender systems to transform high-dimensional sparse one-hot vectors into dense real-valued embeddings. However, the embedding tables are huge and account for most of the parameters in industrial-scale recommender systems. In order to reduce memory costs and improve efficiency, various approaches are proposed to compress the embedding tables. In this survey, we provide a comprehensive review of embedding compression approaches in recommender systems. We first introduce deep learning recommendation models and the basic concept of embedding compression in recommender systems. Subsequently, we systematically organize existing approaches into three categories: low precision, mixed dimension, and weight sharing. Lastly, we summarize the survey with some general suggestions and provide future prospects for this field.},
  archive      = {J_CSUR},
  author       = {Shiwei Li and Huifeng Guo and Xing Tang and Ruiming Tang and Lu Hou and Ruixuan Li and Rui Zhang},
  doi          = {10.1145/3637841},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {130:1–21},
  shortjournal = {ACM Comput. Surv.},
  title        = {Embedding compression in recommender systems: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Appearance and pose-guided human generation: A survey.
<em>CSUR</em>, <em>56</em>(5), 129:1–35. (<a
href="https://doi.org/10.1145/3637060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Appearance and pose-guided human generation is a burgeoning field that has captured significant attention. This subject’s primary objective is to transfer pose information from a target source to a reference image, enabling the generation of high-resolution images or videos that seamlessly link the virtual and real worlds, leading to novel trends and applications. This survey thoroughly illustrates the task of appearance and pose-guided human generation and comprehensively reviews mainstream methods. Specifically, it systematically discusses prior information, pose-based transformation modules, and generators, offering a comprehensive understanding and discussion of each mainstream pose transformation and generation process. Furthermore, the survey explores current applications and future challenges in the domain. Its ultimate goal is to serve as quick guidelines, providing practical assistance in human generation and its diverse applications.},
  archive      = {J_CSUR},
  author       = {Fangjian Liao and Xingxing Zou and Waikeung Wong},
  doi          = {10.1145/3637060},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {129:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Appearance and pose-guided human generation: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Brave new GES world: A systematic literature review of
gestures and referents in gesture elicitation studies. <em>CSUR</em>,
<em>56</em>(5), 128:1–55. (<a
href="https://doi.org/10.1145/3636458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How do we determine highly effective and intuitive gesture sets for interactive systems tailored to end users’ preferences? A substantial body of knowledge is available on this topic, among which gesture elicitation studies stand out distinctively. In these studies, end users are invited to propose gestures for specific referents, which are the functions to control for an interactive system. The vast majority of gesture elicitation studies conclude with a consensus gesture set identified following a process of consensus or agreement analysis. However, the information about specific gesture sets determined for specific applications is scattered across a wide landscape of disconnected scientific publications, which poses challenges to researchers and practitioners to effectively harness this body of knowledge. To address this challenge, we conducted a systematic literature review and examined a corpus of N = 267 studies encompassing a total of 187,265 gestures elicited from 6,659 participants for 4,106 referents. To understand similarities in users’ gesture preferences within this extensive dataset, we analyzed a sample of 2,304 gestures extracted from the studies identified in our literature review. Our approach consisted of (i) identifying the context of use represented by end users, devices, platforms, and gesture sensing technology; (ii) categorizing the referents; (iii) classifying the gestures elicited for those referents; and (iv) cataloging the gestures based on their representation and implementation modalities. Drawing from the findings of this review, we propose guidelines for conducting future end-user gesture elicitation studies.},
  archive      = {J_CSUR},
  author       = {Santiago Villarreal-Narvaez and Arthur Sluÿters and Jean Vanderdonckt and Radu-Daniel Vatavu},
  doi          = {10.1145/3636458},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {128:1–55},
  shortjournal = {ACM Comput. Surv.},
  title        = {Brave new GES world: A systematic literature review of gestures and referents in gesture elicitation studies},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven causal effect estimation based on graphical
causal modelling: A survey. <em>CSUR</em>, <em>56</em>(5), 127:1–37. (<a
href="https://doi.org/10.1145/3636423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many fields of scientific research and real-world applications, unbiased estimation of causal effects from non-experimental data is crucial for understanding the mechanism underlying the data and for decision-making on effective responses or interventions. A great deal of research has been conducted to address this challenging problem from different angles. For estimating causal effect in observational data, assumptions such as Markov condition, faithfulness, and causal sufficiency are always made. Under the assumptions, full knowledge, such as a set of covariates or an underlying causal graph, is typically required. A practical challenge is that in many applications, no such full knowledge or only some partial knowledge is available. In recent years, research has emerged to use search strategies based on graphical causal modelling to discover useful knowledge from data for causal effect estimation, with some mild assumptions, and has shown promise in tackling the practical challenge. In this survey, we review these data-driven methods on causal effect estimation for a single treatment with a single outcome of interest and focus on the challenges faced by data-driven causal effect estimation. We concisely summarise the basic concepts and theories that are essential for data-driven causal effect estimation using graphical causal modelling but are scattered around the literature. We identify and discuss the challenges faced by data-driven causal effect estimation and characterise the existing methods by their assumptions and the approaches to tackling the challenges. We analyse the strengths and limitations of the different types of methods and present an empirical evaluation to support the discussions. We hope this review will motivate more researchers to design better data-driven methods based on graphical causal modelling for the challenging problem of causal effect estimation.},
  archive      = {J_CSUR},
  author       = {Debo Cheng and Jiuyong Li and Lin Liu and Jixue Liu and Thuc Duy Le},
  doi          = {10.1145/3636423},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {127:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Data-driven causal effect estimation based on graphical causal modelling: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
