<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CSUR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="csur---295">CSUR - 295</h2>
<ul>
<li><details>
<summary>
(2024). A survey of machine learning for urban decision making:
Applications in planning, transportation, and healthcare. <em>CSUR</em>,
<em>57</em>(4), 1–41. (<a
href="https://doi.org/10.1145/3695986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing smart cities is vital for ensuring sustainable development and improving human well-being. One critical aspect of building smart cities is designing intelligent methods to address various decision-making problems that arise in urban areas. As machine learning techniques continue to advance rapidly, a growing body of research has been focused on utilizing these methods to achieve intelligent urban decision-making. In this survey, we conduct a systematic literature review on the application of machine learning methods in urban decision-making, with a focus on planning, transportation, and healthcare. First, we provide a taxonomy based on typical applications of machine learning methods for urban decision-making. We then present background knowledge on these tasks and the machine learning techniques that have been adopted to solve them. Next, we examine the challenges and advantages of applying machine learning in urban decision-making, including issues related to urban complexity, urban heterogeneity, and computational cost. Afterward and primarily, we elaborate on the existing machine learning methods that aim at solving urban decision-making tasks in planning, transportation, and healthcare, highlighting their strengths and limitations. Finally, we discuss open problems and the future directions of applying machine learning to enable intelligent urban decision-making, such as developing foundation models and combining reinforcement learning algorithms with human feedback. We hope this survey can help researchers in related fields understand the recent progress made in existing works, and inspire novel applications of machine learning in smart cities.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695986},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of machine learning for urban decision making: Applications in planning, transportation, and healthcare},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cybersecurity in electric and flying vehicles: Threats,
challenges, AI solutions &amp; future directions. <em>CSUR</em>,
<em>57</em>(4), 1–34. (<a
href="https://doi.org/10.1145/3697830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric and Flying Vehicles (EnFVs) represent a transformative shift in transportation, promising enhanced efficiency and reduced environmental impact. However, their integration into interconnected digital ecosystems poses significant cybersecurity challenges, including cyber-physical threats, privacy vulnerabilities, and supply chain risks. This article comprehensively explores these challenges and investigates artificial intelligence (AI)-driven solutions to bolster EnFV cybersecurity. The study begins with an overview of EnFV cybersecurity issues, emphasizing the increasing complexity of threats in digital transportation systems. Methodologically, the article reviews existing literature to identify gaps and assesses recent advancements in AI for cybersecurity applications. Key methodologies include AI-powered intrusion detection, threat analysis leveraging machine learning algorithms, predictive maintenance strategies, and enhanced authentication protocols. Results underscore the effectiveness of AI technologies in mitigating EnFV cybersecurity risks, demonstrating improved threat detection and response capabilities. The study concludes by outlining future research directions, highlighting the need for continued innovation in AI, quantum computing resilience, blockchain applications, and ethical considerations. These findings contribute to a clearer understanding of EnFV cybersecurity dynamics and provide a roadmap for enhancing the security and reliability of future transportation systems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3697830},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Cybersecurity in electric and flying vehicles: Threats, challenges, AI solutions &amp; future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on IoT programming platforms: A business-domain
experts perspective. <em>CSUR</em>, <em>57</em>(4), 1–37. (<a
href="https://doi.org/10.1145/3699954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vast growth and digitalization potential offered by the Internet of Things (IoT) is hindered by substantial barriers in accessibility, interoperability, and complexity, mainly affecting small organizations and non-technical entities. This survey article provides a detailed overview of the landscape of IoT programming platforms, focusing specifically on the development support they offer for varying end user profiles, ranging from developers with IoT expertise to business experts willing to take advantage of IoT solutions to automate their organization processes. The survey examines a range of IoT platforms, classified according to their programming approach between general-purpose programming solutions, model-driven programming, mashups, and end-user programming. Necessary IoT and programming backgrounds are described to empower non-technical readers with a comprehensive field summary. In addition, the article compares the features of the most representative platforms and provides decision insights and guidelines to support end users in selecting appropriate IoT platforms for their use cases. This work contributes to narrowing the knowledge gap between IoT specialists and end users, breaking accessibility barriers and further promoting the integration of IoT technologies in various domains. 1},
  archive      = {J_CSUR},
  doi          = {10.1145/3699954},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on IoT programming platforms: A business-domain experts perspective},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Taxonomy and survey of collaborative intrusion detection
system using federated learning. <em>CSUR</em>, <em>57</em>(4), 1–36.
(<a href="https://doi.org/10.1145/3701724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review article looks at recent research on Federated Learning (FL) for Collaborative Intrusion Detection Systems (CIDS) to establish a taxonomy and survey. The motivation behind this review comes from the difficulty of detecting coordinated cyberattacks in large-scale distributed networks. Collaborative anomalies are one of the network anomalies that need to be detected through robust collaborative learning methods. FL is promising collaborative learning method in recent research. This review aims to offer insights and lesson learn for creating a taxonomy of collaborative anomaly detection in CIDS using FL as a collaborative learning method. Our findings suggest that a taxonomy is required to map the discussion area, including an algorithm for training the learning model, the dataset, global aggregation model, system architecture, security, and privacy. Our results indicate that FL is a promising approach for collaborative anomaly detection in CIDS, and the proposed taxonomy could be useful for future research in this area. Overall, this review contributes to the growing knowledge of FL for CIDS, providing insights and lessons for researchers and practitioners. This research also concludes significant challenges, opportunities, and future directions in CIDS based on collaborative anomaly detection using FL.},
  archive      = {J_CSUR},
  doi          = {10.1145/3701724},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Taxonomy and survey of collaborative intrusion detection system using federated learning},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fog computing technology research: A retrospective overview
and bibliometric analysis. <em>CSUR</em>, <em>57</em>(4), 1–32. (<a
href="https://doi.org/10.1145/3702313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers’ interest in Fog Computing and its application in different sectors has been increasing since the last decade. To discover the emerging trends inherent to this architecture, we analyzed the scientific literature indexed in Scopus through a bibliometric study. Exposing trends in areas of development will allow researchers to understand the changes and evolution over time. For analysis purposes, we used three approaches: performance analysis, science mapping, and literature clustering. Analysis results revealed promising investigation areas in the Fog Computing architecture from 2012 to 2021, which emphasizes that Fog Computing will continue to be an interesting field of research in the future.},
  archive      = {J_CSUR},
  doi          = {10.1145/3702313},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Fog computing technology research: A retrospective overview and bibliometric analysis},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation methodologies in software protection research.
<em>CSUR</em>, <em>57</em>(4), 1–41. (<a
href="https://doi.org/10.1145/3702314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Man-at-the-end (MATE) attackers have full control over the system on which the attacked software runs, and try to break the confidentiality or integrity of assets embedded in the software. Both companies and malware authors want to prevent such attacks. This has driven an arms race between attackers and defenders, resulting in a plethora of different protection and analysis methods. However, it remains difficult to measure the strength of protections because MATE attackers can reach their goals in many different ways and a universally accepted evaluation methodology does not exist. This survey systematically reviews the evaluation methodologies of papers on obfuscation, a major class of protections against MATE attacks. For 571 papers, we collected 113 aspects of their evaluation methodologies, ranging from sample set types and sizes, over sample treatment, to performed measurements. We provide detailed insights into how the academic state of the art evaluates both the protections and analyses thereon. In summary, there is a clear need for better evaluation methodologies. We identify nine challenges for software protection evaluations, which represent threats to the validity, reproducibility, and interpretation of research results in the context of MATE attacks and formulate a number of concrete recommendations for improving the evaluations reported in future research papers.},
  archive      = {J_CSUR},
  doi          = {10.1145/3702314},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Evaluation methodologies in software protection research},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on emerging trends and applications of 5G and 6G to
healthcare environments. <em>CSUR</em>, <em>57</em>(4), 1–36. (<a
href="https://doi.org/10.1145/3703154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A delay, interruption, or failure in the wireless connection has a significant impact on the performance of wirelessly connected medical equipment. Researchers presented the fastest technological innovations and industrial changes to address these problems and improve the applications of information and communication technology. The development of the 6G communication infrastructure was greatly aided by the use of Block-chain technology, artificial intelligence (AI), virtual reality (VR), and the Internet of Things (IoT). In this article, we comprehensively discuss 6G technologies enhancement, its fundamental architecture, difficulties, and other issues associated with it. In addition, the outcomes of our research help make 6G technology more applicable to real-world medical environments. The most important thing that this study has contributed is an explanation of the path that future research will take and the current state-of-the-art. This study might serve as a jumping-off point for future researchers in the academic world who are interested in investigating the possibilities of 6G technological developments.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703154},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on emerging trends and applications of 5G and 6G to healthcare environments},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Private and secure distributed deep learning: A survey.
<em>CSUR</em>, <em>57</em>(4), 1–43. (<a
href="https://doi.org/10.1145/3703452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, deep learning practitioners would bring data into a central repository for model training and inference. Recent developments in distributed learning, such as federated learning and deep learning as a service (DLaaS), do not require centralized data and instead push computing to where the distributed datasets reside. These decentralized training schemes, however, introduce additional security and privacy challenges. This survey first structures the field of distributed learning into two main paradigms and then provides an overview of the recently published protective measures for each. This work highlights both secure training methods as well as private inference measures. Our analyses show that recent publications, while being highly dependent on the problem definition, report progress in terms of security, privacy, and efficiency. Nevertheless, we also identify several current issues within the private and secure distributed deep learning (PSDDL) field that require more research. We discuss these issues and provide a general overview of how they might be resolved.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703452},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-43},
  shortjournal = {ACM Comput. Surv.},
  title        = {Private and secure distributed deep learning: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Acceleration for deep reinforcement learning using parallel
and distributed computing: A survey. <em>CSUR</em>, <em>57</em>(4),
1–35. (<a href="https://doi.org/10.1145/3703453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has led to dramatic breakthroughs in the field of artificial intelligence for the past few years. As the amount of rollout experience data and the size of neural networks for deep reinforcement learning have grown continuously, handling the training process and reducing the time consumption using parallel and distributed computing is becoming an urgent and essential desire. In this article, we perform a broad and thorough investigation on training acceleration methodologies for deep reinforcement learning based on parallel and distributed computing, providing a comprehensive survey in this field with state-of-the-art methods and pointers to core references. In particular, a taxonomy of literature is provided, along with a discussion of emerging topics and open issues. This incorporates learning system architectures, simulation parallelism, computing parallelism, distributed synchronization mechanisms, and deep evolutionary reinforcement learning. Furthermore, we compare 16 current open-source libraries and platforms with criteria of facilitating rapid development. Finally, we extrapolate future directions that deserve further research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703453},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Acceleration for deep reinforcement learning using parallel and distributed computing: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Open-ethical AI: Advancements in open-source human-centric
neural language models. <em>CSUR</em>, <em>57</em>(4), 1–47. (<a
href="https://doi.org/10.1145/3703454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey summarises the most recent methods for building and assessing helpful, honest, and harmless neural language models, considering small, medium, and large-size models. Pointers to open-source resources that help to align pre-trained models are given, including methods that use parameter-efficient techniques, specialized prompting frameworks, adapter modules, case-specific knowledge injection, and adversarially robust training techniques. Special care is given to evidencing recent progress on value alignment, commonsense reasoning, factuality enhancement, and abstract reasoning of language models. Most reviewed works in this survey publicly shared their code and related data and were accepted in world-leading Machine Learning venues. This work aims at helping researchers and practitioners accelerate their entrance into the field of human-centric neural language models, which might be a cornerstone of the contemporary and near-future industrial and societal revolution.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703454},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-47},
  shortjournal = {ACM Comput. Surv.},
  title        = {Open-ethical AI: Advancements in open-source human-centric neural language models},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security and privacy on generative data in AIGC: A survey.
<em>CSUR</em>, <em>57</em>(4), 1–34. (<a
href="https://doi.org/10.1145/3703626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of artificial intelligence-generated content (AIGC) represents a pivotal moment in the evolution of information technology. With AIGC, it can be effortless to generate high-quality data that is challenging for the public to distinguish. Nevertheless, the proliferation of generative data across cyberspace brings security and privacy issues, including privacy leakages of individuals and media forgery for fraudulent purposes. Consequently, both academia and industry begin to emphasize the trustworthiness of generative data, successively providing a series of countermeasures for security and privacy. In this survey, we systematically review the security and privacy on generative data in AIGC, particularly for the first time analyzing them from the perspective of information security properties. Specifically, we reveal the successful experiences of state-of-the-art countermeasures in terms of the foundational properties of privacy, controllability, authenticity, and compliance, respectively. Finally, we show some representative benchmarks, present a statistical analysis, and summarize the potential exploration directions from each of these properties.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703626},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security and privacy on generative data in AIGC: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). When SDN meets low-rate threats: A survey of attacks and
countermeasures in programmable networks. <em>CSUR</em>, <em>57</em>(4),
1–32. (<a href="https://doi.org/10.1145/3704434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rate threats are a class of attack vectors that are disruptive and stealthy, typically crafted for security vulnerabilities. They have been the significant concern for cyber security, impacting both conventional IP-based networks and emerging Software-Defined Networking (SDN). SDN is a revolutionary architecture that separates the control and data planes, offering advantages such as enhanced manageability, flexibility, and network programmability, as well as the ability to introduce new solutions to address security threats. However, its innovative design also poses new vulnerabilities and threats, especially susceptibility to low-rate threats. To this end, this article presents a comprehensive overview of low-rate threats in programmable networks. It explores low-rate threats and countermeasures within the SDN architecture, encompassing the data plane, control plane, control channel, and application plane, together with traditional low-rate threats and countermeasures in SDN. Furthermore, the article offers detailed insight into threats and countermeasures against low-rate attacks exploiting SDN vulnerabilities and low-rate attacks related to the programmable data plane. Additionally, it presents a comparative analysis and discussion of low-rate attacks versus high-volume attacks, along with suggestions for enhancing SDN security. This thorough review aims to assist researchers in developing more resilient and dependable countermeasures against low-rate threats in programmable networks.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704434},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {When SDN meets low-rate threats: A survey of attacks and countermeasures in programmable networks},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tool learning with foundation models. <em>CSUR</em>,
<em>57</em>(4), 1–40. (<a
href="https://doi.org/10.1145/3704435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans possess an extraordinary ability to create and utilize tools. With the advent of foundation models, artificial intelligence systems have the potential to be equally adept in tool use as humans. This paradigm, which is dubbed as tool learning with foundation models , combines the strengths of tools and foundation models to achieve enhanced accuracy, efficiency, and automation in problem-solving. This article presents a systematic investigation and comprehensive review of tool learning. We first introduce the background of tool learning, including its cognitive origins, the paradigm shift of foundation models, and the complementary roles of tools and models. Then we recapitulate existing tool learning research and formulate a general framework: starting from understanding the user instruction, models should learn to decompose a complex task into several subtasks, dynamically adjust their plan through reasoning, and effectively conquer each sub-task by selecting appropriate tools. We also discuss how to train models for improved tool-use capabilities and facilitate generalization in tool learning. Finally, we discuss several open problems that require further investigation, such as ensuring trustworthy tool use, enabling tool creation with foundation models, and addressing personalization challenges. Overall, we hope this article could inspire future research in integrating tools with foundation models.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704435},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Tool learning with foundation models},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Democratizing container live migration for enhanced future
networks - a survey. <em>CSUR</em>, <em>57</em>(4), 1–37. (<a
href="https://doi.org/10.1145/3704436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging cloud-centric networks span from edge clouds to large-scale datacenters with shared infrastructure among multiple tenants and applications with high availability, isolation, fault tolerance, security, and energy efficiency demands. Live migration (LiMi) plays an increasingly critical role in these environments by enabling seamless application mobility covering the edge-to-cloud continuum and maintaining these requirements. This paper presents a comprehensive survey of recent advancements that democratize LiMi, making it more applicable to a broader range of scenarios and network environments both for virtual machines (VMs) and containers, and analyzes LiMi’s technical underpinnings and optimization techniques. It also delves into the issue of connections handover, presenting a taxonomy to categorize methods of traffic redirection synthesized from the existing literature. Finally, it identifies technical challenges and paves the way for future research directions in this key technology.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704436},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Democratizing container live migration for enhanced future networks - a survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Systematic review of generative modelling tools and utility
metrics for fully synthetic tabular data. <em>CSUR</em>, <em>57</em>(4),
1–38. (<a href="https://doi.org/10.1145/3704437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sharing data with third parties is essential for advancing science, but it is becoming more and more difficult with the rise of data protection regulations, ethical restrictions, and growing fear of misuse. Fully synthetic data, which transcends anonymisation, may be the key to unlocking valuable untapped insights stored away in secured data vaults. This review examines current synthetic data generation methods and their utility measurement. We found that more traditional generative models such as Classification and Regression Tree models alongside Bayesian Networks remain highly relevant and are still capable of surpassing deep learning alternatives like Generative Adversarial Networks. However, our findings also display the same lack of agreement on metrics for evaluation, uncovered in earlier reviews, posing a persistent obstacle to advancing the field. We propose a tool for evaluating the utility of synthetic data and illustrate how it can be applied to three synthetic data generation models. By streamlining evaluation and promoting agreement on metrics, researchers can explore novel methods and generate compelling results that will convince data curators and lawmakers to embrace synthetic data. Our review emphasises the potential of synthetic data and highlights the need for greater collaboration and standardisation to unlock its full potential.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704437},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Systematic review of generative modelling tools and utility metrics for fully synthetic tabular data},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Membership inference attacks and defenses in federated
learning: A survey. <em>CSUR</em>, <em>57</em>(4), 1–35. (<a
href="https://doi.org/10.1145/3704633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a decentralized machine learning approach where clients train models locally and share model updates to develop a global model. This enables low-resource devices to collaboratively build a high-quality model without requiring direct access to the raw training data. However, despite only sharing model updates, federated learning still faces several privacy vulnerabilities. One of the key threats is membership inference attacks, which target clients’ privacy by determining whether a specific example is part of the training set. These attacks can compromise sensitive information in real-world applications, such as medical diagnoses within a healthcare system. Although there has been extensive research on membership inference attacks, a comprehensive and up-to-date survey specifically focused on it within federated learning is still absent. To fill this gap, we categorize and summarize membership inference attacks and their corresponding defense strategies based on their characteristics in this setting. We introduce a unique taxonomy of existing attack research and provide a systematic overview of various countermeasures. For these studies, we thoroughly analyze the strengths and weaknesses of different approaches. Finally, we identify and discuss key future research directions for readers interested in advancing the field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704633},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Membership inference attacks and defenses in federated learning: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Backdoor attacks and defenses targeting multi-domain AI
models: A comprehensive review. <em>CSUR</em>, <em>57</em>(4), 1–35. (<a
href="https://doi.org/10.1145/3704725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the emergence of security concerns in artificial intelligence (AI), there has been significant attention devoted to the examination of backdoor attacks. Attackers can utilize backdoor attacks to manipulate model predictions, leading to significant potential harm. However, current research on backdoor attacks and defenses in both theoretical and practical fields still has many shortcomings. To systematically analyze these shortcomings and address the lack of comprehensive reviews, this article presents a comprehensive and systematic summary of both backdoor attacks and defenses targeting multi-domain AI models. Simultaneously, based on the design principles and shared characteristics of triggers in different domains and the implementation stages of backdoor defense, this article proposes a new classification method for backdoor attacks and defenses. We use this method to extensively review backdoor attacks in the fields of computer vision and natural language processing, and we also examine the current applications of backdoor attacks in audio recognition, video action recognition, multimodal tasks, time series tasks, generative learning, and reinforcement learning, while critically analyzing the open problems of various backdoor attack techniques and defense strategies. Finally, this article builds upon the analysis of the current state of AI security to further explore potential future research directions for backdoor attacks and defenses.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704725},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Backdoor attacks and defenses targeting multi-domain AI models: A comprehensive review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motivations, challenges, best practices, and benefits for
bots and conversational agents in software engineering: A multivocal
literature review. <em>CSUR</em>, <em>57</em>(4), 1–37. (<a
href="https://doi.org/10.1145/3704806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bots are software systems designed to support users by automating specific processes, tasks, or activities. When these systems implement a conversational component to interact with users, they are also known as conversational agents or chatbots . Bots—particularly in their conversation-oriented version and AI-powered—have seen increased adoption over time for software development and engineering purposes. Despite their exciting potential, which has been further enhanced by the advent of Generative AI and Large Language Models, bots still face challenges in terms of development and integration into the development cycle, as practitioners report that bots can add difficulties rather than provide improvements. In this work, we aim to provide a taxonomy for characterizing bots, as well as a series of challenges for their adoption in software engineering, accompanied by potential mitigation strategies. To achieve our objectives, we conducted a multivocal literature review , examining both research and practitioner literature. Through such an approach, we hope to contribute to both researchers and practitioners by providing (i) a series of future research directions to pursue, (ii) a list of strategies to adopt for improving the use of bots for software engineering purposes, and (iii) fostering technology and knowledge transfer from the research field to practice—one of the primary goals of multivocal literature reviews.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704806},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Motivations, challenges, best practices, and benefits for bots and conversational agents in software engineering: A multivocal literature review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative distributed machine learning. <em>CSUR</em>,
<em>57</em>(4), 1–36. (<a
href="https://doi.org/10.1145/3704807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various collaborative distributed machine learning (CDML) systems, including federated learning systems and swarm learning systems, with different key traits were developed to leverage resources for the development and use of machine learning models in a confidentiality-preserving way. To meet use case requirements, suitable CDML systems need to be selected. However, comparison between CDML systems to assess their suitability for use cases is often difficult. To support comparison of CDML systems and introduce scientific and practical audiences to the principal functioning and key traits of CDML systems, this work presents a CDML system conceptualization and CDML archetypes.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704807},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Collaborative distributed machine learning},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Racial bias within face recognition: A survey.
<em>CSUR</em>, <em>57</em>(4), 1–39. (<a
href="https://doi.org/10.1145/3705295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial recognition is one of the most academically studied and industrially developed areas within computer vision where we readily find associated applications deployed globally. This widespread adoption has uncovered significant performance variation across subjects of different racial profiles leading to focused research attention on racial bias within face recognition spanning both current causation and future potential solutions. In support, this study provides an extensive taxonomic review of research on racial bias within face recognition exploring every aspect and stage of the associated facial processing pipeline. Firstly, we discuss the problem definition of racial bias, starting with race definition, grouping strategies, and the societal implications of using race or race-related groupings. Secondly, we divide the common face recognition processing pipeline into four stages: image acquisition, face localisation, face representation, face verification and identification, and review the relevant corresponding literature associated with each stage. The overall aim is to provide comprehensive coverage of the racial bias problem with respect to each and every stage of the face recognition processing pipeline whilst also highlighting the potential pitfalls and limitations of contemporary mitigation strategies that need to be considered within future research endeavours or commercial applications alike.},
  archive      = {J_CSUR},
  doi          = {10.1145/3705295},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Racial bias within face recognition: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-powered fraud detection in decentralized finance: A
project life cycle perspective. <em>CSUR</em>, <em>57</em>(4), 1–38. (<a
href="https://doi.org/10.1145/3705296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized finance (DeFi) represents a novel financial system but faces significant fraud challenges, leading to substantial losses. Recent advancements in artificial intelligence (AI) show potential for complex fraud detection. Despite growing interest, a systematic review of these methods is lacking. This survey correlates fraud types with DeFi project stages, presenting a taxonomy based on the project life cycle. We evaluate AI techniques, revealing notable findings, such as the superiority of tree-based and graph-related models. Based on these insights, we offer recommendations and outline future research directions to aid researchers, practitioners, and regulators in enhancing DeFi security.},
  archive      = {J_CSUR},
  doi          = {10.1145/3705296},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {AI-powered fraud detection in decentralized finance: A project life cycle perspective},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causal discovery from temporal data: An overview and new
perspectives. <em>CSUR</em>, <em>57</em>(4), 1–38. (<a
href="https://doi.org/10.1145/3705297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal data, representing chronological observations of complex systems, has always been a typical data structure that can be widely generated by many domains, such as industry, finance, healthcare, and climatology. Analyzing the underlying structures, i.e., the causal relations, could be extremely valuable for various applications. Recently, causal discovery from temporal data has been considered as an interesting yet critical task and attracted much research attention. According to the nature and structure of temporal data, existing causal discovery works can be divided into two highly correlated categories i.e., multivariate time series causal discovery, and event sequence causal discovery. However, most previous surveys are only focused on the multivariate time series causal discovery but ignore the second category. In this article, we specify the similarity between the two categories and provide an overview of existing solutions. Furthermore, we provide public datasets, evaluation metrics, and new perspectives for temporal data causal discovery.},
  archive      = {J_CSUR},
  doi          = {10.1145/3705297},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Causal discovery from temporal data: An overview and new perspectives},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable artificial intelligence: Importance, use
domains, stages, output shapes, and challenges. <em>CSUR</em>,
<em>57</em>(4), 1–36. (<a
href="https://doi.org/10.1145/3705724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an urgent need in many application areas for eXplainable ArtificiaI Intelligence (XAI) approaches to boost people’s confidence and trust in Artificial Intelligence methods. Current works concentrate on specific aspects of XAI and avoid a comprehensive perspective. This study undertakes a systematic survey of importance, approaches, methods, and application domains to address this gap and provide a comprehensive understanding of the XAI domain. Applying the Systematic Literature Review approach has resulted in finding and discussing 155 papers, allowing a wide discussion on the strengths, limitations, and challenges of XAI methods and future research directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3705724},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Explainable artificial intelligence: Importance, use domains, stages, output shapes, and challenges},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). SoK: Access control policy generation from high-level
natural language requirements. <em>CSUR</em>, <em>57</em>(4), 1–37. (<a
href="https://doi.org/10.1145/3706057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Administrator-centered access control failures can cause data breaches, putting organizations at risk of financial loss and reputation damage. Existing graphical policy configuration tools and automated policy generation frameworks attempt to help administrators configure and generate access control policies by avoiding such failures. However, graphical policy configuration tools are prone to human errors, making them unusable. On the other hand, automated policy generation frameworks are prone to erroneous predictions, making them unreliable. Therefore, to find ways to improve their usability and reliability, we conducted a Systematic Literature Review analyzing 49 publications. The thematic analysis of the publications revealed that graphical policy configuration tools are developed to write and visualize policies manually. Moreover, automated policy generation frameworks are developed using machine learning (ML) and natural language processing (NLP) techniques to automatically generate access control policies from high-level requirement specifications. Despite their utility in the access control domain, limitations of these tools, such as the lack of flexibility, and limitations of frameworks, such as the lack of domain adaptation, negatively affect their usability and reliability, respectively. Our study offers recommendations to address these limitations through real-world applications and recent advancements in the NLP domain, paving the way for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3706057},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {SoK: Access control policy generation from high-level natural language requirements},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Object selection and manipulation in VR headsets: Research
challenges, solutions, and success measurements. <em>CSUR</em>,
<em>57</em>(4), 1–34. (<a
href="https://doi.org/10.1145/3706417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object selection and manipulation are the foundation of VR interactions. With the rapid development of VR technology and the field of virtual object selection and manipulation, the literature demands a structured understanding of the core research challenges and a critical reflection of the current practices. To provide such understanding and reflections, we systematically reviewed 106 papers. We identified classic and emerging topics, categorized existing solutions, and evaluated how success was measured in these publications. Based on our analysis, we discuss future research directions and propose a framework for developing and determining appropriate solutions for different application scenarios.},
  archive      = {J_CSUR},
  doi          = {10.1145/3706417},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Object selection and manipulation in VR headsets: Research challenges, solutions, and success measurements},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security challenges, mitigation strategies, and future
trends in wireless sensor networks: A review. <em>CSUR</em>,
<em>57</em>(4), 1–29. (<a
href="https://doi.org/10.1145/3706583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor Networks (WSNs) represent an innovative technology that integrates compact, energy-efficient sensors with wireless communication functionalities, facilitating instantaneous surveillance and data gathering from the surrounding environment. WSNs are utilized across diverse domains, such as environmental monitoring, industrial automation, healthcare, smart agriculture, home automation, and beyond. Due to the inherent characteristics of WSNs they face many security challenges ranging from resource-based attacks, such as energy depletion or computational overload, to eavesdropping, interception, and tampering. Moreover, the dynamic and often ad hoc deployment of sensors in varying environments increases their vulnerability to physical intrusion attacks, the distributed and collaborative nature of WSNs raises concerns about data integrity, as compromised nodes can potentially propagate misleading or malicious information throughout the network. In this article, we categorize WSN attacks, identifying vulnerabilities and corresponding mitigation strategies. We also explore current research directions in WSN security, emphasizing the challenges in addressing these issues.},
  archive      = {J_CSUR},
  doi          = {10.1145/3706583},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-29},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security challenges, mitigation strategies, and future trends in wireless sensor networks: A review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LiDAR-based place recognition for autonomous driving: A
survey. <em>CSUR</em>, <em>57</em>(4), 1–36. (<a
href="https://doi.org/10.1145/3707446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LiDAR has gained popularity in autonomous driving due to advantages like long measurement distance, rich three-dimensional information, and stability in harsh environments. Place Recognition (PR) enables vehicles to identify previously visited locations despite variations in appearance, weather, and viewpoints, even determining their global location within prior maps. This capability is crucial for accurate localization in autonomous driving. Consequently, LiDAR-based Place Recognition (LPR) has emerged as a research hotspot in robotics. However, existing reviews predominantly concentrate on Visual Place Recognition, leaving a gap in systematic reviews on LPR. This article bridges this gap by providing a comprehensive review of LPR methods, thus facilitating and encouraging further research. We commence by exploring the relationship between PR and autonomous driving components. Then, we delve into the problem formulation of LPR, challenges, and relations to previous surveys. Subsequently, we conduct an in-depth review of related research, which offers detailed classifications, strengths and weaknesses, and architectures. Finally, we summarize existing datasets and evaluation metrics and envision promising future directions. This article can serve as a valuable tutorial for newcomers entering the field of place recognition. We plan to maintain an up-to-date project on https://github.com/ShiPC-AI/LPR-Survey .},
  archive      = {J_CSUR},
  doi          = {10.1145/3707446},
  journal      = {ACM Computing Surveys},
  month        = {12},
  number       = {4},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {LiDAR-based place recognition for autonomous driving: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on deep clustering: Taxonomy,
challenges, and future directions. <em>CSUR</em>, <em>57</em>(3), 1–38.
(<a href="https://doi.org/10.1145/3689036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a fundamental machine learning task, which aim at assigning instances into groups so that similar samples belong to the same cluster while dissimilar samples belong to different clusters. Shallow clustering methods usually assume that data are collected and expressed as feature vectors within which clustering is performed. However, clustering high-dimensional data, such as images, texts, videos, and graphs, poses significant challenges for clustering tasks, such as indiscriminate representation and intricate relationships among instances. Over the past decades, deep learning has achieved remarkable success in effective representation learning and modeling complex relationships. Motivated by these advancements, Deep Clustering seeks to improve clustering outcomes through deep learning techniques, garnering considerable interest from both academia and industry. Despite many contributions to this vibrant area of research, the lack of systematic analysis and a comprehensive taxonomy has hindered progress in this field. In this survey, we first explore how deep learning can be integrated into deep clustering and identify two fundamental components: the representation learning module and the clustering module. Then, we summarize and analyze the representative design of these two modules. Furthermore, we introduce a novel taxonomy of deep clustering based on how these two modules interact, specifically through multistage, generative, iterative, and simultaneous approaches. In addition, we present well-known benchmark datasets, evaluation metrics, and open-source tools to clearly demonstrate different experimental approaches. Finally, we examine the practical applications of deep clustering and propose challenging areas for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3689036},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on deep clustering: Taxonomy, challenges, and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The gap between trustworthy AI research and trustworthy
software research: A tertiary study. <em>CSUR</em>, <em>57</em>(3),
1–40. (<a href="https://doi.org/10.1145/3694964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing application and complexity of Artificial Intelligence (AI) systems, the trustworthiness of AI has garnered widespread attention across various fields. An AI system is a specific type of software system with unique trustworthiness requirements due to its distinctive characteristics in data and algorithms. Our objective is to investigate the state-of-the-art in trustworthy AI and trustworthy software separately and to analyze the connections and gaps between them. To this end, we conducted a tertiary study, which is a systematic literature review of existing secondary studies. These secondary studies are divided into two groups: one focuses on trustworthy AI and the other on trustworthy software. We developed frameworks for both trustworthy AI and trustworthy software, summarized the definitions of quality attributes in a structured format, and analyzed the similarities of these attributes between the two areas. Additionally, we created a swimlane diagram illustrating trustworthy practices throughout the development life-cycle and in relation to specific quality attributes. Researchers in these two areas originate from distinct research communities, leading to a significant gap between the trustworthiness of AI and software. However, we believe that existing research on trustworthy software can effectively address some gaps in trustworthy AI research, and we have identified evidence of connections between the two areas.},
  archive      = {J_CSUR},
  doi          = {10.1145/3694964},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {The gap between trustworthy AI research and trustworthy software research: A tertiary study},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning aided intelligent reflective surfaces for 6G:
A survey. <em>CSUR</em>, <em>57</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3696414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The envisioned sixth-generation (6G) networks anticipate robust support for diverse applications, including massive machine-type communications, ultra-reliable low-latency communications, and enhanced mobile broadband. Intelligent Reflecting surface (IRS) have emerged as a key technology capable of intelligently reconfiguring wireless propagation environments, thereby enhancing overall network performance. Traditional optimization techniques face limitations in meeting the stringent performance requirements of 6G networks due to the intricate and dynamic nature of the wireless environment. Consequently, deep learning (DL) techniques are employed within the IRS framework to optimize wireless system performance. This article provides a comprehensive survey of the latest research in DL-aided IRS models, covering optimal beamforming, resource allocation control, channel estimation and prediction, signal detection, and system deployment. The focus is on presenting promising solutions within the constraints of different hardware configurations. The survey explores challenges, opportunities, and open research issues in DL-aided IRS, considering emerging technologies such as digital twins, computer vision, blockchain, network function virtualization, integrated sensing and communication, software-defined networking, mobile edge computing, unmanned aerial vehicles, and non-orthogonal multiple access. Practical design issues associated with these enabling technologies are also discussed, providing valuable insights into the current state and future directions of this evolving field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696414},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning aided intelligent reflective surfaces for 6G: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modal misinformation detection: Approaches, challenges
and opportunities. <em>CSUR</em>, <em>57</em>(3), 1–29. (<a
href="https://doi.org/10.1145/3697349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As social media platforms evolve from text-based forums into multi-modal environments, the nature of misinformation in social media is also transforming accordingly. Taking advantage of the fact that visual modalities such as images and videos are more favorable and attractive to users, and textual content is sometimes skimmed carelessly, misinformation spreaders have recently targeted contextual connections between the modalities, e.g., text and image. Hence, many researchers have developed automatic techniques for detecting possible cross-modal discordance in web-based content. We analyze, categorize, and identify existing approaches in addition to the challenges and shortcomings they face to unearth new research opportunities in the field of multi-modal misinformation detection.},
  archive      = {J_CSUR},
  doi          = {10.1145/3697349},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-29},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multi-modal misinformation detection: Approaches, challenges and opportunities},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The role of multi-agents in digital twin implementation:
Short survey. <em>CSUR</em>, <em>57</em>(3), 1–15. (<a
href="https://doi.org/10.1145/3697350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Digital Twin (DT) technology has emerged as a significant technological advancement. A digital twin is a digital representation of a physical asset that mirrors its data model, behaviour, and interactions with other physical assets. Digital Twin aims at achieving adaptability, seamless data integration, modelling, simulation, automation, and real-time data management. The primary goal of this article is to explore the role of agents in DT implementations, seeking to understand their predominant usage scenarios and purposes. From our perspective, agents serving as intelligent entities play a role in realising the features of DTs. This article also discusses the gaps in DT, highlights future directions, and analyses various technologies integrated with multi-agent systems technologies in DT implementations. Finally, the article briefly discusses an overview of an architecture to implement a DT for smart agriculture with multi-agents.},
  archive      = {J_CSUR},
  doi          = {10.1145/3697350},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-15},
  shortjournal = {ACM Comput. Surv.},
  title        = {The role of multi-agents in digital twin implementation: Short survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning-based artificial intelligence artwork: Methodology
taxonomy and quality evaluation. <em>CSUR</em>, <em>57</em>(3), 1–37.
(<a href="https://doi.org/10.1145/3698105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the theory and technology of computer science, machine or computer painting is increasingly being explored in the creation of art. Machine-made works are referred to as artificial intelligence (AI) artworks. Early methods of AI artwork generation have been classified as non-photorealistic rendering, and, latterly, neural style transfer methods have also been investigated. As technology advances, the variety of machine-generated artworks and the methods used to create them have proliferated. However, there is no unified and comprehensive system to classify and evaluate these works. To date, no work has generalized methods of creating AI artwork including learning-based methods for painting or drawing. Moreover, the taxonomy, evaluation, and development of AI artwork methods face many challenges. This article is motivated by these considerations. We first investigate current learning-based methods for making AI artworks and classify the methods according to art styles. Furthermore, we propose a consistent evaluation system for AI artworks and conduct a user study to evaluate the proposed system on different AI artworks. This evaluation system uses six criteria: beauty, color, texture, content detail, line, and style. The user study demonstrates that the six-dimensional evaluation index is effective for different types of AI artworks.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698105},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Learning-based artificial intelligence artwork: Methodology taxonomy and quality evaluation},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Green IN artificial intelligence from a software
perspective: State-of-the-art and green decalogue. <em>CSUR</em>,
<em>57</em>(3), 1–30. (<a
href="https://doi.org/10.1145/3698111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a structured view of the state-of-the-art research on Artificial Intelligence (AI), from the point of view of efficiency and reduction of the energy consumption of AI software. We analysed the current research on energy consumption of AI algorithms and its improvements, which gave us a starting literature corpus of 2,688 papers that we identified as Green AI with a software perspective. We structure this corpus into Green IN AI and Green BY AI, which led us to discover that only 36 of them could be considered Green IN AI. After some quick insights about Green BY AI, we then introduce our main contribution: a systematic mapping of Green IN AI. We provide an in-depth analysis of the AI models that we observed during the mapping, and what solutions have been proposed for improving their energy efficiency. We also analyse the energy evaluation methodologies employed in Green IN AI, discovering that most papers opt for a software-based energy estimation approach and 27% of all papers do not document their methodology. We finish by synthetising our insights from the mapping into a Decalogue of Good Practices for Green AI.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698111},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Green IN artificial intelligence from a software perspective: State-of-the-art and green decalogue},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge editing for large language models: A survey.
<em>CSUR</em>, <em>57</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3698590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have recently transformed both the academic and industrial landscapes due to their remarkable capacity to understand, analyze, and generate texts based on their vast knowledge and reasoning ability. Nevertheless, one major drawback of LLMs is their substantial computational cost for pre-training due to their unprecedented amounts of parameters. The disadvantage is exacerbated when new knowledge frequently needs to be introduced into the pre-trained model. Therefore, it is imperative to develop effective and efficient techniques to update pre-trained LLMs. Traditional methods encode new knowledge in pre-trained LLMs through direct fine-tuning. However, naively re-training LLMs can be computationally intensive and risks degenerating valuable pre-trained knowledge irrelevant to the update in the model. Recently, Knowledge-based Model Editing (KME), also known as Knowledge Editing or Model Editing , has attracted increasing attention, which aims at precisely modifying the LLMs to incorporate specific knowledge, without negatively influencing other irrelevant knowledge. In this survey, we aim at providing a comprehensive and in-depth overview of recent advances in the field of KME. We first introduce a general formulation of KME to encompass different KME strategies. Afterward, we provide an innovative taxonomy of KME techniques based on how the new knowledge is introduced into pre-trained LLMs, and investigate existing KME strategies while analyzing key insights, advantages, and limitations of methods from each category. Moreover, representative metrics, datasets, and applications of KME are introduced accordingly. Finally, we provide an in-depth analysis regarding the practicality and remaining challenges of KME and suggest promising research directions for further advancement in this field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698590},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Knowledge editing for large language models: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Early-exit deep neural network - a comprehensive survey.
<em>CSUR</em>, <em>57</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3698767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) typically have a single exit point that makes predictions by running the entire stack of neural layers. Since not all inputs require the same amount of computation to reach a confident prediction, recent research has focused on incorporating multiple “exits” into the conventional DNN architecture. Early-exit DNNs are multi-exit neural networks that attach many side branches to the conventional DNN, enabling inference to stop early at intermediate points. This approach offers several advantages, including speeding up the inference process, mitigating the vanishing gradients problems, reducing overfitting and overthinking tendencies. It also supports DNN partitioning across devices and is ideal for multi-tier computation platforms such as edge computing. This article decomposes the early-exit DNN architecture and reviews the recent advances in the field. The study explores its benefits, designs, training strategies, and adaptive inference mechanisms. Various design challenges, application scenarios, and future directions are also extensively discussed.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698767},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Early-exit deep neural network - a comprehensive survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge-based cyber physical security at smart home: A
review. <em>CSUR</em>, <em>57</em>(3), 1–36. (<a
href="https://doi.org/10.1145/3698768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart-home systems represent the future of modern building infrastructure as they integrate numerous devices and applications to improve the overall quality of life. These systems establish connectivity among smart devices, leveraging network technologies and algorithmic controls to monitor and manage physical environments. However, ensuring robust security in smart homes, along with securing smart devices, presents a formidable challenge. A substantial number of security solutions for smart homes rely on data-driven approaches (e.g., machine/deep learning) to identify and mitigate potential threats. These approaches involve training models on extensive datasets, which distinguishes them from knowledge-driven methods. In this review, we examine the role of knowledge within smart homes, focusing on understanding and reasoning regarding various events and their utility toward securing smart homes. We propose a taxonomy to characterize the categorization of decision-making approaches. By specifying the most common vulnerabilities, attacks, and threats, we can analyze and assess the countermeasures against them. We also examine how smart homes have been evaluated in the reviewed literature. Furthermore, we explore the challenges inherent in smart homes and investigate existing solutions that aim at overcoming these limitations. Finally, we examine the key gaps in smart-home-security research and define future research directions for knowledge-driven schemes.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698768},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Knowledge-based cyber physical security at smart home: A review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deepfake detection: A comprehensive survey from the
reliability perspective. <em>CSUR</em>, <em>57</em>(3), 1–35. (<a
href="https://doi.org/10.1145/3699710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mushroomed Deepfake synthetic materials circulated on the internet have raised a profound social impact on politicians, celebrities, and individuals worldwide. In this survey, we provide a thorough review of the existing Deepfake detection studies from the reliability perspective. We identify three reliability-oriented research challenges in the current Deepfake detection domain: transferability, interpretability, and robustness. Moreover, while solutions have been frequently addressed regarding the three challenges, the general reliability of a detection model has been barely considered, leading to the lack of reliable evidence in real-life usages and even for prosecutions on Deepfake-related cases in court. We, therefore, introduce a model reliability study metric using statistical random sampling knowledge and the publicly available benchmark datasets to review the reliability of the existing detection models on arbitrary Deepfake candidate suspects. Case studies are further executed to justify the real-life Deepfake cases including different groups of victims with the help of the reliably qualified detection models as reviewed in this survey. Reviews and experiments on the existing approaches provide informative discussions and future research directions for Deepfake detection.},
  archive      = {J_CSUR},
  doi          = {10.1145/3699710},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deepfake detection: A comprehensive survey from the reliability perspective},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic literature review on automated software
vulnerability detection using machine learning. <em>CSUR</em>,
<em>57</em>(3), 1–36. (<a
href="https://doi.org/10.1145/3699711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, numerous Machine Learning (ML) models, including Deep Learning (DL) and classic ML models, have been developed to detect software vulnerabilities. However, there is a notable lack of comprehensive and systematic surveys that summarize, classify, and analyze the applications of these ML models in software vulnerability detection. This absence may lead to critical research areas being overlooked or under-represented, resulting in a skewed understanding of the current state of the art in software vulnerability detection. To close this gap, we propose a comprehensive and systematic literature review that characterizes the different properties of ML-based software vulnerability detection systems using six major Research Questions (RQs). Using a custom web scraper, our systematic approach involves extracting a set of studies from four widely used online digital libraries: ACM Digital Library, IEEE Xplore, ScienceDirect, and Google Scholar. We manually analyzed the extracted studies to filter out irrelevant work unrelated to software vulnerability detection, followed by creating taxonomies and addressing RQs. Our analysis indicates a significant upward trend in applying ML techniques for software vulnerability detection over the past few years, with many studies published in recent years. Prominent conference venues include the International Conference on Software Engineering (ICSE), the International Symposium on Software Reliability Engineering (ISSRE), the Mining Software Repositories (MSR) conference, and the ACM International Conference on the Foundations of Software Engineering (FSE), whereas Information and Software Technology (IST), Computers &amp; Security (C&amp;S), and Journal of Systems and Software (JSS) are the leading journal venues. Our results reveal that 39.1% of the subject studies use hybrid sources, whereas 37.6% of the subject studies utilize benchmark data for software vulnerability detection. Code-based data are the most commonly used data type among subject studies, with source code being the predominant subtype. Graph-based and token-based input representations are the most popular techniques, accounting for 57.2% and 24.6% of the subject studies, respectively. Among the input embedding techniques, graph embedding and token vector embedding are the most frequently used techniques, accounting for 32.6% and 29.7% of the subject studies. Additionally, 88.4% of the subject studies use DL models, with recurrent neural networks and graph neural networks being the most popular subcategories, whereas only 7.2% use classic ML models. Among the vulnerability types covered by the subject studies, CWE-119, CWE-20, and CWE-190 are the most frequent ones. In terms of tools used for software vulnerability detection, Keras with TensorFlow backend and PyTorch libraries are the most frequently used model-building tools, accounting for 42 studies for each. In addition, Joern is the most popular tool used for code representation, accounting for 24 studies. Finally, we summarize the challenges and future directions in the context of software vulnerability detection, providing valuable insights for researchers and practitioners in the field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3699711},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on automated software vulnerability detection using machine learning},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence to support the training and
assessment of professionals: A systematic literature review.
<em>CSUR</em>, <em>57</em>(3), 1–29. (<a
href="https://doi.org/10.1145/3699712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in Artificial Intelligence (AI) and sensors are significantly impacting multiple areas, including education and workplaces. Following the PRISMA methodology, this review explores the current status of using AI to support the training and assessment of professionals. We examined 83 research papers, analyzing (1) the targeted professionals, (2) the skills assessed, (3) the AI algorithms utilized, (4) the data and devices employed, (5) data fusion techniques utilized, (6) the architecture of the proposed platforms, (7) the management of ethics and privacy, and (8) validations of the proposals. The review highlights a trend in evaluating healthcare professionals (especially surgeons) motivated by the critical role of hands-on training in these professions. Besides, the review reveals that data fusion techniques and certain technologies, like transfer learning and explainable AI, are not widely utilized despite their huge potential. Finally, the review underscores that most proposals remain within the research domain, lacking the integration and maturity needed for sustained use in real-world environments. Therefore, most of the proposals are not currently available to support the training of professionals. The insights of this review can guide researchers aiming to improve the training of professionals and, consequently, their education.},
  archive      = {J_CSUR},
  doi          = {10.1145/3699712},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-29},
  shortjournal = {ACM Comput. Surv.},
  title        = {Artificial intelligence to support the training and assessment of professionals: A systematic literature review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey of studies on predicting anatomical
therapeutic chemical classes of drugs. <em>CSUR</em>, <em>57</em>(3),
1–31. (<a href="https://doi.org/10.1145/3699713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug classification plays a crucial role in contemporary drug discovery, design, and development. Determining the Anatomical Therapeutic Chemical (ATC) classes for new drugs is a laborious, costly, and intricate process, often requiring multiple clinical trial phases. Computational models offer significant benefits by accelerating drug evaluation, reducing complexity, and lowering costs; however, challenges persist in the drug classification system. To address this, a literature survey of computational models used for predicting ATC classes was conducted, covering research from 2008 to 2024. This study reviews numerous research articles on drug classification, focusing on drug descriptors, data sources, tasks, computational methods, model performance, and challenges in predicting ATC classes. It also examines the evolution of computational techniques and their application in identifying ATC classes. Finally, the study highlights open problems and research gaps, suggesting areas for further investigation in ATC class prediction.},
  archive      = {J_CSUR},
  doi          = {10.1145/3699713},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-31},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey of studies on predicting anatomical therapeutic chemical classes of drugs},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mathematical information retrieval: A review. <em>CSUR</em>,
<em>57</em>(3), 1–34. (<a
href="https://doi.org/10.1145/3699953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical formulas are commonly used to demonstrate theories and basic fundamentals in the Science, Technology, Engineering, and Mathematics (STEM) domain. The burgeoning research in the STEM domain results in the mass production of scientific documents that contain both textual and mathematical terms. In scientific information, the definition of mathematical formulas is expressed through context and symbolic structure that adheres to strong domain-specific notions. Whereas the retrieval of textual information is well-researched, and numerous text-based search engines are present. However, textual information retrieval systems are inadequate for searching scientific information containing mathematical formulas, including simple symbols to complicated mathematical structures. The retrieval of mathematical information is in its infancy, and it requires the inclusion of new technologies and tools to promote the retrieval of scientific information and the management of digital libraries. This article provides a comprehensive study of mathematical information retrieval and highlights their challenges and future opportunities.},
  archive      = {J_CSUR},
  doi          = {10.1145/3699953},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Mathematical information retrieval: A review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on rare event prediction.
<em>CSUR</em>, <em>57</em>(3), 1–39. (<a
href="https://doi.org/10.1145/3699955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rare event prediction involves identifying and forecasting events with a low probability using machine learning (ML) and data analysis. Due to the imbalanced data distributions, where the frequency of common events vastly outweighs that of rare events, it requires using specialized methods within each step of the ML pipeline, that is, from data processing to algorithms to evaluation protocols. Predicting the occurrences of rare events is important for real-world applications, such as Industry 4.0, and is an active research area in statistical and ML. This article comprehensively reviews the current approaches for rare event prediction along four dimensions: rare event data, data processing, algorithmic approaches, and evaluation approaches. Specifically, we consider 73 datasets from different modalities (i.e., numerical, image, text, and audio), four major categories of data processing, five major algorithmic groupings, and two broader evaluation approaches. This article aims to identify gaps in the current literature and highlight the challenges of predicting rare events. It also suggests potential research directions, which can help guide practitioners and researchers.},
  archive      = {J_CSUR},
  doi          = {10.1145/3699955},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on rare event prediction},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On efficient training of large-scale deep learning models.
<em>CSUR</em>, <em>57</em>(3), 1–36. (<a
href="https://doi.org/10.1145/3700439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of deep learning has witnessed significant progress in recent times, particularly in areas such as computer vision (CV), natural language processing (NLP), and speech. The use of large-scale models trained on vast amounts of data holds immense promise for practical applications, enhancing industrial productivity and facilitating social development. However, it suffers extremely from the unstable training process and stringent requirements of computational resources. With the increasing demands on the adaption of computational capacity, though numerous studies have explored the efficient training field to a certain extent, a comprehensive summarization/guideline on those general acceleration techniques of training large-scale deep learning models is still much anticipated. In this survey, we present a detailed review of the general techniques for training acceleration. We consider the fundamental update formulation and split its basic components into five main perspectives: (1) “data-centric,” including dataset regularization, data sampling, and data-centric curriculum learning techniques, which can significantly reduce the computational complexity of the data samples; (2) “model-centric,” including acceleration of basic modules, compression training, model initialization, and model-centric curriculum learning techniques, which focus on accelerating the training via reducing the calculations on parameters and providing better initialization; (3) “optimization-centric,” including the selection of learning rate, the employment of large batch size, the designs of efficient objectives, and model average techniques, which pay attention to the training policy and improving the generality for the large-scale models; (4) “budgeted training,” including some distinctive acceleration methods on source-constrained situations, e.g., for limitation on the total iterations; and (5) “system-centric,” including some efficient distributed frameworks and open source libraries that provide adequate hardware support for the implementation of the above-mentioned acceleration algorithms. By presenting this comprehensive taxonomy, our survey presents a comprehensive review to understand the general mechanisms within each component and their joint interaction. Meanwhile, we further provide a detailed analysis and discussion of future works on the development of general acceleration techniques, which could inspire us to re-think and design novel efficient paradigms. Overall, we hope that this survey will serve as a valuable guideline for general efficient training.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700439},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {On efficient training of large-scale deep learning models},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic literature review on multi-robot task
allocation. <em>CSUR</em>, <em>57</em>(3), 1–28. (<a
href="https://doi.org/10.1145/3700591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Muti-Robot system is gaining attention and is one of the critical areas of research when it comes to robotics. Coordination among multiple robots and how different tasks are allocated to different system agents are being studied. The objective of this Systematic Literature Review (SLR) is to provide insights on the recent advancement in Multi-Robot Task Allocation (MRTA) problems emphasizing promising approaches for task allocation. In this study, we collected scientific papers from five different databases for MRTA. We outline the different approaches for task allocation algorithms, classifying them according to the methods, and emphasizing recent advances. In addition, we discuss the function of uncertainty in task allocation and typical coordination techniques utilized in task allocation to identify gaps in the literature and suggest the most promising ones.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700591},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-28},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on multi-robot task allocation},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single-document abstractive text summarization: A systematic
literature review. <em>CSUR</em>, <em>57</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3700639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstractive text summarization is a task in natural language processing that automatically generates the summary from the source document in a human-written form with minimal loss of information. Research in text summarization has shifted towards abstractive text summarization due to its challenging aspects. This study provides a broad systematic literature review of abstractive text summarization on single-document summarization to gain insights into the challenges, widely used datasets, evaluation metrics, approaches, and methods. This study reviews research articles published between 2011 and 2023 from popular electronic databases. In total, 226 journal and conference publications were included in this review. The in-depth analysis of these papers helps researchers understand the challenges, widely used datasets, evaluation metrics, approaches, and methods. This article identifies and discusses potential opportunities and directions along with a generic conceptual framework and guidelines on abstractive summarization models and techniques for research in abstractive text summarization.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700639},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Single-document abstractive text summarization: A systematic literature review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security and reliability of internet of underwater things:
Architecture, challenges, and opportunities. <em>CSUR</em>,
<em>57</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3700640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Underwater Things (IoUT) pertains to a system that utilizes technology of Internet of Things (IoT) for data collection, communication, and control in the underwater environment. The monitoring and management of various parameters in the underwater domain are gathered through the deployment of underwater sensors, communication devices, and controllers. It is crucial in emerging ocean engineering. However, due to the instability of the underwater environment and the particularity of the underwater communication transmission medium, it is vulnerable to security threats, which may damage the system or cause data errors. In this survey, we will discuss the challenges, solutions, and future directions of IoUT from security and reliability, respectively. To ensure the normal operation of IoUT, we analyze the underwater security problems and solutions of the IoUT. Then, we discuss the reliability issue and improved strategies of IoUT system in detail. Finally, we come up with our views about the theories, challenges, and future prospects of IoUT security after the comparative analysis.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700640},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security and reliability of internet of underwater things: Architecture, challenges, and opportunities},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review on blockchain technology, current challenges, and
AI-driven solutions. <em>CSUR</em>, <em>57</em>(3), 1–39. (<a
href="https://doi.org/10.1145/3700641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain provides several advantages, including decentralization, data integrity, traceability, and immutability. However, despite its advantages, blockchain suffers from significant limitations, including scalability, resource greediness, governance complexity, and some security related issues. These limitations prevent its adoption in mainstream applications. Artificial Intelligence (AI) can help addressing some of these limitations. This survey provides a detailed overview of the different blockchain AI-based optimization and improvement approaches, tools and methodologies proposed to meet the needs of existing systems and applications with their benefits and drawbacks. Afterward, the focus is on suggesting AI-based directions where to address some of the fundamental limitations of blockchain.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700641},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review on blockchain technology, current challenges, and AI-driven solutions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modality deep-learning frameworks for fake news detection on
social networks: A systematic literature review. <em>CSUR</em>,
<em>57</em>(3), 1–50. (<a
href="https://doi.org/10.1145/3700748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news on social networks is a challenging problem due to the rapid dissemination and volume of information, as well as the ease of creating and sharing content anonymously. Fake news stories are problematic not only for the credibility of online journalism, but also due to their detrimental real-world consequences. The primary research objective of this study is to identify recent state-of-the-art deep learning methods used to detect fake news in social networks. This article presents a systematic literature review of deep learning-based fake news detection models in social networks. The methodology followed a rigorous approach, including predefined criteria for study selection of deep learning modalities. This study focuses on the types of deep learning modalities: unimodal (refers to the use of a single model for analysis or modeling purposes) and multimodal models (refers to the integration of multiple models). The results of this review reveal the strengths and weaknesses of modalities approaches, as well as the limitations of low-resource languages datasets. Furthermore, it provides insights into future directions for deep learning models and different fact-checking techniques. At the end of this study, we discuss the problem of fake news detection in the era of large language models in terms of advantages, drawbacks, and challenges.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700748},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-50},
  shortjournal = {ACM Comput. Surv.},
  title        = {Modality deep-learning frameworks for fake news detection on social networks: A systematic literature review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on advanced persistent threat detection: A unified
framework, challenges, and countermeasures. <em>CSUR</em>,
<em>57</em>(3), 1–36. (<a
href="https://doi.org/10.1145/3700749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, frequent Advanced Persistent Threat (APT) attacks have caused disastrous damage to critical facilities, leading to severe information leakages, economic losses, and even social disruptions. Via sophisticated, long-term, and stealthy network intrusions, APT attacks are often beyond the capabilities of traditional intrusion detection methods. Existing methods employ various techniques to enhance APT detection at different stages, but this makes it difficult to fairly and objectively evaluate the capability, value, and orthogonality of available techniques. Overly focusing on hardening specific APT detection stages cannot address some essential challenges from a global perspective, which would result in severe consequences. To holistically tackle this problem and explore effective solutions, we abstract a unified framework that covers the complete process of APT attack detection, with standardized summaries of state-of-the-art solutions and analysis of feasible techniques. Further, we provide an in-depth discussion of the challenges and countermeasures faced by each component of the detection framework. In addition, we comparatively analyze public datasets and outline the capability criteria to provide a reference for standardized evaluations. Finally, we discuss insights into potential areas for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700749},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on advanced persistent threat detection: A unified framework, challenges, and countermeasures},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic mapping study on quantum and quantum-inspired
algorithms in operations research. <em>CSUR</em>, <em>57</em>(3), 1–35.
(<a href="https://doi.org/10.1145/3700874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum and quantum-inspired algorithms have not yet been systematically classified in the context of potential Operations Research (OR) applications. Our systematic mapping is designed for quick consultation and shows which algorithms have been significantly explored in the context of OR, as well as which algorithms have been vaguely addressed in the same context. The study provides rapid access to OR professionals, both practitioners and researchers, who are interested in applying and/or further developing these algorithms in their respective contexts. We prepared a replicable protocol as a backbone of this systematic mapping study, specifying research questions, establishing effective search and selection methods, defining quality metrics for assessment, and guiding the analysis of the selected studies. A total of more than 2,000 studies were found, of which 149 were analyzed in detail. Readers can have an interactive hands-on experience with the collected data on an open-source repository with a website. An international standard was used as part of our classification, enabling professionals and researchers from across the world to readily identify which algorithms have been applied in any industry sector. Our effort also culminated in a rich set of takeaways that can help the reader identify potential paths for future work.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700874},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic mapping study on quantum and quantum-inspired algorithms in operations research},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cold start latency in serverless computing: A systematic
review, taxonomy, and future directions. <em>CSUR</em>, <em>57</em>(3),
1–36. (<a href="https://doi.org/10.1145/3700875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, academics and the corporate sector have paid attention to serverless computing, which enables dynamic scalability and an economic model. In serverless computing, users only pay for the time they actually use resources, enabling zero scaling to optimise cost and resource utilisation. However, this approach also introduces the serverless cold start problem. Researchers have developed various solutions to address the cold start problem, yet it remains an unresolved research area. In this article, we propose a systematic literature review on cold start latency in serverless computing. Furthermore, we create a detailed taxonomy of approaches to cold start latency, which we use to investigate existing techniques for reducing the cold start time and frequency. We have classified the current studies on cold start latency into several categories such as caching and application-level optimisation-based solutions, as well as Artificial Intelligence/Machine Learning-based solutions. Moreover, we have analyzed the impact of cold start latency on quality of service, explored current cold start latency mitigation methods, datasets, and implementation platforms, and classified them into categories based on their common characteristics and features. Finally, we outline the open challenges and highlight the possible future directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3700875},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Cold start latency in serverless computing: A systematic review, taxonomy, and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Backdoor attacks against voice recognition systems: A
survey. <em>CSUR</em>, <em>57</em>(3), 1–35. (<a
href="https://doi.org/10.1145/3701985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voice Recognition Systems (VRSs) employ deep learning for speech recognition and speaker recognition. They have been widely deployed in various real-world applications, from intelligent voice assistance to telephony surveillance and biometric authentication. However, prior research has revealed the vulnerability of VRSs to backdoor attacks, which pose a significant threat to the security and privacy of VRSs. Unfortunately, existing literature lacks a thorough review on this topic. This paper fills this research gap by conducting a comprehensive survey on backdoor attacks against VRSs. We first present an overview of VRSs and backdoor attacks, elucidating their basic knowledge. Then we propose a set of evaluation criteria to assess the performance of backdoor attack methods. Next, we present a comprehensive taxonomy of backdoor attacks against VRSs from different perspectives and analyze the characteristic of different categories. After that, we comprehensively review existing attack methods and analyze their pros and cons based on the proposed criteria. Furthermore, we review classic backdoor defense methods and generic audio defense techniques. Then we discuss the feasibility of deploying them on VRSs. Finally, we figure out several open issues and further suggest future research directions to motivate the research of VRSs security.},
  archive      = {J_CSUR},
  doi          = {10.1145/3701985},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Backdoor attacks against voice recognition systems: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey on adversarial attack and defense for medical image
analysis: Methods and challenges. <em>CSUR</em>, <em>57</em>(3), 1–38.
(<a href="https://doi.org/10.1145/3702638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning techniques have achieved superior performance in computer-aided medical image analysis, yet they are still vulnerable to imperceptible adversarial attacks, resulting in potential misdiagnosis in clinical practice. Oppositely, recent years have also witnessed remarkable progress in defense against these tailored adversarial examples in deep medical diagnosis systems. In this exposition, we present a comprehensive survey on recent advances in adversarial attacks and defenses for medical image analysis with a systematic taxonomy in terms of the application scenario. We also provide a unified framework for different types of adversarial attack and defense methods in the context of medical image analysis. For a fair comparison, we establish a new benchmark for adversarially robust medical diagnosis models obtained by adversarial training under various scenarios. To the best of our knowledge, this is the first survey article that provides a thorough evaluation of adversarially robust medical diagnosis models. By analyzing qualitative and quantitative results, we conclude this survey with a detailed discussion of current challenges for adversarial attack and defense in medical image analysis systems to shed light on future research directions. Code is available on GitHub .},
  archive      = {J_CSUR},
  doi          = {10.1145/3702638},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on adversarial attack and defense for medical image analysis: Methods and challenges},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on security of UAV swarm networks: Attacks and
countermeasures. <em>CSUR</em>, <em>57</em>(3), 1–37. (<a
href="https://doi.org/10.1145/3703625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing popularity of Unmanned Aerial Vehicle (UAV) swarms is attributed to their ability to generate substantial returns for various industries at a low cost. Additionally, in the future landscape of wireless networks, UAV swarms can serve as airborne base stations, alleviating the scarcity of communication resources. However, UAV swarm networks are vulnerable to various security threats that attackers can exploit with unpredictable consequences. Against this background, this article provides a comprehensive review on security of UAV swarm networks. We begin by briefly introducing the dominant UAV swarm technologies, followed by their civilian and military applications. We then present and categorize various potential attacks that UAV swarm networks may encounter, such as denial-of-service attacks, man-in-the-middle attacks, and attacks against Machine Learning (ML) models. After that, we introduce security technologies that can be utilized to address these attacks, including cryptography, physical layer security techniques, blockchain, ML, and intrusion detection. Additionally, we investigate and summarize mitigation strategies addressing different security threats in UAV swarm networks. Finally, some research directions and challenges are discussed.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703625},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {3},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on security of UAV swarm networks: Attacks and countermeasures},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancements in federated learning: Models, methods, and
privacy. <em>CSUR</em>, <em>57</em>(2), 1–39. (<a
href="https://doi.org/10.1145/3664650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a promising technique for resolving the rising privacy and security concerns. Its main ingredient is to cooperatively learn the model among the distributed clients without uploading any sensitive data. In this article, we conducted a thorough review of the related works, following the development context and deeply mining the key technologies behind FL from the perspectives of theory and application. Specifically, we first classify the existing works in FL architecture based on the network topology of FL systems with detailed analysis and summarization. Next, we abstract the current application problems, summarize the general techniques, and frame the application problems into the general paradigm of FL base models. Moreover, we provide our proposed solutions for model training via FL. We have summarized and analyzed the existing FedOpt algorithms, and deeply revealed the algorithmic development principles of many first-order algorithms in depth, proposing a more generalized algorithm design framework. With the instantiation of these frameworks, FedOpt algorithms can be simply developed. As privacy and security are the fundamental requirements in FL, we provide the existing attack scenarios and the defense methods. To the best of our knowledge, we are among the first tier to review the theoretical methodology and propose our strategies since there are very few works surveying the theoretical approaches. Our survey targets motivating the development of high-performance, privacy-preserving, and secure methods to integrate FL into real-world applications.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664650},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Advancements in federated learning: Models, methods, and privacy},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A practical tutorial on explainable AI techniques.
<em>CSUR</em>, <em>57</em>(2), 1–44. (<a
href="https://doi.org/10.1145/3670685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past years have been characterized by an upsurge in opaque automatic decision support systems, such as Deep Neural Networks (DNNs). Although DNNs have great generalization and prediction abilities, it is difficult to obtain detailed explanations for their behavior. As opaque Machine Learning models are increasingly being employed to make important predictions in critical domains, there is a danger of creating and using decisions that are not justifiable or legitimate. Therefore, there is a general agreement on the importance of endowing DNNs with explainability. EXplainable Artificial Intelligence (XAI) techniques can serve to verify and certify model outputs and enhance them with desirable notions such as trustworthiness, accountability, transparency, and fairness. This guide is intended to be the go-to handbook for anyone with a computer science background aiming to obtain an intuitive insight from Machine Learning models accompanied by explanations out-of-the-box. The article aims to rectify the lack of a practical XAI guide by applying XAI techniques, in particular, day-to-day models, datasets and use-cases. In each chapter, the reader will find a description of the proposed method as well as one or several examples of use with Python notebooks. These can be easily modified to be applied to specific applications. We also explain what the prerequisites are for using each technique, what the user will learn about them, and which tasks they are aimed at.},
  archive      = {J_CSUR},
  doi          = {10.1145/3670685},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-44},
  shortjournal = {ACM Comput. Surv.},
  title        = {A practical tutorial on explainable AI techniques},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of text watermarking in the era of large language
models. <em>CSUR</em>, <em>57</em>(2), 1–36. (<a
href="https://doi.org/10.1145/3691626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text watermarking algorithms are crucial for protecting the copyright of textual content. Historically, their capabilities and application scenarios were limited. However, recent advancements in large language models (LLMs) have revolutionized these techniques. LLMs not only enhance text watermarking algorithms with their advanced abilities but also create a need for employing these algorithms to protect their own copyrights or prevent potential misuse. This work conducts a comprehensive survey of the current state of text watermarking technology, covering four main aspects: (1) an overview and comparison of different text watermarking techniques; (2) evaluation methods for text watermarking algorithms, including their detectability, impact on text or LLM quality, and robustness under target or untargeted attacks; (3) potential application scenarios for text watermarking technology; and (4) current challenges and future directions for text watermarking. This survey aims to provide researchers with a thorough understanding of text watermarking technology in the era of LLMs, thereby promoting its further advancement.},
  archive      = {J_CSUR},
  doi          = {10.1145/3691626},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of text watermarking in the era of large language models},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approaches to conflict-free replicated data types.
<em>CSUR</em>, <em>57</em>(2), 1–36. (<a
href="https://doi.org/10.1145/3695249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conflict-free Replicated Data Types (CRDTs) allow optimistic replication in a principled way. Different replicas can proceed independently, being available even under network partitions and always converging deterministically: Replicas that have received the same updates will have equivalent state, even if received in different orders. After a historical tour of the evolution from sequential data types to CRDTs, we present in detail the two main approaches to CRDTs, operation-based and state-based, including two important variations, the pure operation-based and the delta-state based. Intended for prospective CRDT researchers and designers, this article provides solid coverage of the essential concepts, clarifying some misconceptions that frequently occur, but also presents some novel insights gained from considerable experience in designing both specific CRDTs and approaches to CRDTs.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695249},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Approaches to conflict-free replicated data types},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Alert prioritisation in security operations centres: A
systematic survey on criteria and methods. <em>CSUR</em>,
<em>57</em>(2), 1–36. (<a
href="https://doi.org/10.1145/3695462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security Operations Centres (SOCs) are specialised facilities where security analysts leverage advanced technologies to monitor, detect and respond to cyber incidents. However, the increasing volume of security incidents has overwhelmed security analysts, leading to alert fatigue. Effective alert prioritisation (AP) becomes crucial to address this problem through the utilisation of proper criteria and methods. Human–AI teaming (HAT) has the potential to significantly enhance AP by combining the complementary strengths of humans and AI. AI excels in processing large volumes of alert data, identifying anomalies, uncovering hidden patterns, and prioritising alerts at scale, all at machine speed. Human analysts can leverage their expertise to investigate prioritised alerts, re-prioritise them based on additional context and provide valuable feedback to the AI system, reducing false positives and ensuring critical alerts are prioritised. This work provides a comprehensive review of the criteria and methods for AP in SOC. We analyse the advantages and disadvantages of the different categories of AP criteria and methods based on HAT, specifically considering automation, augmentation and collaboration. We also identify several areas for future research. We anticipate that our findings will contribute to the advancement of AP techniques, fostering more effective security incident response in SOCs.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695462},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Alert prioritisation in security operations centres: A systematic survey on criteria and methods},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causal representation learning through higher-level
information extraction. <em>CSUR</em>, <em>57</em>(2), 1–37. (<a
href="https://doi.org/10.1145/3696412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large gap between the generalization level of state-of-the-art machine learning and human learning systems calls for the development of artificial intelligence (AI) models that are truly inspired by human cognition. In tasks related to image analysis, searching for pixel-level regularities has reached a power of information extraction still far from what humans capture with image-based observations. This leads to poor generalization when even small shifts occur at the level of the observations. We explore a perspective on this problem that is directed to learning the generative process with causality-related foundations, using models capable of combining symbolic manipulation, probabilistic reasoning, and pattern recognition abilities. We briefly review and explore connections of research from machine learning, cognitive science, and related fields of human behavior to support our perspective for the direction to more robust and human-like artificial learning systems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696412},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Causal representation learning through higher-level information extraction},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph and sequential neural networks in session-based
recommendation: A survey. <em>CSUR</em>, <em>57</em>(2), 1–37. (<a
href="https://doi.org/10.1145/3696413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the remarkable success of recommendation systems (RSs) in alleviating the information overload problem. As a new paradigm of RSs, session-based recommendation (SR) specializes in users’ short-term preferences and aims at providing a more dynamic and timely recommendation based on ongoing interactions. This survey presents a comprehensive overview of the recent works on SR. First, we clarify the key definitions within SR and compare the characteristics of SR against other recommendation tasks. Then, we summarize the existing methods in two categories: sequential neural network based methods and graph neural network (GNN) based methods. The relevant frameworks and technical details are further introduced. Finally, we discuss the challenges of SR and new research directions in this area.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696413},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Graph and sequential neural networks in session-based recommendation: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on video diffusion models. <em>CSUR</em>,
<em>57</em>(2), 1–42. (<a
href="https://doi.org/10.1145/3696415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent wave of AI-generated content (AIGC) has witnessed substantial success in computer vision, with the diffusion model playing a crucial role in this achievement. Due to their impressive generative capabilities, diffusion models are gradually superseding methods based on GANs and auto-regressive Transformers, demonstrating exceptional performance not only in image generation and editing, but also in the realm of video-related research. However, existing surveys mainly focus on diffusion models in the context of image generation, with few up-to-date reviews on their application in the video domain. To address this gap, this article presents a comprehensive review of video diffusion models in the AIGC era. Specifically, we begin with a concise introduction to the fundamentals and evolution of diffusion models. Subsequently, we present an overview of research on diffusion models in the video domain, categorizing the work into three key areas: video generation, video editing, and other video understanding tasks. We conduct a thorough review of the literature in these three key areas, including further categorization and practical contributions in the field. Finally, we discuss the challenges faced by research in this domain and outline potential future developmental trends. A comprehensive list of video diffusion models studied in this survey is available at https://github.com/ChenHsing/Awesome-Video-Diffusion-Models .},
  archive      = {J_CSUR},
  doi          = {10.1145/3696415},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on video diffusion models},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Challenges and opportunities in mobile network security for
vertical applications: A survey. <em>CSUR</em>, <em>57</em>(2), 1–36.
(<a href="https://doi.org/10.1145/3696446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the security of vertical applications in fifth-generation (5G) mobile communication systems and previous generations is crucial. These systems must prioritize maintaining the confidentiality, integrity, and availability of services and data. Examples of vertical applications include smart cities, smart transportation, public services, Industry 4.0, smart grids, smart health, and smart agriculture. Each vertical application has specific security requirements and faces unique threats within the mobile network environment. Thus, it is essential to implement comprehensive and robust security measures. This approach helps minimize the attack surface and effectively manage risks. This survey thoroughly examines mobile networks and their security challenges in vertical applications, shedding light on associated threats and potential solutions. Our study considers the interplay between security considerations in 5G, legacy networks, and vertical applications. We emphasize the challenges, opportunities, and promising directions for future research in this field and the importance of securing vertical applications in the evolving landscape of mobile technology.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696446},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Challenges and opportunities in mobile network security for vertical applications: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review of privacy policy literature.
<em>CSUR</em>, <em>57</em>(2), 1–43. (<a
href="https://doi.org/10.1145/3698393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An organization’s privacy policy states how it collects, stores, processes, and shares its users’ personal information. The growing number of data protection laws and regulations, as well as the numerous sectors where the organizations are collecting user information, has led to the investigation of privacy policies with regards to their accessibility, readability, completeness, comparison with organization’s actual data practices, use of machine learning/natural language processing for automated analysis, and comprehension/perception/concerns of end-users via summarization/visualization tools and user studies. However, there is limited work on systematically reviewing the existing research on this topic. We address this gap by conducting a systematic review of the existing privacy policy literature. To this end, we compiled and analyzed 202 papers (published till 31st December, 2023) that investigated privacy policies. Our work advances the field of privacy policies by summarizing the analysis techniques that have been used to study them, the data protection laws/regulations explored, and the sectors to which these policies pertain. We provide actionable insights for organizations to achieve better end-user privacy.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698393},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-43},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic review of privacy policy literature},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Empowering agrifood system with artificial intelligence: A
survey of the progress, challenges and opportunities. <em>CSUR</em>,
<em>57</em>(2), 1–37. (<a
href="https://doi.org/10.1145/3698589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the world population rapidly increasing, transforming our agrifood systems to be more productive, efficient, safe, and sustainable is crucial to mitigate potential food shortages. Recently, artificial intelligence (AI) techniques such as deep learning (DL) have demonstrated their strong abilities in various areas, including language, vision, remote sensing (RS), and agrifood systems applications. However, the overall impact of AI on agrifood systems remains unclear. In this article, we thoroughly review how AI techniques can transform agrifood systems and contribute to the modern agrifood industry. First, we summarize the data acquisition methods in agrifood systems, including acquisition, storage, and processing techniques. Second, we present a progress review of AI methods in agrifood systems, specifically in agriculture, animal husbandry, and fishery, covering topics such as agrifood classification, growth monitoring, yield prediction, and quality assessment. Furthermore, we highlight potential challenges and promising research opportunities for transforming modern agrifood systems with AI. We hope this survey can offer an overall picture to newcomers in the field and serve as a starting point for their further research. The project website is https://github.com/Frenkie14/Agrifood-Survey.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698589},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Empowering agrifood system with artificial intelligence: A survey of the progress, challenges and opportunities},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Co-clustering: A survey of the main methods, recent trends,
and open problems. <em>CSUR</em>, <em>57</em>(2), 1–33. (<a
href="https://doi.org/10.1145/3698875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since its early formulations, co-clustering has gained popularity and interest both within and outside the machine learning community as a powerful learning paradigm for clustering high-dimensional data with good explainability properties. The simultaneous partitioning of all the modes of the input data tensors (rows and columns in a data matrix) is both a method for improving clustering on one mode while performing dimensionality reduction on the other mode(s), and a tool for providing an actionable interpretation of the clusters in the main mode as summaries of the features in each other mode(s). Hence, it is useful in many complex decision systems and data science applications. In this article, we survey the the co-clustering literature by reviewing the main co-clustering methods, with a special focus on the work done in the past 25 years. We identify, describe, and compare the main algorithmic categories and provide a practical characterization with respect to similar unsupervised techniques. Additionally, we try to explain why it is still a powerful tool despite the apparent recent decreasing interest shown by the machine learning community. To this purpose, we review the most recent trends in co-clustering research and outline the open problems and promising future research perspectives.},
  archive      = {J_CSUR},
  doi          = {10.1145/3698875},
  journal      = {ACM Computing Surveys},
  month        = {11},
  number       = {2},
  pages        = {1-33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Co-clustering: A survey of the main methods, recent trends, and open problems},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A partial offline payment system for connecting the
unconnected using internet of things: A survey. <em>CSUR</em>,
<em>57</em>(2), 1–35. (<a
href="https://doi.org/10.1145/3687132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digital revolution in finance has bypassed many in rural areas due to limited access to technology and infrastructure. While real-time Internet banking is not feasible, a new approach is needed to create a secure, low-cost banking ecosystem for these unconnected populations. Existing offline payment mechanisms, prevalent in countries like India, offer some solutions but may still be expensive for rural communities. Researchers are exploring cost-effective solutions based on the Internet of Things (IoT). This study explores various IoT and non-IoT-based offline digital banking solutions to identify potential ways to provide digital payment options for the unconnected rural population.},
  archive      = {J_CSUR},
  doi          = {10.1145/3687132},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A partial offline payment system for connecting the unconnected using internet of things: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on deep learning for design and generation of
virtual architecture. <em>CSUR</em>, <em>57</em>(2), 1–41. (<a
href="https://doi.org/10.1145/3688569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) shape generation techniques leveraging deep learning have garnered significant interest from both computer vision and architectural design communities, promising to enrich the content in the virtual environment. However, research on virtual architectural design remains limited, particularly regarding designer-AI collaboration and deep learning-assisted design. In our survey, we reviewed 149 related articles (81.2% of articles published between 2019 and 2023) covering architectural design, 3D shape techniques, and virtual environments. Through scrutinizing the literature, we first identify the principles of virtual architecture and illuminate its current production challenges, including datasets, multimodality, design intuition, and generative frameworks. We then introduce the latest approaches to designing and generating virtual buildings leveraging 3D shape generation and summarize four characteristics of various approaches to virtual architecture. Based on our analysis, we expound on four research agendas, including agency, communication, user consideration, and integrating tools. Additionally, we highlight four important enablers of ubiquitous interaction with immersive systems in deep learning-assisted architectural generation. Our work contributes to fostering understanding between designers and deep learning techniques, broadening access to designer-AI collaboration. We advocate for interdisciplinary efforts to address this timely research topic, facilitating content designing and generation in the virtual environment.},
  archive      = {J_CSUR},
  doi          = {10.1145/3688569},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on deep learning for design and generation of virtual architecture},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image steganography approaches and their detection
strategies: A survey. <em>CSUR</em>, <em>57</em>(2), 1–40. (<a
href="https://doi.org/10.1145/3694965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steganography is the art and science of hidden (or covered) communication. In digital steganography, the bits of image, video, audio and text files are tweaked to represent the information to hide. This article covers the current methods for hiding information in images, alongside steganalysis methods that aim to detect the presence of steganography. By reviewing 456 references, this article discusses the different approaches that can be taken toward steganography and its much less widely studied counterpart. Currently in research older steganography approaches are more widely used than newer methods even though these show greater potential. New methods do have flaws; therefore, more research is needed to make these practically applicable. For steganalysis one of the greatest challenges is the generalisability. Often one scheme can detect the presence of one specific hiding method. More research is needed to combine current schemes and/or create new generalisable schemes. To allow readers to compare results between different papers in our work, performance indications of all steganalysis methods are outlined and a comparison of performance is included. This comparison is given using ‘topological sorting’ graphs, which compares detection results from all papers (as stated in the papers themselves) on different steganographic schemes.},
  archive      = {J_CSUR},
  doi          = {10.1145/3694965},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Image steganography approaches and their detection strategies: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of distributed graph algorithms on massive graphs.
<em>CSUR</em>, <em>57</em>(2), 1–39. (<a
href="https://doi.org/10.1145/3694966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed processing of large-scale graph data has many practical applications and has been widely studied. In recent years, a lot of distributed graph processing frameworks and algorithms have been proposed. While many efforts have been devoted to analyzing these, with most analyzing them based on programming models, less research focuses on understanding their challenges in distributed environments. Applying graph tasks to distributed environments is not easy, often facing numerous challenges through our analysis, including parallelism, load balancing, communication overhead, and bandwidth. In this article, we provide an extensive overview of the current state-of-the-art in this field by outlining the challenges and solutions of distributed graph algorithms. We first conduct a systematic analysis of the inherent challenges in distributed graph processing, followed by presenting an overview of existing general solutions. Subsequently, we survey the challenges highlighted in recent distributed graph processing papers and the strategies adopted to address them. Finally, we discuss the current research trends and identify potential future opportunities.},
  archive      = {J_CSUR},
  doi          = {10.1145/3694966},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of distributed graph algorithms on massive graphs},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time-sensitive networking (TSN) for industrial automation:
Current advances and future directions. <em>CSUR</em>, <em>57</em>(2),
1–38. (<a href="https://doi.org/10.1145/3695248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the introduction of Cyber-Physical Systems (CPS) and Internet of Things (IoT) technologies, the automation industry is undergoing significant changes, particularly in improving production efficiency and reducing maintenance costs. Industrial automation applications often need to transmit time- and safety-critical data to closely monitor and control industrial processes. Several Ethernet-based fieldbus solutions, such as PROFINET IRT, EtherNet/IP, and EtherCAT, are widely used to ensure real-time communications in industrial automation systems. These solutions, however, commonly incorporate additional mechanisms to provide latency guarantees, making their interoperability a grand challenge. The IEEE 802.1 Time-Sensitive Networking (TSN) task group was formed to enhance and optimize IEEE 802.1 network standards, particularly for Ethernet-based networks. These solutions can be evolved and adapted for cross-industry scenarios, such as large-scale distributed industrial plants requiring multiple industrial entities to work collaboratively. This paper provides a comprehensive review of current advances in TSN standards for industrial automation. It presents the state-of-the-art IEEE TSN standards and discusses the opportunities and challenges of integrating TSN into the automation industry. Some promising research directions are also highlighted for applying TSN technologies to industrial automation applications.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695248},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Time-sensitive networking (TSN) for industrial automation: Current advances and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal recommender systems: A survey. <em>CSUR</em>,
<em>57</em>(2), 1–17. (<a
href="https://doi.org/10.1145/3695461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recommender system (RS) has been an integral toolkit of online services. They are equipped with various deep learning techniques to model user preference based on identifier and attribute information. With the emergence of multimedia services, such as short videos, news, and and so on, understanding these contents while recommending becomes critical. Besides, multimodal features are also helpful in alleviating the problem of data sparsity in RS. Thus, M ultimodal R ecommender S ystem (MRS) has attracted much attention from both academia and industry recently. In this article, we will give a comprehensive survey of the MRS models, mainly from technical views. First, we conclude the general procedures and major challenges for MRS. Then, we introduce the existing MRS models according to four categories, i.e., Modality Encoder , Feature Interaction , Feature Enhancement , and Model Optimization . Besides, to make it convenient for those who want to research this field, we also summarize the dataset and code resources. Finally, we discuss some promising future directions of MRS and conclude this article. To access more details of the surveyed articles, such as implementation code, we open source a repository. 1},
  archive      = {J_CSUR},
  doi          = {10.1145/3695461},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-17},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multimodal recommender systems: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State of the art and potentialities of graph-level learning.
<em>CSUR</em>, <em>57</em>(2), 1–40. (<a
href="https://doi.org/10.1145/3695863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs have a superior ability to represent relational data, such as chemical compounds, proteins, and social networks. Hence, graph-level learning, which takes a set of graphs as input, has been applied to many tasks, including comparison, regression, classification, and more. Traditional approaches to learning a set of graphs heavily rely on hand-crafted features, such as substructures. While these methods benefit from good interpretability, they often suffer from computational bottlenecks, as they cannot skirt the graph isomorphism problem. Conversely, deep learning has helped graph-level learning adapt to the growing scale of graphs by extracting features automatically and encoding graphs into low-dimensional representations. As a result, these deep graph learning methods have been responsible for many successes. Yet, no comprehensive survey reviews graph-level learning starting with traditional learning and moving through to the deep learning approaches. This article fills this gap and frames the representative algorithms into a systematic taxonomy covering traditional learning, graph-level deep neural networks, graph-level graph neural networks, and graph pooling. In addition, the evolution and interaction between methods from these four branches within their developments are examined to provide an in-depth analysis. This is followed by a brief review of the benchmark datasets, evaluation metrics, and common downstream applications. Finally, the survey concludes with an in-depth discussion of 12 current and future directions in this booming field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695863},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {State of the art and potentialities of graph-level learning},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey on quality assurance of smart contracts.
<em>CSUR</em>, <em>57</em>(2), 1–36. (<a
href="https://doi.org/10.1145/3695864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As blockchain technology continues to advance, the secure deployment of smart contracts has become increasingly prevalent, underscoring the critical need for robust security measures. This surge in usage has led to a rise in security breaches, often resulting in substantial financial losses for users. This article presents a comprehensive survey of smart contract quality assurance, from understanding vulnerabilities to evaluating the effectiveness of detection tools. Our work is notable for its innovative classification of 40 smart contract vulnerabilities, mapping them to established attack patterns. We further examine nine defense mechanisms, assessing their efficacy in mitigating smart contract attacks. Furthermore, we develop a labeled dataset as a benchmark encompassing 10 common vulnerability types, which serves as a critical resource for future research. We also conduct comprehensive experiments to evaluate 14 vulnerability detection tools, providing a comparative analysis that highlights their strengths and limitations. In summary, this survey synthesizes state-of-the-art knowledge in smart contract security, offering practical recommendations to guide future research and foster the development of robust security practices in the field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695864},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on quality assurance of smart contracts},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of mix-based data augmentation: Taxonomy, methods,
applications, and explainability. <em>CSUR</em>, <em>57</em>(2), 1–38.
(<a href="https://doi.org/10.1145/3696206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation (DA) is indispensable in modern machine learning and deep neural networks. The basic idea of DA is to construct new training data to improve the model’s generalization by adding slightly disturbed versions of existing data or synthesizing new data. This survey comprehensively reviews a crucial subset of DA techniques, namely Mix-based Data Augmentation (MixDA), which generates novel samples by combining multiple examples. In contrast to traditional DA approaches that operate on single samples or entire datasets, MixDA stands out due to its effectiveness, simplicity, computational efficiency, theoretical foundation, and broad applicability. We begin by introducing a novel taxonomy that categorizes MixDA into Mixup-based, Cutmix-based, and mixture approaches based on a hierarchical perspective of the data mixing operation. Subsequently, we provide an in-depth review of various MixDA techniques, focusing on their underlying motivations. Owing to its versatility, MixDA has penetrated a wide range of applications, which we also thoroughly investigate in this survey. Moreover, we delve into the underlying mechanisms of MixDA’s effectiveness by examining its impact on model generalization and calibration while providing insights into the model’s behavior by analyzing the inherent properties of MixDA. Finally, we recapitulate the critical findings and fundamental challenges of current MixDA studies while outlining the potential directions for future works. Different from previous related surveys that focus on DA approaches in specific domains (e.g., computer vision and natural language processing) or only review a limited subset of MixDA studies, we are the first to provide a systematical survey of MixDA, covering its taxonomy, methodology, application, and explainability. Furthermore, we provide promising directions for researchers interested in this exciting area.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696206},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of mix-based data augmentation: Taxonomy, methods, applications, and explainability},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning for actionable warning identification: A
comprehensive survey. <em>CSUR</em>, <em>57</em>(2), 1–35. (<a
href="https://doi.org/10.1145/3696352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Actionable Warning Identification (AWI) plays a crucial role in improving the usability of static code analyzers. With recent advances in Machine Learning (ML), various approaches have been proposed to incorporate ML techniques into AWI. These ML-based AWI approaches, benefiting from ML’s strong ability to learn subtle and previously unseen patterns from historical data, have demonstrated superior performance. However, a comprehensive overview of these approaches is missing, which could hinder researchers and practitioners from understanding the current process and discovering potential for future improvement in the ML-based AWI community. In this article, we systematically review the state-of-the-art ML-based AWI approaches. First, we employ a meticulous survey methodology and gather 51 primary studies from January 1, 2000 to January 9, 2023. Then, we outline a typical ML-based AWI workflow, including warning dataset preparation, preprocessing, AWI model construction, and evaluation stages. In such a workflow, we categorize ML-based AWI approaches based on the warning output format. In addition, we analyze the key techniques used in each stage, along with their strengths, weaknesses, and distribution. Finally, we provide practical research directions for future ML-based AWI approaches, focusing on aspects such as data improvement (e.g., enhancing the warning labeling strategy) and model exploration (e.g., exploring large language models for AWI).},
  archive      = {J_CSUR},
  doi          = {10.1145/3696352},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Machine learning for actionable warning identification: A comprehensive survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review on graph neural network-based methods
for stock market forecasting. <em>CSUR</em>, <em>57</em>(2), 1–38. (<a
href="https://doi.org/10.1145/3696411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial technology (FinTech) is a field that uses artificial intelligence to automate financial services. One area of FinTech is stock analysis, which aims to predict future stock prices to develop investment strategies that maximize profits. Traditional methods of stock market prediction, such as time series analysis and machine learning, struggle to handle the non-linear, chaotic, and sudden changes in stock data and may not consider the interdependence between stocks. Recently, graph neural networks (GNNs) have been used in stock market forecasting to improve prediction accuracy by incorporating the interconnectedness of the market. GNNs can process non-Euclidean data in the form of a knowledge graph. However, financial knowledge graphs can have dynamic and complex interactions, which can be challenging for graph modeling technologies. This work presents a systematic review of graph-based approaches for stock market forecasting. This review covers different types of stock analysis tasks (classification, regression, and stock recommendation), a generalized framework for solving these tasks, and a review of various features, datasets, graph models, and evaluation metrics used in the stock market. The results of various studies are analyzed, and future directions for research are highlighted.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696411},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic review on graph neural network-based methods for stock market forecasting},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolving paradigms in automated program repair: Taxonomy,
challenges, and opportunities. <em>CSUR</em>, <em>57</em>(2), 1–43. (<a
href="https://doi.org/10.1145/3696450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development and large-scale popularity of program software, modern society increasingly relies on software systems. However, the problems exposed by software have also come to the fore. The software bug has become an important factor troubling developers. In this context, Automated Program Repair (APR) techniques have emerged, aiming to automatically fix software bug problems and reduce manual debugging work. In particular, benefiting from the advances in deep learning, numerous learning-based APR techniques have emerged in recent years, which also bring new opportunities for APR research. To give researchers a quick overview of APR techniques’ complete development and future opportunities, we review the evolution of APR techniques and discuss in depth the latest advances in APR research. In this article, the development of APR techniques is introduced in terms of four different patch generation schemes: search-based, constraint-based, template-based, and learning-based. Moreover, we propose a uniform set of criteria to review and compare each APR tool and then discuss the current state of APR development. Finally, we analyze current challenges and future directions, especially highlighting the critical opportunities that large language models bring to APR research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696450},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-43},
  shortjournal = {ACM Comput. Surv.},
  title        = {Evolving paradigms in automated program repair: Taxonomy, challenges, and opportunities},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatio-temporal predictive modeling techniques for different
domains: A survey. <em>CSUR</em>, <em>57</em>(2), 1–42. (<a
href="https://doi.org/10.1145/3696661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal prediction tasks play a crucial role in facilitating informed decision-making through anticipatory insights. By accurately predicting future outcomes, the ability to strategize, preemptively address risks, and minimize their potential impact is enhanced. The precision in forecasting spatial and temporal patterns holds significant potential for optimizing resource allocation, land utilization, and infrastructure development. While existing review and survey papers predominantly focus on specific forecasting domains such as intelligent transportation, urban planning, pandemics, disease prediction, climate and weather forecasting, environmental data prediction, and agricultural yield projection, limited attention has been devoted to comprehensive surveys encompassing multiple objects concurrently. This article addresses this gap by comprehensively analyzing techniques employed in traffic, pandemics, disease forecasting, climate and weather prediction, agricultural yield estimation, and environmental data prediction. Furthermore, it elucidates challenges inherent in spatio-temporal forecasting and outlines potential avenues for future research exploration.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696661},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Spatio-temporal predictive modeling techniques for different domains: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of protocol fuzzing. <em>CSUR</em>, <em>57</em>(2),
1–36. (<a href="https://doi.org/10.1145/3696788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication protocols form the bedrock of our interconnected world, yet vulnerabilities within their implementations pose significant security threats. Recent developments have seen a surge in fuzzing-based research dedicated to uncovering these vulnerabilities within protocol implementations. However, there still lacks a systematic overview of protocol fuzzing for answering the essential questions such as what the unique challenges are, how existing works solve them, and so on. To bridge this gap, we conducted a comprehensive investigation of related works from both academia and industry. Our study includes a detailed summary of the specific challenges in protocol fuzzing and provides a systematic categorization and overview of existing research efforts. Furthermore, we explore and discuss potential future research directions in protocol fuzzing.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696788},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {2},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of protocol fuzzing},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of 3D space path-planning methods and algorithms.
<em>CSUR</em>, <em>57</em>(1), 1–32. (<a
href="https://doi.org/10.1145/3673896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their agility, cost-effectiveness, and high maneuverability, Unmanned Aerial Vehicles (UAVs) have attracted considerable attention from researchers and investors alike. Path planning is one of the practical subsets of motion planning for UAVs. It prevents collisions and ensures complete coverage of an area. This study provides a structured review of applicable algorithms and coverage path planning solutions in Three-Dimensional (3D) space, presenting state-of-the-art technologies related to heuristic decomposition approaches for UAVs and the forefront challenges. Additionally, it introduces a comprehensive and novel classification of practical methods and representational techniques for path-planning algorithms. This depends on environmental characteristics and optimal parameters in the real world. The first category presents a classification of semi-accurate decomposition approaches as the most practical decomposition method, along with the data structure of these practices, categorized by phases. The second category illustrates path-planning processes based on symbolic techniques in 3D space. Additionally, it provides a critical analysis of crucial influential approaches based on their importance in path quality and researchers’ attention, highlighting their limitations and research gaps. Furthermore, it will provide the most pertinent recommendations for future work for researchers. The studies demonstrate an apparent inclination among experimenters toward using the semi-accurate cellular decomposition approach to improve 3D path planning.},
  archive      = {J_CSUR},
  doi          = {10.1145/3673896},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of 3D space path-planning methods and algorithms},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Manipulating recommender systems: A survey of poisoning
attacks and countermeasures. <em>CSUR</em>, <em>57</em>(1), 1–39. (<a
href="https://doi.org/10.1145/3677328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have become an integral part of online services due to their ability to help users locate specific information in a sea of data. However, existing studies show that some recommender systems are vulnerable to poisoning attacks, particularly those that involve learning schemes. A poisoning attack is where an adversary injects carefully crafted data into the process of training a model with the goal of manipulating the system’s final recommendations. Based on recent advancements in artificial intelligence (AI), such attacks have gained importance recently. At present, we do not have a full and clear picture of why adversaries mount such attacks, nor do we have comprehensive knowledge of the full capacity to which such attacks can undermine a model or the impacts that might have. While numerous countermeasures to poisoning attacks have been developed, they have not yet been systematically linked to the properties of the attacks. Consequently, assessing the respective risks and potential success of mitigation strategies is difficult, if not impossible. This survey aims to fill this gap by primarily focusing on poisoning attacks and their countermeasures. This is in contrast to prior surveys that mainly focus on attacks and their detection methods. Through an exhaustive literature review, we provide a novel taxonomy for poisoning attacks, formalise its dimensions, and accordingly organise 31 attacks described in the literature. Further, we review 43 countermeasures to detect and/or prevent poisoning attacks, evaluating their effectiveness against specific types of attacks. This comprehensive survey should serve as a point of reference for protecting recommender systems against poisoning attacks. The article concludes with a discussion on open issues in the field and impactful directions for future research. A rich repository of resources associated with poisoning attacks is available at https://github.com/tamlhp/awesome-recsys-poisoning .},
  archive      = {J_CSUR},
  doi          = {10.1145/3677328},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Manipulating recommender systems: A survey of poisoning attacks and countermeasures},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enabling technologies and techniques for floor
identification. <em>CSUR</em>, <em>57</em>(1), 1–48. (<a
href="https://doi.org/10.1145/3678878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location information has initiated a multitude of applications such as location-based services, health care, emergency response and rescue operations, and assets tracking. A plethora of techniques and technologies have been presented to ensure enhanced location accuracy, both horizontal and vertical. Despite many surveys covering horizontal localization technologies, the literature lacks a comprehensive survey incorporating up-to-date vertical localization approaches. This article provides a detailed survey of different vertical localization techniques such as path loss models, time of arrival, received signal strength, reference signal received power, fingerprinting utilized by WiFi, radio-frequency identification (RFID), global system for mobile communications (GSM), long-term evolution (LTE), barometer, inertial measurement unit (IMU) sensors, and geomagnetic field. The article primarily aims at human localization in indoor environments using smartphones in essence. Besides the localization accuracy, the presented approaches are evaluated in terms of cost, infrastructure dependence, deployment complexity, and sensitivity. We highlight the pros and cons of these approaches and outline future research directions to enhance the accuracy to meet the future needs of floor identification standards set by the Federal Communications Commission.},
  archive      = {J_CSUR},
  doi          = {10.1145/3678878},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-48},
  shortjournal = {ACM Comput. Surv.},
  title        = {Enabling technologies and techniques for floor identification},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How to improve video analytics with action recognition: A
survey. <em>CSUR</em>, <em>57</em>(1), 1–36. (<a
href="https://doi.org/10.1145/3679011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition refers to the process of categorizing a video by identifying and classifying the specific actions it encompasses. Videos originate from several domains, and within each domain of video analysis, comprehending actions holds paramount significance. The primary aim of this research is to assist scholars in understanding, comparing, and using action recognition models within the several fields of video analysis. This article provides a comprehensive analysis of action recognition models, comparing their performance and computational requirements. Additionally, it presents a detailed overview of benchmark datasets, which can aid in selecting the most suitable action recognition model. This review additionally examines the diverse applications of action recognition, the datasets available, the research that has been undertaken, potential future prospects, and the challenges encountered.},
  archive      = {J_CSUR},
  doi          = {10.1145/3679011},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {How to improve video analytics with action recognition: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on federated unlearning: Challenges, methods, and
future directions. <em>CSUR</em>, <em>57</em>(1), 1–38. (<a
href="https://doi.org/10.1145/3679014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the notion of “the right to be forgotten” (RTBF) has become a crucial aspect of data privacy for digital trust and AI safety, requiring the provision of mechanisms that support the removal of personal data of individuals upon their requests. Consequently, machine unlearning (MU) has gained considerable attention which allows an ML model to selectively eliminate identifiable information. Evolving from MU, federated unlearning (FU) has emerged to confront the challenge of data erasure within federated learning (FL) settings, which empowers the FL model to unlearn an FL client or identifiable information pertaining to the client. Nevertheless, the distinctive attributes of federated learning introduce specific challenges for FU techniques. These challenges necessitate a tailored design when developing FU algorithms. While various concepts and numerous federated unlearning schemes exist in this field, the unified workflow and tailored design of FU are not yet well understood. Therefore, this comprehensive survey delves into the techniques and methodologies in FU providing an overview of fundamental concepts and principles, evaluating existing federated unlearning algorithms, and reviewing optimizations tailored to federated learning. Additionally, it discusses practical applications and assesses their limitations. Finally, it outlines promising directions for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3679014},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on federated unlearning: Challenges, methods, and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on edge data integrity verification:
Fundamentals and future trends. <em>CSUR</em>, <em>57</em>(1), 1–34. (<a
href="https://doi.org/10.1145/3680277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in edge computing (EC) have pushed cloud-based data caching services to edge; however, such emerging edge storage comes with numerous challenging and unique security issues. One of them is the problem of edge data integrity verification (EDIV), which coordinates multiple participants (e.g., data owners and edge nodes) to inspect whether data cached on edge is authentic. To date, various solutions have been proposed to address the EDIV problem, while there is no systematic review. Thus, we offer a comprehensive survey for the first time, aiming to show current research status, open problems, and potentially promising insights for readers to further investigate this under-explored field. Specifically, we begin by stating the significance of the EDIV problem, the integrity verification difference between data cached on cloud and edge, and three typical system models with corresponding inspection processes. To thoroughly assess prior research efforts, we synthesize a universal criteria framework that an effective verification approach should satisfy. On top of it, a schematic development timeline is developed to reveal the research advance on EDIV in a sequential manner, followed by a detailed review of the existing EDIV solutions. Finally, we highlight intriguing research challenges and possible directions for future work, along with a discussion on how forthcoming technology, e.g., machine learning and context-aware security, can augment security in EC. Given our findings, some major observations are: there is a noticeable trend to equip EDIV solutions with various functions and diversify study scenarios; completing EDIV within two types of participants (i.e., data owner and edge nodes) is garnering escalating interest among researchers; although the majority of existing methods rely on cryptography, emerging technology is being explored to handle the EDIV problem.},
  archive      = {J_CSUR},
  doi          = {10.1145/3680277},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on edge data integrity verification: Fundamentals and future trends},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An interdisciplinary survey on origin-destination flows
modeling: Theory and techniques. <em>CSUR</em>, <em>57</em>(1), 1–49.
(<a href="https://doi.org/10.1145/3682058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Origin-destination (OD) flow modeling is an extensively researched subject across multiple disciplines, such as the investigation of travel demand in transportation and spatial interaction modeling in geography. However, researchers from different fields tend to employ their own unique research paradigms and lack interdisciplinary communication, preventing the cross-fertilization of knowledge and the development of novel solutions to challenges. This article presents a systematic interdisciplinary survey that comprehensively and holistically scrutinizes OD flows from utilizing fundamental theory to studying the mechanism of population mobility and solving practical problems with engineering techniques, such as computational models. Specifically, regional economics, urban geography, and sociophysics are adept at employing theoretical research methods to explore the underlying mechanisms of OD flows. They have developed three influential theoretical models: the gravity model, the intervening opportunities model, and the radiation model. These models specifically focus on examining the fundamental influences of distance, opportunities, and population on OD flows, respectively. In the meantime, fields such as transportation, urban planning, and computer science primarily focus on addressing four practical problems: OD prediction, OD construction, OD estimation, and OD forecasting. Advanced computational models, such as deep learning models, have gradually been introduced to address these problems more effectively. We have constructed the benchmarks for these four problems at https://github.com/tsinghua-fib-lab/OD_benckmark. Finally, based on the existing research, this survey summarizes current challenges and outlines future directions for this topic. Through this survey, we aim to break down the barriers between disciplines in OD flow related research, fostering interdisciplinary perspectives and modes of thinking.},
  archive      = {J_CSUR},
  doi          = {10.1145/3682058},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-49},
  shortjournal = {ACM Comput. Surv.},
  title        = {An interdisciplinary survey on origin-destination flows modeling: Theory and techniques},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review on the use of physiological signals for assessing
postoperative pain. <em>CSUR</em>, <em>57</em>(1), 1–39. (<a
href="https://doi.org/10.1145/3685674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of pain intensity after surgery is important for guiding pain management. Due to the limitations of current pain evaluation tools, there is increasing interest in using objective methods to assess pain in clinical settings. This literature review aims to provide an overview of physiological methods for postoperative pain evaluation. The Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA) guidelines were followed to perform a literature search on the Scopus database from 2002 to March 2024. Sixty-one studies were included in this review investigating parameters derived from six physiological signals, including Electrocardiogram (ECG), Photoplethysmogram (PPG), Skin Conductance (SC), Electroencephalogram (EEG), Electromyogram (EMG), and pupil size and reflexes. Parameters extracted from ECG, PPG, and SC signals were the most commonly studied. While there is evidence to support the use of physiological parameters as measures for postoperative pain evaluation, further research is needed to establish the reliability and generalizability of these parameters to develop an indicator that can be consistently applied across various clinical settings. For this purpose, this review describes current research findings and identifies limitations and directions for future work that should be considered in upcoming research on postoperative pain assessment.},
  archive      = {J_CSUR},
  doi          = {10.1145/3685674},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review on the use of physiological signals for assessing postoperative pain},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Digital food sensing and ingredient analysis techniques to
facilitate human-food interface designs. <em>CSUR</em>, <em>57</em>(1),
1–39. (<a href="https://doi.org/10.1145/3685675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive technologies that shape the traditional human-food experiences are being explored under the emerging field of Human-Food Interaction (HFI). A key challenge in developing HFI technologies is the digital sensing of food, beverages, and their ingredients, commonly known as digital food sensing. Digital food sensing involves recognizing different food and beverages and their internal attributes, such as volume and ingredients (e.g., salt and sugar content). Contemporary research on interactive food applications, such as dietary assessment, primarily employs Computer Vision (CV) techniques to identify food; however, they are ineffective when (1) identifying food’s internal attributes, (2) discriminating visually similar food and beverages, and (3) seamlessly integrating with people’s natural interactions while consuming food. Thus, this article reviews potential food and beverage sensing technologies that can facilitate novel Human-Food Interfaces, primarily focusing on non-disruptive sensing techniques to analyze food and beverages during consumption. First, we review ten different digital food sensing techniques and their applications in four categories. Then, we discuss three main aspects to consider when adopting these food-sensing techniques for human-food interface designs. Finally, we suggest the future research requirements in digital food sensing methodologies, followed by potential applications of digital food sensing in future developments of Human-Food Interfaces.},
  archive      = {J_CSUR},
  doi          = {10.1145/3685675},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Digital food sensing and ingredient analysis techniques to facilitate human-food interface designs},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). COVID-19 modeling: A review. <em>CSUR</em>, <em>57</em>(1),
1–42. (<a href="https://doi.org/10.1145/3686150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The SARS-CoV-2 viruses and their triggered COVID-19 pandemic have fundamentally reshaped the world in almost every aspect, their evolution and influences remain. While over a million of literature have been produced on these unprecedented, overwhelming global disaster, one critical question is open: How has COVID-19 been quantified globally? This further inspires many other questions: What COVID-19 problems have been modeled? How have modeling methods in areas such as epidemiology, artificial intelligence (AI), data science, machine learning, deep learning, mathematics and social science played their roles in characterizing COVID-19? Where are the gaps and issues of these COVID-19 modeling studies? What are the lessons for quantifying future disasters? Answering these questions involves the analysis of a very broad spectrum of literature across different disciplines and domains. Distinguishing from specific efforts, this review takes the first attempt to generate a systematic, structured and contrastive landscape and taxonomy of global COVID-19 modeling. First, the surveyed problems span over a full range of COVID-19, including epidemic transmission processes, case identification and tracing, infection diagnosis and medical treatments, non-pharmaceutical interventions and their influence, drug and vaccine development, psychological, economic and social influence and impact, and misinformation, and so on. Second, the reviewed modeling methods traverse all relevant disciplines, from statistic modeling to epidemic modeling, medical analysis, biomedical analysis, AI, deep and machine learning, analytics, and simulation. Critical analyses further identify significant issues and gaps, for example, simple techniques and similar problems have been overwhelmingly addressed everywhere, while intrinsic and foundational issues and deep insights have been overlooked. The review discloses significant opportunities for more deeply, effectively and uniquely quantifying COVID-19-like global disasters from their intrinsic working mechanisms, interactions and dynamics.},
  archive      = {J_CSUR},
  doi          = {10.1145/3686150},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {COVID-19 modeling: A review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey on federated learning for intrusion detection system:
Concept, architectures, aggregation strategies, challenges, and future
directions. <em>CSUR</em>, <em>57</em>(1), 1–38. (<a
href="https://doi.org/10.1145/3687124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion Detection Systems (IDS) are essential for securing computer networks by identifying and mitigating potential threats. However, traditional IDS face challenges related to scalability, privacy, and computational demands as network data complexity increases. Federated Learning (FL) has emerged as a promising solution, enabling collaborative model training on decentralized data sources while preserving data privacy. Each participant retains local data repositories, ensuring data sovereignty and precluding data sharing. Leveraging the FL framework, participants locally train machine learning models on their respective datasets, subsequently transmitting model updates to a central server for aggregation. The central server then disseminates the aggregated model updates to individual participants, collectively striving to bolster intrusion detection capabilities. This article presents a comprehensive survey of FL applications in IDS, covering core concepts, architectural approaches, and aggregation strategies. We evaluate the strengths and limitations of various FL methodologies for IDS, addressing privacy and security concerns and exploring privacy-preserving techniques and security protocols. Our examination of aggregation strategies within the FL framework for IDS aims to highlight their effectiveness, limitations, and potential enhancements.},
  archive      = {J_CSUR},
  doi          = {10.1145/3687124},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on federated learning for intrusion detection system: Concept, architectures, aggregation strategies, challenges, and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Presentation attack detection: A systematic literature
review. <em>CSUR</em>, <em>57</em>(1), 1–32. (<a
href="https://doi.org/10.1145/3687264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identity authentication is the process of verifying one’s identity. Many identity authentication methods have been developed, from the conventional username-password systems to the recent electroencephalography-based authentication. Among them, biometric authentication shows particular importance due to its convenience and wide application in real-world scenarios. Face recognition is one of the most widely used biometric authentication methods, but simultaneously it receives various attacks. To overcome attacks, face presentation attack detection has been intensively studied in the last two decades regarding diverse domains of datasets, evaluation methods, and attack types. In this systematic literature review, we identify and categorise the state-of-the-art approaches in each domain to cover the challenges and solutions in a single place. We provide comparisons of representative methods on widely used datasets, discuss their pros and cons, and hope our insights can inspire future works.},
  archive      = {J_CSUR},
  doi          = {10.1145/3687264},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Presentation attack detection: A systematic literature review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic literature review on the influence of enhanced
developer experience on developers’ productivity: Factors, practices,
and recommendations. <em>CSUR</em>, <em>57</em>(1), 1–46. (<a
href="https://doi.org/10.1145/3687299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context and Motivation – Developer eXperience (Dev-X) is a recent research area that focuses on developers perceptions, feelings, and values with respect to software development and software quality. Research suggests that factors and practices related to Dev-X can have a substantial impact on developer productivity (Dev-P). However, despite a large and diverse body of literature on factors that can impact Dev-P in general, there is no coherent and comprehensive characterization of how Dev-X-specific insights can influence developer productivity. Aims – In the presented research, we aim to provide a coherent, comprehensive characterization of factors and practices related to Dev-X, with a particular focus on those factors and practices that potentially affect Dev-P. Method – To this end, we performed a systematic literature review and identified 218 relevant papers in this area. We characterize the papers based on the related frameworks and concepts common to Dev-X and Dev-P as presented in the existing literature. Dev-X factors such as “work fragmentation” and practices such as “collaboration with owner-developer” are identified using a grounded-in-the-literature, content-analysis method, guided by the theory. For each Dev-X factor, we identify attributes that might be used to assess/ measure the current status (of an organization or project) regarding that factor and how that factor and its effects on productivity have been evidenced in the literature (mentioned vs. considered in questionnaires vs. substantiated with a more positivist evaluation). Results – We identify 33 Dev-X-related factors and 41 Dev-X-related practices, which are organized into 10 themes to summarize their influence. The results suggest that the availability of required resources, relevant expertise re the allocated tasks, and fewer interruptions are among the top positively impacting factors. Conversely, factors such as code complexity, heterogeneous contexts of tasks, and non-adherence to standardization harm Dev-X and Dev-P. Top industrial practices employed to mitigate the negative influence of factors include characterization-based task assignments, mental model support, and the timely evolution of technologies. Conclusions – Overall, this research suggests that organizations can influence Dev-P through improved Dev-X, incorporating suitable practices to mediate relevant factors in their context. Important in this regard are practices such as fragmenting large tasks, highlighting the utility of proposed tasks/changes to the developers, and promoting (developer) ownership of artefacts. Finally, our results point to areas where further research seems appropriate, i.e., where Dev-X factors/practices have been proposed as being impactful on Dev-P but not yet fully substantiated or explored as such (factors like “Nature of Activity” and practices like choosing practices/protocols appropriately).},
  archive      = {J_CSUR},
  doi          = {10.1145/3687299},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-46},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review on the influence of enhanced developer experience on developers&#39; productivity: Factors, practices, and recommendations},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MITRE ATT&amp;CK: State of the art and way forward.
<em>CSUR</em>, <em>57</em>(1), 1–37. (<a
href="https://doi.org/10.1145/3687300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MITRE ATT&amp;CK is a comprehensive framework of adversary tactics, techniques, and procedures based on real-world observations. It has been used as a foundation for threat modeling in different sectors, such as government, academia, and industry. To the best of our knowledge, no previous work has been devoted to the comprehensive collection, study, and investigation of the current state of the art leveraging the MITRE ATT&amp;CK framework. We select and inspect more than 50 major research contributions, while conducting a detailed analysis of their methodology and objectives in relation to the MITRE ATT&amp;CK framework. We provide a categorization of the identified papers according to different criteria such as use cases, application scenarios, adopted methodologies, and the use of additional data. Finally, we discuss open issues and future research directions involving not only the MITRE ATT&amp;CK framework but also the fields of threat analysis, threat modeling, and in general cyber-threat intelligence.},
  archive      = {J_CSUR},
  doi          = {10.1145/3687300},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {MITRE ATT&amp;CK: State of the art and way forward},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data mesh: A systematic gray literature review.
<em>CSUR</em>, <em>57</em>(1), 1–36. (<a
href="https://doi.org/10.1145/3687301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data mesh is an emerging domain-driven decentralized data architecture that aims to minimize or avoid operational bottlenecks associated with centralized, monolithic data architectures in enterprises. The topic has piqued the practitioners’ interest, and considerable gray literature exists. At the same time, we observe a lack of academic attempts at defining and building upon the concept. Hence, in this article, we aim to start from the foundations and characterize the data mesh architecture regarding its design principles, architectural components, capabilities, and organizational roles. We systematically collected, analyzed, and synthesized 114 industrial gray literature articles. The resulting review provides insights into practitioners’ perspectives on the four key principles of data mesh: data as a product, domain ownership of data, self-serve data platform, and federated computational governance. Moreover, due to the comparability of data mesh and SOA (service-oriented architecture), we mapped the findings from the gray literature into the reference architectures from the SOA academic literature to create the reference architectures for describing three key dimensions of data mesh: organization of capabilities and roles, development, and runtime. Finally, we discuss open research issues in data mesh, partially based on the findings from the gray literature.},
  archive      = {J_CSUR},
  doi          = {10.1145/3687301},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Data mesh: A systematic gray literature review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physics-informed computer vision: A review and perspectives.
<em>CSUR</em>, <em>57</em>(1), 1–38. (<a
href="https://doi.org/10.1145/3689037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incorporation of physical information in machine learning frameworks is opening and transforming many application domains. Here the learning process is augmented through the induction of fundamental knowledge and governing physical laws. In this work, we explore their utility for computer vision tasks in interpreting and understanding visual data. We present a systematic literature review of more than 250 papers on formulation and approaches to computer vision tasks guided by physical laws. We begin by decomposing the popular computer vision pipeline into a taxonomy of stages and investigate approaches to incorporate governing physical equations in each stage. Existing approaches are analyzed in terms of modeling and formulation of governing physical processes, including modifying input data (observation bias), network architectures (inductive bias), and training losses (learning bias). The taxonomy offers a unified view of the application of the physics-informed capability, highlighting where physics-informed learning has been conducted and where the gaps and opportunities are. Finally, we highlight open problems and challenges to inform future research. While still in its early days, the study of physics-informed computer vision has the promise to develop better computer vision models that can improve physical plausibility, accuracy, data efficiency, and generalization in increasingly realistic applications.},
  archive      = {J_CSUR},
  doi          = {10.1145/3689037},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Physics-informed computer vision: A review and perspectives},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Competence awareness for humans and machines: A survey and
future research directions from psychology. <em>CSUR</em>,
<em>57</em>(1), 1–26. (<a
href="https://doi.org/10.1145/3689626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning researchers are beginning to understand the need for machines to be able to self-assess their competence and express it in a human understandable form. However, current machine learning algorithms do not yet have the range or complexity of competence awareness measures present in humans. This review first describes progress towards competence awareness in machines, and then examines the psychology literature on competence awareness and competence motivation to identify the limitations of current competence awareness algorithms. The article concludes with a discussion of the necessary and promising future research directions for creating competence-aware machines.},
  archive      = {J_CSUR},
  doi          = {10.1145/3689626},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-26},
  shortjournal = {ACM Comput. Surv.},
  title        = {Competence awareness for humans and machines: A survey and future research directions from psychology},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-class imbalanced data handling with concept drift in
fog computing: A taxonomy, review, and future directions. <em>CSUR</em>,
<em>57</em>(1), 1–48. (<a
href="https://doi.org/10.1145/3689627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A network of actual physical objects or “IoT components” linked to the internet and equipped with sensors, electronics, software, and network connectivity is known as the Internet of Things (IoT). This ability of the IoT components to gather and share data is made possible by this network connectivity. Many IoT devices are currently operating, which generate a lot of data. When these IoT devices started collecting data, the cloud was the only place to analyze, filter, pre-process, and aggregate it. However, when it comes to IoT, the cloud has restrictions regarding latency and a more centralized method of distributing programs. A new form of computing called Fog computing has been proposed to address the shortcomings of current cloud computing. In an IoT context, sensors regularly communicate signal information, and edge devices process the data obtained from these sensors using Fog computing. The sensors’ internal or external problems, security breaches, or the integration of heterogeneous equipment contribute to the imbalanced data, i.e., comparatively speaking, one class has more instances than the other. As a result of this data, the pattern extraction is imbalanced . Recent attempts have concentrated heavily on binary-class imbalanced concerns with exactly two classes. However, the classification of multi-class imbalanced data is an issue that needs to be fixed in Fog computing, even if it is widespread in other fields, including text categorization, human activity detection, and medical diagnosis. The study intends to deal with this problem. It presents a systematic, thorough, and in-depth comparative analysis of several binary-class and multi-class imbalanced data handling strategies for batch and streaming data in IoT networks and Fog computing. There are five major objectives in this study. First, reviewing the Fog computing concept. Second, outlining the optimization metric used in Fog computing. Third, focusing on binary and multi-class batch data handling for IoT networks and Fog computing. Fourth, reviewing and comparing the current imbalanced data handling methodologies for multi-class data streams. Fifth, explaining how to cope with the concept drift, including novel and recurring classes, targeted optimization measures, and evaluation tools. Finally, the best performance metrics and tools for concept drift, binary-class (batch and stream) data, and multi-class (batch and stream) data are highlighted.},
  archive      = {J_CSUR},
  doi          = {10.1145/3689627},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-48},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multi-class imbalanced data handling with concept drift in fog computing: A taxonomy, review, and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for time series anomaly detection: A survey.
<em>CSUR</em>, <em>57</em>(1), 1–42. (<a
href="https://doi.org/10.1145/3691338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is important for a wide range of research fields and applications, including financial markets, economics, earth sciences, manufacturing, and healthcare. The presence of anomalies can indicate novel or unexpected events, such as production faults, system defects, and heart palpitations, and is therefore of particular interest. The large size and complexity of patterns in time series data have led researchers to develop specialised deep learning models for detecting anomalous patterns. This survey provides a structured and comprehensive overview of state-of-the-art deep learning for time series anomaly detection. It provides a taxonomy based on anomaly detection strategies and deep learning models. Aside from describing the basic anomaly detection techniques in each category, their advantages and limitations are also discussed. Furthermore, this study includes examples of deep anomaly detection in time series across various application domains in recent years. Finally, it summarises open issues in research and challenges faced while adopting deep anomaly detection models to time series data.},
  archive      = {J_CSUR},
  doi          = {10.1145/3691338},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for time series anomaly detection: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on stability of learning with limited labelled data
and its sensitivity to the effects of randomness. <em>CSUR</em>,
<em>57</em>(1), 1–40. (<a
href="https://doi.org/10.1145/3691339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning with limited labelled data, such as prompting, in-context learning, fine-tuning, meta-learning, or few-shot learning, aims to effectively train a model using only a small amount of labelled samples. However, these approaches have been observed to be excessively sensitive to the effects of uncontrolled randomness caused by non-determinism in the training process. The randomness negatively affects the stability of the models, leading to large variances in results across training runs. When such sensitivity is disregarded, it can unintentionally, but unfortunately also intentionally, create an imaginary perception of research progress. Recently, this area started to attract research attention and the number of relevant studies is continuously growing. In this survey, we provide a comprehensive overview of 415 papers addressing the effects of randomness on the stability of learning with limited labelled data. We distinguish between four main tasks addressed in the papers (investigate/evaluate, determine, mitigate, benchmark/compare/report randomness effects), providing findings for each one. Furthermore, we identify and discuss seven challenges and open problems together with possible directions to facilitate further research. The ultimate goal of this survey is to emphasise the importance of this growing research area, which so far has not received an appropriate level of attention, and reveal impactful directions for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3691339},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on stability of learning with limited labelled data and its sensitivity to the effects of randomness},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ransomware reloaded: Re-examining its trend, research and
mitigation in the era of data exfiltration. <em>CSUR</em>,
<em>57</em>(1), 1–40. (<a
href="https://doi.org/10.1145/3691340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ransomware has grown to be a dominant cybersecurity threat by exfiltrating, encrypting, or destroying valuable user data and causing numerous disruptions to victims. The severity of the ransomware endemic has generated research interest from both the academia and the industry. However, many studies held stereotypical assumptions about ransomware, used unverified, outdated, and limited self-collected ransomware samples, and did not consider government strategies, industry guidelines, or cyber intelligence. We observed that ransomware no longer exists simply as an executable file or limits to encrypting files (data loss); data exfiltration (data breach) is the new norm, espionage is an emerging theme, and the industry is shifting focus from technical advancements to cyber governance and resilience. We created a ransomware innovation adoption curve, critically evaluated 212 academic studies published during 2020 and 2023, and cross-verified them against various government strategies, industry reports, and cyber intelligence on ransomware. We concluded that many studies were becoming irrelevant to the contemporary ransomware reality and called for the redirection of ransomware research to align with the continuous ransomware evolution in the industry. We proposed to address data exfiltration as priority over data encryption, to consider ransomware in a business-practical manner, and recommended research collaboration with the industry.},
  archive      = {J_CSUR},
  doi          = {10.1145/3691340},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Ransomware reloaded: Re-examining its trend, research and mitigation in the era of data exfiltration},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Eco-friendly route planning algorithms: Taxonomies,
literature review and future directions. <em>CSUR</em>, <em>57</em>(1),
1–42. (<a href="https://doi.org/10.1145/3691624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eco-friendly navigation (a.k.a. eco-routing) finds a route from A to B in a road network that minimizes the greenhouse gas (GHG) emission or fuel/energy consumption of the traveling vehicle. As road transport is a major contributor to GHG emissions, eco-routing has received considerable research attention in the past decade, mainly on two research themes: (1) developing models to estimate emissions or fuel/energy consumption of vehicles; and (2) developing algorithms to find eco-friendly routes for a vehicle. There are some excellent literature reviews that cover the existing estimation models. However, there is no literature review on eco-friendly route-planning algorithms. This article fills this gap and provides a systematic literature review in this area. From mainstream online databases, we obtained 2,494 articles and shortlisted 76 articles using our exclusion criteria. Accordingly, we establish a holistic view of eco-routing systems and define five taxonomies of estimation models, eco-routing problems and algorithms, vehicle types, traffic, and road network characteristics. Concerning the taxonomies, we categorize and review the shortlisted articles. Finally, we highlight research challenges and outline future directions in this important area.},
  archive      = {J_CSUR},
  doi          = {10.1145/3691624},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Eco-friendly route planning algorithms: Taxonomies, literature review and future directions},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adversarial attacks and countermeasures on image
classification-based deep learning models in autonomous driving systems:
A systematic review. <em>CSUR</em>, <em>57</em>(1), 1–52. (<a
href="https://doi.org/10.1145/3691625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of artificial intelligence (AI) and breakthroughs in Internet of Things (IoT) technologies have driven the innovation of advanced autonomous driving systems (ADSs). Image classification deep learning (DL) algorithms immensely contribute to the decision-making process in ADSs, showcasing their capabilities in handling complex real-world driving scenarios, surpassing human driving intelligence. However, these algorithms are vulnerable to adversarial attacks, which aim to fool them in real-time decision-making and compromise the reliability of the autonomous driving functions. This systematic review offers a comprehensive overview of the most recent literature on adversarial attacks and countermeasures on image classification DL models in ADSs. The review highlights the current challenges in applying successful countermeasures to mitigating these vulnerabilities. We also introduce taxonomies for categorizing adversarial attacks and countermeasures and provide recommendations and guidelines to help researchers design and evaluate countermeasures. We suggest interesting future research directions to improve the robustness of image classification DL models against adversarial attacks in autonomous driving scenarios.},
  archive      = {J_CSUR},
  doi          = {10.1145/3691625},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-52},
  shortjournal = {ACM Comput. Surv.},
  title        = {Adversarial attacks and countermeasures on image classification-based deep learning models in autonomous driving systems: A systematic review},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vulnerabilities and security patches detection in OSS: A
survey. <em>CSUR</em>, <em>57</em>(1), 1–37. (<a
href="https://doi.org/10.1145/3694782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, Open Source Software (OSS) has experienced rapid growth and widespread adoption, attributed to its openness and editability. However, this expansion has also brought significant security challenges, particularly introducing and propagating software vulnerabilities. Despite the use of machine learning and formal methods to tackle these issues, there remains a notable gap in comprehensive surveys that summarize and analyze both Vulnerability Detection (VD) and Security Patch Detection (SPD) in OSS. This article seeks to bridge this gap through an extensive survey that evaluates 127 technical studies published between 2014 and 2023, structured around the Vulnerability-Patch lifecycle. We begin by delineating the six critical events that constitute the Vulnerability-Patch lifecycle, leading to an in-depth exploration of the Vulnerability-Patch ecosystem. We then systematically review the databases commonly used in VD and SPD, and analyze their characteristics. Subsequently, we examine existing VD methods, focusing on traditional and deep learning based approaches. Additionally, we organize current security patch identification methods by kernel type and discuss techniques for detecting the presence of security patches. Based on our comprehensive review, we identify open research questions and propose future research directions that merit further exploration.},
  archive      = {J_CSUR},
  doi          = {10.1145/3694782},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Vulnerabilities and security patches detection in OSS: A survey},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of techniques for ageing detection and monitoring
on embedded systems. <em>CSUR</em>, <em>57</em>(1), 1–34. (<a
href="https://doi.org/10.1145/3695247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedded digital devices are progressively deployed in dependable or safety-critical systems. These devices undergo significant hardware ageing, particularly in harsh environments. This increases their likelihood of failure. It is crucial to understand ageing processes and to detect hardware degradation early for guaranteeing system dependability. In this survey, we review the core ageing mechanisms, and identify and categorize general working principles of ageing detection and monitoring techniques for Commercial-Off-the-Shelf (COTS) components that are prevalent in embedded systems: Field Programmable Gate Arrays (FPGAs), microcontrollers, Systems-on-Chips (SoCs), and their power supplies. From our review, we find that online techniques are more widely applied on FPGAs than on other components, and see a rising trend towards machine learning application for analysing hardware ageing. Based on the reviewed literature, we identify research opportunities and potential directions of interest in the field. With this work, we intend to facilitate future research by systematically presenting all main approaches in a concise way.},
  archive      = {J_CSUR},
  doi          = {10.1145/3695247},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {1},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review of techniques for ageing detection and monitoring on embedded systems},
  volume       = {57},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale simulation of complex systems: A perspective of
integrating knowledge and data. <em>CSUR</em>, <em>56</em>(12), 1–38.
(<a href="https://doi.org/10.1145/3654662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex system simulation has been playing an irreplaceable role in understanding, predicting, and controlling diverse complex systems. In the past few decades, the multi-scale simulation technique has drawn increasing attention for its remarkable ability to overcome the challenges of complex system simulation with unknown mechanisms and expensive computational costs. In this survey, we will systematically review the literature on multi-scale simulation of complex systems from the perspective of knowledge and data. First, we will present background knowledge about simulating complex systems and the scales in complex systems. Then, we divide the main objectives of multi-scale modeling and simulation into five categories by considering scenarios with clear scale and scenarios with unclear scale, respectively. After summarizing the general methods for multi-scale simulation based on the clues of knowledge and data, we introduce the adopted methods to achieve different objectives. Finally, we introduce the applications of multi-scale simulation in typical matter systems and social systems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3654662},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multi-scale simulation of complex systems: A perspective of integrating knowledge and data},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for table detection and structure recognition:
A survey. <em>CSUR</em>, <em>56</em>(12), 1–41. (<a
href="https://doi.org/10.1145/3657281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tables are everywhere, from scientific journals, articles, websites, and newspapers all the way to items we buy at the supermarket. Detecting them is thus of utmost importance to automatically understanding the content of a document. The performance of table detection has substantially increased thanks to the rapid development of deep learning networks. The goals of this survey are to provide a profound comprehension of the major developments in the field of Table Detection, offer insight into the different methodologies, and provide a systematic taxonomy of the different approaches. Furthermore, we provide an analysis of both classic and new applications in the field. Lastly, the datasets and source code of the existing models are organized to provide the reader with a compass on this vast literature. Finally, we go over the architecture of utilizing various object detection and table structure recognition methods to create an effective and efficient system, as well as a set of development trends to keep up with state-of-the-art algorithms and future research. We have also set up a public GitHub repository where we will be updating the most recent publications, open data, and source code. The GitHub repository is available at https://github.com/abdoelsayed2016/table-detection-structure-recognition.},
  archive      = {J_CSUR},
  doi          = {10.1145/3657281},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for table detection and structure recognition: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Qualitative approaches to voice UX. <em>CSUR</em>,
<em>56</em>(12), 1–34. (<a
href="https://doi.org/10.1145/3658666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voice is a natural mode of expression offered by modern computer-based systems. Qualitative perspectives on voice-based user experiences (voice UX) offer rich descriptions of complex interactions that numbers alone cannot fully represent. We conducted a systematic review of the literature on qualitative approaches to voice UX, capturing the nature of this body of work in a systematic map and offering a qualitative synthesis of findings. We highlight the benefits of qualitative methods for voice UX research, identify opportunities for increasing rigour in methods and outcomes, and distill patterns of experience across a diversity of devices and modes of qualitative praxis.},
  archive      = {J_CSUR},
  doi          = {10.1145/3658666},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Qualitative approaches to voice UX},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mix-zones as an effective privacy enhancing technique in
mobile and vehicular ad-hoc networks. <em>CSUR</em>, <em>56</em>(12),
1–33. (<a href="https://doi.org/10.1145/3659576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent Transportation Systems (ITS) promise significant increases in throughput and reductions in trip delay. ITS makes extensive use of Connected and Autonomous Vehicles (CAV) frequently broadcasting location, speed, and intention information. However, with such extensive communication comes the risk to privacy. Preserving privacy while still exchanging vehicle state information has been recognized as an important problem. Mix zones have emerged as a potentially effective way of protecting user privacy in ITS. CAVs are assigned pseudonyms to mask their identity; a mix zone is an area where CAVs can change their pseudonyms to resist being tracked. In order to be effective, mix zone placement must take account of traffic flows. Also, since a mix zone can degrade throughput, mix zones must be used sparingly. Determining the number and placement of mix zones is a difficult dynamic optimization problem. This paper outlines the various approaches recently taken by researchers to deal with this problem.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659576},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Mix-zones as an effective privacy enhancing technique in mobile and vehicular ad-hoc networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on resilience in information sharing on networks:
Taxonomy and applied techniques. <em>CSUR</em>, <em>56</em>(12), 1–36.
(<a href="https://doi.org/10.1145/3659944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information sharing is vital in any communication network environment to enable network operating services take decisions based on the information collected by several deployed computing devices. The various networks that compose cyberspace, as Internet-of-Things (IoT) ecosystems, have significantly increased the need to constantly share information, which is often subject to disturbances. In this sense, the damage of anomalous operations boosted researches aimed at improving resilience to information sharing. Hence, in this survey, we present a systematization of knowledge about scientific efforts for achieving resilience to information sharing on networks. First, we introduce a taxonomy to organize the strategies applied to attain resilience to information sharing on networks, offering brief concepts about network anomalies and connectivity services. Then, we detail the taxonomy in the face of malicious threats, network disruptions, and performance issues, discussing the presented solutions. Next, we analyze the techniques existing in the literature to foster resilience to information exchanged on communication networks to verify their benefits and constraints. Throughout the text, we highlight and argue issues that restrain the use of these techniques during the design and runtime.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659944},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on resilience in information sharing on networks: Taxonomy and applied techniques},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A meta-study of software-change intentions. <em>CSUR</em>,
<em>56</em>(12), 1–41. (<a
href="https://doi.org/10.1145/3661484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every software system undergoes changes, for example, to add new features, fix bugs, or refactor code. The importance of understanding software changes has been widely recognized, resulting in various techniques and studies, for instance, on change-impact analysis or classifying developers’ activities. Since changes are triggered by developers’ intentions—something they plan or want to change in the system—many researchers have studied intentions behind changes. While there appears to be a consensus among software-engineering researchers and practitioners that knowing the intentions behind software changes is important, it is not clear how developers can actually benefit from this knowledge. In fact, there is no consolidated, recent overview of the state of the art on software-change intentions (SCIs) and their relevance for software engineering. We present a meta-study of 122 publications, which we used to derive a categorization of SCIs and to discuss motivations, evidence, and techniques relating to SCIs. Unfortunately, we found that individual pieces of research are often disconnected from each other, because a common understanding is missing. Similarly, some publications showcase the potential of knowing SCIs, but more substantial research to understand the practical benefits of knowing SCIs is needed. Our contributions can help researchers and practitioners improve their understanding of SCIs and how SCIs can aid software engineering tasks.},
  archive      = {J_CSUR},
  doi          = {10.1145/3661484},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A meta-study of software-change intentions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NLOS identification and mitigation for time-based indoor
localization systems: Survey and future research directions.
<em>CSUR</em>, <em>56</em>(12), 1–41. (<a
href="https://doi.org/10.1145/3663473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One hurdle to accurate indoor localization using time-based networks is the presence of Non-Line-Of-Sight (NLOS) and multipath signals, affecting the accuracy of ranging in indoor environments. NLOS identification and mitigation have been studied over the years and applied to different time-based networks, with most works considering NLOS links with WiFi and UWB channels. In this article, we discuss the effects and challenges of NLOS conditions on indoor localization and present current state-of-the-art approaches to NLOS identification and mitigation in literature. We survey these approaches and classify them under different categories together with their merits and demerits. We further categorize approaches to tackle NLOS effects into single and hybrid measurement-based approaches in this work. Lessons learnt from the survey with future directions are also presented in this article.},
  archive      = {J_CSUR},
  doi          = {10.1145/3663473},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {NLOS identification and mitigation for time-based indoor localization systems: Survey and future research directions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Natural language reasoning, a survey. <em>CSUR</em>,
<em>56</em>(12), 1–39. (<a
href="https://doi.org/10.1145/3664194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey article proposes a clearer view of Natural Language Reasoning (NLR) in the field of Natural Language Processing (NLP) , both conceptually and practically. Conceptually, we provide a distinct definition for NLR in NLP, based on both philosophy and NLP scenarios; discuss what types of tasks require reasoning; and introduce a taxonomy of reasoning. Practically, we conduct a comprehensive literature review on NLR in NLP, mainly covering classical logical reasoning, Natural Language Inference (NLI) , multi-hop question answering, and commonsense reasoning. The article also identifies and views backward reasoning, a powerful paradigm for multi-step reasoning, and introduces defeasible reasoning as one of the most important future directions in NLR research. We focus on single-modality unstructured natural language text, excluding neuro-symbolic research and mathematical reasoning. 1},
  archive      = {J_CSUR},
  doi          = {10.1145/3664194},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Natural language reasoning, a survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An overview of privacy-enhancing technologies in biometric
recognition. <em>CSUR</em>, <em>56</em>(12), 1–28. (<a
href="https://doi.org/10.1145/3664596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy-enhancing technologies are technologies that implement fundamental data protection principles. With respect to biometric recognition, different types of privacy-enhancing technologies have been introduced for protecting stored biometric data, which are generally classified as sensitive. In this regard, various taxonomies and conceptual categorizations have been proposed and standardisation activities have been carried out. However, these efforts have mainly been devoted to certain sub-categories of privacy-enhancing technologies and therefore lack generalization. This work provides an overview of concepts of privacy-enhancing technologies for biometric recognition in a unified framework. Key properties and differences between existing concepts are highlighted in detail at each processing step. Fundamental characteristics and limitations of existing technologies are discussed and related to data protection techniques and principles. Moreover, scenarios and methods for the assessment of privacy-enhancing technologies for biometric recognition are presented. This article is meant as a point of entry to the field of data protection for biometric recognition applications and is directed toward experienced researchers as well as non-experts.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664596},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-28},
  shortjournal = {ACM Comput. Surv.},
  title        = {An overview of privacy-enhancing technologies in biometric recognition},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for code intelligence: Survey, benchmark and
toolkit. <em>CSUR</em>, <em>56</em>(12), 1–41. (<a
href="https://doi.org/10.1145/3664597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code intelligence leverages machine learning techniques to extract knowledge from extensive code corpora, with the aim of developing intelligent tools to improve the quality and productivity of computer programming. Currently, there is already a thriving research community focusing on code intelligence, with efforts ranging from software engineering, machine learning, data mining, natural language processing, and programming languages. In this paper, we conduct a comprehensive literature review on deep learning for code intelligence, from the aspects of code representation learning, deep learning techniques, and application tasks. We also benchmark several state-of-the-art neural models for code intelligence, and provide an open-source toolkit tailored for the rapid prototyping of deep-learning-based code intelligence models. In particular, we inspect the existing code intelligence models under the basis of code representation learning, and provide a comprehensive overview to enhance comprehension of the present state of code intelligence. Furthermore, we publicly release the source code and data resources to provide the community with a ready-to-use benchmark, which can facilitate the evaluation and comparison of existing and future code intelligence models (https://xcodemind.github.io). At last, we also point out several challenging and promising directions for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664597},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for code intelligence: Survey, benchmark and toolkit},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified review of deep learning for automated medical
coding. <em>CSUR</em>, <em>56</em>(12), 1–41. (<a
href="https://doi.org/10.1145/3664615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated medical coding, an essential task for healthcare operation and delivery, makes unstructured data manageable by predicting medical codes from clinical documents. Recent advances in deep learning and natural language processing have been widely applied to this task. However, deep learning–based medical coding lacks a unified view of the design of neural network architectures. This review proposes a unified framework to provide a general understanding of the building blocks of medical coding models and summarizes recent advanced models under the proposed framework. Our unified framework decomposes medical coding into four main components, i.e., encoder modules for text feature extraction, mechanisms for building deep encoder architectures, decoder modules for transforming hidden representations into medical codes, and the usage of auxiliary information. Finally, we introduce the benchmarks and real-world usage and discuss key research challenges and future directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664615},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A unified review of deep learning for automated medical coding},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of hardware improvements to secure program
execution. <em>CSUR</em>, <em>56</em>(12), 1–37. (<a
href="https://doi.org/10.1145/3672392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hardware has been constantly augmented for security considerations since the advent of computers. There is also a common perception among computer users that hardware does a relatively better job on security assurance compared with software. Yet, the community has long lacked a comprehensive study to answer questions such as how hardware security support contributes to security, what kind of improvements have been introduced to improve such support and what its advantages/disadvantages are. By generalizing various security goals, we taxonomize hardware security features and their security properties that can aid in securing program execution, considered as three aspects, i.e., state correctness, runtime protection and input/output protection. Based on this taxonomy, the survey systematically examines (1) the roles: how hardware is applied to achieve security; and (2) the problems: how reported attacks have exploited certain defects in hardware. We see that hardware’s unique advantages and problems co-exist and it highly depends on the desired security purpose as to which type to use. Among the survey findings are also that code as part of hardware (aka. firmware) should be treated differently to ensure security by design; and how research proposals have driven the advancement of commodity hardware features.},
  archive      = {J_CSUR},
  doi          = {10.1145/3672392},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of hardware improvements to secure program execution},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on biclustering-based collaborative
filtering. <em>CSUR</em>, <em>56</em>(12), 1–32. (<a
href="https://doi.org/10.1145/3674723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative Filtering (CF) is achieving a plateau of high popularity. Still, recommendation success is challenged by the diversity of user preferences, structural sparsity of user-item ratings, and inherent subjectivity of rating scales. The increasing user base and item dimensionality of e-commerce and e-entertainment platforms creates opportunities, while further raising generalization and scalability needs. Moved by the need to answer these challenges, user-based and item-based clustering approaches for CF became pervasive. However, classic clustering approaches assess user (item) rating similarity across all items (users), neglecting the rich diversity of item and user profiles. Instead, as preferences are generally simultaneously correlated on subsets of users and items, biclustering approaches provide a natural alternative, being successfully applied to CF for nearly two decades and synergistically integrated with emerging deep learning CF stances. Notwithstanding, biclustering-based CF principles are dispersed, causing state-of-the-art approaches to show accentuated behavioral differences. This work offers a structured view on how biclustering aspects impact recommendation success, coverage, and efficiency. To this end, we introduce a taxonomy to categorize contributions in this field and comprehensively survey state-of-the-art biclustering approaches to CF, highlighting their limitations and potentialities.},
  archive      = {J_CSUR},
  doi          = {10.1145/3674723},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on biclustering-based collaborative filtering},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). SoK: Fully homomorphic encryption accelerators.
<em>CSUR</em>, <em>56</em>(12), 1–32. (<a
href="https://doi.org/10.1145/3676955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully Homomorphic Encryption (FHE) is a key technology enabling privacy-preserving computing. However, the fundamental challenge of FHE is its inefficiency, due primarily to the underlying polynomial computations with high computation complexity and extremely time-consuming ciphertext maintenance operations. To tackle this challenge, various FHE accelerators have recently been proposed by both research and industrial communities. This article takes the first initiative to conduct a systematic study on the 14 FHE accelerators: cuHE/cuFHE, nuFHE, HEAT, HEAX, HEXL, HEXL-FPGA, 100×, F1, CraterLake, BTS, ARK, Poseidon, FAB, and TensorFHE. We first make our observations on the evolution trajectory of these existing FHE accelerators to establish a qualitative connection between them. Then, we perform testbed evaluations of representative open-source FHE accelerators to provide a quantitative comparison on them. Finally, with the insights learned from both qualitative and quantitative studies, we discuss potential directions to inform the future design and implementation for FHE accelerators.},
  archive      = {J_CSUR},
  doi          = {10.1145/3676955},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {SoK: Fully homomorphic encryption accelerators},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An overview of FPGA-inspired obfuscation techniques.
<em>CSUR</em>, <em>56</em>(12), 1–35. (<a
href="https://doi.org/10.1145/3677118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building and maintaining a silicon foundry is a costly endeavor that requires substantial financial investment. From this scenario, the semiconductor business has largely shifted to a fabless model where the Integrated Circuit (IC) supply chain is globalized but potentially untrusted. In recent years, several hardware obfuscation techniques have emerged to thwart hardware security threats related to untrusted IC fabrication. Reconfigurable-based obfuscation schemes have shown great promise of security against state-of-the-art attacks—these are techniques that rely on the transformation of static logic configurable elements such as Look Up Tables (LUTs). This survey provides a comprehensive analysis of reconfigurable-based obfuscation techniques, evaluating their overheads and enumerating their effectiveness against all known attacks. The techniques are also classified based on different factors, including the technology used, element type, and IP type. Additionally, we present a discussion on the advantages of reconfigurable-based obfuscation techniques when compared to Logic Locking techniques and the challenges associated with evaluating these techniques on hardware, primarily due to the lack of tapeouts. The survey’s findings are essential for researchers interested in hardware obfuscation and future trends in this area.},
  archive      = {J_CSUR},
  doi          = {10.1145/3677118},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {An overview of FPGA-inspired obfuscation techniques},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counterfactual explanations and algorithmic recourses for
machine learning: A review. <em>CSUR</em>, <em>56</em>(12), 1–42. (<a
href="https://doi.org/10.1145/3677119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning plays a role in many deployed decision systems, often in ways that are difficult or impossible to understand by human stakeholders. Explaining, in a human-understandable way, the relationship between the input and output of machine learning models is essential to the development of trustworthy machine learning based systems. A burgeoning body of research seeks to define the goals and methods of explainability in machine learning. In this article, we seek to review and categorize research on counterfactual explanations , a specific class of explanation that provides a link between what could have happened had input to a model been changed in a particular way. Modern approaches to counterfactual explainability in machine learning draw connections to the established legal doctrine in many countries, making them appealing to fielded systems in high-impact areas such as finance and healthcare. Thus, we design a rubric with desirable properties of counterfactual explanation algorithms and comprehensively evaluate all currently proposed algorithms against that rubric. Our rubric provides easy comparison and comprehension of the advantages and disadvantages of different approaches and serves as an introduction to major research themes in this field. We also identify gaps and discuss promising research directions in the space of counterfactual explainability.},
  archive      = {J_CSUR},
  doi          = {10.1145/3677119},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Counterfactual explanations and algorithmic recourses for machine learning: A review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-based depth estimation methods from monocular
image and videos: A comprehensive survey. <em>CSUR</em>,
<em>56</em>(12), 1–51. (<a
href="https://doi.org/10.1145/3677327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating depth from single RGB images and videos is of widespread interest due to its applications in many areas, including autonomous driving, 3D reconstruction, digital entertainment, and robotics. More than 500 deep learning-based papers have been published in the past 10 years, which indicates the growing interest in the task. This paper presents a comprehensive survey of the existing deep learning-based methods, the challenges they address, and how they have evolved in their architecture and supervision methods. It provides a taxonomy for classifying the current work based on their input and output modalities, network architectures, and learning methods. It also discusses the major milestones in the history of monocular depth estimation, and different pipelines, datasets, and evaluation metrics used in existing methods.},
  archive      = {J_CSUR},
  doi          = {10.1145/3677327},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-51},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning-based depth estimation methods from monocular image and videos: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive analysis of explainable AI for malware
hunting. <em>CSUR</em>, <em>56</em>(12), 1–40. (<a
href="https://doi.org/10.1145/3677374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decade, the number of malware variants has increased rapidly. Many researchers have proposed to detect malware using intelligent techniques, such as Machine Learning (ML) and Deep Learning (DL), which have high accuracy and precision. These methods, however, suffer from being opaque in the decision-making process. Therefore, we need Artificial Intelligence (AI)-based models to be explainable, interpretable, and transparent to be reliable and trustworthy. In this survey, we reviewed articles related to Explainable AI (XAI) and their application to the significant scope of malware detection. The article encompasses a comprehensive examination of various XAI algorithms employed in malware analysis. Moreover, we have addressed the characteristics, challenges, and requirements in malware analysis that cannot be accommodated by standard XAI methods. We discussed that even though Explainable Malware Detection (EMD) models provide explainability, they make an AI-based model more vulnerable to adversarial attacks. We also propose a framework that assigns a level of explainability to each XAI malware analysis model, based on the security features involved in each method. In summary, the proposed project focuses on combining XAI and malware analysis to apply XAI models for scrutinizing the opaque nature of AI systems and their applications to malware analysis.},
  archive      = {J_CSUR},
  doi          = {10.1145/3677374},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive analysis of explainable AI for malware hunting},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Video unsupervised domain adaptation with deep learning: A
comprehensive survey. <em>CSUR</em>, <em>56</em>(12), 1–36. (<a
href="https://doi.org/10.1145/3679010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video analysis tasks such as action recognition have received increasing research interest with growing applications in fields such as smart healthcare, thanks to the introduction of large-scale datasets and deep learning based representations. However, video models trained on existing datasets suffer from significant performance degradation when deployed directly to real-world applications due to domain shifts between the training public video datasets (source video domains) and real-world videos (target video domains). Further, with the high cost of video annotation, it is more practical to use unlabeled videos for training. To tackle performance degradation and address concerns in high video annotation cost uniformly, video unsupervised domain adaptation (VUDA) is introduced to adapt video models from the labeled source domain to the unlabeled target domain by alleviating video domain shift, improving the generalizability and portability of video models. This article surveys recent progress in VUDA with deep learning. We begin with the motivation of VUDA, followed by its definition, and recent progress of methods for both closed-set VUDA and VUDA under different scenarios, and current benchmark datasets for VUDA research. Eventually, future directions are provided to promote further VUDA research. The repository of this survey is provided at https://github.com/xuyu0010/awesome-video-domain-adaptation .},
  archive      = {J_CSUR},
  doi          = {10.1145/3679010},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Video unsupervised domain adaptation with deep learning: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review and benchmark of feature importance methods for
neural networks. <em>CSUR</em>, <em>56</em>(12), 1–30. (<a
href="https://doi.org/10.1145/3679012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature attribution methods (AMs) are a simple means to provide explanations for the predictions of black-box models such as neural networks. Due to their conceptual differences, the numerous different methods, however, yield ambiguous explanations. While this allows for obtaining different insights into the model, it also complicates the decision regarding which method to adopt. This article summarizes the current state of the art regarding AMs, which includes the requirements and desiderata of the methods themselves as well as the properties of their explanations. Based on a survey of existing methods, a representative subset consisting of the δ-sensitivity index, permutation feature importance, variance-based feature importance in artificial neural networks and DeepSHAP, is described in greater detail and, for the first time, benchmarked in a regression context. Specifically for this purpose, a new verification strategy for model-specific AMs is proposed. As expected, the explanations’ agreement with the intuition and among each other clearly depends on the AMs’ properties. This has two implications. First, careful reasoning about the selection of an AM is required. Second, it is recommended to apply multiple AMs and combine their insights in order to reduce the model’s opacity even further.},
  archive      = {J_CSUR},
  doi          = {10.1145/3679012},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-30},
  shortjournal = {ACM Comput. Surv.},
  title        = {A review and benchmark of feature importance methods for neural networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). When federated learning meets privacy-preserving
computation. <em>CSUR</em>, <em>56</em>(12), 1–36. (<a
href="https://doi.org/10.1145/3679013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, with the development of artificial intelligence (AI), privacy issues attract wide attention from society and individuals. It is desirable to make the data available but invisible, i.e., to realize data analysis and calculation without disclosing the data to unauthorized entities. Federated learning (FL) has emerged as a promising privacy-preserving computation method for AI. However, new privacy issues have arisen in FL-based application, because various inference attacks can still infer relevant information about the raw data from local models or gradients. This will directly lead to the privacy disclosure. Therefore, it is critical to resist these attacks to achieve complete privacy-preserving computation. In light of the overwhelming variety and a multitude of privacy-preserving computation protocols, we survey these protocols from a series of perspectives to supply better comprehension for researchers and scholars. Concretely, the classification of attacks is discussed, including four kinds of inference attacks as well as malicious server and poisoning attack. Besides, this article systematically captures the state-of-the-art of privacy-preserving computation protocols by analyzing the design rationale, reproducing the experiment of classic schemes, and evaluating all discussed protocols in terms of efficiency and security properties. Finally, this survey identifies a number of interesting future directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3679013},
  journal      = {ACM Computing Surveys},
  month        = {10},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {When federated learning meets privacy-preserving computation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual tuning. <em>CSUR</em>, <em>56</em>(12), 1–38. (<a
href="https://doi.org/10.1145/3657632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-tuning visual models has been widely shown promising performance on many downstream visual tasks. With the surprising development of pre-trained visual foundation models, visual tuning jumped out of the standard modus operandi that fine-tunes the whole pre-trained model or just the fully connected layer. Instead, recent advances can achieve superior performance than full-tuning the whole pre-trained parameters by updating far fewer parameters, enabling edge devices and downstream applications to reuse the increasingly large foundation models deployed on the cloud. With the aim of helping researchers get the full picture and future directions of visual tuning, this survey characterizes a large and thoughtful selection of recent works, providing a systematic and comprehensive overview of existing work and models. Specifically, it provides a detailed background of visual tuning and categorizes recent visual tuning techniques into five groups: fine-tuning, prompt tuning, adapter tuning, parameter tuning, and remapping tuning. Meanwhile, it offers some exciting research directions for prospective pre-training and various interactions in visual tuning.},
  archive      = {J_CSUR},
  doi          = {10.1145/3657632},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Visual tuning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-learning approaches for few-shot learning: A survey of
recent advances. <em>CSUR</em>, <em>56</em>(12), 1–41. (<a
href="https://doi.org/10.1145/3659943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite its astounding success in learning deeper multi-dimensional data, the performance of deep learning declines on new unseen tasks mainly due to its focus on same-distribution prediction. Moreover, deep learning is notorious for poor generalization from few samples. Meta-learning is a promising approach that addresses these issues by adapting to new tasks with few-shot datasets. This survey first briefly introduces meta-learning and then investigates state-of-the-art meta-learning methods and recent advances in: (i) metric-based, (ii) memory-based, (iii), and learning-based methods. Finally, current challenges and insights for future researches are discussed.},
  archive      = {J_CSUR},
  doi          = {10.1145/3659943},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Meta-learning approaches for few-shot learning: A survey of recent advances},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-task learning in natural language processing: An
overview. <em>CSUR</em>, <em>56</em>(12), 1–32. (<a
href="https://doi.org/10.1145/3663363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning approaches have achieved great success in the field of Natural Language Processing (NLP). However, directly training deep neural models often suffer from overfitting and data scarcity problems that are pervasive in NLP tasks. In recent years, Multi-Task Learning (MTL), which can leverage useful information of related tasks to achieve simultaneous performance improvement on these tasks, has been used to handle these problems. In this article, we give an overview of the use of MTL in NLP tasks. We first review MTL architectures used in NLP tasks and categorize them into four classes, including parallel architecture, hierarchical architecture, modular architecture, and generative adversarial architecture. Then we present optimization techniques on loss construction, gradient regularization, data sampling, and task scheduling to properly train a multi-task model. After presenting applications of MTL in a variety of NLP tasks, we introduce some benchmark datasets. Finally, we make a conclusion and discuss several possible research directions in this field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3663363},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multi-task learning in natural language processing: An overview},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recent advances for aerial object detection: A survey.
<em>CSUR</em>, <em>56</em>(12), 1–36. (<a
href="https://doi.org/10.1145/3664598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aerial object detection, as object detection in aerial images captured from an overhead perspective, has been widely applied in urban management, industrial inspection, and other aspects. However, the performance of existing aerial object detection algorithms is hindered by variations in object scales and orientations attributed to the aerial perspective. This survey presents a comprehensive review of recent advances in aerial object detection. We start with some basic concepts of aerial object detection and then summarize the five imbalance problems of aerial object detection, including scale imbalance, spatial imbalance, objective imbalance, semantic imbalance, and class imbalance. Moreover, we classify and analyze relevant methods and especially introduce the applications of aerial object detection in practical scenarios. Finally, the performance evaluation is presented on two popular aerial object detection datasets VisDrone-DET and DOTA, and we discuss several future directions that could facilitate the development of aerial object detection.},
  archive      = {J_CSUR},
  doi          = {10.1145/3664598},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Recent advances for aerial object detection: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On identity, transaction, and smart contract privacy on
permissioned and permissionless blockchain: A comprehensive survey.
<em>CSUR</em>, <em>56</em>(12), 1–35. (<a
href="https://doi.org/10.1145/3676164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain is a decentralized distributed ledger that combines multiple technologies, including chain data structures, P2P networks, consensus algorithms, cryptography, and smart contracts. This gives the blockchain the characteristics of decentralization, immutability, and traceability. However, blockchain stores smart contracts and transactions in blocks publicly, which poses the risk of data leakage and misuse. For example, by mining and analyzing blockchain transaction information, attackers can correlate transactions with user information, resulting in the disclosure of user privacy. Many current reviews focus on the privacy of permissionless blockchains or cryptocurrencies, requiring more in-depth investigations and detailed categorical analysis. To fill this gap, this work comprehensively reviews the latest and traditional methods related to identity, transaction, and smart contract privacy within permissioned and permissionless blockchains. Additionally, we summarize the existing problems, threats, and challenges of data management in different blockchain architectures. Last, we discuss future research directions for blockchain privacy protection technology, which can offer feasible ideas for researchers to explore further.},
  archive      = {J_CSUR},
  doi          = {10.1145/3676164},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {12},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {On identity, transaction, and smart contract privacy on permissioned and permissionless blockchain: A comprehensive survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The first principles: Setting the context for a safe and
secure metaverse. <em>CSUR</em>, <em>56</em>(11), 1–29. (<a
href="https://doi.org/10.1145/3665495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The metaverse delivered through converged and amalgamated technologies holds promise. No wonder technology heavyweights, large corporates, research organizations and businesses cutting across industry verticals are racing to put in place a metaverse-first strategy. The bets on consumers rapidly migrating from traditional social networks and collaborative applications to more immersive digital experiences have been placed. However, the transition is not expected to be seamless. Privacy, safety and security concerns abound in the early versions of the metaverse. Increased regulatory oversight and diverse national laws threaten to derail the hype around the metaverse. It is increasingly clear that the final iteration of the metaverse will need to assuage the concerns of individual users while addressing complex legal and regulatory requirements. Thus, a multi-perspective approach needs to be adopted to help set the agenda for the evolution of the metaverse. This research paper examines the different aspects and challenges which the future metaverse will need to address. A set of “first principles” are formulated, which if implemented will lead to the development of an equitable, inclusive, safe and secure metaverse.},
  archive      = {J_CSUR},
  doi          = {10.1145/3665495},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-29},
  shortjournal = {ACM Comput. Surv.},
  title        = {The first principles: Setting the context for a safe and secure metaverse},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Databases in edge and fog environments: A survey.
<em>CSUR</em>, <em>56</em>(11), 1–40. (<a
href="https://doi.org/10.1145/3666001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While a significant number of databases are deployed in cloud environments, pushing part or all data storage and querying planes closer to their sources (i.e., to the edge) can provide advantages in latency, connectivity, privacy, energy, and scalability. This article dissects the advantages provided by databases in edge and fog environments by surveying application domains and discussing the key drivers for pushing database systems to the edge. At the same time, it also identifies the main challenges faced by developers in this new environment and analyzes the mechanisms employed to deal with them. By providing an overview of the current state of edge and fog databases, this survey provides valuable insights into future research directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3666001},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-40},
  shortjournal = {ACM Comput. Surv.},
  title        = {Databases in edge and fog environments: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research progress of EEG-based emotion recognition: A
survey. <em>CSUR</em>, <em>56</em>(11), 1–49. (<a
href="https://doi.org/10.1145/3666002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition based on electroencephalography (EEG) signals has emerged as a prominent research field, facilitating objective evaluation of diseases like depression and motion detection for heathy people. Starting from the basic concepts of temporal-frequency-spatial features in EEG and the methods for cross-domain feature fusion, this survey then extends the overfitting challenge of EEG single-modal to the problem of heterogeneous modality modeling in multimodal conditions. It explores issues such as feature selection, sample scarcity, cross-subject emotional transfer, physiological knowledge discovery, multimodal fusion methods, and modality missing. These findings provide clues for researchers to further investigate emotion recognition based on EEG signals.},
  archive      = {J_CSUR},
  doi          = {10.1145/3666002},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-49},
  shortjournal = {ACM Comput. Surv.},
  title        = {Research progress of EEG-based emotion recognition: A survey},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An introduction to the compute express link (CXL)
interconnect. <em>CSUR</em>, <em>56</em>(11), 1–37. (<a
href="https://doi.org/10.1145/3669900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Compute Express Link (CXL) is an open industry-standard interconnect between processors and devices such as accelerators, memory buffers, smart network interfaces, persistent memory, and solid-state drives. CXL offers coherency and memory semantics with bandwidth that scales with PCIe bandwidth while achieving significantly lower latency than PCIe. All major CPU vendors, device vendors, and datacenter operators have adopted CXL as a common standard. This enables an inter-operable ecosystem that supports key computing use cases including highly efficient accelerators, server memory bandwidth and capacity expansion, multi-server resource pooling and sharing, and efficient peer-to-peer communication. This survey provides an introduction to CXL covering the standards CXL 1.0, CXL 2.0, and CXL 3.0. We further survey CXL implementations, discuss CXL&#39;s impact on the datacenter landscape, and future directions.},
  archive      = {J_CSUR},
  doi          = {10.1145/3669900},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {An introduction to the compute express link (CXL) interconnect},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-based affective music generation systems: A review of
methods and challenges. <em>CSUR</em>, <em>56</em>(11), 1–34. (<a
href="https://doi.org/10.1145/3672554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music is a powerful medium for altering the emotional state of the listener. In recent years, with significant advancements in computing capabilities, artificial intelligence-based (AI-based) approaches have become popular for creating affective music generation (AMG) systems. Entertainment, healthcare, and sensor-integrated interactive system design are a few of the areas in which AI-based affective music generation (AI-AMG) systems may have a significant impact. Given the surge of interest in this topic, this article aims to provide a comprehensive review of controllable AI-AMG systems. The main building blocks of an AI-AMG system are discussed and existing systems are formally categorized based on the core algorithm used for music generation. In addition, this article discusses the main musical features employed to compose affective music, along with the respective AI-based approaches used for tailoring them. Lastly, the main challenges and open questions in this field, as well as their potential solutions, are presented to guide future research. We hope that this review will be useful for readers seeking to understand the state-of-the-art in AI-AMG systems and gain an overview of the methods used for developing them, thereby helping them explore this field in the future.},
  archive      = {J_CSUR},
  doi          = {10.1145/3672554},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-34},
  shortjournal = {ACM Comput. Surv.},
  title        = {AI-based affective music generation systems: A review of methods and challenges},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secure UAV (drone) and the great promise of AI.
<em>CSUR</em>, <em>56</em>(11), 1–37. (<a
href="https://doi.org/10.1145/3673225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {UAVs have found their applications in numerous applications from recreational activities to business in addition to military and strategic fields. However, research on UAVs is not going on as quickly as the technology. Especially, when it comes to the security of these devices, the academia is lagging behind the industry. This gap motivates our work in this article as a stepping stone for future research in this area. A comprehensive survey on the security of UAVs and UAV-based systems can help the research community keep pace with, or even lead the industry. Although there are several reviews on UAVs or related areas, there is no recent survey broadly covering various aspects of security. Moreover, none of the existing surveys highlights current and future trends with a focus on the role of an omnipresent technology such as AI. This article endeavors to overcome these shortcomings. We conduct a comprehensive review on security challenges of UAVs as well as the related security controls. Then we develop a future roadmap for research in this area with a focus on the role of AI. The future roadmap is established based on the identified current trends, under-researched topics, and a future look-ahead.},
  archive      = {J_CSUR},
  doi          = {10.1145/3673225},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Secure UAV (Drone) and the great promise of AI},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on relation extraction: Recent
advances and new frontiers. <em>CSUR</em>, <em>56</em>(11), 1–39. (<a
href="https://doi.org/10.1145/3674501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction (RE) involves identifying the relations between entities from underlying content. RE serves as the foundation for many natural language processing (NLP) and information retrieval applications, such as knowledge graph completion and question answering. In recent years, deep neural networks have dominated the field of RE and made noticeable progress. Subsequently, the large pre-trained language models (PLMs) have taken the state-of-the-art RE to a new level. This survey provides a comprehensive review of existing deep learning techniques for RE. First, we introduce RE resources, including datasets and evaluation metrics. Second, we propose a new taxonomy to categorize existing works from three perspectives, i.e., text representation, context encoding, and triplet prediction. Third, we discuss several important challenges faced by RE and summarize potential techniques to tackle these challenges. Finally, we outline some promising future directions and prospects in this field. This survey is expected to facilitate researchers’ collaborative efforts to address the challenges of real-world RE systems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3674501},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on relation extraction: Recent advances and new frontiers},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The landscape of user-centered misinformation interventions
- a systematic literature review. <em>CSUR</em>, <em>56</em>(11), 1–36.
(<a href="https://doi.org/10.1145/3674724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Misinformation is one of the key challenges facing society today. User-centered misinformation interventions as digital countermeasures that exert a direct influence on users represent a promising means to deal with the large amounts of information available. While an extensive body of research on this topic exists, researchers are confronted with a diverse research landscape spanning multiple disciplines. This review systematizes the landscape of user-centered misinformation interventions to facilitate knowledge transfer, identify trends, and enable informed decision-making. Over 6,000 scholarly publications were screened, and a systematic literature review ( N=172 ) was conducted. A taxonomy was derived regarding intervention design (e.g., labels, showing indicators of misinformation, corrections, removal, or visibility reduction of content), user interaction (active or passive), and timing (e.g., pre or post exposure to misinformation or on request of the user). We provide a structured overview of approaches across multiple disciplines and derive six overarching challenges for future research regarding transferability of approaches to (1) novel platforms and (2) emerging video- and image-based misinformation, the sensible combination of automated mechanisms with (3) human experts and (4) user-centered feedback to facilitate comprehensibility, (5) encouraging media literacy without misinformation exposure, and (6) adequately addressing particularly vulnerable users such as older people or adolescents.},
  archive      = {J_CSUR},
  doi          = {10.1145/3674724},
  journal      = {ACM Computing Surveys},
  month        = {7},
  number       = {11},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {The landscape of user-centered misinformation interventions - a systematic literature review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of multi-modal knowledge graphs: Technologies and
trends. <em>CSUR</em>, <em>56</em>(11), 1–41. (<a
href="https://doi.org/10.1145/3656579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Knowledge Graphs (KGs) have played a crucial role in the development of advanced knowledge-intensive applications, such as recommender systems and semantic search. However, the human sensory system is inherently multi-modal, as objects around us are often represented by a combination of multiple signals, such as visual and textual. Consequently, Multi-modal Knowledge Graphs (MMKGs), which combine structured knowledge representation with multiple modalities, represent a powerful extension of KGs. Although MMKGs can handle certain types of tasks (e.g., visual query answering) or queries that standard KGs cannot process, and they can effectively tackle some standard problems (e.g., entity alignment), we lack a widely accepted definition of MMKG. In this survey, we provide a rigorous definition of MMKGs along with a classification scheme based on how existing approaches address four fundamental challenges: representation, fusion, alignment, and translation, which are crucial to improving an MMKG. Our classification scheme is flexible and allows for easy incorporation of new approaches, as well as a comparison of two approaches in terms of how they address one of the fundamental challenges mentioned above. As the first comprehensive survey of MMKG, this article aims at inspiring and provide a reference for relevant researchers in the field of Artificial Intelligence.},
  archive      = {J_CSUR},
  doi          = {10.1145/3656579},
  journal      = {ACM Computing Surveys},
  month        = {6},
  number       = {11},
  pages        = {1-41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of multi-modal knowledge graphs: Technologies and trends},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
