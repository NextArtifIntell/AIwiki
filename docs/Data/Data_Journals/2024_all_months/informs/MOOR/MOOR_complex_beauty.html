<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MOOR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="moor---111">MOOR - 111</h2>
<ul>
<li><details>
<summary>
(2024). Joint mixability and notions of negative dependence.
<em>MOOR</em>, <em>49</em>(4), 2786–2802. (<a
href="https://doi.org/10.1287/moor.2022.0121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A joint mix (JM) is a random vector with a constant component-wise sum. The dependence structure of a joint mix minimizes some common objectives, such as the variance of the component-wise sum, and it is regarded as a concept of extremal negative dependence. In this paper, we explore the connection between the joint mix structure and popular notions of negative dependence in statistics, such as negative correlation dependence, negative orthant dependence, and negative association. A joint mix is not always negatively dependent in any of these senses, but some natural classes of joint mixes are. We derive various necessary and sufficient conditions for a joint mix to be negatively dependent and study the compatibility of these notions. For identical marginal distributions, we show that a negatively dependent joint mix solves a multimarginal optimal transport problem for quadratic cost under a novel setting of uncertainty. Analysis of this optimal transport problem with heterogeneous marginals reveals a trade-off between negative dependence and the joint mix structure. Funding: T. Koike was supported by the Japan Society for the Promotion of Science [Grant JSPS KAKENHI JP21K13275]. R. Wang acknowledges financial support from the Natural Sciences and Engineering Research Council of Canada [Grants RGPIN-2018-03823 and RGPAS-2018-522590].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0121},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2786-2802},
  shortjournal = {Math. Oper. Res.},
  title        = {Joint mixability and notions of negative dependence},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strategy-proof multidimensional mechanism design.
<em>MOOR</em>, <em>49</em>(4), 2768–2785. (<a
href="https://doi.org/10.1287/moor.2022.0324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider direct mechanisms to sell heterogeneous objects when buyers have private additive valuations and nonunit demand. We completely characterize the class of strategy-proof and agent sovereign mechanisms that satisfy a local side-flatness condition. Further, we introduce a notion of “continuity up to utility” and show that any such mechanism allocating all objects at all profiles is continuous and anonymous only if it is efficient. We find that the only mechanism satisfying these properties is equivalent to operating simultaneous second-price auctions for each object—as was done by the New Zealand government in allocating license rights to the use of radio spectrum in 1990. Finally, we present a complete characterization of simultaneous second-price auctions with object-specific reserve prices in terms of these properties and a weak nonbossiness restriction.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0324},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2768-2785},
  shortjournal = {Math. Oper. Res.},
  title        = {Strategy-proof multidimensional mechanism design},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The privacy paradox and optimal bias–variance trade-offs in
data acquisition. <em>MOOR</em>, <em>49</em>(4), 2749–2767. (<a
href="https://doi.org/10.1287/moor.2023.0022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whereas users claim to be concerned about privacy, often they do little to protect their privacy in their online actions. One prominent explanation for this privacy paradox is that, when an individual shares data, it is not just the individual’s privacy that is compromised; the privacy of other individuals with correlated data is also compromised. This information leakage encourages oversharing of data and significantly impacts the incentives of individuals in online platforms. In this paper, we study the design of mechanisms for data acquisition in settings with information leakage and verifiable data. We design an incentive-compatible mechanism that optimizes the worst case trade-off between bias and variance of the estimation subject to a budget constraint, with which the worst case is over the unknown correlation between costs and data. Additionally, we characterize the structure of the optimal mechanism in closed form and study monotonicity and nonmonotonicity properties of the marketplace. Funding: This work is supported by the National Natural Science Foundation of China [Grants 62202512 and 62271434], Shenzhen Science and Technology Program [Grant JCYJ20210324120011032], Guangdong Basic and Applied Basic Research Foundation [Grant 2021B1515120008], Shenzhen Key Laboratory of Crowd Intelligence Empowered Low-Carbon Energy Network [Grant ZDSYS20220606100601002], and the Shenzhen Institute of Artificial Intelligence and Robotics for Society. This work is also supported by the National Science Foundation [Grants CNS-2146814, CPS-2136197, CNS-2106403, and NGSDI-2105648]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/moor.2023.0022 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0022},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2749-2767},
  shortjournal = {Math. Oper. Res.},
  title        = {The privacy paradox and optimal Bias–Variance trade-offs in data acquisition},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The multi-objective polynomial optimization. <em>MOOR</em>,
<em>49</em>(4), 2723–2748. (<a
href="https://doi.org/10.1287/moor.2023.0200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-objective optimization is to optimize several objective functions over a common feasible set. Because the objectives usually do not share a common optimizer, people often consider (weakly) Pareto points. This paper studies multi-objective optimization problems that are given by polynomial functions. First, we study the geometry for (weakly) Pareto values and represent Pareto front as the boundary of a convex set. Linear scalarization problems (LSPs) and Chebyshev scalarization problems (CSPs) are typical approaches for getting (weakly) Pareto points. For LSPs, we show how to use tight relaxations to solve them and how to detect existence or nonexistence of proper weights. For CSPs, we show how to solve them by moment relaxations. Moreover, we show how to check whether a given point is a (weakly) Pareto point or not and how to detect existence or nonexistence of (weakly) Pareto points. We also study how to detect unboundedness of polynomial optimization, which is used to detect nonexistence of proper weights or (weakly) Pareto points. Funding: J. Nie is partially supported by the National Science Foundation [Grant DMS-2110780].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0200},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2723-2748},
  shortjournal = {Math. Oper. Res.},
  title        = {The multi-objective polynomial optimization},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diffusion-based staffing for multitasking service systems
with many servers. <em>MOOR</em>, <em>49</em>(4), 2684–2722. (<a
href="https://doi.org/10.1287/moor.2021.0051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a many-server queue in which each server can serve multiple customers in parallel. Such multitasking phenomena occur in various applications areas (e.g., in hospitals and contact centers), although the impact of the number of customers who are simultaneously served on system efficiency may vary. We establish diffusion limits of the queueing process under the quality-and-efficiency-driven scaling and for different policies of assigning customers to servers depending on the number of customers they serve. We show that for a broad class of routing policies, including routing to the least busy server, the same one-dimensional diffusion process is obtained in the heavy-traffic limit. In case of assignment to the most busy server, there is no state-space collapse, and the diffusion limit involves a custom regulator mapping. Moreover, we also show that assigning customers to the least (most) busy server is optimal when the cumulative service rate per server is concave (convex), motivating the routing policies considered. Finally, we also derive diffusion limits in the nonheavy-traffic scaling regime and in the heavy-traffic scaling regime where customers can be reassigned during service. Funding: The research of J. Storm is partly funded by the Netherlands Organization for Scientific Research (NWO) Gravitation project Networks [Grant 024.002.003].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0051},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2684-2722},
  shortjournal = {Math. Oper. Res.},
  title        = {Diffusion-based staffing for multitasking service systems with many servers},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Limit theorems for default contagion and systemic risk.
<em>MOOR</em>, <em>49</em>(4), 2652–2683. (<a
href="https://doi.org/10.1287/moor.2021.0283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a general tractable model for default contagion and systemic risk in a heterogeneous financial network subjected to an exogenous macroeconomic shock. We show that under certain regularity assumptions, the default cascade model can be transformed into a death process problem represented by a balls-and-bins model. We state various limit theorems regarding the final size of default cascades. Under appropriate assumptions on the degree and threshold distributions, we prove that the final sizes of default cascades have asymptotically Gaussian fluctuations. We next state limit theorems for different system-wide wealth aggregation functions, which enable us to provide systemic risk measures in relation to the structure and heterogeneity of the financial network. Lastly, we demonstrate how these results can be utilized by a social planner to optimally target interventions during a financial crisis given a budget constraint and under partial information of the financial network.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0283},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2652-2683},
  shortjournal = {Math. Oper. Res.},
  title        = {Limit theorems for default contagion and systemic risk},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning-augmented mechanism design: Leveraging predictions
for facility location. <em>MOOR</em>, <em>49</em>(4), 2626–2651. (<a
href="https://doi.org/10.1287/moor.2022.0225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce an alternative model for the design and analysis of strategyproof mechanisms that is motivated by the recent surge of work in “learning-augmented algorithms.” Aiming to complement the traditional worst-case analysis approach in computer science, this line of work has focused on the design and analysis of algorithms that are enhanced with machine-learned predictions. The algorithms can use the predictions as a guide to inform their decisions, aiming to achieve much stronger performance guarantees when these predictions are accurate (consistency), while also maintaining near-optimal worst-case guarantees, even if these predictions are inaccurate (robustness). We initiate the design and analysis of strategyproof mechanisms that are augmented with predictions regarding the private information of the participating agents. To exhibit the important benefits of this approach, we revisit the canonical problem of facility location with strategic agents in the two-dimensional Euclidean space. We study both the egalitarian and utilitarian social cost functions, and we propose new strategyproof mechanisms that leverage predictions to guarantee an optimal trade-off between consistency and robustness. Furthermore, we also prove parameterized approximation results as a function of the prediction error, showing that our mechanisms perform well, even when the predictions are not fully accurate. Funding: The work of E. Balkanski was supported in part by the National Science Foundation [Grants CCF-2210501 and IIS-2147361]. The work of V. Gkatzelis and X. Tan was supported in part by the National Science Foundation [Grant CCF-2210502] and [CAREER Award CCF-2047907].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0225},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2626-2651},
  shortjournal = {Math. Oper. Res.},
  title        = {Learning-augmented mechanism design: Leveraging predictions for facility location},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zero-one composite optimization: Lyapunov exact penalty and
a globally convergent inexact augmented lagrangian method.
<em>MOOR</em>, <em>49</em>(4), 2602–2625. (<a
href="https://doi.org/10.1287/moor.2021.0320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of minimizing the sum of a smooth function and a composition of a zero-one loss function with a linear operator, namely the zero-one composite optimization problem (0/1-COP). It has a vast body of applications, including the support vector machine (SVM), calcium dynamics fitting (CDF), one-bit compressive sensing (1-bCS), and so on. However, it remains challenging to design a globally convergent algorithm for the original model of 0/1-COP because of the nonconvex and discontinuous zero-one loss function. This paper aims to develop an inexact augmented Lagrangian method (IALM), in which the generated whole sequence converges to a local minimizer of 0/1-COP under reasonable assumptions. In the iteration process, IALM performs minimization on a Lyapunov function with an adaptively adjusted multiplier. The involved Lyapunov penalty subproblem is shown to admit the exact penalty theorem for 0/1-COP, provided that the multiplier is optimal in the sense of the proximal-type stationarity. An efficient zero-one Bregman alternating linearized minimization algorithm is also designed to achieve an approximate solution of the underlying subproblem in finite steps. Numerical experiments for handling SVM, CDF, and 1-bCS demonstrate the satisfactory performance of the proposed method in terms of solution accuracy and time efficiency. Funding: This work was supported by the Fundamental Research Funds for the Central Universities [Grant 2022YJS099] and the National Natural Science Foundation of China [Grants 12131004 and 12271022].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0320},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2602-2625},
  shortjournal = {Math. Oper. Res.},
  title        = {Zero-one composite optimization: Lyapunov exact penalty and a globally convergent inexact augmented lagrangian method},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counting and enumerating optimum cut sets for hypergraph
k-partitioning problems for fixed k. <em>MOOR</em>, <em>49</em>(4),
2579–2601. (<a href="https://doi.org/10.1287/moor.2022.0259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of enumerating optimal solutions for two hypergraph k -partitioning problems, namely, H ypergraph - k -C ut and M inmax -H ypergraph - k -P artition . The input in hypergraph k -partitioning problems is a hypergraph G = ( V , E ) with positive hyperedge costs along with a fixed positive integer k . The goal is to find a partition of V into k nonempty parts ( V 1 , V 2 , … , V k ) —known as a k -partition—so as to minimize an objective of interest. (1) If the objective of interest is the maximum cut value of the parts, then the problem is known as M inmax -H ypergraph - k -P artition . A subset of hyperedges is a minmax - k - cut - set if it is the subset of hyperedges crossing an optimum k -partition for M inmax -H ypergraph - k -P artition . (2) If the objective of interest is the total cost of hyperedges crossing the k -partition, then the problem is known as H ypergraph - k -C ut . A subset of hyperedges is a min - k - cut - set if it is the subset of hyperedges crossing an optimum k -partition for H ypergraph - k -C ut . We give the first polynomial bound on the number of minmax - k - cut - set s and a polynomial-time algorithm to enumerate all of them in hypergraphs for every fixed k . Our technique is strong enough to also enable an n O ( k ) p -time deterministic algorithm to enumerate all min - k - cut - set s in hypergraphs, thus improving on the previously known n O ( k 2 ) p -time deterministic algorithm, in which n is the number of vertices and p is the size of the hypergraph. The correctness analysis of our enumeration approach relies on a structural result that is a strong and unifying generalization of known structural results for H ypergraph - k -C ut and M inmax -H ypergraph - k -P artition . We believe that our structural result is likely to be of independent interest in the theory of hypergraphs (and graphs). Funding: All authors were supported by NSF AF 1814613 and 1907937.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0259},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2579-2601},
  shortjournal = {Math. Oper. Res.},
  title        = {Counting and enumerating optimum cut sets for hypergraph k-partitioning problems for fixed k},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The iterates of the frank–wolfe algorithm may not converge.
<em>MOOR</em>, <em>49</em>(4), 2565–2578. (<a
href="https://doi.org/10.1287/moor.2022.0057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Frank–Wolfe algorithm is a popular method for minimizing a smooth convex function f over a compact convex set C . Whereas many convergence results have been derived in terms of function values, almost nothing is known about the convergence behavior of the sequence of iterates ( x t ) t ∈ N . Under the usual assumptions, we design several counterexamples to the convergence of ( x t ) t ∈ N , where f is d -time continuously differentiable, d ⩾ 2 , and f ( x t ) → min C f . Our counterexamples cover the cases of open-loop, closed-loop, and line-search step-size strategies and work for any choice of the linear minimization oracle, thus demonstrating the fundamental pathologies in the convergence behavior of ( x t ) t ∈ N . Funding: The authors acknowledge the support of the AI Interdisciplinary Institute ANITI funding through the French “Investments for the Future – PIA3” program under the Agence Nationale de la Recherche (ANR) agreement [Grant ANR-19-PI3A0004], the Air Force Office of Scientific Research, Air Force Material Command, U.S. Air Force [Grants FA866-22-1-7012 and ANR MaSDOL 19-CE23-0017-0], ANR Chess [Grant ANR-17-EURE-0010], ANR Regulia, and Centre Lagrange.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0057},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2565-2578},
  shortjournal = {Math. Oper. Res.},
  title        = {The iterates of the Frank–Wolfe algorithm may not converge},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantitative convergence for displacement monotone mean
field games with controlled volatility. <em>MOOR</em>, <em>49</em>(4),
2527–2564. (<a href="https://doi.org/10.1287/moor.2023.0106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the convergence problem for mean field games with common noise and controlled volatility. We adopt the strategy recently put forth by Laurière and the second author, using the maximum principle to recast the convergence problem as a question of “forward-backward propagation of chaos” (i.e., (conditional) propagation of chaos for systems of particles evolving forward and backward in time). Our main results show that displacement monotonicity can be used to obtain this propagation of chaos, which leads to quantitative convergence results for open-loop Nash equilibria for a class of mean field games. Our results seem to be the first (quantitative or qualitative) that apply to games in which the common noise is controlled. The proofs are relatively simple and rely on a well-known technique for proving wellposedness of forward-backward stochastic differential equations, which is combined with displacement monotonicity in a novel way. To demonstrate the flexibility of the approach, we also use the same arguments to obtain convergence results for a class of infinite horizon discounted mean field games. Funding: J. Jackson is supported by the National Science Foundation [Grant DGE1610403]. L. Tangpi is partially supported by the National Science Foundation [Grants DMS-2005832 and DMS-2143861].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0106},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2527-2564},
  shortjournal = {Math. Oper. Res.},
  title        = {Quantitative convergence for displacement monotone mean field games with controlled volatility},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence analysis of accelerated stochastic gradient
descent under the growth condition. <em>MOOR</em>, <em>49</em>(4),
2492–2526. (<a href="https://doi.org/10.1287/moor.2021.0293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the convergence of accelerated stochastic gradient descent (SGD) for strongly convex objectives under the growth condition , which states that the variance of stochastic gradient is bounded by a multiplicative part that grows with the full gradient and a constant additive part. Through the lens of the growth condition, we investigate four widely used accelerated methods: Nesterov’s accelerated method (NAM), robust momentum method (RMM), accelerated dual averaging method (DAM+), and implicit DAM+ (iDAM+). Although these methods are known to improve the convergence rate of SGD under the condition that the stochastic gradient has bounded variance, it is not well understood how their convergence rates are affected by the multiplicative noise. In this paper, we show that these methods all converge to a neighborhood of the optimum with accelerated convergence rates (compared with SGD), even under the growth condition. In particular, NAM, RMM, and iDAM+ enjoy acceleration only with a mild multiplicative noise, whereas DAM+ enjoys acceleration, even with a large multiplicative noise. Furthermore, we propose a generic tail-averaged scheme that allows the accelerated rates of DAM+ and iDAM+ to nearly attain the theoretical lower bound (up to a logarithmic factor in the variance term). We conduct numerical experiments to support our theoretical conclusions.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0293},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2492-2526},
  shortjournal = {Math. Oper. Res.},
  title        = {Convergence analysis of accelerated stochastic gradient descent under the growth condition},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear program-based policies for restless bandits:
Necessary and sufficient conditions for (exponentially fast) asymptotic
optimality. <em>MOOR</em>, <em>49</em>(4), 2468–2491. (<a
href="https://doi.org/10.1287/moor.2022.0101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a framework to analyze control policies for the restless Markovian bandit model under both finite and infinite time horizons. We show that when the population of arms goes to infinity, the value of the optimal control policy converges to the solution of a linear program (LP). We provide necessary and sufficient conditions for a generic control policy to be (i) asymptotically optimal, (ii) asymptotically optimal with square root convergence rate, and (iii) asymptotically optimal with exponential rate. We then construct the LP-index policy that is asymptotically optimal with square root convergence rate on all models and with exponential rate if the model is nondegenerate in finite horizon and satisfies a uniform global attractor property in infinite horizon. We next define the LP-update policy, which is essentially a repeated LP-index policy that solves a new LP at each decision epoch. We conclude by providing numerical experiments to compare the efficiency of different LP-based policies. Funding: This work was supported by Agence Nationale de la Recherche [Grant ANR-19-CE23-0015].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0101},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2468-2491},
  shortjournal = {Math. Oper. Res.},
  title        = {Linear program-based policies for restless bandits: Necessary and sufficient conditions for (Exponentially fast) asymptotic optimality},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proximity and flatness bounds for linear integer
optimization. <em>MOOR</em>, <em>49</em>(4), 2446–2467. (<a
href="https://doi.org/10.1287/moor.2022.0335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with linear integer optimization. We develop a technique that can be applied to provide improved upper bounds for two important questions in linear integer optimization. Given an optimal vertex solution for the linear relaxation, how far away is the nearest optimal integer solution (if one exists; proximity bounds)? If a polyhedron contains no integer point, what is the smallest number of integer parallel hyperplanes defined by an integral, nonzero, normal vector that intersect the polyhedron (flatness bounds)? This paper presents a link between these two questions by refining a proof technique that has been recently introduced by the authors. A key technical lemma underlying our technique concerns the areas of certain convex polygons in the plane; if a polygon K ⊆ R 2 satisfies τ K ⊆ K ° , where τ denotes 90 ° counterclockwise rotation and K ° denotes the polar of K , then the area of K ° is at least three. Funding: J. Paat was supported by the Natural Sciences and Engineering Research Council of Canada [Grant RGPIN-2021-02475]. R. Weismantel was supported by the Einstein Stiftung Berlin.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0335},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2446-2467},
  shortjournal = {Math. Oper. Res.},
  title        = {Proximity and flatness bounds for linear integer optimization},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Allocating indivisible goods to strategic agents: Pure nash
equilibria and fairness. <em>MOOR</em>, <em>49</em>(4), 2425–2445. (<a
href="https://doi.org/10.1287/moor.2022.0058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of fairly allocating a set of indivisible goods to a set of strategic agents with additive valuation functions. We assume no monetary transfers, and therefore, a mechanism in our setting is an algorithm that takes as input the reported—rather than the true—values of the agents. Our main goal is to explore whether there exist mechanisms that have pure Nash equilibria for every instance and, at the same time, provide fairness guarantees for the allocations that correspond to these equilibria. We focus on two relaxations of envy-freeness, namely, envy-freeness up to one good (EF1) and envy-freeness up to any good (EFX), and we positively answer the preceding question. In particular, we study two algorithms that are known to produce such allocations in the nonstrategic setting: round-robin (EF1 allocations for any number of agents) and a cut-and-choose algorithm of Plaut and Roughgarden (EFX allocations for two agents). For round-robin, we show that all of its pure Nash equilibria induce allocations that are EF1 with respect to the underlying true values, whereas for the algorithm of Plaut and Roughgarden, we show that the corresponding allocations not only are EFX, but also satisfy maximin share fairness, something that is not true for this algorithm in the nonstrategic setting! Further, we show that a weaker version of the latter result holds for any mechanism for two agents that always has pure Nash equilibria, which all induce EFX allocations. Funding: This work was supported by the Horizon 2020 European Research Council Advanced “Algorithmic and Mechanism Design Research in Online Markets” [Grant 788893], the Ministero dell’Università e della Ricerca Research project of national interest (PRIN) “Algorithms, Games, and Digital Markets,” the Future Artificial Intelligence Research project funded by the NextGenerationEU program within the National Recovery and Resilience Plan (PNRR-PE-AI) scheme [M4C2, investment 1.3, line on Artificial Intelligence], the National Recovery and Resilience Plan-Ministero dell’Università e della Ricerca (PNRR-MUR) project IR0000013-SoBigData.it, the Nederlandse Organisatie voor Wetenschappelijk Onderzoek Veni Project [Grant VI.Veni.192.153], and the National Recovery and Resilience Plan Greece 2.0 funded by the European Union under the NextGenerationEU Program [Grant MIS 5154714].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0058},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2425-2445},
  shortjournal = {Math. Oper. Res.},
  title        = {Allocating indivisible goods to strategic agents: Pure nash equilibria and fairness},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Worst-case iteration bounds for log barrier methods on
problems with nonconvex constraints. <em>MOOR</em>, <em>49</em>(4),
2402–2424. (<a href="https://doi.org/10.1287/moor.2020.0274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interior point methods (IPMs) that handle nonconvex constraints such as IPOPT, KNITRO and LOQO have had enormous practical success. We consider IPMs in the setting where the objective and constraints are thrice differentiable, and have Lipschitz first and second derivatives on the feasible region. We provide an IPM that, starting from a strictly feasible point, finds a μ -approximate Fritz John point by solving O ( μ − 7 / 4 ) trust-region subproblems. For IPMs that handle nonlinear constraints, this result represents the first iteration bound with a polynomial dependence on 1 / μ . We also show how to use our method to find scaled-KKT points starting from an infeasible solution and improve on existing complexity bounds. Funding: This work was supported by Air Force Office of Scientific Research [9550-23-1-0242]. A significant portion of this work was done at Stanford where O. Hinder was supported by the PACCAR, Inc., Stanford Graduate Fellowship and the Dantzig-Lieberman fellowship.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2020.0274},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2402-2424},
  shortjournal = {Math. Oper. Res.},
  title        = {Worst-case iteration bounds for log barrier methods on problems with nonconvex constraints},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The cost of nonconvexity in deterministic nonsmooth
optimization. <em>MOOR</em>, <em>49</em>(4), 2385–2401. (<a
href="https://doi.org/10.1287/moor.2022.0289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the impact of nonconvexity on the complexity of nonsmooth optimization, emphasizing objectives such as piecewise linear functions, which may not be weakly convex. We focus on a dimension-independent analysis, slightly modifying a 2020 black-box algorithm of Zhang-Lin-Jegelka-Sra-Jadbabaie that approximates an ϵ -stationary point of any directionally differentiable Lipschitz objective using O ( ϵ − 4 ) calls to a specialized subgradient oracle and a randomized line search. Seeking by contrast a deterministic method, we present a simple black-box version that achieves O ( ϵ − 5 ) for any difference-of-convex objective and O ( ϵ − 4 ) for the weakly convex case. Our complexity bound depends on a natural nonconvexity modulus that is related, intriguingly, to the negative part of directional second derivatives of the objective, understood in the distributional sense. Funding: This work was supported by the National Science Foundation [Grant DMS-2006990].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0289},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2385-2401},
  shortjournal = {Math. Oper. Res.},
  title        = {The cost of nonconvexity in deterministic nonsmooth optimization},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A mean-field control problem of optimal portfolio
liquidation with semimartingale strategies. <em>MOOR</em>,
<em>49</em>(4), 2356–2384. (<a
href="https://doi.org/10.1287/moor.2022.0174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a mean-field control problem with càdlàg semimartingale strategies arising in portfolio liquidation models with transient market impact and self-exciting order flow. We show that the value function depends on the state process only through its law, and we show that it is of linear-quadratic form and that its coefficients satisfy a coupled system of nonstandard Riccati-type equations. The Riccati equations are obtained heuristically by passing to the continuous-time limit from a sequence of discrete-time models. A sophisticated transformation shows that the system can be brought into standard Riccati form, from which we deduce the existence of a global solution. Our analysis shows that the optimal strategy jumps only at the beginning and the end of the trading period. Funding: Financial support is through the National Natural Science Foundation of China [Grants 12101465 and 12101523], Hong Kong Research Grants Council (Early Career Scheme) [Grant 25215122], Hong Kong Polytechnic University [Internal Grant P0044694, Internal Grant P0045668, and Startup Grant P0035348], and the Hong Kong Research Centre for Quantitative Finance [Grant P0042708].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0174},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2356-2384},
  shortjournal = {Math. Oper. Res.},
  title        = {A mean-field control problem of optimal portfolio liquidation with semimartingale strategies},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extreme-case distortion risk measures: A unification and
generalization of closed-form solutions. <em>MOOR</em>, <em>49</em>(4),
2341–2355. (<a href="https://doi.org/10.1287/moor.2022.0156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme-case risk measures provide an approach for quantifying the upper and lower bounds of risk in situations where limited information is available regarding the underlying distributions. Previous research has demonstrated that for popular risk measures, such as value-at-risk and conditional value-at-risk, the worst-case counterparts can be evaluated in closed form when only the first two moments of the underlying distributions are known. In this study, we extend these findings by presenting closed-form solutions for a general class of distortion risk measures, which consists of various popular risk measures as special cases when the first and certain higher-order (i.e., second or more) absolute center moments, alongside the symmetry properties of the underlying distributions, are known. Moreover, we characterize the extreme-case distributions with convex or concave envelopes of the corresponding distributions. By providing closed-form solutions for extreme-case distortion risk measures and characterizations for the corresponding distributions, our research contributes to the understanding and application of risk quantification methodologies. Funding: H. Shao acknowledges support from the Yangtze River Delta Science and Technology Innovation Community Joint Research Program [Grant 2022CSJGG0800]. Z. G. Zhang acknowledges support from the Canadian Network for Research and Innovation in Machining Technology, Natural Sciences and Engineering Research Council of Canada [Grant RGPIN-2019-06364]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/moor.2022.0156 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0156},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2341-2355},
  shortjournal = {Math. Oper. Res.},
  title        = {Extreme-case distortion risk measures: A unification and generalization of closed-form solutions},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving envy freeness up to any good guarantees through
rainbow cycle number. <em>MOOR</em>, <em>49</em>(4), 2323–2340. (<a
href="https://doi.org/10.1287/moor.2021.0252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of fairly allocating a set of indivisible goods among n agents with additive valuations. Envy freeness up to any good (EFX) is arguably the most compelling fairness notion in this context. However, the existence of an EFX allocation has not been settled and is one of the most important problems in fair division. Toward resolving this question, many impressive results show the existence of its relaxations. In particular, it is known that 0.618-EFX allocations exist and that EFX allocation exists if we do not allocate at most ( n -1) goods. Reducing the number of unallocated goods has emerged as a systematic way to tackle the main question. For example, follow-up works on three- and four-agents cases, respectively, allocated two more unallocated goods through an involved procedure. In this paper, we study the general case and achieve sublinear numbers of unallocated goods. Through a new approach, we show that for every ε ∈ ( 0 , 1 / 2 ] , there always exists a ( 1 − ε ) -EFX allocation with sublinear number of unallocated goods and high Nash welfare. For this, we reduce the EFX problem to a novel problem in extremal graph theory. We define the notion of rainbow cycle number R ( · ) in directed graphs. For all d ∈ N , R ( d ) is the largest k such that there exists a k -partite graph G = ( ∪ i ∈ [ k ] V i , E ) , in which each part has at most d vertices (i.e., | V i | ≤ d for all i ∈ [ k ] ); for any two parts V i and V j , each vertex in V i has an incoming edge from some vertex in V j and vice versa; and there exists no cycle in G that contains at most one vertex from each part. We show that any upper bound on R ( d ) directly translates to a sublinear bound on the number of unallocated goods. We establish a polynomial upper bound on R ( d ) , yielding our main result. Furthermore, our approach is constructive, which also gives a polynomial-time algorithm for finding such an allocation. Funding: J. Garg was supported by the Directorate for Computer and Information Science and Engineering [Grant CCF-1942321]. R. Mehta was supported by the Directorate for Computer and Information Science and Engineering [Grant CCF-1750436].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0252},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2323-2340},
  shortjournal = {Math. Oper. Res.},
  title        = {Improving envy freeness up to any good guarantees through rainbow cycle number},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). V-learning—a simple, efficient, decentralized algorithm for
multiagent reinforcement learning. <em>MOOR</em>, <em>49</em>(4),
2295–2322. (<a href="https://doi.org/10.1287/moor.2021.0317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major challenge of multiagent reinforcement learning (MARL) is the curse of multiagents , where the size of the joint action space scales exponentially with the number of agents. This remains to be a bottleneck for designing efficient MARL algorithms, even in a basic scenario with finitely many states and actions. This paper resolves this challenge for the model of episodic Markov games. We design a new class of fully decentralized algorithms—V-learning, which provably learns Nash equilibria (in the two-player zero-sum setting), correlated equilibria, and coarse correlated equilibria (in the multiplayer general-sum setting) in a number of samples that only scales with max i ∈ [ m ] A i , where A i is the number of actions for the i th player. This is in sharp contrast to the size of the joint action space, which is ∏ i = 1 m A i . V-learning (in its basic form) is a new class of single-agent reinforcement learning (RL) algorithms that convert any adversarial bandit algorithm with suitable regret guarantees into an RL algorithm. Similar to the classical Q-learning algorithm, it performs incremental updates to the value functions. Different from Q-learning, it only maintains the estimates of V-values instead of Q-values. This key difference allows V-learning to achieve the claimed guarantees in the MARL setting by simply letting all agents run V-learning independently. Funding: This work was partially supported by Office of Naval Research Grant N00014-22-1-2253.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0317},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2295-2322},
  shortjournal = {Math. Oper. Res.},
  title        = {V-Learning—A simple, efficient, decentralized algorithm for multiagent reinforcement learning},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fluid limits for longest remaining time first queues.
<em>MOOR</em>, <em>49</em>(4), 2271–2294. (<a
href="https://doi.org/10.1287/moor.2023.0090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A single-server queue with renewal arrivals and generally distributed independent and identically distributed service times is considered. Customers are served using the longest remaining time first scheduling algorithm. In case of a tie, processor sharing is utilized. We introduce a fluid model for the evolution of a measure-valued state descriptor of this queue, and we investigate its properties. We also prove a fluid limit theorem justifying our fluid model as the first-order approximation of the queueing system under consideration.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0090},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2271-2294},
  shortjournal = {Math. Oper. Res.},
  title        = {Fluid limits for longest remaining time first queues},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A class of dissimilarity semimetrics for preference
relations. <em>MOOR</em>, <em>49</em>(4), 2249–2270. (<a
href="https://doi.org/10.1287/moor.2022.0351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a class of semimetrics for acyclic preference relations, any one of which is an alternative to the classical Kemeny-Snell-Bogart metric. These semimetrics are based solely on the implications of preferences for choice behavior and thus appear more suitable in economic contexts and choice experiments. We obtain a fairly simple axiomatic characterization for the class we propose. The apparently most important member of this class, which we dub the “ top-difference semimetric ,” is characterized separately. We also obtain alternative formulae for it and, relative to this particular metric, compute the diameter of the space of complete and transitive preferences, as well as the best transitive extension of a given acyclic preference relation. Supplemental Material: The e-companion is available at https://doi.org/10.1287/moor.2022.0351 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0351},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2249-2270},
  shortjournal = {Math. Oper. Res.},
  title        = {A class of dissimilarity semimetrics for preference relations},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A stochastic sequential quadratic optimization algorithm for
nonlinear-equality-constrained optimization with rank-deficient
jacobians. <em>MOOR</em>, <em>49</em>(4), 2212–2248. (<a
href="https://doi.org/10.1287/moor.2021.0154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sequential quadratic optimization algorithm is proposed for solving smooth nonlinear-equality-constrained optimization problems in which the objective function is defined by an expectation. The algorithmic structure of the proposed method is based on a step decomposition strategy that is known in the literature to be widely effective in practice, wherein each search direction is computed as the sum of a normal step (toward linearized feasibility) and a tangential step (toward objective decrease in the null space of the constraint Jacobian). However, the proposed method is unique from others in the literature in that it both allows the use of stochastic objective gradient estimates and possesses convergence guarantees even in the setting in which the constraint Jacobians may be rank-deficient. The results of numerical experiments demonstrate that the algorithm offers superior performance when compared with popular alternatives. Funding: This material is based upon work supported by the U.S. National Science Foundation’s Division of Computing and Communication Foundations under award [CF-1740796], by the Office of Naval Research under award [N00014-21-1-2532], and by the National Science Foundation under award [2030859] to the Computing Research Association for the CIFellows Project.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0154},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2212-2248},
  shortjournal = {Math. Oper. Res.},
  title        = {A stochastic sequential quadratic optimization algorithm for nonlinear-equality-constrained optimization with rank-deficient jacobians},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fair-share allocations for agents with arbitrary
entitlements. <em>MOOR</em>, <em>49</em>(4), 2180–2211. (<a
href="https://doi.org/10.1287/moor.2021.0199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of fair allocation of indivisible goods to n agents with no transfers. When agents have equal entitlements, the well-established notion of the maximin share (MMS) serves as an attractive fairness criterion for which, to qualify as fair, an allocation needs to give every agent at least a substantial fraction of the agent’s MMS. In this paper, we consider the case of arbitrary (unequal) entitlements. We explain shortcomings in previous attempts that extend the MMS to unequal entitlements. Our conceptual contribution is the introduction of a new notion of a share, the AnyPrice share (APS), that is appropriate for settings with arbitrary entitlements. Even for the equal entitlements case, this notion is new and satisfies APS ⩾ MMS , for which the inequality is sometimes strict. We present two equivalent definitions for the APS (one as a minimization problem, the other as a maximization problem) and provide comparisons between the APS and previous notions of fairness. Our main result concerns additive valuations and arbitrary entitlements, for which we provide a polynomial-time algorithm that gives every agent at least a 3 5 - fraction of the agent’s APS. This algorithm can also be viewed as providing strategies in a certain natural bidding game, and these strategies secure each agent at least a 3 5 - fraction of the agent’s APS. Funding: T. Ezra’s research is partially supported by the European Research Council Advanced [Grant 788893] AMDROMA “Algorithmic and Mechanism Design Research in Online Markets” and MIUR PRIN project ALGADIMAR “Algorithms, Games, and Digital Markets.” U. Feige’s research is supported in part by the Israel Science Foundation [Grant 1122/22].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0199},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2180-2211},
  shortjournal = {Math. Oper. Res.},
  title        = {Fair-share allocations for agents with arbitrary entitlements},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding hall blockers by matrix scaling. <em>MOOR</em>,
<em>49</em>(4), 2166–2179. (<a
href="https://doi.org/10.1287/moor.2022.0198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a nonnegative matrix A = ( A i j ) , the matrix scaling problem asks whether A can be scaled to a doubly stochastic matrix D 1 A D 2 for some positive diagonal matrices D 1 , D 2 . The Sinkhorn algorithm is a simple iterative algorithm, which repeats row-normalization A i j ← A i j / ∑ j A i j and column-normalization A i j ← A i j / ∑ i A i j alternatively. By this algorithm, A converges to a doubly stochastic matrix in limit if and only if the bipartite graph associated with A has a perfect matching. This property can decide the existence of a perfect matching in a given bipartite graph G , which is identified with the 0, 1-matrix A G . Linial et al. (2000) showed that O ( n 2 log n ) iterations for A G decide whether G has a perfect matching. Here, n is the number of vertices in one of the color classes of G . In this paper, we show an extension of this result. If G has no perfect matching, then a polynomial number of the Sinkhorn iterations identifies a Hall blocker—a vertex subset X having neighbors Γ ( X ) with | X | &gt; | Γ ( X ) | , which is a certificate of the nonexistence of a perfect matching. Specifically, we show that O ( n 2 log n ) iterations can identify one Hall blocker and that further polynomial iterations can also identify all parametric Hall blockers X of maximizing ( 1 − λ ) | X | − λ | Γ ( X ) | for λ ∈ [ 0 , 1 ] . The former result is based on an interpretation of the Sinkhorn algorithm as alternating minimization for geometric programming. The latter is on an interpretation as alternating minimization for Kullback–Leibler (KL) divergence and on its limiting behavior for a nonscalable matrix. We also relate the Sinkhorn limit with parametric network flow, principal partition of polymatroids, and the Dulmage–Mendelsohn decomposition of a bipartite graph. Funding: K. Hayashi was supported by the Japan Society for the Promotion of Science [Grant JP19J22605]. H. Hirai was supported by Precursory Research for Embryonic Science and Technology [Grant JPMJPR192A].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0198},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2166-2179},
  shortjournal = {Math. Oper. Res.},
  title        = {Finding hall blockers by matrix scaling},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unbiased time-average estimators for markov chains.
<em>MOOR</em>, <em>49</em>(4), 2136–2165. (<a
href="https://doi.org/10.1287/moor.2022.0326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a time-average estimator f k of a functional of a Markov chain. Under a coupling assumption, we show that the expectation of f k has a limit μ as the number of time steps goes to infinity. We describe a modification of f k that yields an unbiased estimator f ^ k of μ . It is shown that f ^ k is square integrable and has finite expected running time. Under certain conditions, f ^ k can be built without any precomputations and is asymptotically at least as efficient as f k , up to a multiplicative constant arbitrarily close to one. Our approach also provides an unbiased estimator for the bias of f k . We study applications to volatility forecasting, queues, and the simulation of high-dimensional Gaussian vectors. Our numerical experiments are consistent with our theoretical findings.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0326},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2136-2165},
  shortjournal = {Math. Oper. Res.},
  title        = {Unbiased time-average estimators for markov chains},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The complexity of pacing for second-price auctions.
<em>MOOR</em>, <em>49</em>(4), 2109–2135. (<a
href="https://doi.org/10.1287/moor.2022.0009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Budget constraints are ubiquitous in online advertisement auctions. To manage these constraints and smooth out the expenditure across auctions, the bidders (or the platform on behalf of them) often employ pacing: each bidder is assigned a pacing multiplier between zero and one, and her bid on each item is multiplicatively scaled down by the pacing multiplier. This naturally gives rise to a game in which each bidder strategically selects a multiplier. The appropriate notion of equilibrium in this game is known as a pacing equilibrium. In this work, we show that the problem of finding an approximate pacing equilibrium is PPAD-complete for second-price auctions. This resolves an open question of Conitzer et al. [Conitzer V, Kroer C, Sodomka E, Stier-Moses NE (2022a) Multiplicative pacing equilibria in auction markets. Oper. Res . 70(2):963–989]. As a consequence of our hardness result, we show that the tâtonnement-style budget-management dynamics introduced by Borgs et al. [Borgs C, Chayes J, Immorlica N, Jain K, Etesami O, Mahdian M (2007) Dynamics of bid optimization in online advertisement auctions. Proc. 16th Internat. Conf. World Wide Web (ACM, New York), 531–540] are unlikely to converge efficiently for repeated second-price auctions. This disproves a conjecture by Borgs et al. [Borgs C, Chayes J, Immorlica N, Jain K, Etesami O, Mahdian M (2007) Dynamics of bid optimization in online advertisement auctions. Proc. 16th Internat. Conf. World Wide Web (ACM, New York), 531–540], under the assumption that the complexity class PPAD is not equal to P. Our hardness result also implies the existence of a refinement of supply-aware market equilibria which is hard to compute with simple linear utilities. Funding: This work was supported by National Science Foundation (CCF-1703925, IIS-1838154).},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0009},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2109-2135},
  shortjournal = {Math. Oper. Res.},
  title        = {The complexity of pacing for second-price auctions},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new dynamic programming approach for spanning trees with
chain constraints and beyond. <em>MOOR</em>, <em>49</em>(4), 2078–2108.
(<a href="https://doi.org/10.1287/moor.2023.0012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short spanning trees subject to additional constraints are important building blocks in various approximation algorithms, and moreover, they capture interesting problem settings on their own. Especially in the context of the traveling salesman problem (TSP), new techniques for finding spanning trees with well-defined properties have been crucial in recent progress. We consider the problem of finding a spanning tree subject to constraints on the edges in a family of cuts forming a laminar family of small width. Our main contribution is a new dynamic programming approach in which the value of a table entry does not only depend on the values of previous table entries, as is usually the case, but also on a specific representative solution saved together with each table entry. This allows for handling a broad range of constraint types. In combination with other techniques—including negatively correlated rounding and a polyhedral approach that, in the problems we consider, allows for avoiding potential losses in the objective through the randomized rounding—we obtain several new results. We first present a quasi-polynomial time algorithm for the minimum chain-constrained spanning tree problem with an essentially optimal guarantee. More precisely, each chain constraint is violated by a factor of at most 1 + ε , and the cost is no larger than that of an optimal solution not violating any chain constraint. The best previous procedure is a bicriteria approximation violating each chain constraint by up to a constant factor and losing another factor in the objective. Moreover, our approach can naturally handle lower bounds on the chain constraints, and it can be extended to constraints on cuts forming a laminar family of constant width. Furthermore, we show how our approach can also handle parity constraints (or, more precisely, a proxy thereof) as used in the context of (path) TSP and one of its generalizations and discuss implications in this context. Funding: This project received funding through the Swiss National Science Foundation [Grants 200021_184622 and P500PT_206742], the European Research Council under the European Union’s Horizon 2020 research and innovation program [Grant 817750], and the Deutsche Forschungsgemeinschaft (German Research Foundation) under Germany’s Excellence Strategy – EXC 2047/1 [Grant 390685813].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0012},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2078-2108},
  shortjournal = {Math. Oper. Res.},
  title        = {A new dynamic programming approach for spanning trees with chain constraints and beyond},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robustness of stochastic optimal control to approximate
diffusion models under several cost evaluation criteria. <em>MOOR</em>,
<em>49</em>(4), 2049–2077. (<a
href="https://doi.org/10.1287/moor.2022.0134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In control theory, typically a nominal model is assumed based on which an optimal control is designed and then applied to an actual (true) system. This gives rise to the problem of performance loss because of the mismatch between the true and assumed models. A robustness problem in this context is to show that the error because of the mismatch between a true and an assumed model decreases to zero as the assumed model approaches the true model. We study this problem when the state dynamics of the system are governed by controlled diffusion processes. In particular, we discuss continuity and robustness properties of finite and infinite horizon α -discounted/ergodic optimal control problems for a general class of nondegenerate controlled diffusion processes as well as for optimal control up to an exit time. Under a general set of assumptions and a convergence criterion on the models, we first establish that the optimal value of the approximate model converges to the optimal value of the true model. We then establish that the error because of the mismatch that occurs by application of a control policy, designed for an incorrectly estimated model, to a true model decreases to zero as the incorrect model approaches the true model. We see that, compared with related results in the discrete-time setup, the continuous-time theory lets us utilize the strong regularity properties of solutions to optimality (Hamilton–Jacobi–Bellman) equations, via the theory of uniformly elliptic partial differential equations, to arrive at strong continuity and robustness properties. Funding: The research of S. Yüksel was partially supported by the Natural Sciences and Engineering Research Council of Canada (NSERC).},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0134},
  journal      = {Mathematics of Operations Research},
  month        = {11},
  number       = {4},
  pages        = {2049-2077},
  shortjournal = {Math. Oper. Res.},
  title        = {Robustness of stochastic optimal control to approximate diffusion models under several cost evaluation criteria},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A theory of alternating paths and blossoms from the
perspective of minimum length. <em>MOOR</em>, <em>49</em>(3), 2009–2047.
(<a href="https://doi.org/10.1287/moor.2020.0388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Micali–Vazirani (MV) algorithm for finding a maximum cardinality matching in general graphs, which was published in 1980, remains to this day the most efficient known algorithm for the problem. The current paper gives the first complete and correct proof of this algorithm. The MV algorithm resorts to finding minimum-length augmenting paths. However, such paths fail to satisfy an elementary property, called breadth first search honesty in this paper. In the absence of this property, an exponential time algorithm appears to be called for—just for finding one such path. On the other hand, the MV algorithm accomplishes this and additional tasks in linear time. The saving grace is the various “footholds” offered by the underlying structure, which the algorithm uses in order to perform its key tasks efficiently. The theory expounded in this paper elucidates this rich structure and yields a proof of correctness of the algorithm. It may also be of independent interest as a set of well-knit graph-theoretic facts. Funding: This work was supported in part by the National Science Foundation [Grant CCF-2230414].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2020.0388},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2009-2047},
  shortjournal = {Math. Oper. Res.},
  title        = {A theory of alternating paths and blossoms from the perspective of minimum length},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The competition complexity of dynamic pricing.
<em>MOOR</em>, <em>49</em>(3), 1986–2008. (<a
href="https://doi.org/10.1287/moor.2022.0230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the competition complexity of dynamic pricing relative to the optimal auction in the fundamental single-item setting. In prophet inequality terminology, we compare the expected reward A m ( F ) achievable by the optimal online policy on m independent and identically distributed (i.i.d.) random variables distributed according to F to the expected maximum M n ( F ) of n i.i.d. draws from F . We ask how big m has to be to ensure that ( 1 + ε ) A m ( F ) ≥ M n ( F ) for all F . We resolve this question and characterize the competition complexity as a function of ε . When ε = 0 , the competition complexity is unbounded. That is, for any n and m there is a distribution F such that A m ( F ) &lt; M n ( F ) . In contrast, for any ε &gt; 0 , it is sufficient and necessary to have m = ϕ ( ε ) n , where ϕ ( ε ) = Θ ( log log 1 / ε ) . Therefore, the competition complexity not only drops from unbounded to linear, it is actually linear with a very small constant. The technical core of our analysis is a lossless reduction to an infinite dimensional and nonlinear optimization problem that we solve optimally. A corollary of this reduction is a novel proof of the factor ≈ 0.745 i.i.d. prophet inequality, which simultaneously establishes matching upper and lower bounds. Funding: This work was supported by ANID (Anillo ICMD) [Grant ACT210005] and the Center for Mathematical Modeling [Grant FB210005].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0230},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1986-2008},
  shortjournal = {Math. Oper. Res.},
  title        = {The competition complexity of dynamic pricing},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Difference-of-convex algorithm with extrapolation for
nonconvex, nonsmooth optimization problems. <em>MOOR</em>,
<em>49</em>(3), 1973–1985. (<a
href="https://doi.org/10.1287/moor.2020.0393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on the problem of minimizing the sum of a nonconvex differentiable function and a difference of convex (DC) function, where the differentiable function is not restricted to the global Lipschitz gradient continuity assumption. This problem covers a broad range of applications in machine learning and statistics, such as compressed sensing, signal recovery, sparse dictionary learning, matrix factorization, etc. We first take inspiration from the Nesterov acceleration technique and the DC algorithm to develop a novel algorithm for the considered problem. We then study the subsequential convergence of our algorithm to a critical point. Furthermore, we justify the global convergence of the whole sequence generated by our algorithm to a critical point and establish its convergence rate under the Kurdyka–Łojasiewicz condition. Numerical experiments on the nonnegative matrix completion problem are performed to demonstrate the efficiency of our algorithm and its superiority over well-known methods.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2020.0393},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1973-1985},
  shortjournal = {Math. Oper. Res.},
  title        = {Difference-of-convex algorithm with extrapolation for nonconvex, nonsmooth optimization problems},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shapley–scarf housing markets: Respecting improvement,
integer programming, and kidney exchange. <em>MOOR</em>, <em>49</em>(3),
1938–1972. (<a href="https://doi.org/10.1287/moor.2022.0092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a housing market of Shapley and Scarf, each agent is endowed with one indivisible object and has preferences over all objects. An allocation of the objects is in the (strong) core if there exists no (weakly) blocking coalition. We show that, for strict preferences, the unique strong core allocation “respects improvement”—if an agent’s object becomes more desirable for some other agents, then the agent’s allotment in the unique strong core allocation weakly improves. We extend this result to weak preferences for both the strong core (conditional on nonemptiness) and the set of competitive allocations (using probabilistic allocations and stochastic dominance). There are no counterparts of the latter two results in the two-sided matching literature. We provide examples to show how our results break down when there is a bound on the length of exchange cycles. Respecting improvements is an important property for applications of the housing markets model, such as kidney exchange: it incentivizes each patient to bring the best possible set of donors to the market. We conduct computer simulations using markets that resemble the pools of kidney exchange programs. We compare the game-theoretical solutions with current techniques (maximum size and maximum weight allocations) in terms of violations of the respecting improvement property. We find that game-theoretical solutions fare much better at respecting improvements even when exchange cycles are bounded, and they do so at a low efficiency cost. As a stepping stone for our simulations, we provide novel integer programming formulations for computing core, competitive, and strong core allocations. Funding: P. Biró gratefully acknowledges financial support from the Hungarian Scientific Research Fund, OTKA [Grant K143858] and the Hungarian Academy of Sciences [Grant LP2021-2]. F. Klijn gratefully acknowledges financial support from AGAUR–Generalitat de Catalunya [Grants 2017-SGR-1359 and 2021-SGR-00416] and the Spanish Agencia Estatal de Investigación [Grants ECO2017-88130-P and PID2020-114251GB-I00] (funded by MCIN/AEI/10.13039/501100011033) and the Severo Ochoa Programme for Centres of Excellence in R&amp;D (Barcelona School of Economics) [Grant CEX2019-000915-S]. Research visits related to this work were financed by COST Action [Grant CA15210 ENCKEP], supported by COST (European Cooperation in Science and Technology), http://www.cost.eu/ .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0092},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1938-1972},
  shortjournal = {Math. Oper. Res.},
  title        = {Shapley–Scarf housing markets: Respecting improvement, integer programming, and kidney exchange},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A localized progressive hedging algorithm for solving
nonmonotone stochastic variational inequalities. <em>MOOR</em>,
<em>49</em>(3), 1915–1937. (<a
href="https://doi.org/10.1287/moor.2022.0017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The progressive hedging algorithm (PHA) is an effective solution method for solving monotone stochastic variational inequalities (SVIs). However, this validity is based on the assumption of global maximal monotonicity. In this paper, we propose a localized PHA for solving nonmonotone SVIs and show that its validity is based on the weaker assumption of locally elicitable maximal monotonicity. Furthermore, we prove that such assumption holds when the mapping involved in the SVI is locally elicitable monotone or locally monotone. The local convergence of the proposed algorithm is established, and it is shown that the localized PHA has the rate of linear convergence under some mild assumptions. Some numerical experiments, including a two-stage orange market problem and randomly generated two-stage piecewise stochastic linear complementarity problems, indicate that the proposed algorithm is efficient. Funding: This work was supported by the National Natural Science Foundation of China [Grant 12171271].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0017},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1915-1937},
  shortjournal = {Math. Oper. Res.},
  title        = {A localized progressive hedging algorithm for solving nonmonotone stochastic variational inequalities},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A perturbation framework for convex minimization and
monotone inclusion problems with nonlinear compositions. <em>MOOR</em>,
<em>49</em>(3), 1890–1914. (<a
href="https://doi.org/10.1287/moor.2022.0180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a framework based on Rockafellar’s perturbation theory to analyze and solve general nonsmooth convex minimization and monotone inclusion problems involving nonlinearly composed functions as well as linear compositions. Such problems have been investigated only from a primal perspective and only for nonlinear compositions of smooth functions in finite-dimensional spaces in the absence of linear compositions. In the context of Banach spaces, the proposed perturbation analysis serves as a foundation for the construction of a dual problem and of a maximally monotone Kuhn–Tucker operator, which is decomposable as the sum of simpler monotone operators. In the Hilbertian setting, this decomposition leads to a block-iterative primal-dual algorithm that fully splits all the components of the problem and appears to be the first proximal splitting algorithm for handling nonlinear composite problems. Various applications are discussed. Funding: The work of L. M. Briceño-Arias was supported by Agencia Nacional de Investigación y Desarrollo-Chile [Grant Fondo Nacional de Desarrollo Científico y Tecnológico 1190871, Grant Centro de Modelamiento Matemático ACE210010, Grant Centro de Modelamiento Matemático FB210005, and basal Funds for Centers of Excellence], and the work of P. L. Combettes was supported by the National Science Foundation [Grant DMS-1818946].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0180},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1890-1914},
  shortjournal = {Math. Oper. Res.},
  title        = {A perturbation framework for convex minimization and monotone inclusion problems with nonlinear compositions},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bounds on the optimal radius when covering a set with
minimum radius identical disks. <em>MOOR</em>, <em>49</em>(3),
1855–1889. (<a href="https://doi.org/10.1287/moor.2022.0104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of covering a two-dimensional bounded set with a fixed number of minimum-radius identical disks is studied in the present work. Bounds on the optimal radius are obtained for a certain class of nonsmooth domains, and an asymptotic expansion of the bounds as the number of disks goes to infinity is provided. The proof is based on the approximation of the set to be covered by hexagonal honeycombs and on the thinnest covering property of the regular hexagonal lattice arrangement in the whole plane. The dependence of the optimal radius on the number of disks is also investigated numerically using a shape-optimization approach, and theoretical and numerical convergence rates are compared. An initial point construction strategy is introduced, which, in the context of a multistart method, finds good-quality solutions to the problem under consideration. Extensive numerical experiments with a variety of polygonal regions and regular polygons illustrate the introduced approach. Funding: This work was supported by Fundação de Amparo à Pesquisa do Estado de São Paulo [Grants 2013/07375-0, 2016/01860-1, 2018/24293-0, and 2019/25258-7] and Conselho Nacional de Desenvolvimento Científico e Tecnológico [Grants 302682/2019-8, 303243/2021-0, 304258/2018-0, and 408175/2018-4].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0104},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1855-1889},
  shortjournal = {Math. Oper. Res.},
  title        = {Bounds on the optimal radius when covering a set with minimum radius identical disks},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online bipartite matching with reusable resources.
<em>MOOR</em>, <em>49</em>(3), 1825–1854. (<a
href="https://doi.org/10.1287/moor.2022.0242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the classic online bipartite matching problem with a twist: off-line vertices, called resources, are reusable. In particular, when a resource is matched to an online vertex, it is unavailable for a deterministic time duration d , after which it becomes available again for a rematch. Thus, a resource can be matched to many different online vertices over a period of time. Whereas recent work on the problem has resolved the asymptotic case in which we have large starting inventory (i.e., many copies) of every resource, we consider the (more general) case of unit inventory and give the first algorithms that are provably better than the naïve greedy approach, which has a competitive ratio of (exactly) 0.5. Our first algorithm, which achieves a competitive ratio of 0.589, generalizes the classic RANKING algorithm for online bipartite matching of nonreusable resources (Karp et al. 1990) by reranking resources independently over time. Whereas reranking resources frequently has the same worst case performance as greedy, we show that reranking intermittently on a periodic schedule succeeds in addressing reusability of resources and performs significantly better than greedy in the worst case. Our second algorithm, which achieves a competitive ratio of 0.505, is a primal-dual randomized algorithm that works by suggesting up to two resources as candidate matches for every online vertex and then breaking the tie to make the final matching selection in a randomized correlated fashion over time. As a key component of our algorithm, we suitably adapt and extend the powerful technique of online correlated selection (Fahrbach et al. 2020) to reusable resources in order to induce negative correlation in our tie-breaking step and beat the competitive ratio of 0.5. Both of our results also extend to the case in which off-line vertices have weights. Funding: R. Niazadeh’s research is supported by the Asness Junior Faculty Fellowship at The University of Chicago Booth School of Business.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0242},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1825-1854},
  shortjournal = {Math. Oper. Res.},
  title        = {Online bipartite matching with reusable resources},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interim rationalizable implementation of functions.
<em>MOOR</em>, <em>49</em>(3), 1791–1824. (<a
href="https://doi.org/10.1287/moor.2022.0202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates rationalizable implementation of social choice functions (SCFs) in incomplete information environments. We identify weak interim rationalizable monotonicity (weak IRM) as a novel condition and show it to be a necessary and almost sufficient condition for rationalizable implementation. We show by means of robust examples that interim rationalizable monotonicity (IRM), found in the literature, is strictly stronger than weak IRM and that IRM is not necessary for rationalizable implementation, as had been previously claimed. These examples also demonstrate that Bayesian monotonicity, the key condition for full Bayesian implementation, is not necessary for rationalizable implementation. That is, rationalizable implementation can be more permissive than Bayesian implementation. We revisit well-studied classes of economic environments and show that the SCFs considered there are interim rationalizable implementable. A comprehensive discussion of related issues, including well-behaved mechanisms, mechanisms satisfying the best response property, double implementation, and responsive SCFs is also provided. Funding: This work was supported by Ministry of Education, Singapore [Grant MOE Academic Research Fund Tier 2/MOE-T2EP402A20-0].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0202},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1791-1824},
  shortjournal = {Math. Oper. Res.},
  title        = {Interim rationalizable implementation of functions},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic subgradient descent escapes active strict saddles
on weakly convex functions. <em>MOOR</em>, <em>49</em>(3), 1761–1790.
(<a href="https://doi.org/10.1287/moor.2021.0194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In nonsmooth stochastic optimization, we establish the nonconvergence of the stochastic subgradient descent (SGD) to the critical points recently called active strict saddles by Davis and Drusvyatskiy. Such points lie on a manifold M , where the function f has a direction of second-order negative curvature. Off this manifold, the norm of the Clarke subdifferential of f is lower-bounded. We require two conditions on f . The first assumption is a Verdier stratification condition, which is a refinement of the popular Whitney stratification. It allows us to establish a strengthened version of the projection formula of Bolte et al. for Whitney stratifiable functions and which is of independent interest. The second assumption, termed the angle condition, allows us to control the distance of the iterates to M . When f is weakly convex, our assumptions are generic. Consequently, generically, in the class of definable weakly convex functions, SGD converges to a local minimizer. Funding: The work of Sholom Schechtman was supported by “Région Ile-de-France”.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0194},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1761-1790},
  shortjournal = {Math. Oper. Res.},
  title        = {Stochastic subgradient descent escapes active strict saddles on weakly convex functions},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On strategic measures and optimality properties in
discrete-time stochastic control with universally measurable policies.
<em>MOOR</em>, <em>49</em>(3), 1734–1760. (<a
href="https://doi.org/10.1287/moor.2022.0188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns discrete-time infinite-horizon stochastic control systems with Borel state and action spaces and universally measurable policies. We study optimization problems on strategic measures induced by the policies in these systems. The results are then applied to risk-neutral and risk-sensitive Markov decision processes to establish the measurability of the optimal value functions and the existence of universally measurable, randomized or nonrandomized, ϵ -optimal policies, for a variety of average cost criteria and risk criteria. We also extend our analysis to a class of minimax control problems and establish similar optimality results under the axiom of analytic determinacy. Funding: This work was supported by grants from DeepMind, the Alberta Machine Intelligence Institute (AMII), and Alberta Innovates-Technology Futures (AITF).},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0188},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1734-1760},
  shortjournal = {Math. Oper. Res.},
  title        = {On strategic measures and optimality properties in discrete-time stochastic control with universally measurable policies},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A riemannian smoothing steepest descent method for
non-lipschitz optimization on embedded submanifolds of rn.
<em>MOOR</em>, <em>49</em>(3), 1710–1733. (<a
href="https://doi.org/10.1287/moor.2022.0286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the generalized subdifferentials and the Riemannian gradient subconsistency that are the basis for non-Lipschitz optimization on embedded submanifolds of R n . We then propose a Riemannian smoothing steepest descent method for non-Lipschitz optimization on complete embedded submanifolds of R n . We prove that any accumulation point of the sequence generated by the Riemannian smoothing steepest descent method is a stationary point associated with the smoothing function employed in the method, which is necessary for the local optimality of the original non-Lipschitz problem. We also prove that any accumulation point of the sequence generated by our method that satisfies the Riemannian gradient subconsistency is a limiting stationary point of the original non-Lipschitz problem. Numerical experiments are conducted to demonstrate the advantages of Riemannian ℓ p ( 0 &lt; p &lt; 1 ) optimization over Riemannian ℓ 1 optimization for finding sparse solutions and the effectiveness of the proposed method. Funding: C. Zhang was supported in part by the National Natural Science Foundation of China [Grant 12171027] and the Natural Science Foundation of Beijing [Grant 1202021]. X. Chen was supported in part by the Hong Kong Research Council [Grant PolyU15300219]. S. Ma was supported in part by the National Science Foundation [Grants DMS-2243650 and CCF-2308597], the UC Davis Center for Data Science and Artificial Intelligence Research Innovative Data Science Seed Funding Program, and a startup fund from Rice University.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0286},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1710-1733},
  shortjournal = {Math. Oper. Res.},
  title        = {A riemannian smoothing steepest descent method for non-lipschitz optimization on embedded submanifolds of rn},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A superlinearly convergent subgradient method for sharp
semismooth problems. <em>MOOR</em>, <em>49</em>(3), 1678–1709. (<a
href="https://doi.org/10.1287/moor.2023.1390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subgradient methods comprise a fundamental class of nonsmooth optimization algorithms. Classical results show that certain subgradient methods converge sublinearly for general Lipschitz convex functions and converge linearly for convex functions that grow sharply away from solutions. Recent work has moreover extended these results to certain nonconvex problems. In this work, we seek to improve the complexity of these algorithms by asking the following question. Is it possible to design a superlinearly convergent subgradient method? We provide a positive answer to this question for a broad class of sharp semismooth functions. Funding: The research of D. Davis was supported by the Division of Mathematical Sciences [Grant 2047637] and the Alfred P. Sloan Foundation.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1390},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1678-1709},
  shortjournal = {Math. Oper. Res.},
  title        = {A superlinearly convergent subgradient method for sharp semismooth problems},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic pricing provides robust equilibria in stochastic
ridesharing networks. <em>MOOR</em>, <em>49</em>(3), 1647–1677. (<a
href="https://doi.org/10.1287/moor.2022.0163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using prices induced by dual variables of a centralized optimization problem induces welfare-optimal equilibria among strategic drivers. We reveal a stark deficiency of such static pricing algorithms: it is possible for them to induce additional equilibria with arbitrarily low social welfare. Moreover, small perturbations to the marketplace, such as those caused by idiosyncratic randomness or model misspecification, can cause the welfare-optimal equilibrium to be Pareto-dominated (in terms of driver utility) by suboptimal equilibria. We show that dynamic pricing solves this problem. We describe a dynamic pricing algorithm that resolves the centralized optimization problem in each time period and show that it satisfies a new equilibrium robustness property, which guarantees that every induced (approximate) equilibrium is (approximately) welfare optimal. We also propose a novel two-level model of ridesharing networks with strategic drivers and spatiotemporal dynamics that lets us retain macroscopic uncertainty, such as correlated shocks caused by weather or other public events, when analyzing a large market limit in which idiosyncratic sources of uncertainty vanish. Funding: J. M. Cashore was supported by an NSERC PGS D Fellowship. P. Frazier was supported by AFOSR [Grant FA9550-19-1-0283]. É. Tardos was supported by AFOSR [Grant FA9550-19-1-0183] and [NSF Grants CCF-1408673 and CCF-1563714]. Supplemental Material: The online companion is available at https://doi.org/10.1287/moor.2022.0163 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0163},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1647-1677},
  shortjournal = {Math. Oper. Res.},
  title        = {Dynamic pricing provides robust equilibria in stochastic ridesharing networks},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rate-optimal bayesian simple regret in best arm
identification. <em>MOOR</em>, <em>49</em>(3), 1629–1646. (<a
href="https://doi.org/10.1287/moor.2022.0011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider best arm identification in the multiarmed bandit problem. Assuming certain continuity conditions of the prior, we characterize the rate of the Bayesian simple regret. Differing from Bayesian regret minimization, the leading term in the Bayesian simple regret derives from the region in which the gap between optimal and suboptimal arms is smaller than ( log T ) / T . We propose a simple and easy-to-compute algorithm with its leading term matching with the lower bound up to a constant factor; simulation results support our theoretical findings.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0011},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1629-1646},
  shortjournal = {Math. Oper. Res.},
  title        = {Rate-optimal bayesian simple regret in best arm identification},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online stochastic max-weight bipartite matching: Beyond
prophet inequalities. <em>MOOR</em>, <em>49</em>(3), 1607–1628. (<a
href="https://doi.org/10.1287/moor.2023.1389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rich literature on online Bayesian selection problems has long focused on so-called prophet inequalities, which compare the gain of an online algorithm to that of a “prophet” who knows the future. An equally natural, though significantly less well-studied, benchmark is the optimum online algorithm, which may be omnipotent (i.e., computationally unbounded), but not omniscient. What is the computational complexity of the optimum online? How well can a polynomial-time algorithm approximate it? Motivated by applications in ride hailing, we study the above questions for the online stochastic maximum-weight matching problem under vertex arrivals. For this problem, a number of 1 / 2 -competitive algorithms are known. This is the best possible ratio for this problem, as it generalizes the original single-item prophet inequality problem. We present a polynomial-time algorithm, which approximates the optimal online algorithm within a factor of 0.51—strictly more than the best-possible constant against a prophet. In contrast, we show that it is PSPACE-hard to approximate this problem within some universal constant α &lt; 1 . Funding: Financial support from the National Science Foundation [Grants CCF1763970, CCF1812919, and CCF191070], the Office of Naval Research [Grant N000141912550], and Cisco Research is gratefully acknowledged.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1389},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1607-1628},
  shortjournal = {Math. Oper. Res.},
  title        = {Online stochastic max-weight bipartite matching: Beyond prophet inequalities},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved online contention resolution for matchings and
applications to the gig economy. <em>MOOR</em>, <em>49</em>(3),
1582–1606. (<a href="https://doi.org/10.1287/moor.2023.1388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by applications in the gig economy, we study approximation algorithms for a sequential pricing problem . The input is a bipartite graph G = ( I , J , E ) between individuals I and jobs J . The platform has a value of v j for matching job j to an individual worker. In order to find a matching, the platform can consider the edges ( i j ) ∈ E in any order and make a one-time take-it-or-leave-it offer of a price π i j = w of its choosing to i for completing j . The worker accepts the offer with a known probability p ijw ; in this case, the job and the worker are irrevocably matched. What is the best way to make offers to maximize revenue and/or social welfare? The optimal algorithm is known to be NP-hard to compute (even if there is only a single job). With this in mind, we design efficient approximations to the optimal policy via a new random-order online contention resolution scheme (RO-OCRS) for matching. Our main result is a 0.456-balanced RO-OCRS in bipartite graphs and a 0.45-balanced RO-OCRS in general graphs. These algorithms improve on the recent bound of 1 2 ( 1 − e − 2 ) ≈ 0.432 and improve on the best-known lower bounds for the correlation gap of matching, despite applying to a significantly more restrictive setting. As a consequence of our online contention resolution scheme results, we obtain a 0.456-approximate algorithm for the sequential pricing problem. We further extend our results to settings where workers can only be contacted a limited number of times and show how to achieve improved results for this problem via improved algorithms for the well-studied stochastic probing problem. Funding: This work was supported by the National Science Foundation [Grant CCF2209520] and a gift from Amazon Research.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1388},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1582-1606},
  shortjournal = {Math. Oper. Res.},
  title        = {Improved online contention resolution for matchings and applications to the gig economy},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Binary extended formulations and sequential convexification.
<em>MOOR</em>, <em>49</em>(3), 1566–1581. (<a
href="https://doi.org/10.1287/moor.2021.0129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A binarization of a bounded variable x is obtained via a system of linear inequalities that involve x together with additional variables y 1 , … , y t in [ 0 , 1 ] so that the integrality of x is implied by the integrality of y 1 , … , y t . A binary extended formulation of a mixed-integer linear set is obtained by adding to its original description binarizations of its integer variables. Binary extended formulations are useful in mixed-integer programming as imposing integrality on 0/1 variables rather than on general integer variables has interesting convergence properties and has been studied from both the theoretical and practical points of view. We study the behavior of binary extended formulations with respect to sequential convexification. In particular, given a binary extended formulation and one of its variables x , we study a parameter that measures the progress made toward enforcing the integrality of x via application of sequential convexification. We formulate this parameter, which we call rank, as the solution of a set-covering problem and express it exactly for the classic binarizations from the literature. Funding: M. Aprile and M. Di Summa are supported by the University of Padova [SID 2019 Grant C94I20000280005].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0129},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1566-1581},
  shortjournal = {Math. Oper. Res.},
  title        = {Binary extended formulations and sequential convexification},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A primal-dual smoothing framework for max-structured
non-convex optimization. <em>MOOR</em>, <em>49</em>(3), 1535–1565. (<a
href="https://doi.org/10.1287/moor.2023.1387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a primal-dual smoothing framework for finding a near-stationary point of a class of nonsmooth nonconvex optimization problems with max-structure. We analyze the primal and dual gradient complexities of the framework via two approaches, that is, the dual-then-primal and primal-the-dual smoothing approaches. Our framework improves the best-known oracle complexities of the existing method, even in the restricted problem setting. As an important part of our framework, we propose a first-order method for solving a class of (strongly) convex-concave saddle-point problems, which is based on a newly developed non-Hilbertian inexact accelerated proximal gradient algorithm for strongly convex composite minimization that enjoys duality-gap convergence guarantees. Some variants and extensions of our framework are also discussed. Funding: R. Zhao’s research is partially supported by AFOSR [Grant FA9550-22-1-0356].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1387},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1535-1565},
  shortjournal = {Math. Oper. Res.},
  title        = {A primal-dual smoothing framework for max-structured non-convex optimization},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving strong-substitutes product-mix auctions.
<em>MOOR</em>, <em>49</em>(3), 1502–1534. (<a
href="https://doi.org/10.1287/moor.2019.0248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops algorithms to solve strong-substitutes product-mix auctions: it finds competitive equilibrium prices and quantities for agents who use this auction’s bidding language to truthfully express their strong-substitutes preferences over an arbitrary number of goods, each of which is available in multiple discrete units. Our use of the bidding language and the information it provides contrasts with existing algorithms that rely on access to a valuation or demand oracle. We compute market-clearing prices using algorithms that apply existing submodular minimization methods. Allocating the supply among the bidders at these prices then requires solving a novel constrained matching problem. Our algorithm iteratively simplifies the allocation problem, perturbing bids and prices in a way that resolves tie-breaking choices created by bids that can be accepted on more than one good. We provide practical running time bounds on both price finding and allocation and illustrate experimentally that our allocation mechanism is practical. Funding: E. Baldwin and P. Klemperer were supported by the Economic and Social Research Council [Grant ES/L003058/1]. P. W. Goldberg and E. Lock were supported by a JP Morgan faculty fellowship during the work on the final version of the paper. Supplemental Material: The online companion is available at https://doi.org/10.1287/moor.2019.0248 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0248},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1502-1534},
  shortjournal = {Math. Oper. Res.},
  title        = {Solving strong-substitutes product-mix auctions},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimal-access rights in school choice and the deferred
acceptance mechanism. <em>MOOR</em>, <em>49</em>(3), 1487–1501. (<a
href="https://doi.org/10.1287/moor.2022.0275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A classical school choice problem consists of a set of schools with priorities over students and a set of students with preferences over schools. Schools’ priorities are often based on multiple criteria, for example, merit-based test scores as well as minimal-access rights (siblings attending the school, students’ proximity to the school, etc.). Traditionally, minimal-access rights are incorporated into priorities by always giving minimal-access students higher priority over non-minimal-access students. However, stability based on such adjusted priorities can be considered unfair because a minimal-access student may be admitted to a popular school, whereas another student with a higher merit score but without a minimal-access right is rejected, even though the former minimal-access student could easily attend another of her minimal-access schools. We therefore weaken stability to minimal-access stability: minimal-access rights promote access to only at most one minimal-access school. Apart from minimal-access stability, we also would want a school choice mechanism to satisfy strategy-proofness and minimal-access monotonicity, that is, additional minimal-access rights for a student do not harm her. Our main result is that the deferred acceptance mechanism is the only mechanism that satisfies minimal-access stability, strategy-proofness, and minimal-access monotonicity. Because this mechanism is in fact stable, our result can be interpreted as an impossibility result: fairer outcomes that are made possible by the weaker property of minimal-access stability are incompatible with strategy-proofness and minimal-access monotonicity. Funding: This work was supported by the Spanish State Research Agency [Grant PID2020-114251GB-I00], AGAUR–Generalitat de Catalunya [Grant 2021-SGR-00416], the Severo Ochoa Programme for Centres of Excellence in R&amp;D (Barcelona School of Economics) [Grant CEX2019-000915-S], and the Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung [Grant 100018_192583].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0275},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1487-1501},
  shortjournal = {Math. Oper. Res.},
  title        = {Minimal-access rights in school choice and the deferred acceptance mechanism},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Oriented calmness and sweeping process dynamics.
<em>MOOR</em>, <em>49</em>(3), 1472–1486. (<a
href="https://doi.org/10.1287/moor.2021.0269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Daniilidis and Drusviatskiy, in 2017, extended the celebrated Kurdyka–Łojasiewicz inequality from definable functions to definable multivalued maps by establishing that the coderivative mapping admits a desingularization around every critical value. As was the case in the gradient dynamics, this desingularization yields a uniform control of the lengths of all bounded orbits of the corresponding sweeping process. In this paper, working outside the framework of o-minimal geometry, we characterize the existence of a desingularization for the coderivative in terms of the behavior of the sweeping process orbits and the integrability of the talweg function. These results are close in spirit with the ones in Bolte et al., 2010, in which characterizations for the desingularization of the (sub)gradient of functions is obtained. Funding: A. Daniilidis was supported by the Austrian Science Fund [Grant FWF P-36344N], Fondo Nacional de Desarrollo Científico y Tecnológico [Grant 1211217], and Centro de Modelamiento Matemático [Grant FB210005]. S. Tapia was supported by Agencia Nacional de Investigación y Desarrollo (Chile)-Programa de Fortalecimiento de Capital Humano Académico Doctorado Nacional [Grant 2018-21181905].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0269},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1472-1486},
  shortjournal = {Math. Oper. Res.},
  title        = {Oriented calmness and sweeping process dynamics},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). (No-)betting pareto optima under rank-dependent utility.
<em>MOOR</em>, <em>49</em>(3), 1452–1471. (<a
href="https://doi.org/10.1287/moor.2022.0317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a pure-exchange economy with no aggregate uncertainty, we characterize in closed form and full generality Pareto-optimal allocations between two agents who maximize (nonconcave) rank-dependent utilities (RDU). We then derive a necessary and sufficient condition for Pareto optima to be no-betting allocations (i.e., deterministic allocations or full insurance allocations). This condition depends only on the probability weighting functions of the two agents and not on their (concave) utility of wealth. Hence, with RDU preferences, it is the difference in probabilistic risk attitudes given common beliefs rather than heterogeneity or ambiguity in beliefs that is a driver of betting behavior. As by-product of our analysis, we answer the question of when sunspots matter in this economy. Funding: M. Ghossoub acknowledges financial support from the Natural Sciences and Engineering Research Council of Canada [Grant 2018-03961].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0317},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1452-1471},
  shortjournal = {Math. Oper. Res.},
  title        = {(No-)Betting pareto optima under rank-dependent utility},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inner moreau envelope of nonsmooth conic chance-constrained
optimization problems. <em>MOOR</em>, <em>49</em>(3), 1419–1451. (<a
href="https://doi.org/10.1287/moor.2021.0338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization problems with uncertainty in the constraints occur in many applications. Particularly, probability functions present a natural form to deal with this situation. Nevertheless, in some cases, the resulting probability functions are nonsmooth, which motivates us to propose a regularization employing the Moreau envelope of a scalar representation of the vector inequality. More precisely, we consider a probability function that covers most of the general classes of probabilistic constraints: φ ( x ) = P ( Φ ( x , ξ ) ∈ − K ) , where K is a convex cone of a Banach space. The conic inclusion Φ ( x , ξ ) ∈ − K represents an abstract system of inequalities, and ξ is a random vector. We propose a regularization by applying the Moreau envelope to the scalarization of the function Φ . In this paper, we demonstrate, under mild assumptions, the smoothness of such a regularization and that it satisfies a type of variational convergence to the original probability function. Consequently, when considering an appropriately structured problem involving probabilistic constraints, we can, thus, entail the convergence of the minimizers of the regularized approximate problems to the minimizers of the original problem. Finally, we illustrate our results with examples and applications in the field of (nonsmooth) joint, semidefinite, and probust chance-constrained optimization problems. Funding: P. Pérez-Aros was supported by Centro de Modelamiento Matemático [Grants ACE210010 and FB210005] and BASAL funds for center of excellence and ANID-Chile grant Fondecyt Regular [Grants 1200283 and 1190110] and Fondecyt Exploración [Grant 13220097]. C. Soto was supported by the National Agency for Research and Development (ANID)/Scholarship Program/Doctorado Nacional Chile [Grant 2017-21170428]. E. Vilches was supported by Centro de Modelamiento Matemático [Grants ACE210010 and FB210005] and BASAL funds for center of excellence and Fondecyt Regular [Grant 1200283] and Fondecyt Exploración [Grant 13220097] from ANID-Chile.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0338},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1419-1451},
  shortjournal = {Math. Oper. Res.},
  title        = {Inner moreau envelope of nonsmooth conic chance-constrained optimization problems},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asymptotic consistency for nonconvex risk-averse stochastic
optimization with infinite-dimensional decision spaces. <em>MOOR</em>,
<em>49</em>(3), 1403–1418. (<a
href="https://doi.org/10.1287/moor.2022.0200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal values and solutions of empirical approximations of stochastic optimization problems can be viewed as statistical estimators of their true values. From this perspective, it is important to understand the asymptotic behavior of these estimators as the sample size goes to infinity. This area of study has a long tradition in stochastic programming. However, the literature is lacking consistency analysis for problems in which the decision variables are taken from an infinite-dimensional space, which arise in optimal control, scientific machine learning, and statistical estimation. By exploiting the typical problem structures found in these applications that give rise to hidden norm compactness properties for solution sets, we prove consistency results for nonconvex risk-averse stochastic optimization problems formulated in infinite-dimensional space. The proof is based on several crucial results from the theory of variational convergence. The theoretical results are demonstrated for several important problem classes arising in the literature.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0200},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1403-1418},
  shortjournal = {Math. Oper. Res.},
  title        = {Asymptotic consistency for nonconvex risk-averse stochastic optimization with infinite-dimensional decision spaces},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weak approachability of convex sets in absorbing games.
<em>MOOR</em>, <em>49</em>(3), 1372–1402. (<a
href="https://doi.org/10.1287/moor.2021.0160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we extend previous results on weak approachability in generalized quitting games with vector payoffs to the general case of absorbing games. Specifically, we show that a necessary condition and a different sufficient condition for weak approachability of a convex set, established by Flesch, Laraki, and Perchet, remain valid in the general case. To do so, we extend results on Blackwell approachability to a setup in which stage weights depend on past actions as well as the current action of player 1 (the approaching player). Additionally, we prove that the strategy used to approach the convex set can be defined in blocks of fixed length, and so it has bounded memory and can be implemented by a finite automata.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0160},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1372-1402},
  shortjournal = {Math. Oper. Res.},
  title        = {Weak approachability of convex sets in absorbing games},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic games with general payoff functions.
<em>MOOR</em>, <em>49</em>(3), 1349–1371. (<a
href="https://doi.org/10.1287/moor.2023.1385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider multiplayer stochastic games with finitely many players and actions, and countably many states, in which the payoff of each player is a bounded and Borel-measurable function of the infinite play. By using a generalization of the technique of Martin [Martin DA (1998) The determinacy of Blackwell games. J. Symb. Log. 63(4):1565–1581] and Maitra and Sudderth [Maitra A, Sudderth W (1998) Finitely additive stochastic games with Borel measurable payoffs. Internat. J. Game Theory 27:257–267], we show four different existence results. In each stochastic game, it holds for every ε &gt; 0 that (i) each player has a strategy that guarantees in each subgame that this player’s payoff is at least his or her maxmin value up to ε , (ii) there exists a strategy profile under which in each subgame each player’s payoff is at least his or her minmax value up to ε , (iii) the game admits an extensive-form correlated ε -equilibrium, and (iv) there exists a subgame that admits an ε -equilibrium. Funding: This work was supported by the Israel Science Foundation (Nos. 217/17 and 211/22).},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1385},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1349-1371},
  shortjournal = {Math. Oper. Res.},
  title        = {Stochastic games with general payoff functions},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Congruency-constrained TU problems beyond the bimodular
case. <em>MOOR</em>, <em>49</em>(3), 1303–1348. (<a
href="https://doi.org/10.1287/moor.2023.1381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A long-standing open question in integer programming is whether integer programs with constraint matrices with bounded subdeterminants are efficiently solvable. An important special case thereof are congruency-constrained integer programs min { c ⊤ x : T x ≤ b , γ ⊤ x ≡ r ( mod m ) , x ∈ Z n } with a totally unimodular constraint matrix T . Such problems are shown to be polynomial-time solvable for m = 2, which led to an efficient algorithm for integer programs with bimodular constraint matrices, that is, full-rank matrices whose n × n subdeterminants are bounded by two in absolute value. Whereas these advances heavily rely on existing results on well-known combinatorial problems with parity constraints, new approaches are needed beyond the bimodular case, that is, for m &gt; 2. We make first progress in this direction through several new techniques. In particular, we show how to efficiently decide feasibility of congruency-constrained integer programs with a totally unimodular constraint matrix for m = 3 using a randomized algorithm. Furthermore, for general m , our techniques also allow for identifying flat directions of infeasible problems and deducing bounds on the proximity between solutions of the problem and its relaxation. Funding: This project received funding from the Swiss National Science Foundation [Grants 200021_184622 and P500PT_206742], the European Research Council under the European Union’s Horizon 2020 research and innovation program [Grant 817750], and the Deutsche Forschungsgemeinschaft (German Research Foundation) under Germany’s Excellence Strategy–GZ 2047/1 [Grant 390685813].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1381},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1303-1348},
  shortjournal = {Math. Oper. Res.},
  title        = {Congruency-constrained TU problems beyond the bimodular case},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Binary matrix factorization and completion via integer
programming. <em>MOOR</em>, <em>49</em>(2), 1278–1302. (<a
href="https://doi.org/10.1287/moor.2023.1386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary matrix factorization is an essential tool for identifying discrete patterns in binary data. In this paper, we consider the rank- k binary matrix factorization problem ( k -BMF) under Boolean arithmetic: we are given an n × m binary matrix X with possibly missing entries and need to find two binary matrices A and B of dimension n × k and k × m , respectively, which minimize the distance between X and the Boolean product of A and B in the squared Frobenius distance. We present a compact and two exponential size integer programs (IPs) for k -BMF and show that the compact IP has a weak linear programming (LP) relaxation, whereas the exponential size IPs have a stronger equivalent LP relaxation. We introduce a new objective function, which differs from the traditional squared Frobenius objective in attributing a weight to zero entries of the input matrix that is proportional to the number of times the zero is erroneously covered in a rank- k factorization. For one of the exponential size Ips, we describe a computational approach based on column generation. Experimental results on synthetic and real-world data sets suggest that our integer programming approach is competitive against available methods for k -BMF and provides accurate low-error factorizations. Funding: O. Günlük was partially supported by the Office of Naval Research [Grant N00014-21-1-2575]. R. Á. Kovács was supported by a doctoral scholarship from The Alan Turing Institute under the EPSRC [Grant EP/N510129/1] and the Office for National Statistics. R. A. Hauser was supported by The Alan Turing Institute under the EPSRC [Grant EP/N510129/1].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1386},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1278-1302},
  shortjournal = {Math. Oper. Res.},
  title        = {Binary matrix factorization and completion via integer programming},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extension of additive valuations to general valuations on
the existence of EFX. <em>MOOR</em>, <em>49</em>(2), 1263–1277. (<a
href="https://doi.org/10.1287/moor.2022.0044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Envy freeness is one of the most widely studied notions in fair division. Because envy-free allocations do not always exist when items are indivisible, several relaxations have been considered. Among them, possibly the most compelling notion is envy freeness up to any item (EFX). Informally speaking, EFX requires that no agent i envies another agent j after the removal of any item in j ’s bundle. The existence of EFX allocations is a major open problem. We study the existence of EFX allocations when agents have general valuations. For general valuations, it is known that an EFX allocation always exists (i) when n = 2 or (ii) when all agents have identical valuations, where n is the number of agents. It is also known that an EFX allocation always exists when one can leave at most n − 1 items unallocated. We develop new techniques and extend some results of additive valuations to general valuations on the existence of EFX allocations. We show that an EFX allocation always exists (i) when all agents have one of two general valuations or (ii) when the number of items is at most n + 3. We also show that an EFX allocation always exists when one can leave at most n − 2 items unallocated. In addition to the positive results, we construct an instance with n = 3, in which an existing approach does not work. Funding: This work was partially supported by Kyoto University and Toyota Motor Corporation [Joint Project “Advanced Mathematical Science for Mobility Society”].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0044},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1263-1277},
  shortjournal = {Math. Oper. Res.},
  title        = {Extension of additive valuations to general valuations on the existence of EFX},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The secretary problem with predictions. <em>MOOR</em>,
<em>49</em>(2), 1241–1262. (<a
href="https://doi.org/10.1287/moor.2022.0031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The value maximization version of the secretary problem is the problem of hiring a candidate with the largest value from a randomly ordered sequence of candidates. In this work, we consider a setting where predictions of candidate values are provided in advance. We propose an algorithm that achieves a nearly optimal value if the predictions are accurate and results in a constant-factor competitive ratio otherwise. We also show that the worst-case competitive ratio of an algorithm cannot be higher than some constant &lt; 1 / e , which is the best possible competitive ratio when we ignore predictions, if the algorithm performs nearly optimally when the predictions are accurate. Additionally, for the multiple-choice secretary problem, we propose an algorithm with a similar theoretical guarantee. We empirically illustrate that if the predictions are accurate, the proposed algorithms perform well; meanwhile, if the predictions are inaccurate, performance is comparable to existing algorithms that do not use predictions.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0031},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1241-1262},
  shortjournal = {Math. Oper. Res.},
  title        = {The secretary problem with predictions},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence rates for regularized optimal transport via
quantization. <em>MOOR</em>, <em>49</em>(2), 1223–1240. (<a
href="https://doi.org/10.1287/moor.2022.0245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the convergence of divergence-regularized optimal transport as the regularization parameter vanishes. Sharp rates for general divergences including relative entropy or L p regularization, general transport costs, and multimarginal problems are obtained. A novel methodology using quantization and martingale couplings is suitable for noncompact marginals and achieves, in particular, the sharp leading-order term of entropically regularized 2-Wasserstein distance for marginals with a finite ( 2 + δ ) -moment. Funding: This work was supported by the Alfred P. Sloan Foundation [Grant FG-2016-6282] and the Division of Mathematical Sciences [Grants DMS-1812661 and DMS-2106056].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0245},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1223-1240},
  shortjournal = {Math. Oper. Res.},
  title        = {Convergence rates for regularized optimal transport via quantization},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Managing customer churn via service mode control.
<em>MOOR</em>, <em>49</em>(2), 1192–1222. (<a
href="https://doi.org/10.1287/moor.2021.0179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel stochastic control model for the problem of a service firm interacting over time with one of its customers who probabilistically churns depending on the customer’s satisfaction. The firm has two service modes available, and they determine the drift and volatility of the Brownian reward process. The firm’s objective is to maximize the rewards generated over the customer’s lifetime. Meanwhile, the customer might churn probabilistically if the customer’s satisfaction, modeled as an Orstein–Uhlenbeck process controlled by the firm’s service mode, is below a certain threshold. We build upon Markov processes with spatial delay to solve this problem, and we explicitly characterize the firm’s optimal policy, which is either myopic or a sandwich policy. A sandwich policy is one in which the firm deploys the service mode with inferior reward rate when the customer satisfaction level is in a specific interval near the satisfaction threshold and uses the myopically optimal service mode for all other satisfaction levels. Specifically, we find that the firm should use the safe service mode when the customer is marginally satisfied and the risky service mode when the customer is marginally unsatisfied. We find numerically that the customer lifetime value under the optimal policy is large relative to that under the myopic policy. Our results are robust to a variety of alternative model specifications. Funding: J. Lu gratefully acknowledges financial support from Natural Science Foundation of China (NSFC) [Project 72192805]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/moor.2021.0179 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0179},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1192-1222},
  shortjournal = {Math. Oper. Res.},
  title        = {Managing customer churn via service mode control},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probabilistic bounds on the k-traveling salesman problem and
the traveling repairman problem. <em>MOOR</em>, <em>49</em>(2),
1169–1191. (<a href="https://doi.org/10.1287/moor.2021.0286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k - traveling salesman problem ( k -TSP) seeks a tour of minimal length that visits a subset of k ≤ n points. The traveling repairman problem (TRP) seeks a complete tour with minimal latency. This paper provides constant-factor probabilistic approximations of both problems. We first show that the optimal length of the k -TSP path grows at a rate of Θ ( k / n k / ( 2 ( k − 1 ) ) ) . The proof provides a constant-factor approximation scheme, which solves a TSP in a high-concentration zone, leveraging large deviations of local concentrations. Then, we show that the optimal TRP latency grows at a rate of Θ ( n n ) . This result extends the classic Beardwood–Halton–Hammersley theorem to the TRP. Again, the proof provides a constant-factor approximation scheme, which visits zones by decreasing order of probability density. We discuss practical implications of this result in the design of transportation and logistics systems. Finally, we propose dedicated notions of fairness—randomized population-based fairness for the k -TSP and geographic fairness for the TRP—and give algorithms to balance efficiency and fairness. Funding: This work was partly supported by [Grant ONR N00014-18-1-2122] and the Singapore National Research Foundation through the Singapore–Massachusetts Institute of Technology Alliance for Research and Technology Centre for Future Urban Mobility. Supplemental Material: The e-companion is available at https://doi.org/10.1287/moor.2021.0286 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0286},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1169-1191},
  shortjournal = {Math. Oper. Res.},
  title        = {Probabilistic bounds on the k-traveling salesman problem and the traveling repairman problem},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimizing compositions of differences-of-convex functions
with smooth mappings. <em>MOOR</em>, <em>49</em>(2), 1140–1168. (<a
href="https://doi.org/10.1287/moor.2021.0258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the so-called DC (difference-of-convex functions) composite minimization problems (or DC composite programs ) whose objective function is a composition of a DC function with a continuously differentiable mapping. We first develop an algorithm named DC composite algorithm (DCCA in short) for unconstrained DC composite programs and further extend to DC composite programs with constraints of inclusion associated with a smooth mapping and a closed convex set. The convergence analysis of the proposed algorithms is investigated. Applications of DCCA for two different problems, computation of the numerical radius of a square matrix and minimization of composite energies, are presented.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0258},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1140-1168},
  shortjournal = {Math. Oper. Res.},
  title        = {Minimizing compositions of differences-of-convex functions with smooth mappings},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Satiation in fisher markets and approximation of nash social
welfare. <em>MOOR</em>, <em>49</em>(2), 1109–1139. (<a
href="https://doi.org/10.1287/moor.2019.0129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study linear Fisher markets with satiation. In these markets, sellers have earning limits , and buyers have utility limits . Beyond applications in economics, they arise in the context of maximizing Nash social welfare when allocating indivisible items to agents. In contrast to markets with either earning or utility limits, markets with both limits have not been studied before. They turn out to have fundamentally different properties. In general, the existence of competitive equilibria is not guaranteed. We identify a natural property of markets (termed money clearing ) that implies existence. We show that the set of equilibria is not always convex, answering a question posed in the literature. We design an FPTAS to compute an approximate equilibrium and prove that the problem of computing an exact equilibrium lies in the complexity class continuous local search ( CLS ; i.e., the intersection of polynomial local search ( PLS ) and polynomial parity arguments on directed graphs ( PPAD )). For a constant number of buyers or goods, we give a polynomial-time algorithm to compute an exact equilibrium. We show how (approximate) equilibria can be rounded and provide the first constant-factor approximation algorithm (with a factor of 2.404) for maximizing Nash social welfare when agents have capped linear (also known as budget-additive) valuations. Finally, we significantly improve the approximation hardness for additive valuations to 8 / 7 &gt; 1.069 . Funding: J. Garg was supported by the National Science Foundation [Grant CCF-1942321 (CAREER)]. M. Hoefer was supported by Deutsche Forschungsgemeinschaft [Grants Ho 3831/5-1, Ho 3831/6-1, and Ho 3831/7-1].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0129},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1109-1139},
  shortjournal = {Math. Oper. Res.},
  title        = {Satiation in fisher markets and approximation of nash social welfare},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zero-sum games and linear programming duality.
<em>MOOR</em>, <em>49</em>(2), 1091–1108. (<a
href="https://doi.org/10.1287/moor.2022.0149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimax theorem for zero-sum games is easily proved from the strong duality theorem of linear programming. For the converse direction, the standard proof by Dantzig is known to be incomplete. We explain and combine classical theorems about solving linear equations with nonnegative variables to give a correct alternative proof more directly than Adler. We also extend Dantzig’s game so that any max-min strategy gives either an optimal LP solution or shows that none exists.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0149},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1091-1108},
  shortjournal = {Math. Oper. Res.},
  title        = {Zero-sum games and linear programming duality},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nash equilibrium problems of polynomials. <em>MOOR</em>,
<em>49</em>(2), 1065–1090. (<a
href="https://doi.org/10.1287/moor.2022.0334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies Nash equilibrium problems that are given by polynomial functions. We formulate efficient polynomial optimization problems for computing Nash equilibria. The Moment-sum-of-squares relaxations are used to solve them. Under generic assumptions, the method can find a Nash equilibrium, if there is one. Moreover, it can find all Nash equilibria if there are finitely many ones of them. The method can also detect nonexistence if there is no Nash equilibrium. Funding: J. Nie was supported by the National Science Foundation [Grant DMS-2110780].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0334},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1065-1090},
  shortjournal = {Math. Oper. Res.},
  title        = {Nash equilibrium problems of polynomials},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quickest detection problems for ornstein–uhlenbeck
processes. <em>MOOR</em>, <em>49</em>(2), 1045–1064. (<a
href="https://doi.org/10.1287/moor.2021.0186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider an Ornstein–Uhlenbeck process that initially reverts to zero at a known mean-reversion rate β 0 , and then after some random/unobservable time, this mean-reversion rate is changed to β 1 . Assuming that the process is observed in real time, the problem is to detect when exactly this change occurs as accurately as possible. We solve this problem in the most uncertain scenario when the random/unobservable time is (i) exponentially distributed and (ii) independent from the process prior to the change of its mean-reversion rate. The solution is expressed in terms of a stopping time that minimises the probability of a false early detection and the expected delay of a missed late detection. Allowing for both positive and negative values of β 0 and β 1 (including zero), the problem and its solution embed many intuitive and practically interesting cases. For example, the detection of a mean-reverting process changing to a simple Brownian motion ( β 0 &gt; 0 and β 1 = 0 ) and vice versa ( β 0 = 0 and β 1 &gt; 0 ) finds a natural application to pairs trading in finance. The formulation also allows for the detection of a transient process becoming recurrent ( β 0 &lt; 0 and β 1 ≥ 0 ) as well as a recurrent process becoming transient ( β 0 ≥ 0 and β 1 &lt; 0 ). The resulting optimal stopping problem is inherently two-dimensional (because of a state-dependent signal-to-noise ratio), and various properties of its solution are established. In particular, we find the somewhat surprising fact that the optimal stopping boundary is an increasing function of the modulus of the observed process for all values of β 0 and β 1 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0186},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1045-1064},
  shortjournal = {Math. Oper. Res.},
  title        = {Quickest detection problems for Ornstein–Uhlenbeck processes},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast temporal decomposition procedure for long-horizon
nonlinear dynamic programming. <em>MOOR</em>, <em>49</em>(2), 1012–1044.
(<a href="https://doi.org/10.1287/moor.2023.1378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a fast temporal decomposition procedure for solving long-horizon nonlinear dynamic programs. The core of the procedure is sequential quadratic programming (SQP) that utilizes a differentiable exact augmented Lagrangian as the merit function. Within each SQP iteration, we approximately solve the Newton system using an overlapping temporal decomposition strategy. We show that the approximate search direction is still a descent direction of the augmented Lagrangian provided the overlap size and penalty parameters are suitably chosen, which allows us to establish the global convergence. Moreover, we show that a unit step size is accepted locally for the approximate search direction and further establish a uniform, local linear convergence over stages. This local convergence rate matches the rate of the recent Schwarz scheme (Na et al. 2022). However, the Schwarz scheme has to solve nonlinear subproblems to optimality in each iteration, whereas we only perform a single Newton step instead. Numerical experiments validate our theories and demonstrate the superiority of our method. Funding: This work was supported by the National Science Foundation [Grant CNS-1545046] and the U.S. Department of Energy, Office of Science, Office of Advanced Scientific Computing Research [Grant DE-AC02-06CH11347].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1378},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1012-1044},
  shortjournal = {Math. Oper. Res.},
  title        = {A fast temporal decomposition procedure for long-horizon nonlinear dynamic programming},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable computation of dynamic flow problems via
multimarginal graph-structured optimal transport. <em>MOOR</em>,
<em>49</em>(2), 986–1011. (<a
href="https://doi.org/10.1287/moor.2021.0148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we develop a new framework for dynamic network flow problems based on optimal transport theory. We show that the dynamic multicommodity minimum-cost network flow problem can be formulated as a multimarginal optimal transport problem, where the cost function and the constraints on the marginals are associated with a graph structure. By exploiting these structures and building on recent advances in optimal transport theory, we develop an efficient method for such entropy-regularized optimal transport problems. In particular, the graph structure is utilized to efficiently compute the projections needed in the corresponding Sinkhorn iterations, and we arrive at a scheme that is both highly computationally efficient and easy to implement. To illustrate the performance of our algorithm, we compare it with a state-of-the-art linear programming (LP) solver. We achieve good approximations to the solution at least one order of magnitude faster than the LP solver. Finally, we showcase the methodology on a traffic routing problem with a large number of commodities. Funding: This work was supported by KTH Digital Futures, Knut och Alice Wallenbergs Stiftelse [Grants KAW 2018.0349, KAW 2021.0274, the Wallenberg AI, Autonomous Systems and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation], Vetenskapsrådet [Grant 2020-03454], and the National Science Foundation [Grants 1942523 and 2206576].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0148},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {986-1011},
  shortjournal = {Math. Oper. Res.},
  title        = {Scalable computation of dynamic flow problems via multimarginal graph-structured optimal transport},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asymptotically optimal control of make-to-stock systems.
<em>MOOR</em>, <em>49</em>(2), 948–985. (<a
href="https://doi.org/10.1287/moor.2021.0161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider multiclass make-to-stock production/inventory systems in which the manager makes three decisions, including pricing, outsourcing, and scheduling, to maximize the long-run average profit. For a sequence of systems in the heavy-traffic regime, with linear or strictly convex holding/waiting cost functions, we propose a sequence of policies and establish its asymptotic optimality. Our proof combines the lower bound approach and a thorough steady-state analysis of the systems. We also establish general results on the existence and tightness of the stationary distributions of the state processes under a more general family of policies. Funding: X. Gao’s research is supported in part by the Hong Kong Research Grants Council [Grants 14201520, 14201421, and 14212522]. J. Huang’s research is supported in part by the Hong Kong Research Grants Council [Grants 14500819 and 14505820] and the National Natural Science Foundation of China [Grant 72222023].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0161},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {948-985},
  shortjournal = {Math. Oper. Res.},
  title        = {Asymptotically optimal control of make-to-stock systems},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimization fractional prophet inequalities for sequential
procurement. <em>MOOR</em>, <em>49</em>(2), 928–947. (<a
href="https://doi.org/10.1287/moor.2021.0173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a minimization variant on the classical prophet inequality with monomial cost functions. A firm would like to procure some fixed amount of a divisible commodity from sellers that arrive sequentially. Whenever a seller arrives, the seller’s cost function is revealed, and the firm chooses how much of the commodity to buy. We first show that if one restricts the set of distributions for the coefficients to a family of natural distributions that include, for example, the uniform and truncated normal distributions, then there is a thresholding policy that is asymptotically optimal in the number of sellers. We then compare two scenarios based on whether the firm has in-house production capabilities or not. We precisely compute the optimal algorithm’s competitive ratio when in-house production capabilities exist and for a special case when they do not. We show that the main advantage of the ability to produce the commodity in house is that it shields the firm from price spikes in worst-case scenarios. Funding: This work was supported by NSF Grants [CNS-2146814, CPS-2136197, CNS-2106403, NGSDI-2105648].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0173},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {928-947},
  shortjournal = {Math. Oper. Res.},
  title        = {Minimization fractional prophet inequalities for sequential procurement},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nontruthful position auctions are more robust to
misspecification. <em>MOOR</em>, <em>49</em>(2), 901–927. (<a
href="https://doi.org/10.1287/moor.2023.1380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the classical model of sponsored search due to Edelman et al. and Varian and examine how robust standard position auctions are to a misspecification of the position-dependent quality factors used by this model. We show that under both complete and incomplete information a nontruthful position auction admits an efficient equilibrium for a strictly broader range of parameter values than the Vickrey-Clarke-Groves (VCG) mechanism, which would be truthful if the parameters were specified correctly. Our result for complete information concerns the generalized second-price (GSP) mechanism and is driven by a detailed understanding of the Nash equilibrium polytopes of the VCG mechanism and the GSP mechanism. Our result for incomplete information concerns the generalized first-price (GFP) mechanism and uses a surprising connection between the unique candidate equilibrium bidding functions of the VCG mechanism and the GFP mechanism. Funding: F. Fischer was supported by the Engineering and Physical Sciences Research Council [Grant EP/T015187/1] and Einstein Stiftung Berlin.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1380},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {901-927},
  shortjournal = {Math. Oper. Res.},
  title        = {Nontruthful position auctions are more robust to misspecification},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stateful posted pricing with vanishing regret via dynamic
deterministic markov decision processes. <em>MOOR</em>, <em>49</em>(2),
880–900. (<a href="https://doi.org/10.1287/moor.2023.1375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An online problem called dynamic resource allocation with capacity constraints ( DRACC ) is introduced and studied in the realm of posted price mechanisms. This problem subsumes several applications of stateful pricing, including but not limited to posted prices for online job scheduling and matching over a dynamic bipartite graph. Because existing online learning techniques do not yield vanishing regret for this problem, we develop a novel online learning framework over deterministic Markov decision processes with dynamic state transition and reward functions. Following that, we prove, based on a reduction to the well-studied problem of online learning with switching costs, that if the Markov decision process admits a chasing oracle (i.e., an oracle that simulates any given policy from any initial state with bounded loss), then the online learning problem can be solved with vanishing regret. Our results for the DRACC problem and its applications are then obtained by devising (randomized and deterministic) chasing oracles that exploit the particular structure of these problems. Funding: The work of Y. Emek was supported in part by the Israel Science Foundation [Grant 1016/17]. The work of R. Lavi was partially supported by the Israel Science Foundation [Grant 2560/17] and the National Natural Science Foundation of China [Grant 2560/17]. The work of R. Niazadeh was supported by the University of Chicago Booth School of Business. The work of Y. Shi was partially supported at the Technion by the Council for Higher Education [fellowship], and at Shandong University by the Science Fund Program of Shandong Province for Distinguished Oversea Young Scholars [Grant 2023HWYQ-006].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1375},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {880-900},
  shortjournal = {Math. Oper. Res.},
  title        = {Stateful posted pricing with vanishing regret via dynamic deterministic markov decision processes},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secretaries with advice. <em>MOOR</em>, <em>49</em>(2),
856–879. (<a href="https://doi.org/10.1287/moor.2023.1384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The secretary problem is probably the purest model of decision making under uncertainty. In this paper, we ask which advice we can give the algorithm to improve its success probability. We propose a general model that unifies a broad range of problems: from the classic secretary problem with no advice to the variant where the quality of a secretary is drawn from a known distribution and the algorithm learns each candidate’s quality on arrival, more modern versions of advice in the form of samples, and a machine-learning inspired model where a classifier gives us a noisy signal about whether the current secretary is the best on the market. Our main technique is a factor-revealing linear program (LP) that captures all of these problems. We use this LP formulation to gain structural insight into the optimal policy. Using tools from linear programming, we present a tight analysis of optimal algorithms for secretaries with samples, optimal algorithms when secretaries’ qualities are drawn from a known distribution, and optimal algorithms for a new noisy binary advice model.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1384},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {856-879},
  shortjournal = {Math. Oper. Res.},
  title        = {Secretaries with advice},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified analysis of a class of proximal bundle methods for
solving hybrid convex composite optimization problems. <em>MOOR</em>,
<em>49</em>(2), 832–855. (<a
href="https://doi.org/10.1287/moor.2023.1372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a proximal bundle (PB) framework based on a generic bundle update scheme for solving the hybrid convex composite optimization (HCCO) problem and establishes a common iteration-complexity bound for any variant belonging to it. As a consequence, iteration-complexity bounds for three PB variants based on different bundle update schemes are obtained in the HCCO context for the first time and in a unified manner. Although two of the PB variants are universal (i.e., their implementations do not require parameters associated with the HCCO instance), the other newly (as far as the authors are aware) proposed one is not, but has the advantage that it generates simple—namely, one-cut—bundle models. The paper also presents a universal adaptive PB variant (which is not necessarily an instance of the framework) based on one-cut models and shows that its iteration-complexity is the same as the two aforementioned universal PB variants. Funding: Financial support from the Office of Naval Research [N00014-18-1-2077] and the Air Force Office of Scientific Research [Grant FA9550-22-1-0088] is gratefully acknowledged.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1372},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {832-855},
  shortjournal = {Math. Oper. Res.},
  title        = {A unified analysis of a class of proximal bundle methods for solving hybrid convex composite optimization problems},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simple characterization of supply correspondences.
<em>MOOR</em>, <em>49</em>(2), 826–831. (<a
href="https://doi.org/10.1287/moor.2023.1379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove that supply correspondences are characterized by two properties: the law of supply and being homogeneous of degree zero.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1379},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {826-831},
  shortjournal = {Math. Oper. Res.},
  title        = {A simple characterization of supply correspondences},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On geometric connections of embedded and quotient geometries
in riemannian fixed-rank matrix optimization. <em>MOOR</em>,
<em>49</em>(2), 782–825. (<a
href="https://doi.org/10.1287/moor.2023.1377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a general procedure for establishing the geometric landscape connections of a Riemannian optimization problem under the embedded and quotient geometries. By applying the general procedure to the fixed-rank positive semidefinite (PSD) and general matrix optimization, we establish an exact Riemannian gradient connection under two geometries at every point on the manifold and sandwich inequalities between the spectra of Riemannian Hessians at Riemannian first-order stationary points (FOSPs). These results immediately imply an equivalence on the sets of Riemannian FOSPs, Riemannian second-order stationary points (SOSPs), and strict saddles of fixed-rank matrix optimization under the embedded and the quotient geometries. To the best of our knowledge, this is the first geometric landscape connection between the embedded and the quotient geometries for fixed-rank matrix optimization, and it provides a concrete example of how these two geometries are connected in Riemannian optimization. In addition, the effects of the Riemannian metric and quotient structure on the landscape connection are discussed. We also observe an algorithmic connection between two geometries with some specific Riemannian metrics in fixed-rank matrix optimization: there is an equivalence between gradient flows under two geometries with shared spectra of Riemannian Hessians. A number of novel ideas and technical ingredients—including a unified treatment for different Riemannian metrics, novel metrics for the Stiefel manifold, and new horizontal space representations under quotient geometries—are developed to obtain our results. The results in this paper deepen our understanding of geometric and algorithmic connections of Riemannian optimization under different Riemannian geometries and provide a few new theoretical insights to unanswered questions in the literature. Funding: X. Li was partially supported by National Key R&amp;D Program of China [Grants 2020YFA0711900, 2020YFA0711901], the National Natural Science Foundation of China [Grants 12271107, 62141407], the Young Elite Scientists Sponsorship Program by CAST [Grant 2019QNRC001], the “Chenguang Program” by the Shanghai Education Development Foundation and Shanghai Municipal Education Commission [Grant 19CG02], the Shanghai Science and Technology Program [21JC1400600]. Y. Luo and A. R. Zhang were partially supported by the National Science Foundation [CAREER-2203741].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1377},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {782-825},
  shortjournal = {Math. Oper. Res.},
  title        = {On geometric connections of embedded and quotient geometries in riemannian fixed-rank matrix optimization},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Numeraire-invariant quadratic hedging and mean–variance
portfolio allocation. <em>MOOR</em>, <em>49</em>(2), 752–781. (<a
href="https://doi.org/10.1287/moor.2023.1374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper investigates quadratic hedging in a semimartingale market that does not necessarily contain a risk-free asset. An equivalence result for hedging with and without numeraire change is established. This permits direct computation of the optimal strategy without choosing a reference asset and/or performing a numeraire change. New explicit expressions for optimal strategies are obtained, featuring the use of oblique projections that provide unified treatment of the case with and without a risk-free asset. The analysis yields a streamlined computation of the efficient frontier for the pure investment problem in terms of three easily interpreted processes. The main result advances our understanding of the efficient frontier formation in the most general case in which a risk-free asset may not be present. Several illustrations of the numeraire-invariant approach are given.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1374},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {752-781},
  shortjournal = {Math. Oper. Res.},
  title        = {Numeraire-invariant quadratic hedging and Mean–Variance portfolio allocation},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semismooth newton-type method for the nearest doubly
stochastic matrix problem. <em>MOOR</em>, <em>49</em>(2), 729–751. (<a
href="https://doi.org/10.1287/moor.2023.1382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a semismooth Newton-type method for the nearest doubly stochastic matrix problem where the nonsingularity of the Jacobian can fail. The optimality conditions for this problem are formulated as a system of strongly semismooth functions. We show that the nonsingularity of the Jacobian does not hold for this system. By exploiting the problem structure, we construct a modified two step semismooth Newton method that guarantees a nonsingular Jacobian matrix at each iteration, and that converges to the nearest doubly stochastic matrix quadratically. Funding: This work was supported by Canadian Network for Research and Innovation in Machining Technology. The research of H. Hu, H. Im, and H. Wolkowocz was supported by The Natural Sciences and Engineering Research Council of Canada. The research of X. Li was supported by the National Natural Science Foundation of China [No. 11601183] and Natural Science Foundation for Young Scientist of Jilin Province [No. 20180520212JH].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1382},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {729-751},
  shortjournal = {Math. Oper. Res.},
  title        = {A semismooth newton-type method for the nearest doubly stochastic matrix problem},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving optimization problems with blackwell
approachability. <em>MOOR</em>, <em>49</em>(2), 697–728. (<a
href="https://doi.org/10.1287/moor.2023.1376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new algorithm for solving convex-concave saddle-point problems using regret minimization in the repeated game framework. To do so, we introduce the Conic Blackwell Algorithm + ( CB A + ), a new parameter- and scale-free regret minimizer for general convex compact sets. CB A + is based on Blackwell approachability and attains O ( T ) regret. We show how to efficiently instantiate CB A + for many decision sets of interest, including the simplex, ℓ p norm balls, and ellipsoidal confidence regions in the simplex. Based on CB A + , we introduce SP-CB A + , a new parameter-free algorithm for solving convex-concave saddle-point problems achieving a O ( 1 / T ) ergodic convergence rate. In our simulations, we demonstrate the wide applicability of SP-CB A + on several standard saddle-point problems from the optimization and operations research literature, including matrix games, extensive-form games, distributionally robust logistic regression, and Markov decision processes. In each setting, SP-CB A + achieves state-of-the-art numerical performance and outperforms classical methods, without the need for any choice of step sizes or other algorithmic parameters. Funding: J. Grand-Clément is supported by the Agence Nationale de la Recherche [Grant 11-LABX-0047] and by Hi! Paris. C. Kroer is supported by the Office of Naval Research [Grant N00014-22-1-2530] and by the National Science Foundation [Grant IIS-2147361].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1376},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {697-728},
  shortjournal = {Math. Oper. Res.},
  title        = {Solving optimization problems with blackwell approachability},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large ranking games with diffusion control. <em>MOOR</em>,
<em>49</em>(2), 675–696. (<a
href="https://doi.org/10.1287/moor.2023.1373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a symmetric stochastic differential game where each player can control the diffusion intensity of an individual dynamic state process, and the players whose states at a deterministic finite time horizon are among the best α ∈ ( 0 , 1 ) of all states receive a fixed prize. Within the mean field limit version of the game, we compute an explicit equilibrium, a threshold strategy that consists of choosing the maximal fluctuation intensity when the state is below a given threshold and the minimal intensity otherwise. We show that for large n , the symmetric n -tuple of the threshold strategy provides an approximate Nash equilibrium of the n -player game. We also derive the rate at which the approximate equilibrium reward and the best-response reward converge to each other, as the number of players n tends to infinity. Finally, we compare the approximate equilibrium for large games with the equilibrium of the two-player case. Funding: Support from the Deutsche Forschungsgemeinschaft [Grant AN 1024/5-1] is acknowledged. The research of N. Kazi-Tani is supported by the Agence Nationale de la Recherche [Grant ANR-21-CE46-0002-03]. The research of C. Zhou is supported by the National Natural Science Foundation of China [Grant 11871364], the Singapore Ministry of Education [Grants A-8000453-00-00, A-0004273-00-00 and A-0004277-00-00] and the MERLION 2020 award [Grant A-0004589-00-00].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1373},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {675-696},
  shortjournal = {Math. Oper. Res.},
  title        = {Large ranking games with diffusion control},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combinatorial auctions with interdependent valuations: SOS
to the rescue. <em>MOOR</em>, <em>49</em>(2), 653–674. (<a
href="https://doi.org/10.1287/moor.2023.1371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study combinatorial auctions with interdependent valuations, where each agent i has a private signal s i that captures her private information and the valuation function of every agent depends on the entire signal profile, s = ( s 1 , … , s n ) . The literature in economics shows that the interdependent model gives rise to strong impossibility results and identifies assumptions under which optimal solutions can be attained. The computer science literature provides approximation results for simple single-parameter settings (mostly single-item auctions or matroid feasibility constraints). Both bodies of literature focus largely on valuations satisfying a technical condition termed single crossing (or variants thereof). We consider the class of submodular over signals (SOS) valuations (without imposing any single crossing-type assumption) and provide the first welfare approximation guarantees for multidimensional combinatorial auctions achieved by universally ex post incentive-compatible, individually rational mechanisms. Our main results are (i) four approximation for any single-parameter downward-closed setting with single-dimensional signals and SOS valuations; (ii) four approximation for any combinatorial auction with multidimensional signals and separable -SOS valuations; and (iii) ( k + 3) and (2 log( k ) + 4) approximation for any combinatorial auction with single-dimensional signals, with k -sized signal space, for SOS and strong-SOS valuations, respectively. All of our results extend to a parameterized version of SOS, d-approximate SOS , while losing a factor that depends on d . Funding: A. Eden was partially supported by NSF Award IIS-2007887, the European Research Council (ERC) under the European Union&#39;s Seventh Framework Programme [FP7/2007-2013]/ERC Grant Agreement 337122, by the Israel Science Foundation [Grant 317/17], and by an Amazon research award. M. Feldman received funding from the European Research Council (ERC) under the European Union&#39;s Horizon 2020 research and innovation program [Grant Agreement 866132], by the Israel Science Foundation [Grant 317/17], by an Amazon research award, and by the NSF-BSF [Grant 2020788]. The work of K. Goldner was supported partially by NSF awards DMS-1903037 and CNS-2228610 and a Shibulal Family Career Development Professorship. A. R. Karlin was supported by the NSF-CCF [Grant 1813135].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1371},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {653-674},
  shortjournal = {Math. Oper. Res.},
  title        = {Combinatorial auctions with interdependent valuations: SOS to the rescue},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural temporal difference and q learning provably converge
to global optima. <em>MOOR</em>, <em>49</em>(1), 619–651. (<a
href="https://doi.org/10.1287/moor.2023.1370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal difference learning (TD), coupled with neural networks, is among the most fundamental building blocks of deep reinforcement learning. However, because of the nonlinearity in value function approximation, such a coupling leads to nonconvexity and even divergence in optimization. As a result, the global convergence of neural TD remains unclear. In this paper, we prove for the first time that neural TD converges at a sublinear rate to the global optimum of the mean-squared projected Bellman error for policy evaluation. In particular, we show how such global convergence is enabled by the overparameterization of neural networks, which also plays a vital role in the empirical success of neural TD. We establish the theory for two-layer neural networks in the main paper and extend them to multilayer neural networks in the appendix. Beyond policy evaluation, we establish the global convergence of neural (soft) Q learning. Funding: Z. Yang acknowledges the Theory of Reinforceement Learning program at Simons Institute. J. D. Lee acknowledges support of the ARO under MURI Award W911NF-11-1-0304, the Sloan Research Fellowship, NSF CCF 2002272, NSF IIS 2107304, ONR Young Investigator Award, and NSF-CAREER under award #2144994. Z. Wang acknowledges National Science Foundation [Awards 2048075, 2008827, 2015568, 1934931], Simons Institute (Theory of Reinforcement Learning), Amazon, J.P. Morgan, and Two Sigma for their supports.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1370},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {619-651},
  shortjournal = {Math. Oper. Res.},
  title        = {Neural temporal difference and q learning provably converge to global optima},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distribution-free contextual dynamic pricing. <em>MOOR</em>,
<em>49</em>(1), 599–618. (<a
href="https://doi.org/10.1287/moor.2023.1369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contextual dynamic pricing aims to set personalized prices based on sequential interactions with customers. At each time period, a customer who is interested in purchasing a product comes to the platform. The customer’s valuation for the product is a linear function of contexts, including product and customer features, plus some random market noise. The seller does not observe the customer’s true valuation, but instead needs to learn the valuation by leveraging contextual information and historic binary purchase feedback. Existing models typically assume full or partial knowledge of the random noise distribution. In this paper, we consider contextual dynamic pricing with unknown random noise in the linear valuation model. Our distribution-free pricing policy learns both the contextual function and the market noise simultaneously. A key ingredient of our method is a novel perturbed linear bandit framework, in which a modified linear upper confidence bound algorithm is proposed to balance the exploration of market noise and the exploitation of the current knowledge for better pricing. We establish the regret upper bound and a matching lower bound of our policy in the perturbed linear bandit framework and prove a sublinear regret bound in the considered pricing problem. Finally, we demonstrate the superior performance of our policy on simulations and a real-life auto loan data set. Funding: Y. Liu and W.W. Sun acknowledge support from the National Science Foundation Division of Social and Economic Sciences [Grant NSF-SES 2217440]. Supplemental Material: The supplementary material is available at https://doi.org/10.1287/moor.2023.1369 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1369},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {599-618},
  shortjournal = {Math. Oper. Res.},
  title        = {Distribution-free contextual dynamic pricing},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximation algorithms and linear programming relaxations
for scheduling problems related to min-sum set cover. <em>MOOR</em>,
<em>49</em>(1), 578–598. (<a
href="https://doi.org/10.1287/moor.2023.1368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider single-machine scheduling problems that are natural generalizations or variations of the min-sum set-cover problem. For these scheduling problems, we give new approximation algorithms. Some of these algorithms rely on time-indexed linear programming relaxations. We show how a variant of alpha-point scheduling leads to the best known approximation ratios, including a guarantee of four for an interesting special case of the so-called generalized min-sum set-cover problem. We also make explicit the connection between the greedy algorithm for min-sum set cover and the concept of Sidney decomposition for precedence-constrained single-machine scheduling and show how this leads to a 4-approximation algorithm for single-machine scheduling with so-called bipartite OR-precedence constraints. Funding: This work has been supported by the Alexander von Humboldt Foundation with funds from the German Federal Ministry of Education and Research.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1368},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {578-598},
  shortjournal = {Math. Oper. Res.},
  title        = {Approximation algorithms and linear programming relaxations for scheduling problems related to min-sum set cover},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asymptotic optimality of constant-order policies in joint
pricing and inventory models. <em>MOOR</em>, <em>49</em>(1), 557–577.
(<a href="https://doi.org/10.1287/moor.2023.1367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a classic joint pricing and inventory control problem with lead times, which is extensively studied in the literature but is notoriously difficult to solve because of the complex structure of the optimal policy. In this work, rather than analyzing the optimal policy, we propose a class of constant-order dynamic pricing policies, which are fundamentally different from base-stock list price policies, the primary emphasis in the existing literature. Under such a policy, a constant-order amount of new inventory is ordered every period, and a pricing decision is made based on the inventory level. The policy is independent of the lead time. We prove that the best constant-order dynamic pricing policy is asymptotically optimal as the lead time grows large, which is exactly the setting in which the problem becomes computationally intractable because of the curse of dimensionality. As our main methodological contributions, we establish the convergence to a long-run average random yield inventory model with zero lead time and ordering capacities by its discounted counterpart as the discount factor goes to one, nontrivially extending the previous results in Federgruen and Yang that analyze a similar model but without capacity constraints. Funding: Research of X. Chen and L. Xin was partly supported by the National Science Foundation [Grant CMMI-1635160].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1367},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {557-577},
  shortjournal = {Math. Oper. Res.},
  title        = {Asymptotic optimality of constant-order policies in joint pricing and inventory models},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sensitivity analysis of the maximal value function with
applications in nonconvex minimax programs. <em>MOOR</em>,
<em>49</em>(1), 536–556. (<a
href="https://doi.org/10.1287/moor.2023.1366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we perform a sensitivity analysis for the maximal value function, which is the optimal value function for a parametric maximization problem. Our aim is to study various subdifferentials for the maximal value function. We obtain upper estimates of Fréchet, limiting, and horizon subdifferentials of the maximal value function by using some sensitivity analysis techniques sophisticatedly. The derived upper estimates depend only on the union of all solutions and not on its convex hull or only one solution from the solution set. Finally, we apply the derived results to develop some new necessary optimality conditions for nonconvex minimax problems. In the nonconvex-concave setting, our Wolfe duality approach compares favorably with the first-order approach in that the necessary condition is sharper and the constraint qualification is weaker. Funding: L. Guo was supported by the National Natural Science Foundation of China [Grants 72131007, 72140006, and 12271161] and the Natural Science Foundation of Shanghai [Grant 22ZR1415900]. J. J. Ye was partially supported by the Natural Sciences and Engineering Research Council of Canada. J. Zhang was supported by the National Natural Science Foundation of China [Grant 12222106], the Shenzhen Science and Technology Program [Grant RCYX20200714114700072], and the Guangdong Basic and Applied Basic Research Foundation [Grant 2022B1515020082].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1366},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {536-556},
  shortjournal = {Math. Oper. Res.},
  title        = {Sensitivity analysis of the maximal value function with applications in nonconvex minimax programs},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uniform mixed equilibria in network congestion games with
link failures. <em>MOOR</em>, <em>49</em>(1), 509–535. (<a
href="https://doi.org/10.1287/moor.2023.1365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by possible applications in fault-tolerant selfish routing, we introduce the notion of uniform mixed equilibrium in network congestion games with adversarial link failures, where agents need to route traffic from a source to a destination node. Given an integer ρ ≥ 1 , a ρ -uniform mixed strategy is a mixed strategy in which an agent plays exactly ρ edge-disjoint paths with uniform probability; therefore, a ρ -uniform mixed equilibrium is a tuple of ρ -uniform mixed strategies, one for each agent, in which no agent can lower her cost by deviating to another ρ -uniform mixed strategy. For games with weighted agents and affine latency functions, we show the existence of ρ -uniform mixed equilibria and provide a tight characterization of their price of anarchy. For games with unweighted agents, we extend the existential guarantee to any class of latency functions, and restricted to games with affine latencies, we derive a tight characterization of the price of anarchy and the price of stability. Funding: This work was partially supported by the INdAM-GNCS and the Italian MIUR PRIN 2017 Project ALGADIMAR “Algorithms, Games, and Digital Markets.”},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1365},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {509-535},
  shortjournal = {Math. Oper. Res.},
  title        = {Uniform mixed equilibria in network congestion games with link failures},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new approach to capacity scaling augmented with unreliable
machine learning predictions. <em>MOOR</em>, <em>49</em>(1), 476–508.
(<a href="https://doi.org/10.1287/moor.2023.1364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern data centers suffer from immense power consumption. As a result, data center operators have heavily invested in capacity-scaling solutions, which dynamically deactivate servers if the demand is low and activate them again when the workload increases. We analyze a continuous-time model for capacity scaling, where the goal is to minimize the weighted sum of flow time, switching cost, and power consumption in an online fashion. We propose a novel algorithm, called adaptive balanced capacity scaling (ABCS), that has access to black-box machine learning predictions. ABCS aims to adapt to the predictions and is also robust against unpredictable surges in the workload. In particular, we prove that ABCS is ( 1 + ε ) competitive if the predictions are accurate, and yet, it has a uniformly bounded competitive ratio even if the predictions are completely inaccurate. Finally, we investigate the performance of this algorithm on a real-world data set and carry out extensive numerical experiments, which positively support the theoretical results. Funding: This work was partially supported by the Division of Computing and Communication Foundations [Grant 2113027]. The authors also acknowledge financial support for this project from the Algorithm and Randomness Center–Transdisciplinary Research Institute for Advancing Data Science Fellowship at Georgia Tech.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1364},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {476-508},
  shortjournal = {Math. Oper. Res.},
  title        = {A new approach to capacity scaling augmented with unreliable machine learning predictions},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sample-driven optimal stopping: From the secretary problem
to the i.i.d. Prophet inequality. <em>MOOR</em>, <em>49</em>(1),
441–475. (<a href="https://doi.org/10.1287/moor.2023.1363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We take a unifying approach to single selection optimal stopping problems with random arrival order and independent sampling of items. In the problem we consider, a decision maker (DM) initially gets to sample each of N items independently with probability p , and can observe the relative rankings of these sampled items. Then, the DM faces the remaining items in an online fashion, observing the relative rankings of all revealed items. While scanning the sequence the DM makes irrevocable stop/continue decisions and her reward for stopping the sequence facing the item with rank i is Y i . The goal of the DM is to maximize her reward. We start by studying the case in which the values Y i are known to the DM, and then move to the case in which these values are adversarial. For the former case we are able to recover several classic results in the area, thus giving a unifying framework for single selection optimal stopping. For the latter, we pin down the optimal algorithm, obtaining the optimal competitive ratios for all values of p . Funding: This work was partially supported by The Center for Mathematical Modeling at the University of Chile (ANID FB210005), Grant Anillo Information and Computation in Market Design (ANID ACT210005), FONDECYT 1220054 and 1181180, and a Meta Research PhD Fellowship.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1363},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {441-475},
  shortjournal = {Math. Oper. Res.},
  title        = {Sample-driven optimal stopping: From the secretary problem to the i.i.d. prophet inequality},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constrained trading networks. <em>MOOR</em>, <em>49</em>(1),
430–440. (<a href="https://doi.org/10.1287/moor.2023.1362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trades based on bilateral (indivisible) contracts can be represented by a network. Vertices correspond to agents, whereas arcs represent the nonprice elements of a bilateral contract. Given prices for each arc, agents choose the incident arcs that maximize their utility. We enlarge the model to allow for polymatroidal constraints on the set of contracts that may be traded, which can be interpreted as modeling limited one-for-one substitution. We show that, for two-sided markets, there exists a competitive equilibrium; however, for multisided markets, this may not be possible. Funding: This work was supported by the Defense Advanced Research Projects Agency [Grant HR001118S0045].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1362},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {430-440},
  shortjournal = {Math. Oper. Res.},
  title        = {Constrained trading networks},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Algorithms for competitive division of chores.
<em>MOOR</em>, <em>49</em>(1), 398–429. (<a
href="https://doi.org/10.1287/moor.2023.1361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of allocating divisible bads (chores) among multiple agents with additive utilities when monetary transfers are not allowed. The competitive rule is known for its remarkable fairness and efficiency properties in the case of goods. This rule was extended to chores by Bogomolnaia, Moulin, Sandomirskiy, and Yanovskaya. For both goods and chores, the rule produces Pareto optimal and envy-free allocations. In the case of goods, the outcome of the competitive rule can be easily computed. Competitive allocations solve the Eisenberg-Gale convex program; hence the outcome is unique and can be approximately found by standard gradient methods. An exact algorithm that runs in polynomial time in the number of agents and goods was given by Orlin. In the case of chores, the competitive rule does not solve any convex optimization problem; instead, competitive allocations correspond to local minima, local maxima, and saddle points of the Nash social welfare on the Pareto frontier of the set of feasible utilities. The Pareto frontier may contain many such points and, consequently, the outcome of the competitive rule is no longer unique. In this paper, we show that all the outcomes of the competitive rule for chores can be computed in strongly polynomial time if either the number of agents or the number of chores is fixed. The approach is based on a combination of three ideas: all consumption graphs of Pareto optimal allocations can be listed in polynomial time; for a given consumption graph, a candidate for a competitive utility profile can be constructed via an explicit formula; each candidate can be checked for competitiveness and the allocation can be reconstructed using a maximum flow computation. Our algorithm immediately gives an approximately-fair allocation of indivisible chores by the rounding technique of Barman and Krishnamurthy. Funding: This work was supported by National Science Foundation (CNS 1518941); Lady Davis Fellowship Trust, Hebrew University of Jerusalem; H2020 European Research Council (740435); Linde Institute at Caltech.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1361},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {398-429},
  shortjournal = {Math. Oper. Res.},
  title        = {Algorithms for competitive division of chores},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dissolving constraints for riemannian optimization.
<em>MOOR</em>, <em>49</em>(1), 366–397. (<a
href="https://doi.org/10.1287/moor.2023.1360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider optimization problems over closed embedded submanifolds of R n , which are defined by the constraints c ( x ) = 0. We propose a class of constraint-dissolving approaches for these Riemannian optimization problems. In these proposed approaches, solving a Riemannian optimization problem is transferred into the unconstrained minimization of a constraint-dissolving function ( CDF ). Different from existing exact penalty functions, the exact gradient and Hessian of CDF are easy to compute. We study the theoretical properties of CDF and prove that the original problem and CDF have the same first-order and second-order stationary points, local minimizers, and Łojasiewicz exponents in a neighborhood of the feasible region. Remarkably, the convergence properties of our proposed constraint-dissolving approaches can be directly inherited from the existing rich results in unconstrained optimization. Therefore, the proposed constraint-dissolving approaches build up short cuts from unconstrained optimization to Riemannian optimization. Several illustrative examples further demonstrate the potential of our proposed constraint-dissolving approaches. Funding: The research of N. Xiao and K.-C. Toh is supported by the Ministry of Education of Singapore Academic Research Fund Tier 3 [Grant MOE-2019-T3-1-010]. The research of X. Liu is supported in part by the National Natural Science Foundation of China [Grants 12125108, 11971466, 12288201, 12021001, and 11991021]; the National Key R&amp;D Program of China [Grants 2020YFA0711900 and 2020YFA0711904]; and the Key Research Program of Frontier Sciences, Chinese Academy of Sciences [Grant ZDBS-LY-7022].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1360},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {366-397},
  shortjournal = {Math. Oper. Res.},
  title        = {Dissolving constraints for riemannian optimization},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the diameter of the stopped spider process.
<em>MOOR</em>, <em>49</em>(1), 346–365. (<a
href="https://doi.org/10.1287/moor.2023.1359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Brownian “spider process,” also known as Walsh Brownian motion, first introduced by J. B. Walsh [Walsh JB (1978) A diffusion with a discontinuous local time. Asterisque 52:37–45]. The paper provides the best constant C n for the inequality Funding: P. A. Ernst thanks the Royal Society Wolfson Fellowship (RSWF\R2\222005) and the U.S. Office of Naval Research (ONR N00014-21-1-2672) for their support of this research.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1359},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {346-365},
  shortjournal = {Math. Oper. Res.},
  title        = {On the diameter of the stopped spider process},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Delay-adaptive learning in generalized linear contextual
bandits. <em>MOOR</em>, <em>49</em>(1), 326–345. (<a
href="https://doi.org/10.1287/moor.2023.1358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider online learning in generalized linear contextual bandits where rewards are not immediately observed. Instead, rewards are available to the decision maker only after some delay, which is unknown and stochastic. Such delayed feedback occurs in several active learning settings, including product recommendation, personalized medical treatment selection, bidding in first-price auctions, and bond trading in over-the-counter markets. We study the performance of two well-known algorithms adapted to this delayed setting: one based on upper confidence bounds and the other based on Thompson sampling. We describe modifications on how these two algorithms should be adapted to handle delays and give regret characterizations for both algorithms. To the best of our knowledge, our regret bounds provide the first theoretical characterizations in generalized linear contextual bandits with large delays. Our results contribute to the broad landscape of contextual bandits literature by establishing that both algorithms can be made to be robust to delays, thereby helping clarify and reaffirm the empirical success of these two algorithms, which are widely deployed in modern recommendation engines. Funding: This work was supported by the National Science Foundation [Grants 2118199, 1915967, and CCF-2106508], the Air Force Office of Scientific Research [Award FA9550-20-1-0397], a Digital Twin research grant from Bain &amp; Company, and a faculty research grant from New York University’s Center for Global Economy and Business.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1358},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {326-345},
  shortjournal = {Math. Oper. Res.},
  title        = {Delay-adaptive learning in generalized linear contextual bandits},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assortment planning for recommendations at checkout under
inventory constraints. <em>MOOR</em>, <em>49</em>(1), 297–325. (<a
href="https://doi.org/10.1287/moor.2023.1357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a personalized assortment planning problem under inventory constraints, where each arriving customer type is defined by a primary item of interest. As long as that item is in stock, the customer adds it to the shopping cart, at which point the retailer can recommend to the customer an assortment of add-ons to go along with the primary item. This problem is motivated by the new “recommendation at checkout” systems that have been deployed at many online retailers, and it also serves as a framework that unifies many existing problems in online algorithms (e.g., personalized assortment planning, single-leg booking, and online matching with stochastic rewards). In our problem, add-on recommendation opportunities are eluded when primary items go out of stock, which poses additional challenges for the development of an online policy. We overcome these challenges by introducing the notion of an inventory protection level in expectation and derive an algorithm with a 1/4-competitive ratio guarantee under adversarial arrivals. Funding: This work was supported by the Adobe Data Science Research Award and the Alibaba Innovation Research Award. L. Xin was partly supported by the National Science Foundation (NSF) [Award CMMI-1635160], X. Chen was supported by the NSF [CAREER Award IIS-1845444]. W. Ma and D. Simchi-Levi were supported by the Accenture and MIT Alliance in Business Analytics.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1357},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {297-325},
  shortjournal = {Math. Oper. Res.},
  title        = {Assortment planning for recommendations at checkout under inventory constraints},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Naive feature selection: A nearly tight convex relaxation
for sparse naive bayes. <em>MOOR</em>, <em>49</em>(1), 278–296. (<a
href="https://doi.org/10.1287/moor.2023.1356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of its linear complexity, naive Bayes classification remains an attractive supervised learning method, especially in very large-scale settings. We propose a sparse version of naive Bayes, which can be used for feature selection. This leads to a combinatorial maximum-likelihood problem, for which we provide an exact solution in the case of binary data, or a bound in the multinomial case. We prove that our convex relaxation bounds become tight as the marginal contribution of additional features decreases using a priori duality gap bounds derived from the Shapley–Folkman theorem. We show how to produce primal solutions satisfying these bounds. Both binary and multinomial sparse models are solvable in time almost linear in problem size, representing a very small extra relative cost compared with the classical naive Bayes. Numerical experiments on text data show that the naive Bayes feature selection method is as statistically effective as state-of-the-art feature selection methods such as recursive feature elimination, l 1 -penalized logistic regression, and LASSO while being orders of magnitude faster (a python implementation can be found at https://github.com/aspremon/NaiveFeatureSelection ). Funding: A. d’Aspremont acknowledges support from the Fonds AXA Pour la Recherche and Kamet Ventures [Machine Learning and Optimisation Joint Research Initiative] and a Google-focused award as well as funding from Agence Nationale de la Recherche [Grant ANR-19-P3IA-0001]. L. El Ghaoui acknowledges support from Berkeley Artificial Intelligence Research and the Tsinghua–Berkeley–Shenzhen Institute.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1356},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {278-296},
  shortjournal = {Math. Oper. Res.},
  title        = {Naive feature selection: A nearly tight convex relaxation for sparse naive bayes},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A geometric model of opinion polarization. <em>MOOR</em>,
<em>49</em>(1), 251–277. (<a
href="https://doi.org/10.1287/moor.2023.1355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a simple geometric model of opinion polarization. It is a model of political persuasion as well as marketing and advertising, utilizing social values. It focuses on the interplay between different topics and persuasion efforts. We demonstrate that societal opinion polarization often arises as an unintended by-product of influencers attempting to promote a product or idea. We discuss a number of mechanisms for the emergence of polarization involving one or more influencers, sending messages strategically, heuristically, or randomly. We also examine some computational aspects of choosing the most effective means of influencing agents and the effects of those strategic considerations on polarization. Funding: J. Hązła was partially supported by the National Science Foundation [Grant DMS-1737944] and later, the Alexander von Humboldt Foundation [African Institute for Mathematical Sciences Rwanda research chair funding] as well as the German Academic Exchange Service (DAAD) [grant in cooperation with Goethe University in Frankfurt]. Y. Jin was partially supported by the Department of Defense [Grant ARO MURI W911NF1910217]. E. Mossel was partially supported by the Simons Investigator in Mathematics [Award 622132], the National Science Foundation [Awards DMS-1737944 and CCF-1918421] and the Department of Defense [Grant ARO MURI W911NF1910217] and Vannevar Bush [Faculty Fellowship ONR-N00014-20-1-2826]. G. Ramnarayan was partially supported by the National Science Foundation [Grant DMS-1737944] and the Department of Defense [Grant ARO MURI W911NF1910217].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1355},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {251-277},
  shortjournal = {Math. Oper. Res.},
  title        = {A geometric model of opinion polarization},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uniqueness of clearing payment matrices in financial
networks. <em>MOOR</em>, <em>49</em>(1), 232–250. (<a
href="https://doi.org/10.1287/moor.2023.1354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study bankruptcy problems in financial networks in the presence of general bankruptcy laws. The set of clearing payment matrices is shown to be a lattice, which guarantees the existence of a greatest clearing payment and a least clearing payment. Multiplicity of clearing payment matrices is both a theoretical and a practical concern. We present a new condition for uniqueness that generalizes all the existing conditions proposed in the literature. Our condition depends on the decomposition of the financial network into strongly connected components. A strongly connected component that contains more than one agent is called a cycle, and the involved agents are called cyclical agents. If there is a cycle without successors, then one of the agents in such a cycle should have a strictly positive endowment. The division rule used by a cyclical agent with a strictly positive endowment should be positive monotonic, and the rule used by a cyclical agent with a zero endowment should be strictly monotonic. Because division rules involving priorities are not positive monotonic, uniqueness of the clearing payment matrix is a much bigger concern for such division rules than for proportional ones. As a final contribution of the paper, we exhibit the relationship between the uniqueness of clearing payment matrices and the continuity of bankruptcy rules, a property that is very much desired for stability of financial systems. Funding: This research was supported by the Higher Education Institutional Excellence Program 2020 of the Ministry of Innovation and Technology in the framework of the “Financial and Public Services” research project [Grant TKP2020-IKA-02] at Corvinus University of Budapest. P. Csóka received funding from the National Research, Development and Innovation Office [Grants K-120035 and K-138826].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1354},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {232-250},
  shortjournal = {Math. Oper. Res.},
  title        = {Uniqueness of clearing payment matrices in financial networks},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An oblivious ellipsoid algorithm for solving a system of
(in)feasible linear inequalities. <em>MOOR</em>, <em>49</em>(1),
204–231. (<a href="https://doi.org/10.1287/moor.2023.1353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ellipsoid algorithm is a fundamental algorithm for computing a solution to the system of m linear inequalities in n variables ( P ) : A ⊤ x ≤ u when its set of solutions has positive volume. However, when ( P ) is infeasible, the ellipsoid algorithm has no mechanism for proving that ( P ) is infeasible. This is in contrast to the other two fundamental algorithms for tackling ( P ) , namely, the simplex and interior-point methods, each of which can be easily implemented in a way that either produces a solution of ( P ) or proves that ( P ) is infeasible by producing a solution to the alternative system ( Alt ) : A λ = 0 , u ⊤ λ &lt; 0 , λ ≥ 0 . This paper develops an oblivious ellipsoid algorithm (OEA) that either produces a solution of ( P ) or produces a solution of ( Alt ) . Depending on the dimensions and other condition measures, the computational complexity of the basic OEA may be worse than, the same as, or better than that of the standard ellipsoid algorithm. We also present two modified versions of OEA, whose computational complexity is superior to that of OEA when n ≪ m . This is achieved in the first modified version by proving infeasibility without producing a solution of ( Alt ) , and in the second version by using more memory. Funding: J. Lamperski and R. M. Freund were supported by the Air Force Office of Scientific Research [Grant FA9550-19-1-0240].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1353},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {204-231},
  shortjournal = {Math. Oper. Res.},
  title        = {An oblivious ellipsoid algorithm for solving a system of (In)Feasible linear inequalities},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bilateral trade: A regret minimization perspective.
<em>MOOR</em>, <em>49</em>(1), 171–203. (<a
href="https://doi.org/10.1287/moor.2023.1351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilateral trade, a fundamental topic in economics, models the problem of intermediating between two strategic agents, a seller and a buyer, willing to trade a good for which they hold private valuations. In this paper, we cast the bilateral trade problem in a regret minimization framework over T rounds of seller/buyer interactions, with no prior knowledge on their private valuations. Our main contribution is a complete characterization of the regret regimes for fixed-price mechanisms with different feedback models and private valuations, using as a benchmark the best fixed price in hindsight. More precisely, we prove the following tight bounds on the regret: Funding: This work was partially supported by the European Research Council Advanced [Grant 788893] AMDROMA “Algorithmic and Mechanism Design Research in Online Markets”, the Ministero dell’Istruzione, dell’Università e della Ricerca PRIN project ALGADIMAR “Algorithms, Games, and Digital Markets”, the AI Interdisciplinary Institute ANITI (funded by the French “Investing for the Future—PIA3” program under the [Grant agreement ANR-19-PI3A-0004], the project BOLD from the French national research agency (ANR), the EU Horizon 2020 ICT-48 research and innovation action ELISE (European Learning and Intelligent Systems Excellence, [Grant agreement 951847].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1351},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {171-203},
  shortjournal = {Math. Oper. Res.},
  title        = {Bilateral trade: A regret minimization perspective},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Packing feedback arc sets in tournaments exactly.
<em>MOOR</em>, <em>49</em>(1), 151–170. (<a
href="https://doi.org/10.1287/moor.2023.1352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let T = ( V , A ) be a tournament with a nonnegative integral weight w ( e ) on each arc e . A subset F of arcs is called a feedback arc set (FAS) if T \ F contains no cycles (directed). A collection F of FASs (with repetition allowed) is called an FAS packing if each arc e is used at most w ( e ) times by the members of F . The purpose of this paper is to give a characterization of all tournaments T = ( V , A ) with the property that, for every nonnegative integral weight function w defined on A , the minimum total weight of a cycle is equal to the maximum size of an FAS packing. Funding: This work was supported by the National Natural Science Foundation of China [Grants 11801266 and 11971228]; the Chinese Academy of Sciences [Grants XDA27000000 and ZDBS-LY-7008]; the Ministry of Science and Technology of China [Grant 2018AAA0101002]; the Research Grants Council of Hong Kong; the Fundamental Research Funds for the Central Universities [Grant 020314380035].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.1352},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {151-170},
  shortjournal = {Math. Oper. Res.},
  title        = {Packing feedback arc sets in tournaments exactly},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A first-order primal-dual method for nonconvex constrained
optimization based on the augmented lagrangian. <em>MOOR</em>,
<em>49</em>(1), 125–150. (<a
href="https://doi.org/10.1287/moor.2022.1350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinearly constrained nonconvex and nonsmooth optimization models play an increasingly important role in machine learning, statistics, and data analytics. In this paper, based on the augmented Lagrangian function, we introduce a flexible first-order primal-dual method, to be called nonconvex auxiliary problem principle of augmented Lagrangian (NAPP-AL), for solving a class of nonlinearly constrained nonconvex and nonsmooth optimization problems. We demonstrate that NAPP-AL converges to a stationary solution at the rate of o ( 1 / k ) , where k is the number of iterations. Moreover, under an additional error bound condition (to be called HVP-EB in the paper) with exponent θ ∈ ( 0 , 1 ) , we further show the global convergence of NAPP-AL. Additionally, if θ ∈ ( 0 , 1 2 ] , then we furthermore show that the convergence rate is in fact linear. Finally, we show that the well-known Kurdyka-Łojasiewicz property and the Hölderian metric subregularity imply the aforementioned HVP-EB condition. We demonstrate that under mild conditions, NAPP-AL can also be interpreted as a variant of the forward-backward operator splitting method in this context. Funding: This work was supported by the National Natural Science Foundation of China [Grant 71871140].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.1350},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {125-150},
  shortjournal = {Math. Oper. Res.},
  title        = {A first-order primal-dual method for nonconvex constrained optimization based on the augmented lagrangian},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online generalized network design under (dis)economies of
scale. <em>MOOR</em>, <em>49</em>(1), 107–124. (<a
href="https://doi.org/10.1287/moor.2022.1349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a general online network design problem in which a sequence of N requests arrive over time, each of which needs to use some subset of the available resources E . The cost incurred by a resource e ∈ E is some function f e of the total load ℓ e on that resource. The objective is to minimize the total cost ∑ e ∈ E f e ( ℓ e ) . We focus on cost functions that exhibit (dis)economies of scale. These functions are of the form f e ( x ) = σ e + ξ e · x α e if x &gt; 0 (and zero if x = 0), in which the exponent α e ≥ 1 . Optimization problems under these functions have received significant recent attention because of applications in energy-efficient computing. Our main result is a deterministic online algorithm with tight competitive ratio Θ ( max e ∈ E ( σ e ξ e ) 1 / α e ) when α e is constant for all e ∈ E . This framework is applicable to a variety of network design problems in undirected and directed graphs, including multicommodity routing, Steiner tree/forest connectivity, and set connectivity. In fact, our online competitive ratio even matches the previous best (offline) approximation ratio. We also demonstrate the practical performance of our online algorithm on instances of multicommodity routing. Funding: This work was supported by the Directorate for Computer and Information Science and Engineering [Grant CCF-1750127] and the Division of Civil, Mechanical and Manufacturing Innovation [Grant CMMI-1940766].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.1349},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {107-124},
  shortjournal = {Math. Oper. Res.},
  title        = {Online generalized network design under (Dis)Economies of scale},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constrained information design. <em>MOOR</em>,
<em>49</em>(1), 78–106. (<a
href="https://doi.org/10.1287/moor.2022.1346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide tools to analyze information design problems subject to constraints. We do so by extending an insight by Le Treust and Tomala to the case of multiple inequality and equality constraints. Namely, that an information design problem subject to constraints can be represented as an unconstrained information design problem with additional states, one for each constraint. Thus, without loss of generality, optimal solutions induce as many posteriors as the number of states and constraints. We provide results that refine this upper bound. Furthermore, we provide conditions under which there is no duality gap in constrained information design, thus validating a Lagrangian approach. We illustrate our results with applications to mechanism design with limited commitment and persuasion of a privately informed receiver. Funding: L. Doval acknowledges the support of the National Science Foundation through [Grant SES-2131706]. V. Skreta acknowledges the support from the National Science Foundation through [Grant SES-1851729] and from the European Research Council (ERC) through consolidator [Grant 682417]. Supplemental Material: The e-companion is available at https://doi.org/10.1287/moor.2022.1346 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.1346},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {78-106},
  shortjournal = {Math. Oper. Res.},
  title        = {Constrained information design},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the douglas–rachford algorithm for solving possibly
inconsistent optimization problems. <em>MOOR</em>, <em>49</em>(1),
58–77. (<a href="https://doi.org/10.1287/moor.2022.1347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More than 40 years ago, Lions and Mercier introduced in a seminal paper the Douglas–Rachford algorithm. Today, this method is well-recognized as a classic and highly successful splitting method to find minimizers of the sum of two (not necessarily smooth) convex functions. Whereas the underlying theory has matured, one case remains a mystery: the behavior of the shadow sequence when the given functions have disjoint domains. Building on previous work, we establish for the first time weak and value convergence of the shadow sequence generated by the Douglas–Rachford algorithm in a setting of unprecedented generality. The weak limit point is shown to solve the associated normal problem, which is a minimal perturbation of the original optimization problem. We also present new results on the geometry of the minimal displacement vector. Funding: The research of H. H. Bauschke and W. M. Moursi was partially supported by Discovery Grants of the Natural Sciences and Engineering Research Council of Canada [Grants RGPIN-2018-03703 and RGPIN-2019-04803], respectively.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.1347},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {58-77},
  shortjournal = {Math. Oper. Res.},
  title        = {On the Douglas–Rachford algorithm for solving possibly inconsistent optimization problems},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conditional uniformity and hawkes processes. <em>MOOR</em>,
<em>49</em>(1), 40–57. (<a
href="https://doi.org/10.1287/moor.2022.1348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classic results show that the Hawkes self-exciting point process can be viewed as a collection of temporal clusters, in which exogenously generated initial events give rise to endogenously driven descendant events. This perspective provides the distribution of a cluster’s size through a natural connection to branching processes, but this is irrespective of time. Insight into the chronology of a Hawkes process cluster has been much more elusive. Here, we employ this cluster perspective and a novel adaptation of the random time change theorem to establish an analog of the conditional uniformity property enjoyed by Poisson processes. Conditional on the number of epochs in a cluster, we show that the transformed times are jointly uniform within a particular convex polytope. Furthermore, we find that this polytope leads to a surprising connection between these continuous state clusters and parking functions, discrete objects central in enumerative combinatorics and closely related to Dyck paths on the lattice. In particular, we show that uniformly random parking functions constitute hidden spines within Hawkes process clusters. This yields a decomposition that is valuable both methodologically and practically, which we demonstrate through application to the popular Markovian Hawkes model and proposal of a flexible and efficient simulation algorithm.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.1348},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {40-57},
  shortjournal = {Math. Oper. Res.},
  title        = {Conditional uniformity and hawkes processes},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A feasible method for solving an SDP relaxation of the
quadratic knapsack problem. <em>MOOR</em>, <em>49</em>(1), 19–39. (<a
href="https://doi.org/10.1287/moor.2022.1345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a semidefinite programming (SDP) relaxation of the quadratic knapsack problem. After applying low-rank factorization, we get a nonconvex problem, whose feasible region is an algebraic variety with certain good geometric properties, which we analyze. We derive a rank condition under which these two formulations are equivalent. This rank condition is much weaker than the classical rank condition if the coefficient matrix has certain special structures. We also prove that, under an appropriate rank condition, the nonconvex problem has no spurious local minima without assuming linearly independent constraint qualification. We design a feasible method that can escape from nonoptimal nonregular points. Numerical experiments are conducted to verify the high efficiency and robustness of our algorithm as compared with other solvers. In particular, our algorithm is able to solve a one-million-dimensional sparse SDP problem accurately in about 20 minutes on a modest computer. Funding: The research of K.-C. Toh is supported by the Ministry of Education, Singapore, under its Academic Research Fund Tier 3 grant call [Grant MOE-2019-T3-1-010].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.1345},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {19-39},
  shortjournal = {Math. Oper. Res.},
  title        = {A feasible method for solving an SDP relaxation of the quadratic knapsack problem},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Error analysis of surrogate models constructed through
operations on submodels. <em>MOOR</em>, <em>49</em>(1), 1–18. (<a
href="https://doi.org/10.1287/moor.2022.1344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based methods are popular in derivative-free optimization (DFO). In most of them, a single model function is built to approximate the objective function. This is generally based on the assumption that the objective function is one black box. However, some real-life and theoretical problems show that the objective function may consist of several black boxes. In those problems, the information provided by each black box may not be equal. In this situation, one can build multiple submodels that are then combined to become a final model. In this paper, we analyze the relation between the accuracy of those submodels and the model constructed through their operations. We develop a broad framework that can be used as a theoretical tool in model error analysis and future research in DFO algorithm design. Funding: Y. Chen’s research is partially funded by the MITACS Globalink program. All authors research partially supported by NSERC of Canada Discovery [Grant 2018-03865].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.1344},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Math. Oper. Res.},
  title        = {Error analysis of surrogate models constructed through operations on submodels},
  volume       = {49},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
