<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJOC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijoc---91">IJOC - 91</h2>
<ul>
<li><details>
<summary>
(2024). Feasibility verification and upper bound computation in
global minimization using approximate active index sets. <em>IJOC</em>,
<em>36</em>(6), 1737–1756. (<a
href="https://doi.org/10.1287/ijoc.2023.0162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new upper bounding procedure for global minimization problems with continuous variables and possibly nonconvex inequality and equality constraints. Upper bounds are crucial for standard termination criteria of spatial branch-and-bound (SBB) algorithms to ensure that they can enclose globally minimal values sufficiently well. However, whereas for most lower bounding procedures from the literature, convergence on smaller boxes is established, this does not hold for several methods to compute upper bounds even though they often perform well in practice. In contrast, our emphasis is on the convergence. We present a new approach to verify the existence of feasible points on boxes, on which upper bounds can then be determined. To this end, we resort to existing convergent feasibility verification approaches for purely equality and box constrained problems. By considering carefully designed modifications of subproblems based on the approximation of active index sets, we enhance such methods to problems with additional inequality constraints. We prove that our new upper bounding procedure finds sufficiently good upper bounds so that termination of SBB algorithms is guaranteed after a finite number of iterations. Our theoretical findings are illustrated by computational results on a large number of standard test problems. These results show that compared with interval Newton methods from the literature, our proposed method is more successful in feasibility verification for both, a full SBB implementation (42 instead of 26 test problems) and exhaustive sequences of boxes around known feasible points (120 instead of 29 test problems). History: Accepted by Antonio Frangioni, Area Editor for Design &amp; Analysis of Algorithms–Continuous. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0162 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0162 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0162},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1737-1756},
  shortjournal = {INFORMS J. Comput.},
  title        = {Feasibility verification and upper bound computation in global minimization using approximate active index sets},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A graph-based approach for relating integer programs.
<em>IJOC</em>, <em>36</em>(6), 1715–1736. (<a
href="https://doi.org/10.1287/ijoc.2023.0255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework for classifying and comparing instances of integer linear programs (ILPs) based on their mathematical structure. It has long been observed that the structure of ILPs can play an important role in determining the effectiveness of certain solution techniques; those that work well for one class of ILPs are often found to be effective in solving similarly structured problems. In this work, the structure of a given ILP instance is captured via a graph-based representation, where decision variables and constraints are described by nodes, and edges denote the presence of decision variables in certain constraints. Using machine learning techniques for graph-structured data, we introduce two approaches for leveraging the graph representations for relating ILPs. In the first approach, a graph convolutional network (GCN) is used to classify ILP graphs as having come from one of a known number of problem classes. The second approach makes use of latent features learned by the GCN to compare ILP graphs to one another directly. As part of the latter approach, we introduce a formal measure of graph-based structural similarity. A series of empirical studies indicate strong performance for both the classification and comparison procedures. Additional properties of ILP graphs, namely, losslessness and permutation invariance, are also explored via computational experiments. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0255 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0255 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0255},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1715-1736},
  shortjournal = {INFORMS J. Comput.},
  title        = {A graph-based approach for relating integer programs},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A flow-based formulation for parallel machine scheduling
using decision diagrams. <em>IJOC</em>, <em>36</em>(6), 1696–1714. (<a
href="https://doi.org/10.1287/ijoc.2022.0301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new flow-based formulation for identical parallel machine scheduling with a regular objective function and without idle time. The formulation is constructed with the help of a decision diagram that represents all job sequences that respect specific ordering rules. These rules rely on a partition of the planning horizon into, generally nonuniform, periods and do not exclude all optimal solutions, but they constrain solutions to adhere to a canonical form. The new formulation has numerous variables and constraints, and hence we apply a Dantzig-Wolfe decomposition to compute the linear programming relaxation in reasonable time; the resulting lower bound is stronger than the bound from the classical time-indexed formulation. We develop a branch-and-price framework that solves three instances from the literature for the first time. We compare the new formulation with the time-indexed and arc time–indexed formulation by means of a series of computational experiments. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms—Discrete. Funding: This work was partially funded by the European Union’s Horizon 2020 research and innovation program under [Marie Skłodowska-Curie Grant 754462]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0301 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0301 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0301},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1696-1714},
  shortjournal = {INFORMS J. Comput.},
  title        = {A flow-based formulation for parallel machine scheduling using decision diagrams},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The continuous time-resource trade-off scheduling problem
with time windows. <em>IJOC</em>, <em>36</em>(6), 1676–1695. (<a
href="https://doi.org/10.1287/ijoc.2022.0142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a variant of the cumulative scheduling problem (CuSP) characterized by continuous modes, time windows, and a criterion that involves safety margin maximization. The study of this variant is motivated by the Geospatial based Environment for Optimisation Systems Addressing Fire Emergencies Horizon 2020 Project, which is devoted to the design of evacuation plans in the face of natural disasters and more specifically, wildfire. People and goods have to be transferred from endangered places to safe places, and evacuation planning consists of scheduling evacuee moves along precomputed paths under arc capacities and deadlines. The resulting model is relevant in other contexts, such as project or industrial process scheduling. We consider here several formulations of the continuous time-resource trade-off scheduling problem (CTRTP-TW) with a safety maximization objective. We establish a complete complexity characterization distinguishing polynomial and NP-hard special cases depending on key parameters. We show that the problem with fixed sequencing (i.e., with predetermined overlap or precedence relations between activities) is convex. We then show that the preemptive variant is polynomial, and we propose lower and upper bounds based on this relaxation. A flow-based mixed-integer linear programming formulation is presented, from which a branch-and-cut exact method and an insertion heuristic are derived. An exact dedicated branch-and-bound algorithm is also designed. Extensive computational experiments are carried out to compare the different approaches on evacuation planning instances and on general CTRTP-TW instances. The experiments also show the interest of the continuous model compared with a previously proposed discrete approximation. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms—Discrete. Funding: This work was funded by the Horizon 2020 Marie Skłodowska-Curie Research and Innovation Staff Exchange European Project 691161 GEO-SAFE (Geospatial based Environment for Optimisation Systems Addressing Fire Emergencie). This work has also been supported by ANITI, the Artificial and Natural Intelligence Toulouse Institute. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0142 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0142 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0142},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1676-1695},
  shortjournal = {INFORMS J. Comput.},
  title        = {The continuous time-resource trade-off scheduling problem with time windows},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rescheduling with new orders under bounded disruption.
<em>IJOC</em>, <em>36</em>(6), 1654–1675. (<a
href="https://doi.org/10.1287/ijoc.2023.0038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rescheduling problems arise when unpredicted events occur, such as the arrival of new orders. These new jobs should be integrated in a proper way in the existing schedule of the so-called old jobs, with the aim of minimizing an objective function for the joint set of jobs. To avoid a major disruption of the original schedule, each old job is not allowed to deviate from its original completion time by more than a certain threshold. Filling a gap in the existing literature, we consider the minimization of the total weighted completion time. The resulting rescheduling problem is shown to be weakly NP-hard and several properties of the structure of an optimal schedule are derived. These can be used for the construction of an exact dynamic programming algorithm with pseudo-polynomial running time. A fully polynomial time approximation scheme is obtained from the dynamic program by three different scaling and reduction steps. Finally, for the minimization of the number of late jobs a strong NP-hardness result is derived. History: Accepted by Erwin Pesch, Area Editor for Heuristic Search &amp; Approximation Algorithms. Funding: This work was partially supported by the Ministero dell’Istruzione, dell’Università e della Ricerca [Award TESUN-83486178370409 finanziamento dipartimenti di eccellenza CAP. 1694 TIT. 232 ART. 6]. U. Pferschy acknowledges support by the Field of Excellence COLIBRI at the University of Graz.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0038},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1654-1675},
  shortjournal = {INFORMS J. Comput.},
  title        = {Rescheduling with new orders under bounded disruption},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computing bipath multicommodity flows with constraint
programming–based branch-and-price-and-cut. <em>IJOC</em>,
<em>36</em>(6), 1634–1653. (<a
href="https://doi.org/10.1287/ijoc.2023.0128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a constraint programming (CP)–based branch-and-price-and-cut framework to exactly solve bipath multicommodity flow (MCF): an MCF problem with two paths for each demand. The goal is to route demands in a capacitated network under the minimum cost. The two paths must have disjoint arcs, and the delays accumulated along the two paths must be within a small deviation of each other. CP is used at multiple points in this framework: for solving pricing problems, for cut generation, and for primal and branching node heuristics. These modules use a CP solver designed for network routing problems and can be adapted to other combinatorial optimization problems. We also develop a novel, complete, two-level branching scheme. On a set of diverse bipath MCF instances, experimental results show that our algorithm significantly outperforms monolithic CP and mixed integer linear programming models and demonstrate the efficiency and flexibility brought by the tailored integration of linear programming and CP methodologies. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Funding: This work was supported by the Natural Sciences and Engineering Research Council of Canada; Huawei Technologies. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0128 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0128 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0128},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1634-1653},
  shortjournal = {INFORMS J. Comput.},
  title        = {Computing bipath multicommodity flows with constraint Programming–Based branch-and-price-and-cut},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence rates of zeroth order gradient descent for
łojasiewicz functions. <em>IJOC</em>, <em>36</em>(6), 1611–1633. (<a
href="https://doi.org/10.1287/ijoc.2023.0247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove convergence rates of Zeroth-order Gradient Descent (ZGD) algorithms for Łojasiewicz functions. Our results show that for smooth Łojasiewicz functions with Łojasiewicz exponent larger than 0.5 and smaller than 1, the functions values can converge much faster than the (zeroth-order) gradient descent trajectory. Similar results hold for convex nonsmooth Łojasiewicz functions. History: Accepted by Antonio Frangioni, Area Editor for Design &amp; Analysis of Algorithms–Continuous. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0247 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0247 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0247},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1611-1633},
  shortjournal = {INFORMS J. Comput.},
  title        = {Convergence rates of zeroth order gradient descent for Łojasiewicz functions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computing optimality certificates for convex mixed-integer
nonlinear problems. <em>IJOC</em>, <em>36</em>(6), 1579–1610. (<a
href="https://doi.org/10.1287/ijoc.2022.0099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every optimization problem has a corresponding verification problem that checks whether a given optimal solution is in fact optimal. In the literature, there are a lot of such ways to verify optimality for a given solution, for example, the branch-and-bound tree. To simplify this task, optimality certificates were introduced for convex mixed-integer nonlinear programs, and it was shown that the sizes of the certificates are bounded in terms of the number of integer variables. We introduce an algorithm to compute the certificates and conduct computational experiments. Through the experiments, we show that the optimality certificates can be surprisingly small. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms—Discrete. Funding: This work was supported by the Deutsche Forschungsgemeinschaft [CRC 154 Subproject A05, CRC 154 Subproject B07, and SFB Transregio 154], the Bundesministerium für Wirtschaft und Energie. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0099 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0099 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0099},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1579-1610},
  shortjournal = {INFORMS J. Comput.},
  title        = {Computing optimality certificates for convex mixed-integer nonlinear problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decomposable formulation of transmission constraints for
decentralized power systems optimization. <em>IJOC</em>, <em>36</em>(6),
1562–1578. (<a href="https://doi.org/10.1287/ijoc.2022.0326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most complicating factors in decentralized solution methods for a broad range of power system optimization problems is the modeling of power flow equations. Existing formulations for direct current power flows either have limited scalability or are very dense and unstructured, making them unsuitable for large-scale decentralized studies. In this work, we present a novel sparsified variant of the injection shift factors formulation, which has a decomposable block-diagonal structure and scales well for large systems. We also propose a decentralized solution method, based on the alternating direction multiplier method, that efficiently handles transmission line outages in N-1 security requirements. Benchmarks on multizonal security-constrained unit commitment problems show that the proposed formulation and algorithm can reliably and efficiently solve interconnection-level test systems with up to 6,515 buses with no convergence or numerical issues. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Funding: This work was partially supported by Laboratory Directed Research and Development funding from Argonne National Laboratory provided by the Director, Office of Science, of the U.S. Department of Energy [Grant DE-AC02-06CH11357]. This work was also partially supported by the U.S. Department of Energy Advanced Grid Modeling Program [Grant DE-OE0000875]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0326 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0326 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0326},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1562-1578},
  shortjournal = {INFORMS J. Comput.},
  title        = {Decomposable formulation of transmission constraints for decentralized power systems optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regret minimization and separation in multi-bidder,
multi-item auctions. <em>IJOC</em>, <em>36</em>(6), 1543–1561. (<a
href="https://doi.org/10.1287/ijoc.2022.0275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a robust auction design problem with a minimax regret objective, in which a seller seeks a mechanism for selling multiple items to multiple bidders with additive values. The seller knows that the bidders’ values range over a box uncertainty set but has no information on their probability distribution. The robust auction design model we study requires no distributional information except for upper bounds on the bidders’ values for each item. This model is relevant if there is no trustworthy distributional information or if any distributional information is costly or time-consuming to acquire. We propose a mechanism that sells each item separately via a second price auction with a random reserve price and prove that this mechanism is optimal using duality techniques from robust optimization. We then interpret the auction design problem as a zero-sum game between the seller, who chooses a mechanism, and a fictitious adversary or “nature,” who chooses the bidders’ values from within the uncertainty set with the aim to maximize the seller’s regret. We characterize the Nash equilibrium of this game analytically when the bidders are symmetric. The Nash strategy of the seller coincides with the optimal separable second price auction, whereas the Nash strategy of nature is mixed and constitutes a probability distribution on the uncertainty set under which each bidder’s values for the items are comonotonic. We also study a restricted auction design problem over deterministic mechanisms. In this setting, we characterize the suboptimality of a separable second price auction with deterministic reserve prices and show that this auction becomes optimal if the bidders are symmetric. The optimal mechanism is derived in closed form and can easily be implemented by practitioners. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms–Discrete. Funding: This research was funded by the Swiss National Science Foundation [Grant BSCGI0_157733] and by the Ministry of Education, Singapore, under its Academic Research Fund Tier 2 [Grant MOE-T2EP20222-0003]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0275 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0275 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0275},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1543-1561},
  shortjournal = {INFORMS J. Comput.},
  title        = {Regret minimization and separation in multi-bidder, multi-item auctions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decision diagram-based branch-and-bound with caching for
dominance and suboptimality detection. <em>IJOC</em>, <em>36</em>(6),
1522–1542. (<a href="https://doi.org/10.1287/ijoc.2022.0340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The branch-and-bound algorithm based on decision diagrams is a framework for solving discrete optimization problems with a dynamic programming formulation. It works by compiling a series of bounded-width decision diagrams that can provide lower and upper bounds for any given subproblem. Eventually, every part of the search space will be either explored or pruned by the algorithm, thus proving optimality. This paper presents new ingredients to speed up the search by exploiting the structure of dynamic programming models. The key idea is to prevent the repeated expansion of nodes corresponding to the same dynamic programming states by querying expansion thresholds cached throughout the search. These thresholds are based on dominance relations between partial solutions previously found and on pruning inequalities given by rough upper bounds and local bounds — two additional filtering techniques recently introduced. Computational experiments show that the pruning brought by this caching mechanism allows for significantly reducing the number of nodes expanded by the algorithm. This results in more benchmark instances of difficult optimization problems being solved in less time while using narrower decision diagrams. History: Accepted by Andrea Lodi, Area Editor for Design and Analysis of Algorithms–Discrete. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0340 ), as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0340 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0340},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1522-1542},
  shortjournal = {INFORMS J. Comput.},
  title        = {Decision diagram-based branch-and-bound with caching for dominance and suboptimality detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual bounding framework through cost splitting for binary
quadratic optimization. <em>IJOC</em>, <em>36</em>(6), 1501–1521. (<a
href="https://doi.org/10.1287/ijoc.2021.0186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary quadratic programming (BQP) is a class of combinatorial optimization problems comprising binary variables, quadratic objective functions, and linear/nonlinear constraints. This paper examines a unified framework to reformulate a BQP problem with linear constraints to a new BQP with an exponential number of variables defined on a graph. This framework relies on the concept of stars in the graph to split the quadratic costs into adjacent and nonadjacent components indicating in-star and out-of-star interactions. We exploit the star-based structure of the new reformulation to develop a decomposition-based column generation algorithm. In our computational experiments, we evaluate the performance of our methodology on different applications with different quadratic structures. The quadratic component of the problem is dealt with in the column generation master problem and its subproblem. Results indicate the superiority of the framework over one of the state-of-the-art solvers, GUROBI, when applied to various benchmark reformulations with adjacent-only or sparse quadratic cost matrices. The framework outperforms GUROBI in terms of both dual bound and computational time in almost all instances. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms—Discrete. Funding: The authors thank the Mitacs Accelerate Program for providing funding for this project. In addition, B. Rostami gratefully acknowledges the funding provided by the Canadian Natural Sciences and Engineering Research Council (NSERC) under a Discovery Grant [Grant RGPIN-2020-05395]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoc.2021.0186 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.0186},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1501-1521},
  shortjournal = {INFORMS J. Comput.},
  title        = {A dual bounding framework through cost splitting for binary quadratic optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A FAST method for nested estimation. <em>IJOC</em>,
<em>36</em>(6), 1481–1500. (<a
href="https://doi.org/10.1287/ijoc.2023.0118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nested estimation involves estimating an expectation of a function of a conditional expectation and has many important applications in operations research and machine learning. Nested simulation is a classic approach to this estimation, and the convergence rate of the mean squared error (MSE) of nested simulation estimators is only of order Γ − 2 / 3 , where Γ is the simulation budget. To accelerate the convergence, in this paper, we establish a jackkniFe-bAsed neSted simulaTion (FAST) method for nested estimation, and a unified theoretical analysis for general functions in the nested estimation shows that the MSE of the proposed method converges at the faster rate of Γ − 4 / 5 or even Γ − 6 / 7 . We also provide an efficient algorithm that ensures the estimator’s MSE decays at its optimal rate in practice. In numerical experiments, we apply the proposed estimator in portfolio risk measurement and Bayesian experimental design in operations research and machine learning areas, respectively, and numerical results are consistent with the theory presented. History: Accepted by Bruno Tuffin, Area Editor for Simulation. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72031006, 72101260, and 72394375]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0118 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0118 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0118},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1481-1500},
  shortjournal = {INFORMS J. Comput.},
  title        = {A FAST method for nested estimation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Path-based formulations for the design of on-demand
multimodal transit systems with adoption awareness. <em>IJOC</em>,
<em>36</em>(6), 1459–1480. (<a
href="https://doi.org/10.1287/ijoc.2023.0014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reconsiders the On-Demand Multimodal Transit Systems (ODMTS) Design with Adoptions problem (ODMTS-DA) to capture the latent demand in on-demand multimodal transit systems. The ODMTS-DA is a bilevel optimization problem, for which Basciftci and Van Hentenryck proposed an exact combinatorial Benders decomposition. Unfortunately, their proposed algorithm only finds high-quality solutions for medium-sized cities and is not practical for large metropolitan areas. The main contribution of this paper is to propose a new path-based optimization model, called P-P ath , to address these computational difficulties. The key idea underlying P-P ath is to enumerate two specific sets of paths which capture the essence of the choice model associated with the adoption behavior of riders. With the help of these path sets, the ODMTS-DA can be formulated as a single-level mixed-integer programming model. In addition, the paper presents preprocessing techniques that can reduce the size of the model significantly. P-P ath is evaluated on two comprehensive case studies: the midsize transit system of the Ann Arbor – Ypsilanti region in Michigan (which was studied by Basciftci and Van Hentenryck) and the large-scale transit system for the city of Atlanta. The experimental results show that P-P ath solves the Michigan ODMTS-DA instances in a few minutes, bringing more than two orders of magnitude improvements compared with the existing approach. For Atlanta, the results show that P-P ath can solve large-scale ODMTS-DA instances (about 17 millions variables and 37 millions constraints) optimally in a few hours or in a few days. These results show the tremendous computational benefits of P-P ath which provides a scalable approach to the design of on-demand multimodal transit systems with latent demand. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms—Discrete. Funding: This work was partially supported by National Science Foundation Leap-HI [Grant 1854684] and the Tier 1 University Transportation Center (UTC): Transit - Serving Communities Optimally, Responsively, and Efficiently (T-SCORE) from the U.S. Department of Transportation [69A3552047141]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0014 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0014 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0014},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1459-1480},
  shortjournal = {INFORMS J. Comput.},
  title        = {Path-based formulations for the design of on-demand multimodal transit systems with adoption awareness},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified framework for choice-based facility location
problem. <em>IJOC</em>, <em>36</em>(6), 1436–1458. (<a
href="https://doi.org/10.1287/ijoc.2022.0366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The choice-based facility location (CBFL) problem arises in various industrial and business contexts. The problem stands on a decentralized perspective: Companies set up chains of facilities, and customers determine from which chain or facility to seek service according to their own preferences. Essentially, customer preferences or choices play a key role in characterizing various CBFL problems, which differ mainly in the models or rules used to characterize the choice. Consequently, a large number of formulations appear and are often solved by dedicatedly designed approaches in the literature. Such a situation significantly complicates practitioners’ decision-making process when they are facing practical problems but are unsure which ad hoc model is suitable for their cases. In this article, we address this dilemma by providing a unified modeling framework based on the concept of preference dominance. Specifically, we conceptualize the choice behavior as a sequential two-step procedure: Given a set of open facilities, each customer first forms a nondominated consideration set and then splits the buying power within the set. Such an interpretation renders practitioners high modeling flexibility as they can tailor how preference dominance is constructed according to their specific contexts. In particular, we show that our model can represent several streams of CBFL problems. To support our model’s applicability, we design an efficient exact decomposition algorithm. Extensive computational studies reveal that although the algorithm is designed for a general purpose, it outperforms most approaches that are tailored for ad hoc problems by a large margin, which justifies both the effectiveness and the efficiency of the unified framework. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0366 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0366 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0366},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1436-1458},
  shortjournal = {INFORMS J. Comput.},
  title        = {Unified framework for choice-based facility location problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact solution of the single-picker routing problem with
scattered storage. <em>IJOC</em>, <em>36</em>(6), 1417–1435. (<a
href="https://doi.org/10.1287/ijoc.2023.0075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new modeling approach for the single-picker routing problem with scattered storage (SPRP-SS) for order picking in warehouses. The SPRP-SS assumes that an article is, in general, stored at more than one pick position. The task is then the simultaneous selection of pick positions for requested articles and the determination of a minimum-length picker tour collecting the articles. It is a classical result of Ratliff and Rosenthal that, for given pick positions, an optimal picker tour is a shortest path in the state space of a dynamic program with a linear number of states and transitions. We extend the state space of Ratliff and Rosenthal to include scattered storage so that every feasible picker tour is still a path. The additional requirement to make consistent decisions regarding articles to collect is not modeled in the state space so that dynamic programming can no longer be used for the solution. Instead, demand covering can be modeled as additional constraints in shortest-path problems. Therefore, we solve the resulting model with a mixed-integer (linear) programming (MIP) solver. The paper shows that this approach is not only convenient and elegant for single-block parallel-aisle warehouse SPRP-SSs but also generalizable: the solution principle can be applied to different warehouse layouts (we present additional results for a two-block parallel-aisle warehouse) and can incorporate further extensions. Computational experiments with other approaches for the SPRP-SS show that the new modeling approach outperforms the available exact algorithms regarding computational speed. History: Accepted by Andrea Lodi, Area Editor for Design and Analysis of Algorithms—Discrete. Supplemental Material: The e-companion is available at https://doi.org/10.1287/ijoc.2023.0075 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0075},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1417-1435},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exact solution of the single-picker routing problem with scattered storage},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Let the laser beam connect the dots: Forecasting and
narrating stock market volatility. <em>IJOC</em>, <em>36</em>(6),
1400–1416. (<a href="https://doi.org/10.1287/ijoc.2022.0055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting market volatility, especially high-volatility incidents, is a critical issue in financial market research and practice. Business news as an important source of market information is often exploited by artificial intelligence–based volatility forecasting models. Computationally, deep learning architectures, such as recurrent neural networks, on extremely long input sequences remain infeasible because of time complexity and memory limitations. Meanwhile, understanding the inner workings of deep neural networks is challenging because of the largely black box nature of large neural networks. In this work, we address the first challenge by proposing a long- and short-term memory retrieval (LASER) architecture with flexible memory and horizon configurations to forecast market volatility. Then, we tackle the interpretability issue by devising a BEAM algorithm that leverages a large pretrained language model (GPT-2). It generates human-readable narratives verbalizing the evidence leading to the model prediction. Experiments on a Wall Street Journal news data set demonstrate the superior performance of our proposed LASER-BEAM pipeline in predicting high-volatility market scenarios and generating high-quality narratives compared with existing methods in the literature. History: Accepted by Ram Ramesh, Area Editor for Data Science &amp; Machine Learning. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0055 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0055 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0055},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1400-1416},
  shortjournal = {INFORMS J. Comput.},
  title        = {Let the laser beam connect the dots: Forecasting and narrating stock market volatility},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constraint learning to define trust regions in optimization
over pre-trained predictive models. <em>IJOC</em>, <em>36</em>(6),
1382–1399. (<a href="https://doi.org/10.1287/ijoc.2022.0312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a recent proliferation of research on the integration of machine learning and optimization. One expansive area within this research stream is optimization over pre-trained predictive models, which proposes the use of pre-trained predictive models as surrogates for uncertain or highly complex objective functions. In this setting, features of the predictive models become decision variables in the optimization problem. Despite a recent surge in publications in this area, only a few papers note the importance of incorporating trust-region considerations in this decision-making pipeline, that is, enforcing solutions to be similar to the data used to train the predictive models. Without such constraints, the evaluation of the predictive model at solutions obtained from optimization cannot be trusted and the practicality of the solutions may be unreasonable. In this paper, we provide an overview of the approaches appearing in the literature to construct a trust region and propose three alternative approaches. Our numerical evaluation highlights that trust-region constraints learned through our newly proposed approaches compare favorably with previously suggested approaches, both in terms of solution quality and computational time. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0312 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0312 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0312},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1382-1399},
  shortjournal = {INFORMS J. Comput.},
  title        = {Constraint learning to define trust regions in optimization over pre-trained predictive models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impact of passive social media viewers in influence
maximization. <em>IJOC</em>, <em>36</em>(6), 1362–1381. (<a
href="https://doi.org/10.1287/ijoc.2023.0047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A frequently studied problem in the context of digital marketing for online social networks is the influence maximization problem that seeks for an initial seed set of influencers to trigger an information propagation cascade (in terms of active message forwarders) of expected maximum impact. Previously studied problems typically neglect that the probability that individuals passively view content without forwarding it is much higher than the probability that they forward content. Considering passive viewing enables us to maximize more natural (social media) marketing metrics, including (a) the expected organic reach, (b) the expected number of total impressions, or (c) the expected patronage, all of which are investigated in this paper for the first time in the context of influence maximization. We propose mathematical models to maximize these objectives, whereby the model for variant (c) includes individual’s resistances and uses a multinomial logit model to model customer behavior. We also show that these models can be easily adapted to a competitive setting in which the seed set of a competitor is known. In a computational study based on network graphs from Twitter (now X) and from the literature, we show that one can increase the expected patronage, organic reach, and number of total impressions by 36% on average (and up to 13 times in particular cases) compared with seed sets obtained from the classical maximization of message-forwarding users. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms—Discrete. Funding: This work was supported by the Federal Ministry of Education, Science and Research of Austria and by the Austrian Agency for International Mobility and Cooperation in Education, Science and Research [Reference ICM-2019-13384]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0047 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0047 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0047},
  journal      = {INFORMS Journal on Computing},
  month        = {11-12},
  number       = {6},
  pages        = {1362-1381},
  shortjournal = {INFORMS J. Comput.},
  title        = {The impact of passive social media viewers in influence maximization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An integrated predictive maintenance and operations
scheduling framework for power systems under failure uncertainty.
<em>IJOC</em>, <em>36</em>(5), 1335–1358. (<a
href="https://doi.org/10.1287/ijoc.2022.0154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintenance planning plays a key role in power system operations under uncertainty as it helps providers and operators ensure a reliable and secure power grid. This paper studies a short-term condition-based integrated maintenance planning with operations scheduling problem while considering the possible unexpected failure of generators as well as transmission lines. We formulate this problem as a two-stage stochastic mixed-integer program with failure scenarios sampled from the sensor-driven remaining lifetime distributions of the individual system elements whereas a joint chance constraint consisting of Poisson Binomial random variables is introduced to account for failure risks. Because of its intractability, we develop a cutting-plane method to obtain an exact reformulation of the joint chance constraint by proposing a separation subroutine and deriving stronger cuts as part of this procedure. We also derive a second-order cone programming-based safe approximation of this constraint to solve large-scale instances. Furthermore, we propose a decomposition algorithm implemented in parallel fashion for solving the resulting stochastic program, which exploits the features of the integer L-shaped method and the special structure of the maintenance and operations scheduling problem to derive valid and stronger sets of optimality cuts. We further present preprocessing steps over transmission line flow constraints to identify redundancies. To illustrate the computational performance and efficiency of our algorithm compared with more conventional maintenance approaches, we design a computational study focusing on a weekly plan with daily maintenance and hourly operational decisions involving detailed unit commitment subproblems. Our computational results on various IEEE instances demonstrate the computational efficiency of the proposed approach with reliable and cost-effective maintenance and operational schedules. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms—Discrete. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoc.2022.0154 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0154},
  journal      = {INFORMS Journal on Computing},
  month        = {9-10},
  number       = {5},
  pages        = {1335-1358},
  shortjournal = {INFORMS J. Comput.},
  title        = {An integrated predictive maintenance and operations scheduling framework for power systems under failure uncertainty},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding regions of counterfactual explanations via robust
optimization. <em>IJOC</em>, <em>36</em>(5), 1316–1334. (<a
href="https://doi.org/10.1287/ijoc.2023.0153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual explanations (CEs) play an important role in detecting bias and improving the explainability of data-driven classification models. A CE is a minimal perturbed data point for which the decision of the model changes. Most of the existing methods can only provide one CE, which may not be achievable for the user. In this work, we derive an iterative method to calculate robust CEs (i.e., CEs that remain valid even after the features are slightly perturbed). To this end, our method provides a whole region of CEs, allowing the user to choose a suitable recourse to obtain a desired outcome. We use algorithmic ideas from robust optimization and prove convergence results for the most common machine learning methods, including decision trees, tree ensembles, and neural networks. Our experiments show that our method can efficiently generate globally optimal robust CEs for a variety of common data sets and classification models. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms—Discrete. Funding: This work was supported by the Nederlandse Organisatie voor Wetenschappelijk Onderzoek [Grant OCENW.GROOT.2019.015, Optimization for and with Machine Learning (OPTIMAL)]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoc.2023.0153 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0153},
  journal      = {INFORMS Journal on Computing},
  month        = {9-10},
  number       = {5},
  pages        = {1316-1334},
  shortjournal = {INFORMS J. Comput.},
  title        = {Finding regions of counterfactual explanations via robust optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact method for production hub location. <em>IJOC</em>,
<em>36</em>(5), 1287–1315. (<a
href="https://doi.org/10.1287/ijoc.2023.0339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a production hub location (PHL) problem that integrates the classical multiplant lot-sizing and hub location problems. The PHL problem is to determine the location of production facilities, lot-sizing, inventory, hub location, and the distribution of multiple commodities from plants to customers, with an objective to minimize the total production, setup, inventory, hub operating, and transportation costs. The PHL problem applies to manufacturing companies that either have built a hub-and-spoke distribution network or are accessible to such a network through collaborations with other third-party logistics companies. Because the PHL problem is N P -hard, we propose an exact method that integrates dynamic programming and Benders decomposition (DPBD) for solving the problem. The DPBD method is enhanced by exploring several problem properties, such as a multicut reformulation, the generation of Pareto-optimal cuts, a two-stage hub elimination and restoration procedure, and the inclusion of a novel heuristic procedure. We compare the PHL model with several related models theoretically and computationally with newly created benchmark instances. The computational results indicate that the proposed model can reduce the total costs and facilitate better network designs and system decisions, highlighting the value of an integrated approach. We also provide managerial insights into the benefits of integration and show the efficiency of the DPBD method through an extensive number of computational tests. History: Accepted by Andrea Lodi, Area Editor for Design and Analysis of Algorithms—Discrete. Supplemental Material: The online supplement is available at https://doi.org/10.1287/ijoc.2023.0339 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0339},
  journal      = {INFORMS Journal on Computing},
  month        = {9-10},
  number       = {5},
  pages        = {1287-1315},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exact method for production hub location},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying socially optimal equilibria using combinatorial
properties of nash equilibria in bimatrix games. <em>IJOC</em>,
<em>36</em>(5), 1261–1286. (<a
href="https://doi.org/10.1287/ijoc.2022.0072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nash equilibrium is arguably the most fundamental concept in game theory, which is used to analyze and predict the behavior of the players. In many games, there exist multiple equilibria, with different expected payoffs for the players, which in turn raises the question of equilibrium selection. In this paper, we study the N P -hard problem of identifying a socially optimal Nash equilibrium in two-player normal-form games (called bimatrix games), which may be represented by a mixed integer linear program (MILP). We characterize the properties of the equilibria and develop several classes of valid inequalities accordingly. We use these theoretical results to provide a decomposition-based reformulation of the MILP, which we solve by a branch-and-cut algorithm. Our extensive computational experiments demonstrate superiority of our approach over solving the MILP formulation through feeding it into a commercial solver or through the “traditional” Benders’ decomposition. Of note, our proposed approach can find provably optimal solutions for many instances. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms. Funding: This work was supported by the National Institute of Dental and Craniofacial Research [Grant R01DE028283]. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. The funding agreements ensured the authors’ independence in designing the study, interpreting the data, writing, and publishing the report. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0072 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0072 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0072},
  journal      = {INFORMS Journal on Computing},
  month        = {9-10},
  number       = {5},
  pages        = {1261-1286},
  shortjournal = {INFORMS J. Comput.},
  title        = {Identifying socially optimal equilibria using combinatorial properties of nash equilibria in bimatrix games},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cost-effective acquisition of first-party data for business
analytics. <em>IJOC</em>, <em>36</em>(5), 1242–1260. (<a
href="https://doi.org/10.1287/ijoc.2022.0037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer data acquisition is an important task in data-driven business analytics. Recently, there has been a growing interest in the effective use of an organization’s internal customer data, also known as first-party data. This work studies the acquisition of new data for business analytics based on first-party data resource. We address issues related to both acquisition cost and data quality. To reduce acquisition cost, we consider using auction-based methods, such as the generalized second price (GSP) auction, for acquiring data with differential prices for different customers. We find that the GSP-based data acquisition method incurs a lower cost and/or achieves a higher response rate than fixed price methods. To maximize data quality, we propose novel optimization models for different data acquisition methods and data quality measures. The proposed models maximize the quality of the acquired data while satisfying budget constraints. We derive and discuss the solutions to the optimization models analytically and provide managerial insights from the solutions. The proposed approach is effective in increasing customer responses, reducing selection bias, and enabling more accurate estimation and prediction for business analytics. The results of the experimental evaluation demonstrate the advantage of the proposed approach over existing data acquisition methods. History: Accepted by Ram Ramesh, Area Editor for Data Science and Machine Learning. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0037 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0037 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0037},
  journal      = {INFORMS Journal on Computing},
  month        = {9-10},
  number       = {5},
  pages        = {1242-1260},
  shortjournal = {INFORMS J. Comput.},
  title        = {Cost-effective acquisition of first-party data for business analytics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving bilevel programs based on lower-level mond-weir
duality. <em>IJOC</em>, <em>36</em>(5), 1225–1241. (<a
href="https://doi.org/10.1287/ijoc.2023.0108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on developing effective algorithms for solving a bilevel program. The most popular approach is to replace the lower-level problem with its Karush-Kuhn-Tucker conditions to generate a mathematical program with complementarity constraints (MPCC). However, MPCC does not satisfy the Mangasarian-Fromovitz constraint qualification (MFCQ) at any feasible point. In this paper, inspired by a recent work using the lower-level Wolfe duality (WDP), we apply the lower-level Mond-Weir duality to present a new reformulation, called MDP, for bilevel program. It is shown that, under mild assumptions, they are equivalent in globally or locally optimal sense. An example is given to show that, different from MPCC, MDP may satisfy the MFCQ at its feasible points. Relations among MDP, WDP, and MPCC are investigated. On this basis, we extend the MDP reformulation to present another new reformulation (called eMDP), which has similar properties to MDP. Furthermore, to compare two new reformulations with the MPCC and WDP approaches, we design a procedure to generate 150 tested problems randomly and comprehensive numerical experiments show that MDP has quite evident advantages over MPCC and WDP in terms of feasibility to the original bilevel programs, success efficiency, and average CPU time, whereas eMDP is far superior to all other three reformulations. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Funding: This work was supported by the National Natural Science Foundation of China [Grants 12071280 and 11901380]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0108 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0108 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0108},
  journal      = {INFORMS Journal on Computing},
  month        = {9-10},
  number       = {5},
  pages        = {1225-1241},
  shortjournal = {INFORMS J. Comput.},
  title        = {Solving bilevel programs based on lower-level mond-weir duality},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Appointment scheduling with delay tolerance heterogeneity.
<em>IJOC</em>, <em>36</em>(5), 1201–1224. (<a
href="https://doi.org/10.1287/ijoc.2023.0025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigate an appointment sequencing and scheduling problem with heterogeneous user delay tolerances under service time uncertainty. We aim to capture the delay tolerance effect with heterogeneity, in an operationally effective and computationally tractable fashion, for the appointment scheduling problem. To this end, we first propose a Tolerance-Aware Delay (TAD) index that incorporates explicitly the user tolerance information in delay evaluation. We show that the TAD index enjoys decision-theoretical rationale in terms of Tolerance sensitivity , monotonicity , and convexity and positive homogeneity , which enables it to incorporate the frequency and intensity of delays over the tolerance in a coherent manner. Specifically, the convexity of TAD index ensures a tractable modeling of the collective delay dissatisfaction in the appointment scheduling problem. Using the TAD index, we then develop an appointment model with known empirical service time distribution that minimizes the overall tolerance-aware delays of all users. We analyze the impact of delay tolerance on the sequence and schedule decisions and show that the resultant TAD appointment model can be reformulated as a mixed-integer linear program (MILP). Furthermore, we extend the TAD appointment model by considering service time ambiguity. In particular, we encode into the TAD index a moment ambiguity set and a Wasserstein ambiguity set, respectively. The former captures effectively the correlation among service times across positions and user types, whereas the latter captures directly the service time data information. We show that both of the resultant TAD models under ambiguity can be reformulated as polynomial-sized, mixed-integer conic programs (MICPs). Finally, we compare our TAD models with some existing counterpart approaches and the current practice using synthetic data and a case of real hospital data, respectively. Our results demonstrate the effectiveness of the TAD appointment models in capturing the user delay tolerance with heterogeneity and mitigating the worst-case delays. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Funding: S. Wang was supported by the National Natural Science Foundation of China [Grants 71922020, 72171221, and 71988101, entitled “Econometric Modeling and Economic Policy Studies”], the Fundamental Research Funds for the Central Universities [Grant UCAS-E2ET0808X2], and the Major Program of National Natural Science Foundation of China [Grant 72192843]. S. Wang was also supported by a grant from MOE Social Science Laboratory of Digital Economic Forecasts and Policy Simulation at UCAS. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0025 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0025 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0025},
  journal      = {INFORMS Journal on Computing},
  month        = {9-10},
  number       = {5},
  pages        = {1201-1224},
  shortjournal = {INFORMS J. Comput.},
  title        = {Appointment scheduling with delay tolerance heterogeneity},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive influence maximization: Adaptability via
nonadaptability. <em>IJOC</em>, <em>36</em>(5), 1190–1200. (<a
href="https://doi.org/10.1287/ijoc.2023.0267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive influence maximization is an important research problem in computational social networks, which is also a typical problem in the study of adaptive processing of information and adaptive construction of objects. In this paper, we propose a new method that reduces the adaptive influence maximization problem into a nonadaptive one in a different social network, so that an adaptive optimization can be solved by those methods for nonadaptive optimization. In addition, we provide a new approximation algorithm for the submodular maximization problem with a knapsack constraint, which runs in O ( n 2 ) time and has performance ratio 1 − 1 / e , where n is the number of nodes in the network. The ratio is better than the best known previous one with the same running time. History: Accepted by Erwin Pesch, Area Editor for Heuristic Search &amp; Approximation Algorithms. Funding: This research is supported in part by the National Natural Science Foundation of China [Grant U20A2068].},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0267},
  journal      = {INFORMS Journal on Computing},
  month        = {9-10},
  number       = {5},
  pages        = {1190-1200},
  shortjournal = {INFORMS J. Comput.},
  title        = {Adaptive influence maximization: Adaptability via nonadaptability},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time derivative pricing and hedging with consistent
metamodels. <em>IJOC</em>, <em>36</em>(5), 1168–1189. (<a
href="https://doi.org/10.1287/ijoc.2023.0292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In derivative pricing and hedging, the consistency between the price and Greek surfaces (i.e., the Greek surfaces can be obtained by differentiating the price surface) is important in stabilizing the balance sheet and reducing the hedging cost. To build consistent surfaces of the price and Greeks for real-time decisions, we propose to use the gradient-enhanced stochastic kriging method, based on the data collected through extensive simulation experiments conducted when the market is closed. In addition to the naturally guaranteed consistency, we prove that the constructed price and Greek surfaces are more accurate than those constructed separately using stochastic kriging. Besides the consistency between the price and Greeks, we show that the partial differential equation relation between the price and Greeks, implied by the famous Feynman-Kac formula, can also be used to further improve the accuracy of the constructed surfaces. The numerical studies show that our proposed metamodeling methods work well for derivative pricing and hedging. History: Accepted by Bruno Tuffin, Area Editor for Simulation. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72161160340, 72293562, 72121001, 72031006, and 72171060]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0292 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0292 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0292},
  journal      = {INFORMS Journal on Computing},
  month        = {9-10},
  number       = {5},
  pages        = {1168-1189},
  shortjournal = {INFORMS J. Comput.},
  title        = {Real-time derivative pricing and hedging with consistent metamodels},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quadratic optimization models for balancing preferential
access and fairness: Formulations and optimality conditions.
<em>IJOC</em>, <em>36</em>(5), 1150–1167. (<a
href="https://doi.org/10.1287/ijoc.2022.0308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typically, within facility location problems, fairness is defined in terms of accessibility of users. However, for facilities perceived as undesirable by communities hosting them, fairness between the usage of facilities becomes especially important. Limited research exists on this notion of fairness. To close this gap, we develop a series of optimization models for the allocation of populations of users to facilities such that access for users is balanced with a fair utilization of facilities. The optimality conditions of the underlying nonconvex quadratic models state the precise balance between accessibility and fairness. We define new classes of fairness and a metric to quantify the extent to which fairness is achieved in both optimal and suboptimal allocations. We show that a continuous relaxation of our central model is sufficient to achieve a perfect extent of fairness, while a special case reduces to the classical notion of proportional fairness. Our work is motivated by pervasive ecological challenges faced by the waste management community as policymakers seek to reduce the number of recycling centers in the last few years. As a computational case study, applying our models on data for the state of Bavaria in Germany, we find that even after the closure of a moderate number of recycling centers, large degrees of access can be ensured, provided that the closures are conducted optimally. Fairness, however, is impacted more, with facilities in rural regions shouldering larger loads of visiting populations than those in urban regions. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Funding: Computer resources and support provided by the Erlangen Regional Computing Center are gratefully acknowledged. B. Singh was partially financially supported by the Bavarian State Ministry for Science and Art (Bayerisches Staatsministerium für Wissenschaft und Kunst) under the Competence Network for Scientific High Performance Computing in Bavaria. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0308 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0308 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0308},
  journal      = {INFORMS Journal on Computing},
  month        = {9-10},
  number       = {5},
  pages        = {1150-1167},
  shortjournal = {INFORMS J. Comput.},
  title        = {Quadratic optimization models for balancing preferential access and fairness: Formulations and optimality conditions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Use of machine learning models to warmstart column
generation for unit commitment. <em>IJOC</em>, <em>36</em>(4),
1129–1146. (<a href="https://doi.org/10.1287/ijoc.2022.0140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unit commitment problem is an important optimization problem in the energy industry used to compute the most economical operating schedules of power plants. Typically, this problem has to be solved repeatedly with different data but with the same problem structure. Machine learning techniques have been applied in this context to find primal feasible solutions. Dantzig-Wolfe decomposition with a column generation procedure is another approach that has been shown to be successful in solving the unit commitment problem to tight tolerance. We propose the use of machine learning models not to find primal feasible solutions directly but to generate initial dual values for the column generation procedure. Our numerical experiments compare machine learning–based methods for warmstarting the column generation procedure with three baselines: column prepopulation, the linear programming relaxation, and coldstart. The experiments reveal that the machine learning approaches are able to find both tight lower bounds and accurate primal feasible solutions in a shorter time compared with the baselines. Furthermore, these approaches scale well to handle large instances. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms—Discrete.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0140},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1129-1146},
  shortjournal = {INFORMS J. Comput.},
  title        = {Use of machine learning models to warmstart column generation for unit commitment},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dedicated pricing algorithm to solve a large family of
nurse scheduling problems with branch-and-price. <em>IJOC</em>,
<em>36</em>(4), 1108–1128. (<a
href="https://doi.org/10.1287/ijoc.2023.0019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we describe a branch-and-price algorithm for the personalized nurse scheduling problem. The variants that appear in the literature involve a large number of constraints that can be hard or soft, meaning that they can be violated at the price of a penalty. We capture the diversity of the constraints on individual schedules by seven generic constraints characterized by lower and upper bounds on a given quantity. The core of the column generation procedure is in the identification of individual schedules with minimum reduced cost. For this, we solve a shortest path problem with resource constraints (SPPRC) where several generic constraints are modeled as resource constraints. We then describe dominance rules adapted to the presence of both upper and lower bounds on the resources and leverage soft constraints to improve the dominance. We also describe several acceleration techniques for the solution of the SPPRC, and branching rules that fit the specificities of the problem. Our numerical experiments are based on the instances of three benchmarks of the literature including those of the two international nurse rostering competitions (INRC-I and INRC-II). Their objective is threefold: assess the dominance rules and the acceleration techniques, investigate the capacity of the algorithm to find provable optimal solutions of instances that are still open, and conduct a comparison with best published results. The most noticeable conclusion is that the improved solution of the SPPRC allows to solve optimally all the INRC-II instances where a four-week planning horizon is considered and 40% of the eight-week instances. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms–Discrete. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoc.2023.0019 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0019},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1108-1128},
  shortjournal = {INFORMS J. Comput.},
  title        = {A dedicated pricing algorithm to solve a large family of nurse scheduling problems with branch-and-price},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact and heuristic solution techniques for mixed-integer
quantile minimization problems. <em>IJOC</em>, <em>36</em>(4),
1084–1107. (<a href="https://doi.org/10.1287/ijoc.2022.0105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider mixed-integer linear quantile minimization problems that yield large-scale problems that are very hard to solve for real-world instances. We motivate the study of this problem class by two important real-world problems: a maintenance planning problem for electricity networks and a quantile-based variant of the classic portfolio optimization problem. For these problems, we develop valid inequalities and present an overlapping alternating direction method. Moreover, we discuss an adaptive scenario clustering method for which we prove that it terminates after a finite number of iterations with a global optimal solution. We study the computational impact of all presented techniques and finally show that their combination leads to an overall method that can solve the maintenance planning problem on large-scale real-world instances provided by the ROADEF/EURO challenge 2020 1 and that they also lead to significant improvements when solving a quantile-version of the classic portfolio optimization problem. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms–Discrete. Funding: This work was supported by the Deutsche Forschungsgemeinschaft [CRC TRR 154], Fonds De La Recherche Scientifique [PDR T0098.18], and Bundesministerium für Bildung und Forschung. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoc.2022.0105 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0105},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1084-1107},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exact and heuristic solution techniques for mixed-integer quantile minimization problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decremental state-space relaxations for the basic traveling
salesman problem with a drone. <em>IJOC</em>, <em>36</em>(4), 1064–1083.
(<a href="https://doi.org/10.1287/ijoc.2022.0390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Truck-and-drone routing problems have become an important research topic in the last decade because of their applications for last-mile deliveries. Despite the many publications in this area, the most efficient exact algorithms designed thus far struggle to solve the benchmark instances with 39 or more customers. This fact holds even for one of the simplest variants involving one truck and one drone whose routes must synchronize at customers’ locations: the basic traveling salesman problem with a drone (TSP-D). In this article, we devise a new algorithm for the TSP-D that solves every benchmark instance with up to 59 customers, and it scales up to 99 customers when the drone is much faster than the truck. The core of our method is a dynamic programming algorithm that is applied for column generation and variable fixing within tailored decremental state-space relaxation strategies. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms–Discrete. Funding: This work was supported by Fondo para la Investigación Científica y Tecnológica [Grant PICT-2018-2961] (Ministry of Science, Argentina). Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoc.2022.0390 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0390},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1064-1083},
  shortjournal = {INFORMS J. Comput.},
  title        = {Decremental state-space relaxations for the basic traveling salesman problem with a drone},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polyhedral relaxations for optimal pump scheduling of
potable water distribution networks. <em>IJOC</em>, <em>36</em>(4),
1040–1063. (<a href="https://doi.org/10.1287/ijoc.2022.0233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classic pump scheduling or optimal water flow (OWF) problem for water distribution networks (WDNs) minimizes the cost of power consumption for a given WDN over a fixed time horizon. In its exact form, the OWF is a computationally challenging mixed-integer nonlinear program (MINLP). It is complicated by nonlinear equality constraints that model network physics, discrete variables that model operational controls, and intertemporal constraints that model changes to storage devices. To address the computational challenges of the OWF, this paper develops tight polyhedral relaxations of the original MINLP, derives novel valid inequalities (or cuts) using duality theory, and implements novel optimization-based bound tightening and cut generation procedures. The efficacy of each new method is rigorously evaluated by measuring empirical improvements in OWF primal and dual bounds over 45 literature instances. The evaluation suggests that our relaxation improvements, model strengthening techniques, and a thoughtfully selected polyhedral relaxation partitioning scheme can substantially improve OWF primal and dual bounds, especially when compared with similar relaxation-based techniques that do not leverage these new methods. History: Accepted by David Alderson, Area Editor for Network Optimization: Algorithms &amp; Applications. Funding: This work was supported by the U.S. Department of Energy (DOE) Advanced Grid Modeling project, Coordinated Planning and Operation of Water and Power Infrastructures for Increased Resilience and Reliability. Incorporation of the P olyhedral R elaxations J ulia package was supported by Los Alamos National Laboratory’s Directed Research and Development program under the project Fast, Linear Programming-Based Algorithms with Solution Quality Guarantees for Nonlinear Optimal Control Problems [Grant 20220006ER]. All work at Los Alamos National Laboratory was conducted under the auspices of the National Nuclear Security Administration of the U.S. DOE, Contract No. 89233218CNA000001. This work was also authored in part by the National Renewable Energy Laboratory, operated by the Alliance for Sustainable Energy, LLC, for the U.S. DOE, Contract No. DE-AC36-08GO28308. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0233 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0233 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0233},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1040-1063},
  shortjournal = {INFORMS J. Comput.},
  title        = {Polyhedral relaxations for optimal pump scheduling of potable water distribution networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A shrinkage approach to improve direct bootstrap resampling
under input uncertainty. <em>IJOC</em>, <em>36</em>(4), 1023–1039. (<a
href="https://doi.org/10.1287/ijoc.2022.0044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete-event simulation models generate random variates from input distributions and compute outputs according to the simulation logic. The input distributions are typically fitted to finite real-world data and thus are subject to estimation errors that can propagate to the simulation outputs: an issue commonly known as input uncertainty (IU). This paper investigates quantifying IU using the output confidence intervals (CIs) computed from bootstrap quantile estimators. The standard direct bootstrap method has overcoverage due to convolution of the simulation error and IU; however, the brute-force way of washing away the former is computationally demanding. We present two new bootstrap methods to enhance direct resampling in both statistical and computational efficiencies using shrinkage strategies to down-scale the variabilities encapsulated in the CIs. Our asymptotic analysis shows how both approaches produce tight CIs accounting for IU under limited input data and simulation effort along with the simulation sample-size requirements relative to the input data size. We demonstrate performances of the shrinkage strategies with several numerical experiments and investigate the conditions under which each method performs well. We also show advantages of nonparametric approaches over parametric bootstrap when the distribution family is misspecified and over metamodel approaches when the dimension of the distribution parameters is high. History: Accepted by Bruno Tuffin, Area Editor for Simulation. Funding: This work was supported by the National Science Foundation [CAREER CMMI-1834710, CAREER CMMI-2045400, DMS-1854659, and IIS-1849280]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0044 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0044 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0044},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1023-1039},
  shortjournal = {INFORMS J. Comput.},
  title        = {A shrinkage approach to improve direct bootstrap resampling under input uncertainty},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An approximate dynamic programming approach to dynamic
stochastic matching. <em>IJOC</em>, <em>36</em>(4), 1006–1022. (<a
href="https://doi.org/10.1287/ijoc.2021.0203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic stochastic matching problems arise in a variety of recent applications, ranging from ridesharing and online video games to kidney exchange. Such problems are naturally formulated as Markov decision processes (MDPs) that are, however, intractable in general. To improve tractability, we investigate the linear programming-based approach to approximate dynamic programming. This approach can provide both feasible control policies and bounds on the MDPs’ optimal policy value, which can be used to establish optimality gaps. However, the approximate linear programs (ALPs) resulting from this approach can often be difficult to solve. To address this computational challenge, we derive novel ALP reformulations that can be used for a broad class of dynamic stochastic matching problems that incorporate, among others, possible match failures and certain restrictions on feasible matchings. We show that these ALP reformulations can be solved efficiently and applied to a broad class of dynamic matching problems. In addition, our numerical results indicate that our ALP reformulations can produce tight bounds that allow us to establish near-optimal policy performance for a broad set of problem instances. Thus, ALP reformulations can present an attractive alternative for applications that involve dynamic stochastic matching. History: Accepted by Nicola Secomandi, Area Editor for Stochastic Models &amp; Reinforcement Learning. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2021.0203 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2021.0203 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.0203},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {1006-1022},
  shortjournal = {INFORMS J. Comput.},
  title        = {An approximate dynamic programming approach to dynamic stochastic matching},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A neural separation algorithm for the rounded capacity
inequalities. <em>IJOC</em>, <em>36</em>(4), 987–1005. (<a
href="https://doi.org/10.1287/ijoc.2022.0310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cutting plane method is a key technique for successful branch-and-cut and branch-price-and-cut algorithms that find the exact optimal solutions for various vehicle routing problems (VRPs). Among various cuts, the rounded capacity inequalities (RCIs) are the most fundamental. To generate RCIs, we need to solve the separation problem, whose exact solution takes a long time to obtain; therefore, heuristic methods are widely used. We design a learning-based separation heuristic algorithm with graph coarsening that learns the solutions of the exact separation problem with a graph neural network (GNN), which is trained with small instances of 50 to 100 customers. We embed our separation algorithm within the cutting plane method to find a lower bound for the capacitated VRP (CVRP) with up to 1,000 customers. We compare the performance of our approach with CVRPSEP, a popular separation software package for various cuts used in solving VRPs. Our computational results show that our approach finds better lower bounds than CVRPSEP for large-scale problems with 400 or more customers, whereas CVRPSEP shows strong competency for problems with less than 400 customers. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms–Discrete. Funding: This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korean government (MSIT) [RS-2023-00259550] and the Institute of Information &amp; Communications Technology Planning &amp; Evaluation (IITP) grant funded by the Korean government (MSIT) [2022-0-01032, Development of Collective Collaboration Intelligence Framework for Internet of Autonomous Things]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoc.2022.0310 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0310},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {987-1005},
  shortjournal = {INFORMS J. Comput.},
  title        = {A neural separation algorithm for the rounded capacity inequalities},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AILS-II: An adaptive iterated local search heuristic for the
large-scale capacitated vehicle routing problem. <em>IJOC</em>,
<em>36</em>(4), 974–986. (<a
href="https://doi.org/10.1287/ijoc.2023.0106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent study on the classical capacitated vehicle routing problem (CVRP) introduced an adaptive version of the widely used iterated local search paradigm, hybridized with a path-relinking (PR) strategy. The solution method, called adaptive iterated local search (AILS)-PR, outperformed existing meta-heuristics for the CVRP on benchmark instances. However, tests on large-scale instances suggest that PR is too slow, making AILS-PR less advantageous in this case. To overcome this challenge, this paper presents an AILS combined with mechanisms to handle large CVRP instances, called AILS-II. The computational cost of this implementation is reduced, whereas the algorithm also searches the solution space more efficiently. AILS-II is very competitive on smaller instances, outperforming the other methods from the literature with respect to the average gap to the best-known solutions. Moreover, AILS-II consistently outperforms the state of the art on larger instances with up to 30,000 vertices. History: Accepted by Ted Ralphs, Area Editor for Software Tools. This paper has been accepted for the INFORMS Journal on Computing Special Issue on Software Tools for Vehicle Routing. Funding: This work was supported by the Fundação de Amparo à Pesquisa do Estado de São Paulo [Grants 2013/07375-0, 2019/22067-6, and 2022/05803-3] and the Conselho Nacional de Desenvolvimento Científico e Tecnológico [Grants 309385/2021-0 and 403735/2021-1]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0106 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0106 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0106},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {974-986},
  shortjournal = {INFORMS J. Comput.},
  title        = {AILS-II: An adaptive iterated local search heuristic for the large-scale capacitated vehicle routing problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RoutingBlocks: An open-source python package for vehicle
routing problems with intermediate stops. <em>IJOC</em>, <em>36</em>(4),
966–973. (<a href="https://doi.org/10.1287/ijoc.2023.0104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce RoutingBlocks , a versatile open-source Python package designed to simplify the development of algorithms for vehicle routing problems with intermediate stops (VRPIS). The package offers a variety of modular algorithmic components and optimized data structures crafted specifically to address key challenges of VRPIS, such as a lack of exact constant-time move evaluations and difficult station visit decisions. By using a unified solution and instance representation that abstracts problem-specific behavior (for example, constraint checking, move evaluation, and cost computation) into well-defined interfaces, RoutingBlocks maintains a clear separation between algorithmic components and specific problem configurations, thus allowing the application of the same algorithm to a variety of problem settings. Leveraging an efficient C ++ implementation for performance-critical core elements, RoutingBlocks combines the high performance of C ++ with the user-friendliness and adaptability of Python, thereby streamlining the development of effective metaheuristic algorithms. As a result, researchers using RoutingBlocks can focus on their algorithms’ core features, allocating more resources to innovation and advancement in the VRPIS domain. History: Accepted by Ted Ralphs, Area Editor for Software Tools. This paper has been accepted for the INFORMS Journal on Computing Special Issue on Software Tools for Vehicle Routing.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0104},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {966-973},
  shortjournal = {INFORMS J. Comput.},
  title        = {RoutingBlocks: An open-source python package for vehicle routing problems with intermediate stops},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VRPSolverEasy: A python library for the exact solution of a
rich vehicle routing problem. <em>IJOC</em>, <em>36</em>(4), 956–965.
(<a href="https://doi.org/10.1287/ijoc.2023.0103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization community has made significant progress in solving vehicle routing problems (VRPs) to optimality using sophisticated branch-cut-and-price (BCP) algorithms. VRPSolver is a BCP algorithm with excellent performance in many VRP variants. However, its complex underlying mathematical model makes it hardly accessible to routing practitioners. To address this, VRPSolverEasy provides a Python interface to VRPSolver that does not require any knowledge of mixed integer programming modeling. Instead, routing problems are defined in terms of familiar elements, such as depots, customers, links, and vehicle types. VRPSolverEasy can handle several popular VRP variants and arbitrary combinations of them. History: Accepted by Ted Ralphs, Area Editor for Software Tools. This paper has been accepted for the INFORMS Journal on Computing Special Issue on Software Tools for Vehicle Routing. Funding: This work was supported by Faperj [Grant E-26/202.887/2017] and Conselho Nacional de Desenvolvimento Científico e Tecnológico [Grant 305684/2022-1]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0103 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0103 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0103},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {956-965},
  shortjournal = {INFORMS J. Comput.},
  title        = {VRPSolverEasy: A python library for the exact solution of a rich vehicle routing problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PyVRP: A high-performance VRP solver package. <em>IJOC</em>,
<em>36</em>(4), 943–955. (<a
href="https://doi.org/10.1287/ijoc.2023.0055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce PyVRP, a Python package that implements hybrid genetic search in a state-of-the-art vehicle routing problem (VRP) solver. The package is designed for the VRP with time windows (VRPTW) but can be easily extended to support other VRP variants. PyVRP combines the flexibility of Python with the performance of C++ by implementing (only) performance-critical parts of the algorithm in C++ while being fully customizable at the Python level. PyVRP is a polished implementation of the algorithm that ranked first in the 2021 DIMACS VRPTW challenge and, after improvements, ranked first on the static variant of the EURO meets NeurIPS 2022 vehicle routing competition. The code follows good software engineering practices and is well documented and unit tested. PyVRP is freely available under the liberal MIT license. Through numerical experiments, we show that PyVRP achieves state-of-the-art results on the VRPTW and capacitated VRP. We hope that PyVRP enables researchers and practitioners to easily and quickly build on a state-of-the-art VRP solver. History: Accepted by Ted Ralphs, Area Editor for Software Tools. This paper has been accepted for the INFORMS Journal on Computing Special Issue on Software Tools for Vehicle Routing. Funding: Funding was provided by TKI Dinalog, Topsector Logistics, and the Dutch Ministry of Economic Affairs and Climate Policy. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0055 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0055 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ . There is a video associated with this paper. Click here to view the Video Overview . To save the file, right click and choose “Save Link As” from the menu.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0055},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {943-955},
  shortjournal = {INFORMS J. Comput.},
  title        = {PyVRP: A high-performance VRP solver package},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Introduction to the special section on software tools for
vehicle routing. <em>IJOC</em>, <em>36</em>(4), 941–942. (<a
href="https://doi.org/10.1287/ijoc.2024.ed.v36.n4.2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2024.ed.v36.n4.2},
  journal      = {INFORMS Journal on Computing},
  month        = {7-8},
  number       = {4},
  pages        = {941-942},
  shortjournal = {INFORMS J. Comput.},
  title        = {Introduction to the special section on software tools for vehicle routing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A sequential follower refinement algorithm for robust
surgery scheduling. <em>IJOC</em>, <em>36</em>(3), 918–937. (<a
href="https://doi.org/10.1287/ijoc.2022.0191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An algorithm for the two-stage robust optimization surgery-to-operating room allocation problem is presented. The second-stage problem is an integer linear program whose convex hull is approximated using three types of specialized valid inequalities and Chvátal-Gomory cuts. The resulting linear relaxation of the second-stage problem is then dualized and integrated into the first-stage problem. The resulting mixed integer linear program, which is an approximation of the original problem, is then solved using a commercial solver. If the solution of this model is not optimal for the second-stage problem, valid inequalities for the second-stage problem are generated, yielding a type of column-generation based approach that we refer to as the sequential follower refinement ( SFR ) algorithm. Data from an academic medical center are used to compare the computational performance of SFR with the constraint and column generation ( C&amp;CG ) algorithm, which is the only exact approach that has been specifically applied for this problem in the literature. An extensive numerical study of SFR and its computational characteristics is presented that shows that SFR yields better-quality solutions compared with C&amp;CG , even as the termination criterion of SFR is met much sooner, especially for problems involving higher number of surgeries. History: Accepted by Paul Brooks, Area Editor for Applications in Biology, Medicine, &amp; Healthcare. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0191 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0191 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0191},
  journal      = {INFORMS Journal on Computing},
  month        = {5},
  number       = {3},
  pages        = {918-937},
  shortjournal = {INFORMS J. Comput.},
  title        = {A sequential follower refinement algorithm for robust surgery scheduling},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximate kernel learning uncertainty set for robust
combinatorial optimization. <em>IJOC</em>, <em>36</em>(3), 900–917. (<a
href="https://doi.org/10.1287/ijoc.2022.0330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector clustering (SVC) has been proposed in the literature as a data-driven approach to build uncertainty sets in robust optimization. Unfortunately, the resulting SVC-based uncertainty sets induces a large number of additional variables and constraints in the robust counterpart of mathematical formulations. We propose a two-phase method to approximate the resulting uncertainty sets and overcome these tractability issues. This method is controlled by a parameter defining a trade-off between the quality of the approximation and the complexity of the robust models formulated. We evaluate the approximation method on three distinct, well-known optimization problems. Experimental results show that the approximated uncertainty set leads to solutions that are comparable to those obtained with the classic SVC-based uncertainty set with a significant reduction of the computation time. History: Accepted by Andrea Lodi, Area Editor for Design and Analysis of Algorithms—Discrete. Funding: This work was supported by the German-French Academy for the Industry of the Future [Data-driven collaboration in Industrial Supply Chains project].},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0330},
  journal      = {INFORMS Journal on Computing},
  month        = {5},
  number       = {3},
  pages        = {900-917},
  shortjournal = {INFORMS J. Comput.},
  title        = {Approximate kernel learning uncertainty set for robust combinatorial optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving sparse separable bilinear programs using lifted
bilinear cover inequalities. <em>IJOC</em>, <em>36</em>(3), 884–899. (<a
href="https://doi.org/10.1287/ijoc.2022.0230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently a class of second-order cone representable convex inequalities called lifted bilinear cover inequalities were introduced, which are valid for a set described by a separable bilinear constraint together with bounds on variables. In this paper, we study the computational potential of these inequalities for separable bilinear optimization problems. We first prove that the semidefinite programming relaxation provides no benefit over the McCormick relaxation for such problems. We then design a simple randomized separation heuristic for lifted bilinear cover inequalities. In our computational experiments, we separate many rounds of these inequalities starting from McCormick’s relaxation of instances where each constraint is a separable bilinear constraint set. We demonstrate that there is a significant improvement in the performance of a state-of-the-art global solver in terms of gap closed, when these inequalities are added at the root node compared with when they are not. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms – Discrete. Funding: S. S. Dey gratefully acknowledges the support by the Office of Naval Research [Grant N000141912323].},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0230},
  journal      = {INFORMS Journal on Computing},
  month        = {5},
  number       = {3},
  pages        = {884-899},
  shortjournal = {INFORMS J. Comput.},
  title        = {Solving sparse separable bilinear programs using lifted bilinear cover inequalities},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient propagation techniques for handling cyclic
symmetries in binary programs. <em>IJOC</em>, <em>36</em>(3), 868–883.
(<a href="https://doi.org/10.1287/ijoc.2022.0060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presence of symmetries in binary programs typically degrades the performance of branch-and-bound solvers. In this article, we derive efficient variable fixing algorithms to discard symmetric solutions from the search space based on propagation techniques for cyclic groups. Our algorithms come with the guarantee to find all possible variable fixings that can be derived from symmetry arguments; that is, one cannot find more variable fixings than those found by our algorithms. Because every permutation symmetry group of a binary program has cyclic subgroups, the derived algorithms can be used to handle symmetries in any symmetric binary program. In experiments, we also provide numerical evidence that our algorithms handle symmetries more efficiently than other variable fixing algorithms for cyclic symmetries. History: Accepted by Andrea Lodi, Area Editor for Design and Analysis of Algorithms—Discrete. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoc.2022.0060 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0060},
  journal      = {INFORMS Journal on Computing},
  month        = {5},
  number       = {3},
  pages        = {868-883},
  shortjournal = {INFORMS J. Comput.},
  title        = {Efficient propagation techniques for handling cyclic symmetries in binary programs},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A column generation scheme for distributionally robust
multi-item newsvendor problems. <em>IJOC</em>, <em>36</em>(3), 849–867.
(<a href="https://doi.org/10.1287/ijoc.2022.0010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a distributionally robust multi-item newsvendor problem, where the demand distribution is unknown but specified with a general event-wise ambiguity set. Using the event-wise affine decision rules, we can obtain a conservative approximation formulation of the problem, which can typically be further reformulated as a linear program. In order to efficiently solve the resulting large-scale linear program, we develop a column generation-based decomposition scheme and speed up the computational efficiency by exploiting a special column selection strategy and stopping early based on a Karush-Kuhn-Tucker condition test. Focusing on the Wasserstein ambiguity set and the event-wise mean absolute deviation set, a computational study demonstrates both the computational efficiency of the proposed algorithm, which significantly outperforms a commercial solver and a Benders decomposition method, and the out-of-sample superiority of distributionally robust solutions relative to their sample average approximation counterparts. History: Accepted by Nicola Secomandi, Area Editor for Stochastic Models &amp; Reinforcement Learning. Funding: This work was supported by the Natural Sciences and Engineering Research Council of Canada [492997-2016, RGPIN-2016-05208], the National Natural Science Foundation of China [71972012], Alliance de recherche numérique du Canada, and Canada Research Chairs [CRC-2018-00105]. It was also supported by Groupe d’études et de recherche en analyse des décisions (GERAD). Finally, this research was enabled in part by support provided by Digital Research Alliance of Canada ( https://alliancecan.ca/en ). Supplemental Material: The software that supports the findings of this study is available within the paper and its supplemental information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0010 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0010 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0010},
  journal      = {INFORMS Journal on Computing},
  month        = {5},
  number       = {3},
  pages        = {849-867},
  shortjournal = {INFORMS J. Comput.},
  title        = {A column generation scheme for distributionally robust multi-item newsvendor problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimizing the weighted number of tardy jobs via
(max,+)-convolutions. <em>IJOC</em>, <em>36</em>(3), 836–848. (<a
href="https://doi.org/10.1287/ijoc.2022.0307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the fundamental scheduling problem of minimizing the weighted number of tardy jobs on a single machine. We present a simple pseudo polynomial-time algorithm for this problem that improves upon the classical Lawler and Moore algorithm from the late 60’s under certain scenarios and parameter settings. Our algorithm uses (max,+)-convolutions as its main tool, exploiting recent improved algorithms for computing such convolutions, and obtains several different running times depending on the specific improvement used. We also provide a related lower bound for the problem under a variant of the well-known Strong Exponential Time Hypothesis (SETH). History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms – Discrete. Funding: This work was supported by the Israel Science Foundation [Grant 1070/20].},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0307},
  journal      = {INFORMS Journal on Computing},
  month        = {5},
  number       = {3},
  pages        = {836-848},
  shortjournal = {INFORMS J. Comput.},
  title        = {Minimizing the weighted number of tardy jobs via (max,+)-convolutions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparsity-exploiting distributed projections onto a simplex.
<em>IJOC</em>, <em>36</em>(3), 820–835. (<a
href="https://doi.org/10.1287/ijoc.2022.0328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Projecting a vector onto a simplex is a well-studied problem that arises in a wide range of optimization problems. Numerous algorithms have been proposed for determining the projection; however, the primary focus of the literature is on serial algorithms. We present a parallel method that decomposes the input vector and distributes it across multiple processors for local projection. Our method is especially effective when the resulting projection is highly sparse, which is the case, for instance, in large-scale problems with independent and identically distributed (i.i.d.) entries. Moreover, the method can be adapted to parallelize a broad range of serial algorithms from the literature. We fill in theoretical gaps in serial algorithm analysis and develop similar results for our parallel analogues. Numerical experiments conducted on a wide range of large-scale instances, both real world and simulated, demonstrate the practical effectiveness of the method. History: Accepted by Antonio Frangioni, Area Editor for Design &amp; Analysis of Algorithms—Continuous. Funding: This work was supported by the Office of Naval Research [Grant N00014-23-1-2632]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0328 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0328 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0328},
  journal      = {INFORMS Journal on Computing},
  month        = {5},
  number       = {3},
  pages        = {820-835},
  shortjournal = {INFORMS J. Comput.},
  title        = {Sparsity-exploiting distributed projections onto a simplex},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Largest volume inscribed rectangles in convex sets defined
by finite number of inequalities. <em>IJOC</em>, <em>36</em>(3),
787–819. (<a href="https://doi.org/10.1287/ijoc.2022.0239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of finding maximum volume (axis-aligned) inscribed boxes in a compact convex set, defined by a finite number of convex inequalities, and presents optimization and geometric approaches for solving them. Several optimization models are developed that can be easily generalized to find other inscribed geometric shapes such as triangles, rhombi, and squares. To find the largest volume axis-aligned inscribed rectangles in the higher dimensions, an interior-point method algorithm is presented and analyzed. For two-dimensional space, a parametrized optimization approach is developed to find the largest area (axis-aligned) inscribed rectangles in convex sets. The optimization approach provides a uniform framework for solving a wide variety of relevant problems. Finally, two computational geometric ( 1 − ε ) –approximation algorithms with sublinear running times are presented that improve the previous results. History: Accepted by Antonio Frangioni, Area Editor for Design &amp; Analysis of Algorithms—Continuous. Funding: The author is grateful for the support of Northeastern University for this research. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0239 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0239 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0239},
  journal      = {INFORMS Journal on Computing},
  month        = {5},
  number       = {3},
  pages        = {787-819},
  shortjournal = {INFORMS J. Comput.},
  title        = {Largest volume inscribed rectangles in convex sets defined by finite number of inequalities},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Supervised ML for solving the GI/GI/1 queue. <em>IJOC</em>,
<em>36</em>(3), 766–786. (<a
href="https://doi.org/10.1287/ijoc.2022.0263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We apply supervised learning to a general problem in queueing theory: using a neural net , we develop a fast and accurate predictor of the stationary system-length distribution of a GI / GI /1 queue—a fundamental queueing model for which no analytical solutions are available. To this end, we must overcome three main challenges: (i) generating a large library of training instances that cover a wide range of arbitrary interarrival and service time distributions, (ii) labeling the training instances, and (iii) providing continuous arrival and service distributions as inputs to the neural net. To overcome (i), we develop an algorithm to sample phase-type interarrival and service time distributions with complex transition structures. We demonstrate that our distribution-generating algorithm indeed covers a wide range of possible positive-valued distributions. For (ii), we label our training instances via quasi-birth-and-death(QBD) that was used to approximate PH / PH /1 (with phase-type arrival and service process) as labels for the training data. For (iii), we find that using only the first five moments of both the interarrival and service times distribution as inputs is sufficient to train the neural net. Our empirical results show that our neural model can estimate the stationary behavior of the GI / GI /1—far exceeding other available methods in terms of both accuracy and runtimes. History: Ram Ramesh, Area Editor for Data Science and Machine Learning. Funding: O. Baron received financial support from the Natural Sciences and Engineering Research Council of Canada (NERC) [Grant 458051]. D. Krass received financial support from the NERC [Grant 458395]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0263 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0263 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0263},
  journal      = {INFORMS Journal on Computing},
  month        = {5},
  number       = {3},
  pages        = {766-786},
  shortjournal = {INFORMS J. Comput.},
  title        = {Supervised ML for solving the GI/GI/1 queue},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Product redesign and innovation based on online reviews: A
multistage combined search method. <em>IJOC</em>, <em>36</em>(3),
742–765. (<a href="https://doi.org/10.1287/ijoc.2022.0333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online reviews published on the e-commerce platform provide a new source of information for designers to develop new products. Past research on new product development (NPD) using user-generated textual data commonly focused solely on extracting and identifying product features to be improved. However, the competitive analysis of product features and more specific improvement strategies have not been explored deeply. This study fully uses the rich semantic attributes of online review texts and proposes a novel online review–driven modeling framework. This new approach can extract fine-grained product features; calculate their importance, performance, and competitiveness; and build a competitiveness network for each feature. As a result, decision making is assisted, and specific product improvement strategies are developed for NPD beyond existing modeling approaches in this domain. Specifically, online reviews are first classified into redesign- and innovation-related themes using a multiple embedding model, and the redesign and innovation product features can be extracted accordingly using a mutual information multilevel feature extraction method. Moreover, the importance and performance of features are calculated, and the competitiveness and competitiveness network of features are obtained through a personalized unidirectional bipartite graph algorithm. Finally, the importance performance competitiveness analysis plot is constructed, and the product improvement strategy is developed via a multistage combined search algorithm. Case studies and comparative experiments show the effectiveness of the proposed method and provide novel business insights for stakeholders, such as product providers, managers, and designers. History: Accepted by Ram Ramesh, Area Editor for Data Science and Machine Learning. Funding: This work was supported by the National Natural Science Foundation of China [Project 72071151] and the Natural Science Foundation of Hubei Province, China [Grant 2023CFB712]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0333 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0333 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0333},
  journal      = {INFORMS Journal on Computing},
  month        = {5},
  number       = {3},
  pages        = {742-765},
  shortjournal = {INFORMS J. Comput.},
  title        = {Product redesign and innovation based on online reviews: A multistage combined search method},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterative rule extension for logic analysis of data: An
MILP-based heuristic to derive interpretable binary classifiers from
large data sets. <em>IJOC</em>, <em>36</em>(3), 723–741. (<a
href="https://doi.org/10.1287/ijoc.2021.0284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven decision making is rapidly gaining popularity, fueled by the ever-increasing amounts of available data and encouraged by the development of models that can identify nonlinear input–output relationships. Simultaneously, the need for interpretable prediction and classification methods is increasing as this improves both our trust in these models and the amount of information we can abstract from data. An important aspect of this interpretability is to obtain insight in the sensitivity–specificity trade-off constituted by multiple plausible input–output relationships. These are often shown in a receiver operating characteristic curve. These developments combined lead to the need for a method that can identify complex yet interpretable input–output relationships from large data, that is, data containing large numbers of samples and features. Boolean phrases in disjunctive normal form (DNF) are highly suitable for explaining nonlinear input–output relationships in a comprehensible way. Mixed integer linear programming can be used to obtain these Boolean phrases from binary data though its computational complexity prohibits the analysis of large data sets. This work presents IRELAND, an algorithm that allows for abstracting Boolean phrases in DNF from data with up to 10,000 samples and features. The results show that, for large data sets, IRELAND outperforms the current state of the art in terms of prediction accuracy. Additionally, by construction, IRELAND allows for an efficient computation of the sensitivity–specificity trade-off curve, allowing for further understanding of the underlying input–output relationship. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms–Discrete. Funding: This work was supported by the Netherlands Organization for Scientific Research (Nederlandse Organisatie voor Wetenschappelijk Onderzoek) [Grant VI.VENI.192.043]. Supplemental Material: The online supplement is available at https://doi.org/10.1287/ijoc.2021.0284 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.0284},
  journal      = {INFORMS Journal on Computing},
  month        = {5},
  number       = {3},
  pages        = {723-741},
  shortjournal = {INFORMS J. Comput.},
  title        = {Iterative rule extension for logic analysis of data: An MILP-based heuristic to derive interpretable binary classifiers from large data sets},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving a class of cut-generating linear programs via
machine learning. <em>IJOC</em>, <em>36</em>(3), 708–722. (<a
href="https://doi.org/10.1287/ijoc.2022.0241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cut-generating linear programs (CGLPs) play a key role as a separation oracle to produce valid inequalities for the feasible region of mixed-integer programs. When incorporated inside branch-and-bound, the cutting planes obtained from CGLPs help to tighten relaxations and improve dual bounds. However, running the CGLPs at the nodes of the branch-and-bound tree is computationally cumbersome due to the large number of node candidates and the lack of a priori knowledge on which nodes admit useful cutting planes. As a result, CGLPs are often avoided at default settings of branch-and-cut algorithms despite their potential impact on improving dual bounds. In this paper, we propose a novel framework based on machine learning to approximate the optimal value of a CGLP class that determines whether a cutting plane can be generated at a node of the branch-and-bound tree. Translating the CGLP as an indicator function of the objective function vector, we show that it can be approximated through conventional data classification techniques. We provide a systematic procedure to efficiently generate training data sets for the corresponding classification problem based on the CGLP structure. We conduct computational experiments on benchmark instances using classification methods such as logistic regression. These results suggest that the approximate CGLP obtained from classification can improve the solution time compared with that of conventional cutting plane methods. Our proposed framework can be efficiently applied to a large number of nodes in the branch-and-bound tree to identify the best candidates for adding a cut. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms—Discrete. Supplemental Material: The e-companion is available at https://doi.org/10.1287/ijoc.2022.0241 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0241},
  journal      = {INFORMS Journal on Computing},
  month        = {5},
  number       = {3},
  pages        = {708-722},
  shortjournal = {INFORMS J. Comput.},
  title        = {Solving a class of cut-generating linear programs via machine learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient global optimal method for cardinality
constrained portfolio optimization. <em>IJOC</em>, <em>36</em>(2),
690–704. (<a href="https://doi.org/10.1287/ijoc.2022.0344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the cardinality constrained mean-variance portfolio optimization, in which only a small number of assets are invested. We first treat the covariance matrix of asset returns as a diagonal matrix with a special matrix processing technique. Using the dual theory, we formulate the lower bound problem of the original problem as a max-min optimization. For the inner minimization problem with the cardinality constraint, we obtain its analytical solution for the portfolio weights. Then, the lower bound problem turns out to be a simple concave optimization with respect to the Lagrangian multipliers. Thus, the interval split method and the supergradient method are developed to solve it. Based on the precise lower bound, the depth-first branch and bound method are designed to find the global optimal investment selection strategy. Compared with other lower bounds and the current popular mixed integer programming solvers, such as CPLEX and SCIP, the numerical experiments show that our method has a high searching efficiency. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Funding: This work was supported by the National Natural Science Foundation of China [Grants 12101317, 12271071, and 11991024], the Natural Science Foundation of Jiangsu Province [Grant BK20200819], the Team Project of Innovation Leading Talent in Chongqing [Grant CQYC20210309536], the Contract System Project of Chongqing Talent Plan [Grant cstc2022ycjh-bgzxm0147], and the Philosophy and Social Science Fund of Education Department of Jiangsu Province [Grant 2020SJA0168]. K.F.C. Yiu is supported in part by the Research Grants Council of Hong Hong [Grant PolyU 15223419], the Hong Kong Polytechnic University [Grants 4-ZZPT and 1-WZ0E], and the Research Centre for Quantitative Finance [Grant 1-CE03]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0344 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0344 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0344},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {690-704},
  shortjournal = {INFORMS J. Comput.},
  title        = {An efficient global optimal method for cardinality constrained portfolio optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correlation clustering problem under mediation.
<em>IJOC</em>, <em>36</em>(2), 672–689. (<a
href="https://doi.org/10.1287/ijoc.2022.0129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of community detection, correlation clustering (CC) provides a measure of balance for social networks as well as a tool to explore their structures. However, CC does not encompass features such as the mediation between the clusters, which could be all the more relevant with the recent rise of ideological polarization. In this work, we study correlation clustering under mediation (CCM), a new variant of CC in which a set of mediators is determined. This new signed graph clustering problem is proved to be NP-hard and formulated as an integer programming formulation. An extensive investigation of the mediation set structure leads to the development of two efficient exact enumeration algorithms for CCM. The first one exhaustively enumerates the maximal sets of mediators in order to provide several relevant solutions. The second algorithm implements a pruning mechanism, which drastically reduces the size of the exploration tree in order to return a single optimal solution. Computational experiments are presented on two sets of instances: signed networks representing voting activity in the European Parliament and random signed graphs. History: Accepted by Van Hentenryck, Area Editor for Pascal. Funding: This work was supported by Fondation Mathématique Jacques Hadamard [Grant P-2019-0031]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0129 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0129 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0129},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {672-689},
  shortjournal = {INFORMS J. Comput.},
  title        = {Correlation clustering problem under mediation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The descent–ascent algorithm for DC programming.
<em>IJOC</em>, <em>36</em>(2), 657–671. (<a
href="https://doi.org/10.1287/ijoc.2023.0142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a bundle method for the unconstrained minimization of nonsmooth difference-of-convex (DC) functions, and it is based on the calculation of a special type of descent direction called descent–ascent direction. The algorithm only requires evaluations of the minuend component function at each iterate, and it can be considered as a parsimonious bundle method as accumulation of information takes place only in case the descent–ascent direction does not provide a sufficient decrease. No line search is performed, and proximity control is pursued independent of whether the decrease in the objective function is achieved. Termination of the algorithm at a point satisfying a weak criticality condition is proved, and numerical results on a set of benchmark DC problems are reported. History: Accepted by Antonio Frangioni, Area Editor for Design &amp; Analysis of Algorithms – Continuous. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2023.0142 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2023.0142 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0142},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {657-671},
  shortjournal = {INFORMS J. Comput.},
  title        = {The Descent–Ascent algorithm for DC programming},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stabilizing grand cooperation via cost adjustment: An
inverse optimization approach. <em>IJOC</em>, <em>36</em>(2), 635–656.
(<a href="https://doi.org/10.1287/ijoc.2022.0268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For an unbalanced cooperative game, its grand coalition can be stabilized by some instruments, such as subsidization and penalization, that impose new cost terms to certain coalitions. In this paper, we study an alternative instrument, referred to as cost adjustment, that does not need to impose any new coalition-specific cost terms. Specifically, our approach is to adjust existing cost coefficients of the game under which (i) the game becomes balanced so that the grand coalition becomes stable, (ii) a desired way of cooperation is optimal for the grand coalition to adopt, and (iii) the total cost to be shared by the grand coalition is within a prescribed range. Focusing on a broad class of cooperative games, known as integer minimization games, we formulate the problem on how to optimize the cost adjustment as a constrained inverse optimization problem. We prove N P -hardness and derive easy-to-check feasibility conditions for the problem. Based on two linear programming reformulations, we develop two solution algorithms. One is a cutting-plane algorithm, which runs in polynomial time when the corresponding separation problem is polynomial time solvable. The other needs to explicitly derive all the inequalities of a linear program, which runs in polynomial time when the linear program contains only a polynomial number of inequalities. We apply our models and solution algorithms to two typical unbalanced games, including a weighted matching game and an uncapacitated facility location game, showing that their optimal cost adjustments can be obtained in polynomial time. History: Accepted by Area Editor Andrea Lodi for Design &amp; Analysis of Algorithms—Discrete. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72022018 and 72091210]; the Research Grants Council of the Hong Kong SAR, China [Grant 16210020]; Hong Kong Polytechnic University [Grant P0032007]; and the Youth Innovation Promotion Association, Chinese Academy of Sciences [Grant 2021454]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoc.2022.0268 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0268},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {635-656},
  shortjournal = {INFORMS J. Comput.},
  title        = {Stabilizing grand cooperation via cost adjustment: An inverse optimization approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning and image processing pipeline for object
characterization in firm operations. <em>IJOC</em>, <em>36</em>(2),
616–634. (<a href="https://doi.org/10.1287/ijoc.2022.0260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the abundance of images related to operations that are being captured and stored, it behooves firms to innovate systems using image processing to improve operational performance that refers to any activity that can save labor cost. In this paper, we use deep learning techniques, combined with classic image/signal processing methods, to propose a pipeline to solve certain types of object counting and layer characterization problems in firm operations. Using data obtained by us through a collaborative effort with real manufacturers, we demonstrate that the proposed pipeline method is able to achieve higher than 93% accuracy in layer and log counting. Theoretically, our study conceives, constructs, and evaluates proof of concept of a novel pipeline method in characterizing and quantifying the number of defined items with images, which overcomes the limitations of methods based only on deep learning or signal processing. Practically, our proposed method can help firms significantly reduce labor costs and/or improve quality and inventory control by recording the number of products in real time, more accurately and with minimal up-front technological investment. The codes and data are made publicly available online through the INFORMS Journal on Computing GitHub site. History: Accepted by Ram Ramesh, Area Editor for Data Science and Machine Learning. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0260 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0260 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0260},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {616-634},
  shortjournal = {INFORMS J. Comput.},
  title        = {A deep learning and image processing pipeline for object characterization in firm operations},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). InfrastructureModels: Composable multi-infrastructure
optimization in julia. <em>IJOC</em>, <em>36</em>(2), 600–615. (<a
href="https://doi.org/10.1287/ijoc.2022.0118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been an increasing need to understand the complex interdependencies between critical infrastructure systems, for example, electric power, natural gas, and potable water. Whereas open-source and commercial tools for the independent simulation of these systems are well established, frameworks for cosimulation with other systems are nascent and tools for co-optimization are scarce—the major challenge being the hidden combinatorics that arise when connecting multiple-infrastructure system models. Building toward a comprehensive solution for modeling interdependent infrastructure systems, this work presents I nfrastructure M odels , an extensible, open-source mathematical programming framework for co-optimizing multiple interdependent infrastructures. This work provides new insights into methods and programming abstractions that make state-of-the-art independent infrastructure models composable with minimal additional effort. To that end, this paper presents the design of the I nfrastructure M odels framework, documents key components of the software’s implementation, and demonstrates its effectiveness with three case studies on canonical co-optimization tasks arising in interdependent infrastructure systems. History: Accepted by Ted Ralphs, Area Editor for Software Tools. Funding: The work was funded by Los Alamos National Laboratory’s Directed Research and Development project “The Optimization of Machine Learning: Imposing Requirements on Artificial Intelligence” and the U.S. Department of Energy’s Office of Electricity Advanced Grid Modeling projects “Joint Power System and Natural Gas Pipeline Optimal Expansion Planning” and “Coordinated Planning and Operation of Water and Power Infrastructures for Increased Resilience and Reliability.” This work was carried out under the U.S. DOE contract no. [DE-AC52-06NA25396]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0118 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0118 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0118},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {600-615},
  shortjournal = {INFORMS J. Comput.},
  title        = {InfrastructureModels: Composable multi-infrastructure optimization in julia},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ensemble variance reduction methods for stochastic
mixed-integer programming and their application to the stochastic
facility location problem. <em>IJOC</em>, <em>36</em>(2), 587–599. (<a
href="https://doi.org/10.1287/ijoc.2021.0324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sample average approximation (SAA), the standard approach to stochastic mixed-integer programming, does not provide guidance for cases with limited computational budgets. In such settings, variance reduction is critical in identifying good decisions. This paper explores two closely related ensemble methods to determine effective decisions with a probabilistic guarantee. (a) The first approach recommends a decision by coordinating aggregation in the space of decisions as well as aggregation of objective values. This combination of aggregation methods generalizes the bagging method and the “compromise decision” of stochastic linear programming. Combining these concepts, we propose a stopping rule that provides an upper bound on the probability of early termination. (b) The second approach applies efficient computational budget allocation for objective function evaluation and contributes to identifying the best solution with a predicted lower bound on the probability of correct selection. It also reduces the variance of the upper bound estimate at optimality. Furthermore, it adaptively selects the evaluation sample size. Both approaches provide approximately optimal solutions even in cases with a huge number of scenarios, especially when scenarios are generated by using oracles/simulators. Finally, we demonstrate the effectiveness of these methods via extensive computational results for “megascale” (extremely large scale) stochastic facility location problems. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Funding: This work was supported by The Office of Naval Research [Grant N00014-20-1-2077] and the Air Force Office of Scientific Research [Grant FA9550-20-1-0006]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2021.0324 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2021.0324 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.0324},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {587-599},
  shortjournal = {INFORMS J. Comput.},
  title        = {Ensemble variance reduction methods for stochastic mixed-integer programming and their application to the stochastic facility location problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deterring the gray market: Product diversion detection via
learning disentangled representations of multivariate time series.
<em>IJOC</em>, <em>36</em>(2), 571–586. (<a
href="https://doi.org/10.1287/ijoc.2022.0155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A gray market emerges when some distributors divert products to unauthorized distributors/retailers to make sneaky profits from the manufacturers’ differential channel incentives, such as quantity discounts. Traditionally, manufacturers rely heavily on internal audits to periodically investigate the flows of products and funds so as to deter the gray market; however, this is too costly given the large number of distributors and their huge volumes of orders. Owing to the advances in data analytics techniques, the ordering quantities of a distributor over time, which form multivariate time series, can help reveal suspicious product diversion behaviors and narrow the audit scope drastically. To that end, in this paper, we build on the recent advancement of representation learning for time series and adopt a sequence autoencoder to automatically characterize the overall demand patterns. To cope with the underlying entangled factors and interfering information in the multivariate time series of ordering quantities, we develop a disentangled learning scheme to construct more effective sequence representations. An interdistributor correlation regularization is also proposed to ensure more reliable representations. Finally, given the highly scarce anomaly labels for the detection task, an unsupervised deep generative model based on the learned representations of the distributors is developed to estimate the densities of distributions, which enables the anomaly scores generated through end-to-end learning. Extensive experiments on a real-world distribution channel data set and a larger simulated data set empirically validate our model’s superior and robust performances compared with several state-of-the-art baselines. Additionally, our illustrative economic analysis demonstrates that the manufacturers can launch more targeted and cost-effective audits toward the suspected distributors recommended by our model so as to deter the gray market. History: Accepted by Ram Ramesh, Area Editor for Data Science &amp; Machine Learning. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72031001, 72301017, 72371011, and 72242101]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0155 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0155 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0155},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {571-586},
  shortjournal = {INFORMS J. Comput.},
  title        = {Deterring the gray market: Product diversion detection via learning disentangled representations of multivariate time series},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A decomposition method for the group-based quay crane
scheduling problem. <em>IJOC</em>, <em>36</em>(2), 543–570. (<a
href="https://doi.org/10.1287/ijoc.2022.0298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the quay crane scheduling problem (QCSP), which involves scheduling a fixed number of quay cranes to load and unload containers from ships in a maritime container terminal. The objective is to minimize the completion time while adhering to precedence, safety margin, and noncrossing constraints. Efficient scheduling of quay cranes plays a crucial role in reducing the time vessels spend at terminals. To solve the QCSP, we explore different schedule directions for the quay cranes. Specifically, we consider three directions: unidirectional, where the quay cranes maintain a consistent movement direction from upper to lower bays or vice versa after initial repositioning; bidirectional, allowing the cranes to change direction once during operations; and multidirectional, permitting freely changing movement direction during operations. For the bidirectional QCSP, we propose a new compact mathematical formulation. To obtain valid lower bounds on the optimal completion time, we derive various relaxations of this new formulation based on the different schedule directions. Our solution framework employs logic-based Benders decomposition, decomposing the problem into an assignment master problem and operation-sequence slave subproblems. Extensive computational experiments using benchmark instances from existing literature and newly generated instances validate the efficiency and effectiveness of the lower bounds and the exact solution approach. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms–Discrete. Funding: This work was supported by the Major Program of the National Natural Science Foundation of China [Grants 72192830 and 72192831], the National Natural Science Foundation of China [Grant 72102034], and the 111 Project [Grant B16009]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoc.2022.0298},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0298},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {543-570},
  shortjournal = {INFORMS J. Comput.},
  title        = {A decomposition method for the group-based quay crane scheduling problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A decision rule approach for two-stage data-driven
distributionally robust optimization problems with random recourse.
<em>IJOC</em>, <em>36</em>(2), 526–542. (<a
href="https://doi.org/10.1287/ijoc.2021.0306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study two-stage stochastic optimization problems with random recourse, where the coefficients of the adaptive decisions involve uncertain parameters. To deal with the infinite-dimensional recourse decisions, we propose a scalable approximation scheme via piecewise linear and piecewise quadratic decision rules. We develop a data-driven distributionally robust framework with two layers of robustness to address distributional uncertainty. We also establish out-of-sample performance guarantees for the proposed scheme. Applying known ideas, the resulting optimization problem can be reformulated as an exact copositive program that admits semidefinite programming approximations. We design an iterative decomposition algorithm, which converges under some regularity conditions, to reduce the runtime needed to solve this program. Through numerical examples for various known operations management applications, we demonstrate that our method produces significantly better solutions than the traditional sample-average approximation scheme especially when the data are limited. For the problem instances for which only the recourse cost coefficients are random, our method exhibits slightly inferior out-of-sample performance but shorter runtimes compared with a competing approach. History: Accepted by Nicola Secomandi, Area Editor for Stochastic Models &amp; Reinforcement Learning. Funding: This work was supported by the National Science Foundation [Grants 2342505 and 2343869]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2021.0306 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2021.0306 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.0306},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {526-542},
  shortjournal = {INFORMS J. Comput.},
  title        = {A decision rule approach for two-stage data-driven distributionally robust optimization problems with random recourse},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary algorithm on general cover with theoretically
guaranteed approximation ratio. <em>IJOC</em>, <em>36</em>(2), 510–525.
(<a href="https://doi.org/10.1287/ijoc.2022.0327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theoretical studies on evolutionary algorithms have developed vigorously in recent years. Many such algorithms have theoretical guarantees in both running time and approximation ratio. Some approximation mechanism seems to be inherently embedded in many evolutionary algorithms. In this paper, we identify such a relation by proposing a unified analysis framework for a global simple multiobjective evolutionary algorithm (GSEMO) and apply it on a minimum weight general cover problem, which is general enough to subsume many important problems including the minimum submodular cover problem in which the submodular function is real-valued, and the minimum connected dominating set problem for which the potential function is nonsubmodular. We show that GSEMO yields theoretically guaranteed approximation ratios matching those achievable by a greedy algorithm in expected polynomial time when the potential function g is polynomial in the input size and the minimum gap between different g -values is a constant. History: Accepted by Erwin Pesch, Area Editor for Heuristic Search &amp; Approximation Algorithms. Funding: This work was supported by National Natural Science Foundation of China [11771013, U20A2068]; Zhejiang Provincial Natural Science Foundation of China [LD19A010001].},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0327},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {510-525},
  shortjournal = {INFORMS J. Comput.},
  title        = {Evolutionary algorithm on general cover with theoretically guaranteed approximation ratio},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian network models for PTSD screening in veterans.
<em>IJOC</em>, <em>36</em>(2), 495–509. (<a
href="https://doi.org/10.1287/ijoc.2021.0174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of posttraumatic stress disorder (PTSD) has gained a lot of interest in clinical studies. Identifying patients with a high risk of PTSD can guide mental healthcare workers when making treatment decisions. The main goal of this paper is to propose several Bayesian network (BN) models to assess the probability that a veteran has PTSD when first visiting a U.S. Department of Veteran Affairs (VA) facility seeking medical care. The current practice is to use a five-question test called PC-PTSD-5. We aim to use the PC-PTSD-5 test, which is currently administered to most incoming new patients, and demographic information, military service history, and medical history. We construct a Bayes information criterion score-based BN, a group L 2 -regularized BN ( GL 2 -regularized BN), and a naïve Bayes BN to assess the probability that a patient has PTSD. The GL 2 -regularized BN is a new method for constructing a BN motivated by some of the challenges of analyzing this data set. A secondary goal is to identify which features are important in predicting PTSD. We discover that the following features help compute the probability of PTSD: PC-PTSD-5, service-connected flag, combat flag, agent orange flag, military sexual trauma flag, traumatic brain injury, and age. History: Accepted by Ram Ramesh, Area Editor for Data Science &amp; Machine Learning. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2021.0174 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2021.0174 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.0174},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {495-509},
  shortjournal = {INFORMS J. Comput.},
  title        = {Bayesian network models for PTSD screening in veterans},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An exact method for (constrained) assortment optimization
problems with product costs. <em>IJOC</em>, <em>36</em>(2), 479–494. (<a
href="https://doi.org/10.1287/ijoc.2022.0262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of optimizing assortment decisions in the presence of product-specific costs when customers choose according to a multinomial logit model. This problem is NP-hard, and approximate solutions methods have been proposed in the literature to obtain both lower and upper bounds in a tractable manner. We propose the first exact solution method for this problem and show that provably optimal assortments of instances with up to 1,000 products can be found, on average, in about 2/10 of a second. In particular, we propose a bounding procedure to enhance an approximation method originally proposed by Feldman and Topaloglu and provide tight lower and upper bounds at a fraction of a second. We show how these bounds can be used to effectively identify an optimal assortment. We also describe how to adapt our approach to handle cardinality or space/resource capacity constraints on the assortment as well as assortment optimization under a mixed-multinomial logit model. In both cases, our solution method provides significant computational boosts compared with exact methods from the literature.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0262},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {479-494},
  shortjournal = {INFORMS J. Comput.},
  title        = {An exact method for (Constrained) assortment optimization problems with product costs},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Flexible differentiable optimization via model
transformations. <em>IJOC</em>, <em>36</em>(2), 456–478. (<a
href="https://doi.org/10.1287/ijoc.2022.0283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce DiffOpt.jl, a Julia library to differentiate through the solution of optimization problems with respect to arbitrary parameters present in the objective and/or constraints. The library builds upon MathOptInterface, thus leveraging the rich ecosystem of solvers and composing well with modeling languages like JuMP. DiffOpt offers both forward and reverse differentiation modes, enabling multiple use cases from hyperparameter optimization to backpropagation and sensitivity analysis, bridging constrained optimization with end-to-end differentiable programming. DiffOpt is built on two known rules for differentiating quadratic programming and conic programming standard forms. However, thanks to its ability to differentiate through model transformations, the user is not limited to these forms and can differentiate with respect to the parameters of any model that can be reformulated into these standard forms. This notably includes programs mixing affine conic constraints and convex quadratic constraints or objective function. History: Accepted by Ted Ralphs, Area Editor for Software Tools. Funding: The work of A. Sharma on DiffOpt.jl was funded by the Google Summer of Code program through NumFocus. M. Besançon was partially supported through the Research Campus Modal funded by the German Federal Ministry of Education and Research [Grant 05M14ZAM, 05M20ZBM]. J. Dias Garcia was supported in part by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior – Brasil (CAPES) – Finance Code 001. B. Legat was supported by a BAEF Postdoctoral Fellowship, the NSF [Grant OAC-1835443], and the ERC Adv. [Grant 885682]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0283 ), as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0283 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0283},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {456-478},
  shortjournal = {INFORMS J. Comput.},
  title        = {Flexible differentiable optimization via model transformations},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combination chemotherapy optimization with discrete dosing.
<em>IJOC</em>, <em>36</em>(2), 434–455. (<a
href="https://doi.org/10.1287/ijoc.2022.0207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chemotherapy drug administration is a complex problem that often requires expensive clinical trials to evaluate potential regimens; one way to alleviate this burden and better inform future trials is to build reliable models for drug administration. This paper presents a mixed-integer program for combination chemotherapy (utilization of multiple drugs) optimization that incorporates various important operational constraints and, besides dose and concentration limits, controls treatment toxicity based on its effect on the count of white blood cells. To address the uncertainty of tumor heterogeneity, we also propose chance constraints that guarantee reaching an operable tumor size with a high probability in a neoadjuvant setting. We present analytical results pertinent to the accuracy of the model in representing biological processes of chemotherapy and establish its potential for clinical applications through a numerical study of breast cancer. History: Accepted by Paul Brooks, Area Editor for Applications in Biology, Medicine, &amp; Healthcare. Funding: This work was supported by the National Science Foundation [Grants CMMI-1933369 and CMMI-1933373]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0207 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0207 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0207},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {434-455},
  shortjournal = {INFORMS J. Comput.},
  title        = {Combination chemotherapy optimization with discrete dosing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On solving MAX-SAT using sum of squares. <em>IJOC</em>,
<em>36</em>(2), 417–433. (<a
href="https://doi.org/10.1287/ijoc.2023.0036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider semidefinite programming (SDP) approaches for solving the maximum satisfiability (MAX-SAT) problem and weighted partial MAX-SAT. It is widely known that SDP is well-suited to approximate (MAX-)2-SAT. Our work shows the potential of SDP also for other satisfiability problems by being competitive with some of the best solvers in the yearly MAX-SAT competition. Our solver combines sum of squares (SOS)–based SDP bounds and an efficient parser within a branch-and-bound scheme. On the theoretical side, we propose a family of semidefinite feasibility problems and show that a member of this family provides the rank-two guarantee. We also provide a parametric family of semidefinite relaxations for MAX-SAT and derive several properties of monomial bases used in the SOS approach. We connect two well-known SDP approaches for (MAX)-SAT in an elegant way. Moreover, we relate our SOS-SDP relaxations for partial MAX-SAT to the known SAT relaxations. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms – Discrete. Supplemental Material: The online appendix is available at https://doi.org/10.1287/ijoc.2023.0036 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2023.0036},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {417-433},
  shortjournal = {INFORMS J. Comput.},
  title        = {On solving MAX-SAT using sum of squares},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A consensus-based alternating direction method for
mixed-integer and PDE-constrained gas transport problems. <em>IJOC</em>,
<em>36</em>(2), 397–416. (<a
href="https://doi.org/10.1287/ijoc.2022.0319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider dynamic gas transport optimization problems, which lead to large-scale and nonconvex mixed-integer nonlinear optimization problems (MINLPs) on graphs. Usually, the resulting instances are too challenging to be solved by state-of-the-art MINLP solvers. In this paper, we use graph decompositions to obtain multiple optimization problems on smaller blocks, which can be solved in parallel and may result in simpler classes of optimization problems because not every block necessarily contains mixed-integer or nonlinear aspects. For achieving feasibility at the interfaces of the several blocks, we employ a tailored consensus-based penalty alternating direction method. Our numerical results show that such decomposition techniques can outperform the baseline approach of just solving the overall MINLP from scratch. However, a complete answer to the question of how to decompose MINLPs on graphs in dependence of the given model is still an open topic for future research. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms–Discrete. Funding: This work was supported by Deutsche Forschungsgemeinschaft [Grant TRR 154].},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0319},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {397-416},
  shortjournal = {INFORMS J. Comput.},
  title        = {A consensus-based alternating direction method for mixed-integer and PDE-constrained gas transport problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A differentiable path-following method with a compact
formulation to compute proper equilibria. <em>IJOC</em>, <em>36</em>(2),
377–396. (<a href="https://doi.org/10.1287/ijoc.2022.0148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of proper equilibrium was established as a strict refinement of perfect equilibrium. This establishment has significantly advanced the development of game theory and its applications. Nonetheless, it remains a challenging problem to compute such an equilibrium. This paper develops a differentiable path-following method with a compact formulation to compute a proper equilibrium. The method incorporates square-root-barrier terms into payoff functions with an extra variable and constitutes a square-root-barrier game. As a result of this barrier game, we acquire a smooth path to a proper equilibrium. To further reduce the computational burden, we present a compact formulation of an ε -proper equilibrium with a polynomial number of variables and equations. Numerical results show that the differentiable path-following method is numerically stable and efficient. Moreover, by relaxing the requirements of proper equilibrium and imposing Selten’s perfection, we come up with the notion of perfect d -proper equilibrium, which approximates a proper equilibrium and is less costly to compute. Numerical examples demonstrate that even when d is rather large, a perfect d -proper equilibrium remains to be a proper equilibrium. History: Accepted by Antonio Frangioni, Area Editor for Design &amp; Analysis of Algorithms-Continuous. Funding: This work was partially supported by General Research Fund (GRF) CityU 11306821 of Hong Kong SAR Government. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0148 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0148 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0148},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {377-396},
  shortjournal = {INFORMS J. Comput.},
  title        = {A differentiable path-following method with a compact formulation to compute proper equilibria},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Group equality in adaptive submodular maximization.
<em>IJOC</em>, <em>36</em>(2), 359–376. (<a
href="https://doi.org/10.1287/ijoc.2022.0384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the classic submodular maximization problem subject to a group equality constraint under both nonadaptive and adaptive settings. It is shown that the utility function of many machine learning applications, including data summarization, influence maximization in social networks, and personalized recommendation, satisfies the property of submodularity. Hence, maximizing a submodular function subject to various constraints can be found at the heart of many of those applications. On a high level, submodular maximization aims to select a group of most representative items (e.g., data points). However, the design of most existing algorithms does not incorporate the fairness constraint, leading to underrepresentation or overrepresentation of some particular groups. This motivates us to study the submodular maximization problem with group equality, in which we aim to select a group of items to maximize a (possibly nonmonotone) submodular utility function subject to a group equality constraint. To this end, we develop the first constant-factor approximation algorithm for this problem. The design of our algorithm is robust enough to be extended to solving the submodular maximization problem under a more complicated adaptive setting. Moreover, we further extend our study to incorporating a global cardinality constraint and other fairness notations. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms–Discrete. Supplemental Material: The online supplement is available at https://doi.org/10.1287/ijoc.2022.0384 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0384},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {359-376},
  shortjournal = {INFORMS J. Comput.},
  title        = {Group equality in adaptive submodular maximization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Seamless multimodal transportation scheduling.
<em>IJOC</em>, <em>36</em>(2), 336–358. (<a
href="https://doi.org/10.1287/ijoc.2019.0163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ride-hailing services have expanded the role of shared mobility in passenger transportation systems, creating new markets and creative planning solutions for major urban centers. In this paper, we consider their use for the first-mile or last-mile passenger transportation in coordination with a mass transit service to provide a seamless multimodal transportation experience for the user. A system that provides passengers with predictable information on travel and waiting times in their commutes is immensely valuable. We envision that the passengers will inform the system of their desired travel and arrival windows so that the system can jointly optimize the schedules of passengers. The problem we study balances minimizing travel time and the number of trips taken by the last-mile vehicles, so that long-term planning, maintenance, and environmental impact are all taken into account. We focus on the case where the last-mile service aggregates passengers by destination. We show that this problem is NP-hard, and we propose a decision diagram–based branch-and-price decomposition model that can solve instances of real-world size (10,000 passengers spread over an hour, 50 last-mile destinations, 600 last-mile vehicles) in computational time (∼1 minute) that is orders of magnitude faster than the solution times of other methods appearing in the literature. Our experiments also indicate that aggregating passengers by destination on the last-mile service provides high-quality solutions to more general settings. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods and Analysis. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2019.0163 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2019.0163 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2019.0163},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {336-358},
  shortjournal = {INFORMS J. Comput.},
  title        = {Seamless multimodal transportation scheduling},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BilevelJuMP.jl: Modeling and solving bilevel optimization
problems in julia. <em>IJOC</em>, <em>36</em>(2), 327–335. (<a
href="https://doi.org/10.1287/ijoc.2022.0135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present BilevelJuMP.jl, a new Julia package to support bilevel optimization within the JuMP framework. The package is a Julia library that enables the user to describe both upper and lower-level optimization problems using the JuMP algebraic syntax. Because of the generality and flexibility that our library inherits from JuMP’s syntax, our package allows users to model bilevel optimization problems with conic constraints in the lower level and all constraints supported by JuMP in the upper level including conic, quadratic, and nonlinear constraints. Moreover, the models defined with the syntax from BilevelJuMP.jl can be solved by multiple techniques that are based on reformulations as mathematical programs with equilibrium constraints (MPEC). Manipulations on the original problem data are possible due to MathOptInterface.jl’s structures and Dualization.jl features. Hence, the proposed package allows quick modeling, deployment, and thereby experimenting with bilevel models based on off-the-shelf mixed-integer linear programming and nonlinear solvers. History: Accepted by Ted Ralphs, Area Editor for Software Tools. Funding: The authors were partially supported by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES) - Finance Code 001. The work of A. Street was also partially supported by Fundação Carlos Chagas Filho de Amparo à Pesquisa do Estado do Rio de Janeiro (FAPERJ) and Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq). The work was partially funded by the project P&amp;D ANEEL PD-00403-0050/2020 sponsored by ENGIE BRASIL ENERGIA S.A. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0135 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0135 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0135},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {327-335},
  shortjournal = {INFORMS J. Comput.},
  title        = {BilevelJuMP.jl: Modeling and solving bilevel optimization problems in julia},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heuristic search for rank aggregation with application to
label ranking. <em>IJOC</em>, <em>36</em>(2), 308–326. (<a
href="https://doi.org/10.1287/ijoc.2022.0019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rank aggregation combines the preference rankings of multiple alternatives from different voters into a single consensus ranking, providing a useful model for a variety of practical applications but posing a computationally challenging problem. In this paper, we provide an effective hybrid evolutionary ranking algorithm to solve the rank aggregation problem with both complete and partial rankings. The algorithm features a semantic crossover based on concordant pairs and an enhanced late acceptance local search method reinforced by a relaxed acceptance and replacement strategy and a fast incremental evaluation mechanism. Experiments are conducted to assess the algorithm, indicating a highly competitive performance on both synthetic and real-world benchmark instances compared with state-of-the-art algorithms. To demonstrate its practical usefulness, the algorithm is applied to label ranking, a well-established machine learning task. We additionally analyze several key algorithmic components to gain insight into their operation. History: Accepted by Erwin Pesch, Area Editor for Heuristic Search &amp; Approximation Algorithms. Funding: This work was supported by the National Natural Science Foundation of China [Grant 72371157] and Shanghai Pujiang Programme [Grant 23PJC069]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0019 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0019 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0019},
  journal      = {INFORMS Journal on Computing},
  month        = {3},
  number       = {2},
  pages        = {308-326},
  shortjournal = {INFORMS J. Comput.},
  title        = {Heuristic search for rank aggregation with application to label ranking},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing branch-and-bound for multiobjective 0-1
programming. <em>IJOC</em>, <em>36</em>(1), 285–304. (<a
href="https://doi.org/10.1287/ijoc.2022.0299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the biobjective branch-and-bound literature, a key ingredient is objective branching, that is, to create smaller and disjoint subproblems in the objective space, obtained from the partial dominance of the lower bound set by the upper bound set. When considering three or more objective functions, however, applying objective branching becomes more complex, and its benefit has so far been unclear. In this paper, we investigate several ingredients that allow us to better exploit objective branching in a multiobjective setting. We extend the idea of probing to multiple objectives for the 0-1 case, enhance it in several ways, and show that, when coupled with objective branching, it results in significant speedups in terms of CPU times. We also show how to adapt it to the general integer case. Furthermore, we investigate cut generation based on the objective branching constraints. Besides, we generalize the best bound idea for node selection to multiple objectives, and we show that the proposed rules outperform, in the multiobjective literature, the commonly employed depth-first and breadth-first strategies. We also analyze problem-specific branching rules. We test the proposed ideas on available benchmark instances for three problem classes with three and four objectives, namely, the capacitated facility location problem, the uncapacitated facility location problem, and the knapsack problem. Our enhanced multiobjective branch-and-bound algorithm outperforms the best existing branch-and-bound–based approach and is the first to obtain competitive and even slightly better results than a state-of-the-art objective space search method on a subset of the problem classes. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms – Discrete. Funding: This work was supported in whole, or in part, by the Austrian Science Fund [Grant P 31366]. Supplemental Material: The online supplement is available at https://doi.org/10.1287/ijoc.2022.0299 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0299},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {285-304},
  shortjournal = {INFORMS J. Comput.},
  title        = {Enhancing branch-and-bound for multiobjective 0-1 programming},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Monte carlo methods for economic capital. <em>IJOC</em>,
<em>36</em>(1), 266–284. (<a
href="https://doi.org/10.1287/ijoc.2021.0261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Economic capital (EC) is a risk measure used by financial firms to specify capital levels to protect (with high probability) against large unforeseen losses. Defined as the difference between an (extreme) quantile and the mean of the loss distribution, the EC is often estimated via Monte Carlo methods. Although simple random sampling (SRS) may be effective in estimating the mean, it can be inefficient for the extreme quantile in the EC. Applying importance sampling (IS) may lead to an efficient quantile estimator but can do poorly for the mean. Measure-specific IS (MSIS) instead uses IS to estimate only the quantile, and the mean is independently handled via SRS. We analyze large-sample properties of EC estimators obtained via SRS only, IS only, MSIS, IS using a defensive mixture, and a double estimator using both SRS and IS to estimate both the quantile and the mean, establishing Bahadur-type representations for the EC estimators and proving they obey central limit theorems. We provide asymptotic theory comparing the estimators when the loss is the sum of a large number of independent and identically distributed random variables. Numerical and simulation results, including for a large portfolio credit risk model with dependent obligors, complement the theory. History: Accepted by Bruno Tuffin, Area Editor for Simulation. Funding: This work was supported by the National Science Foundation [Grant CMMI-1537322]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2021.0261 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2021.0261 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.0261},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {266-284},
  shortjournal = {INFORMS J. Comput.},
  title        = {Monte carlo methods for economic capital},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact matrix factorization updates for nonlinear
programming. <em>IJOC</em>, <em>36</em>(1), 245–265. (<a
href="https://doi.org/10.1287/ijoc.2021.0331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LU and Cholesky matrix factorization algorithms are core subroutines used to solve systems of linear equations (SLEs) encountered when solving an optimization problem. Standard floating-point algorithms are highly efficient but remain susceptible to the accumulation of round-off errors, which can lead solvers to return feasibility and optimality claims that are actually invalid. This paper introduces a novel direct solution approach for solving sequences of closely related SLEs encountered in nonlinear programming efficiently and without round-off errors. Specifically, it introduces rank-one update algorithms for the round-off error–free factorization framework, a tool set built on integer-preserving arithmetic that has led to the development and implementation of extremely reliable subroutines for solving SLEs occurring in linear programming. The formal guarantees of the presented algorithms are established through the derivation of theoretical insights. Their advantages are supported with computational experiments, which demonstrate upward of 75× improvements over exact factorization runtimes on fully dense matrices with more than one million entries. A significant advantage of the featured integer-preserving framework is that the length of any matrix coefficient produced by its algorithms is bounded polynomially in the size of the inputs without having to resort to greatest common divisor operations, which are required by and thereby hinder an efficient implementation of exact rational arithmetic approaches. History: Accepted by Antonio Frangioni, Area Editor for Design &amp; Analysis of Algorithms–Continuous. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2021.0331 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2021.0331 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.0331},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {245-265},
  shortjournal = {INFORMS J. Comput.},
  title        = {Exact matrix factorization updates for nonlinear programming},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Resource-window reduction by reduced costs in path-based
formulations for routing and scheduling problems. <em>IJOC</em>,
<em>36</em>(1), 224–244. (<a
href="https://doi.org/10.1287/ijoc.2022.0214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many routing and scheduling problems are modeled through variables that represent paths (routes, schedules, etc.). For such extensive formulations, branch-price-and-cut (BPC) algorithms nowadays constitute the leading exact solution technique, and most of the time, the pricing problem is a shortest-path problem with resource constraints that can be solved by a dynamic-programming labeling algorithm. For this setting, variable fixing techniques based on the reduced costs of the paths have been proposed with the aim of eliminating arcs from the underlying network and speeding up the solution process of the pricing problem as well as of the overall BPC algorithm. For an efficient variable fixation, bidirectional labeling must be possible. We move one step forward and show how the reduced costs of paths can also be exploited to reduce the resource windows for many types of resources, including the time resource and a load-related resource. This can be achieved without modifying the pricing problem network and altering the structure of the pricing problem itself. Moreover, different resources can be considered simultaneously. A straightforward reduction of the resource windows associated with the vertices of the network can tighten them, but this reduction does not translate into savings in computation times. On the contrary, the reduction of the resource windows is effective when distinct forward and backward resource windows are defined for each arc and reduced independently based on the traversal direction of the arc itself. Moreover, an arc can be eliminated when one of its arc-specific resource windows becomes empty, and the explicit use of variable fixing techniques can be avoided. Computational results obtained for benchmark instances of the vehicle-routing problem with time windows show that the overall computation times of the BPC algorithm can be significantly reduced compared with a fully fledged BPC algorithm using variable fixing techniques. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms – Discrete. Funding: This research was supported by the Deutsche Forschungsgemeinschaft (DFG) [Grants GS 83/1-1 and IR 122/10-1] of Project 418727865. This support is gratefully acknowledged.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0214},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {224-244},
  shortjournal = {INFORMS J. Comput.},
  title        = {Resource-window reduction by reduced costs in path-based formulations for routing and scheduling problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast continuous and integer l-shaped heuristics through
supervised learning. <em>IJOC</em>, <em>36</em>(1), 203–223. (<a
href="https://doi.org/10.1287/ijoc.2022.0175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a methodology at the nexus of operations research and machine learning (ML) leveraging generic approximators available from ML to accelerate the solution of mixed-integer linear two-stage stochastic programs. We aim at solving problems where the second stage is demanding. Our core idea is to gain large reductions in online solution time, while incurring small reductions in first-stage solution accuracy by substituting the exact second-stage solutions with fast, yet accurate, supervised ML predictions. This upfront investment in ML would be justified when similar problems are solved repeatedly over time—for example, in transport planning related to fleet management, routing, and container yard management. Our numerical results focus on the problem class seminally addressed with the integer and continuous L-shaped cuts. Our extensive empirical analysis is grounded in standardized families of problems derived from stochastic server location (SSLP) and stochastic multi-knapsack (SMKP) problems available in the literature. The proposed method can solve the hardest instances of SSLP in less than 9% of the time it takes the state-of-the-art exact method, and in the case of SMKP, the same figure is 20%. Average optimality gaps are, in most cases, less than 0.1%. History: Accepted by Alice Smith, Area Editor (for this paper) for Design and Analysis of Algorithms–Discrete. Funding: Financial support from the Institut de Valorisation des Données (IVADO) Fundamental Research Project Grants [project entitled “Machine Learning for (Discrete) Optimization”]; Canada Research Chairs; the Natural Sciences and Engineering Research Council of Canada [Collaborative Research and Development Grant CRD-477938-14]; and the Canadian National Railway Company Chair in Optimization of Railway Operations at Université de Montréal is gratefully acknowledged. E. Frejinger holds a Canada Research Chair. Computations were made on the supercomputer Béluga, managed by Calcul Québec and Digital Research Alliance of Canada. The operation of this supercomputer is funded by the Canada Foundation for Innovation; the Ministère de l’Économie, de la Science et de l’Innovation du Québec; and the Fonds de Recherche du Québec – Nature et Technologies.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0175},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {203-223},
  shortjournal = {INFORMS J. Comput.},
  title        = {Fast continuous and integer L-shaped heuristics through supervised learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated optimization under intermittent client
availability. <em>IJOC</em>, <em>36</em>(1), 185–202. (<a
href="https://doi.org/10.1287/ijoc.2022.0057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a new distributed machine learning framework, where numerous heterogeneous clients collaboratively train a model without sharing training data. In this work, we consider a practical and ubiquitous issue when deploying federated learning in mobile environments: intermittent client availability , where the set of eligible clients may change during the training process. Such intermittent client availability would seriously deteriorate the performance of the classical federated averaging algorithm (FedAvg). Thus, we propose a simple distributed nonconvex optimization algorithm, called federated latest averaging (FedLaAvg), which leverages the latest gradients of all clients, even when the clients are not available, to jointly update the global model in each iteration. Our theoretical analysis shows that FedLaAvg achieves guaranteed convergence and a sublinear speedup with respect to the total number of clients. We implement FedLaAvg along with several baselines and evaluate them over the benchmarking MNIST and Sentiment140 data sets. The evaluation results demonstrate that FedLaAvg achieves more stable training than FedAvg in both convex and nonconvex settings and reaches a sublinear speedup. Source code and online supplement are available at the IJOC GitHub site ( http://dx.doi.org/10.1287/ijoc.2022.0057.cd , https://github.com/INFORMSJoC/2022.0057 ). History: Accepted by Ram Ramesh, Area Editor for Data Science &amp; Machine Leaning. Funding: This work was supported by the National Key R&amp;D Program of China [Grant 2022ZD0119100], the National Natural Science Foundation of China (NSFC) [Grants 61972252, 61972254, 62072303, 62025204, 62132018, 62202296, and 62202297], the Alibaba Innovation Research (AIR) Program, and the Tencent Rhino Bird Key Research Project. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0057 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0057 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0057},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {185-202},
  shortjournal = {INFORMS J. Comput.},
  title        = {Federated optimization under intermittent client availability},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automation of strategic data prioritization in system model
calibration: Sensor placement. <em>IJOC</em>, <em>36</em>(1), 163–184.
(<a href="https://doi.org/10.1287/ijoc.2022.0128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model calibration is challenging for large-scale system models with a great number of variables. Existing approaches to partitioning system models and prioritizing data acquisition rely on heuristics rather than formal treatments. The sensor placement problem in physical dynamic systems points to a promising avenue for formalizing data acquisition priorities, which addresses the following question for system models: With the model at hand and pre-existing data availability on a subset of model variables, what are the (next) k model variables that would bring the largest utility to model calibration, once their data are acquired? In this study, we formalize this problem as a combinatorial optimization and adapt two solutions, the information-entropy approach and the miss-probability approach, from physical dynamic systems to system models in management sciences. Next, based on the idea of the data availability partition, we develop a third solution. The new approach can be understood from the entropy perspective and is embedded in the theoretical framework for the evaluation of side information. Our solution applies to system models of all topologies: analytical results of the optimal placement are derived for binary/multinary trees; for general (directed) tree structures, an algorithm to determine the optimal placement is devised, whose complexity is upper-bounded by O ( nlog 2 ( n ) ) for an n -variable system; for arbitrary model topologies with the presence of loops, sequential-optimal and simulated-annealing schemes are formulated. Three approaches are compared on a validating example; our solution outperforms the two alternatives. Application on a multicompartment system demonstrates the toolkit’s practical use. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0128 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0128 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0128},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {163-184},
  shortjournal = {INFORMS J. Comput.},
  title        = {Automation of strategic data prioritization in system model calibration: Sensor placement},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A numerically exact algorithm for the bin-packing problem.
<em>IJOC</em>, <em>36</em>(1), 141–162. (<a
href="https://doi.org/10.1287/ijoc.2022.0257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a numerically exact algorithm for solving the Bin-Packing Problem (BPP) based on a branch-price-and-cut framework combined with a pattern-enumeration method. Key to the algorithm is a novel technique for the computation of numerically safe dual bounds for the widely adopted set covering reformulation of the BPP (tightened with additional valid inequalities) with a precision that is higher than the one of general-purpose floating-point solvers. Our branch-price-and-cut algorithm also relies on an exact integer (fixed-point) label setting algorithm for solving the pricing problem associated with the tightened set-covering formulation. To the best of our knowledge, ours is the first algorithm for the BPP that is numerically exact and practical for solving large-scale instances. Extensive computational results on instances affected by notorious numerical difficulties (those of the Augmented Non-IRUP class) show that our exact algorithm outperforms all of the not numerically exact state-of-the-art algorithms based on branch-and-cut-and-price techniques that rely on a set-covering formulation of the BPP. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms − Discrete.},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0257},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {141-162},
  shortjournal = {INFORMS J. Comput.},
  title        = {A numerically exact algorithm for the bin-packing problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A study on optimal release schedule for multiversion
software. <em>IJOC</em>, <em>36</em>(1), 121–140. (<a
href="https://doi.org/10.1287/ijoc.2021.0141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on software reliability growth models (SRGMs) has been extensively conducted for decades, and the models were often developed based on two assumptions: (1) once the errors are detected, they can be completely removed instantly, and (2) errors can be removed eternally, and the debugging tasks will not produce any new errors. However, both assumptions are unrealistic. This study proposes an SRGM that ignores these restricted assumptions by introducing a detection process that may remove an error after a period of time once it has been detected and by considering imperfect debugging, which indicates that new errors may emerge through corresponding debugging tasks. In addition, because software can be upgraded to respond on a timely basis to constantly changing consumer expectations and thus extend product life in the market, the proposed SRGM also considers software upgrades for the multiversion software, and a dynamic programming approach is used to effectively obtain the optimal release schedule with consideration of the constraint of budget. Real data sets are used to examine the effectiveness of the proposed model, and the fitting results show that the proposed model outperforms other existing models. The results of numerical validation indicate that the proposed dynamic programming method with information updating outperforms the sequential solution method in determining the optimal release time for each version. Moreover, decision makers should carefully evaluate the parameters because overestimating the parameters of the mean value functions will cause serious software risk due to excessively shortening the testing time. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2021.0141 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2021.0141 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.0141},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {121-140},
  shortjournal = {INFORMS J. Comput.},
  title        = {A study on optimal release schedule for multiversion software},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). D-optimal data fusion: Exact and approximation algorithms.
<em>IJOC</em>, <em>36</em>(1), 97–120. (<a
href="https://doi.org/10.1287/ijoc.2022.0235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the D-optimal Data Fusion (DDF) problem, which aims to select new data points, given an existing Fisher information matrix, so as to maximize the logarithm of the determinant of the overall Fisher information matrix. We show that the DDF problem is NP-hard and has no constant-factor polynomial-time approximation algorithm unless P = NP. Therefore, to solve the DDF problem effectively, we propose two convex integer-programming formulations and investigate their corresponding complementary and Lagrangian-dual problems. Leveraging the concavity of the objective functions in the two proposed convex integer-programming formulations, we design an exact algorithm, aimed at solving the DDF problem to optimality. We further derive a family of submodular valid inequalities and optimality cuts, which can significantly enhance the algorithm performance. We also develop scalable randomized-sampling and local-search algorithms with provable performance guarantees. Finally, we test our algorithms using real-world data on the new phasor-measurement-units placement problem for modern power grids, considering the existing conventional sensors. Our numerical study demonstrates the efficiency of our exact algorithm and the scalability and high-quality outputs of our approximation algorithms. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms—Discrete. Funding: Y. Li and W. Xie were supported in part by Division of Civil, Mechanical and Manufacturing Innovation [Grant 2046414] and Division of Computing and Communication Foundations [Grant 2246417]. J. Lee was supported in part by Air Force Office of Scientific Research [Grants FA9550-19-1-0175 and FA9550-22-1-0172]. M. Fampa was supported in part by Conselho Nacional de Desenvolvimento Científico e Tecnológico [Grants 305444/2019-0 and 434683/2018-3]. F. Qiu and R. Yao were supported in part by the U.S. Department of Energy Advanced Grid Modeling Program under [Grant DE-OE0000875]. Supplemental Material: The e-companion is available at https://doi.org/10.1287/ijoc.2022.0235 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0235},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {97-120},
  shortjournal = {INFORMS J. Comput.},
  title        = {D-optimal data fusion: Exact and approximation algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adjustable robust optimization with discrete uncertainty.
<em>IJOC</em>, <em>36</em>(1), 78–96. (<a
href="https://doi.org/10.1287/ijoc.2022.0086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study adjustable robust optimization (ARO) problems with discrete uncertainty. Under a very general modeling framework, we show that such two-stage robust problems can be exactly reformulated as ARO problems with objective uncertainty only. This reformulation is valid with and without the fixed recourse assumption and is not limited to continuous wait-and-see decision variables unlike most of the existing literature. Additionally, we extend an enumerative algorithm akin to a branch-and-cut scheme for which we study the asymptotic convergence. We discuss how to apply the reformulation on two variants of well-known optimization problems, a facility location problem in which uncertainty may affect the capacity values and a multiple knapsack problem with uncertain weights, and we report extensive computational results demonstrating the effectiveness of the approach. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms – Discrete. Funding: This work was supported by the Air Force Office of Scientific Research [Grants FA8655-20-1-7012, FA8655-20-1-7019].},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0086},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {78-96},
  shortjournal = {INFORMS J. Comput.},
  title        = {Adjustable robust optimization with discrete uncertainty},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DiversiTree: A new method to efficiently compute diverse
sets of near-optimal solutions to mixed-integer optimization problems.
<em>IJOC</em>, <em>36</em>(1), 61–77. (<a
href="https://doi.org/10.1287/ijoc.2022.0164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although most methods for solving mixed-integer optimization problems compute a single optimal solution, a diverse set of near-optimal solutions can often lead to improved outcomes. We present a new method for finding a set of diverse solutions by emphasizing diversity within the search for near-optimal solutions. Specifically, within a branch-and-bound framework, we investigated parameterized node selection rules that explicitly consider diversity. Our results indicate that our approach significantly increases the diversity of the final solution set. When compared with two existing methods, our method runs with similar runtime as regular node selection methods and gives a diversity improvement between 12% and 190%. In contrast, popular node selection rules, such as best-first search, in some instances performed worse than state-of-the-art methods by more than 35% and gave an improvement of no more than 130%. Furthermore, we find that our method is most effective when diversity in node selection is continuously emphasized after reaching a minimal depth in the tree and when the solution set has grown sufficiently large. Our method can be easily incorporated into integer programming solvers and has the potential to significantly increase the diversity of solution sets. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Funding: This work was supported by the Army Research Office [Grant W911NF-21-1-0079]. The views expressed in this study do not represent those of the U.S. Government, the U.S. Department of Defense, or the U.S. Army. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0164 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0164 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0164},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {61-77},
  shortjournal = {INFORMS J. Comput.},
  title        = {DiversiTree: A new method to efficiently compute diverse sets of near-optimal solutions to mixed-integer optimization problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting critical nodes in sparse graphs via
“reduce-solve-combine” memetic search. <em>IJOC</em>, <em>36</em>(1),
39–60. (<a href="https://doi.org/10.1287/ijoc.2022.0130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers a well-known critical node detection problem that aims to minimize a pairwise connectivity measure of an undirected graph via the removal of a subset of nodes (referred to as critical nodes) subject to a cardinality constraint. Potential applications include epidemic control, emergency response, vulnerability assessment, carbon emission monitoring, network security, and drug design. To solve the problem, we present a “reduce-solve-combine” memetic search approach that integrates a problem reduction mechanism into the popular population-based memetic algorithm framework. At each generation, a common pattern mined from two parent solutions is first used to reduce the given problem instance, then the reduced instance is solved by a component-based hybrid neighborhood search that effectively combines an articulation point impact strategy and a node weighting strategy, and finally an offspring solution is produced by combining the mined common pattern and the solution of the reduced instance. Extensive evaluations on 42 real-world and synthetic benchmark instances show the efficacy of the proposed method, which discovers nine new upper bounds and significantly outperforms the current state-of-the-art algorithms. Investigation of key algorithmic modules additionally discloses the importance of the proposed ideas and strategies. Finally, we demonstrate the generality of the proposed method via its adaptation to solve the node-weighted critical node problem. History: Accepted by Erwin Pesch, Area Editor for Heuristic Search &amp; Approximation Algorithms. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72371157, 61903144, 72031007]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2022.0130 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2022.0130 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0130},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {39-60},
  shortjournal = {INFORMS J. Comput.},
  title        = {Detecting critical nodes in sparse graphs via “Reduce-solve-combine” memetic search},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A set-covering approach to customized coverage
instrumentation. <em>IJOC</em>, <em>36</em>(1), 21–38. (<a
href="https://doi.org/10.1287/ijoc.2021.0349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Program coverage customization selectively adds instrumentation to a compiled computer program so that a limited amount of directly observed data can be used to infer other program coverage information after a run. A good instrumentation plan can reduce run-time overheads while still giving software developers the information they need. Unfortunately, optimal coverage planning is NP-hard, limiting either the quality of heuristic plans or the sizes of programs that can be instrumented optimally. We exploit the monotonicity property of feasible instrumentations to formulate this problem as an intraprocedural set covering problem. Our formulation has an exponential number of constraints, and we design a polynomial-time separation algorithm to incrementally add the necessary subset of these inequalities. Our approach reduces expected run-time probing costs compared with existing methods, offers a guarantee of the optimality of the instrumentation, and has compilation-time overhead suitable for wide practical use. History: Accepted by Pascal Van Hentenryck, Area Editor for Computational Modeling: Methods &amp; Analysis. Funding: This work was supported by the National Science Foundation [Grants CCF-1318489, CCF-1420866, and CCF-1423237] and the Air Force Research Laboratory [Grant FA8750-14-2-0270]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2021.0349 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2021.0349 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2021.0349},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {21-38},
  shortjournal = {INFORMS J. Comput.},
  title        = {A set-covering approach to customized coverage instrumentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Routing replenishment workers: The prize collecting
traveling salesman problem in scattered storage warehouses.
<em>IJOC</em>, <em>36</em>(1), 3–20. (<a
href="https://doi.org/10.1287/ijoc.2022.0173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many online retailers apply scattered (or mixed-shelves) storage in the picking areas of their warehouses. Instead of keeping unit loads together, individual pieces of stock keeping units (SKUs) are stored on various shelves throughout the warehouse. This storage strategy increases the probability that—whatever it is that customers order jointly—somewhere in the warehouse these products will be located in close proximity. Hence, a picker can retrieve them without excessive unproductive walking. The price for this advantage on the picking side, however, is additional effort for the replenishment workers (also denoted as stowers) when restocking the shelves. Instead of moving only a single homogeneous unit load toward an SKU’s designated storage position, each stower has to travel along multiple open shelf spaces until all products on the cart are stored on shelves. The resulting stower routing problem is equivalent to the well-known prize collecting traveling salesman problem (PCTSP). While the PCTSP for general graphs is known to be strongly N P -hard, we show that in a warehousing environment, where all open storage positions are located along parallel aisles, it is only binary N P -hard. The special parallel-aisle structure allows us to derive an exact solution algorithm with pseudo-polynomial runtime, which solves even instances with hundreds of open storage positions to proven optimality in just a few seconds. Our computational tests show that the performance gains of an optimized stowing process over the status quo, where stowers operate without decision support, are significant. Especially, when the fill level of a warehouse is high, directing stowers on optimized routes promises huge improvements. History: Accepted by Andrea Lodi, Area Editor for Design &amp; Analysis of Algorithms – Discrete. Funding: This work was supported by the German Science Foundation/Deutsche Forschungsgemeinschaft (DFG) by the grant “Routing of human and automated order pickers in modern warehouses” (BO 3148/14-1 and BO 1972/2-1). Supplemental Material: The e-companion is available at https://doi.org/10.1287/ijoc.2022.0173 .},
  archive      = {J_IJOC},
  doi          = {10.1287/ijoc.2022.0173},
  journal      = {INFORMS Journal on Computing},
  month        = {1},
  number       = {1},
  pages        = {3-20},
  shortjournal = {INFORMS J. Comput.},
  title        = {Routing replenishment workers: The prize collecting traveling salesman problem in scattered storage warehouses},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
