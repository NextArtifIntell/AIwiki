<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JMLR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jmlr---417">JMLR - 417</h2>
<ul>
<li><details>
<summary>
(2024). Countering the communication bottleneck in federated
learning: A highly efficient zero-order optimization technique.
<em>JMLR</em>, <em>25</em>(418), 1–53. (<a
href="https://jmlr.org/papers/v25/24-1189.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a creative technique that enables multiple edge devices to train a model without revealing raw data. However, several issues hinder the practical implementation of FL, especially in wireless environments. These issues comprise the limited capacity of the upload transmission link between the edge devices and the aggregator, as well as the wireless disturbances. To address these challenges, we develop a zero-order (ZO) communication-efficient framework for FL. While in standard FL, each device must upload a long vector containing the gradient or the model per communication round, our novel ZO method incorporates a two-point gradient estimator, which requires uploading only two scalars. What also sets our approach apart is that it directly incorporates wireless perturbations into the learning, eliminating the need for additional computational resources to remove their impact. In this work, we overcome the technical and analytical challenges associated with FL problems and ZO methods, comprehensively study our algorithm, and prove it converges almost surely under different conditions, convexity and non-convexity, noise-free and noisy environments. We then find theoretical bounds on the convergence rate when the objective is strongly convex, non-convex, and $\kappa$-gradient-dominated that compete with first-order (FO) or centralized methods under the same settings. Finally, we provide experimental results demonstrating the effectiveness of our algorithm, considering relevant examples. We provide an example illustrating the amount of communication saved due to its efficiency compared to its FO counterpart.},
  archive      = {J_JMLR},
  author       = {Elissa Mhanna and Mohamad Assaad},
  journal      = {Journal of Machine Learning Research},
  number       = {418},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Countering the communication bottleneck in federated learning: A highly efficient zero-order optimization technique},
  url          = {https://jmlr.org/papers/v25/24-1189.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PyDMD: A python package for robust dynamic mode
decomposition. <em>JMLR</em>, <em>25</em>(417), 1–9. (<a
href="https://jmlr.org/papers/v25/24-0739.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic mode decomposition (DMD) is a powerful data-driven modeling technique that reveals coherent spatiotemporal patterns from dynamical system snapshot observations. PyDMD is a Python package that implements DMD and several of its major optimizations and methodological extensions. In this paper, we introduce the version 1.0 release of PyDMD, which includes new data preprocessors, plotting tools, and a number of cutting-edge DMD methods specifically designed to handle real-world data that may be noisy, multi-scale, parameterized, prohibitively high-dimensional, and even strongly nonlinear. The package is friendly to install, thoroughly-documented, supplemented with extensive code examples, and modularly-structured to support future additions. The entire codebase is released under the MIT license and is available at https://github.com/PyDMD/PyDMD.},
  archive      = {J_JMLR},
  author       = {Sara M. Ichinaga and Francesco Andreuzzi and Nicola Demo and Marco Tezzele and Karl Lapo and Gianluigi Rozza and Steven L. Brunton and J. Nathan Kutz},
  journal      = {Journal of Machine Learning Research},
  number       = {417},
  pages        = {1-9},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {PyDMD: A python package for robust dynamic mode decomposition},
  url          = {https://jmlr.org/papers/v25/24-0739.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic-constrained stochastic optimization with
markovian data. <em>JMLR</em>, <em>25</em>(416), 1–69. (<a
href="https://jmlr.org/papers/v25/23-1630.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers stochastic-constrained stochastic optimization where the stochastic constraint is to satisfy that the expectation of a random function is below a certain threshold. In particular, we study the setting where data samples are drawn from a Markov chain and thus are not independent and identically distributed. We generalize the drift-plus-penalty framework, a primal-dual stochastic gradient method developed for the i.i.d. case, to the Markov chain sampling setting. We propose three variants of drift-plus-penalty; two are for the case when the mixing time of the underlying Markov chain is known while the other is for the case of unknown mixing time. In fact, our algorithms apply to a more general setting of constrained online convex optimization where the sequence of constraint functions follows a Markov chain. The algorithms are adaptive in that the first two work without knowledge of the time horizon while the third uses AdaGrad-style algorithm parameters, which is of independent interest. We demonstrate the effectiveness of our proposed methods through numerical experiments on classification with fairness constraints.},
  archive      = {J_JMLR},
  author       = {Yeongjong Kim and Dabeen Lee},
  journal      = {Journal of Machine Learning Research},
  number       = {416},
  pages        = {1-69},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Stochastic-constrained stochastic optimization with markovian data},
  url          = {https://jmlr.org/papers/v25/23-1630.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimation of the order of non-parametric hidden markov
models using the singular values of an integral operator. <em>JMLR</em>,
<em>25</em>(415), 1–37. (<a
href="https://jmlr.org/papers/v25/23-1372.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interested in estimating the order of a finite-state Hidden Markov Model (HMM) with non-parametric emission distributions from a single observed sequence, we introduce a new method that only requires full rank transition matrix and linear independence between the emission distributions. This method relies on the equality between the order of the HMM and the rank of a specific integral operator. Since only the empirical counter-part of the singular values of the operator can be obtained, a thresholding procedure is proposed. At a non-asymptotic level, an upper-bound on the probability of overestimating the order of the HMM is provided. At an asymptotic level, the consistency of the estimator is established. In addition, we introduce a general heuristic that can be successfully applied to several problems in spectral analysis for designing a data-driven procedure for the threshold. The approach has the advantage of not requiring any knowledge of an upper-bound on the order of the HMM. Moreover, different types of data (including circular or mixed-type data) can be managed. The relevance of the approach is illustrated on numerical experiments and on real data considering multivariate data with directional variables.},
  archive      = {J_JMLR},
  author       = {Marie Du Roy de Chaumaray and Salima El Kolei and Marie-Pierre Etienne and Matthieu Marbac},
  journal      = {Journal of Machine Learning Research},
  number       = {415},
  pages        = {1-37},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Estimation of the order of non-parametric hidden markov models using the singular values of an integral operator},
  url          = {https://jmlr.org/papers/v25/23-1372.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Infinite-dimensional diffusion models. <em>JMLR</em>,
<em>25</em>(414), 1–52. (<a
href="https://jmlr.org/papers/v25/23-1271.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have had a profound impact on many application areas, including those where data are intrinsically infinite-dimensional, such as images or time series. The standard approach is first to discretize and then to apply diffusion models to the discretized data. While such approaches are practically appealing, the performance of the resulting algorithms typically deteriorates as discretization parameters are refined. In this paper, we instead directly formulate diffusion-based generative models in infinite dimensions and apply them to the generative modelling of functions. We prove that our formulations are well posed in the infinite-dimensional setting and provide dimension-independent distance bounds from the sample to the target measure. Using our theory, we also develop guidelines for the design of infinite-dimensional diffusion models. For image distributions, these guidelines are in line with current canonical choices. For other distributions, however, we can improve upon these canonical choices. We demonstrate these results both theoretically and empirically, by applying the algorithms to data distributions on manifolds and to distributions arising in Bayesian inverse problems or simulation-based inference.},
  archive      = {J_JMLR},
  author       = {Jakiw Pidstrigach and Youssef Marzouk and Sebastian Reich and Sven Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {414},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Infinite-dimensional diffusion models},
  url          = {https://jmlr.org/papers/v25/23-1271.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-response linear discriminant analysis in high
dimensions. <em>JMLR</em>, <em>25</em>(413), 1–66. (<a
href="https://jmlr.org/papers/v25/23-0961.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of classifying multiple categorical responses is fundamental in modern machine learning and statistics, with diverse applications in fields such as bioinformatics and imaging. This manuscript investigates linear discriminant analysis (LDA) with high-dimensional predictors and multiple multi-class responses. Specifically, we first examine two different classification scenarios under the bivariate LDA model: joint classification of the two responses and conditional classification of one response while observing the other. To achieve optimal classification rules for both scenarios, we introduce two novel tensor formulations of the discriminant coefficients and corresponding regularization strategies. For joint classification, we propose an overlapping group lasso penalty and a blockwise coordinate descent algorithm to efficiently compute the joint discriminant coefficient tensors. For conditional classification, we utilize an alternating direction method of multipliers (ADMM) algorithm to compute the discriminant coefficient tensors under new constraints. We then extend our method and algorithms to general multivariate responses. Finally, we validate the effectiveness of our approach through simulation studies and applications to benchmark datasets.},
  archive      = {J_JMLR},
  author       = {Kai Deng and Xin Zhang and Aaron J. Molstad},
  journal      = {Journal of Machine Learning Research},
  number       = {413},
  pages        = {1-66},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Multi-response linear discriminant analysis in high dimensions},
  url          = {https://jmlr.org/papers/v25/23-0961.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards unbiased exploration in partial label learning.
<em>JMLR</em>, <em>25</em>(412), 1–56. (<a
href="https://jmlr.org/papers/v25/23-0868.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider learning a probabilistic classifier from partially-labelled supervision (inputs denoted with multiple possibilities) using standard neural architectures with a softmax as the final layer. We identify a bias phenomenon that can arise from the softmax layer in even simple architectures that prevents proper exploration of alternative options, making the dynamics of gradient descent overly sensitive to initialization. We introduce a novel loss function that allows for unbiased exploration within the space of alternative outputs. We give a theoretical justification for our loss function, and provide an extensive evaluation of its impact on synthetic data, on standard partially labelled benchmarks and on a contributed novel benchmark related to an existing rule learning challenge.},
  archive      = {J_JMLR},
  author       = {Zsolt Zombori and Agapi Rissaki and Kristóf Szabó and Wolfgang Gatterbauer and Michael Benedikt},
  journal      = {Journal of Machine Learning Research},
  number       = {412},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Towards unbiased exploration in partial label learning},
  url          = {https://jmlr.org/papers/v25/23-0868.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Logistic regression under network dependence. <em>JMLR</em>,
<em>25</em>(411), 1–62. (<a
href="https://jmlr.org/papers/v25/22-1040.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logistic regression is a key method for modeling the probability of a binary outcome based on a collection of covariates. However, the classical formulation of logistic regression relies on the independent sampling assumption, which is often violated when the outcomes interact through an underlying network structure, such as over a temporal/spatial domain or on a social network. This necessitates the development of models that can simultaneously handle both the network &#39;peer-effect&#39; (arising from neighborhood interactions) and the effect of (possibly) high-dimensional covariates. In this paper, we develop a framework for incorporating such dependencies in a high-dimensional logistic regression model by introducing a quadratic interaction term, as in the Ising model, designed to capture the pairwise interactions from the underlying network. The resulting model can also be viewed as an Ising model, where the node-dependent external fields linearly encode the high-dimensional covariates. We propose a penalized maximum pseudo-likelihood method for estimating the network peer-effect and the effect of the covariates (the regression coefficients), which, in addition to handling the high-dimensionality of the parameters, conveniently avoids the computational intractability of the maximum likelihood approach. Under various standard regularity conditions, we show that the corresponding estimate attains the classical high-dimensional rate of consistency. In particular, our results imply that even under network dependence it is possible to consistently estimate the model parameters at the same rate as in classical (independent) logistic regression, when the true parameter is sparse and the underlying network is not too dense. Consequently, we derive the rates of consistency of our proposed estimator for various natural graph ensembles, such as bounded degree graphs, sparse Erd\H{o}s-R\&#39;{e}nyi random graphs, and stochastic block models. We also develop an efficient algorithm for computing the estimates and validate our theoretical results in numerical experiments. An application to selecting genes in clustering spatial transcriptomics data is also discussed.},
  archive      = {J_JMLR},
  author       = {Somabha Mukherjee and Ziang Niu and Sagnik Halder and Bhaswar B. Bhattacharya and George Michailidis},
  journal      = {Journal of Machine Learning Research},
  number       = {411},
  pages        = {1-62},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Logistic regression under network dependence},
  url          = {https://jmlr.org/papers/v25/22-1040.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nearest neighbor sampling for covariate shift adaptation.
<em>JMLR</em>, <em>25</em>(410), 1–42. (<a
href="https://jmlr.org/papers/v25/24-0890.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many existing covariate shift adaptation methods estimate sample weights to mitigate the gap between the source and the target distribution. However, estimating the optimal weights typically involves computationally expensive matrix inversion and hyper-parameter tuning. In this paper, we propose a new covariate shift adaptation method which avoids estimating the weights. The basic idea is to directly work on unlabeled target data, labeled according to the $k$-nearest neighbors in the source dataset. Our analysis reveals that setting $k = 1$ is an optimal choice. This property eliminates the necessity of tuning the hyper-parameter $k$ and leads to a running time quasi-linear in the sample size. Our results include sharp rates of convergence for our estimator, with a tight control of the mean square error and explicit constants. In particular, the variance of our estimator has the same rate of convergence as for standard parametric estimation despite their non-parametric nature. The proposed estimator shares similarities with some matching-based treatment effect estimators used, e.g., in biostatistics, econometrics, and epidemiology. Our experiments show that it achieves drastic reduction in the running time with remarkable accuracy.},
  archive      = {J_JMLR},
  author       = {François Portier and Lionel Truquet and Ikko Yamane},
  journal      = {Journal of Machine Learning Research},
  number       = {410},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Nearest neighbor sampling for covariate shift adaptation},
  url          = {https://jmlr.org/papers/v25/24-0890.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uniform generalization bounds on data-dependent hypothesis
sets via PAC-bayesian theory on random sets. <em>JMLR</em>,
<em>25</em>(409), 1–55. (<a
href="https://jmlr.org/papers/v25/24-0605.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose data-dependent uniform generalization bounds by approaching the problem from a PAC-Bayesian perspective. We first apply the PAC-Bayesian framework on “random sets” in a rigorous way, where the training algorithm is assumed to output a data-dependent hypothesis set after observing the training data. This approach allows us to prove data-dependent bounds, which can be applicable in numerous contexts. To highlight the power of our approach, we consider two main applications. First, we propose a PAC-Bayesian formulation of the recently developed fractal-dimension-based generalization bounds. The derived results are shown to be tighter and they unify the existing results around one simple proof technique. Second, we prove uniform bounds over the trajectories of continuous Langevin dynamics and stochastic gradient Langevin dynamics. These results provide novel information about the generalization properties of noisy algorithms.},
  archive      = {J_JMLR},
  author       = {Benjamin Dupuis and Paul Viallard and George Deligiannidis and Umut Simsekli},
  journal      = {Journal of Machine Learning Research},
  number       = {409},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Uniform generalization bounds on data-dependent hypothesis sets via PAC-bayesian theory on random sets},
  url          = {https://jmlr.org/papers/v25/24-0605.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stage-aware learning for dynamic treatments. <em>JMLR</em>,
<em>25</em>(408), 1–51. (<a
href="https://jmlr.org/papers/v25/23-1422.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in dynamic treatment regimes (DTRs) facilitate the search for optimal treatments, which are tailored to individuals&#39; specific needs and able to maximize their expected clinical benefits. However, existing algorithms relying on consistent trajectories, such as inverse probability weighting estimators (IPWEs), could suffer from insufficient sample size under optimal treatments and a growing number of decision-making stages, particularly in the context of chronic diseases. To address these challenges, we propose a novel individualized learning method which estimates the DTR with a focus on prioritizing alignment between the observed treatment trajectory and the one obtained by the optimal regime across decision stages. By relaxing the restriction that the observed trajectory must be fully aligned with the optimal treatments, our approach substantially improves the sample efficiency and stability of IPWE-based methods. In particular, the proposed learning scheme builds a more general framework which includes the popular outcome weighted learning framework as a special case of ours. Moreover, we introduce the notion of stage importance scores along with an attention mechanism to explicitly account for heterogeneity among decision stages. We establish the theoretical properties of the proposed approach, including Fisher consistency and the finite-sample performance bound. Empirically, we evaluate the proposed method in extensive simulated environments and a real case study for the COVID-19 pandemic.},
  archive      = {J_JMLR},
  author       = {Hanwen Ye and Wenzhuo Zhou and Ruoqing Zhu and Annie Qu},
  journal      = {Journal of Machine Learning Research},
  number       = {408},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Stage-aware learning for dynamic treatments},
  url          = {https://jmlr.org/papers/v25/23-1422.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Information-theoretic generalization bounds for transductive
learning and its applications. <em>JMLR</em>, <em>25</em>(407), 1–69.
(<a href="https://jmlr.org/papers/v25/23-1368.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we establish generalization bounds for transductive learning algorithms in the context of information theory and PAC-Bayes, covering both the random sampling and the random splitting setting. First, we show that the transductive generalization gap can be controlled by the mutual information between training label selection and the hypothesis. Next, we propose the concept of transductive supersample and use it to derive transductive information-theoretic bounds involving conditional mutual information and different information measures. We further establish transductive PAC-Bayesian bounds with weaker assumptions on the type of loss function and the number of training and test data points. Lastly, we use the theoretical results to derive upper bounds for adaptive optimization algorithms under the transductive learning setting. We also apply them to semi-supervised learning and transductive graph learning scenarios, meanwhile validating the derived bounds by experiments on synthetic and real-world datasets.},
  archive      = {J_JMLR},
  author       = {Huayi Tang and Yong Liu},
  journal      = {Journal of Machine Learning Research},
  number       = {407},
  pages        = {1-69},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Information-theoretic generalization bounds for transductive learning and its applications},
  url          = {https://jmlr.org/papers/v25/23-1368.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence of message-passing graph neural networks with
generic aggregation on large random graphs. <em>JMLR</em>,
<em>25</em>(406), 1–49. (<a
href="https://jmlr.org/papers/v25/23-0965.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the convergence of message-passing graph neural networks on random graph models toward their continuous counterparts as the number of nodes tends to infinity. Until now, this convergence was only known for architectures with aggregation functions in the form of normalized means, or, equivalently, of an application of classical operators like the adjacency matrix or the graph Laplacian. We extend such results to a large class of aggregation functions, that encompasses all classically used message-passing graph neural networks, such as attention-based message-passing, max convolutional message-passing, (degree-normalized) convolutional message-passing, or moment-based aggregation message-passing. Under mild assumptions, we give non-asymptotic bounds with high probability to quantify this convergence. Our main result is based on the McDiarmid inequality. Interestingly, this result does not apply to the case where the aggregation is a coordinate-wise maximum. We treat this case separately and obtain a different convergence rate.},
  archive      = {J_JMLR},
  author       = {Matthieu Cordonnier and Nicolas Keriven and Nicolas Tremblay and Samuel Vaiter},
  journal      = {Journal of Machine Learning Research},
  number       = {406},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Convergence of message-passing graph neural networks with generic aggregation on large random graphs},
  url          = {https://jmlr.org/papers/v25/23-0965.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable resampling in massive generalized linear models via
subsampled residual bootstrap. <em>JMLR</em>, <em>25</em>(405), 1–36.
(<a href="https://jmlr.org/papers/v25/23-0916.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Residual bootstrap is a classical method of statistical inference in regression settings. With massive data sets becoming increasingly common, there is a demand for computationally efficient alternatives to residual bootstrap. We propose a simple and versatile scalable algorithm called subsampled residual bootstrap (SRB) for generalized linear models (GLMs), a large class of regression models that includes the classical linear regression model as well as other widely used models such as logistic, Poisson and probit regression. We prove consistency and distributional results that establish that the SRB has the same theoretical guarantees under the GLM framework as the classical residual bootstrap, while being computationally much faster. We demonstrate the empirical performance of SRB via simulation studies and a real data analysis of the Forest Covertype data from the UCI Machine Learning Repository.},
  archive      = {J_JMLR},
  author       = {Indrila Ganguly and Srijan Sengupta and Sujit Ghosh},
  journal      = {Journal of Machine Learning Research},
  number       = {405},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Scalable resampling in massive generalized linear models via subsampled residual bootstrap},
  url          = {https://jmlr.org/papers/v25/23-0916.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal scaling for the proximal langevin algorithm in high
dimensions. <em>JMLR</em>, <em>25</em>(404), 1–32. (<a
href="https://jmlr.org/papers/v25/23-0139.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Metropolis-adjusted Langevin (MALA) algorithm is a sampling algorithm that incorporates the gradient of the logarithm of the target density in its proposal distribution. In an earlier joint work, the author had extended the seminal work of Roberts and Rosenthal and showed that in stationarity, MALA applied to an $N-$dimensional approximation of the target will take ${\cal O}(N^{\frac13})$ steps to explore its target measure. It was also shown that, as a consequence of the diffusion limit, the MALA algorithm is optimized at an average acceptance probability of $0.574$. Pereyra introduced the proximal MALA algorithm where the gradient of the log target density is replaced by the proximal function (mainly aimed at implementing MALA for non-differentiable target densities). In this paper, we show that for a wide class of twice differentiable target densities, the proximal MALA enjoys the same optimal scaling as that of MALA in high dimensions and also has an average optimal acceptance probability of $0.574$. The results of this paper thus give the following practically useful guideline: for smooth target densities where it is expensive to compute the gradient while implementing MALA, users may replace the gradient with the corresponding proximal function (that can be often computed relatively cheaply via convex optimization) without losing any efficiency gains from optimal scaling. We show this for two class of examples. First, for the product of Gaussians, we identify the optimal scale for proximal MALA and show that it is identical to MALA. Next, following the exact framework used in the author&#39;s previous paper, we define a version of the proximal MALA algorithm in a Hilbert space. We show that for a certain class of twice differentiable, infinite dimensional non-product measures commonly used in applications, the proximal MALA applied to an $N-$dimensional approximation of the target also will take ${\cal O}(N^{\frac13})$ steps to explore the invariant measure, with an optimal acceptance probability of $0.574$. This confirms some of the empirical observations made in Pereyra.},
  archive      = {J_JMLR},
  author       = {Natesh S. Pillai},
  journal      = {Journal of Machine Learning Research},
  number       = {404},
  pages        = {1-32},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal scaling for the proximal langevin algorithm in high dimensions},
  url          = {https://jmlr.org/papers/v25/23-0139.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximate information tests on statistical submanifolds.
<em>JMLR</em>, <em>25</em>(403), 1–27. (<a
href="https://jmlr.org/papers/v25/19-272.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parametric inference posits a statistical model that is a specified family of probability distributions. Restricted inference, for example, restricted likelihood ratio testing, attempts to exploit the structure of a statistical submodel that is a subset of the specified family. We consider the problem of testing a simple hypothesis against alternatives from such a submodel. In the case of an unknown submodel, it is not clear how to realize the benefits of restricted inference. To do so, we first construct information tests that are locally asymptotically equivalent to likelihood ratio tests. Information tests are conceptually appealing but (in general) computationally intractable. However, unlike restricted likelihood ratio tests, restricted information tests can be approximated even when the statistical submodel is unknown. We construct approximate information tests using manifold learning procedures to extract information from samples of an unknown (or intractable) submodel, thereby providing a roadmap for computational solutions to a class of previously impenetrable problems in statistical inference. Examples illustrate the efficacy of the proposed methodology.},
  archive      = {J_JMLR},
  author       = {Michael W. Trosset and Carey E. Priebe},
  journal      = {Journal of Machine Learning Research},
  number       = {403},
  pages        = {1-27},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Approximate information tests on statistical submanifolds},
  url          = {https://jmlr.org/papers/v25/19-272.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PirateNets: Physics-informed deep learning with residual
adaptive networks. <em>JMLR</em>, <em>25</em>(402), 1–51. (<a
href="https://jmlr.org/papers/v25/24-0313.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While physics-informed neural networks (PINNs) have become a popular deep learning framework for tackling forward and inverse problems governed by partial differential equations (PDEs), their performance is known to degrade when larger and deeper neural network architectures are employed. Our study identifies that the root of this counter-intuitive behavior lies in the use of multi-layer perceptron (MLP) architectures with non-suitable initialization schemes, which result in poor trainablity for the network derivatives, and ultimately lead to an unstable minimization of the PDE residual loss. To address this, we introduce Physics-Informed Residual Adaptive Networks (PirateNets), a novel architecture that is designed to facilitate stable and efficient training of deep PINN models. PirateNets leverage a novel adaptive residual connection, which allows the networks to be initialized as shallow networks that progressively deepen during training. We also show that the proposed initialization scheme allows us to encode appropriate inductive biases corresponding to a given PDE system into the network architecture. We provide comprehensive empirical evidence showing that PirateNets are easier to optimize and can gain accuracy from considerably increased depth, ultimately achieving state-of-the-art results across various benchmarks. All code and data accompanying this manuscript will be made publicly available at https://github.com/PredictiveIntelligenceLab/jaxpi/tree/pirate.},
  archive      = {J_JMLR},
  author       = {Sifan Wang and Bowen Li and Yuhan Chen and Paris Perdikaris},
  journal      = {Journal of Machine Learning Research},
  number       = {402},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {PirateNets: Physics-informed deep learning with residual adaptive networks},
  url          = {https://jmlr.org/papers/v25/24-0313.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep backward and galerkin methods for the finite state
master equation. <em>JMLR</em>, <em>25</em>(401), 1–50. (<a
href="https://jmlr.org/papers/v25/24-0215.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes and analyzes two neural network methods to solve the master equation for finite-state mean field games (MFGs). Solving MFGs provides approximate Nash equilibria for stochastic, differential games with finite but large populations of agents. The master equation is a partial differential equation (PDE) whose solution characterizes MFG equilibria for any possible initial distribution. The first method we propose relies on backward induction in a time component while the second method directly tackles the PDE without discretizing time. For both approaches, we prove two types of results: there exist neural networks that make the algorithms&#39; loss functions arbitrarily small and conversely, if the losses are small, then the neural networks are good approximations of the master equation&#39;s solution. We conclude the paper with numerical experiments on benchmark problems from the literature up to dimension 15, and a comparison with solutions computed by a classical method for fixed initial distributions.},
  archive      = {J_JMLR},
  author       = {Asaf Cohen and Mathieu Laurière and Ethan Zell},
  journal      = {Journal of Machine Learning Research},
  number       = {401},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Deep backward and galerkin methods for the finite state master equation},
  url          = {https://jmlr.org/papers/v25/24-0215.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new, physics-informed continuous-time reinforcement
learning algorithm with performance guarantees. <em>JMLR</em>,
<em>25</em>(400), 1–35. (<a
href="https://jmlr.org/papers/v25/24-0017.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new, physics-informed continuous-time reinforcement learning (CT-RL) algorithm for control of affine nonlinear systems, an area that enables a plethora of well-motivated applications. Based on fundamental control principles, our approach uses reference command input (RCI) as probing noise to enable exploration in learning. With known physical dynamics of the environment, by leveraging on the Kleinman algorithm structure, and using state-action trajectory data, RCI provides a data-efficient optimal control solution under an infinite-horizon undiscounted cost. We show that our RCI-based CT-RL algorithm not only provides theoretical guarantees such as learning convergence, solution optimality, and closed-loop stability, but also well-behaved dynamic system responses. It is noted that our evaluations not only include extensive baseline and ablation studies using typical performance measures in RL, but also essential control-centric performance measures that are critical for real-life control applications. As a result, we demonstrate that our RCI-based CT-RL leads to new, SOTA control design and performance.},
  archive      = {J_JMLR},
  author       = {Brent A. Wallace and Jennie Si},
  journal      = {Journal of Machine Learning Research},
  number       = {400},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A new, physics-informed continuous-time reinforcement learning algorithm with performance guarantees},
  url          = {https://jmlr.org/papers/v25/24-0017.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning with a linear loss function: Excess risk and
estimation bounds for ERM, minmax MOM and their regularized versions
with applications to robustness in sparse PCA. <em>JMLR</em>,
<em>25</em>(399), 1–90. (<a
href="https://jmlr.org/papers/v25/23-1405.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by several examples, we consider a general framework of learning with linear loss functions. In this context, we provide excess risk and estimation bounds that hold with large probability for four estimators: ERM, minmax MOM and their regularized versions. These general bounds are applied for the problem of robustness in sparse PCA. In particular, we improve the state of the art result for this this problems, obtain results under weak moment assumptions as well as for adversarial contaminated data.},
  archive      = {J_JMLR},
  author       = {Guillaume Lecué and Lucie Neirac},
  journal      = {Journal of Machine Learning Research},
  number       = {399},
  pages        = {1-90},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning with a linear loss function: Excess risk and estimation bounds for ERM, minmax MOM and their regularized versions with applications to robustness in sparse PCA.},
  url          = {https://jmlr.org/papers/v25/23-1405.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust spectral clustering with rank statistics.
<em>JMLR</em>, <em>25</em>(398), 1–81. (<a
href="https://jmlr.org/papers/v25/23-0552.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the statistical performance of a robust spectral clustering method for latent structure recovery in noisy data matrices. We consider eigenvector-based clustering applied to a matrix of nonparametric rank statistics that is derived entrywise from the raw, original data matrix. This approach is robust in the sense that, unlike traditional spectral clustering procedures, it can provably recover population-level latent block structure even when the observed data matrix includes heavy-tailed entries and has a heterogeneous variance profile. Here, the raw input data may be viewed as a weighted adjacency matrix whose entries constitute links that connect nodes in an underlying graph or network. Our main theoretical contributions are threefold and hold under flexible data generating conditions. First, we establish that robust spectral clustering with rank statistics can consistently recover latent block structure, viewed as communities of nodes in a graph, in the sense that unobserved community memberships for all but a vanishing fraction of nodes are correctly recovered with high probability when the data matrix is large. Second, we refine the former result and further establish that, under certain conditions, the community membership of any individual, specified node of interest can be asymptotically exactly recovered with probability tending to one in the large-data limit. Third, we establish asymptotic normality results associated with the truncated eigenstructure of matrices whose entries are rank statistics, made possible by synthesizing contemporary entrywise matrix perturbation analysis with the classical nonparametric theory of so-called simple linear rank statistics. Collectively, these results demonstrate the statistical utility of rank-based data transformations when paired with spectral techniques for dimensionality reduction. Numerical examples illustrate and support our theoretical findings. Additionally, for a data set consisting of human connectomes, our approach yields parsimonious dimensionality reduction and improved recovery of ground-truth neuroanatomical cluster structure. We conclude with a discussion of extensions, practical considerations, and future work.},
  archive      = {J_JMLR},
  author       = {Joshua Cape and Xianshi Yu and Jonquil Z. Liao},
  journal      = {Journal of Machine Learning Research},
  number       = {398},
  pages        = {1-81},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Robust spectral clustering with rank statistics},
  url          = {https://jmlr.org/papers/v25/23-0552.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning dynamic mechanisms in unknown environments: A
reinforcement learning approach. <em>JMLR</em>, <em>25</em>(397), 1–73.
(<a href="https://jmlr.org/papers/v25/23-0159.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic mechanism design studies how mechanism designers should allocate resources among agents in a time-varying environment. We consider the problem where the agents interact with the mechanism designer according to an unknown Markov Decision Process (MDP), where agent rewards and the mechanism designer&#39;s state evolve according to an episodic MDP with unknown reward functions and transition kernels. We focus on the online setting with linear function approximation and propose novel learning algorithms to recover the dynamic Vickrey-Clarke-Grove (VCG) mechanism over multiple rounds of interaction. A key contribution of our approach is incorporating reward-free online Reinforcement Learning (RL) to aid exploration over a rich policy space to estimate prices in the dynamic VCG mechanism. We show that the regret of our proposed method is upper bounded by $\tilde{\mathcal{O}}(T^{2/3})$ and further devise a lower bound to show that our algorithm is efficient, incurring the same $\Omega(T^{2 / 3})$ regret as the lower bound, where $T$ is the total number of rounds. Our work establishes the regret guarantee for online RL in solving dynamic mechanism design problems without prior knowledge of the underlying model.},
  archive      = {J_JMLR},
  author       = {Shuang Qiu and Boxiang Lyu and Qinglin Meng and Zhaoran Wang and Zhuoran Yang and Michael I. Jordan},
  journal      = {Journal of Machine Learning Research},
  number       = {397},
  pages        = {1-73},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning dynamic mechanisms in unknown environments: A reinforcement learning approach},
  url          = {https://jmlr.org/papers/v25/23-0159.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transfer learning for tensor gaussian graphical models.
<em>JMLR</em>, <em>25</em>(396), 1–40. (<a
href="https://jmlr.org/papers/v25/22-1313.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor Gaussian graphical models (GGMs), interpreting conditional independence structures within tensor data, have important applications in numerous areas. Yet, the available tensor data in one single study is often limited due to high acquisition costs. Although relevant studies can provide additional data, it remains an open question how to pool such heterogeneous data. In this paper, we propose a transfer learning framework for tensor GGMs, which takes full advantage of informative auxiliary domains even when non-informative auxiliary domains are present, benefiting from the carefully designed data-adaptive weights. Our theoretical analysis shows substantial improvement of estimation errors and variable selection consistency on the target domain under much relaxed conditions, by leveraging information from auxiliary domains. Extensive numerical experiments are conducted on both synthetic tensor graphs and brain functional connectivity network data, which demonstrates the satisfactory performance of the proposed method.},
  archive      = {J_JMLR},
  author       = {Mingyang Ren and Yaoming Zhen and Junhui Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {396},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Transfer learning for tensor gaussian graphical models},
  url          = {https://jmlr.org/papers/v25/22-1313.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scaled conjugate gradient method for nonconvex optimization
in deep neural networks. <em>JMLR</em>, <em>25</em>(395), 1–37. (<a
href="https://jmlr.org/papers/v25/22-0815.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A scaled conjugate gradient method that accelerates existing adaptive methods utilizing stochastic gradients is proposed for solving nonconvex optimization problems with deep neural networks. It is shown theoretically that, whether with a constant or diminishing learning rate, the proposed method can obtain a stationary point of the problem. Additionally, its rate of convergence with a diminishing learning rate is verified to be superior to that of the conjugate gradient method. The proposed method is shown to minimize training loss functions faster than the existing adaptive methods in practical applications of image and text classification. Furthermore, in the training of generative adversarial networks, one version of the proposed method achieved the lowest Fr\&#39;echet inception distance score among those of the adaptive methods.},
  archive      = {J_JMLR},
  author       = {Naoki Sato and Koshiro Izumi and Hideaki Iiduka},
  journal      = {Journal of Machine Learning Research},
  number       = {395},
  pages        = {1-37},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Scaled conjugate gradient method for nonconvex optimization in deep neural networks},
  url          = {https://jmlr.org/papers/v25/22-0815.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contextual bandits with packing and covering constraints: A
modular lagrangian approach via regression. <em>JMLR</em>,
<em>25</em>(394), 1–37. (<a
href="https://jmlr.org/papers/v25/24-1220.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider contextual bandits with linear constraints (CBwLC), a variant of contextual bandits in which the algorithm consumes multiple resources subject to linear constraints on total consumption. This problem generalizes contextual bandits with knapsacks (CBwK), allowing for packing and covering constraints, as well as positive and negative resource consumption. We provide the first algorithm for CBwLC (or CBwK) that is based on regression oracles. The algorithm is simple, computationally efficient, and statistically optimal under mild assumptions. Further, we provide the first vanishing-regret guarantees for CBwLC (or CBwK) that extend beyond the stochastic environment. We side-step strong impossibility results from prior work by identifying a weaker (and, arguably, fairer) benchmark to compare against. Our algorithm builds on LagrangeBwK (Immorlica et al., 2019, 2022), a Lagrangianbased technique for CBwK, and SquareCB (Foster and Rakhlin, 2020), a regression-based technique for contextual bandits. Our analysis leverages the inherent modularity of both techniques.},
  archive      = {J_JMLR},
  author       = {Aleksandrs Slivkins and Xingyu Zhou and Karthik Abinav Sankararaman and Dylan J. Foster},
  journal      = {Journal of Machine Learning Research},
  number       = {394},
  pages        = {1-37},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Contextual bandits with packing and covering constraints: A modular lagrangian approach via regression},
  url          = {https://jmlr.org/papers/v25/24-1220.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An optimal transport approach for computing adversarial
training lower bounds in multiclass classification. <em>JMLR</em>,
<em>25</em>(393), 1–45. (<a
href="https://jmlr.org/papers/v25/24-0268.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the success of deep learning-based algorithms, it is widely known that neural networks may fail to be robust. A popular paradigm to enforce robustness is adversarial training (AT), however, this introduces many computational and theoretical difficulties. Recent works have developed a connection between AT in the multiclass classification setting and multimarginal optimal transport (MOT), unlocking a new set of tools to study this problem. In this paper, we leverage the MOT connection to propose computationally tractable numerical algorithms for computing universal lower bounds on the optimal adversarial risk and identifying optimal classifiers. We propose two main algorithms based on linear programming (LP) and entropic regularization (Sinkhorn). Our key insight is that one can harmlessly truncate the higher order interactions between classes, preventing the combinatorial run times typically encountered in MOT problems. We validate these results with experiments on MNIST and CIFAR-$10$, which demonstrate the tractability of our approach.},
  archive      = {J_JMLR},
  author       = {Nicolas Garcia Trillos and Matt Jacobs and Jakwang Kim and Matthew Werenski},
  journal      = {Journal of Machine Learning Research},
  number       = {393},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {An optimal transport approach for computing adversarial training lower bounds in multiclass classification},
  url          = {https://jmlr.org/papers/v25/24-0268.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fisher information dissipation for time-inhomogeneous
stochastic differential equations. <em>JMLR</em>, <em>25</em>(392),
1–45. (<a href="https://jmlr.org/papers/v25/24-0206.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a Lyapunov convergence analysis for time-inhomogeneous variable coefficient stochastic differential equations (SDEs). Three typical examples include overdamped, irreversible drift, and underdamped Langevin dynamics. We first formulate the probability transition equation of Langevin dynamics as a modified gradient flow of the Kullback-Leibler divergence in the probability space with respect to time-dependent optimal transport metrics. This formulation contains both gradient and non-gradient directions depending on a class of time-dependent target distribution. We then select a time-dependent relative Fisher information functional as a Lyapunov functional. We develop a time-dependent Hessian matrix condition, which guarantees the convergence of the probability density function of the SDE. We verify the proposed conditions for several time-inhomogeneous Langevin dynamics. For the overdamped Langevin dynamics, we prove the $O(t^{-1/2})$ convergence in $L^1$ distance for the simulated annealing dynamics with a strongly convex potential function. For the irreversible drift Langevin dynamics, we prove an improved convergence towards the target distribution in an asymptotic regime. We also verify the convergence condition for the underdamped Langevin dynamics. Numerical examples demonstrate the convergence results for the time-dependent Langevin dynamics.},
  archive      = {J_JMLR},
  author       = {Qi Feng and Xinzhe Zuo and Wuchen Li},
  journal      = {Journal of Machine Learning Research},
  number       = {392},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fisher information dissipation for time-inhomogeneous stochastic differential equations},
  url          = {https://jmlr.org/papers/v25/24-0206.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zeroth-order stochastic approximation algorithms for
DR-submodular optimization. <em>JMLR</em>, <em>25</em>(391), 1–55. (<a
href="https://jmlr.org/papers/v25/23-1523.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study approximation algorithms for several classes of DR-submodular optimization problems, where DR is short for diminishing return. Following a newly introduced algorithm framework for zeroth-order stochastic approximation methods, we first propose algorithms {\bf CG-ZOSA} and {\bf RG-ZOSA} for smooth DR-submodular optimization based on the coordinate-wise gradient estimator and the randomized gradient estimator, respectively. Our theoretical analysis proves that \rm{\bf{CG-ZOSA}} can reach a solution whose expected objective value exceeds $(1-e^{-1}-\epsilon^{2})$OPT$-\epsilon$ after $\mathcal{O}(\epsilon^{-2})$ iterations and $\mathcal{O}(N^{2/3}d\epsilon^{-2})$ oracle calls, where $d$ represents the problem dimension. On the other hand, \rm{\bf{RG-ZOSA}} improves the approximation ratio to $(1-e^{-1}-\epsilon^{2}/d)$ while maintaining the same overall oracle complexity. For non-smooth up-concave maximization problems, we propose a novel auxiliary function based on a smoothed objective function and introduce the \rm{\bf{NZOSA}} algorithm. This algorithm achieves an approximation ratio of $(1-e^{-1}-\epsilon \ln \epsilon^{-1}- \epsilon^{2}\ln \epsilon^{-1})$ with $\mathcal{O}(d\epsilon^{-2})$ iterations and $\mathcal{O}(N^{2/3}d^{3/2} \epsilon^{-3})$ oracle calls. We also extend \rm{\bf{NZOSA}} to handle a class of robust DR-submodular maximization problems. To validate the effectiveness of our proposed algorithms, we conduct experiments on both synthetic and real-world problems. The results demonstrate the superior performance and efficiency of our methods in solving DR-submodular optimization problems.},
  archive      = {J_JMLR},
  author       = {Yuefang Lian and Xiao Wang and Dachuan Xu and Zhongrui Zhao},
  journal      = {Journal of Machine Learning Research},
  number       = {391},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Zeroth-order stochastic approximation algorithms for DR-submodular optimization},
  url          = {https://jmlr.org/papers/v25/23-1523.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural bayes estimators for censored inference with
peaks-over-threshold models. <em>JMLR</em>, <em>25</em>(390), 1–49. (<a
href="https://jmlr.org/papers/v25/23-1134.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Making inference with spatial extremal dependence models can be computationally burdensome since they involve intractable and/or censored likelihoods. Building on recent advances in likelihood-free inference with neural Bayes estimators, that is, neural networks that approximate Bayes estimators, we develop highly efficient estimators for censored peaks-over-threshold models that use augmented data to encode censoring information in the neural network input. Our new method provides a paradigm shift that challenges traditional censored likelihood-based inference methods for spatial extremal dependence models. Our simulation studies highlight significant gains in both computational and statistical efficiency, relative to competing likelihood-based approaches, when applying our novel estimators to make inference with popular extremal dependence models, such as max-stable, $r$-Pareto, and random scale mixture process models. We also illustrate that it is possible to train a single neural Bayes estimator for a general censoring level, precluding the need to retrain the network when the censoring level is changed. We illustrate the efficacy of our estimators by making fast inference on hundreds-of-thousands of high-dimensional spatial extremal dependence models to assess extreme particulate matter 2.5 microns or less in diameter (${\rm PM}_{2.5}$) concentration over the whole of Saudi Arabia.},
  archive      = {J_JMLR},
  author       = {Jordan Richards and Matthew Sainsbury-Dale and Andrew Zammit-Mangion and Raphaël Huser},
  journal      = {Journal of Machine Learning Research},
  number       = {390},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Neural bayes estimators for censored inference with peaks-over-threshold models},
  url          = {https://jmlr.org/papers/v25/23-1134.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Infeasible deterministic, stochastic, and variance-reduction
algorithms for optimization under orthogonality constraints.
<em>JMLR</em>, <em>25</em>(389), 1–38. (<a
href="https://jmlr.org/papers/v25/23-0451.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orthogonality constraints naturally appear in many machine learning problems, from principal component analysis to robust neural network training. They are usually solved using Riemannian optimization algorithms, which minimize the objective function while enforcing the constraint. However, enforcing the orthogonality constraint can be the most time-consuming operation in such algorithms. Recently, Ablin and Peyré (2022) proposed the landing algorithm, a method with cheap iterations that does not enforce the orthogonality constraints but is attracted towards the manifold in a smooth manner. This article provides new practical and theoretical developments for the landing algorithm. First, the method is extended to the Stiefel manifold, the set of rectangular orthogonal matrices. We also consider stochastic and variance reduction algorithms when the cost function is an average of many functions. We demonstrate that all these methods have the same rate of convergence as their Riemannian counterparts that exactly enforce the constraint, and converge to the manifold. Finally, our experiments demonstrate the promise of our approach to an array of machine-learning problems that involve orthogonality constraints.},
  archive      = {J_JMLR},
  author       = {Pierre Ablin and Simon Vary and Bin Gao and Pierre-Antoine Absil},
  journal      = {Journal of Machine Learning Research},
  number       = {389},
  pages        = {1-38},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Infeasible deterministic, stochastic, and variance-reduction algorithms for optimization under orthogonality constraints},
  url          = {https://jmlr.org/papers/v25/23-0451.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exponential tail local rademacher complexity risk bounds
without the bernstein condition. <em>JMLR</em>, <em>25</em>(388), 1–43.
(<a href="https://jmlr.org/papers/v25/23-0063.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The local Rademacher complexity framework is one of the most successful general-purpose toolboxes for establishing sharp excess risk bounds for statistical estimators based on empirical risk minimization. However, applying this toolbox typically requires using the Bernstein condition, which often restricts the applicability domain to convex and proper settings. Recent years have witnessed several examples of problems where optimal statistical performance is only achievable via non-convex and improper estimators originating from aggregation theory, including the fundamental problem of model selection. These examples are currently outside the reach of the classical local Rademacher complexity theory. In this work, we build upon the recent approach to localization via offset Rademacher complexities, for which a general high-probability theory has yet to be established. Our main result is an exponential-tail offset Rademacher complexity excess risk upper bound that yields results at least as sharp as those obtainable via the classical theory. However, our bound applies under an estimator-dependent geometric condition (the “offset condition”) instead of the estimator-independent (but, in general, distribution-dependent) Bernstein condition on which the classical theory relies. Our results apply to improper prediction regimes not directly covered by the classical theory, such as optimal model selection aggregation for arbitrary classes (including infinite and non-convex classes), and early-stopping/iterative regularization; the Bernstein condition does not hold in both examples.},
  archive      = {J_JMLR},
  author       = {Varun Kanade and Patrick Rebeschini and Tomas Vaskevicius},
  journal      = {Journal of Machine Learning Research},
  number       = {388},
  pages        = {1-43},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Exponential tail local rademacher complexity risk bounds without the bernstein condition},
  url          = {https://jmlr.org/papers/v25/23-0063.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Near-optimal algorithms for making the gradient small in
stochastic minimax optimization. <em>JMLR</em>, <em>25</em>(387), 1–44.
(<a href="https://jmlr.org/papers/v25/22-1126.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of finding a near-stationary point for smooth minimax optimization. The recently proposed extra anchored gradient (EAG) methods achieve the optimal convergence rate for the convex-concave minimax problem in the deterministic setting. However, the direct extension of EAG to stochastic optimization is not efficient. In this paper, we design a novel stochastic algorithm called Recursive Anchored IteratioN (RAIN). We show that the RAIN achieves near-optimal stochastic first-order oracle (SFO) complexity for stochastic minimax optimization in both convex-concave and strongly-convex-strongly-concave cases. In addition, we extend the idea of RAIN to solve structured nonconvex-nonconcave minimax problem and it also achieves near-optimal SFO complexity.},
  archive      = {J_JMLR},
  author       = {Lesi Chen and Luo Luo},
  journal      = {Journal of Machine Learning Research},
  number       = {387},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Near-optimal algorithms for making the gradient small in stochastic minimax optimization},
  url          = {https://jmlr.org/papers/v25/22-1126.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning discretized neural networks under ricci flow.
<em>JMLR</em>, <em>25</em>(386), 1–44. (<a
href="https://jmlr.org/papers/v25/22-0444.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study Discretized Neural Networks (DNNs) composed of low-precision weights and activations, which suffer from either infinite or zero gradients due to the non-differentiable discrete function during training. Most training-based DNNs in such scenarios employ the standard Straight-Through Estimator (STE) to approximate the gradient w.r.t. discrete values. However, the use of STE introduces the problem of gradient mismatch, arising from perturbations in the approximated gradient. To address this problem, this paper reveals that this mismatch can be interpreted as a metric perturbation in a Riemannian manifold, viewed through the lens of duality theory. Building on information geometry, we construct the Linearly Nearly Euclidean (LNE) manifold for DNNs, providing a background for addressing perturbations. By introducing a partial differential equation on metrics, i.e., the Ricci flow, we establish the dynamical stability and convergence of the LNE metric with the $L^2$-norm perturbation. In contrast to previous perturbation theories with convergence rates in fractional powers, the metric perturbation under the Ricci flow exhibits exponential decay in the LNE manifold. Experimental results across various datasets demonstrate that our method achieves superior and more stable performance for DNNs compared to other representative training-based methods.},
  archive      = {J_JMLR},
  author       = {Jun Chen and Hanwen Chen and Mengmeng Wang and Guang Dai and Ivor W. Tsang and Yong Liu},
  journal      = {Journal of Machine Learning Research},
  number       = {386},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning discretized neural networks under ricci flow},
  url          = {https://jmlr.org/papers/v25/22-0444.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep nonparametric quantile regression under covariate
shift. <em>JMLR</em>, <em>25</em>(385), 1–50. (<a
href="https://jmlr.org/papers/v25/24-0906.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on addressing the challenges posed by covariate shift in nonparametric quantile regression using deep neural networks. We propose a two-stage pre-training reweighted method that leverages importance weighting to mitigate the effects of distribution shift. In the first stage, density ratios are estimated with a neural network by minimizing least squares. In the second stage, a deep neural network estimator is obtained using pre-training weights. Theoretical analysis is provided, offering non-asymptotic error bounds for the unweighted, reweighted, and pre-training reweighted estimators. We consider scenarios with both bounded and unbounded density ratios. Notably, we employ a novel proof technique to bound the generalization error, characterized by the size and weights bound of ReLU neural networks. This enables us to establish fast rates of convergence under the adaptive self-calibration condition, distinguishing our approach from those relying on local Rademacher complexity techniques. Additionally, we derive the approximation error with weight bounds for ReLU neural networks approximating the H\&quot;older class. Our theoretical findings provide valuable insights for the pre-training process and highlight the efficacy of reweighted techniques. Numerical experiments are conducted to further validate the theoretical findings and demonstrate the effectiveness of our proposed method.},
  archive      = {J_JMLR},
  author       = {Xingdong Feng and Xin He and Yuling Jiao and Lican Kang and Caixing Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {385},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Deep nonparametric quantile regression under covariate shift},
  url          = {https://jmlr.org/papers/v25/24-0906.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Virtual-event-based posterior sampling and inference for
neyman-scott processes. <em>JMLR</em>, <em>25</em>(384), 1–67. (<a
href="https://jmlr.org/papers/v25/24-0235.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neyman-Scott processes (NSPs) are a class of Cox processes constructed by stacking layers of Poisson processes into a deep structure. While a lot of research has been conducted regarding the posterior sampling and inference for NSPs, most of the existing methods only work for shallow NSPs (i.e., NSPs with one layer of latent Poisson processes). In this paper, we present virtual-event-based posterior sampling and inference algorithms for NSPs. The algorithms work for both deep NSPs and shallow NSPs. Moreover, we show that deep NSPs can be viewed as branching processes or a limiting case of probabilistic graphical models. We conduct a theoretical analysis of the convergence of our algorithms and provide the condition for the convergence to hold. In doing so, we also prove the convergence of virtual-event-based sampling inference algorithms for other point process models with missing information (Markov jump processes, piecewise-constant intensity models, and Hawkes processes). Like NSPs, the latent variables of these models with missing information are also point processes. Our experimental results demonstrate that the prediction based on our sampling and inference algorithms for NSPs can achieve good prediction performance compared with state-of-the-art methods.},
  archive      = {J_JMLR},
  author       = {Chengkuan Hong and Christian R. Shelton and Jun Zhu},
  journal      = {Journal of Machine Learning Research},
  number       = {384},
  pages        = {1-67},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Virtual-event-based posterior sampling and inference for neyman-scott processes},
  url          = {https://jmlr.org/papers/v25/24-0235.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guaranteed nonconvex factorization approach for tensor train
recovery. <em>JMLR</em>, <em>25</em>(383), 1–48. (<a
href="https://jmlr.org/papers/v25/24-0029.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor train (TT) decomposition represents an order-$N$ tensor using $O(N)$ order-$3$ tensors (i.e., factors of small dimension), achieved through products among these factors. Due to its compact representation, TT decomposition has been widely used in the fields of signal processing, machine learning, and quantum physics. It offers benefits such as reduced memory requirements, enhanced computational efficiency, and decreased sampling complexity. Nevertheless, existing optimization algorithms with guaranteed performance concentrate exclusively on using the TT format for reducing the optimization space in recovery problems, while still operating on the entire tensor in each iteration. There is a lack of comprehensive theoretical analysis for optimization involving the factors directly, despite the proven efficacy of such factorization methods in practice. In this paper, we provide the first convergence guarantee for the factorization approach in a TT-based recovery problem. Specifically, to avoid the scaling ambiguity and to facilitate theoretical analysis, we optimize over the so-called left-orthogonal TT format which enforces orthonormality among most of the factors. To ensure the orthonormal structure, we utilize the Riemannian gradient descent (RGD) for optimizing those factors over the Stiefel manifold. We first delve into the TT factorization/decomposition problem and establish the local linear convergence of RGD. Notably, the rate of convergence only experiences a linear decline as the tensor order increases. We then study the sensing problem that aims to recover a TT format tensor from linear measurements. Assuming the sensing operator satisfies the restricted isometry property (RIP), we show that with a proper initialization, which could be obtained through spectral initialization, RGD also converges to the ground-truth tensor at a linear rate. Furthermore, we expand our analysis to encompass scenarios involving Gaussian noise in the measurements. We prove that RGD can reliably recover the ground truth at a linear rate, with the recovery error exhibiting only polynomial growth in relation to the tensor order $N$. We conduct various experiments to validate our theoretical findings.},
  archive      = {J_JMLR},
  author       = {Zhen Qin and Michael B. Wakin and Zhihui Zhu},
  journal      = {Journal of Machine Learning Research},
  number       = {383},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Guaranteed nonconvex factorization approach for tensor train recovery},
  url          = {https://jmlr.org/papers/v25/24-0029.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal decision tree and adaptive submodular ranking with
noisy outcomes. <em>JMLR</em>, <em>25</em>(382), 1–42. (<a
href="https://jmlr.org/papers/v25/23-1484.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In pool-based active learning, the learner is given an unlabeled data set and aims to efficiently learn the unknown hypothesis by querying the labels of the data points. This can be formulated as the classical Optimal Decision Tree (ODT) problem: Given a set of tests, a set of hypotheses, and an outcome for each pair of test and hypothesis, our objective is to find a low-cost testing procedure (i.e., decision tree) that identifies the true hypothesis. This optimization problem has been extensively studied under the assumption that each test generates a deterministic outcome. However, in numerous applications, for example, clinical trials, the outcomes may be uncertain, which renders the ideas in the deterministic setting invalid. In this work, we study a fundamental variant of the ODT problem in which some test outcomes are noisy, even in the more general case where the noise is persistent, i.e., repeating a test gives the same noisy output. Our approximation algorithms provide guarantees that are nearly best possible and hold for the general case of a large number of noisy outcomes per test or per hypothesis where the performance degrades continuously with this number. Furthermore, most of our results hold for a more general problem called Adaptive Submodular Ranking with Noise (ASRN). We numerically evaluated our algorithms for identifying toxic chemicals and learning linear classifiers and observed that our algorithms have costs very close to the information-theoretic minimum.},
  archive      = {J_JMLR},
  author       = {Su Jia and Fatemeh Navidi and Viswanath Nagarajan and R. Ravi},
  journal      = {Journal of Machine Learning Research},
  number       = {382},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal decision tree and adaptive submodular ranking with noisy outcomes},
  url          = {https://jmlr.org/papers/v25/23-1484.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decomposing global feature effects based on feature
interactions. <em>JMLR</em>, <em>25</em>(381), 1–65. (<a
href="https://jmlr.org/papers/v25/23-0699.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global feature effect methods, such as partial dependence plots, provide an intelligible visualization of the expected marginal feature effect. However, such global feature effect methods can be misleading, as they do not represent local feature effects of single observations well when feature interactions are present. We formally introduce generalized additive decomposition of global effects (GADGET), which is a new framework based on recursive partitioning to find interpretable regions in the feature space such that the interaction-related heterogeneity of local feature effects is minimized. We provide a mathematical foundation of the framework and show that it is applicable to the most popular methods to visualize marginal feature effects, namely partial dependence, accumulated local effects, and Shapley additive explanations (SHAP) dependence. Furthermore, we introduce and validate a new permutation-based interaction detection procedure that is applicable to any feature effect method that fits into our proposed framework. We empirically evaluate the theoretical characteristics of the proposed methods based on various feature effect methods in different experimental settings. Moreover, we apply our introduced methodology to three real-world examples to showcase their usefulness.},
  archive      = {J_JMLR},
  author       = {Julia Herbinger and Marvin N. Wright and Thomas Nagler and Bernd Bischl and Giuseppe Casalicchio},
  journal      = {Journal of Machine Learning Research},
  number       = {381},
  pages        = {1-65},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Decomposing global feature effects based on feature interactions},
  url          = {https://jmlr.org/papers/v25/23-0699.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A random projection approach to personalized federated
learning: Enhancing communication efficiency, robustness, and fairness.
<em>JMLR</em>, <em>25</em>(380), 1–88. (<a
href="https://jmlr.org/papers/v25/23-0215.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized Federated Learning (FL) faces many challenges such as expensive communication costs, training-time adversarial attacks, and performance unfairness across devices. Recent developments witness a trade-off between a reference model and local models to achieve personalization. Following the avenue, we propose a personalized FL method toward the three goals. When it is time to communicate, our method projects local models into a shared-and-fixed low-dimensional random subspace and uses infimal convolution to control the deviation between the reference model and projected local models. We theoretically show our method converges for both strongly convex and non-convex but smooth objectives with square regularizers and the convergence dependence on the projection dimension is mild. We also illustrate the benefits of robustness and fairness on a class of linear problems. Finally, we conduct a large number of experiments to show the empirical superiority of our method over several state-of-the-art methods on the three aspects.},
  archive      = {J_JMLR},
  author       = {Yuze Han and Xiang Li and Shiyun Lin and Zhihua Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {380},
  pages        = {1-88},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A random projection approach to personalized federated learning: Enhancing communication efficiency, robustness, and fairness},
  url          = {https://jmlr.org/papers/v25/23-0215.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerating nuclear-norm regularized low-rank matrix
optimization through burer-monteiro decomposition. <em>JMLR</em>,
<em>25</em>(379), 1–52. (<a
href="https://jmlr.org/papers/v25/23-0049.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a rapid algorithm, BM-Global, for nuclear-norm-regularized convex and low-rank matrix optimization problems. BM-Global efficiently decreases the objective value via low-cost steps leveraging the nonconvex but smooth Burer-Monteiro (BM) decomposition, while effectively escapes saddle points and spurious local minima ubiquitous in the BM form to obtain guarantees of fast convergence rates to the global optima of the original nuclear-norm-regularized problem through aperiodic inexact proximal gradient steps on it. The proposed approach adaptively adjusts the rank for the BM decomposition and can provably identify an optimal rank for the BM decomposition problem automatically in the course of optimization through tools of manifold identification. BM-Global hence also spends significantly less time on parameter tuning than existing matrix-factorization methods, which require an exhaustive search for finding this optimal rank. Extensive experiments on real-world large-scale problems of recommendation systems, regularized kernel estimation, and molecular conformation confirm that BM-Global can indeed effectively escapes spurious local minima at which existing BM approaches are stuck, and is a magnitude faster than state-of-the-art algorithms for low-rank matrix optimization problems involving a nuclear-norm regularizer. Based on this research, we have released an open-source package of the proposed BM-Global.},
  archive      = {J_JMLR},
  author       = {Ching-pei Lee and Ling Liang and Tianyun Tang and Kim-Chuan Toh},
  journal      = {Journal of Machine Learning Research},
  number       = {379},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Accelerating nuclear-norm regularized low-rank matrix optimization through burer-monteiro decomposition},
  url          = {https://jmlr.org/papers/v25/23-0049.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Targeted separation and convergence with kernel
discrepancies. <em>JMLR</em>, <em>25</em>(378), 1–50. (<a
href="https://jmlr.org/papers/v25/22-1123.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximum mean discrepancies (MMDs) like the kernel Stein discrepancy (KSD) have grown central to a wide range of applications, including hypothesis testing, sampler selection, distribution approximation, and variational inference. In each setting, these kernel-based discrepancy measures are required to $(i)$ separate a target $\mathrm{P}$ from other probability measures or even $(ii)$ control weak convergence to $\mathrm{P}$. In this article we derive new sufficient and necessary conditions to ensure $(i)$ and $(ii)$. For MMDs on separable metric spaces, we characterize those kernels that separate Bochner embeddable measures and introduce simple conditions for separating all measures with unbounded kernels and for controlling convergence with bounded kernels. We use these results on $\mathbb{R}^d$ to substantially broaden the known conditions for KSD separation and convergence control and to develop the first KSDs known to exactly metrize weak convergence to $\mathrm{P}$. Along the way, we highlight the implications of our results for hypothesis testing, measuring and improving sample quality, and sampling with Stein variational gradient descent.},
  archive      = {J_JMLR},
  author       = {Alessandro Barp and Carl-Johann Simon-Gabriel and Mark Girolami and Lester Mackey},
  journal      = {Journal of Machine Learning Research},
  number       = {378},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Targeted separation and convergence with kernel discrepancies},
  url          = {https://jmlr.org/papers/v25/22-1123.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Learning gaussian DAGs from network data. <em>JMLR</em>,
<em>25</em>(377), 1–52. (<a
href="https://jmlr.org/papers/v25/21-0846.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural learning of directed acyclic graphs (DAGs) or Bayesian networks has been studied extensively under the assumption that the data are independent. We propose a new Gaussian DAG model for dependent data which assumes the observations are correlated according to an undirected network. Under this model, we develop a method to estimate the DAG structure given a topological ordering of the nodes. The proposed method jointly estimates the Bayesian network and the correlations among observations by optimizing a scoring function based on penalized likelihood. We show that under some mild conditions, the proposed method produces consistent estimators after one iteration. Extensive numerical experiments also demonstrate that, by jointly estimating the DAG structure and the sample correlation, our method achieves much higher accuracy in structure learning. When the node ordering is unknown, through experiments on synthetic and real data, we show that our algorithm can be used to estimate the correlations between samples, with which we can de-correlate the dependent data to significantly improve the performance of classical DAG learning methods.},
  archive      = {J_JMLR},
  author       = {Hangjian Li and Oscar Hernan Madrid Padilla and Qing Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {377},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning gaussian DAGs from network data},
  url          = {https://jmlr.org/papers/v25/21-0846.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to “wasserstein distance estimates for the
distributions of numerical approximations to ergodic stochastic
differential equations”. <em>JMLR</em>, <em>25</em>(376), 1–9. (<a
href="https://jmlr.org/papers/v25/24-0895.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A method for analyzing non-asymptotic guarantees of numerical discretizations of ergodic SDEs in Wasserstein-2 distance is presented by Sanz-Serna and Zygalakis in Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations. They analyze the UBU integrator which is strong order two and only requires one gradient evaluation per step, resulting in desirable non-asymptotic guarantees, in particular $O(d^{1/4}\epsilon^{-1/2})$ steps to reach a distance of $\epsilon &gt; 0$ in Wasserstein-2 distance away from the target distribution. However, there is a mistake in the local error estimates in Sanz-Serna and Zygalakis (2021), in particular, a stronger assumption is needed to achieve these complexity estimates. This note reconciles the theory with the dimension dependence observed in practice in many applications of interest.},
  archive      = {J_JMLR},
  author       = {Daniel Paulin and Peter A. Whalley},
  journal      = {Journal of Machine Learning Research},
  number       = {376},
  pages        = {1-9},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Correction to &quot;Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations&quot;},
  url          = {https://jmlr.org/papers/v25/24-0895.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KerasCV and KerasNLP: Multi-framework models. <em>JMLR</em>,
<em>25</em>(375), 1–10. (<a
href="https://jmlr.org/papers/v25/24-0404.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the Keras domain packages KerasCV and KerasNLP, extensions of the Keras API for Computer Vision and Natural Language Processing workflows, capable of running on either JAX, TensorFlow, or PyTorch. These domain packages are designed to enable fast experimentation, with a focus on ease-of-use and performance. We adopt a modular, layered design: at the library&#39;s lowest level of abstraction, we provide building blocks for creating models and data preprocessing pipelines, and at the library&#39;s highest level of abstraction, we provide pretrained &quot;task&quot; models for popular architectures such as Stable Diffusion, YOLOv8, GPT2, BERT, Mistral, CLIP, Gemma, T5, etc. Task models have built-in preprocessing, pretrained weights, and can be fine-tuned on raw inputs. To enable efficient training, we support XLA compilation for all models, and run all preprocessing via a compiled graph of TensorFlow operations using the tf.data API. The libraries are fully open-source (Apache 2.0 license) and available on GitHub. Keywords: KerasCV, KerasNLP, Keras multi-backend, Deep learning, Generative AI},
  archive      = {J_JMLR},
  author       = {Matthew Watson and Divyashree Shivakumar Sreepathihalli and François Chollet and Martin Górner and Kiranbir Sodhia and Ramesh Sampath and Tirth Patel and Haifeng Jin and Neel Kovelamudi and Gabriel Rasskin and Samaneh Saadat and Luke Wood and Chen Qian and Jonathan Bischof and Ian Stenbit and Abheesht Sharma and Anshuman Mishra},
  journal      = {Journal of Machine Learning Research},
  number       = {375},
  pages        = {1-10},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {KerasCV and KerasNLP: Multi-framework models},
  url          = {https://jmlr.org/papers/v25/24-0404.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TopoX: A suite of python packages for machine learning on
topological domains. <em>JMLR</em>, <em>25</em>(374), 1–8. (<a
href="https://jmlr.org/papers/v25/24-0110.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce \texttt{TopoX}, a Python software suite that provides reliable and user-friendly building blocks for computing and machine learning on topological domains that extend graphs: hypergraphs, simplicial, cellular, path and combinatorial complexes. \texttt{TopoX} consists of three packages: \texttt{TopoNetX} facilitates constructing and computing on these domains, including working with nodes, edges and higher-order cells; \texttt{TopoEmbedX} provides methods to embed topological domains into vector spaces, akin to popular graph-based embedding algorithms such as node2vec; \texttt{TopoModelX} is built on top of \texttt{PyTorch} and offers a comprehensive toolbox of higher-order message passing functions for neural networks on topological domains. The extensively documented and unit-tested source code of \texttt{TopoX} is available under MIT license at \textcolor{blue}{\Href{https://pyt-team.github.io/}{https://pyt-team.github.io/}}.},
  archive      = {J_JMLR},
  author       = {Mustafa Hajij and Mathilde Papillon and Florian Frantzen and Jens Agerberg and Ibrahem AlJabea and Rubén Ballester and Claudio Battiloro and Guillermo Bernárdez and Tolga Birdal and Aiden Brent and Peter Chin and Sergio Escalera and Simone Fiorellino and Odin Hoff Gardaa and Gurusankar Gopalakrishnan and Devendra Govil and Josef Hoppe and Maneel Reddy Karri and Jude Khouja and Manuel Lecha and Neal Livesay and Jan Meißner and Soham Mukherjee and Alexander Nikitin and Theodore Papamarkou and Jaro Prílepok and Karthikeyan Natesan Ramamurthy and Paul Rosen and Aldo Guzmán-Sáenz and Alessandro Salatiello and Shreyas N. Samaga and Simone Scardapane and Michael T. Schaub and Luca Scofano and Indro Spinelli and Lev Telyatnikov and Quang Truong and Robin Walters and Maosheng Yang and Olga Zaghen and Ghada Zamzmi and Ali Zia and Nina Miolane},
  journal      = {Journal of Machine Learning Research},
  number       = {374},
  pages        = {1-8},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {TopoX: A suite of python packages for machine learning on topological domains},
  url          = {https://jmlr.org/papers/v25/24-0110.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An inexact projected regularized newton method for fused
zero-norms regularization problems. <em>JMLR</em>, <em>25</em>(373),
1–48. (<a href="https://jmlr.org/papers/v25/23-1700.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns structured $\ell_0$-norms regularization problems, with a twice continuously differentiable loss function and a box constraint. This class of problems have a wide range of applications in statistics, machine learning and image processing. To the best of our knowledge, there is no efficient algorithm in the literature for solving them. In this paper, we first provide a polynomial-time algorithm to find a point in the proximal mapping of the fused $\ell_0$-norms with a box constraint based on dynamic programming principle. We then propose a hybrid algorithm of proximal gradient method and inexact projected regularized Newton method to solve structured $\ell_0$-norms regularization problems. The iterate sequence generated by the algorithm is shown to be convergent by virtue of a non-degeneracy condition, a curvature condition and a Kurdyka-{\L}ojasiewicz property. A superlinear convergence rate of the iterates is established under a locally H\&quot;{o}lderian error bound condition on a second-order stationary point set, without requiring the local optimality of the limit point. Finally, numerical experiments are conducted to highlight the features of our considered model, and the superiority of our proposed algorithm.},
  archive      = {J_JMLR},
  author       = {Yuqia Wu and Shaohua Pan and Xiaoqi Yang},
  journal      = {Journal of Machine Learning Research},
  number       = {373},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {An inexact projected regularized newton method for fused zero-norms regularization problems},
  url          = {https://jmlr.org/papers/v25/23-1700.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning regularized graphon mean-field games with unknown
graphons. <em>JMLR</em>, <em>25</em>(372), 1–95. (<a
href="https://jmlr.org/papers/v25/23-1409.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design and analyze reinforcement learning algorithms for Graphon Mean-Field Games (GMFGs). In contrast to previous works that require the precise values of the graphons, we aim to learn the Nash Equilibrium (NE) of the regularized GMFGs when the graphons are unknown. Our contributions are threefold. First, we propose the Proximal Policy Optimization for GMFG (GMFG-PPO) algorithm and show that it converges at a rate of $\tilde{O}(T^{-1/3})$ after $T$ iterations with an estimation oracle, improving on a previous work by Xie et al. (ICML, 2021). Second, using kernel embedding of distributions, we design efficient algorithms to estimate the transition kernels, reward functions, and graphons from sampled agents. Convergence rates are then derived when the positions of the agents are either known or unknown. Results for the combination of the optimization algorithm GMFG-PPO and the estimation algorithm are then provided. These algorithms are the first specifically designed for learning graphons from sampled agents. Finally, the efficacy of the proposed algorithms are corroborated through simulations. These simulations demonstrate that learning the unknown graphons reduces the exploitability effectively.},
  archive      = {J_JMLR},
  author       = {Fengzhuo Zhang and Vincent Y. F. Tan and Zhaoran Wang and Zhuoran Yang},
  journal      = {Journal of Machine Learning Research},
  number       = {372},
  pages        = {1-95},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning regularized graphon mean-field games with unknown graphons},
  url          = {https://jmlr.org/papers/v25/23-1409.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PGMax: Factor graphs for discrete probabilistic graphical
models and loopy belief propagation in JAX. <em>JMLR</em>,
<em>25</em>(371), 1–25. (<a
href="https://jmlr.org/papers/v25/23-1010.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PGMax is an open-source Python/ JAX package for (a) easily specifying discrete Probabilistic Graphical Models (PGMs) as factor graphs; and (b) automatically running efficient and scalable differentiable Loopy Belief Propagation (LBP). PGMax supports general factor graphs with tractable factors, and leverages modern accelerators like GPUs for inference. Compared with alternative libraries, PGMax obtains higher-quality inference results with up to three orders-of-magnitude inference time speedups. PGMax interacts seamlessly with the growing JAX ecosystem, opening up new research possibilities. Our source code, examples and documentation are available at https://github.com/google-deepmind/PGMax},
  archive      = {J_JMLR},
  author       = {Guangyao Zhou and Antoine Dedieu and Nishanth Kumar and Wolfgang Lehrach and Shrinu Kushagra and Dileep George and Miguel Lázaro-Gredilla},
  journal      = {Journal of Machine Learning Research},
  number       = {371},
  pages        = {1-25},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {PGMax: Factor graphs for discrete probabilistic graphical models and loopy belief propagation in JAX},
  url          = {https://jmlr.org/papers/v25/23-1010.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gradient-free optimization of highly smooth functions:
Improved analysis and a new algorithm. <em>JMLR</em>, <em>25</em>(370),
1–50. (<a href="https://jmlr.org/papers/v25/23-0733.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work studies minimization problems with zero-order noisy oracle information under the assumption that the objective function is highly smooth and possibly satisfies additional properties. We consider two kinds of zero-order projected gradient descent algorithms, which differ in the form of the gradient estimator. The first algorithm uses a gradient estimator based on randomization over the $\ell_2$ sphere due to Bach and Perchet (2016). We present an improved analysis of this algorithm on the class of highly smooth and strongly convex functions studied in the prior work, and we derive rates of convergence for two more general classes of non-convex functions. Namely, we consider highly smooth functions satisfying the Polyak-Łojasiewicz condition and the class of highly smooth functions with no additional property. The second algorithm is based on randomization over the $\ell_1$ sphere, and it extends to the highly smooth setting the algorithm that was recently proposed for Lipschitz convex functions in Akhavan et al. (2022). We show that, in the case of noiseless oracle, this novel algorithm enjoys better bounds on bias and variance than the $\ell_2$ randomization and the commonly used Gaussian randomization algorithms, while in the noisy case both $\ell_1$ and $\ell_2$ algorithms benefit from similar improved theoretical guarantees. The improvements are achieved thanks to a new proof techniques based on Poincaré type inequalities for uniform distributions on the $\ell_1$ or $\ell_2$ spheres. The results are established under weak (almost adversarial) assumptions on the noise. Moreover, we provide minimax lower bounds proving optimality or near optimality of the obtained upper bounds in several cases.},
  archive      = {J_JMLR},
  author       = {Arya Akhavan and Evgenii Chzhen and Massimiliano Pontil and Alexandre B. Tsybakov},
  journal      = {Journal of Machine Learning Research},
  number       = {370},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Gradient-free optimization of highly smooth functions: Improved analysis and a new algorithm},
  url          = {https://jmlr.org/papers/v25/23-0733.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A minimax optimal approach to high-dimensional double sparse
linear regression. <em>JMLR</em>, <em>25</em>(369), 1–66. (<a
href="https://jmlr.org/papers/v25/23-0653.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus our attention on the high-dimensional double sparse linear regression, that is, a combination of element-wise and group-wise sparsity. To address this problem, we propose an IHT-style (iterative hard thresholding) procedure that dynamically updates the threshold at each step. We establish the matching upper and lower bounds for parameter estimation, showing the optimality of our proposal in the minimax sense. More importantly, we introduce a fully adaptive optimal procedure designed to address unknown sparsity and noise levels. Our adaptive procedure demonstrates optimal statistical accuracy with fast convergence. Additionally, we elucidate the significance of the element-wise sparsity level $s_0$ as the trade-off between IHT and group IHT, underscoring the superior performance of our method over both. Leveraging the beta-min condition, we establish that our IHT-style procedure can attain the oracle estimation rate and achieve almost full recovery of the true support set at both the element level and group level. Finally, we demonstrate the superiority of our method by comparing it with several state-of-the-art algorithms on both synthetic and real-world datasets.},
  archive      = {J_JMLR},
  author       = {Yanhang Zhang and Zhifan Li and Shixiang Liu and Jianxin Yin},
  journal      = {Journal of Machine Learning Research},
  number       = {369},
  pages        = {1-66},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A minimax optimal approach to high-dimensional double sparse linear regression},
  url          = {https://jmlr.org/papers/v25/23-0653.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Localisation of regularised and multiview support vector
machine learning. <em>JMLR</em>, <em>25</em>(368), 1–47. (<a
href="https://jmlr.org/papers/v25/23-0522.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove some representer theorems for a localised version of a semisupervised, manifold regularised and multiview support vector machine learning problem introduced by H.Q. Minh, L. Bazzani, and V. Murino, Journal of Machine Learning Research, 17(2016) 1-72, that involves operator valued positive semidefinite kernels and their reproducing kernel Hilbert spaces. The results concern general cases when convex or nonconvex lossfunctions and finite or infinite dimensional underlying Hilbert spaces are considered. We show that the general framework allows infinite dimensional Hilbert spaces and nonconvex loss functions for some special cases, in particular in case the loss functions are Gâteaux differentiable. Detailed calculations are provided for the exponential least squares loss functions that lead to systems of partially nonlinear equations for which some Newton&#39;s approximation methods based on the interior point method can be used. Some numerical experiments are performed on a toy model that illustratethe tractability of the methods that we propose.},
  archive      = {J_JMLR},
  author       = {Aurelian Gheondea and Cankat Tilki},
  journal      = {Journal of Machine Learning Research},
  number       = {368},
  pages        = {1-47},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Localisation of regularised and multiview support vector machine learning},
  url          = {https://jmlr.org/papers/v25/23-0522.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consistent multiclass algorithms for complex metrics and
constraints. <em>JMLR</em>, <em>25</em>(367), 1–81. (<a
href="https://jmlr.org/papers/v25/22-1137.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present consistent algorithms for multiclass learning with complex performance metrics and constraints, where the objective and constraints are defined by arbitrary functions of the confusion matrix. This setting includes many common performance metrics such as the multiclass G-mean and micro F-measure, and constraints such as those on the classifier&#39;s precision and recall and more recent measures of fairness discrepancy. We give a general framework for designing consistent algorithms for such complex design goals by viewing the learning problem as an optimization problem over the set of feasible confusion matrices. We provide multiple instantiations of our framework under different assumptions on the performance metrics and constraints, and in each case show rates of convergence to the optimal (feasible) classifier (and thus asymptotic consistency). Experiments on a variety of multiclass classification tasks and fairness constrained problems show that our algorithms compare favorably to the state-of-the-art baselines.},
  archive      = {J_JMLR},
  author       = {Harikrishna Narasimhan and Harish G. Ramaswamy and Shiv Kumar Tavker and Drona Khurana and Praneeth Netrapalli and Shivani Agarwal},
  journal      = {Journal of Machine Learning Research},
  number       = {367},
  pages        = {1-81},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Consistent multiclass algorithms for complex metrics and constraints},
  url          = {https://jmlr.org/papers/v25/22-1137.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximate bayesian inference from noisy likelihoods with
gaussian process emulated MCMC. <em>JMLR</em>, <em>25</em>(366), 1–55.
(<a href="https://jmlr.org/papers/v25/21-0421.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a framework for approximate Bayesian inference intended for a situation where only a limited number of noisy log-likelihood evaluations can be obtained due to constraints on the available computational budget, which is becoming increasingly common for expensive simulator-based models. We model the log-likelihood function using a Gaussian process (GP) and our main methodological innovation is to apply this model to emulate the progression that an exact Metropolis-Hastings (MH) sampler would take if it was applicable. Informative log-likelihood evaluation locations are selected using a sequential experimental design strategy until the MH accept/reject decisions are performed with sufficient level of accuracy based on a prespecified error tolerance criterion. The resulting approximate sampler is conceptually simple and shown to be sample-efficient. It is also more robust compared with earlier “Bayesian optimisation-like” methods tailored for approximate Bayesian inference, which generally assume a global surrogate model across the parameter space that can be challenging to fit well. We discuss some theoretical aspects and various interpretations of the resulting approximate MH sampler, and demonstrate its benefits in the context of Bayesian and generalised Bayesian likelihood-free inference for simulator-based statistical models.},
  archive      = {J_JMLR},
  author       = {Marko Järvenpää and Jukka Corander},
  journal      = {Journal of Machine Learning Research},
  number       = {366},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Approximate bayesian inference from noisy likelihoods with gaussian process emulated MCMC},
  url          = {https://jmlr.org/papers/v25/21-0421.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Topological analysis for detecting anomalies in dependent
sequences: Application to time series. <em>JMLR</em>, <em>25</em>(365),
1–49. (<a href="https://jmlr.org/papers/v25/24-0853.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new methodology based on the field of Topological Data Analysis for detecting structural anomalies in dependent sequences of complex data. A motivating example is that of multivariate time series, for which our method allows to detect global changes in the dependence structure between channels. The proposed approach is lean enough to handle large scale data sets, and extensive numerical experiments back the intuition that it is more suitable for detecting global changes of correlation structures than existing methods. Some theoretical guarantees for quantization algorithms based on dependent sequences are also provided.},
  archive      = {J_JMLR},
  author       = {Frédéric Chazal and Clément Levrard and Martin Royer},
  journal      = {Journal of Machine Learning Research},
  number       = {365},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Topological analysis for detecting anomalies in dependent sequences: Application to time series},
  url          = {https://jmlr.org/papers/v25/24-0853.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Operator learning without the adjoint. <em>JMLR</em>,
<em>25</em>(364), 1–54. (<a
href="https://jmlr.org/papers/v25/24-0162.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a mystery at the heart of operator learning: how can one recover a non-self-adjoint operator from data without probing the adjoint? Current practical approaches suggest that one can accurately recover an operator while only using data generated by the forward action of the operator without access to the adjoint. However, naively, it seems essential to sample the action of the adjoint. In this paper, we partially explain this mystery by proving that without querying the adjoint, one can approximate a family of non-self-adjoint infinite-dimensional compact operators via projection onto a Fourier basis. We then apply the result to recovering Green&#39;s functions of elliptic partial differential operators and derive an adjoint-free sample complexity bound. While existing theory justifies low sample complexity in operator learning, ours is the first adjoint-free analysis that attempts to close the gap between theory and practice.},
  archive      = {J_JMLR},
  author       = {Nicolas Boullé and Diana Halikias and Samuel E. Otto and Alex Townsend},
  journal      = {Journal of Machine Learning Research},
  number       = {364},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Operator learning without the adjoint},
  url          = {https://jmlr.org/papers/v25/24-0162.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Entropic gromov-wasserstein distances: Stability and
algorithms. <em>JMLR</em>, <em>25</em>(363), 1–52. (<a
href="https://jmlr.org/papers/v25/24-0039.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gromov-Wasserstein (GW) distance quantifies discrepancy between metric measure spaces and provides a natural framework for aligning heterogeneous datasets. Alas, as exact computation of GW alignment is NP-complete, entropic regularization provides an avenue towards a computationally tractable proxy. Leveraging a recently derived variational representation for the quadratic entropic GW (EGW) distance, this work derives the first efficient algorithms for solving the EGW problem subject to formal, non-asymptotic convergence guarantees. To that end, we derive smoothness and convexity properties of the objective in this variational problem, which enables its resolution by the accelerated gradient method. Our algorithms employ Sinkhorn&#39;s fixed point iterations to compute an approximate gradient, which we model as an inexact oracle. We furnish convergence rates towards local and even global solutions (the latter holds under a precise quantitative condition on the regularization parameter), characterize the effects of gradient inexactness, and prove that stationary points of the EGW problem converge towards a stationary point of the unregularized GW problem, in the limit of vanishing regularization. We provide numerical experiments that validate our theory and empirically demonstrate the state-of-the-art empirical performance of our algorithm.},
  archive      = {J_JMLR},
  author       = {Gabriel Rioux and Ziv Goldfeld and Kengo Kato},
  journal      = {Journal of Machine Learning Research},
  number       = {363},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Entropic gromov-wasserstein distances: Stability and algorithms},
  url          = {https://jmlr.org/papers/v25/24-0039.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Line graph vietoris-rips persistence diagram for topological
graph representation learning. <em>JMLR</em>, <em>25</em>(362), 1–36.
(<a href="https://jmlr.org/papers/v25/23-1610.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While message passing graph neural networks result in informative node embeddings, they may suffer from describing the topological properties of graphs. To this end, node filtration has been widely used as an attempt to obtain the topological information of a graph using persistence diagrams. However, these attempts have faced the problem of losing node embedding information, which in turn prevents them from providing a more expressive graph representation. To tackle this issue, we shift our focus to edge filtration and introduce a novel edge filtration-based persistence diagram, named Topological Edge Diagram (TED), which is mathematically proven to preserve node embedding information as well as contain additional topological information. To implement TED, we propose a neural network based algorithm, named Line Graph Vietoris-Rips (LGVR) Persistence Diagram, that extracts edge information by transforming a graph into its line graph. Through LGVR, we propose two model frameworks that can be applied to any message passing GNNs, and prove that they are strictly more powerful than Weisfeiler-Lehman type colorings. Finally we empirically validate superior performance of our models on several graph classification and regression benchmarks.},
  archive      = {J_JMLR},
  author       = {Jaesun Shin and Eunjoo Jeon and Taewon Cho and Namkyeong Cho and Youngjune Gwon},
  journal      = {Journal of Machine Learning Research},
  number       = {362},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Line graph vietoris-rips persistence diagram for topological graph representation learning},
  url          = {https://jmlr.org/papers/v25/23-1610.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gradual domain adaptation: Theory and algorithms.
<em>JMLR</em>, <em>25</em>(361), 1–40. (<a
href="https://jmlr.org/papers/v25/23-1180.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) adapts a model from a labeled source domain to an unlabeled target domain in a one-off way. Though widely applied, UDA faces a great challenge whenever the distribution shift between the source and the target is large. Gradual domain adaptation (GDA) mitigates this limitation by using intermediate domains to gradually adapt from the source to the target domain. In this work, we first theoretically analyze gradual self-training, a popular GDA algorithm, and provide a significantly improved generalization bound compared with Kumar et al. (2020). Our theoretical analysis leads to an interesting insight: to minimize the generalization error on the target domain, the sequence of intermediate domains should be placed uniformly along the Wasserstein geodesic between the source and target domains. The insight is particularly useful under the situation where intermediate domains are missing or scarce, which is often the case in real-world applications. Based on the insight, we propose Generative Gradual Domain Adaptation with Optimal Transport (GOAT), an algorithmic framework that can generate intermediate domains in a data-dependent way. More concretely, we first generate intermediate domains along the Wasserstein geodesic between two given consecutive domains in a feature space, then apply gradual self-training to adapt the source-trained classifier to the target along the sequence of intermediate domains. Empirically, we demonstrate that our GOAT framework can improve the performance of standard GDA when the given intermediate domains are scarce, significantly broadening the real-world application scenarios of GDA. Our code is available at https://github.com/uiuctml/GOAT.},
  archive      = {J_JMLR},
  author       = {Yifei He and Haoxiang Wang and Bo Li and Han Zhao},
  journal      = {Journal of Machine Learning Research},
  number       = {361},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Gradual domain adaptation: Theory and algorithms},
  url          = {https://jmlr.org/papers/v25/23-1180.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The nyström method for convex loss functions. <em>JMLR</em>,
<em>25</em>(360), 1–60. (<a
href="https://jmlr.org/papers/v25/23-0768.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate an extension of classical empirical risk minimization, where the hypothesis space consists of a random subspace within a given Hilbert space. Specifically, we examine the Nyström method where the subspaces are defined by a random subset of the data. This approach recovers Nyström approximations used in kernel methods as a specific case. Using random subspaces naturally leads to computational advantages, but a key question is whether it compromises the learning accuracy. Recently, the tradeoﬀs between statistics and computation have been explored for the square loss and self-concordant losses, such as the logistic loss. In this paper, we extend these analyses to general convex Lipschitz losses, which may lack smoothness, such as the hinge loss used in support vector machines. Our main results show the existence of various scenarios where computational gains can be achieved without sacrificing learning performance. When specialized to smooth loss functions, our analysis recovers most previous results. Moreover, it allows to consider classification problems and translate the surrogate risk bounds into classification error bounds. Indeed, this gives the opportunity to compare the eﬀect of Nyström approximations when combined with diﬀerent loss functions such as the hinge or the square loss.},
  archive      = {J_JMLR},
  author       = {Andrea Della Vecchia and Ernesto De Vito and Jaouad Mourtada and Lorenzo Rosasco},
  journal      = {Journal of Machine Learning Research},
  number       = {360},
  pages        = {1-60},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {The nyström method for convex loss functions},
  url          = {https://jmlr.org/papers/v25/23-0768.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed kernel-driven data clustering. <em>JMLR</em>,
<em>25</em>(359), 1–39. (<a
href="https://jmlr.org/papers/v25/23-0669.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel fully distributed joint kernel learning and clustering framework is derived which is capable of determining clustering configurations in an unsupervised manner. Semidefinite programming is utilized to quantify closeness of candidate kernel similarity matrices to a block diagonal structure of certain rank. Utilizing difference of convex functions and block coordinate descent a recursive algorithm is derived that determines jointly a proper kernel similarity matrix and clustering factors. Reformulating the involved semidefinite programs in a separable way we build on the alternating direction method of multipliers, to construct a fully distributed scheme that enables joint kernel learning and clustering in ad hoc networks via collaborating neighboring agents. Convergence claims establish that the proposed algorithmic framework returns bounded similarity kernel updates promoting a block diagonal structure. Detailed numerical examples utilizing both synthetic and real data demonstrate that the distributed novel approach can achieve clustering performance that gets close or even exceeds the one achieved by existing centralized alternatives.},
  archive      = {J_JMLR},
  author       = {Ioannis Schizas},
  journal      = {Journal of Machine Learning Research},
  number       = {359},
  pages        = {1-39},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Distributed kernel-driven data clustering},
  url          = {https://jmlr.org/papers/v25/23-0669.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertainty quantification of MLE for entity ranking with
covariates. <em>JMLR</em>, <em>25</em>(358), 1–83. (<a
href="https://jmlr.org/papers/v25/23-0554.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study statistical estimation and inference for the ranking problems based on pairwise comparisons with additional covariate information. In specific, in this paper, we study a Covariate-Assisted Ranking Estimation (CARE) model in a systematic way, that extends the well-known Bradley-Terry-Luce (BTL) model by incorporating the covariate information. We impose natural identifiability conditions, derive the statistical rates for the MLE under a sparse comparison graph, and obtain its asymptotic distribution. Moreover, we validate our theoretical results through large-scale numerical studies.},
  archive      = {J_JMLR},
  author       = {Jianqing Fan and Jikai Hou and Mengxin Yu},
  journal      = {Journal of Machine Learning Research},
  number       = {358},
  pages        = {1-83},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Uncertainty quantification of MLE for entity ranking with covariates},
  url          = {https://jmlr.org/papers/v25/23-0554.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated automatic differentiation. <em>JMLR</em>,
<em>25</em>(357), 1–39. (<a
href="https://jmlr.org/papers/v25/23-0223.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a framework for learning across an axis of group partitioned data (heterogeneous clients) while preserving data privacy, under the orchestration of a central server. FL methods often compute gradients of loss functions purely locally (e.g. at each client), typically using automatic differentiation (AD) techniques. In this work, we consider the problem of applying AD to federated computations while preserving compatibility with privacy-enhancing technologies. We propose a framework, federated automatic differentiation (federated AD), that 1) enables computing derivatives of functions involving client and server computation as well as communication between them and 2) operates in a manner compatible with existing federated technology. We show, in analogy with AD, that federated AD may be implemented using various accumulation modes, which introduce distinct computation-communication trade-offs and systems requirements. Further, we show that a broad class of federated computations is closed under these modes of federated AD, implying that if the original computation can be implemented using privacy-preserving primitives, its derivative may be computed using the same primitives. We then show how federated AD can be used to create algorithms that dynamically learn components of the algorithm itself. We demonstrate that performance of FedAvg-style algorithms can be significantly improved by using federated AD in this manner.},
  archive      = {J_JMLR},
  author       = {Keith Rush and Zachary Charles and Zachary Garrett},
  journal      = {Journal of Machine Learning Research},
  number       = {357},
  pages        = {1-39},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Federated automatic differentiation},
  url          = {https://jmlr.org/papers/v25/23-0223.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the impact of hard adversarial instances on overfitting
in adversarial training. <em>JMLR</em>, <em>25</em>(356), 1–46. (<a
href="https://jmlr.org/papers/v25/22-0950.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial training is a popular method to robustify models against adversarial attacks. However, it exhibits much more severe overfitting than training on clean inputs. In this work, we investigate this phenomenon from the perspective of training instances, i.e., training input-target pairs. Based on a quantitative metric measuring the relative difficulty of an instance in the training set, we analyze the model&#39;s behavior on training instances of different difficulty levels. This lets us demonstrate that the decay in generalization performance of adversarial training is a result of fitting hard adversarial instances. We theoretically verify our observations for both linear and general nonlinear models, proving that models trained on hard instances have worse generalization performance than ones trained on easy instances, and that this generalization gap increases with the size of the adversarial budget. Finally, we investigate solutions to mitigate adversarial overfitting in several scenarios, including fast adversarial training and fine-tuning a pretrained model with additional data. Our results demonstrate that using training data adaptively improves the model&#39;s robustness.},
  archive      = {J_JMLR},
  author       = {Chen Liu and Zhichao Huang and Mathieu Salzmann and Tong Zhang and Sabine Süsstrunk},
  journal      = {Journal of Machine Learning Research},
  number       = {356},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the impact of hard adversarial instances on overfitting in adversarial training},
  url          = {https://jmlr.org/papers/v25/22-0950.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fréchet random forests for metric space valued regression
with non euclidean predictors. <em>JMLR</em>, <em>25</em>(355), 1–41.
(<a href="https://jmlr.org/papers/v25/20-1173.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random forests are a statistical learning method widely used in many areas of scientific research because of its ability to learn complex relationships between input and output variables and also its capacity to handle high-dimensional data. However, current random forest approaches are not flexible enough to handle heterogeneous data such as curves, images and shapes. In this paper, we introduce Fréchet trees and Fréchet random forests, which allow to handle data for which input and output variables take values in general metric spaces. To this end, a new way of splitting the nodes of trees is introduced and the prediction procedures of trees and forests are generalized. Then, random forests out-of-bag error and variable importance score are naturally adapted. A consistency theorem for Fréchet regressogram predictor using data-driven partitions is given and applied to Fréchet purely uniformly random trees. The method is studied through several simulation scenarios on heterogeneous data combining longitudinal, image and scalar data. Finally, one real data set about air quality is used to illustrate the use of the proposed method in practice.},
  archive      = {J_JMLR},
  author       = {Louis Capitaine and Jérémie Bigot and Rodolphe Thiébaut and Robin Genuer},
  journal      = {Journal of Machine Learning Research},
  number       = {355},
  pages        = {1-41},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fréchet random forests for metric space valued regression with non euclidean predictors},
  url          = {https://jmlr.org/papers/v25/20-1173.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aequitas flow: Streamlining fair ML experimentation.
<em>JMLR</em>, <em>25</em>(354), 1–7. (<a
href="https://jmlr.org/papers/v25/24-0677.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aequitas Flow is an open-source framework and toolkit for end-to-end Fair Machine Learning (ML) experimentation, and benchmarking in Python. This package fills integration gaps that exist in other fair ML packages. In addition to the existing audit capabilities in Aequitas, the Aequitas Flow module provides a pipeline for fairness-aware model training, hyperparameter optimization, and evaluation, enabling easy-to-use and rapid experiments and analysis of results. Aimed at ML practitioners and researchers, the framework offers implementations of methods, datasets, metrics, and standard interfaces for these components to improve extensibility. By facilitating the development of fair ML practices, Aequitas Flow hopes to enhance the incorporation of fairness concepts in AI systems making AI systems more robust and fair.},
  archive      = {J_JMLR},
  author       = {Sérgio Jesus and Pedro Saleiro and Inês Oliveira e Silva and Beatriz M. Jorge and Rita P. Ribeiro and João Gama and Pedro Bizarro and Rayid Ghani},
  journal      = {Journal of Machine Learning Research},
  number       = {354},
  pages        = {1-7},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Aequitas flow: Streamlining fair ML experimentation},
  url          = {https://jmlr.org/papers/v25/24-0677.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Information capacity regret bounds for bandits with mediator
feedback. <em>JMLR</em>, <em>25</em>(353), 1–36. (<a
href="https://jmlr.org/papers/v25/24-0227.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the mediator feedback problem, a bandit game where the decision set consists of a number of policies, each associated with a probability distribution over a common space of outcomes. Upon choosing a policy, the learner observes an outcome sampled from its distribution and incurs the loss assigned to this outcome in the present round. We introduce the policy set capacity as an information-theoretic measure for the complexity of the policy set. Adopting the classical EXP4 algorithm, we provide new regret bounds depending on the policy set capacity in both the adversarial and the stochastic settings. For a selection of policy set families, we prove nearly-matching lower bounds, scaling similarly with the capacity. We also consider the case when the policies&#39; distributions can vary between rounds, thus addressing the related bandits with expert advice problem, which we improve upon its prior results. Additionally, we prove a lower bound showing that exploiting the similarity between the policies is not possible in general under linear bandit feedback. Finally, for a full-information variant, we provide a regret bound scaling with the information radius of the policy set.},
  archive      = {J_JMLR},
  author       = {Khaled Eldowa and Nicolo Cesa-Bianchi and Alberto Maria Metelli and Marcello Restelli},
  journal      = {Journal of Machine Learning Research},
  number       = {353},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Information capacity regret bounds for bandits with mediator feedback},
  url          = {https://jmlr.org/papers/v25/24-0227.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DAG-informed structure learning from multi-dimensional point
processes. <em>JMLR</em>, <em>25</em>(352), 1–56. (<a
href="https://jmlr.org/papers/v25/24-0067.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by inferring causal relationships among neurons using ensemble spike train data, this paper introduces a new technique for learning the structure of a directed acyclic graph (DAG) within a large network of events, applicable to diverse multi-dimensional temporal point process (MuTPP) data. At the core of MuTPP lie the conditional intensity functions, for which we construct a generative model parameterized by the graph parameters of a DAG and develop an equality-constrained estimator, departing from exhaustive search-based methods. We present a novel, flexible augmented Lagrangian (Flex-AL) optimization scheme that ensures provable global convergence and computational efficiency gains over the classical AL algorithm. Additionally, we explore causal structure learning by integrating acyclicity-constraints and sparsity-regularization. We demonstrate: (i) in cases without regularization, the incorporation of the acyclicity constraint is essential for ensuring DAG recovery consistency; (ii) with suitable regularization, the DAG-constrained estimator achieves both parameter estimation and DAG reconstruction consistencies similar to the unconstrained counterpart, but significantly enhances empirical performance. Furthermore, simulation studies indicate that our proposed DAG-constrained estimator, when appropriately penalized, yields more accurate graphs compared to unconstrained or unregularized estimators. Finally, we apply the proposed method to two real MuTPP datasets.},
  archive      = {J_JMLR},
  author       = {Chunming Zhang and Muhong Gao and Shengji Jia},
  journal      = {Journal of Machine Learning Research},
  number       = {352},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {DAG-informed structure learning from multi-dimensional point processes},
  url          = {https://jmlr.org/papers/v25/24-0067.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing noise for f-differential privacy via
anti-concentration and stochastic dominance. <em>JMLR</em>,
<em>25</em>(351), 1–32. (<a
href="https://jmlr.org/papers/v25/23-1624.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we establish anti-concentration inequalities for additive noise mechanisms which achieve $f$-differential privacy ($f$-DP), a notion of privacy phrased in terms of a tradeoff function $f$ which limits the ability of an adversary to determine which individuals were in the database. We show that canonical noise distributions (CNDs), proposed by Awan and Vadhan (2023), match the anti-concentration bounds at half-integer values, indicating that their tail behavior is near-optimal. We also show that all CNDs are sub-exponential, regardless of the $f$-DP guarantee. In the case of log-concave CNDs, we show that they are the stochastically smallest noise compared to any other noise distributions with the same strong privacy guarantee. In terms of integer-valued noise, we propose a new notion of discrete CND and prove that a discrete CND always exists, can be constructed by rounding a continuous CND, and that the discrete CND is unique when designed for a statistic with sensitivity 1. We further show that the discrete CND at sensitivity 1 is stochastically smallest compared to other integer-valued noises. Our theoretical results shed light on the different types of privacy guarantees possible in the $f$-DP framework and can be incorporated in more complex mechanisms to optimize performance.},
  archive      = {J_JMLR},
  author       = {Jordan Awan and Aishwarya Ramasethu},
  journal      = {Journal of Machine Learning Research},
  number       = {351},
  pages        = {1-32},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimizing noise for f-differential privacy via anti-concentration and stochastic dominance},
  url          = {https://jmlr.org/papers/v25/23-1624.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A rainbow in deep network black boxes. <em>JMLR</em>,
<em>25</em>(350), 1–59. (<a
href="https://jmlr.org/papers/v25/23-1573.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A central question in deep learning is to understand the functions learned by deep networks. What is their approximation class? Do the learned weights and representations depend on initialization? Previous empirical work has evidenced that kernels defined by network activations are similar across initializations. For shallow networks, this has been theoretically studied with random feature models, but an extension to deep networks has remained elusive. Here, we provide a deep extension of such random feature models, which we call the rainbow model. We prove that rainbow networks define deterministic (hierarchical) kernels in the infinite-width limit. The resulting functions thus belong to a data-dependent RKHS which does not depend on the weight randomness. We also verify numerically our modeling assumptions on deep CNNs trained on image classification tasks, and show that the trained networks approximately satisfy the rainbow hypothesis. In particular, rainbow networks sampled from the corresponding random feature model achieve similar performance as the trained networks. Our results highlight the central role played by the covariances of network weights at each layer, which are observed to be low-rank as a result of feature learning.},
  archive      = {J_JMLR},
  author       = {Florentin Guth and Brice Ménard and Gaspar Rochette and Stéphane Mallat},
  journal      = {Journal of Machine Learning Research},
  number       = {350},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A rainbow in deep network black boxes},
  url          = {https://jmlr.org/papers/v25/23-1573.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How two-layer neural networks learn, one (giant) step at a
time. <em>JMLR</em>, <em>25</em>(349), 1–65. (<a
href="https://jmlr.org/papers/v25/23-1543.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For high-dimensional Gaussian data, we investigate theoretically how the features of a two-layer neural network adapt to the structure of the target function through a few large batch gradient descent steps, leading to an improvement in the approximation capacity with respect to the initialization. First, we compare the influence of batch size to that of multiple (but finitely many) steps. For a single gradient step, a batch of size $n = O(d)$ is both necessary and sufficient to align with the target function, although only a single direction can be learned. In contrast, $n = O(d^2)$ is essential for neurons to specialize in multiple relevant directions of the target with a single gradient step. Even in this case, we show there might exist “hard” directions requiring $n = O(d^\ell)$ samples to be learned, where $\ell$ is known as the leap index of the target. Second, we show that the picture drastically improves over multiple gradient steps: a batch size of $n = O(d)$ is indeed sufficient to learn multiple target directions satisfying a staircase property, where more and more directions can be learned over time. Finally, we discuss how these directions allow for a drastic improvement in the approximation capacity and generalization error over the initialization, illustrating a separation of scale between the random features/lazy regime and the feature learning regime. Our technical analysis leverages a combination of techniques related to concentration, projection-based conditioning, and Gaussian equivalence, which we believe are of independent interest. By pinning down the conditions necessary for specialization and learning, our results highlight the intertwined role of the structure of the task to learn, the detail of the algorithm (the batch size), and the architecture (i.e., the number of hidden neurons), shedding new light on how neural networks adapt to the feature and learn complex task from data over time.},
  archive      = {J_JMLR},
  author       = {Yatin Dandi and Florent Krzakala and Bruno Loureiro and Luca Pesce and Ludovic Stephan},
  journal      = {Journal of Machine Learning Research},
  number       = {349},
  pages        = {1-65},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {How two-layer neural networks learn, one (Giant) step at a time},
  url          = {https://jmlr.org/papers/v25/23-1543.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hamiltonian monte carlo for efficient gaussian sampling:
Long and random steps. <em>JMLR</em>, <em>25</em>(348), 1–30. (<a
href="https://jmlr.org/papers/v25/23-1521.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hamiltonian Monte Carlo (HMC) is a Markov chain algorithm for sampling from a high-dimensional distribution with density $e^{-f(x)}$, given access to the gradient of $f$. A particular case of interest is that of a $d$-dimensional Gaussian distribution with covariance matrix $\Sigma$, in which case $f(x) = x^\top \Sigma^{-1} x$. We show that Metropolis-adjusted HMC can sample from a distribution that is $\varepsilon$-close to a Gaussian in total variation distance using $\widetilde{O}(\sqrt{\kappa} d^{1/4} \log(1/\varepsilon))$ gradient queries, where $\varepsilon&gt;0$ and $\kappa$ is the condition number of $\Sigma$. Our algorithm uses long and random integration times for the Hamiltonian dynamics, and it creates a warm start by first running HMC without a Metropolis adjustment. This contrasts with (and was motivated by) recent results that give an $\widetilde\Omega(\kappa d^{1/2})$ query lower bound for HMC with a fixed integration times or from a cold start, even for the Gaussian case.},
  archive      = {J_JMLR},
  author       = {Simon Apers and Sander Gribling and Dániel Szilágyi},
  journal      = {Journal of Machine Learning Research},
  number       = {348},
  pages        = {1-30},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Hamiltonian monte carlo for efficient gaussian sampling: Long and random steps},
  url          = {https://jmlr.org/papers/v25/23-1521.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Memorization with neural nets: Going beyond the worst case.
<em>JMLR</em>, <em>25</em>(347), 1–38. (<a
href="https://jmlr.org/papers/v25/23-1376.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practice, deep neural networks are often able to easily interpolate their training data. To understand this phenomenon, many works have aimed to quantify the memorization capacity of a neural network architecture: the largest number of points such that the architecture can interpolate any placement of these points with any assignment of labels. For real-world data, however, one intuitively expects the presence of a benign structure so that interpolation already occurs at a smaller network size than suggested by memorization capacity. In this paper, we investigate interpolation by adopting an instance-specific viewpoint. We introduce a simple randomized algorithm that, given a fixed finite data set with two classes, with high probability constructs an interpolating three-layer neural network in polynomial time. The required number of parameters is linked to geometric properties of the two classes and their mutual arrangement. As a result, we obtain guarantees that are independent of the number of samples and hence move beyond worst-case memorization capacity bounds. We verify our theoretical result with numerical experiments and additionally investigate the effectiveness of the algorithm on MNIST and CIFAR-10.},
  archive      = {J_JMLR},
  author       = {Sjoerd Dirksen and Patrick Finke and Martin Genzel},
  journal      = {Journal of Machine Learning Research},
  number       = {347},
  pages        = {1-38},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Memorization with neural nets: Going beyond the worst case},
  url          = {https://jmlr.org/papers/v25/23-1376.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PROMISE: Preconditioned stochastic optimization methods by
incorporating scalable curvature estimates. <em>JMLR</em>,
<em>25</em>(346), 1–57. (<a
href="https://jmlr.org/papers/v25/23-1187.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ill-conditioned problems are ubiquitous in large-scale machine learning: as a data set grows to include more and more features correlated with the labels, the condition number increases. Yet traditional stochastic gradient methods converge slowly on these ill-conditioned problems, even with careful hyperparameter tuning. This paper introduces PROMISE (Preconditioned Stochastic Optimization Methods by Incorporating Scalable Curvature Estimates), a suite of sketching-based preconditioned stochastic gradient algorithms that deliver fast convergence on ill-conditioned large-scale convex optimization problems arising in machine learning. PROMISE includes preconditioned versions of SVRG, SAGA, and Katyusha; each algorithm comes with a strong theoretical analysis and effective default hyperparameter values. Empirically, we verify the superiority of the proposed algorithms by showing that, using default hyperparameter values, they outperform or match popular tuned stochastic gradient optimizers on a test bed of 51 ridge and logistic regression problems assembled from benchmark machine learning repositories. On the theoretical side, this paper introduces the notion of quadratic regularity in order to establish linear convergence of all proposed methods even when the preconditioner is updated infrequently. The speed of linear convergence is determined by the quadratic regularity ratio, which often provides a tighter bound on the convergence rate compared to the condition number, both in theory and in practice, and explains the fast global linear convergence of the proposed methods.},
  archive      = {J_JMLR},
  author       = {Zachary Frangella and Pratik Rathore and Shipu Zhao and Madeleine Udell},
  journal      = {Journal of Machine Learning Research},
  number       = {346},
  pages        = {1-57},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {PROMISE: Preconditioned stochastic optimization methods by incorporating scalable curvature estimates},
  url          = {https://jmlr.org/papers/v25/23-1187.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causal effects of intervening variables in settings with
unmeasured confounding. <em>JMLR</em>, <em>25</em>(345), 1–54. (<a
href="https://jmlr.org/papers/v25/23-1077.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present new results on average causal effects in settings with unmeasured exposure-outcome confounding. Our results are motivated by a class of estimands, e.g., frequently of interest in medicine and public health, that are currently not targeted by standard approaches for average causal effects. We recognize these estimands as queries about the average causal effect of an intervening variable. We anchor our introduction of these estimands in an investigation of the role of chronic pain and opioid prescription patterns, and illustrate how conventional approaches will lead to non-replicable estimates with ambiguous policy implications. We argue that our alternative effects are replicable and have clear policy implications, and furthermore are non-parametrically identified by the classical frontdoor formula. As an independent contribution, we derive a new semiparametric efficient estimator of the frontdoor formula with a uniform sample boundedness guarantee. This property is unique among previously-described estimators in its class, and we demonstrate superior performance in finite-sample settings. The theoretical results are applied to data from the National Health and Nutrition Examination Survey.},
  archive      = {J_JMLR},
  author       = {Lan Wen and Aaron Sarvet and Mats Stensrud},
  journal      = {Journal of Machine Learning Research},
  number       = {345},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Causal effects of intervening variables in settings with unmeasured confounding},
  url          = {https://jmlr.org/papers/v25/23-1077.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lower complexity adaptation for empirical entropic optimal
transport. <em>JMLR</em>, <em>25</em>(344), 1–55. (<a
href="https://jmlr.org/papers/v25/23-0856.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entropic optimal transport (EOT) presents an effective and computationally viable alternative to unregularized optimal transport (OT), offering diverse applications for large-scale data analysis. In this work, we derive novel statistical bounds for empirical plug-in estimators of the EOT cost and show that their statistical performance in the entropy regularization parameter $\varepsilon$ and the sample size $n$ only depends on the simpler of the two probability measures. For instance, under sufficiently smooth costs this yields the parametric rate $n^{-1/2}$ with factor $\varepsilon^{-d/2}$, where $d$ is the minimum dimension of the two population measures. This confirms that empirical EOT also adheres to the lower complexity adaptation principle, a hallmark feature only recently identified for unregularized OT. As a consequence of our theory, we show that the empirical entropic Gromov-Wasserstein distance and its unregularized version for measures on Euclidean spaces also obey this principle. Additionally, we comment on computational aspects and complement our findings with Monte Carlo simulations. Our technique employs empirical process theory and relies on a dual formulation of EOT over a single function class. Central to our analysis is the observation that the entropic cost-transformation of a function class does not increase its uniform metric entropy by much.},
  archive      = {J_JMLR},
  author       = {Michel Groppe and Shayan Hundrieser},
  journal      = {Journal of Machine Learning Research},
  number       = {344},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Lower complexity adaptation for empirical entropic optimal transport},
  url          = {https://jmlr.org/papers/v25/23-0856.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A note on entrywise consistency for mixed-data matrix
completion. <em>JMLR</em>, <em>25</em>(343), 1–66. (<a
href="https://jmlr.org/papers/v25/23-0834.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This note studies matrix completion for a partially observed $n$ by $p$ data matrix involving mixed types of variables (e.g., continuous, binary, ordinal). A general family of non-linear factor models is considered, under which the matrix completion problem becomes the estimation of an $n$ by $p$ low-rank matrix ${\mathbf M}$. For existing methods in the literature, estimation consistency is established by showing $\Vert \hat {\mathbf M} - {\mathbf M}^*\Vert_F/\sqrt{np}$, the scaled Frobenius norm of the difference between the estimated and true ${\mathbf M}$ matrices, converges to zero in probability as $n$ and $p$ grow to infinity. However, this notion of consistency does not guarantee the convergence of each individual entry and, thus, may not be sufficient when specific data entries or the worst-case scenario is of interest. To address this issue, we consider the notion of entrywise consistency based on $\Vert \hat {\mathbf M} - {\mathbf M}^* \Vert_{\mbox{max}}$, the max norm of the estimation error matrix. We propose refinement procedures that turn estimators, which are consistent in the Frobenius norm sense, into entrywise estimators through a one-step refinement. Tight probabilistic error bounds are derived for the proposed estimators. The proposed methods are evaluated by simulation studies and real-data applications for collaborative filtering and large-scale educational assessment.},
  archive      = {J_JMLR},
  author       = {Yunxiao Chen and Xiaoou Li},
  journal      = {Journal of Machine Learning Research},
  number       = {343},
  pages        = {1-66},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A note on entrywise consistency for mixed-data matrix completion},
  url          = {https://jmlr.org/papers/v25/23-0834.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A characterization of multioutput learnability.
<em>JMLR</em>, <em>25</em>(342), 1–54. (<a
href="https://jmlr.org/papers/v25/23-078.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of learning multioutput function classes in the batch and online settings. In both settings, we show that a multioutput function class is learnable if and only if each single-output restriction of the function class is learnable. This provides a complete characterization of the learnability of multilabel classification and multioutput regression in both batch and online settings. As an extension, we also consider multilabel learnability in the bandit feedback setting and show a similar characterization as in the full-feedback setting.},
  archive      = {J_JMLR},
  author       = {Vinod Raman and Unique Subedi and Ambuj Tewari},
  journal      = {Journal of Machine Learning Research},
  number       = {342},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A characterization of multioutput learnability},
  url          = {https://jmlr.org/papers/v25/23-078.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sample complexity of variance-reduced distributionally
robust q-learning. <em>JMLR</em>, <em>25</em>(341), 1–77. (<a
href="https://jmlr.org/papers/v25/23-0526.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic decision-making under distributional shifts is of fundamental interest in theory and applications of reinforcement learning: The distribution of the environment in which the data is collected can differ from that of the environment in which the model is deployed. This paper presents two novel model-free algorithms, namely the distributionally robust Q-learning and its variance-reduced counterpart, that can effectively learn a robust policy despite distributional shifts. These algorithms are designed to efficiently approximate the $q$-function of an infinite-horizon $\gamma$-discounted robust Markov decision process with Kullback-Leibler ambiguity set to an entry-wise $\epsilon$-degree of precision. Further, the variance-reduced distributionally robust Q-learning combines the synchronous Q-learning with variance-reduction techniques to enhance its performance. Consequently, we establish that it attains a minimax sample complexity upper bound of $\tilde O(|\mathbf{S}||\mathbf{A}|(1-\gamma)^{-4}\epsilon^{-2})$, where $\mathbf{S}$ and $\mathbf{A}$ denote the state and action spaces. This is the first complexity result that is independent of the ambiguity size $\delta$, thereby providing new complexity theoretic insights. Additionally, a series of numerical experiments confirm the theoretical findings and the efficiency of the algorithms in handling distributional shifts.},
  archive      = {J_JMLR},
  author       = {Shengbo Wang and Nian Si and Jose Blanchet and Zhengyuan Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {341},
  pages        = {1-77},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sample complexity of variance-reduced distributionally robust Q-learning},
  url          = {https://jmlr.org/papers/v25/23-0526.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lower bounds on the bayesian risk via information measures.
<em>JMLR</em>, <em>25</em>(340), 1–45. (<a
href="https://jmlr.org/papers/v25/23-0361.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on parameter estimation and introduces a new method for lower bounding the Bayesian risk. The method allows for the use of virtually any information measure, including R\&#39;enyi&#39;s $\alpha$, $\varphi$-divergences, and Sibson&#39;s $\alpha$-Mutual Information. The approach considers divergences as functionals of measures and exploits the duality between spaces of measures and spaces of functions. In particular, we show that one can lower bound the risk with any information measure by upper bounding its dual via Markov&#39;s inequality. We are thus able to provide estimator-independent impossibility results thanks to the Data-Processing Inequalities that divergences satisfy. The results are then applied to settings of interest involving both discrete and continuous parameters, including the “Hide-and-Seek” problem, and compared to the state-of-the-art techniques. An important observation is that the behaviour of the lower bound in the number of samples is influenced by the choice of the information measure. We leverage this by introducing a new divergence inspired by the “Hockey-Stick” divergence, which is demonstrated empirically to provide the largest lower bound across all considered settings. If the observations are subject to privatisation, stronger impossibility results can be obtained via Strong Data-Processing Inequalities. The paper also discusses some generalisations and alternative directions.},
  archive      = {J_JMLR},
  author       = {Amedeo Roberto Esposito and Adrien Vandenbroucque and Michael Gastpar},
  journal      = {Journal of Machine Learning Research},
  number       = {340},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Lower bounds on the bayesian risk via information measures},
  url          = {https://jmlr.org/papers/v25/23-0361.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian structural learning with parametric marginals for
count data: An application to microbiota systems. <em>JMLR</em>,
<em>25</em>(339), 1–26. (<a
href="https://jmlr.org/papers/v25/23-0056.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High dimensional and heterogeneous count data are collected in various applied fields. In this paper, we look closely at high-resolution sequencing data on the microbiome, which have enabled researchers to study the genomes of entire microbial communities. Revealing the underlying interactions between these communities is of vital importance to learn how microbes influence human health. To perform structural learning from multivariate count data such as these, we develop a novel Gaussian copula graphical model with two key elements. Firstly, we employ parametric regression to characterize the marginal distributions. This step is crucial for accommodating the impact of external covariates. Neglecting this adjustment could potentially introduce distortions in the inference of the underlying network of dependences. Secondly, we advance a Bayesian structure learning framework, based on a computationally efficient search algorithm that is suited to high dimensionality. The approach returns simultaneous inference of the marginal effects and of the dependence structure, including graph uncertainty estimates. A simulation study and a real data analysis of microbiome data highlight the applicability of the proposed approach at inferring networks from multivariate count data in general, and its relevance to microbiome analyses in particular. The proposed method is implemented in the R package BDgraph.},
  archive      = {J_JMLR},
  author       = {Veronica Vinciotti and Pariya Behrouzi and Reza Mohammadi},
  journal      = {Journal of Machine Learning Research},
  number       = {339},
  pages        = {1-26},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bayesian structural learning with parametric marginals for count data: An application to microbiota systems},
  url          = {https://jmlr.org/papers/v25/23-0056.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transfer learning with uncertainty quantification: Random
effect calibration of source to target (RECaST). <em>JMLR</em>,
<em>25</em>(338), 1–40. (<a
href="https://jmlr.org/papers/v25/22-1369.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning uses a data model, trained to make predictions or inferences on data from one population, to make reliable predictions or inferences on data from another population. Most existing transfer learning approaches are based on fine-tuning pre-trained neural network models, and fail to provide crucial uncertainty quantification. We develop a statistical framework for model predictions based on transfer learning, called RECaST. The primary mechanism is a Cauchy random effect that recalibrates a source model to a target population; we mathematically and empirically demonstrate the validity of our RECaST approach for transfer learning between linear models, in the sense that prediction sets will achieve their nominal stated coverage, and we numerically illustrate the method&#39;s robustness to asymptotic approximations for nonlinear models. Whereas many existing techniques are built on particular source models, RECaST is agnostic to the choice of source model, and does not require access to source data. For example, our RECaST transfer learning approach can be applied to a continuous or discrete data model with linear or logistic regression, deep neural network architectures, etc. Furthermore, RECaST provides uncertainty quantification for predictions, which is mostly absent in the literature. We examine our method&#39;s performance in a simulation study and in an application to real hospital data.},
  archive      = {J_JMLR},
  author       = {Jimmy Hickey and Jonathan P. Williams and Emily C. Hector},
  journal      = {Journal of Machine Learning Research},
  number       = {338},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Transfer learning with uncertainty quantification: Random effect calibration of source to target (RECaST)},
  url          = {https://jmlr.org/papers/v25/22-1369.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inference on high-dimensional single-index models with
streaming data. <em>JMLR</em>, <em>25</em>(337), 1–68. (<a
href="https://jmlr.org/papers/v25/22-1124.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional statistical methods are faced with new challenges due to streaming data. The major challenge is the rapidly growing volume and velocity of data, which makes storing such huge data sets in memory impossible. The paper presents an online inference framework for regression parameters in high-dimensional semiparametric single-index models with unknown link functions. The proposed online procedure updates only the current data batch and summary statistics of historical data instead of re-accessing the entire raw data set. At the same time, we do not need to estimate the unknown link function, which is a highly challenging task. In addition, a generalized convex loss function is used in the proposed inference procedure. To illustrate the proposed method, we use the Huber loss function and the negative log-likelihood of the logistic regression model. In this study, the asymptotic normality of the proposed online debiased Lasso estimators and the bounds of the proposed online Lasso estimators are investigated. To evaluate the performance of the proposed method, extensive simulation studies have been conducted. We provide applications to Nasdaq stock prices and financial distress data sets.},
  archive      = {J_JMLR},
  author       = {Dongxiao Han and Jinhan Xie and Jin Liu and Liuquan Sun and Jian Huang and Bei Jiang and Linglong Kong},
  journal      = {Journal of Machine Learning Research},
  number       = {337},
  pages        = {1-68},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Inference on high-dimensional single-index models with streaming data},
  url          = {https://jmlr.org/papers/v25/22-1124.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the convergence of projected alternating maximization for
equitable and optimal transport. <em>JMLR</em>, <em>25</em>(336), 1–33.
(<a href="https://jmlr.org/papers/v25/22-0524.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the equitable and optimal transport (EOT) problem, which has many applications such as fair division problems and optimal transport with multiple agents etc. In the discrete distributions case, the EOT problem can be formulated as a linear program (LP). Since this LP is prohibitively large for general LP solvers, (Scetbon et al., 2021) suggests to perturb the problem by adding an entropy regularization. They proposed a projected alternating maximization algorithm (PAM) to solve the dual of the entropy regularized EOT. In this paper, we provide the first convergence analysis of PAM. A novel rounding procedure is proposed to help construct the primal solution for the original EOT problem. We also propose a variant of PAM by incorporating the extrapolation technique that can numerically improve the performance of PAM. Results in this paper may shed lights on block coordinate (gradient) descent methods for general optimization problems.},
  archive      = {J_JMLR},
  author       = {Minhui Huang and Shiqian Ma and Lifeng Lai},
  journal      = {Journal of Machine Learning Research},
  number       = {336},
  pages        = {1-33},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the convergence of projected alternating maximization for equitable and optimal transport},
  url          = {https://jmlr.org/papers/v25/22-0524.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ENNS: Variable selection, regression, classification, and
deep neural network for high-dimensional data. <em>JMLR</em>,
<em>25</em>(335), 1–45. (<a
href="https://jmlr.org/papers/v25/21-0893.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional, low-sample-size (HDLSS) data have been attracting people&#39;s attention for a long time. Many studies have proposed different approaches to dealing with this situation, among which variable selection is a significant idea. However, neural networks have been used to model complicated relationships. This paper discusses current variable selection techniques with neural networks. We showed that the stage-wise algorithm with the neural network suffers from some disadvantages, such as that the variables entering the model later may not be consistent. We also proposed an ensemble method to achieve better variable selection and proved that it has a probability tending to zero that a false variable will be selected. Moreover, we discussed further regularization to deal with over-fitting. Simulations and examples of real data are given to support the theory.},
  archive      = {J_JMLR},
  author       = {Kaixu Yang and Arkaprabha Ganguli and Tapabrata Maiti},
  journal      = {Journal of Machine Learning Research},
  number       = {335},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {ENNS: Variable selection, regression, classification, and deep neural network for high-dimensional data},
  url          = {https://jmlr.org/papers/v25/21-0893.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the optimality of gaussian kernel based nonparametric
tests against smooth alternatives. <em>JMLR</em>, <em>25</em>(334),
1–62. (<a href="https://jmlr.org/papers/v25/20-1228.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparametric tests via kernel embedding of distributions have witnessed a great deal of practical successes in recent years. However, statistical properties of these tests are largely unknown beyond consistency against a fixed alternative. To fill in this void, we study here the asymptotic properties of goodness-of-fit, homogeneity and independence tests using Gaussian kernels, arguably the most popular and successful among such tests. Our results provide theoretical justifications for this common practice by showing that tests using a Gaussian kernel with an appropriately chosen scaling parameter are minimax optimal against smooth alternatives in all three settings. In addition, our analysis also pinpoints the importance of choosing a diverging scaling parameter when using Gaussian kernels and suggests a data-driven choice of the scaling parameter that yields tests optimal, up to an iterated logarithmic factor, over a wide range of smooth alternatives. Numerical experiments are also presented to further demonstrate the practical merits of the methodology.},
  archive      = {J_JMLR},
  author       = {Tong Li and Ming Yuan},
  journal      = {Journal of Machine Learning Research},
  number       = {334},
  pages        = {1-62},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the optimality of gaussian kernel based nonparametric tests against smooth alternatives},
  url          = {https://jmlr.org/papers/v25/20-1228.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Open-source conversational AI with SpeechBrain 1.0.
<em>JMLR</em>, <em>25</em>(333), 1–11. (<a
href="https://jmlr.org/papers/v25/24-0991.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SpeechBrain is an open-source Conversational AI toolkit based on PyTorch, focused particularly on speech processing tasks such as speech recognition, speech enhancement, speaker recognition, text-to-speech, and much more. It promotes transparency and replicability by releasing both the pre-trained models and the complete recipes of code and algorithms required for training them. This paper presents SpeechBrain 1.0, a significant milestone in the evolution of the toolkit, which now has over 200 recipes for speech, audio, and language processing tasks, and more than 100 models available on Hugging Face. SpeechBrain 1.0 introduces new technologies to support diverse learning modalities, Large Language Model (LLM) integration, and advanced decoding strategies, along with novel models, tasks, and modalities. It also includes a new benchmark repository, offering researchers a unified platform for evaluating models across diverse tasks.},
  archive      = {J_JMLR},
  author       = {Mirco Ravanelli and Titouan Parcollet and Adel Moumen and Sylvain de Langen and Cem Subakan and Peter Plantinga and Yingzhi Wang and Pooneh Mousavi and Luca Della Libera and Artem Ploujnikov and Francesco Paissan and Davide Borra and Salah Zaiem and Zeyu Zhao and Shucong Zhang and Georgios Karakasidis and Sung-Lin Yeh and Pierre Champion and Aku Rouhe and Rudolf Braun and Florian Mai and Juan Zuluaga-Gomez and Seyed Mahed Mousavi and Andreas Nautsch and Ha Nguyen and Xuechen Liu and Sangeet Sagar and Jarod Duret and Salima Mdhaffar and Gaëlle Laperrière and Mickael Rouvier and Renato De Mori and Yannick Estève},
  journal      = {Journal of Machine Learning Research},
  number       = {333},
  pages        = {1-11},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Open-source conversational AI with SpeechBrain 1.0},
  url          = {https://jmlr.org/papers/v25/24-0991.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Triple component matrix factorization: Untangling global,
local, and noisy components. <em>JMLR</em>, <em>25</em>(332), 1–76. (<a
href="https://jmlr.org/papers/v25/24-0400.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the problem of common and unique feature extraction from noisy data. When we have $N$ observation matrices from $N$ different and associated sources corrupted by sparse and potentially gross noise, can we recover the common and unique components from these noisy observations? This is a challenging task as the number of parameters to estimate is approximately thrice the number of observations. Despite the difficulty, we propose an intuitive alternating minimization algorithm called triple component matrix factorization (TCMF) to recover the three components exactly. TCMF is distinguished from existing works in literature thanks to two salient features. First, TCMF is a principled method to separate the three components given noisy observations provably. Second, the bulk of the computation in TCMF can be distributed. On the technical side, we formulate the problem as a constrained nonconvex nonsmooth optimization problem. Despite the intricate nature of the problem, we provide a Taylor series characterization of its solution by solving the corresponding Karush–Kuhn–Tucker conditions. Using this characterization, we can show that the alternating minimization algorithm makes significant progress at each iteration and converges into the ground truth at a linear rate. Numerical experiments in video segmentation and anomaly detection highlight the superior feature extraction abilities of TCMF.},
  archive      = {J_JMLR},
  author       = {Naichen Shi and Salar Fattahi and Raed Al Kontar},
  journal      = {Journal of Machine Learning Research},
  number       = {332},
  pages        = {1-76},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Triple component matrix factorization: Untangling global, local, and noisy components},
  url          = {https://jmlr.org/papers/v25/24-0400.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalization on the unseen, logic reasoning and degree
curriculum. <em>JMLR</em>, <em>25</em>(331), 1–58. (<a
href="https://jmlr.org/papers/v25/24-0220.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the learning of logical (Boolean) functions with a focus on the generalization on the unseen (GOTU) setting, a strong case of out-of-distribution generalization. This is motivated by the fact that the rich combinatorial nature of data in certain reasoning tasks (e.g., arithmetic/logic) makes representative data sampling challenging, and learning successfully under GOTU gives a first vignette of an &#39;extrapolating&#39; or &#39;reasoning&#39; learner. We study how different network architectures trained by (S)GD perform under GOTU and provide both theoretical and experimental evidence that for sparse functions and a class of network models including instances of Transformers, random features models, and linear networks, a min-degree-interpolator is learned on the unseen. More specifically, this means an interpolator of the training data that has minimal Fourier mass on the higher degree basis elements. These findings lead to two implications: (1) we provide an explanation to the length generalization problem for Boolean functions (e.g., Anil et al. 2022); (2) we introduce a curriculum learning algorithm called Degree-Curriculum that learns monomials more efficiently by incrementing supports. Finally, we discuss extensions to other models or non-sparse regimes where the min-degree bias may still occur or fade, as well as how it can be potentially corrected when undesirable.},
  archive      = {J_JMLR},
  author       = {Emmanuel Abbe and Samy Bengio and Aryo Lotfi and Kevin Rizk},
  journal      = {Journal of Machine Learning Research},
  number       = {331},
  pages        = {1-58},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Generalization on the unseen, logic reasoning and degree curriculum},
  url          = {https://jmlr.org/papers/v25/24-0220.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Goal-space planning with subgoal models. <em>JMLR</em>,
<em>25</em>(330), 1–57. (<a
href="https://jmlr.org/papers/v25/24-0040.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a new approach to model-based reinforcement learning using background planning: mixing (approximate) dynamic programming updates and model-free updates, similar to the Dyna architecture. Background planning with learned models is often worse than model-free alternatives, such as Double DQN, even though the former uses significantly more memory and computation. The fundamental problem is that learned models can be inaccurate and often generate invalid states, especially when iterated many steps. In this paper, we avoid this limitation by constraining background planning to a given set of (abstract) subgoals and learning only local, subgoal-conditioned models. This goal-space planning (GSP) approach is more computationally efficient, naturally incorporates temporal abstraction for faster long-horizon planning, and avoids learning the transition dynamics entirely. We show that our GSP algorithm can propagate value from an abstract space in a manner that helps a variety of base learners learn significantly faster in different domains.},
  archive      = {J_JMLR},
  author       = {Chunlok Lo and Kevin Roice and Parham Mohammad Panahi and Scott M. Jordan and Adam White and Gabor Mihucz and Farzane Aminmansour and Martha White},
  journal      = {Journal of Machine Learning Research},
  number       = {330},
  pages        = {1-57},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Goal-space planning with subgoal models},
  url          = {https://jmlr.org/papers/v25/24-0040.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Homeomorphic projection to ensure neural-network solution
feasibility for constrained optimization. <em>JMLR</em>,
<em>25</em>(329), 1–55. (<a
href="https://jmlr.org/papers/v25/23-1577.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been growing interest in employing neural networks (NNs) to directly solve constrained optimization problems with low run-time complexity. However, it is non-trivial to ensure NN solutions strictly satisfy problem constraints due to inherent NN prediction errors. Existing feasibility-ensuring methods are either computationally expensive or lack performance guarantee. In this paper, we propose Homeomorphic Projection as a low-complexity scheme to guarantee NN solution feasibility for optimization over a general set homeomorphic to a unit ball, covering all compact convex sets and certain classes of non-convex sets. The idea is to (i) learn a minimum distortion homeomorphic mapping between the constraint set and a unit ball using a bi-Lipschitz invertible NN (INN), and then (ii) perform a simple bisection operation concerning the unit ball such that the INN-mapped final solution is feasible with respect to the constraint set with minor distortion-induced optimality loss. We prove the feasibility guarantee and bounded optimality loss under mild conditions. Simulation results, including those for non-convex AC-OPF problems in power grid operation, show that homeomorphic projection outperforms existing methods in solution feasibility and run-time complexity while achieving similar optimality loss.},
  archive      = {J_JMLR},
  author       = {Enming Liang and Minghua Chen and Steven H. Low},
  journal      = {Journal of Machine Learning Research},
  number       = {329},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Homeomorphic projection to ensure neural-network solution feasibility for constrained optimization},
  url          = {https://jmlr.org/papers/v25/23-1577.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label noise robustness of conformal prediction.
<em>JMLR</em>, <em>25</em>(328), 1–66. (<a
href="https://jmlr.org/papers/v25/23-1549.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the robustness of conformal prediction, a powerful tool for uncertainty quantification, to label noise. Our analysis tackles both regression and classification problems, characterizing when and how it is possible to construct uncertainty sets that correctly cover the unobserved noiseless ground truth labels. We further extend our theory and formulate the requirements for correctly controlling a general loss function, such as the false negative proportion, with noisy labels. Our theory and experiments suggest that conformal prediction and risk-controlling techniques with noisy labels attain conservative risk over the clean ground truth labels whenever the noise is dispersive and increases variability. In other adversarial cases, we can also correct for noise of bounded size in the conformal prediction algorithm in order to ensure achieving the correct risk of the ground truth labels without score or data regularity.},
  archive      = {J_JMLR},
  author       = {Bat-Sheva Einbinder and Shai Feldman and Stephen Bates and Anastasios N. Angelopoulos and Asaf Gendler and Yaniv Romano},
  journal      = {Journal of Machine Learning Research},
  number       = {328},
  pages        = {1-66},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Label noise robustness of conformal prediction},
  url          = {https://jmlr.org/papers/v25/23-1549.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PAPAL: A provable PArticle-based primal-dual ALgorithm for
mixed nash equilibrium. <em>JMLR</em>, <em>25</em>(327), 1–48. (<a
href="https://jmlr.org/papers/v25/23-1522.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the non-convex non-concave objective function in two-player zero-sum continuous games. The existence of pure Nash equilibrium requires stringent conditions, posing a major challenge for this problem. To circumvent this difficulty, we examine the problem of identifying a mixed Nash equilibrium, where strategies are randomized and characterized by probability distributions over continuous domains. To this end, we propose PArticle-based Primal-dual ALgorithm (PAPAL) tailored for a weakly entropy-regularized min-max optimization over probability distributions. This algorithm employs the stochastic movements of particles to represent the updates of random strategies for the $\epsilon$-mixed Nash equilibrium. We offer a comprehensive convergence analysis of the proposed algorithm, demonstrating its effectiveness. In contrast to prior research that attempted to update particle importance without movements, PAPAL is the first implementable particle-based algorithm accompanied by non-asymptotic quantitative convergence results, running time, and sample complexity guarantees. Our framework contributes novel insights into the particle-based algorithms for continuous min-max optimization in the general non-convex non-concave setting.},
  archive      = {J_JMLR},
  author       = {Shihong Ding and Hanze Dong and Cong Fang and Zhouchen Lin and Tong Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {327},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {PAPAL: A provable PArticle-based primal-dual ALgorithm for mixed nash equilibrium},
  url          = {https://jmlr.org/papers/v25/23-1522.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Geometric learning with positively decomposable kernels.
<em>JMLR</em>, <em>25</em>(326), 1–42. (<a
href="https://jmlr.org/papers/v25/23-1400.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel methods are powerful tools in machine learning. Classical kernel methods are based on positive definite kernels, which enable learning in reproducing kernel Hilbert spaces (RKHS). For non-Euclidean data spaces, positive definite kernels are difficult to come by. In this case, we propose the use of reproducing kernel Krein space (RKKS) based methods, which require only kernels that admit a positive decomposition. We show that one does not need to access this decomposition to learn in RKKS. We then investigate the conditions under which a kernel is positively decomposable. We show that invariant kernels admit a positive decomposition on homogeneous spaces under tractable regularity assumptions. This makes them much easier to construct than positive definite kernels, providing a route for learning with kernels for non-Euclidean data. By the same token, this provides theoretical foundations for RKKS-based methods in general.},
  archive      = {J_JMLR},
  author       = {Nathael Da Costa and Cyrus Mostajeran and Juan-Pablo Ortega and Salem Said},
  journal      = {Journal of Machine Learning Research},
  number       = {326},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Geometric learning with positively decomposable kernels},
  url          = {https://jmlr.org/papers/v25/23-1400.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mentored learning: Improving generalization and convergence
of student learner. <em>JMLR</em>, <em>25</em>(325), 1–45. (<a
href="https://jmlr.org/papers/v25/23-1213.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Student learners typically engage in an iterative process of actively updating its hypotheses, like active learning. While this behavior can be advantageous, there is an inherent risk of introducing mistakes through incremental updates including weak initialization, inaccurate or insignificant history states, resulting in expensive convergence cost. In this work, rather than solely monitoring the update of the learner&#39;s status, we propose monitoring the disagreement w.r.t. $\mathcal{F}^\mathcal{T}(\cdot)$ between the learner and teacher, and call this new paradigm “Mentored Learning”, which consists of `how to teach&#39; and `how to learn&#39;. By actively incorporating feedback that deviates from the learner&#39;s current hypotheses, convergence will be much easier to analyze without strict assumptions on learner&#39;s historical status, then deriving tighter generalization bounds on error and label complexity. Formally, we introduce an approximately optimal teaching hypothesis, $h^\mathcal{T}$, incorporating a tighter slack term $\left(1+\mathcal{F}^{\mathcal{T}}(\widehat{h}_t)\right)\Delta_t$ to replace the typical $2\Delta_t$ used in hypothesis pruning. Theoretically, we demonstrate that, guided by this teaching hypothesis, the learner can converge to tighter generalization bounds on error and label complexity compared to non-educated learners who lack guidance from a teacher: 1) the generalization error upper bound can be reduced from $R(h^*)+4\Delta_{T-1}$ to approximately $R(h^{\mathcal{T}})+2\Delta_{T-1}$, and 2) the label complexity upper bound can be decreased from $4 \theta\left(TR(h^{*})+2O(\sqrt{T})\right)$ to approximately $2\theta\left(2TR(h^{\mathcal{T}})+3 O(\sqrt{T})\right)$. To adhere strictly to our assumption, self-improvement of teaching is proposed when $h^\mathcal{T}$ loosely approximates $h^*$. In the context of learning, we further consider two teaching scenarios: instructing a white-box and black-box learner. Experiments validate this teaching concept and demonstrate superior generalization performance compared to fundamental active learning strategies, such as IWAL, IWAL-D, etc.},
  archive      = {J_JMLR},
  author       = {Xiaofeng Cao and Yaming Guo and Heng Tao Shen and Ivor W. Tsang and James T. Kwok},
  journal      = {Journal of Machine Learning Research},
  number       = {325},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Mentored learning: Improving generalization and convergence of student learner},
  url          = {https://jmlr.org/papers/v25/23-1213.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust principal component analysis using density power
divergence. <em>JMLR</em>, <em>25</em>(324), 1–40. (<a
href="https://jmlr.org/papers/v25/23-1096.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Principal component analysis (PCA) is a widely employed statistical tool used primarily for dimensionality reduction. However, it is known to be adversely affected by the presence of outlying observations in the sample, which is quite common. Robust PCA methods using M-estimators have theoretical benefits, but their robustness drop substantially for high dimensional data. On the other end of the spectrum, robust PCA algorithms solving principal component pursuit or similar optimization problems have high breakdown, but lack theoretical richness and demand high computational power compared to the M-estimators. We introduce a novel robust PCA estimator based on the minimum density power divergence estimator. This combines the theoretical strength of the M-estimators and the minimum divergence estimators with a high breakdown guarantee regardless of data dimension. We present a computationally efficient algorithm for this estimate. Our theoretical findings are supported by extensive simulations and comparisons with existing robust PCA methods. We also showcase the proposed algorithm&#39;s applicability on two benchmark data sets and a credit card transactions data set for fraud detection.},
  archive      = {J_JMLR},
  author       = {Subhrajyoty Roy and Ayanendranath Basu and Abhik Ghosh},
  journal      = {Journal of Machine Learning Research},
  number       = {324},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Robust principal component analysis using density power divergence},
  url          = {https://jmlr.org/papers/v25/23-1096.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graphical dirichlet process for clustering non-exchangeable
grouped data. <em>JMLR</em>, <em>25</em>(323), 1–56. (<a
href="https://jmlr.org/papers/v25/23-1048.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of clustering grouped data with possibly non-exchangeable groups whose dependencies can be characterized by a known directed acyclic graph. To allow the sharing of clusters among the non-exchangeable groups, we propose a Bayesian nonparametric approach, termed graphical Dirichlet process, that jointly models the dependent group-specific random measures by assuming each random measure to be distributed as a Dirichlet process whose concentration parameter and base probability measure depend on those of its parent groups. The resulting joint stochastic process respects the Markov property of the directed acyclic graph that links the groups. We characterize the graphical Dirichlet process using a novel hypergraph representation as well as the stick-breaking representation, the restaurant-type representation, and the representation as a limit of a finite mixture model. We develop an efficient posterior inference algorithm and illustrate our model with simulations and a real grouped single-cell data set.},
  archive      = {J_JMLR},
  author       = {Arhit Chakrabarti and Yang Ni and Ellen Ruth A. Morris and Michael L. Salinas and Robert S. Chapkin and Bani K. Mallick},
  journal      = {Journal of Machine Learning Research},
  number       = {323},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Graphical dirichlet process for clustering non-exchangeable grouped data},
  url          = {https://jmlr.org/papers/v25/23-1048.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stability and l2-penalty in model averaging. <em>JMLR</em>,
<em>25</em>(322), 1–59. (<a
href="https://jmlr.org/papers/v25/23-0853.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model averaging has received much attention in the past two decades, which integrates available information by averaging over potential models. Although various model averaging methods have been developed, there is little literature on the theoretical properties of model averaging from the perspective of stability, and the majority of these methods constrain model weights to a simplex. The aim of this paper is to introduce stability from statistical learning theory into model averaging. Thus, we define the stability, asymptotic empirical risk minimization, generalization and consistency of model averaging, and study the relationship among them. Similar to the existing results in literature, we find that stability can ensure that the model averaging estimator has good generalization performance and consistency under reasonable conditions, where consistency means that the model averaging estimator can asymptotically minimize the mean squared prediction error. We also propose an $L_2$-penalty model averaging method without limiting model weights, and prove that it has stability and consistency. In order to overcome selection uncertainty of the $L_2$-penalty parameter, we use cross-validation to select a candidate set of $L_2$-penalty parameters, and then perform a weighted average of the estimators of model weights based on cross-validation errors. We demonstrate the usefulness of the proposed method with a Monte Carlo simulation and application to a prediction task on the wage1 dataset.},
  archive      = {J_JMLR},
  author       = {Hengkun Zhu and Guohua Zou},
  journal      = {Journal of Machine Learning Research},
  number       = {322},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Stability and l2-penalty in model averaging},
  url          = {https://jmlr.org/papers/v25/23-0853.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural networks with sparse activation induced by large
bias: Tighter analysis with bias-generalized NTK. <em>JMLR</em>,
<em>25</em>(321), 1–51. (<a
href="https://jmlr.org/papers/v25/23-0831.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study training one-hidden-layer ReLU networks in the neural tangent kernel (NTK) regime, where the networks&#39; biases are initialized to some constant rather than zero. We prove that under such initialization, the neural network will have sparse activation throughout the entire training process, which enables fast training procedures via some sophisticated computational methods. With such initialization, we show that the neural networks possess a different limiting kernel which we call bias-generalized NTK, and we study various properties of the neural networks with this new kernel. We first characterize the gradient descent dynamics. In particular, we show that the network in this case can achieve as fast convergence as the dense network, as opposed to the previous work suggesting that the sparse networks converge slower. In addition, our result improves the previous required width to ensure convergence. Secondly, we study the networks&#39; generalization: we show a width-sparsity dependence, which yields a sparsity-dependent Rademacher complexity and generalization bound. To our knowledge, this is the first sparsity-dependent generalization result via Rademacher complexity. Lastly, we study the smallest eigenvalue of this new kernel. We identify a data-dependent region where we can derive a much sharper lower bound on the NTK&#39;s smallest eigenvalue than the worst-case bound previously known. This can lead to improvement in the generalization bound.},
  archive      = {J_JMLR},
  author       = {Hongru Yang and Ziyu Jiang and Ruizhe Zhang and Yingbin Liang and Zhangyang Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {321},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Neural networks with sparse activation induced by large bias: Tighter analysis with bias-generalized NTK},
  url          = {https://jmlr.org/papers/v25/23-0831.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal weighted random forests. <em>JMLR</em>,
<em>25</em>(320), 1–81. (<a
href="https://jmlr.org/papers/v25/23-0607.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random forest (RF) algorithm has become a very popular prediction method for its great flexibility and promising accuracy. In RF, it is conventional to put equal weights on all the base learners (trees) to aggregate their predictions. However, the predictive performance of different trees within the forest can vary significantly due to the randomization of the embedded bootstrap sampling and feature selection. In this paper, we focus on RF for regression and propose two optimal weighting algorithms, namely the 1 Step Optimal Weighted RF (1step-WRF$_\mathrm{opt}$) and 2 Steps Optimal Weighted RF (2steps-WRF$_\mathrm{opt}$), that combine the base learners through the weights determined by weight choice criteria. Under some regularity conditions, we show that these algorithms are asymptotically optimal in the sense that the resulting squared loss and risk are asymptotically identical to those of the infeasible but best possible weighted RF. Numerical studies conducted on real-world data sets and semi-synthetic data sets indicate that these algorithms outperform the equal-weight forest and two other weighted RFs proposed in the existing literature in most cases.},
  archive      = {J_JMLR},
  author       = {Xinyu Chen and Dalei Yu and Xinyu Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {320},
  pages        = {1-81},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal weighted random forests},
  url          = {https://jmlr.org/papers/v25/23-0607.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient active manifold identification via accelerated
iteratively reweighted nuclear norm minimization. <em>JMLR</em>,
<em>25</em>(319), 1–44. (<a
href="https://jmlr.org/papers/v25/23-0449.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of minimizing the sum of a smooth function and the Schatten-$p$ norm of the matrix. Our contribution involves proposing accelerated iteratively reweighted nuclear norm methods designed to solve the nonconvex low-rank minimization problem. Two major novelties characterize our approach. First, the proposed method possesses an active manifold identification property, enabling the provable identification of the correct rank of the stationary point within a finite number of iterations. Second, we introduce an adaptive updating strategy for smoothing parameters. This strategy automatically fixes parameters associated with zero singular values as constants upon detecting the correct rank while quickly driving the remaining parameters to zero. This adaptive behavior transforms the algorithm into one that effectively solves smooth problems after a few iterations, setting our work apart from existing iteratively reweighted methods for low-rank optimization. We prove the global convergence of the proposed algorithm, guaranteeing that every limit point of the iterates is a critical point. Furthermore, a local convergence rate analysis is provided under the Kurdyka-Łojasiewicz property. We conduct numerical experiments using both synthetic and real data to showcase our algorithm&#39;s efficiency and superiority over existing methods.},
  archive      = {J_JMLR},
  author       = {Hao Wang and Ye Wang and Xiangyu Yang},
  journal      = {Journal of Machine Learning Research},
  number       = {319},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Efficient active manifold identification via accelerated iteratively reweighted nuclear norm minimization},
  url          = {https://jmlr.org/papers/v25/23-0449.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Empirical design in reinforcement learning. <em>JMLR</em>,
<em>25</em>(318), 1–63. (<a
href="https://jmlr.org/papers/v25/23-0183.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empirical design in reinforcement learning is no small task. Running good experiments requires attention to detail and at times significant computational resources. While compute resources available per dollar have continued to grow rapidly, so have the scale of typical experiments in reinforcement learning. It is now common to benchmark agents with millions of parameters against dozens of tasks, each using the equivalent of 30 days of experience. The scale of these experiments often conflict with the need for statistical evidence, especially when comparing algorithms. Recent studies have highlighted how popular algorithms are sensitive to hyperparameter settings and implementation details, and that common empirical practice leads to weak statistical evidence (Machado et al., 2018; Henderson et al., 2018). This manuscript represents both a call to action, and a comprehensive resource for how to do good experiments in reinforcement learning. In particular, we cover: the statistical assumptions underlying common performance measures, how to properly characterize performance variation and stability, hypothesis testing, special considerations for comparing multiple agents, baseline and illustrative example construction, and how to deal with hyperparameters and experimenter bias. Throughout we highlight common mistakes found in the literature and the statistical consequences of those in example experiments. The objective of this document is to provide answers on how we can use our unprecedented compute to do good science in reinforcement learning, as well as stay alert to potential pitfalls in our empirical design.},
  archive      = {J_JMLR},
  author       = {Andrew Patterson and Samuel Neumann and Martha White and Adam White},
  journal      = {Journal of Machine Learning Research},
  number       = {318},
  pages        = {1-63},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Empirical design in reinforcement learning},
  url          = {https://jmlr.org/papers/v25/23-0183.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A data-adaptive RKHS prior for bayesian learning of kernels
in operators. <em>JMLR</em>, <em>25</em>(317), 1–37. (<a
href="https://jmlr.org/papers/v25/22-1491.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernels effectively represent nonlocal dependencies and are extensively employed in formu- lating operators between function spaces. Thus, learning kernels in operators from data is an inverse problem of general interest. Due to the nonlocal dependence, the inverse prob- lem is often severely ill-posed with a data-dependent normal operator. Traditional Bayesian methods address the ill-posedness by a non-degenerate prior, which may result in an unsta- ble posterior mean in the small noise regime, especially when data induces a perturbation in the null space of the normal operator. We propose a new data-adaptive Reproducing Kernel Hilbert Space (RKHS) prior, which ensures the stability of the posterior mean in the small noise regime. We analyze this adaptive prior and showcase its efficacy through applications on Toeplitz matrices and integral operators. Numerical experiments reveal that fixed non-degenerate priors can produce divergent posterior means under errors from discretization, model inaccuracies, partial observations, or erroneous noise assumptions. In contrast, our data-adaptive RKHS prior consistently yields convergent posterior means.},
  archive      = {J_JMLR},
  author       = {Neil K. Chada and Quanjun Lang and Fei Lu and Xiong Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {317},
  pages        = {1-37},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A data-adaptive RKHS prior for bayesian learning of kernels in operators},
  url          = {https://jmlr.org/papers/v25/22-1491.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GGD: Grafting gradient descent. <em>JMLR</em>,
<em>25</em>(316), 1–87. (<a
href="https://jmlr.org/papers/v25/22-1236.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simple random sampling has been widely used in traditional stochastic optimization algorithms. Although the gradient sampled by simple random sampling is a descent direction in expectation, it may have a relatively high variance which will cause the descent curve wiggling and slow down the optimization process. In this paper, we propose a novel stochastic optimization method called grafting gradient descent (GGD), which combines the strength from minibatching and importance sampling, and provide the convergence results of GGD. We show that the grafting gradient possesses a doubly robust property which ensures that the performance of GGD method is superior to the worse one of SGD with importance sampling method and mini-batch SGD method. Combined with advanced variance reduction techniques such as stochastic variance reduced gradient and adaptive stepsize methods such as Adam, these composite GGD-based methods and their theoretical bounds are provided. The real data studies also show that GGD achieves an intermediate performance among SGD with importance sampling and mini-batch SGD, and outperforms original SGD method. Then the proposed GGD is a better and more robust stochastic optimization framework in practice.},
  archive      = {J_JMLR},
  author       = {Yanjing Feng and Yongdao Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {316},
  pages        = {1-87},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {GGD: Grafting gradient descent},
  url          = {https://jmlr.org/papers/v25/22-1236.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Debiasing evaluations that are biased by evaluations.
<em>JMLR</em>, <em>25</em>(315), 1–120. (<a
href="https://jmlr.org/papers/v25/22-0775.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is common to evaluate a set of items by soliciting people to rate them. For example, universities ask students to rate the teaching quality of their instructors, and conference organizers ask authors of submissions to evaluate the quality of the reviews. However, in these applications, students often give a higher rating to a course if they receive higher grades in a course, and authors often give a higher rating to the reviews if their papers are accepted to the conference. In this work, we call these external factors the &quot;outcome&quot; experienced by people, and consider the problem of mitigating these outcome-induced biases in the given ratings when some information about the outcome is available. We formulate the information about the outcome as a known partial ordering on the bias. We propose a debiasing method by solving a regularized optimization problem under this ordering constraint, and also provide a carefully designed cross-validation method that adaptively chooses the appropriate amount of regularization. We provide theoretical guarantees on the performance of our algorithm, as well as experimental evaluations.},
  archive      = {J_JMLR},
  author       = {Jingyan Wang and Ivan Stelmakh and Yuting Wei and Nihar Shah},
  journal      = {Journal of Machine Learning Research},
  number       = {315},
  pages        = {1-120},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Debiasing evaluations that are biased by evaluations},
  url          = {https://jmlr.org/papers/v25/22-0775.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal learning policies for differential privacy in
multi-armed bandits. <em>JMLR</em>, <em>25</em>(314), 1–52. (<a
href="https://jmlr.org/papers/v25/21-1267.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the multi-armed bandit problem with a requirement of differential privacy guarantee or global differential privacy guarantee. We first prove that, the lower bound for the extra regret to protect $(\epsilon,\delta)$-global differential privacy is $\Omega({N\over \epsilon }\log {(e^{\epsilon} -1)T + \delta T \over (e^{\epsilon}-1) + \delta T})$ ($N$ is the number of arms and $T$ is the time horizon), which is independent with $T$ for $\delta &gt; 0$ and large enough $T$. Moreover, the lower bound for the extra regret to protect $(\epsilon,\delta)$-differential privacy can be no more than the above bound. This means that, different with the case $\delta = 0$, it is possible to design algorithms that protect privacy and achieve the same asymptotical regret upper bound as the non-private algorithms when $\delta &gt; 0$. Then we adapt the Follow the Perturbed Leader (FTPL) framework, and propose learning policies with both Gaussian and Beta perturbed distributions (DP-FTPL-Gauss and DP-FTPL-Beta) to protect $(\epsilon,\delta)$-differential privacy. The analysis shows that they achieve an $O({N\log T\over \Delta_{\min}} + N \min\{{1\over \delta^2}, {1\over \epsilon^2}\log{1\over \delta}\})$ regret upper bound, where $\Delta_{\min}$ is the minimum expected reward gap between the optimal arm and any other ones. We also design a unique perturbed distribution to protect $(\epsilon,\delta)$-differential privacy in the FTPL framework (DP-FTPL-New), which reduces the regret upper bound to $O({N\log T\over \Delta_{\min}} + {N\over \epsilon }\log {(e^{\epsilon} -1)T + \delta T \over (e^{\epsilon}-1) + \delta T})$. We further show that this perturbed distribution could also be used to protect $(\epsilon,\delta)$-global differential privacy, and design a corresponding algorithm GDP-Elim-New. We show that its regret upper bound is $O({\Delta_{\max} \over \Delta_{\min}}({N\log T\over \Delta_{\min}} + {N\over \epsilon }\log {(e^{\epsilon} -1)T + \delta T \over (e^{\epsilon}-1) + \delta T}))$. This shows that our $\Omega({N\over \epsilon }\log {(e^{\epsilon} -1)T + \delta T \over (e^{\epsilon}-1) + \delta T})$ regret lower bound is tight (e.g. when ${\Delta_{\max}\over \Delta_{\min}}$ is bounded).},
  archive      = {J_JMLR},
  author       = {Siwei Wang and Jun Zhu},
  journal      = {Journal of Machine Learning Research},
  number       = {314},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal learning policies for differential privacy in multi-armed bandits},
  url          = {https://jmlr.org/papers/v25/21-1267.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-efficient policy evaluation through behavior policy
search. <em>JMLR</em>, <em>25</em>(313), 1–58. (<a
href="https://jmlr.org/papers/v25/21-0346.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the task of evaluating a policy for a Markov decision process (MDP). The standard unbiased technique for evaluating a policy is to deploy the policy and observe its performance. We show that the data collected from deploying a different policy, commonly called the behavior policy, can be used to produce unbiased estimates with lower mean squared error than this standard technique. We derive an analytic expression for a minimal variance behavior policy -- a behavior policy that minimizes the mean squared error of the resulting estimates. Because this expression depends on terms that are unknown in practice, we propose a novel policy evaluation sub-problem, behavior policy search: searching for a behavior policy that reduces mean squared error. We present two behavior policy search algorithms and empirically demonstrate their effectiveness in lowering the mean squared error of policy performance estimates.},
  archive      = {J_JMLR},
  author       = {Josiah P. Hanna and Yash Chandak and Philip S. Thomas and Martha White and Peter Stone and Scott Niekum},
  journal      = {Journal of Machine Learning Research},
  number       = {313},
  pages        = {1-58},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Data-efficient policy evaluation through behavior policy search},
  url          = {https://jmlr.org/papers/v25/21-0346.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Just wing it: Near-optimal estimation of missing mass in a
markovian sequence. <em>JMLR</em>, <em>25</em>(312), 1–43. (<a
href="https://jmlr.org/papers/v25/24-0511.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of estimating the stationary mass---also called the unigram mass---that is missing from a single trajectory of a discrete-time, ergodic Markov chain. This problem has several applications---for example, estimating the stationary missing mass is critical for accurately smoothing probability estimates in sequence models. While the classical Good--Turing estimator from the 1950s has appealing properties for i.i.d. data, it is known to be biased in the Markovian setting, and other heuristic estimators do not come equipped with guarantees. Operating in the general setting in which the size of the state space may be much larger than the length $n$ of the trajectory, we develop a linear-runtime estimator called Windowed Good--Turing (WingIt) and show that its risk decays as $\widetilde{O}(\mathsf{T_{mix}}/n)$, where $\mathsf{T_{mix}}$ denotes the mixing time of the chain in total variation distance. Notably, this rate is independent of the size of the state space and minimax-optimal up to a logarithmic factor in $n / \mathsf{T_{mix}}$. We also present an upper bound on the variance of the missing mass random variable, which may be of independent interest. We extend our estimator to approximate the stationary mass placed on elements occurring with small frequency in the trajectory. Finally, we demonstrate the efficacy of our estimators both in simulations on canonical chains and on sequences constructed from natural language text.},
  archive      = {J_JMLR},
  author       = {Ashwin Pananjady and Vidya Muthukumar and Andrew Thangaraj},
  journal      = {Journal of Machine Learning Research},
  number       = {312},
  pages        = {1-43},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Just wing it: Near-optimal estimation of missing mass in a markovian sequence},
  url          = {https://jmlr.org/papers/v25/24-0511.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating the replication probability of significant
classification benchmark experiments. <em>JMLR</em>, <em>25</em>(311),
1–42. (<a href="https://jmlr.org/papers/v25/24-0158.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental question in machine learning is: &quot;What are the chances that a statistically significant result will replicate?&quot; The standard framework of null hypothesis significance testing, however, cannot answer this question directly. In this work, we derive formulas for estimating the replication probability that are applicable in two of the most widely used experimental designs in machine learning: the comparison of two classifiers over multiple benchmark datasets and the comparison of two classifiers in k-fold cross-validation. Using simulation studies, we show that p-values just below the common significance threshold of 0.05 are insufficient to warrant a high confidence in the replicability of significant results, as such p-values are barely more informative than the flip of a coin. If a replication probability of around 0.95 is desired, then the significance threshold should be lowered to at least 0.003. This observation might explain, at least in part, why many published research findings fail to replicate.},
  archive      = {J_JMLR},
  author       = {Daniel Berrar},
  journal      = {Journal of Machine Learning Research},
  number       = {311},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Estimating the replication probability of significant classification benchmark experiments},
  url          = {https://jmlr.org/papers/v25/24-0158.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causal discovery with generalized linear models through
peeling algorithms. <em>JMLR</em>, <em>25</em>(310), 1–49. (<a
href="https://jmlr.org/papers/v25/23-1228.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel method for causal discovery with generalized structural equation models suited for analyzing diverse types of outcomes, including discrete, continuous, and mixed data. Causal discovery often faces challenges due to unmeasured confounders that hinder the identification of causal relationships. The proposed approach addresses this issue by developing two peeling algorithms (bottom-up and top-down) to ascertain causal relationships and valid instruments. This approach first reconstructs a super-graph to represent ancestral relationships between variables, using a peeling algorithm based on nodewise GLM regressions that exploit relationships between primary and instrumental variables. Then, it estimates parent-child effects from the ancestral relationships using another peeling algorithm while deconfounding a child&#39;s model with information borrowed from its parents&#39; models. The article offers a theoretical analysis of the proposed approach, establishing conditions for model identifiability and providing statistical guarantees for accurately discovering parent-child relationships via the peeling algorithms. Furthermore, the article presents numerical experiments showcasing the effectiveness of our approach in comparison to state-of-the-art structure learning methods without confounders. Lastly, it demonstrates an application to Alzheimer&#39;s disease (AD), highlighting the method&#39;s utility in constructing gene-to-gene and gene-to-disease regulatory networks involving Single Nucleotide Polymorphisms (SNPs) for healthy and AD subjects.},
  archive      = {J_JMLR},
  author       = {Minjie Wang and Xiaotong Shen and Wei Pan},
  journal      = {Journal of Machine Learning Research},
  number       = {310},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Causal discovery with generalized linear models through peeling algorithms},
  url          = {https://jmlr.org/papers/v25/23-1228.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spectral regularized kernel goodness-of-fit tests.
<em>JMLR</em>, <em>25</em>(309), 1–52. (<a
href="https://jmlr.org/papers/v25/23-1031.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximum mean discrepancy (MMD) has enjoyed a lot of success in many machine learning and statistical applications, including non-parametric hypothesis testing, because of its ability to handle non-Euclidean data. Recently, it has been demonstrated in Balasubramanian et al. (2021) that the goodness-of-fit test based on MMD is not minimax optimal while a Tikhonov regularized version of it is, for an appropriate choice of the regularization parameter. However, the results in Balasubramanian et al. (2021) are obtained under the restrictive assumptions of the mean element being zero, and the uniform boundedness condition on the eigenfunctions of the integral operator. Moreover, the test proposed in Balasubramanian et al. (2021) is not practical as it is not computable for many kernels. In this paper, we address these shortcomings and extend the results to general spectral regularizers that include Tikhonov regularization.},
  archive      = {J_JMLR},
  author       = {Omar Hagrass and Bharath K. Sriperumbudur and Bing Li},
  journal      = {Journal of Machine Learning Research},
  number       = {309},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Spectral regularized kernel goodness-of-fit tests},
  url          = {https://jmlr.org/papers/v25/23-1031.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Matryoshka policy gradient for entropy-regularized RL:
Convergence and global optimality. <em>JMLR</em>, <em>25</em>(308),
1–52. (<a href="https://jmlr.org/papers/v25/23-0879.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel Policy Gradient (PG) algorithm, called Matryoshka Policy Gradient (MPG), is introduced and studied, in the context of fixed-horizon max-entropy reinforcement learning, where an agent aims at maximizing entropy bonuses additional to its cumulative rewards. In the linear function approximation setting with softmax policies, we prove uniqueness and characterize the optimal policy of the entropy regularized objective, together with global convergence of MPG. These results are proved in the case of continuous state and action space. MPG is intuitive, theoretically sound and we furthermore show that the optimal policy of the infinite horizon max-entropy objective can be approximated arbitrarily well by the optimal policy of the MPG framework. Finally, we provide a criterion for global optimality when the policy is parametrized by a neural network in terms of the neural tangent kernel at convergence. As a proof of concept, we evaluate numerically MPG on standard test benchmarks.},
  archive      = {J_JMLR},
  author       = {François G. Ged and Maria Han Veiga},
  journal      = {Journal of Machine Learning Research},
  number       = {308},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Matryoshka policy gradient for entropy-regularized RL: Convergence and global optimality},
  url          = {https://jmlr.org/papers/v25/23-0879.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-euclidean monotone operator theory and applications.
<em>JMLR</em>, <em>25</em>(307), 1–33. (<a
href="https://jmlr.org/papers/v25/23-0805.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While monotone operator theory is often studied on Hilbert spaces, many interesting problems in machine learning and optimization arise naturally in finite-dimensional vector spaces endowed with non-Euclidean norms, such as diagonally-weighted $\ell_{1}$ or $\ell_{\infty}$ norms. This paper provides a natural generalization of monotone operator theory to finite-dimensional non-Euclidean spaces. The key tools are weak pairings and logarithmic norms. We show that the resolvent and reflected resolvent operators of non-Euclidean monotone mappings exhibit similar properties to their counterparts in Hilbert spaces. Furthermore, classical iterative methods and splitting methods for finding zeros of monotone operators are shown to converge in the non-Euclidean case. We apply our theory to equilibrium computation and Lipschitz constant estimation of recurrent neural networks, obtaining novel iterations and tighter upper bounds via forward-backward splitting.},
  archive      = {J_JMLR},
  author       = {Alexander Davydov and Saber Jafarpour and Anton V. Proskurnikov and Francesco Bullo},
  journal      = {Journal of Machine Learning Research},
  number       = {307},
  pages        = {1-33},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Non-euclidean monotone operator theory and applications},
  url          = {https://jmlr.org/papers/v25/23-0805.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic regularized majorization-minimization with weakly
convex and multi-convex surrogates. <em>JMLR</em>, <em>25</em>(306),
1–83. (<a href="https://jmlr.org/papers/v25/23-0349.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic majorization-minimization (SMM) is a class of stochastic optimization algorithms that proceed by sampling new data points and minimizing a recursive average of surrogate functions of an objective function. The surrogates are required to be strongly convex and the existing convergence rate analysis for the general non-convex setting was not available. In this paper, we propose an extension of SMM where surrogates are allowed to be only weakly convex or block multi-convex, and the averaged surrogates are approximately minimized with proximal regularization or block-minimized within diminishing radii, respectively. For the general nonconvex constrained setting with non-i.i.d. data samples, we show that the first-order optimality gap of the proposed algorithm decays at the rate $\widetilde{O}(n^{-1/4})$ for the empirical loss and $\widetilde{O}(n^{-1/8})$ for the expected loss, where $n$ denotes the number of data samples processed. Under some additional assumption, the latter convergence rate can be improved to $\widetilde{O}(n^{-1/4})$. As a corollary, we obtain the first convergence rate bounds for various optimization methods under general nonconvex non-i.i.d. data setting: Double-averaging projected gradient descent and its generalizations, proximal point empirical risk minimization, and online matrix/tensor decomposition algorithms. We also provide experimental validation of our results.},
  archive      = {J_JMLR},
  author       = {Hanbaek Lyu},
  journal      = {Journal of Machine Learning Research},
  number       = {306},
  pages        = {1-83},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Stochastic regularized majorization-minimization with weakly convex and multi-convex surrogates},
  url          = {https://jmlr.org/papers/v25/23-0349.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pure differential privacy for functional summaries with a
laplace-like process. <em>JMLR</em>, <em>25</em>(305), 1–50. (<a
href="https://jmlr.org/papers/v25/22-1384.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many existing mechanisms for achieving differential privacy (DP) on infinite-dimensional functional summaries typically involve embedding these functional summaries into finite-dimensional subspaces and applying traditional multivariate DP techniques. These mechanisms generally treat each dimension uniformly and struggle with complex, structured summaries. This work introduces a novel mechanism to achieve pure DP for functional summaries in a separable infinite-dimensional Hilbert space, named the Independent Component Laplace Process (ICLP) mechanism. This mechanism treats the summaries of interest as truly infinite-dimensional functional objects, thereby addressing several limitations of the existing mechanisms. Several statistical estimation problems are considered, and we demonstrate how one can enhance the utility of private summaries by oversmoothing the non-private counterparts. Numerical experiments on synthetic and real datasets demonstrate the effectiveness of the proposed mechanism.},
  archive      = {J_JMLR},
  author       = {Haotian Lin and Matthew Reimherr},
  journal      = {Journal of Machine Learning Research},
  number       = {305},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Pure differential privacy for functional summaries with a laplace-like process},
  url          = {https://jmlr.org/papers/v25/22-1384.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse recovery with multiple data streams: An adaptive
sequential testing approach. <em>JMLR</em>, <em>25</em>(304), 1–59. (<a
href="https://jmlr.org/papers/v25/22-1310.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multistage design has been utilized across a variety of scientific fields, enabling the adaptive allocation of sensing resources to effectively eliminate null locations and localize signals. We present a decision-theoretic framework for multi-stage adaptive testing that minimizes the total number of measurements while ensuring pre-specified constraints on both the false positive rate (FPR) and the missed discovery rate (MDR). Our method, SMART, explicitly addresses the often-overlooked aspect of uncertainty quantification in machine learning algorithms, incorporating it at every decision stage. This enables SMART to respond adaptively to important patterns in the data streams, adjusting its decisions based on the strength of evidence at specific locations. By leveraging technical tools and key concepts from multiple testing, adaptive thresholding, and compound decision theory, SMART not only enhances the aggregation of information across individual tests but also allows for varying thresholds tailored to the observed data, thereby ensuring effective error rate control and resulting in significant savings on total study costs. Through comprehensive analyses of large-scale A/B tests, high-throughput screening, and image analysis, we demonstrate that our approach yields substantial efficiency gains and improved control over error rates compared to existing methodologies.},
  archive      = {J_JMLR},
  author       = {Weinan Wang and Bowen Gang and Wenguang Sun},
  journal      = {Journal of Machine Learning Research},
  number       = {304},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sparse recovery with multiple data streams: An adaptive sequential testing approach},
  url          = {https://jmlr.org/papers/v25/22-1310.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Instrumental variable value iteration for causal offline
reinforcement learning. <em>JMLR</em>, <em>25</em>(303), 1–56. (<a
href="https://jmlr.org/papers/v25/22-0965.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In offline reinforcement learning (RL) an optimal policy is learned solely from a priori collected observational data. However, in observational data, actions are often confounded by unobserved variables. Instrumental variables (IVs), in the context of RL, are the variables whose influence on the state variables is all mediated by the action. When a valid instrument is present, we can recover the confounded transition dynamics through observational data. We study a confounded Markov decision process where the transition dynamics admit an additive nonlinear functional form. Using IVs, we derive a conditional moment restriction through which we can identify transition dynamics based on observational data. We propose a provably efficient IV-aided Value Iteration (IVVI) algorithm based on a primal-dual reformulation of the conditional moment restriction. To our knowledge, this is the first provably efficient algorithm for instrument-aided offline RL.},
  archive      = {J_JMLR},
  author       = {Luofeng Liao and Zuyue Fu and Zhuoran Yang and Yixin Wang and Dingli Ma and Mladen Kolar and Zhaoran Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {303},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Instrumental variable value iteration for causal offline reinforcement learning},
  url          = {https://jmlr.org/papers/v25/22-0965.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying causal eﬀects using instrumental time series:
Nuisance IV and correcting for the past. <em>JMLR</em>,
<em>25</em>(302), 1–51. (<a
href="https://jmlr.org/papers/v25/22-0262.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instrumental variable (IV) regression relies on instruments to infer causal eﬀects from observational data with unobserved confounding. We consider IV regression in time series models, such as vector auto-regressive (VAR) processes. Direct applications of i.i.d. techniques are generally inconsistent as they do not correctly adjust for dependencies in the past. In this paper, we outline the diﬃculties that arise due to time structure and propose methodology for constructing identifying equations that can be used for consistent parametric estimation of causal eﬀects in time series data. One method uses extra nuisance covariates to obtain identifiability (an idea that can be of interest even in the i.i.d. case). We further propose a graph marginalization framework that allows us to apply nuisance IV and other IV methods in a principled way to time series. Our methods make use of a version of the global Markov property, which we prove holds for VAR(p) processes. For VAR(1) processes, we prove identifiability conditions that relate to Jordan forms and are diﬀerent from the well-known rank conditions in the i.i.d. case (they do not require as many instruments as covariates, for example). We provide methods, prove their consistency, and show how the inferred causal eﬀect can be used for distribution generalization. Simulation experiments corroborate our theoretical results. We provide ready-to-use Python code.},
  archive      = {J_JMLR},
  author       = {Nikolaj Thams and Rikke Søndergaard and Sebastian Weichwald and Jonas Peters},
  journal      = {Journal of Machine Learning Research},
  number       = {302},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Identifying causal eﬀects using instrumental time series: Nuisance IV and correcting for the past},
  url          = {https://jmlr.org/papers/v25/22-0262.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RLtools: A fast, portable deep reinforcement learning
library for continuous control. <em>JMLR</em>, <em>25</em>(301), 1–19.
(<a href="https://jmlr.org/papers/v25/24-0248.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning (RL) can yield capable agents and control policies in several domains but is commonly plagued by prohibitively long training times. Additionally, in the case of continuous control problems, the applicability of learned policies on real-world embedded devices is limited due to the lack of real-time guarantees and portability of existing libraries. To address these challenges, we present RLtools, a dependency-free, header-only, pure C++ library for deep supervised and reinforcement learning. Its novel architecture allows RLtools to be used on a wide variety of platforms, from HPC clusters over workstations and laptops to smartphones, smartwatches, and microcontrollers. Specifically, due to the tight integration of the RL algorithms with simulation environments, RL can solve popular RL problems up to 76 times faster than other popular RL frameworks. We also benchmark the inference on a diverse set of microcontrollers and show that in most cases our optimized implementation is by far the fastest. Finally, RLtools enables the first-ever demonstration of training a deep RL algorithm directly on a microcontroller, giving rise to the field of TinyRL. The source code as well as documentation and live demos are available through our project page at https://rl.tools.},
  archive      = {J_JMLR},
  author       = {Jonas Eschmann and Dario Albani and Giuseppe Loianno},
  journal      = {Journal of Machine Learning Research},
  number       = {301},
  pages        = {1-19},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {RLtools: A fast, portable deep reinforcement learning library for continuous control},
  url          = {https://jmlr.org/papers/v25/24-0248.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). White-box transformers via sparse rate reduction:
Compression is all there is? <em>JMLR</em>, <em>25</em>(300), 1–128. (<a
href="https://jmlr.org/papers/v25/23-1547.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we contend that a natural objective of representation learning is to compress and transform the distribution of the data, say sets of tokens, towards a low-dimensional Gaussian mixture supported on incoherent subspaces. The goodness of such a representation can be evaluated by a principled measure, called sparse rate reduction, that simultaneously maximizes the intrinsic information gain and extrinsic sparsity of the learned representation. From this perspective, popular deep network architectures, including transformers, can be viewed as realizing iterative schemes to optimize this measure. Particularly, we derive a transformer block from alternating optimization on parts of this objective: the multi-head self-attention operator compresses the representation by implementing an approximate gradient descent step on the coding rate of the features, and the subsequent multi-layer perceptron sparsifies the features. This leads to a family of white-box transformer-like deep network architectures, named CRATE, which are mathematically fully interpretable. We show, by way of a novel connection between denoising and compression, that the inverse to the aforementioned compressive encoding can be realized by the same class of CRATE architectures. Thus, the so-derived white-box architectures are universal to both encoders and decoders. Experiments show that these networks, despite their simplicity, indeed learn to compress and sparsify representations of large-scale real-world image and text datasets, and achieve strong performance across different settings: ViT, MAE, DINO, BERT, and GPT2. We believe the proposed computational framework demonstrates great potential in bridging the gap between theory and practice of deep learning, from a unified perspective of data compression.},
  archive      = {J_JMLR},
  author       = {Yaodong Yu and Sam Buchanan and Druv Pai and Tianzhe Chu and Ziyang Wu and Shengbang Tong and Hao Bai and Yuexiang Zhai and Benjamin D. Haeffele and Yi Ma},
  journal      = {Journal of Machine Learning Research},
  number       = {300},
  pages        = {1-128},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {White-box transformers via sparse rate reduction: Compression is all there is?},
  url          = {https://jmlr.org/papers/v25/23-1547.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Commutative scaling of width and depth in deep neural
networks. <em>JMLR</em>, <em>25</em>(299), 1–41. (<a
href="https://jmlr.org/papers/v25/23-1163.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the commutativity of infinite width and depth limits in deep neural networks. Our aim is to understand the behavior of neural functions (functions that depend on a neural network model) as width and depth go to infinity (in some sense), and eventually identify settings under which commutativity holds, i.e. the neural function tends to the same limit no matter how width and depth limits are taken. In this paper, we formally introduce and define the commutativity framework, and discuss its implications on neural network design and scaling. We study commutativity for the neural covariance kernel which reflects how network layers separate data. Our findings extend previous results established in Hayou and Yang (2023) by showing that taking the width and depth to infinity in a deep neural network with skip connections, when branches are suitably scaled to avoid exploding behavior, result in the same covariance structure no matter how that limit is taken. This has a number of theoretical and practical implications that we discuss in the paper. The proof techniques in this paper are new and rely on tools that are more accessible to readers who are not familiar with stochastic calculus (used in the proofs of Hayou and Yang (2023)).},
  archive      = {J_JMLR},
  author       = {Soufiane Hayou},
  journal      = {Journal of Machine Learning Research},
  number       = {299},
  pages        = {1-41},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Commutative scaling of width and depth in deep neural networks},
  url          = {https://jmlr.org/papers/v25/23-1163.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Value-distributional model-based reinforcement learning.
<em>JMLR</em>, <em>25</em>(298), 1–42. (<a
href="https://jmlr.org/papers/v25/23-0913.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying uncertainty about a policy&#39;s long-term performance is important to solve sequential decision-making tasks. We study the problem from a model-based Bayesian reinforcement learning perspective, where the goal is to learn the posterior distribution over value functions induced by parameter (epistemic) uncertainty of the Markov decision process. Previous work restricts the analysis to a few moments of the distribution over values or imposes a particular distribution shape, e.g., Gaussians. Inspired by distributional reinforcement learning, we introduce a Bellman operator whose fixed-point is the value distribution function. Based on our theory, we propose Epistemic Quantile-Regression (EQR), a model-based algorithm that learns a value distribution function. We combine EQR with soft actor-critic (SAC) for policy optimization with an arbitrary differentiable objective function of the learned value distribution. Evaluation across several continuous-control tasks shows performance benefits with respect to both model-based and model-free algorithms. The code is available at https://github.com/boschresearch/dist-mbrl.},
  archive      = {J_JMLR},
  author       = {Carlos E. Luis and Alessandro G. Bottero and Julia Vinogradska and Felix Berkenkamp and Jan Peters},
  journal      = {Journal of Machine Learning Research},
  number       = {298},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Value-distributional model-based reinforcement learning},
  url          = {https://jmlr.org/papers/v25/23-0913.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimistic search: Change point estimation for large-scale
data via adaptive logarithmic queries. <em>JMLR</em>, <em>25</em>(297),
1–64. (<a href="https://jmlr.org/papers/v25/23-0871.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change point estimation is often formulated as a search for the maximum of a gain function describing improved fits when segmenting the data. Searching one change point through all candidates requires $O(n)$ evaluations of the gain function for an interval with $n$ observations. If each evaluation is computationally demanding (e.g. in high-dimensional models), this can become infeasible. Instead, we propose optimistic search, a methodology that only requires $O(\log n)$ evaluations of the gain function, leading to huge computational gains for massive (large-scale, high-dimensional) data for single and multiple change point estimation. Towards solid understanding of our strategy, we investigate in detail the $p$-dimensional Gaussian changing means setup, including high-dimensional scenarios. For some of our proposals, we prove asymptotic minimax optimality for detecting change points and derive sharp asymptotic rates for localizing change points. Our search strategy generalizes far beyond the theoretically analyzed setup. We illustrate, as an example, massive computational speedup in change point detection for high-dimensional Gaussian graphical models.},
  archive      = {J_JMLR},
  author       = {Solt Kovács and Housen Li and Lorenz Haubner and Axel Munk and Peter Bühlmann},
  journal      = {Journal of Machine Learning Research},
  number       = {297},
  pages        = {1-64},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimistic search: Change point estimation for large-scale data via adaptive logarithmic queries},
  url          = {https://jmlr.org/papers/v25/23-0871.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PyPop7: A pure-python library for population-based black-box
optimization. <em>JMLR</em>, <em>25</em>(296), 1–28. (<a
href="https://jmlr.org/papers/v25/23-0386.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an open-source pure-Python library called PyPop7 for black-box optimization (BBO). As population-based methods (e.g., evolutionary algorithms, swarm intelligence, and pattern search) become increasingly popular for BBO, the design goal of PyPop7 is to provide a unified API and elegant implementations for them, particularly in challenging high-dimensional scenarios. Since these population-based methods easily suffer from the notorious curse of dimensionality owing to random sampling as one of core operations for most of them, recently various improvements and enhancements have been proposed to alleviate this issue more or less mainly via exploiting possible problem structures: such as, decomposition of search distribution or space, low-memory approximation, low-rank metric learning, variance reduction, ensemble of random subspaces, model self-adaptation, and fitness smoothing. These novel sampling strategies could better exploit different problem structures in high-dimensional search space and therefore they often result in faster rates of convergence and/or better qualities of solution for large-scale BBO. Now PyPop7 has covered many of these important advances on a set of well-established BBO algorithm families and also provided an open-access interface to adding the latest or missed black-box optimizers for further functionality extensions. Its well-designed source code (under GPL-3.0 license) and full-fledged online documents (under CC-BY 4.0 license) have been freely available at https://github.com/Evolutionary-Intelligence/pypop and https://pypop.readthedocs.io, respectively.},
  archive      = {J_JMLR},
  author       = {Qiqi Duan and Guochen Zhou and Chang Shao and Zhuowei Wang and Mingyang Feng and Yuwei Huang and Yajing Tan and Yijun Yang and Qi Zhao and Yuhui Shi},
  journal      = {Journal of Machine Learning Research},
  number       = {296},
  pages        = {1-28},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {PyPop7: A pure-python library for population-based black-box optimization},
  url          = {https://jmlr.org/papers/v25/23-0386.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evidence estimation in gaussian graphical models using a
telescoping block decomposition of the precision matrix. <em>JMLR</em>,
<em>25</em>(295), 1–43. (<a
href="https://jmlr.org/papers/v25/23-0254.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marginal likelihood, also known as model evidence, is a fundamental quantity in Bayesian statistics. It is used for model selection using Bayes factors or for empirical Bayes tuning of prior hyper-parameters. Yet, the calculation of evidence has remained a longstanding open problem in Gaussian graphical models. Currently, the only feasible solutions that exist are for special cases such as the Wishart or G-Wishart, in moderate dimensions. We develop an approach based on a novel telescoping block decomposition of the precision matrix that allows the estimation of evidence by application of Chib&#39;s technique under a very broad class of priors under mild requirements. Specifically, the requirements are: (a) the priors on the diagonal terms on the precision matrix can be written as gamma or scale mixtures of gamma random variables and (b) those on the off-diagonal terms can be represented as normal or scale mixtures of normal. This includes structured priors such as the Wishart or G-Wishart, and more recently introduced element-wise priors, such as the Bayesian graphical lasso and the graphical horseshoe. Among these, the true marginal is known in an analytically closed form for Wishart, providing a useful validation of our approach. For the general setting of the other three, and several more priors satisfying conditions (a) and (b) above, the calculation of evidence has remained an open question that this article resolves under a unifying framework.},
  archive      = {J_JMLR},
  author       = {Anindya Bhadra and Ksheera Sagar and David Rowe and Sayantan Banerjee and Jyotishka Datta},
  journal      = {Journal of Machine Learning Research},
  number       = {295},
  pages        = {1-43},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Evidence estimation in gaussian graphical models using a telescoping block decomposition of the precision matrix},
  url          = {https://jmlr.org/papers/v25/23-0254.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An asymptotic study of discriminant and vote-averaging
schemes for randomly-projected linear discriminants. <em>JMLR</em>,
<em>25</em>(294), 1–65. (<a
href="https://jmlr.org/papers/v25/22-1367.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern technology has contributed to the rise of high-dimensional data in various domains such as bio-informatics, chemometrics, and face recognition. In the recent literature, random projections and, in particular, randomly-projected ensembles based on the classical Linear Discriminant Analysis (LDA), have been proposed for classification problems involving such high-dimensional data. In this work, we study the two main classes of randomly-projected LDA ensemble classifiers, namely discriminant averaging and vote averaging. Through asymptotic analysis in a growth regime where the problem dimensions are assumed to grow at constant rates to each other for a fixed ensemble size, we determine the exact mechanism through which the ensemble size affects the classification performance. Furthermore, we investigate whether projection selection truly matters in an ensemble setting, and, ultimately, derive the optimal form of the randomly-projected LDA ensemble. Motivated by these findings, we propose a framework for efficient tuning of the optimal classifier&#39;s ensemble size and projection dimension based on an estimator of the classifier probability of misclassification which is consistent under the assumed growth regime. The proposed framework is shown to outperform the existing rule-of-thumb, as well as other methods for parameter tuning, on both real and synthetic data.},
  archive      = {J_JMLR},
  author       = {Lama B. Niyazi and Abla Kammoun and Hayssam Dahrouj and Mohamed-Slim Alouini and Tareq Y. Al-Naffouri},
  journal      = {Journal of Machine Learning Research},
  number       = {294},
  pages        = {1-65},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {An asymptotic study of discriminant and vote-averaging schemes for randomly-projected linear discriminants},
  url          = {https://jmlr.org/papers/v25/22-1367.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning and scoring gaussian latent variable causal models
with unknown additive interventions. <em>JMLR</em>, <em>25</em>(293),
1–68. (<a href="https://jmlr.org/papers/v25/22-0979.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With observational data alone, causal structure learning is a challenging problem. The task becomes easier when having access to data collected from perturbations of the underlying system, even when the nature of these is unknown. Existing methods either do not allow for the presence of latent variables or assume that these remain unperturbed. However, these assumptions are hard to justify if the nature of the perturbations is unknown. We provide results that enable scoring causal structures in the setting with additive, but unknown interventions. Specifically, we propose a maximum-likelihood estimator in a structural equation model that exploits system-wide invariances to output an equivalence class of causal structures from perturbation data. Furthermore, under certain structural assumptions on the population model, we provide a simple graphical characterization of all the DAGs in the interventional equivalence class. We illustrate the utility of our framework on synthetic data as well as real data involving California reservoirs and protein expressions. The software implementation is available as the Python package utlvce.},
  archive      = {J_JMLR},
  author       = {Armeen Taeb and Juan L. Gamella and Christina Heinze-Deml and Peter Bühlmann},
  journal      = {Journal of Machine Learning Research},
  number       = {293},
  pages        = {1-68},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning and scoring gaussian latent variable causal models with unknown additive interventions},
  url          = {https://jmlr.org/papers/v25/22-0979.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-splitting neyman-pearson classifiers. <em>JMLR</em>,
<em>25</em>(292), 1–61. (<a
href="https://jmlr.org/papers/v25/22-0795.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Neyman-Pearson (NP) binary classification paradigm constrains the more severe type of error (e.g., the type I error) under a preferred level while minimizing the other (e.g., the type II error). This paradigm is suitable for applications such as severe disease diagnosis, fraud detection, among others. A series of NP classifiers have been developed to guarantee the type I error control with high probability. However, these existing classifiers involve a sample splitting step: a mixture of class 0 and class 1 observations to construct a scoring function and some left-out class 0 observations to construct a threshold. This splitting enables classifier threshold construction built upon independence, but it amounts to insufficient use of data for training and a potentially higher type II error. Leveraging a canonical linear discriminant analysis (LDA) model, we derive a quantitative CLT for a certain functional of quadratic forms of the inverse of sample and population covariance matrices, and based on this result, develop for the first time NP classifiers without splitting the training sample. Numerical experiments have confirmed the advantages of our new non-splitting parametric strategy.},
  archive      = {J_JMLR},
  author       = {Jingming Wang and Lucy Xia and Zhigang Bao and Xin Tong},
  journal      = {Journal of Machine Learning Research},
  number       = {292},
  pages        = {1-61},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Non-splitting neyman-pearson classifiers},
  url          = {https://jmlr.org/papers/v25/22-0795.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Studying the interplay between information loss and
operation loss in representations for classification. <em>JMLR</em>,
<em>25</em>(291), 1–71. (<a
href="https://jmlr.org/papers/v25/21-1551.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information-theoretic measures have been widely adopted for machine learning (ML) feature design. Inspired by this, we look at the relationship between information loss in the Shannon sense and the operation loss in the minimum probability of error (MPE) sense when considering a family of lossy representations. Our first result offers a lower bound on a weak form of information loss as a function of its respective operation loss when adopting a discrete encoder. When considering a general family of lossy continuous representations, we show that a form of vanishing information loss (a weak informational sufficiency (WIS)) implies a vanishing MPE loss. Our findings support the observation that selecting/designing representations that capture informational sufficiency is appropriate for learning. However, this selection is rather conservative if the intended goal is achieving MPE in classification. Supporting this, we show that it is possible to adopt an alternative notion of informational sufficiency (strictly weaker than pure sufficiency in the mutual information sense) to achieve operational sufficiency in learning. Furthermore, our new WIS condition is used to demonstrate the expressive power of digital encoders and the capacity of two existing compression-based algorithms to achieve lossless prediction in ML.},
  archive      = {J_JMLR},
  author       = {Jorge F. Silva and Felipe Tobar and Mario Vicuña and Felipe Cordova},
  journal      = {Journal of Machine Learning Research},
  number       = {291},
  pages        = {1-71},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Studying the interplay between information loss and operation loss in representations for classification},
  url          = {https://jmlr.org/papers/v25/21-1551.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Skscope: Fast sparsity-constrained optimization in python.
<em>JMLR</em>, <em>25</em>(290), 1–9. (<a
href="https://jmlr.org/papers/v25/23-1574.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying iterative solvers on sparsity-constrained optimization (SCO) requires tedious mathematical deduction and careful programming/debugging that hinders these solvers&#39; broad impact. In the paper, the library skscope is introduced to overcome such an obstacle. With skscope, users can solve the SCO by just programming the objective function. The convenience of skscope is demonstrated through two examples in the paper, where sparse linear regression and trend filtering are addressed with just four lines of code. More importantly, skscope&#39;s efficient implementation allows state-of-the-art solvers to quickly attain the sparse solution regardless of the high dimensionality of parameter space. Numerical experiments reveal the available solvers in skscope can achieve up to 80x speedup on the competing relaxation solutions obtained via the benchmarked convex solver. skscope is published on the Python Package Index (PyPI) and Conda, and its source code is available at: https://github.com/abess-team/skscope.},
  archive      = {J_JMLR},
  author       = {Zezhi Wang and Junxian Zhu and Xueqin Wang and Jin Zhu and Huiyang Pen and Peng Chen and Anran Wang and Xiaoke Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {290},
  pages        = {1-9},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Skscope: Fast sparsity-constrained optimization in python},
  url          = {https://jmlr.org/papers/v25/23-1574.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aeon: A python toolkit for learning from time series.
<em>JMLR</em>, <em>25</em>(289), 1–10. (<a
href="https://jmlr.org/papers/v25/23-1444.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {aeon is a unified Python 3 library for all machine learning tasks involving time series. The package contains modules for time series forecasting, classification, extrinsic regression and clustering, as well as a variety of utilities, transformations and distance measures designed for time series data. aeon also has a number of experimental modules for tasks such as anomaly detection, similarity search and segmentation. aeon follows the scikit-learn API as much as possible to help new users and enable easy integration of aeon estimators with useful tools such as model selection and pipelines. It provides a broad library of time series algorithms, including efficient implementations of the very latest advances in research. Using a system of optional dependencies, aeon integrates a wide variety of packages into a single interface while keeping the core framework with minimal dependencies. The package is distributed under the 3-Clause BSD license and is available at https://github.com/aeon-toolkit/aeon.},
  archive      = {J_JMLR},
  author       = {Matthew Middlehurst and Ali Ismail-Fawaz and Antoine Guillaume and Christopher Holder and David Guijo-Rubio and Guzal Bulatova and Leonidas Tsaprounis and Lukasz Mentel and Martin Walter and Patrick Schäfer and Anthony Bagnall},
  journal      = {Journal of Machine Learning Research},
  number       = {289},
  pages        = {1-10},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Aeon: A python toolkit for learning from time series},
  url          = {https://jmlr.org/papers/v25/23-1444.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Compressed and distributed least-squares regression:
Convergence rates with applications to federated learning.
<em>JMLR</em>, <em>25</em>(288), 1–80. (<a
href="https://jmlr.org/papers/v25/23-1040.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the impact of compression on stochastic gradient algorithms for machine learning, a technique widely used in distributed and federated learning. We underline differences in terms of convergence rates between several unbiased compression operators, that all satisfy the same condition on their variance, thus going beyond the classical worst-case analysis. To do so, we focus on the case of least-squares regression (LSR) and analyze a general stochastic approximation algorithm for minimizing quadratic functions relying on a random field. We consider weak assumptions on the random field, tailored to the analysis (specifically, expected Hölder regularity), and on the noise covariance, enabling the analysis of various randomizing mechanisms, including compression. We then extend our results to the case of federated learning. More formally, we highlight the impact on the convergence of the covariance $\mathfrak{C}_{\mathrm{ania}}$ of the additive noise induced by the algorithm. We demonstrate despite the non-regularity of the stochastic field, that the limit variance term scales with $\mathrm{Tr}(\mathfrak{C}_{\mathrm{ania}} H^{-1})/K$ (where $H$ is the Hessian of the optimization problem and $K$ the number of iterations) generalizing the rate for the vanilla LSR case where it is $\sigma^2 \mathrm{Tr}(H H^{-1}) / K = \sigma^2 d / K$ (Bach and Moulines, 2013). Then, we analyze the dependency of $\mathfrak{C}_{\mathrm{ania}}$ on the compression strategy and ultimately its impact on convergence, first in the centralized case, then in two heterogeneous FL frameworks.},
  archive      = {J_JMLR},
  author       = {Constantin Philippenko and Aymeric Dieuleveut},
  journal      = {Journal of Machine Learning Research},
  number       = {288},
  pages        = {1-80},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Compressed and distributed least-squares regression: Convergence rates with applications to federated learning},
  url          = {https://jmlr.org/papers/v25/23-1040.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contamination-source based k-sample clustering.
<em>JMLR</em>, <em>25</em>(287), 1–32. (<a
href="https://jmlr.org/papers/v25/23-0914.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate the $K$-sample clustering of populations subject to contamination phenomena. A contamination model is a two-component mixture model where one component is known (standard behaviour) and the second component, modeling a departure from the standard behaviour, is unknown.When $K$ populations from such a model are observed we propose a semiparametric clustering methodology to detect which populations are impacted by the same type of contamination, with the aim of faciliting coordinated diagnosis and best practices sharing. We prove the consistency of our approach under the assumption of the existence of true clusters and demonstrate the performances of our methodology through an extensive Monte Carlo study. Finally, we apply our methodology, implemented in the R admix package, to a European countries COVID-19 excess of mortality dataset, aiming to cluster countries similarly impacted by the pandemic across different age groups.},
  archive      = {J_JMLR},
  author       = {Xavier Milhaud and Denys Pommeret and Yahia Salhi and Pierre Vandekerkhove},
  journal      = {Journal of Machine Learning Research},
  number       = {287},
  pages        = {1-32},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Contamination-source based K-sample clustering},
  url          = {https://jmlr.org/papers/v25/23-0914.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Measuring sample quality in algorithms for intractable
normalizing function problems. <em>JMLR</em>, <em>25</em>(286), 1–32.
(<a href="https://jmlr.org/papers/v25/23-0810.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models with intractable normalizing functions have numerous applications. Because the normalizing constants are functions of the parameters of interest, standard Markov chain Monte Carlo cannot be used for Bayesian inference for these models. A number of algorithms have been developed for such models. Some have the posterior distribution as their asymptotic distribution. Other &quot;asymptotically inexact&quot; algorithms do not possess this property. There is limited guidance for evaluating approximations based on these algorithms. Hence it is very hard to tune them. We propose two new diagnostics that address these problems for intractable normalizing function models. Our first diagnostic, inspired by the second Bartlett identity, is in principle broadly applicable to Monte Carlo approximations beyond the normalizing function problem. We develop an approximate version of this diagnostic that is applicable to intractable normalizing function problems. Our second diagnostic is a Monte Carlo approximation to a kernel Stein discrepancy-based diagnostic introduced by Gorham and Mackey (2017). We provide theoretical justification for our methods and apply them to several algorithms in challenging simulated and real data examples including an Ising model, an exponential random graph model, and a Conway-Maxwell-Poisson regression model, obtaining interesting insights about the algorithms in these contexts.},
  archive      = {J_JMLR},
  author       = {Bokgyeong Kang and John Hughes and Murali Haran},
  journal      = {Journal of Machine Learning Research},
  number       = {286},
  pages        = {1-32},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Measuring sample quality in algorithms for intractable normalizing function problems},
  url          = {https://jmlr.org/papers/v25/23-0810.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OmniSafe: An infrastructure for accelerating safe
reinforcement learning research. <em>JMLR</em>, <em>25</em>(285), 1–6.
(<a href="https://jmlr.org/papers/v25/23-0681.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI systems empowered by reinforcement learning (RL) algorithms harbor the immense potential to catalyze societal advancement, yet their deployment is often impeded by significant safety concerns. Particularly in safety-critical applications, researchers have raised concerns about unintended harms or unsafe behaviors of unaligned RL agents. The philosophy of safe reinforcement learning (SafeRL) is to align RL agents with harmless intentions and safe behavioral patterns. In SafeRL, agents learn to develop optimal policies by receiving feedback from the environment, while also fulfilling the requirement of minimizing the risk of unintended harm or unsafe behavior. However, due to the intricate nature of SafeRL algorithm implementation, combining methodologies across various domains presents a formidable challenge. This had led to an absence of a cohesive and efficacious learning framework within the contemporary SafeRL research milieu. In this work, we introduce a foundational framework designed to expedite SafeRL research endeavors. Our comprehensive framework encompasses an array of algorithms spanning different RL domains and places heavy emphasis on safety elements. Our efforts are to make the SafeRL-related research process more streamlined and efficient, therefore facilitating further research in AI safety.},
  archive      = {J_JMLR},
  author       = {Jiaming Ji and Jiayi Zhou and Borong Zhang and Juntao Dai and Xuehai Pan and Ruiyang Sun and Weidong Huang and Yiran Geng and Mickel Liu and Yaodong Yang},
  journal      = {Journal of Machine Learning Research},
  number       = {285},
  pages        = {1-6},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {OmniSafe: An infrastructure for accelerating safe reinforcement learning research},
  url          = {https://jmlr.org/papers/v25/23-0681.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Random smoothing regularization in kernel gradient descent
learning. <em>JMLR</em>, <em>25</em>(284), 1–88. (<a
href="https://jmlr.org/papers/v25/23-0580.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random smoothing data augmentation is a unique form of regularization that can prevent overfitting by introducing noise to the input data, encouraging the model to learn more generalized features. Despite its success in various applications, there has been a lack of systematic study on the regularization ability of random smoothing. In this paper, we aim to bridge this gap by presenting a framework for random smoothing regularization that can adaptively and effectively learn a wide range of ground truth functions belonging to the classical Sobolev spaces. Specifically, we investigate two underlying function spaces: the Sobolev space of low intrinsic dimension, which includes the Sobolev space in D-dimensional Euclidean space or low-dimensional sub-manifolds as special cases, and the mixed smooth Sobolev space with a tensor structure. By using random smoothing regularization as novel convolution-based smoothing kernels, we can attain optimal convergence rates in these cases using a kernel gradient descent algorithm, either with early stopping or weight decay. It is noteworthy that our estimator can adapt to the structural assumptions of the underlying data and avoid the curse of dimensionality. This is achieved through various choices of injected noise distributions such as Gaussian, Laplace, or general polynomial noises, allowing for broad adaptation to the aforementioned structural assumptions of the underlying data. The convergence rate depends only on the effective dimension, which may be significantly smaller than the actual data dimension. We conduct numerical experiments on simulated data to validate our theoretical results.},
  archive      = {J_JMLR},
  author       = {Liang Ding and Tianyang Hu and Jiahang Jiang and Donghao Li and Wenjia Wang and Yuan Yao},
  journal      = {Journal of Machine Learning Research},
  number       = {284},
  pages        = {1-88},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Random smoothing regularization in kernel gradient descent learning},
  url          = {https://jmlr.org/papers/v25/23-0580.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MLRegTest: A benchmark for the machine learning of regular
languages. <em>JMLR</em>, <em>25</em>(283), 1–45. (<a
href="https://jmlr.org/papers/v25/23-0518.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic datasets constructed from formal languages allow fine-grained examination of the learning and generalization capabilities of machine learning systems for sequence classification. This article presents a new benchmark for machine learning systems on sequence classification called MLRegTest, which contains training, development, and test sets from 1,800 regular languages. Different kinds of formal languages represent different kinds of long-distance dependencies, and correctly identifying long-distance dependencies in sequences is a known challenge for ML systems to generalize successfully. MLRegTest organizes its languages according to their logical complexity (monadic second order, first order, propositional, or restricted propositional) and the kind of logical literals (string, tier-string, subsequence, or combinations thereof). The logical complexity and choice of literal provides a systematic way to understand different kinds of long-distance dependencies in regular languages, and therefore to understand the capacities of different ML systems to learn such long-distance dependencies. Finally, the performance of different neural networks (simple RNN, LSTM, GRU, transformer) on MLRegTest is examined. The main conclusion is that performance depends significantly on the kind of test set, the class of language, and the neural network architecture.},
  archive      = {J_JMLR},
  author       = {Sam van der Poel and Dakotah Lambert and Kalina Kostyszyn and Tiantian Gao and Rahul Verma and Derek Andersen and Joanne Chau and Emily Peterson and Cody St. Clair and Paul Fodor and Chihiro Shibata and Jeffrey Heinz},
  journal      = {Journal of Machine Learning Research},
  number       = {283},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {MLRegTest: A benchmark for the machine learning of regular languages},
  url          = {https://jmlr.org/papers/v25/23-0518.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A tensor factorization model of multilayer network
interdependence. <em>JMLR</em>, <em>25</em>(282), 1–54. (<a
href="https://jmlr.org/papers/v25/23-0205.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilayer networks describe the rich ways in which nodes are related by accounting for different relationships in separate layers. These multiple relationships are naturally represented by an adjacency tensor. In this work we study the use of the nonnegative Tucker decomposition (NNTuck) of such tensors under a KL loss as an expressive factor model that naturally generalizes existing stochastic block models of multilayer networks. Quantifying interdependencies between layers can identify redundancies in the structure of a network, indicate relationships between disparate layers, and potentially inform survey instruments for collecting social network data. We propose definitions of layer independence, dependence, and redundancy based on likelihood ratio tests between nested nonnegative Tucker decompositions. Using both synthetic and real-world data, we evaluate the use and interpretation of the NNTuck as a model of multilayer networks. Algorithmically, we show that using expectation maximization (EM) to maximize the log-likelihood under the NNTuck is step-by-step equivalent to tensorial multiplicative updates for the NNTuck under a KL loss, extending a previously known equivalence from nonnegative matrices to nonnegative tensors.},
  archive      = {J_JMLR},
  author       = {Izabel Aguiar and Dane Taylor and Johan Ugander},
  journal      = {Journal of Machine Learning Research},
  number       = {282},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A tensor factorization model of multilayer network interdependence},
  url          = {https://jmlr.org/papers/v25/23-0205.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stationary kernels and gaussian processes on lie groups and
their homogeneous spaces i: The compact case. <em>JMLR</em>,
<em>25</em>(280), 1–52. (<a
href="https://jmlr.org/papers/v25/22-1434.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian processes are arguably the most important class of spatiotemporal models within machine learning. They encode prior information about the modeled function and can be used for exact or approximate Bayesian learning. In many applications, particularly in physical sciences and engineering, but also in areas such as geostatistics and neuroscience, invariance to symmetries is one of the most fundamental forms of prior information one can consider. The invariance of a Gaussian process&#39; covariance to such symmetries gives rise to the most natural generalization of the concept of stationarity to such spaces. In this work, we develop constructive and practical techniques for building stationary Gaussian processes on a very large class of non-Euclidean spaces arising in the context of symmetries. Our techniques make it possible to (i) calculate covariance kernels and (ii) sample from prior and posterior Gaussian processes defined on such spaces, both in a practical manner. This work is split into two parts, each involving different technical considerations: part I studies compact spaces, while part II studies non-compact spaces possessing certain structure. Our contributions make the non-Euclidean Gaussian process models we study compatible with well-understood computational techniques available in standard Gaussian process software packages, thereby making them accessible to practitioners.},
  archive      = {J_JMLR},
  author       = {Iskander Azangulov and Andrei Smolensky and Alexander Terenin and Viacheslav Borovitskiy},
  journal      = {Journal of Machine Learning Research},
  number       = {280},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Stationary kernels and gaussian processes on lie groups and their homogeneous spaces i: The compact case},
  url          = {https://jmlr.org/papers/v25/22-1434.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On doubly robust inference for double machine learning in
semiparametric regression. <em>JMLR</em>, <em>25</em>(279), 1–46. (<a
href="https://jmlr.org/papers/v25/22-1233.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to concerns about parametric model misspecification, there is interest in using machine learning to adjust for confounding when evaluating the causal effect of an exposure on an outcome. Unfortunately, exposure effect estimators that rely on machine learning predictions are generally subject to so-called plug-in bias, which can render naive p-values and confidence intervals invalid. Progress has been made via proposals like targeted minimum loss estimation and more recently double machine learning, which rely on learning the conditional mean of both the outcome and exposure. Valid inference can then be obtained so long as both predictions converge (sufficiently fast) to the truth. Focusing on partially linear regression models, we show that a specific implementation of the machine learning techniques can yield exposure effect estimators that have small bias even when one of the first-stage predictions does not converge to the truth. The resulting tests and confidence intervals are doubly robust. We also show that the proposed estimators may fail to be regular when only one nuisance parameter is consistently estimated; nevertheless, we observe in simulation studies that our proposal can lead to reduced bias and improved confidence interval coverage in moderate-to-large samples.},
  archive      = {J_JMLR},
  author       = {Oliver Dukes and Stijn Vansteelandt and David Whitney},
  journal      = {Journal of Machine Learning Research},
  number       = {279},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On doubly robust inference for double machine learning in semiparametric regression},
  url          = {https://jmlr.org/papers/v25/22-1233.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep neural network approximation of invariant functions
through dynamical systems. <em>JMLR</em>, <em>25</em>(278), 1–57. (<a
href="https://jmlr.org/papers/v25/22-0982.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the approximation of functions which are invariant with respect to certain permutations of the input indices using flow maps of dynamical systems. Such invariant functions include the much studied translation-invariant ones involving image tasks, but also encompasses many permutation-invariant functions that find emerging applications in science and engineering. We prove sufficient conditions for universal approximation of these functions by a controlled dynamical system, which can be viewed as a general abstraction of deep residual networks with symmetry constraints. These results not only imply the universal approximation for a variety of commonly employed neural network architectures for symmetric function approximation, but also guide the design of architectures with approximation guarantees for applications involving new symmetry requirements.},
  archive      = {J_JMLR},
  author       = {Qianxiao Li and Ting Lin and Zuowei Shen},
  journal      = {Journal of Machine Learning Research},
  number       = {278},
  pages        = {1-57},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Deep neural network approximation of invariant functions through dynamical systems},
  url          = {https://jmlr.org/papers/v25/22-0982.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A statistical experimental design method for constructing
deterministic sensing matrices for compressed sensing. <em>JMLR</em>,
<em>25</em>(277), 1–28. (<a
href="https://jmlr.org/papers/v25/22-0760.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressed sensing is a signal processing technique used to efficiently acquire and reconstruct signals across various fields, including science, engineering, and business. A critical research challenge in compressed sensing is constructing a sensing matrix with desirable reconstruction properties. For optimal performance, the reconstruction process requires the sensing matrix to have low coherence. Several methods have been proposed to create deterministic sensing matrices. We propose a new statistical method to construct deterministic sensing matrices by intelligently sampling rows of Walsh-Hadamard matrices. Compared to existing methods, our approach yields sensing matrices with lower coherence, accommodates a more flexible number of measurements, and entails lower computational cost.},
  archive      = {J_JMLR},
  author       = {Youran Qi and Xu He and Tzu-Hsiang Hung and Peter Chien},
  journal      = {Journal of Machine Learning Research},
  number       = {277},
  pages        = {1-28},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A statistical experimental design method for constructing deterministic sensing matrices for compressed sensing},
  url          = {https://jmlr.org/papers/v25/22-0760.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Functional optimal transport: Regularized map estimation and
domain adaptation for functional data. <em>JMLR</em>, <em>25</em>(276),
1–49. (<a href="https://jmlr.org/papers/v25/22-0217.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a formulation of regularized optimal transport problem for distributions on function spaces, where the stochastic map between functional domains can be approximated in terms of an (infinite-dimensional) Hilbert-Schmidt operator mapping a Hilbert space of functions to another. For numerous machine learning applications, data can be naturally viewed as samples drawn from spaces of functions, such as curves and surfaces, in high dimensions. Optimal transport for functional data analysis provides a useful framework of treatment for such domains. Since probability measures in infinite dimensional spaces generally lack absolute continuity (i.e., with respect to non-degenerate Gaussian measures), the Monge map in the standard optimal transport theory for finite dimensional spaces typically does not exist in the functional settings arising in such machine learning applications. This necessitates a suitable notion of approximation for the best pushforward measure to be obtained via a transport map. Indeed, our approach to the transportation problem in functional spaces is by a suitable regularization technique --- we restrict the class of transport maps to be a Hilbert-Schmidt space of operators.Within this regularization framework, we develop an efficient algorithm for finding the stochastic transport map between functional domains and provide theoretical guarantees on the existence, uniqueness, and consistency of our estimate for the Hilbert-Schmidt space of compact linear operators. We validate our method on synthetic datasets and examine the functional properties of the transport map. Experiments on real-world datasets of robot arm trajectories further demonstrate the effectiveness of our method on applications in domain adaptation.},
  archive      = {J_JMLR},
  author       = {Jiacheng Zhu and Aritra Guha and Dat Do and Mengdi Xu and XuanLong Nguyen and Ding Zhao},
  journal      = {Journal of Machine Learning Research},
  number       = {276},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Functional optimal transport: Regularized map estimation and domain adaptation for functional data},
  url          = {https://jmlr.org/papers/v25/22-0217.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Desiderata for representation learning: A causal
perspective. <em>JMLR</em>, <em>25</em>(275), 1–65. (<a
href="https://jmlr.org/papers/v25/21-107.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning constructs low-dimensional representations tosummarize essential features of high-dimensional data. This learningproblem is often approached by describing various desiderataassociated with learned representations; e.g., that they benon-spurious, efficient, or disentangled. It can be challenging,however, to turn these intuitive desiderata into formal criteria thatcan be measured and enhanced based on observed data. In this paper,we take a causal perspective on representation learning, formalizingnon-spuriousness and efficiency (in supervised representationlearning) and disentanglement (in unsupervised representationlearning) using counterfactual quantities and observable consequencesof causal assertions. This yields computable metrics that can be usedto assess the degree to which representations satisfy the desiderataof interest and learn non-spurious and disentangled representationsfrom single observational datasets.},
  archive      = {J_JMLR},
  author       = {Yixin Wang and Michael I. Jordan},
  journal      = {Journal of Machine Learning Research},
  number       = {275},
  pages        = {1-65},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Desiderata for representation learning: A causal perspective},
  url          = {https://jmlr.org/papers/v25/21-107.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerated gradient tracking over time-varying graphs for
decentralized optimization. <em>JMLR</em>, <em>25</em>(274), 1–52. (<a
href="https://jmlr.org/papers/v25/21-0475.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized optimization over time-varying graphs has been increasingly common in modern machine learning with massive data stored on millions of mobile devices, such as in federated learning. This paper revisits the widely used accelerated gradient tracking and extends it to time-varying graphs. We prove that the practical single loop accelerated gradient tracking needs $O((\frac{\gamma}{1-\sigma_{\gamma}})^2\sqrt{\frac{L}{\epsilon}})$ and $O((\frac{\gamma}{1-\sigma_{\gamma}})^{1.5}\sqrt{\frac{L}{\mu}}\log\frac{1}{\epsilon})$ iterations to reach an $\epsilon$-optimal solution over time-varying graphs when the problems are nonstrongly convex and strongly convex, respectively, where $\gamma$ and $\sigma_{\gamma}$ are two common constants charactering the network connectivity, $L$ and $\mu$ are the smoothness and strong convexity constants, respectively, and one iteration corresponds to one gradient oracle call and one communication round. Our convergence rates improve significantly over the ones of $O(\frac{1}{\epsilon^{5/7}})$ and $O((\frac{L}{\mu})^{5/7}\frac{1}{(1-\sigma)^{1.5}}\log\frac{1}{\epsilon})$, respectively, which were proved in the original literature of accelerated gradient tracking only for static graphs, where $\frac{\gamma}{1-\sigma_{\gamma}}$ equals $\frac{1}{1-\sigma}$ when the network is time-invariant. When combining with a multiple consensus subroutine, the dependence on the network connectivity constants can be further improved to $O(1)$ and $O(\frac{\gamma}{1-\sigma_{\gamma}})$ for the gradient oracle and communication round complexities, respectively. When the network is static, by employing the Chebyshev acceleration, our complexities exactly match the lower bounds without hiding any poly-logarithmic factor for both nonstrongly convex and strongly convex problems.},
  archive      = {J_JMLR},
  author       = {Huan Li and Zhouchen Lin},
  journal      = {Journal of Machine Learning Research},
  number       = {274},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Accelerated gradient tracking over time-varying graphs for decentralized optimization},
  url          = {https://jmlr.org/papers/v25/21-0475.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pearl: A production-ready reinforcement learning agent.
<em>JMLR</em>, <em>25</em>(273), 1–30. (<a
href="https://jmlr.org/papers/v25/24-0196.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) is a versatile framework for optimizing long-term goals. Although many real-world problems can be formalized with RL, learning and deploying a performant RL policy requires a system designed to address several important challenges, including the exploration-exploitation dilemma, partial observability, dynamic action spaces, and safety concerns. While the importance of these challenges has been well recognized, existing open-source RL libraries do not explicitly address them. This paper introduces Pearl, a Production-Ready RL software package designed to embrace these challenges in a modular way. In addition to presenting benchmarking results, we also highlight examples of Pearl&#39;s ongoing industry adoption to demonstrate its advantages for production use cases. Pearl is open sourced on GitHub at github.com/facebookresearch/pearl and its official website is pearlagent.github.io.},
  archive      = {J_JMLR},
  author       = {Zheqing Zhu and Rodrigo de Salvo Braz and Jalaj Bhandari and Daniel Jiang and Yi Wan and Yonathan Efroni and Liyuan Wang and Ruiyang Xu and Hongbo Guo and Alex Nikulkov and Dmytro Korenkevych and Urun Dogan and Frank Cheng and Zheng Wu and Wanqiao Xu},
  journal      = {Journal of Machine Learning Research},
  number       = {273},
  pages        = {1-30},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Pearl: A production-ready reinforcement learning agent},
  url          = {https://jmlr.org/papers/v25/24-0196.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boundary constrained gaussian processes for robust
physics-informed machine learning of linear partial differential
equations. <em>JMLR</em>, <em>25</em>(272), 1–61. (<a
href="https://jmlr.org/papers/v25/23-1508.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a framework for designing boundary constrained Gaussian process (BCGP) priors for exact enforcement of linear boundary conditions, and apply it to the machine learning of (initial) boundary value problems involving linear partial differential equations (PDEs).In contrast to existing work, we illustrate how to design boundary constrained mean and kernel functions for all classes of boundary conditions typically used in PDE modelling, namely Dirichlet, Neumann, Robin and mixed conditions. Importantly, this is done in a manner which allows for both forward and inverse problems to be naturally accommodated. We prove that the BCGP kernel has a universal representational capacity under Dirichlet conditions, and establish a formal equivalence between BCGPs and boundary-constrained neural networks (BCNNs) of infinite width.Finally, extensive numerical experiments are performed involving several linear PDEs, the results of which demonstrate the effectiveness and robustness of BCGP inference in the presence of sparse, noisy data.},
  archive      = {J_JMLR},
  author       = {David Dalton and Alan Lazarus and Hao Gao and Dirk Husmeier},
  journal      = {Journal of Machine Learning Research},
  number       = {272},
  pages        = {1-61},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Boundary constrained gaussian processes for robust physics-informed machine learning of linear partial differential equations},
  url          = {https://jmlr.org/papers/v25/23-1508.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Almost sure convergence rates analysis and saddle avoidance
of stochastic gradient methods. <em>JMLR</em>, <em>25</em>(271), 1–40.
(<a href="https://jmlr.org/papers/v25/23-1436.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vast majority of convergence rates analysis for stochastic gradient methods in the literature focus on convergence in expectation, whereas trajectory-wise almost sure convergence is clearly important to ensure that any instantiation of the stochastic algorithms would converge with probability one. Here we provide a unified almost sure convergence rates analysis for stochastic gradient descent (SGD), stochastic heavy-ball (SHB), and stochastic Nesterov&#39;s accelerated gradient (SNAG) methods. We show, for the first time, that the almost sure convergence rates obtained for these stochastic gradient methods on strongly convex functions, are arbitrarily close to their optimal convergence rates possible. For non-convex objective functions, we not only show that a weighted average of the squared gradient norms converges to zero almost surely, but also the last iterates of the algorithms. We further provide last-iterate almost sure convergence rates analysis for stochastic gradient methods on general convex smooth functions, in contrast with most existing results in the literature that only provide convergence in expectation for a weighted average of the iterates. The last-iterate almost sure convergence results also enable us to obtain almost sure avoidance of any strict saddle manifold by stochastic gradient methods with or without momentum. To the best of our knowledge, this is the first time such results are obtained for SHB and SNAG methods.},
  archive      = {J_JMLR},
  author       = {Jun Liu and Ye Yuan},
  journal      = {Journal of Machine Learning Research},
  number       = {271},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Almost sure convergence rates analysis and saddle avoidance of stochastic gradient methods},
  url          = {https://jmlr.org/papers/v25/23-1436.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). False discovery proportion envelopes with m-consistency.
<em>JMLR</em>, <em>25</em>(270), 1–52. (<a
href="https://jmlr.org/papers/v25/23-1025.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide new nonasymptotic false discovery proportion (FDP) confidence envelopes in several multiple testing settings relevant for modern high dimensional-data methods. We revisit the multiple testing scenarios considered in the recent work of Katsevich and Ramdas (2020): top-$k$, preordered (including knockoffs), online. Our emphasis is on obtaining FDP confidence bounds that both have non-asymptotical coverage and are asymptotically accurate in a specific sense, as the number $m$ of tested hypotheses grows. Namely, we introduce and study the property (which we call $m$-consistency) that the confidence bound converges to or below the desired level $\alpha$ when applied to a specific reference $\alpha$-level false discovery rate (FDR) controlling procedure. In this perspective, we derive new bounds that provide improvements over existing ones, both theoretically and practically, and are suitable for situations where at least a moderate number of rejections is expected. These improvements are illustrated with numerical experiments and real data examples. In particular, the improvement is significant in the knockoffs setting, which shows the impact of the method for a practical use. As side results, we introduce a new confidence envelope for the empirical cumulative distribution function of i.i.d. uniform variables, and we provide new power results in sparse cases, both being of independent interest.},
  archive      = {J_JMLR},
  author       = {Meah Iqraa and Blanchard Gilles and Roquain Etienne},
  journal      = {Journal of Machine Learning Research},
  number       = {270},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {False discovery proportion envelopes with m-consistency},
  url          = {https://jmlr.org/papers/v25/23-1025.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wasserstein proximal coordinate gradient algorithms.
<em>JMLR</em>, <em>25</em>(269), 1–66. (<a
href="https://jmlr.org/papers/v25/23-0889.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by approximation Bayesian computation using mean-field variational approximation and the computation of equilibrium in multi-species systems with cross-interaction, this paper investigates the composite geodesically convex optimization problem over multiple distributions. The objective functional under consideration is composed of a convex potential energy on a product of Wasserstein spaces and a sum of convex self-interaction and internal energies associated with each distribution. To efficiently solve this problem, we introduce the Wasserstein Proximal Coordinate Gradient (WPCG) algorithms with parallel, sequential, and random update schemes. Under a quadratic growth (QG) condition that is weaker than the usual strong convexity requirement on the objective functional, we show that WPCG converges exponentially fast to the unique global optimum. In the absence of the QG condition, WPCG is still demonstrated to converge to the global optimal solution, albeit at a slower polynomial rate. Numerical results for both motivating examples are consistent with our theoretical findings.},
  archive      = {J_JMLR},
  author       = {Rentian Yao and Xiaohui Chen and Yun Yang},
  journal      = {Journal of Machine Learning Research},
  number       = {269},
  pages        = {1-66},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Wasserstein proximal coordinate gradient algorithms},
  url          = {https://jmlr.org/papers/v25/23-0889.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Concentration and moment inequalities for general functions
of independent random variables with heavy tails. <em>JMLR</em>,
<em>25</em>(268), 1–33. (<a
href="https://jmlr.org/papers/v25/23-0744.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concentration of measure phenomenon serves an essential role in statistics and machine learning. This paper gives bounded difference-type concentration and moment inequalities for general functions of independent random variables with heavy tails. A general framework is presented, which can be used to prove inequalities for general functions once the moment inequality for sums of independent random variables is established. We illustrate the power of the framework by showing how it can be used to derive novel concentration and moment inequalities for bounded, Bernstein&#39;s moment condition, weak-exponential, and polynomial-moment random variables. Furthermore, we give potential applications of these inequalities to statistical learning theory.},
  archive      = {J_JMLR},
  author       = {Shaojie Li and Yong Liu},
  journal      = {Journal of Machine Learning Research},
  number       = {268},
  pages        = {1-33},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Concentration and moment inequalities for general functions of independent random variables with heavy tails},
  url          = {https://jmlr.org/papers/v25/23-0744.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Random fully connected neural networks as perturbatively
solvable hierarchies. <em>JMLR</em>, <em>25</em>(267), 1–58. (<a
href="https://jmlr.org/papers/v25/23-0643.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the distribution of fully connected neural networks with Gaussian random weights/biases and L hidden layers, each of width proportional to a large parameter n. For polynomially bounded non-linearities we give sharp estimates in powers of 1/n for the joint cumulants of the network output and its derivatives. We further show that network cumulants form a perturbatively solvable hierarchy in powers of 1/n. That is, the k-th order cumulants in each layer are determined to leading order in 1/n by cumulants of order at most k computed at the previous layer. By explicitly deriving and then solving several such recursions, we find that the depth-to-width ratio L/n plays the role of an effective network depth, controlling both the distance to Gaussianity and the size of inter-neuron correlations.},
  archive      = {J_JMLR},
  author       = {Boris Hanin},
  journal      = {Journal of Machine Learning Research},
  number       = {267},
  pages        = {1-58},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Random fully connected neural networks as perturbatively solvable hierarchies},
  url          = {https://jmlr.org/papers/v25/23-0643.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On regularized radon-nikodym differentiation. <em>JMLR</em>,
<em>25</em>(266), 1–24. (<a
href="https://jmlr.org/papers/v25/23-0567.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss the problem of estimating Radon-Nikodym derivatives. This problem appears in various applications, such as covariate shift adaptation, likelihood-ratio testing, mutual information estimation, and conditional probability estimation. However, in many of the above applications one is interested in the pointwise evaluation of the Radon-Nikodym derivatives rather than in their approximation as elements of some spaces of functions, and this aspect has been left unexplored in the previous studies. To address the above problem, we employ the general regularization scheme in reproducing kernel Hilbert spaces. The convergence rate of the corresponding regularized algorithm is established by taking into account both the smoothness of the derivative and the capacity of the space in which it is estimated. This is done in terms of general source conditions and the regularized Christoffel functions. We also find that the reconstruction of Radon-Nikodym derivatives at any particular point can be done with higher order of accuracy as compared to the reported work available so far. Our theoretical results are illustrated by numerical simulations.},
  archive      = {J_JMLR},
  author       = {Duc Hoan Nguyen and Werner Zellinger and Sergei Pereverzyev},
  journal      = {Journal of Machine Learning Research},
  number       = {266},
  pages        = {1-24},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On regularized radon-nikodym differentiation},
  url          = {https://jmlr.org/papers/v25/23-0567.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pgmpy: A python toolkit for bayesian networks.
<em>JMLR</em>, <em>25</em>(265), 1–8. (<a
href="https://jmlr.org/papers/v25/23-0487.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian Networks (BNs) are used in various fields for modeling, prediction, and decision making. pgmpy is a python package that provides a collection of algorithms and tools to work with BNs and related models. It implements algorithms for structure learning, parameter estimation, approximate and exact inference, causal inference, and simulations. These implementations focus on modularity and easy extensibility to allow users to quickly modify/add to existing algorithms, or to implement new algorithms for different use cases. pgmpy is released under the MIT License; the source code is available at: https://github.com/pgmpy/pgmpy, and the documentation at: https://pgmpy.org.},
  archive      = {J_JMLR},
  author       = {Ankur Ankan and Johannes Textor},
  journal      = {Journal of Machine Learning Research},
  number       = {265},
  pages        = {1-8},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Pgmpy: A python toolkit for bayesian networks},
  url          = {https://jmlr.org/papers/v25/23-0487.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recursive estimation of conditional kernel mean embeddings.
<em>JMLR</em>, <em>25</em>(264), 1–35. (<a
href="https://jmlr.org/papers/v25/23-0168.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel mean embeddings, a widely used technique in machine learning, map probability distributions to elements of a reproducing kernel Hilbert space (RKHS). For supervised learning problems, where input-output pairs are observed, the conditional distribution of outputs given the inputs is a key object. The input dependent conditional distribution of an output can be encoded with an RKHS valued function, the conditional kernel mean map. In this paper we present a new recursive algorithm to estimate the conditional kernel mean map in a Hilbert space valued $L_2$ space, that is in a Bochner space. We prove the weak and strong $L_2$ consistency of our recursive estimator under mild conditions. The idea is to generalize Stone&#39;s theorem for Hilbert space valued regression in a locally compact Polish space. We present new insights about conditional kernel mean embeddings and give strong asymptotic bounds regarding the convergence of the proposed recursive method. Finally, the results are demonstrated on three application domains: for inputs coming from Euclidean spaces, Riemannian manifolds and locally compact subsets of function spaces.},
  archive      = {J_JMLR},
  author       = {Ambrus Tamás and Balázs Csanád Csáji},
  journal      = {Journal of Machine Learning Research},
  number       = {264},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Recursive estimation of conditional kernel mean embeddings},
  url          = {https://jmlr.org/papers/v25/23-0168.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Penalized overdamped and underdamped langevin monte carlo
algorithms for constrained sampling. <em>JMLR</em>, <em>25</em>(263),
1–67. (<a href="https://jmlr.org/papers/v25/22-1443.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the constrained sampling problem where the goal is to sample from a target distribution $\pi(x)\propto e^{-f(x)}$ when $x$ is constrained to lie on a convex body $C\subset \mathbb{R}^d$. Motivated by penalty methods from continuous optimization, we propose and study penalized Langevin Dynamics (PLD) and penalized underdamped Langevin Monte Carlo (PULMC) methods for constrained sampling that convert the constrained sampling problem into an unconstrained sampling problem by introducing a penalty function for constraint violations. When $f$ is smooth and gradients of $f$ are available, we show ${\tilde{O}}(d/\varepsilon^{10})$ iteration complexity for PLD to sample the target up to an $\varepsilon$-error where the error is measured in terms of the total variation distance and $\tilde{O}(\cdot)$ hides some logarithmic factors. For PULMC, we improve this result to $\tilde{O}(\sqrt{d}/\varepsilon^{7})$ when the Hessian of $f$ is Lipschitz and the boundary of $C$ is sufficiently smooth. To our knowledge, these are the first convergence rate results for underdamped Langevin Monte Carlo methods in the constrained sampling setting that can handle non-convex choices of $f$ and can provide guarantees with the best dimension dependency among existing methods for constrained sampling when the gradients are deterministically available. We then consider the setting where only unbiased stochastic estimates of the gradients of $f$ are available, motivated by applications to large-scale Bayesian learning problems. We propose PSGLD and PSGULMC methods that are variants of PLD and PULMC that can handle stochastic gradients and that are scaleable to large datasets without requiring Metropolis-Hasting correction steps. For PSGLD and PSGULMC, when $f$ is strongly convex and smooth, we obtain an iteration complexity of $\tilde{O}(d/\varepsilon^{18})$ and $\tilde{O}(d\sqrt{d}/\varepsilon^{39})$ respectively in the 2-Wasserstein distance. For the more general case, when $f$ is smooth and $f$ can be non-convex, we also provide finite-time performance bounds and iteration complexity results. Finally, we illustrate the performance of our algorithms on Bayesian LASSO regression and Bayesian constrained deep learning problems.},
  archive      = {J_JMLR},
  author       = {Mert Gurbuzbalaban and Yuanhan Hu and Lingjiong Zhu},
  journal      = {Journal of Machine Learning Research},
  number       = {263},
  pages        = {1-67},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Penalized overdamped and underdamped langevin monte carlo algorithms for constrained sampling},
  url          = {https://jmlr.org/papers/v25/22-1443.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast rates in pool-based batch active learning.
<em>JMLR</em>, <em>25</em>(262), 1–42. (<a
href="https://jmlr.org/papers/v25/22-1409.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a batch active learning scenario where the learner adaptively issues batches of points to a labeling oracle. Sampling labels in batches is highly desirable in practice due to the smaller number of interactive rounds with the labeling oracle (often human beings). However, batch active learning typically pays the price of a reduced adaptivity, leading to suboptimal results. In this paper we propose a solution which requires a careful trade off between the informativeness of the queried points and their diversity. We theoretically investigate batch active learning in the practically relevant scenario where the unlabeled pool of data is available beforehand (pool-based active learning). We analyze a novel stage-wise greedy algorithm and show that, as a function of the label complexity, the excess risk of this algorithm matches the known minimax rates in a standard statistical learning setting with linear function spaces. Our results also exhibit a mild dependence on the batch size. These initial results are then extended to hold for general function spaces with similar algorithmics. These are the first theoretical results that employ careful trade offs between informativeness and diversity to rigorously quantify the statistical performance of batch active learning in the pool-based scenario.},
  archive      = {J_JMLR},
  author       = {Claudio Gentile and Zhilei Wang and Tong Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {262},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fast rates in pool-based batch active learning},
  url          = {https://jmlr.org/papers/v25/22-1409.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On causality in domain adaptation and semi-supervised
learning: An information-theoretic analysis for parametric models.
<em>JMLR</em>, <em>25</em>(261), 1–57. (<a
href="https://jmlr.org/papers/v25/22-1024.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in unsupervised domain adaptation (UDA) and semi-supervised learning (SSL), particularly incorporating causality, have led to significant methodological improvements in these learning problems. However, a formal theory that explains the role of causality in the generalization performance of UDA/SSL is still lacking. In this paper, we consider the UDA/SSL scenarios where we access $m$ labelled source data and $n$ unlabelled target data as training instances under different causal settings with a parametric probabilistic model. We study the learning performance (e.g., excess risk) of prediction in the target domain from an information-theoretic perspective. Specifically, we distinguish two scenarios: the learning problem is called causal learning if the feature is the cause and the label is the effect, and is called anti-causal learning otherwise. We show that in causal learning, the excess risk depends on the size of the source sample at a rate of $O(\frac{1}{m})$ only if the labelling distribution between the source and target domains remains unchanged. In anti-causal learning, we show that the unlabelled data dominate the performance at a rate of typically $O(\frac{1}{n})$. These results bring out the relationship between the data sample size and the hardness of the learning problem with different causal mechanisms.},
  archive      = {J_JMLR},
  author       = {Xuetong Wu and Mingming Gong and Jonathan H. Manton and Uwe Aickelin and Jingge Zhu},
  journal      = {Journal of Machine Learning Research},
  number       = {261},
  pages        = {1-57},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On causality in domain adaptation and semi-supervised learning: An information-theoretic analysis for parametric models},
  url          = {https://jmlr.org/papers/v25/22-1024.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mean-field approximation of cooperative constrained
multi-agent reinforcement learning (CMARL). <em>JMLR</em>,
<em>25</em>(260), 1–33. (<a
href="https://jmlr.org/papers/v25/22-0956.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mean-Field Control (MFC) has recently been proven to be a scalable tool to approximately solve large-scale multi-agent reinforcement learning (MARL) problems. However, these studies are typically limited to unconstrained cumulative reward maximization framework. In this paper, we show that one can use the MFC approach to approximate the MARL problem even in the presence of constraints. Specifically, we prove that, an $N$-agent constrained MARL problem, with state, and action spaces of each individual agents being of sizes $|\mathcal{X}|$, and $|\mathcal{U}|$ respectively, can be approximated by an associated constrained MFC problem with an error, $e\triangleq \mathcal{O}\left([\sqrt{|\mathcal{X}|}+\sqrt{|\mathcal{U}|}]/\sqrt{N}\right)$. In a special case where the reward, cost, and state transition functions are independent of the action distribution of the population, we prove that the error can be improved to $e=\mathcal{O}(\sqrt{|\mathcal{X}|}/\sqrt{N})$. Also, we provide a Natural Policy Gradient based algorithm, and prove that it can solve the constrained MARL problem within an error of $\mathcal{O}(e)$ with a sample complexity of $\mathcal{O}(e^{-6})$.},
  archive      = {J_JMLR},
  author       = {Washim Uddin Mondal and Vaneet Aggarwal and Satish V. Ukkusuri},
  journal      = {Journal of Machine Learning Research},
  number       = {260},
  pages        = {1-33},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Mean-field approximation of cooperative constrained multi-agent reinforcement learning (CMARL)},
  url          = {https://jmlr.org/papers/v25/22-0956.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structured optimal variational inference for dynamic latent
space models. <em>JMLR</em>, <em>25</em>(259), 1–55. (<a
href="https://jmlr.org/papers/v25/22-0514.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a latent space model for dynamic networks, where our objective is to estimate the pairwise inner products plus the intercept of the latent positions. To balance posterior inference and computational scalability, we consider a structured mean-field variational inference framework, where the time-dependent properties of the dynamic networks are exploited to facilitate computation and inference. Additionally, an easy-to-implement block coordinate ascent algorithm is developed with message-passing type updates in each block, whereas the complexity per iteration is linear with the number of nodes and time points. To certify the optimality, we demonstrate that the variational risk of the proposed variational inference approach attains the minimax optimal rate with only a logarithm factor under certain conditions. To this end, we first derive the minimax lower bound, which might be of independent interest. In addition, we show that the posterior under commonly adopted Gaussian random walk priors can achieve the minimax lower bound with only a logarithm factor. To the best of our knowledge, this is the first such a throughout theoretical analysis of Bayesian dynamic latent space models. Simulations and real data analysis demonstrate the efficacy of our methodology and the efficiency of our algorithm.},
  archive      = {J_JMLR},
  author       = {Peng Zhao and Anirban Bhattacharya and Debdeep Pati and Bani K. Mallick},
  journal      = {Journal of Machine Learning Research},
  number       = {259},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Structured optimal variational inference for dynamic latent space models},
  url          = {https://jmlr.org/papers/v25/22-0514.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stable and consistent density-based clustering via
multiparameter persistence. <em>JMLR</em>, <em>25</em>(258), 1–74. (<a
href="https://jmlr.org/papers/v25/21-1185.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the degree-Rips construction from topological data analysis, which provides a density-sensitive, multiparameter hierarchical clustering algorithm. We analyze its stability to perturbations of the input data using the correspondence-interleaving distance, a metric for hierarchical clusterings that we introduce. Taking certain one-parameter slices of degree-Rips recovers well-known methods for density-based clustering, but we show that these methods are unstable. However, we prove that degree-Rips, as a multiparameter object, is stable, and we propose an alternative approach for taking slices of degree-Rips, which yields a one-parameter hierarchical clustering algorithm with better stability properties. We prove that this algorithm is consistent, using the correspondence-interleaving distance. We provide an algorithm for extracting a single clustering from one-parameter hierarchical clusterings, which is stable with respect to the correspondence-interleaving distance. And, we integrate these methods into a pipeline for density-based clustering, which we call Persistable. Adapting tools from multiparameter persistent homology, we propose visualization tools that guide the selection of all parameters of the pipeline. We demonstrate Persistable on benchmark data sets, showing that it identifies multi-scale cluster structure in data.},
  archive      = {J_JMLR},
  author       = {Alexander Rolle and Luis Scoccola},
  journal      = {Journal of Machine Learning Research},
  number       = {258},
  pages        = {1-74},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Stable and consistent density-based clustering via multiparameter persistence},
  url          = {https://jmlr.org/papers/v25/21-1185.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Faster randomized methods for orthogonality constrained
problems. <em>JMLR</em>, <em>25</em>(257), 1–59. (<a
href="https://jmlr.org/papers/v25/21-1022.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent literature has advocated the use of randomized methods foraccelerating the solution of various matrix problems arising inmachine learning and data science. One popular strategy for leveraging randomization in numerical linear algebra is to use it as a way to reduce problem size. However, methods based on this strategy lack sufficient accuracy for some applications. Randomized preconditioning is another approach for leveraging randomization in numerical linear algebra, which provides higher accuracy. The main challenge in using randomized preconditioning is the need for an underlying iterative method, thus randomized preconditioning so far has been applied almost exclusively to solving regression problems and linear systems. In this article, we show how to expand the application of randomized preconditioning to another important set of problems prevalent in machine learning: optimization problems with (generalized) orthogonality constraints. We demonstrate our approach, which is based on the framework of Riemannian optimization and Riemannian preconditioning, on the problem of computing the dominant canonical correlations and on the Fisher linear discriminant analysis problem. More broadly, our method is designed for problems with input matrices featuring one dimension much larger than the other (e.g., the number of samples much larger than the number of features). For both problems, we evaluate the effect of preconditioning on the computational costs and asymptotic convergenceand demonstrate empirically the utility of our approach.},
  archive      = {J_JMLR},
  author       = {Boris Shustin and Haim Avron},
  journal      = {Journal of Machine Learning Research},
  number       = {257},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Faster randomized methods for orthogonality constrained problems},
  url          = {https://jmlr.org/papers/v25/21-1022.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimation of sparse gaussian graphical models with hidden
clustering structure. <em>JMLR</em>, <em>25</em>(256), 1–36. (<a
href="https://jmlr.org/papers/v25/20-354.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimation of Gaussian graphical models is important in natural science when modeling the statistical relationships between variables in the form of a graph. The sparsity and clustering structure of the concentration matrix is enforced to reduce model complexity and describe inherent regularities. We propose a model to estimate the sparse Gaussian graphical models with hidden clustering structure, which also allows additional linear constraints to be imposed on the concentration matrix. We design an efficient two-phase algorithm for solving the proposed model. Specifically, we develop a symmetric Gauss-Seidel based alternating direction method of multipliers (sGS-ADMM) to generate an initial point to warm start the second phase algorithm, which is a proximal augmented Lagrangian method (pALM), to get a solution with high accuracy. Numerical experiments on both synthetic data and real data demonstrate the good performance of our model, as well as the efficiency and robustness of our proposed algorithm.},
  archive      = {J_JMLR},
  author       = {Meixia Lin and Defeng Sun and Kim-Chuan Toh and Chengjing Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {256},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Estimation of sparse gaussian graphical models with hidden clustering structure},
  url          = {https://jmlr.org/papers/v25/20-354.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking discount regularization: New interpretations,
unintended consequences, and solutions for regularization in
reinforcement learning. <em>JMLR</em>, <em>25</em>(255), 1–48. (<a
href="https://jmlr.org/papers/v25/24-0087.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discount regularization, using a shorter planning horizon when calculating the optimal policy, is a popular choice to avoid overfitting when faced with sparse or noisy data. It is commonly interpreted as de-emphasizing or ignoring delayed effects. In this paper, we prove two alternative views of discount regularization that expose unintended consequences and motivate novel regularization methods. In model-based RL, planning under a lower discount factor acts like a prior with stronger regularization on state-action pairs with more transition data. This leads to poor performance when the transition matrix is estimated from data sets with uneven amounts of data across state-action pairs. In model-free RL, discount regularization equates to planning using a weighted average Bellman update, where the agent plans as if the values of all state-action pairs are closer than implied by the data. Our equivalence theorems motivate simple methods that generalize discount regularization by setting parameters locally for individual state-action pairs rather than globally. We demonstrate the failures of discount regularization and how we remedy them using our state-action-specific methods across empirical examples with both tabular and continuous state spaces.},
  archive      = {J_JMLR},
  author       = {Sarah Rathnam and Sonali Parbhoo and Siddharth Swaroop and Weiwei Pan and Susan A. Murphy and Finale Doshi-Velez},
  journal      = {Journal of Machine Learning Research},
  number       = {255},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Rethinking discount regularization: New interpretations, unintended consequences, and solutions for regularization in reinforcement learning},
  url          = {https://jmlr.org/papers/v25/24-0087.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PromptBench: A unified library for evaluation of large
language models. <em>JMLR</em>, <em>25</em>(254), 1–22. (<a
href="https://jmlr.org/papers/v25/24-0023.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of large language models (LLMs) is crucial to assess their performance and mitigate potential security risks. In this paper, we introduce PromptBench, a unified library to evaluate LLMs. It consists of several key components that can be easily used and extended by researchers: prompt construction, prompt engineering, dataset and model loading, adversarial prompt attack, dynamic evaluation protocols, and analysis tools. PromptBench is designed as an open, general, and flexible codebase for research purpose. It aims to facilitate original study in creating new benchmarks, deploying downstream applications, and designing new evaluation protocols. The code is available at: https://github.com/microsoft/promptbench and will be continuously supported.},
  archive      = {J_JMLR},
  author       = {Kaijie Zhu and Qinlin Zhao and Hao Chen and Jindong Wang and Xing Xie},
  journal      = {Journal of Machine Learning Research},
  number       = {254},
  pages        = {1-22},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {PromptBench: A unified library for evaluation of large language models},
  url          = {https://jmlr.org/papers/v25/24-0023.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gaussian interpolation flows. <em>JMLR</em>,
<em>25</em>(253), 1–52. (<a
href="https://jmlr.org/papers/v25/23-1515.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian denoising has emerged as a powerful method for constructing simulation-free continuous normalizing flows for generative modeling. Despite their empirical successes, theoretical properties of these flows and the regularizing effect of Gaussian denoising have remained largely unexplored. In this work, we aim to address this gap by investigating the well-posedness of simulation-free continuous normalizing flows built on Gaussian denoising. Through a unified framework termed Gaussian interpolation flow, we establish the Lipschitz regularity of the flow velocity field, the existence and uniqueness of the flow, and the Lipschitz continuity of the flow map and the time-reversed flow map for several rich classes of target distributions. This analysis also sheds light on the auto-encoding and cycle consistency properties of Gaussian interpolation flows. Additionally, we study the stability of these flows in source distributions and perturbations of the velocity field, using the quadratic Wasserstein distance as a metric. Our findings offer valuable insights into the learning techniques employed in Gaussian interpolation flows for generative modeling, providing a solid theoretical foundation for end-to-end error analyses of learning Gaussian interpolation flows with empirical observations.},
  archive      = {J_JMLR},
  author       = {Yuan Gao and Jian Huang and and Yuling Jiao},
  journal      = {Journal of Machine Learning Research},
  number       = {253},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Gaussian interpolation flows},
  url          = {https://jmlr.org/papers/v25/23-1515.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gaussian mixture models with rare events. <em>JMLR</em>,
<em>25</em>(252), 1–40. (<a
href="https://jmlr.org/papers/v25/23-1245.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study here a Gaussian mixture model (GMM) with rare events data. In this case, the commonly used Expectation-Maximization (EM) algorithm exhibits extremely slow numerical convergence rate. To theoretically understand this phenomenon, we formulate the numerical convergence problem of the EM algorithm with rare events data as a problem about a contraction operator. Theoretical analysis reveals that the spectral radius of the contraction operator in this case could be arbitrarily close to 1 asymptotically. This theoretical finding explains the empirical slow numerical convergence of the EM algorithm with rare events data. To overcome this challenge, a Mixed EM (MEM) algorithm is developed, which utilizes the information provided by partially labeled data. As compared with the standard EM algorithm, the key feature of the MEM algorithm is that it requires additionally labeled data. We find that MEM algorithm significantly improves the numerical convergence rate as compared with the standard EM algorithm. The finite sample performance of the proposed method is illustrated by both simulation studies and a real-world dataset of Swedish traffic signs.},
  archive      = {J_JMLR},
  author       = {Xuetong Li and Jing Zhou and Hansheng Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {252},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Gaussian mixture models with rare events},
  url          = {https://jmlr.org/papers/v25/23-1245.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the concentration of the minimizers of empirical risks.
<em>JMLR</em>, <em>25</em>(251), 1–53. (<a
href="https://jmlr.org/papers/v25/23-1149.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obtaining guarantees on the convergence of the minimizers of empirical risks to the ones of the true risk is a fundamental matter in statistical learning. Instead of deriving guarantees on the usual estimation error, the goal of this paper is to provide concentration inequalities on the distance between the sets of minimizers of the risks for a broad spectrum of estimation problems. In particular, the risks are defined on metric spaces through probability measures that are also supported on metric spaces. A particular attention will therefore be given to include unbounded spaces and non-convex cost functions that might also be unbounded. This work identifies a set of high-level assumptions allowing to describe a regime that seems to govern the concentration in many estimation problems, where the empirical minimizers are stable. This stability can then be leveraged to prove parametric concentration rates in probability and in expectation. The assumptions are verified, and the bounds showcased, on a selection of estimation problems such as barycenters on metric space with positive or negative curvature, subspaces of covariance matrices, regression problems and entropic-Wasserstein barycenters.},
  archive      = {J_JMLR},
  author       = {Paul Escande},
  journal      = {Journal of Machine Learning Research},
  number       = {251},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the concentration of the minimizers of empirical risks},
  url          = {https://jmlr.org/papers/v25/23-1149.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variance estimation in graphs with the fused lasso.
<em>JMLR</em>, <em>25</em>(250), 1–45. (<a
href="https://jmlr.org/papers/v25/23-1061.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of variance estimation in general graph-structured problems. First, we develop a linear time estimator for the homoscedastic case that can consistently estimate the variance in general graphs. We show that our estimator attains minimax rates for the chain and 2D grid graphs when the mean signal has total variation with canonical scaling. Furthermore, we provide general upper bounds on the mean squared error performance of the fused lasso estimator in general graphs under a moment condition and a bound on the tail behavior of the errors. These upper bounds allow us to generalize for broader classes of distributions, such as sub-Exponential, many existing results on the fused lasso that are only known to hold with the assumption that errors are sub-Gaussian random variables. Exploiting our upper bounds, we then study a simple total variation regularization estimator for estimating the signal of variances in the heteroscedastic case. We also provide lower bounds showing that our heteroscedastic variance estimator attains minimax rates for estimating signals of bounded variation in grid graphs, and $K$-nearest neighbor graphs, and the estimator is consistent for estimating the variances in any connected graph.},
  archive      = {J_JMLR},
  author       = {Oscar Hernan Madrid Padilla},
  journal      = {Journal of Machine Learning Research},
  number       = {250},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Variance estimation in graphs with the fused lasso},
  url          = {https://jmlr.org/papers/v25/23-1061.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Random measure priors in bayesian recovery from sketches.
<em>JMLR</em>, <em>25</em>(249), 1–53. (<a
href="https://jmlr.org/papers/v25/23-1058.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a Bayesian nonparametric approach to frequency recovery from lossy-compressed discrete data, leveraging all information contained in a sketch obtained through random hashing. By modeling the data points as random samples from an unknown discrete distribution endowed with a Poisson-Kingman prior, we derive the posterior distribution of a symbol&#39;s empirical frequency given the sketch. This leads to principled frequency estimates through mean functionals, e.g., the posterior mean, median and mode. We highlight applications of this general result to Dirichlet process and Pitman-Yor process priors. Notably, we prove that the former prior uniquely satisfies a sufficiency property that simplifies the posterior distribution, while the latter enables a convenient large-sample asymptotic approximation. Additionally, we extend our approach to the problem of cardinality recovery, estimating the number of distinct symbols in the sketched dataset. Our approach to frequency recovery also adapts to a more general “traits” setting, where each data point has integer levels of association with multiple symbols, typically referred to as “traits”. By employing a generalized Indian buffet process, we compute the posterior distribution of a trait&#39;s frequency using both the Poisson and Bernoulli distributions for the trait association levels, respectively yielding exact and approximate posterior frequency distributions.},
  archive      = {J_JMLR},
  author       = {Mario Beraha and Stefano Favaro and Matteo Sesia},
  journal      = {Journal of Machine Learning Research},
  number       = {249},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Random measure priors in bayesian recovery from sketches},
  url          = {https://jmlr.org/papers/v25/23-1058.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From continuous-time formulations to discretization schemes:
Tensor trains and robust regression for BSDEs and parabolic PDEs.
<em>JMLR</em>, <em>25</em>(248), 1–40. (<a
href="https://jmlr.org/papers/v25/23-0982.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The numerical approximation of partial differential equations (PDEs) poses formidable challenges in high dimensions since classical grid-based methods suffer from the so-called curse of dimensionality. Recent attempts rely on a combination of Monte Carlo methods and variational formulations, using neural networks for function approximation. Extending previous work (Richter et al., 2021), we argue that tensor trains provide an appealing framework for parabolic PDEs: The combination of reformulations in terms of backward stochastic differential equations and regression-type methods holds the promise of leveraging latent low-rank structures, enabling both compression and efficient computation. Emphasizing a continuous-time viewpoint, we develop iterative schemes, which differ in terms of computational efficiency and robustness. We demonstrate both theoretically and numerically that our methods can achieve a favorable trade-off between accuracy and computational efficiency. While previous methods have been either accurate or fast, we have identified a novel numerical strategy that can often combine both of these aspects.},
  archive      = {J_JMLR},
  author       = {Lorenz Richter and Leon Sallandt and Nikolas Nüsken},
  journal      = {Journal of Machine Learning Research},
  number       = {248},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {From continuous-time formulations to discretization schemes: Tensor trains and robust regression for BSDEs and parabolic PDEs},
  url          = {https://jmlr.org/papers/v25/23-0982.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label alignment regularization for distribution shift.
<em>JMLR</em>, <em>25</em>(247), 1–32. (<a
href="https://jmlr.org/papers/v25/23-0899.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work has highlighted the label alignment property (LAP) in supervised learning, where the vector of all labels in the dataset is mostly in the span of the top few singular vectors of the data matrix. Drawing inspiration from this observation, we propose a regularization method for unsupervised domain adaptation that encourages alignment between the predictions in the target domain and its top singular vectors. Unlike conventional domain adaptation approaches that focus on regularizing representations, we instead regularize the classifier to align with the unsupervised target data, guided by the LAP in both the source and target domains. Theoretical analysis demonstrates that, under certain assumptions, our solution resides within the span of the top right singular vectors of the target domain data and aligns with the optimal solution. By removing the reliance on the commonly used optimal joint risk assumption found in classic domain adaptation theory, we showcase the effectiveness of our method on addressing problems where traditional domain adaptation methods often fall short due to high joint error. Additionally, we report improved performance over domain adaptation baselines in well-known tasks such as MNIST-USPS domain adaptation and cross-lingual sentiment analysis. An implementation is available at https://github.com/EhsanEI/lar/.},
  archive      = {J_JMLR},
  author       = {Ehsan Imani and Guojun Zhang and Runjia Li and Jun Luo and Pascal Poupart and Philip H.S. Torr and Yangchen Pan},
  journal      = {Journal of Machine Learning Research},
  number       = {247},
  pages        = {1-32},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Label alignment regularization for distribution shift},
  url          = {https://jmlr.org/papers/v25/23-0899.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fairness in survival analysis with distributionally robust
optimization. <em>JMLR</em>, <em>25</em>(246), 1–85. (<a
href="https://jmlr.org/papers/v25/23-0888.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a general approach for encouraging fairness in survival analysis models that is based on minimizing a worst-case error across all subpopulations that are “large enough” (occurring with at least a user-specified probability threshold). This approach can be used to convert a wide variety of existing survival analysis models into ones that simultaneously encourage fairness, without requiring the user to specify which attributes or features to treat as sensitive in the training loss function. From a technical standpoint, our approach applies recent methodological developments of distributionally robust optimization (DRO) to survival analysis. The complication is that existing DRO theory uses a training loss function that decomposes across contributions of individual data points, i.e., any term that shows up in the loss function depends only on a single training point. This decomposition does not hold for commonly used survival loss functions, including for the standard Cox proportional hazards model, its deep neural network variants, and many other recently developed survival analysis models that use loss functions involving ranking or similarity score calculations. We address this technical hurdle using a sample splitting strategy. We demonstrate our sample splitting DRO approach by using it to create fair versions of a diverse set of existing survival analysis models including the classical Cox model (and its deep neural network variant DeepSurv), the discrete-time model DeepHit, and the neural ODE model SODEN. We also establish a finite-sample theoretical guarantee to show what our sample splitting DRO loss converges to. Specifically for the Cox model, we further derive an exact DRO approach that does not use sample splitting. For all the survival models that we convert into DRO variants, we show that the DRO variants often score better on recently established fairness metrics (without incurring a significant drop in accuracy) compared to existing survival analysis fairness regularization techniques, including ones which directly use sensitive demographic information in their training loss functions.},
  archive      = {J_JMLR},
  author       = {Shu Hu and George H. Chen},
  journal      = {Journal of Machine Learning Research},
  number       = {246},
  pages        = {1-85},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fairness in survival analysis with distributionally robust optimization},
  url          = {https://jmlr.org/papers/v25/23-0888.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FineMorphs: Affine-diffeomorphic sequences for regression.
<em>JMLR</em>, <em>25</em>(245), 1–38. (<a
href="https://jmlr.org/papers/v25/23-0824.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multivariate regression model of affine and diffeomorphic transformation sequences—FineMorphs—is presented. Leveraging concepts from shape analysis, model states are optimally &quot;reshaped&quot; by diffeomorphisms generated by smooth vector fields during learning. Affine transformations and vector fields are optimized within an optimal control setting, and the model can naturally reduce (or increase) dimensionality and adapt to large data sets via sub-optimal vector fields. An existence proof of solution and necessary conditions for optimality for the model are derived. Experimental results on real data sets from the UCI repository are presented, with favorable results in comparison with state-of-the-art in the literature, neural ordinary differential equation models, and densely-connected neural networks in TensorFlow.},
  archive      = {J_JMLR},
  author       = {Michele Lohr and Laurent Younes},
  journal      = {Journal of Machine Learning Research},
  number       = {245},
  pages        = {1-38},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {FineMorphs: Affine-diffeomorphic sequences for regression},
  url          = {https://jmlr.org/papers/v25/23-0824.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tensor-train methods for sequential state and parameter
learning in state-space models. <em>JMLR</em>, <em>25</em>(244), 1–51.
(<a href="https://jmlr.org/papers/v25/23-0743.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider sequential state and parameter learning in state-space models with intractable state transition and observation processes. By exploiting low-rank tensor train (TT) decompositions, we propose new sequential learning methods for joint parameter and state estimation under the Bayesian framework. Our key innovation is the introduction of scalable function approximation tools such as TT for recursively learning the sequentially updated posterior distributions. The function approximation perspective of our methods offers tractable error analysis and potentially alleviates the particle degeneracy faced by many particle-based methods. In addition to the new insights into the algorithmic design, our methods complement conventional particle-based methods. Our TT-based approximations naturally define conditional Knothe--Rosenblatt (KR) rearrangements that lead to parameter estimation, filtering, smoothing and path estimation accompanying our sequential learning algorithms, which open the door to removing potential approximation bias. We also explore several preconditioning techniques based on either linear or nonlinear KR rearrangements to enhance the approximation power of TT for practical problems. We demonstrate the efficacy and efficiency of our proposed methods on several state-space models, in which our methods achieve state-of-the-art estimation accuracy and computational performance.},
  archive      = {J_JMLR},
  author       = {Yiran Zhao and Tiangang Cui},
  journal      = {Journal of Machine Learning Research},
  number       = {244},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Tensor-train methods for sequential state and parameter learning in state-space models},
  url          = {https://jmlr.org/papers/v25/23-0743.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Memory of recurrent networks: Do we compute it right?
<em>JMLR</em>, <em>25</em>(243), 1–38. (<a
href="https://jmlr.org/papers/v25/23-0568.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical evaluations of the memory capacity (MC) of recurrent neural networks reported in the literature often contradict well-established theoretical bounds. In this paper, we study the case of linear echo state networks, for which the total memory capacity has been proven to be equal to the rank of the corresponding Kalman controllability matrix. We shed light on various reasons for the inaccurate numerical estimations of the memory, and we show that these issues, often overlooked in the recent literature, are of an exclusively numerical nature. More explicitly, we prove that when the Krylov structure of the linear MC is ignored, a gap between the theoretical MC and its empirical counterpart is introduced. As a solution, we develop robust numerical approaches by exploiting a result of MC neutrality with respect to the input mask matrix. Simulations show that the memory curves that are recovered using the proposed methods fully agree with the theory.},
  archive      = {J_JMLR},
  author       = {Giovanni Ballarin and Lyudmila Grigoryeva and Juan-Pablo Ortega},
  journal      = {Journal of Machine Learning Research},
  number       = {243},
  pages        = {1-38},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Memory of recurrent networks: Do we compute it right?},
  url          = {https://jmlr.org/papers/v25/23-0568.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The loss landscape of deep linear neural networks: A
second-order analysis. <em>JMLR</em>, <em>25</em>(242), 1–76. (<a
href="https://jmlr.org/papers/v25/23-0493.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the optimization landscape of deep linear neural networks with square loss. It is known that, under weak assumptions, there are no spurious local minima and no local maxima. However, the existence and diversity of non-strict saddle points, which can play a role in first-order algorithms&#39; dynamics, have only been lightly studied. We go a step further with a complete analysis of the optimization landscape at order $2$. Among all critical points, we characterize global minimizers, strict saddle points, and non-strict saddle points. We enumerate all the associated critical values. The characterization is simple, involves conditions on the ranks of partial matrix products, and sheds some light on global convergence or implicit regularization that has been proved or observed when optimizing linear neural networks. In passing, we provide an explicit parameterization of the set of all global minimizers and exhibit large sets of strict and non-strict saddle points.},
  archive      = {J_JMLR},
  author       = {El Mehdi Achour and François Malgouyres and Sébastien Gerchinovitz},
  journal      = {Journal of Machine Learning Research},
  number       = {242},
  pages        = {1-76},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {The loss landscape of deep linear neural networks: A second-order analysis},
  url          = {https://jmlr.org/papers/v25/23-0493.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). High probability convergence bounds for non-convex
stochastic gradient descent with sub-weibull noise. <em>JMLR</em>,
<em>25</em>(241), 1–36. (<a
href="https://jmlr.org/papers/v25/23-0466.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient descent is one of the most common iterative algorithms used in machine learning and its convergence analysis is a rich area of research. Understanding its convergence properties can help inform what modifications of it to use in different settings. However, most theoretical results either assume convexity or only provide convergence results in mean. This paper, on the other hand, proves convergence bounds in high probability without assuming convexity. Assuming strong smoothness, we prove high probability convergence bounds in two settings: (1) assuming the Polyak-Łojasiewicz inequality and norm sub-Gaussian gradient noise and (2) assuming norm sub-Weibull gradient noise. In the second setting, as an intermediate step to proving convergence, we prove a sub-Weibull martingale difference sequence self-normalized concentration inequality of independent interest. It extends Freedman-type concentration beyond the sub-exponential threshold to heavier-tailed martingale difference sequences. We also provide a post-processing method that picks a single iterate with a provable convergence guarantee as opposed to the usual bound for the unknown best iterate. Our convergence result for sub-Weibull noise extends the regime where stochastic gradient descent has equal or better convergence guarantees than stochastic gradient descent with modifications such as clipping, momentum, and normalization.},
  archive      = {J_JMLR},
  author       = {Liam Madden and Emiliano Dall&#39;Anese and Stephen Becker},
  journal      = {Journal of Machine Learning Research},
  number       = {241},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {High probability convergence bounds for non-convex stochastic gradient descent with sub-weibull noise},
  url          = {https://jmlr.org/papers/v25/23-0466.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Euler characteristic tools for topological data analysis.
<em>JMLR</em>, <em>25</em>(240), 1–39. (<a
href="https://jmlr.org/papers/v25/23-0353.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study Euler characteristic techniques in topological data analysis. Pointwise computing the Euler characteristic of a family of simplicial complexes built from data gives rise to the so-called Euler characteristic profile. We show that this simple descriptor achieves state-of-the-art performance in supervised tasks at a meagre computational cost. Inspired by signal analysis, we compute hybrid transforms of Euler characteristic profiles. These integral transforms mix Euler characteristic techniques with Lebesgue integration to provide highly efficient compressors of topological signals. As a consequence, they show remarkable performances in unsupervised settings. On the qualitative side, we provide numerous heuristics on the topological and geometric information captured by Euler profiles and their hybrid transforms. Finally, we prove stability results for these descriptors as well as asymptotic guarantees in random settings.},
  archive      = {J_JMLR},
  author       = {Olympio Hacquard and Vadim Lebovici},
  journal      = {Journal of Machine Learning Research},
  number       = {240},
  pages        = {1-39},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Euler characteristic tools for topological data analysis},
  url          = {https://jmlr.org/papers/v25/23-0353.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Depth degeneracy in neural networks: Vanishing angles in
fully connected ReLU networks on initialization. <em>JMLR</em>,
<em>25</em>(239), 1–45. (<a
href="https://jmlr.org/papers/v25/23-0350.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite remarkable performance on a variety of tasks, many properties of deep neural networks are not yet theoretically understood. One such mystery is the depth degeneracy phenomenon: the deeper you make your network, the closer your network is to a constant function on initialization. In this paper, we examine the evolution of the angle between two inputs to a ReLU neural network as a function of the number of layers. By using combinatorial expansions, we find precise formulas for how fast this angle goes to zero as depth increases. These formulas capture microscopic fluctuations that are not visible in the popular framework of infinite width limits, and leads to qualitatively different predictions. We validate our theoretical results with Monte Carlo experiments and show that our results accurately approximate finite network behaviour. We also empirically investigate how the depth degeneracy phenomenon can negatively impact training of real networks. The formulas are given in terms of the mixed moments of correlated Gaussians passed through the ReLU function. We also find a surprising combinatorial connection between these mixed moments and the Bessel numbers that allows us to explicitly evaluate these moments.},
  archive      = {J_JMLR},
  author       = {Cameron Jakub and Mihai Nica},
  journal      = {Journal of Machine Learning Research},
  number       = {239},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Depth degeneracy in neural networks: Vanishing angles in fully connected ReLU networks on initialization},
  url          = {https://jmlr.org/papers/v25/23-0350.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fortuna: A library for uncertainty quantification in deep
learning. <em>JMLR</em>, <em>25</em>(238), 1–7. (<a
href="https://jmlr.org/papers/v25/23-0145.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Fortuna, an open-source library for uncertainty quantification in deep learning. Fortuna supports a range of calibration techniques, such as conformal prediction that can be applied to any trained neural network to generate reliable uncertainty estimates, and scalable Bayesian inference methods that can be applied to deep neural networks trained from scratch for improved uncertainty quantification and accuracy. By providing a coherent framework for advanced uncertainty quantification methods, Fortuna simplifies the process of benchmarking and helps practitioners build robust AI systems.},
  archive      = {J_JMLR},
  author       = {Gianluca Detommaso and Alberto Gasparin and Michele Donini and Matthias Seeger and Andrew Gordon Wilson and Cedric Archambeau},
  journal      = {Journal of Machine Learning Research},
  number       = {238},
  pages        = {1-7},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fortuna: A library for uncertainty quantification in deep learning},
  url          = {https://jmlr.org/papers/v25/23-0145.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Characterization of translation invariant MMD on rd and
connections with wasserstein distances. <em>JMLR</em>, <em>25</em>(237),
1–39. (<a href="https://jmlr.org/papers/v25/22-1338.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel mean embeddings and maximum mean discrepancies (MMD) associated with positive definite kernels are important tools in machine learning that allow to compare probability measures and sample distributions. We provide a full characterization of translation invariant MMDs on $\mathbb{R}^d$ that are parametrized by a spectral measure and a semi-definite positive symmetric matrix. Furthermore, we investigate the connections between translation invariant MMDs and Wasserstein distances on $\mathbb{R}^d$. We show in particular that convergence with respect to the MMD associated with the Energy Kernel of order $\alpha\in(0,1)$ implies convergence with respect to the Wasserstein distance of order $\beta&lt;\alpha$. We also provide examples of kernels metrizing the Wasserstein space of order $\alpha\geq 1$. A short numerical experiment illustrates our findings in the framework of the one-sample-test.},
  archive      = {J_JMLR},
  author       = {Thibault Modeste and Clément Dombry},
  journal      = {Journal of Machine Learning Research},
  number       = {237},
  pages        = {1-39},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Characterization of translation invariant MMD on rd and connections with wasserstein distances},
  url          = {https://jmlr.org/papers/v25/22-1338.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the hyperparameters in stochastic gradient descent with
momentum. <em>JMLR</em>, <em>25</em>(236), 1–40. (<a
href="https://jmlr.org/papers/v25/22-1189.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following the same routine as Shi et al. (2023), we continue to present the theoretical analysis for stochastic gradient descent with momentum (SGD with momentum) in this paper. Differently, for SGD with momentum, we demonstrate that the two hyperparameters together, the learning rate and the momentum coefficient, play a significant role in the linear convergence rate in non-convex optimizations. Our analysis is based on using a hyperparameters-dependent stochastic differential equation (hp-dependent SDE) that serves as a continuous surrogate for SGD with momentum. Similarly, we establish the linear convergence for the continuous-time formulation of SGD with momentum and obtain an explicit expression for the optimal linear rate by analyzing the spectrum of the Kramers-Fokker-Planck operator. By comparison, we demonstrate how the optimal linear rate of convergence and the final gap for SGD only about the learning rate varies with the momentum coefficient increasing from zero to one when the momentum is introduced. Then, we propose a mathematical interpretation of why, in practice, SGD with momentum converges faster and is more robust in the learning rate than standard stochastic gradient descent (SGD). Finally, we show the Nesterov momentum under the presence of noise has no essential difference from the traditional momentum.},
  archive      = {J_JMLR},
  author       = {Bin Shi},
  journal      = {Journal of Machine Learning Research},
  number       = {236},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the hyperparameters in stochastic gradient descent with momentum},
  url          = {https://jmlr.org/papers/v25/22-1189.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved random features for dot product kernels.
<em>JMLR</em>, <em>25</em>(235), 1–75. (<a
href="https://jmlr.org/papers/v25/22-0118.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dot product kernels, such as polynomial and exponential (softmax) kernels, are among the most widely used kernels in machine learning, as they enable modeling the interactions between input features, which is crucial in applications like computer vision, natural language processing, and recommender systems. We make several novel contributions for improving the efficiency of random feature approximations for dot product kernels, to make these kernels more useful in large scale learning. First, we present a generalization of existing random feature approximations for polynomial kernels, such as Rademacher and Gaussian sketches and TensorSRHT, using complex-valued random features. We show empirically that the use of complex features can significantly reduce the variances of these approximations. Second, we provide a theoretical analysis for understanding the factors affecting the efficiency of various random feature approximations, by deriving closed-form expressions for their variances. These variance formulas elucidate conditions under which certain approximations (e.g., TensorSRHT) achieve lower variances than others (e.g., Rademacher sketches), and conditions under which the use of complex features leads to lower variances than real features. Third, by using these variance formulas, which can be evaluated in practice, we develop a data-driven optimization approach to improve random feature approximations for general dot product kernels, which is also applicable to the Gaussian kernel. We describe the improvements brought by these contributions with extensive experiments on a variety of tasks and datasets.},
  archive      = {J_JMLR},
  author       = {Jonas Wacker and Motonobu Kanagawa and Maurizio Filippone},
  journal      = {Journal of Machine Learning Research},
  number       = {235},
  pages        = {1-75},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Improved random features for dot product kernels},
  url          = {https://jmlr.org/papers/v25/22-0118.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regret analysis of bilateral trade with a smoothed
adversary. <em>JMLR</em>, <em>25</em>(234), 1–36. (<a
href="https://jmlr.org/papers/v25/23-1627.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study repeated bilateral trade where an adaptive $\sigma$-smooth adversary generates the valuations of sellers and buyers. We completely characterize the regret regimes for fixed-price mechanisms under different feedback models in the two cases where the learner can post the same or different prices to buyers and sellers. We begin by showing that, in the full-feedback scenario, the minimax regret after $T$ rounds is of order $\sqrt{T}$. Under partial feedback, any algorithm that has to post the same price to buyers and sellers suffers worst-case linear regret. However, when the learner can post two different prices at each round, we design an algorithm enjoying regret of order $T^{3/4}$, ignoring log factors. We prove that this rate is optimal by presenting a surprising $T^{3/4}$ lower bound, which is the paper&#39;s main technical contribution.},
  archive      = {J_JMLR},
  author       = {Nicolò Cesa-Bianchi and Tommaso Cesari and Roberto Colomboni and Federico Fusco and Stefano Leonardi},
  journal      = {Journal of Machine Learning Research},
  number       = {234},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Regret analysis of bilateral trade with a smoothed adversary},
  url          = {https://jmlr.org/papers/v25/23-1627.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Invariant physics-informed neural networks for ordinary
differential equations. <em>JMLR</em>, <em>25</em>(233), 1–24. (<a
href="https://jmlr.org/papers/v25/23-1511.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks have emerged as a prominent new method for solving differential equations. While conceptually straightforward, they often suffer training difficulties that lead to relatively large discretization errors or the failure to obtain correct solutions. In this paper we introduce invariant physics-informed neural networks for ordinary differential equations that admit a finite-dimensional group of Lie point symmetries. Using the method of equivariant moving frames, a differential equation is invariantized to obtain a, generally, simpler equation in the space of differential invariants. A solution to the invariantized equation is then mapped back to a solution of the original differential equation by solving the reconstruction equations for the left moving frame. The invariantized differential equation together with the reconstruction equations are solved using a physics-informed neural network, and form what we call an invariant physics-informed neural network. We illustrate the method with several examples, all of which considerably outperform standard non-invariant physics-informed neural networks.},
  archive      = {J_JMLR},
  author       = {Shivam Arora and Alex Bihlo and Francis Valiquette},
  journal      = {Journal of Machine Learning Research},
  number       = {233},
  pages        = {1-24},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Invariant physics-informed neural networks for ordinary differential equations},
  url          = {https://jmlr.org/papers/v25/23-1511.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distribution learning via neural differential equations: A
nonparametric statistical perspective. <em>JMLR</em>, <em>25</em>(232),
1–61. (<a href="https://jmlr.org/papers/v25/23-1280.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinary differential equations (ODEs), via their induced flow maps, provide a powerful framework to parameterize invertible transformations for representing complex probability distributions. While such models have achieved enormous success in machine learning, little is known about their statistical properties. This work establishes the first general nonparametric statistical convergence analysis for distribution learning via ODE models trained through likelihood maximization. We first prove a convergence theorem applicable to arbitrary velocity field classes $\mathcal{F}$ satisfying certain simple boundary constraints. This general result captures the trade-off between the approximation error and complexity of the ODE model. We show that the latter can be quantified via the $C^1$-metric entropy of the class $\mathcal{F}$. We then apply this general framework to the setting of $C^k$-smooth target densities, and establish nearly minimax-optimal convergence rates for two relevant velocity field classes $\mathcal{F}$: $C^k$ functions and neural networks. The latter is the practically important case of neural ODEs. Our results also provide insight on how the choice of velocity field class, and the dependence of this choice on sample size (e.g., the scaling of neural network classes), impact statistical performance.},
  archive      = {J_JMLR},
  author       = {Youssef Marzouk and Zhi (Robert) Ren and Sven Wang and Jakob Zech},
  journal      = {Journal of Machine Learning Research},
  number       = {232},
  pages        = {1-61},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Distribution learning via neural differential equations: A nonparametric statistical perspective},
  url          = {https://jmlr.org/papers/v25/23-1280.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variation spaces for multi-output neural networks: Insights
on multi-task learning and network compression. <em>JMLR</em>,
<em>25</em>(231), 1–40. (<a
href="https://jmlr.org/papers/v25/23-0677.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel theoretical framework for the analysis of vector-valued neural networks through the development of vector-valued variation spaces, a new class of reproducing kernel Banach spaces. These spaces emerge from studying the regularization effect of weight decay in training networks with activation functions like the rectified linear unit (ReLU). This framework offers a deeper understanding of multi-output networks and their function-space characteristics. A key contribution of this work is the development of a representer theorem for the vector-valued variation spaces. This representer theorem establishes that shallow vector-valued neural networks are the solutions to data-fitting problems over these infinite-dimensional spaces, where the network widths are bounded by the square of the number of training data. This observation reveals that the norm associated with these vector-valued variation spaces encourages the learning of features that are useful for multiple tasks, shedding new light on multi-task learning with neural networks. Finally, this paper develops a connection between weight-decay regularization and the multi-task lasso problem. This connection leads to novel bounds for layer widths in deep networks that depend on the intrinsic dimensions of the training data representations. This insight not only deepens the understanding of the deep network architectural requirements, but also yields a simple convex optimization method for deep neural network compression. The performance of this compression procedure is evaluated on various architectures.},
  archive      = {J_JMLR},
  author       = {Joseph Shenouda and Rahul Parhi and Kangwook Lee and Robert D. Nowak},
  journal      = {Journal of Machine Learning Research},
  number       = {231},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Variation spaces for multi-output neural networks: Insights on multi-task learning and network compression},
  url          = {https://jmlr.org/papers/v25/23-0677.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Individual-centered partial information in social networks.
<em>JMLR</em>, <em>25</em>(230), 1–60. (<a
href="https://jmlr.org/papers/v25/23-0005.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In statistical network analysis, we often assume either the full network is available or multiple subgraphs can be sampled to estimate various global properties of the network. However, in a real social network, people frequently make decisions based on their local view of the network alone. Here, we consider a partial information framework that characterizes the local network centered at a given individual by path length $L$ and gives rise to a partial adjacency matrix. Under $L=2$, we focus on the problem of (global) community detection using the popular stochastic block model (SBM) and its degree-corrected variant (DCSBM). We derive theoretical properties of the eigenvalues and eigenvectors from the signal term of the partial adjacency matrix and propose new spectral-based community detection algorithms that achieve consistency under appropriate conditions. Our analysis also allows us to propose a new centrality measure that assesses the importance of an individual&#39;s partial information in determining global community structure. Using simulated and real networks, we demonstrate the performance of our algorithms and compare our centrality measure with other popular alternatives to show it captures unique nodal information. Our results illustrate that the partial information framework enables us to compare the viewpoints of different individuals regarding the global structure.},
  archive      = {J_JMLR},
  author       = {Xiao Han and Y. X. Rachel Wang and Qing Yang and Xin Tong},
  journal      = {Journal of Machine Learning Research},
  number       = {230},
  pages        = {1-60},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Individual-centered partial information in social networks},
  url          = {https://jmlr.org/papers/v25/23-0005.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven automated negative control estimation (DANCE):
Search for, validation of, and causal inference with negative controls.
<em>JMLR</em>, <em>25</em>(229), 1–35. (<a
href="https://jmlr.org/papers/v25/22-1062.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Negative control variables are increasingly used to adjust for unmeasured confounding bias in causal inference using observational data. They are typically identified by subject matter knowledge and there is currently a severe lack of data-driven methods to find negative controls. In this paper, we present a statistical test for discovering negative controls of a special type---disconnected negative controls---that can serve as surrogates of the unmeasured confounder, and we incorporate that test into the Data-driven Automated Negative Control Estimation (DANCE) algorithm. DANCE first uses the new validation test to identify subsets of a set of candidate negative control variables that satisfy the assumptions of disconnected negative controls. It then applies a negative control method to each pair of these validated negative control variables, and aggregates the output to produce an unbiased point estimate and confidence interval for a causal effect in the presence of unmeasured confounding. We (1) prove the correctness of this validation test, and thus of DANCE; (2) demonstrate via simulation experiments that DANCE outperforms both naive analysis ignoring unmeasured confounding and negative control method with randomly selected candidate negative controls; and (3) demonstrate the effectiveness of DANCE on a challenging real-world problem.},
  archive      = {J_JMLR},
  author       = {Erich Kummerfeld and Jaewon Lim and Xu Shi},
  journal      = {Journal of Machine Learning Research},
  number       = {229},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Data-driven automated negative control estimation (DANCE): Search for, validation of, and causal inference with negative controls},
  url          = {https://jmlr.org/papers/v25/22-1062.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continuous prediction with experts’ advice. <em>JMLR</em>,
<em>25</em>(228), 1–32. (<a
href="https://jmlr.org/papers/v25/22-0803.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction with experts&#39; advice is one of the most fundamental problems in online learning and captures many of its technical challenges. A recent line of work has looked at online learning through the lens of differential equations and continuous-time analysis. This viewpoint has yielded optimal results for several problems in online learning. In this paper, we employ continuous-time stochastic calculus in order to study the discrete-time experts&#39; problem. We use these tools to design a continuous-time, parameter-free algorithm with improved guarantees on the quantile regret. We then develop an analogous discrete-time algorithm with a very similar analysis and identical quantile regret bounds. Finally, we design an anytime continuous-time algorithm with regret matching the optimal fixed-time rate when the gains are independent Brownian motions; in many settings, this is the most difficult case. This gives some evidence that, even with adversarial gains, the optimal anytime and fixed-time regrets may coincide.},
  archive      = {J_JMLR},
  author       = {Nicholas J. A. Harvey and Christopher Liaw and Victor S. Portella},
  journal      = {Journal of Machine Learning Research},
  number       = {228},
  pages        = {1-32},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Continuous prediction with experts&#39; advice},
  url          = {https://jmlr.org/papers/v25/22-0803.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Memory-efficient sequential pattern mining with hybrid
tries. <em>JMLR</em>, <em>25</em>(227), 1–29. (<a
href="https://jmlr.org/papers/v25/22-0125.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a memory-efficient approach for Sequential Pattern Mining (SPM), a fundamental topic in knowledge discovery that faces a well-known memory bottleneck for large data sets. Our methodology involves a novel hybrid trie data structure that exploits recurring patterns to compactly store the data set in memory; and a corresponding mining algorithm designed to effectively extract patterns from this compact representation. Numerical results on small to medium-sized real-life test instances show an average improvement of 85% in memory consumption and 49% in computation time compared to the state of the art. For large data sets, our algorithm stands out as the only capable SPM approach within 256GB of system memory, potentially saving 1.7TB in memory consumption.},
  archive      = {J_JMLR},
  author       = {Amin Hosseininasab and Willem-Jan van Hoeve and Andre A. Cire},
  journal      = {Journal of Machine Learning Research},
  number       = {227},
  pages        = {1-29},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Memory-efficient sequential pattern mining with hybrid tries},
  url          = {https://jmlr.org/papers/v25/22-0125.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sample complexity of neural policy mirror descent for policy
optimization on low-dimensional manifolds. <em>JMLR</em>,
<em>25</em>(226), 1–67. (<a
href="https://jmlr.org/papers/v25/24-0066.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Policy gradient methods equipped with deep neural networks have achieved great success in solving high-dimensional reinforcement learning (RL) problems. However, current analyses cannot explain why they are resistant to the curse of dimensionality. In this work, we study the sample complexity of the neural policy mirror descent (NPMD) algorithm with deep convolutional neural networks (CNN). Motivated by the empirical observation that many high-dimensional environments have state spaces possessing low-dimensional structures, such as those taking images as states, we consider the state space to be a $d$-dimensional manifold embedded in the $D$-dimensional Euclidean space with intrinsic dimension $d\ll D$. We show that in each iteration of NPMD, both the value function and the policy can be well approximated by CNNs. The approximation errors are controlled by the size of the networks, and the smoothness of the previous networks can be inherited. As a result, by properly choosing the network size and hyperparameters, NPMD can find an $\epsilon$-optimal policy with $\tilde{O}(\epsilon^{-\frac{d}{\alpha}-2})$ samples in expectation, where $\alpha\in(0,1]$ indicates the smoothness of environment. Compared to previous work, our result exhibits that NPMD can leverage the low-dimensional structure of state space to escape from the curse of dimensionality, explaining the efficacy of deep policy gradient algorithms.},
  archive      = {J_JMLR},
  author       = {Zhenghao Xu and Xiang Ji and Minshuo Chen and Mengdi Wang and Tuo Zhao},
  journal      = {Journal of Machine Learning Research},
  number       = {226},
  pages        = {1-67},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sample complexity of neural policy mirror descent for policy optimization on low-dimensional manifolds},
  url          = {https://jmlr.org/papers/v25/24-0066.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Split conformal prediction and non-exchangeable data.
<em>JMLR</em>, <em>25</em>(225), 1–38. (<a
href="https://jmlr.org/papers/v25/23-1553.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Split conformal prediction (CP) is arguably the most popular CP method for uncertainty quantification, enjoying both academic interest and widespread deployment. However, the original theoretical analysis of split CP makes the crucial assumption of data exchangeability, which hinders many real-world applications. In this paper, we present a novel theoretical framework based on concentration inequalities and decoupling properties of the data, proving that split CP remains valid for many non-exchangeable processes by adding a small coverage penalty. Through experiments with both real and synthetic data, we show that our theoretical results translate to good empirical performance under non-exchangeability, e.g., for time series and spatiotemporal data. Compared to recent conformal algorithms designed to counter specific exchangeability violations, we show that split CP is competitive in terms of coverage and interval size, with the benefit of being extremely simple and orders of magnitude faster than alternatives.},
  archive      = {J_JMLR},
  author       = {Roberto I. Oliveira and Paulo Orenstein and Thiago Ramos and João Vitor Romano},
  journal      = {Journal of Machine Learning Research},
  number       = {225},
  pages        = {1-38},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Split conformal prediction and non-exchangeable data},
  url          = {https://jmlr.org/papers/v25/23-1553.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structured dynamic pricing: Optimal regret in a global
shrinkage model. <em>JMLR</em>, <em>25</em>(224), 1–46. (<a
href="https://jmlr.org/papers/v25/23-1365.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider dynamic pricing strategies in a streamed longitudinal data set-up where the objective is to maximize, over time, the cumulative profit across a large number of customer segments. We consider a dynamic model with the consumers’ preferences as well as price sensitivity varying over time. Building on the well-known finding that consumers sharing similar characteristics act in similar ways, we consider a global shrinkage structure, which assumes that the consumers’ preferences across the different segments can be well approximated by a spatial autoregressive (SAR) model. In such a streamed longitudinal setup, we measure the performance of a dynamic pricing policy via regret, which is the expected revenue loss compared to a clairvoyant that knows the sequence of model parameters in advance. We propose a pricing policy based on penalized stochastic gradient descent (PSGD) and explicitly characterize its regret as functions of time, the temporal variability in the model parameters as well as the strength of the auto-correlation network structure spanning the varied customer segments. Our regret analysis results not only demonstrate asymptotic optimality of the proposed policy but also show that for policy planning it is essential to incorporate available structural information as policies based on unshrunken models are highly sub-optimal in the aforementioned set-up. We conduct simulation experiments across a wide range of regimes as well as real-world networks based studies and report encouraging performance for our proposed method.},
  archive      = {J_JMLR},
  author       = {Rashmi Ranjan Bhuyan and Adel Javanmard and Sungchul Kim and Gourab Mukherjee and Ryan A. Rossi and Tong Yu and Handong Zhao},
  journal      = {Journal of Machine Learning Research},
  number       = {224},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Structured dynamic pricing: Optimal regret in a global shrinkage model},
  url          = {https://jmlr.org/papers/v25/23-1365.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse graphical linear dynamical systems. <em>JMLR</em>,
<em>25</em>(223), 1–53. (<a
href="https://jmlr.org/papers/v25/23-0878.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series datasets are central in machine learning with applications in numerous fields of science and engineering, such as biomedicine, Earth observation, and network analysis. Extensive research exists on state-space models (SSMs), which are powerful mathematical tools that allow for probabilistic and interpretable learning on time series. Learning the model parameters in SSMs is arguably one of the most complicated tasks, and the inclusion of prior knowledge is known to both ease the interpretation but also to complicate the inferential tasks. Very recent works have attempted to incorporate a graphical perspective on some of those model parameters, but they present notable limitations that this work addresses. More generally, existing graphical modeling tools are designed to incorporate either static information, focusing on statistical dependencies among independent random variables (e.g., graphical Lasso approach), or dynamic information, emphasizing causal relationships among time series samples (e.g., graphical Granger approaches). However, there are no joint approaches combining static and dynamic graphical modeling within the context of SSMs. This work proposes a novel approach to fill this gap by introducing a joint graphical modeling framework that bridges the graphical Lasso model and a causal-based graphical approach for the linear-Gaussian SSM. We present DGLASSO (Dynamic Graphical Lasso), a new inference method within this framework that implements an efficient block alternating majorization-minimization algorithm. The algorithm&#39;s convergence is established by departing from modern tools from nonlinear analysis. Experimental validation on various synthetic data showcases the effectiveness of the proposed model and inference algorithm. This work will significantly contribute to the understanding and utilization of time-series data in diverse scientific and engineering applications where incorporating a graphical approach is essential to perform the inference.},
  archive      = {J_JMLR},
  author       = {Emilie Chouzenoux and Victor Elvira},
  journal      = {Journal of Machine Learning Research},
  number       = {223},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sparse graphical linear dynamical systems},
  url          = {https://jmlr.org/papers/v25/23-0878.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Statistical analysis for a penalized EM algorithm in
high-dimensional mixture linear regression model. <em>JMLR</em>,
<em>25</em>(222), 1–85. (<a
href="https://jmlr.org/papers/v25/23-0296.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expectation-maximization (EM) algorithm and its variants are widely used in statistics. In high-dimensional mixture linear regression, the model is assumed to be a finite mixture of linear regression and the number of predictors is much larger than the sample size. The standard EM algorithm, which attempts to find the maximum likelihood estimator, becomes infeasible for such model. We devise a group lasso penalized EM algorithm and study its statistical properties. Existing theoretical results of regularized EM algorithms often rely on dividing the sample into many independent batches and employing a fresh batch of sample in each iteration of the algorithm. Our algorithm and theoretical analysis do not require sample-splitting, and can be extended to multivariate response cases. The proposed methods also have encouraging performances in numerical studies.},
  archive      = {J_JMLR},
  author       = {Ning Wang and Xin Zhang and Qing Mai},
  journal      = {Journal of Machine Learning Research},
  number       = {222},
  pages        = {1-85},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Statistical analysis for a penalized EM algorithm in high-dimensional mixture linear regression model},
  url          = {https://jmlr.org/papers/v25/23-0296.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bridging distributional and risk-sensitive reinforcement
learning with provable regret bounds. <em>JMLR</em>, <em>25</em>(221),
1–56. (<a href="https://jmlr.org/papers/v25/22-1253.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the regret guarantee for risk-sensitive reinforcement learning (RSRL) via distributional reinforcement learning (DRL) methods. In particular, we consider finite episodic Markov decision processes whose objective is the entropic risk measure (EntRM) of return. By leveraging a key property of the EntRM, the independence property, we establish the risk-sensitive distributional dynamic programming framework. We then propose two novel DRL algorithms that implement optimism through two different schemes, including a model-free one and a model-based one. We prove that they both attain $\tilde{\mathcal{O}}\left(\frac{\exp(|\beta| H)-1}{|\beta|}H\sqrt{S^2AK}\right)$ regret upper bound, where $S$, $A$, $K$, $H$, $T=KH$, and $\beta$ represent the number of states, actions, episodes, time horizon, number of total time-steps, and risk parameter respectively. It matches RSVI2, with novel distributional analysis that focuses on the distributions of returns rather than the risk values associated with these returns. To the best of our knowledge, this is the first regret analysis that bridges DRL and RSRL in terms of sample complexity. To address the computational inefficiencies inherent in the model-free DRL algorithm, we propose an alternative DRL algorithm with distribution representation. This approach effectively represents any bounded distribution using a refined distribution class. It significantly amplifies computational efficiency while maintaining the established regret bounds. We also prove a tighter minimax lower bound of $\Omega\left(\frac{\exp(\beta H/6)-1}{\beta }\sqrt{SAT}\right)$ for the $\beta&gt;0$ case, which recovers the tight lower bound $\Omega(H\sqrt{SAT})$ in the risk-neutral setting.},
  archive      = {J_JMLR},
  author       = {Hao Liang and Zhi-Quan Luo},
  journal      = {Journal of Machine Learning Research},
  number       = {221},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bridging distributional and risk-sensitive reinforcement learning with provable regret bounds},
  url          = {https://jmlr.org/papers/v25/22-1253.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Low-rank matrix estimation in the presence of change-points.
<em>JMLR</em>, <em>25</em>(220), 1–71. (<a
href="https://jmlr.org/papers/v25/22-0852.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a general trace regression model with multiple structural changes and propose a universal approach for simultaneous exact or near-low-rank matrix recovery and change-point detection. It incorporates nuclear norm penalized least-squares minimization into a grid search scheme that determines the potential structural break. Under a set of general conditions, we establish the non-asymptotic error bounds with a nearly-oracle rate for the matrix estimators as well as the super-consistency rate for the change-point localization. We use concrete random design instances to justify the appropriateness of the proposed conditions. Numerical results demonstrate the validity and effectiveness of the proposed scheme.},
  archive      = {J_JMLR},
  author       = {Lei Shi and Guanghui Wang and Changliang Zou},
  journal      = {Journal of Machine Learning Research},
  number       = {220},
  pages        = {1-71},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Low-rank matrix estimation in the presence of change-points},
  url          = {https://jmlr.org/papers/v25/22-0852.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A framework for improving the reliability of black-box
variational inference. <em>JMLR</em>, <em>25</em>(219), 1–71. (<a
href="https://jmlr.org/papers/v25/22-0327.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Black-box variational inference (BBVI) now sees widespread use in machine learning and statistics as a fast yet flexible alternative to Markov chain Monte Carlo methods for approximate Bayesian inference. However, stochastic optimization methods for BBVI remain unreliable and require substantial expertise and hand-tuning to apply effectively. In this paper, we propose robust and automated black-box VI (RABVI), a framework for improving the reliability of BBVI optimization. RABVI is based on rigorously justified automation techniques, includes just a small number of intuitive tuning parameters, and detects inaccurate estimates of the optimal variational approximation. RABVI adaptively decreases the learning rate by detecting convergence of the fixed--learning-rate iterates, then estimates the symmetrized Kullback--Leibler (KL) divergence between the current variational approximation and the optimal one. It also employs a novel optimization termination criterion that enables the user to balance desired accuracy against computational cost by comparing (i) the predicted relative decrease in the symmetrized KL divergence if a smaller learning were used and (ii) the predicted computation required to converge with the smaller learning rate. We validate the robustness and accuracy of RABVI through carefully designed simulation studies and on a diverse set of real-world model and data examples.},
  archive      = {J_JMLR},
  author       = {Manushi Welandawe and Michael Riis Andersen and Aki Vehtari and Jonathan H. Huggins},
  journal      = {Journal of Machine Learning Research},
  number       = {219},
  pages        = {1-71},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A framework for improving the reliability of black-box variational inference},
  url          = {https://jmlr.org/papers/v25/22-0327.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding entropic regularization in GANs.
<em>JMLR</em>, <em>25</em>(218), 1–32. (<a
href="https://jmlr.org/papers/v25/21-1295.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are a popular method for learning distributions from data by modeling the target distribution as a function of a known distribution. The function, often referred to as the generator, is optimized to minimize a chosen distance measure between the generated and target distributions. One commonly used measure for this purpose is the Wasserstein distance. However, Wasserstein distance is hard to compute and optimize, and in practice entropic regularization techniques are used to facilitate its computation and improve numerical convergence. The influence of regularization on the learned solution, however, remains not well-understood. In this paper, we study how several popular entropic regularizations of Wasserstein distance impact the solution learned by a Wasserstein GAN in a simple benchmark setting where the generator is linear and the target distribution is high-dimensional Gaussian. We show that entropy regularization of Wasserstein distance promotes sparsification of the solution, while replacing the Wasserstein distance with the Sinkhorn divergence recovers the unregularized solution. The significant benefit of both regularization techniques is that they remove the curse of dimensionality suffered by Wasserstein distance. We show that in both cases the optimal generator can be learned to accuracy $\epsilon$ with $O(1/\epsilon^2)$ samples from the target distribution without requiring to constrain the discriminator. We thus conclude that these regularization techniques can improve the quality of the generator learned from empirical data in a way that is applicable for a large class of distributions.},
  archive      = {J_JMLR},
  author       = {Daria Reshetova and Yikun Bai and Xiugang Wu and Ayfer Özgür},
  journal      = {Journal of Machine Learning Research},
  number       = {218},
  pages        = {1-32},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Understanding entropic regularization in GANs},
  url          = {https://jmlr.org/papers/v25/21-1295.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BenchMARL: Benchmarking multi-agent reinforcement learning.
<em>JMLR</em>, <em>25</em>(217), 1–10. (<a
href="https://jmlr.org/papers/v25/23-1612.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of Multi-Agent Reinforcement Learning (MARL) is currently facing a reproducibility crisis. While solutions for standardized reporting have been proposed to address the issue, we still lack a benchmarking tool that enables standardization and reproducibility, while leveraging cutting-edge Reinforcement Learning (RL) implementations. In this paper, we introduce BenchMARL, the first MARL training library created to enable standardized benchmarking across different algorithms, models, and environments. BenchMARL uses TorchRL as its backend, granting it high-performance and maintained state-of-the-art implementations while addressing the broad community of MARL PyTorch users. Its design enables systematic configuration and reporting, thus allowing users to create and run complex benchmarks from simple one-line inputs. BenchMARL is open-sourced on GitHub at https://github.com/facebookresearch/BenchMARL},
  archive      = {J_JMLR},
  author       = {Matteo Bettini and Amanda Prorok and Vincent Moens},
  journal      = {Journal of Machine Learning Research},
  number       = {217},
  pages        = {1-10},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {BenchMARL: Benchmarking multi-agent reinforcement learning},
  url          = {https://jmlr.org/papers/v25/23-1612.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning from many trajectories. <em>JMLR</em>,
<em>25</em>(216), 1–109. (<a
href="https://jmlr.org/papers/v25/23-1145.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We initiate a study of supervised learning from many independent sequences (&quot;trajectories&quot;) of non-independent covariates, reflecting tasks in sequence modeling, control, and reinforcement learning. Conceptually, our multi-trajectory setup sits between two traditional settings in statistical learning theory: learning from independent examples and learning from a single auto-correlated sequence. Our conditions for efficient learning generalize the former setting---trajectories must be non-degenerate in ways that extend standard requirements for independent examples. Notably, we do not require that trajectories be ergodic, long, nor strictly stable. For linear least-squares regression, given $n$-dimensional examples produced by $m$ trajectories, each of length $T$, we observe a notable change in statistical efficiency as the number of trajectories increases from a few (namely $m \lesssim n$) to many (namely $m \gtrsim n$). Specifically, we establish that the worst-case error rate of this problem is $\Theta(n / m T)$ whenever $m \gtrsim n$. Meanwhile, when $m \lesssim n$, we establish a (sharp) lower bound of $\Omega(n^2 / m^2 T)$ on the worst-case error rate, realized by a simple, marginally unstable linear dynamical system. A key upshot is that, in domains where trajectories regularly reset, the error rate eventually behaves as if all of the examples were independent, drawn from their marginals. As a corollary of our analysis, we also improve guarantees for the linear system identification problem.},
  archive      = {J_JMLR},
  author       = {Stephen Tu and Roy Frostig and Mahdi Soltanolkotabi},
  journal      = {Journal of Machine Learning Research},
  number       = {216},
  pages        = {1-109},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning from many trajectories},
  url          = {https://jmlr.org/papers/v25/23-1145.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpretable algorithmic fairness in structured and
unstructured data. <em>JMLR</em>, <em>25</em>(215), 1–42. (<a
href="https://jmlr.org/papers/v25/23-0816.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systemic bias with respect to gender and race is prevalent in datasets, making it challenging to train classification models that are accurate and alleviate bias. We propose a unified method for alleviating bias in structured and unstructured data, based on a novel optimization approach for optimally flipping outcome labels and training classification models simultaneously. In the case of structured data, we introduce constraints on selected objective measures of meritocracy, and present four case studies, demonstrating that our approach often outperforms state-of the art methods in terms of fairness and meritocracy. In the case of unstructured data, we present two case studies on image classification, demonstrating that our method outperforms state-of-the-art approaches in terms of fairness. Moreover, we note that the decrease in accuracy over the nominal model is $3.31 \%$ on structured data and $0.65 \%$ on unstructured data. Finally, we leverage Optimal Classification Trees (OCTs), to provide insights on which attributes of individuals lead to flipping of their labels and apply it to interpret the flipping decisions on structured data. Utilizing OCTs with auxiliary tabular data as well as Gradient-weighted Class Activation Mapping (Grad-CAM), we provide insights on the flipping decisions for unstructured data.},
  archive      = {J_JMLR},
  author       = {Hari Bandi and Dimitris Bertsimas and Thodoris Koukouvinos and Sofie Kupiec},
  journal      = {Journal of Machine Learning Research},
  number       = {215},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Interpretable algorithmic fairness in structured and unstructured data},
  url          = {https://jmlr.org/papers/v25/23-0816.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedCBO: Reaching group consensus in clustered federated
learning through consensus-based optimization. <em>JMLR</em>,
<em>25</em>(214), 1–51. (<a
href="https://jmlr.org/papers/v25/23-0764.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is an important framework in modern machine learning that seeks to integrate the training of learning models from multiple users, each user having their own local data set, in a way that is sensitive to data privacy and to communication loss constraints. In clustered federated learning, one assumes an additional unknown group structure among users, and the goal is to train models that are useful for each group, rather than simply training a single global model for all users. In this paper, we propose a novel solution to the problem of clustered federated learning that is inspired by ideas in consensus-based optimization (CBO). Our new CBO-type method is based on a system of interacting particles that is oblivious to group memberships. Our model is motivated by rigorous mathematical reasoning, which includes a mean-field analysis describing the large number of particles limit of our particle system, as well as convergence guarantees for the simultaneous global optimization of general non-convex objective functions (corresponding to the loss functions of each cluster of users) in the mean-field regime. Experimental results demonstrate the efficacy of our FedCBO algorithm compared to other state-of-the-art methods and help validate our methodological and theoretical work.},
  archive      = {J_JMLR},
  author       = {José A. Carrillo and Nicolás García Trillos and Sixu Li and Yuhua Zhu},
  journal      = {Journal of Machine Learning Research},
  number       = {214},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {FedCBO: Reaching group consensus in clustered federated learning through consensus-based optimization},
  url          = {https://jmlr.org/papers/v25/23-0764.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the connection between lp- and risk consistency and its
implications on regularized kernel methods. <em>JMLR</em>,
<em>25</em>(213), 1–33. (<a
href="https://jmlr.org/papers/v25/23-0397.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a predictor&#39;s quality is often assessed by means of its risk, it is natural to regard risk consistency as a desirable property of learning methods, and many such methods have indeed been shown to be risk consistent. The first aim of this paper is to establish the close connection between risk consistency and $L_p$-consistency for a considerably wider class of loss functions than has been done before. The attempt to transfer this connection to shifted loss functions surprisingly reveals that this shift does not reduce the assumptions needed on the underlying probability measure to the same extent as it does for many other results. The results are applied to regularized kernel methods such as support vector machines.},
  archive      = {J_JMLR},
  author       = {Hannes Köhler},
  journal      = {Journal of Machine Learning Research},
  number       = {213},
  pages        = {1-33},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the connection between lp- and risk consistency and its implications on regularized kernel methods},
  url          = {https://jmlr.org/papers/v25/23-0397.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pre-trained gaussian processes for bayesian optimization.
<em>JMLR</em>, <em>25</em>(212), 1–83. (<a
href="https://jmlr.org/papers/v25/23-0269.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization (BO) has become a popular strategy for global optimization of expensive real-world functions. Contrary to a common expectation that BO is suited to optimizing black-box functions, it actually requires domain knowledge about those functions to deploy BO successfully. Such domain knowledge often manifests in Gaussian process (GP) priors that specify initial beliefs on functions. However, even with expert knowledge, it is non-trivial to quantitatively define a prior. This is especially true for hyperparameter tuning problems on complex machine learning models, where landscapes of tuning objectives are often difficult to comprehend. We seek an alternative practice for setting these functional priors. In particular, we consider the scenario where we have data from similar functions that allow us to pre-train a tighter distribution a priori. We detail what pre-training entails for GPs using a KL divergence based loss function, and propose a new pre-training based BO framework named HyperBO. Theoretically, we show bounded posterior predictions and near-zero regrets for HyperBO without assuming the &quot;ground truth&quot; GP prior is known. To verify our approach in realistic setups, we collect a large multi-task hyperparameter tuning dataset by training tens of thousands of configurations of near-state-of-the-art deep learning models on popular image and text datasets, as well as a protein sequence dataset. Our results show that on average, HyperBO is able to locate good hyperparameters at least 3 times more efficiently than the best competing methods on both our new tuning dataset and existing multi-task BO benchmarks.},
  archive      = {J_JMLR},
  author       = {Zi Wang and George E. Dahl and Kevin Swersky and Chansoo Lee and Zachary Nado and Justin Gilmer and Jasper Snoek and Zoubin Ghahramani},
  journal      = {Journal of Machine Learning Research},
  number       = {212},
  pages        = {1-83},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Pre-trained gaussian processes for bayesian optimization},
  url          = {https://jmlr.org/papers/v25/23-0269.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Heterogeneity-aware clustered distributed learning for
multi-source data analysis. <em>JMLR</em>, <em>25</em>(211), 1–60. (<a
href="https://jmlr.org/papers/v25/23-0059.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In diverse fields ranging from finance to omics, it is increasingly common that data is distributed with multiple individual sources (referred to as “clients” in some studies). Integrating raw data, although powerful, is often not feasible, for example, when there are considerations on privacy protection. Distributed learning techniques have been developed to integrate summary statistics as opposed to raw data. In many existing distributed learning studies, it is stringently assumed that all the clients have the same model. To accommodate data heterogeneity, some federated learning methods allow for client-specific models. In this article, we consider the scenario that clients form clusters, those in the same cluster have the same model, and different clusters have different models. Further considering the clustering structure can lead to a better understanding of the “interconnections” among clients and reduce the number of parameters. To this end, we develop a novel penalization approach. Specifically, group penalization is imposed for regularized estimation and selection of important variables, and fusion penalization is imposed to automatically cluster clients. An effective ADMM algorithm is developed, and the estimation, selection, and clustering consistency properties are established under mild conditions. Simulation and data analysis further demonstrate the practical utility and superiority of the proposed approach.},
  archive      = {J_JMLR},
  author       = {Yuanxing Chen and Qingzhao Zhang and Shuangge Ma and Kuangnan Fang},
  journal      = {Journal of Machine Learning Research},
  number       = {211},
  pages        = {1-60},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Heterogeneity-aware clustered distributed learning for multi-source data analysis},
  url          = {https://jmlr.org/papers/v25/23-0059.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From small scales to large scales: Distance-to-measure
density based geometric analysis of complex data. <em>JMLR</em>,
<em>25</em>(210), 1–53. (<a
href="https://jmlr.org/papers/v25/22-1344.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can we tell complex point clouds with different small scale characteristics apart, while disregarding global features? Can we find a suitable transformation of such data in a way that allows to discriminate between differences in this sense with statistical guarantees? In this paper, we consider the analysis and classification of complex point clouds as they are obtained, e.g., via single molecule localization microscopy. We focus on the task of identifying differences between noisy point clouds based on small scale characteristics, while disregarding large scale information such as overall size. We propose an approach based on a transformation of the data via the so-called Distance-to-Measure (DTM) function, a transformation which is based on the average of nearest neighbor distances. For each data set, we estimate the probability density of average local distances of all data points and use the estimated densities for classification. While the applicability is immediate and the practical performance of the proposed methodology is very good, the theoretical study of the density estimators is quite challenging, as they are based on non-i.i.d. observations that have been obtained via a complicated transformation. In fact, the transformed data are stochastically dependent in a non-local way that is not captured by commonly considered dependence measures. Nonetheless, we show that the asymptotic behaviour of the density estimator is driven by a kernel density estimator of certain i.i.d. random variables by using theoretical properties of $U$-statistics, which allows to handle the dependencies via a Hoeffding decomposition. We show via a numerical study and in an application to simulated single molecule localization microscopy data of chromatin fibers that unsupervised classification tasks based on estimated DTM-densities achieve excellent separation results.},
  archive      = {J_JMLR},
  author       = {Katharina Proksch and Christoph Alexander Weikamp and Thomas Staudt and Benoit Lelandais and Christophe Zimmer},
  journal      = {Journal of Machine Learning Research},
  number       = {210},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {From small scales to large scales: Distance-to-measure density based geometric analysis of complex data},
  url          = {https://jmlr.org/papers/v25/22-1344.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PAMI: An open-source python library for pattern mining.
<em>JMLR</em>, <em>25</em>(209), 1–6. (<a
href="https://jmlr.org/papers/v25/22-1026.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crucial information that can empower users with competitive information to achieve socio-economic development lies hidden in big data. Pattern mining aims to discover this needy information by finding user interest-based patterns in big data. Unfortunately, existing pattern mining libraries are limited to finding a few types of patterns in transactional and sequence databases. This paper tackles this problem by providing a cross-platform open-source Python library called PAttern MIning (PAMI). PAMI provides several algorithms to discover different types of patterns hidden in various types of databases across multiple computing architectures. PAMI also contains algorithms to generate various types of synthetic databases. PAMI offers a command line interface, Jupyter Notebook support, and easy maintenance through the Python Package Index. Furthermore, the source code is available under the GNU General Public License, version 3. Finally, PAMI offers several resources, such as a user&#39;s guide, a developer&#39;s guide, datasets, and a bug report.},
  archive      = {J_JMLR},
  author       = {Uday Kiran Rage and Veena Pamalla and Masashi Toyoda and Masaru Kitsuregawa},
  journal      = {Journal of Machine Learning Research},
  number       = {209},
  pages        = {1-6},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {PAMI: An open-source python library for pattern mining},
  url          = {https://jmlr.org/papers/v25/22-1026.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Law of large numbers and central limit theorem for wide
two-layer neural networks: The mini-batch and noisy case. <em>JMLR</em>,
<em>25</em>(208), 1–76. (<a
href="https://jmlr.org/papers/v25/22-0952.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider a wide two-layer neural network and study the behavior of its empirical weights under a dynamics set by a stochastic gradient descent along the quadratic loss with mini-batches and noise. Our goal is to prove a trajectorial law of large number as well as a central limit theorem for their evolution. When the noise is scaling as $1/N^\beta$ and $1/2&lt;\beta\le\infty$, we rigorously derive and generalize the LLN obtained for example by Rotskoff and Van den Injden (Com. Pure. Appl. Math, 2022), Mei and Montanari and Nguyen (Pnas 2018) or Sirignano and Spiliopoulos (Siam. J. Appl. Math. 2020). When $3/4&lt;\beta\le\infty$, we also generalize the CLT of Sirignano and Spiliopoulos (Stoch. Proc. Appl. 2020) and further exhibit the effect of mini-batching on the asymptotic variance which leads the fluctuations. The case $\beta=3/4$ is trickier and we give an example showing the divergence with time of the variance thus establishing the instability of the predictions of the neural network in this case. It is illustrated by simple numerical examples.},
  archive      = {J_JMLR},
  author       = {Arnaud Descours and Arnaud Guillin and Manon Michel and Boris Nectoux},
  journal      = {Journal of Machine Learning Research},
  number       = {208},
  pages        = {1-76},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Law of large numbers and central limit theorem for wide two-layer neural networks: The mini-batch and noisy case},
  url          = {https://jmlr.org/papers/v25/22-0952.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Risk measures and upper probabilities: Coherence and
stratification. <em>JMLR</em>, <em>25</em>(207), 1–100. (<a
href="https://jmlr.org/papers/v25/22-0641.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning typically presupposes classical probability theory which implies that aggregation is built upon expectation. There are now multiple reasons to motivate looking at richer alternatives to classical probability theory as a mathematical foundation for machine learning. We systematically examine a powerful and rich class of alternative aggregation functionals, known variously as spectral risk measures, Choquet integrals or Lorentz norms. We present a range of characterization results, and demonstrate what makes this spectral family so special. In doing so we arrive at a natural stratification of all coherent risk measures in terms of the upper probabilities that they induce by exploiting results from the theory of rearrangement invariant Banach spaces. We empirically demonstrate how this new approach to uncertainty helps tackling practical machine learning problems.},
  archive      = {J_JMLR},
  author       = {Christian Fröhlich and Robert C. Williamson},
  journal      = {Journal of Machine Learning Research},
  number       = {207},
  pages        = {1-100},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Risk measures and upper probabilities: Coherence and stratification},
  url          = {https://jmlr.org/papers/v25/22-0641.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parallel-in-time probabilistic numerical ODE solvers.
<em>JMLR</em>, <em>25</em>(206), 1–27. (<a
href="https://jmlr.org/papers/v25/23-1261.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic numerical solvers for ordinary differential equations (ODEs) treat the numerical simulation of dynamical systems as problems of Bayesian state estimation. Aside from producing posterior distributions over ODE solutions and thereby quantifying the numerical approximation error of the method itself, one less-often noted advantage of this formalism is the algorithmic flexibility gained by formulating numerical simulation in the framework of Bayesian filtering and smoothing. In this paper, we leverage this flexibility and build on the time-parallel formulation of iterated extended Kalman smoothers to formulate a parallel-in-time probabilistic numerical ODE solver. Instead of simulating the dynamical system sequentially in time, as done by current probabilistic solvers, the proposed method processes all time steps in parallel and thereby reduces the computational complexity from linear to logarithmic in the number of time steps. We demonstrate the effectiveness of our approach on a variety of ODEs and compare it to a range of both classic and probabilistic numerical ODE solvers.},
  archive      = {J_JMLR},
  author       = {Nathanael Bosch and Adrien Corenflos and Fatemeh Yaghoobi and Filip Tronarp and Philipp Hennig and Simo Särkkä},
  journal      = {Journal of Machine Learning Research},
  number       = {206},
  pages        = {1-27},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Parallel-in-time probabilistic numerical ODE solvers},
  url          = {https://jmlr.org/papers/v25/23-1261.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable high-dimensional multivariate linear regression for
feature-distributed data. <em>JMLR</em>, <em>25</em>(205), 1–59. (<a
href="https://jmlr.org/papers/v25/23-0882.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature-distributed data, referred to data partitioned by features and stored across multiple computing nodes, are increasingly common in applications with a large number of features. This paper proposes a two-stage relaxed greedy algorithm (TSRGA) for applying multivariate linear regression to such data. The main advantage of TSRGA is that its communication complexity does not depend on the feature dimension, making it highly scalable to very large data sets. In addition, for multivariate response variables, TSRGA can be used to yield low-rank coefficient estimates. The fast convergence of TSRGA is validated by simulation experiments. Finally, we apply the proposed TSRGA in a financial application that leverages unstructured data from the 10-K reports, demonstrating its usefulness in applications with many dense large-dimensional matrices.},
  archive      = {J_JMLR},
  author       = {Shuo-Chieh Huang and Ruey S. Tsay},
  journal      = {Journal of Machine Learning Research},
  number       = {205},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Scalable high-dimensional multivariate linear regression for feature-distributed data},
  url          = {https://jmlr.org/papers/v25/23-0882.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dropout regularization versus l2-penalization in the linear
model. <em>JMLR</em>, <em>25</em>(204), 1–48. (<a
href="https://jmlr.org/papers/v25/23-0803.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the statistical behavior of gradient descent iterates with dropout in the linear regression model. In particular, non-asymptotic bounds for the convergence of expectations and covariance matrices of the iterates are derived. The results shed more light on the widely cited connection between dropout and $\ell_2$-regularization in the linear model. We indicate a more subtle relationship, owing to interactions between the gradient descent dynamics and the additional randomness induced by dropout. Further, we study a simplified variant of dropout which does not have a regularizing effect and converges to the least squares estimator.},
  archive      = {J_JMLR},
  author       = {Gabriel Clara and Sophie Langer and Johannes Schmidt-Hieber},
  journal      = {Journal of Machine Learning Research},
  number       = {204},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Dropout regularization versus l2-penalization in the linear model},
  url          = {https://jmlr.org/papers/v25/23-0803.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient convex algorithms for universal kernel learning.
<em>JMLR</em>, <em>25</em>(203), 1–40. (<a
href="https://jmlr.org/papers/v25/23-0528.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy and complexity of machine learning algorithms based on kernel optimization are determined by the set of kernels over which they are able to optimize. An ideal set of kernels should: admit a linear parameterization (for tractability); be dense in the set of all kernels (for robustness); be universal (for accuracy). Recently, a framework was proposed for using positive matrices to parameterize a class of positive semi-separable kernels. Although this class can be shown to meet all three criteria, previous algorithms for optimization of such kernels were limited to classification and furthermore relied on computationally complex Semidefinite Programming (SDP) algorithms. In this paper, we pose the problem of learning semiseparable kernels as a minimax optimization problem and propose a SVD-QCQP primal-dual algorithm which dramatically reduces the computational complexity as compared with previous SDP-based approaches. Furthermore, we provide an efficient implementation of this algorithm for both classification and regression -- an implementation which enables us to solve problems with 100 features and up to 30,000 datums. Finally, when applied to benchmark data, the algorithm demonstrates the potential for significant improvement in accuracy over typical (but non-convex) approaches such as Neural Nets and Random Forest with similar or better computation time.},
  archive      = {J_JMLR},
  author       = {Aleksandr Talitckii and Brendon Colbert and Matthew M. Peet},
  journal      = {Journal of Machine Learning Research},
  number       = {203},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Efficient convex algorithms for universal kernel learning},
  url          = {https://jmlr.org/papers/v25/23-0528.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Manifold learning by mixture models of VAEs for inverse
problems. <em>JMLR</em>, <em>25</em>(202), 1–35. (<a
href="https://jmlr.org/papers/v25/23-0396.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representing a manifold of very high-dimensional data with generative models has been shown to be computationally efficient in practice. However, this requires that the data manifold admits a global parameterization. In order to represent manifolds of arbitrary topology, we propose to learn a mixture model of variational autoencoders. Here, every encoder-decoder pair represents one chart of a manifold. We propose a loss function for maximum likelihood estimation of the model weights and choose an architecture that provides us the analytical expression of the charts and of their inverses. Once the manifold is learned, we use it for solving inverse problems by minimizing a data fidelity term restricted to the learned manifold. To solve the arising minimization problem we propose a Riemannian gradient descent algorithm on the learned manifold. We demonstrate the performance of our method for low-dimensional toy examples as well as for deblurring and electrical impedance tomography on certain image manifolds.},
  archive      = {J_JMLR},
  author       = {Giovanni S. Alberti and Johannes Hertrich and Matteo Santacesaria and Silvia Sciutto},
  journal      = {Journal of Machine Learning Research},
  number       = {202},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Manifold learning by mixture models of VAEs for inverse problems},
  url          = {https://jmlr.org/papers/v25/23-0396.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An algorithmic framework for the optimization of deep neural
networks architectures and hyperparameters. <em>JMLR</em>,
<em>25</em>(201), 1–33. (<a
href="https://jmlr.org/papers/v25/23-0166.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose DRAGON (for DiRected Acyclic Graph OptimizatioN), an algorithmic framework to automatically generate efficient deep neural networks architectures and optimize their associated hyperparameters. The framework is based on evolving Directed Acyclic Graphs (DAGs), defining a more flexible search space than the existing ones in the literature. It allows mixtures of different classical operations: convolutions, recurrences and dense layers, but also more newfangled operations such as self-attention. Based on this search space we propose neighbourhood and evolution search operators to optimize both the architecture and hyper-parameters of our networks. These search operators can be used with any metaheuristic capable of handling mixed search spaces. We tested our algorithmic framework with an asynchronous evolutionary algorithm on a time series forecasting benchmark. The results demonstrate that DRAGON outperforms state-of-the-art handcrafted models and AutoML techniques for time series forecasting on numerous datasets. DRAGON has been implemented as a python open-source package.},
  archive      = {J_JMLR},
  author       = {Julie Keisler and El-Ghazali Talbi and Sandra Claudel and Gilles Cabriel},
  journal      = {Journal of Machine Learning Research},
  number       = {201},
  pages        = {1-33},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {An algorithmic framework for the optimization of deep neural networks architectures and hyperparameters},
  url          = {https://jmlr.org/papers/v25/23-0166.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributionally robust model-based offline reinforcement
learning with near-optimal sample complexity. <em>JMLR</em>,
<em>25</em>(200), 1–91. (<a
href="https://jmlr.org/papers/v25/22-1482.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the central issues of model robustness and sample efficiency in offline reinforcement learning (RL), which aims to learn to perform decision making from history data without active exploration. Due to uncertainties and variabilities of the environment, it is critical to learn a robust policy---with as few samples as possible---that performs well even when the deployed environment deviates from the nominal one used to collect the history dataset. We consider a distributionally robust formulation of offline RL, focusing on tabular robust Markov decision processes with an uncertainty set specified by the Kullback-Leibler divergence in both finite-horizon and infinite-horizon settings. To combat with sample scarcity, a model-based algorithm that combines distributionally robust value iteration with the principle of pessimism in the face of uncertainty is proposed, by penalizing the robust value estimates with a carefully designed data-driven penalty term. Under a mild and tailored assumption of the history dataset that measures distribution shift without requiring full coverage of the state-action space, we establish the finite-sample complexity of the proposed algorithms. We further develop an information-theoretic lower bound, which suggests that learning RMDPs is at least as hard as the standard MDPs when the uncertainty level is sufficient small, and corroborates the tightness of our upper bound up to polynomial factors of the (effective) horizon length for a range of uncertainty levels. To the best our knowledge, this provides the first provably near-optimal robust offline RL algorithm that learns under model uncertainty and partial coverage.},
  archive      = {J_JMLR},
  author       = {Laixi Shi and Yuejie Chi},
  journal      = {Journal of Machine Learning Research},
  number       = {200},
  pages        = {1-91},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Distributionally robust model-based offline reinforcement learning with near-optimal sample complexity},
  url          = {https://jmlr.org/papers/v25/22-1482.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Grokking phase transitions in learning local rules with
gradient descent. <em>JMLR</em>, <em>25</em>(199), 1–52. (<a
href="https://jmlr.org/papers/v25/22-1228.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss two solvable grokking (generalisation beyond overfitting) models in a rule-learning scenario. We show that grokking is a phase transition and find exact analytic expressions for the critical exponents, grokking probability, and grokking time distribution. Further, we introduce a tensor network map that connects the proposed grokking setup with the standard (perceptron) statistical learning theory and provide evidence that grokking is a consequence of the locality of the teacher model. We analyze the rule-30 cellular automaton learning task, numerically determine the critical exponent and the grokking time distribution, and compare them with the prediction of the proposed grokking model. Finally, we numerically study the connection between structure formation and grokking.},
  archive      = {J_JMLR},
  author       = {Bojan Žunkovič and Enej Ilievski},
  journal      = {Journal of Machine Learning Research},
  number       = {199},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Grokking phase transitions in learning local rules with gradient descent},
  url          = {https://jmlr.org/papers/v25/22-1228.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised tree boosting for learning probability
distributions. <em>JMLR</em>, <em>25</em>(198), 1–52. (<a
href="https://jmlr.org/papers/v25/22-0980.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an unsupervised tree boosting algorithm for inferring the underlying sampling distribution of an i.i.d. sample based on fitting additive tree ensembles in a manner analogous to supervised tree boosting. Integral to the algorithm is a new notion of &quot;addition&quot; on probability distributions that leads to a coherent notion of &quot;residualization&quot;, i.e., subtracting a probability distribution from an observation to remove the distributional structure from the sampling distribution of the latter. We show that these notions arise naturally for univariate distributions through cumulative distribution function (CDF) transforms and compositions due to several &quot;group-like&quot; properties of univariate CDFs. While the traditional multivariate CDF does not preserve these properties, a new definition of multivariate CDF can restore these properties, thereby allowing the notions of &quot;addition&quot; and &quot;residualization&quot; to be formulated for multivariate settings as well. This then gives rise to the unsupervised boosting algorithm based on forward-stagewise fitting of an additive tree ensemble, which sequentially reduces the Kullback-Leibler divergence from the truth. The algorithm allows analytic evaluation of the fitted density and outputs a generative model that can be readily sampled from. We enhance the algorithm with scale-dependent shrinkage and a two-stage strategy that separately fits the marginals and the copula. The algorithm then performs competitively with state-of-the-art deep-learning approaches in multivariate density estimation on multiple benchmark data sets.},
  archive      = {J_JMLR},
  author       = {Naoki Awaya and Li Ma},
  journal      = {Journal of Machine Learning Research},
  number       = {198},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Unsupervised tree boosting for learning probability distributions},
  url          = {https://jmlr.org/papers/v25/22-0980.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear regression with unmatched data: A deconvolution
perspective. <em>JMLR</em>, <em>25</em>(197), 1–55. (<a
href="https://jmlr.org/papers/v25/22-0930.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the regression problem where the response $Y\in\mathbb{R}$ and the covariate $X\in\mathbb{R}^d$ for $d\geq 1$ are unmatched. Under this scenario, we do not have access to pairs of observations from the distribution of $(X, Y)$, but instead, we have separate data sets $\{Y_i\}_{i=1}^{n_Y}$ and $\{X_j\}_{j=1}^{n_X}$, possibly collected from different sources. We study this problem assuming that the regression function is linear and the noise distribution is known, an assumption that we relax in the applications we consider. We introduce an estimator of the regression vector based on deconvolution and demonstrate its consistency and asymptotic normality under identifiability. Even when identifiability does not hold, we show in some cases that our estimator, the DLSE (Deconvolution Least Squared Estimator), is consistent in terms of an extended $\ell_2$ norm. Using this observation, we devise a method for semi-supervised learning, i.e., when we have access to a small sample of matched pairs $\{(X_k, Y_k)\}_{k=1}^m$. Several applications with synthetic and real data sets are considered to illustrate the theory.},
  archive      = {J_JMLR},
  author       = {Mona Azadkia and Fadoua Balabdaoui},
  journal      = {Journal of Machine Learning Research},
  number       = {197},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Linear regression with unmatched data: A deconvolution perspective},
  url          = {https://jmlr.org/papers/v25/22-0930.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Training integrable parameterizations of deep neural
networks in the infinite-width limit. <em>JMLR</em>, <em>25</em>(196),
1–130. (<a href="https://jmlr.org/papers/v25/21-1260.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To theoretically understand the behavior of trained deep neural networks, it is necessary to study the dynamics induced by gradient methods from a random initialization. However, the nonlinear and compositional structure of these models make these dynamics difficult to analyze. To overcome these challenges, large-width asymptotics have recently emerged as a fruitful viewpoint and led to practical insights on real-world deep networks. For two-layer neural networks, it has been understood via these asymptotics that the nature of the trained model radically changes depending on the scale of the initial random weights, ranging from a kernel regime (for large initial variance) to a feature learning regime (for small initial variance). For deeper networks more regimes are possible, and in this paper we study in detail a specific choice of &quot;small&quot; initialization corresponding to &quot;mean-field&quot; limits of neural networks, which we call integrable parameterizations (IPs). First, we show that under standard i.i.d. zero-mean initialization, integrable parameterizations of neural networks with more than four layers start at a stationary point in the infinite-width limit and no learning occurs. We then propose various methods to avoid this trivial behavior and analyze in detail the resulting dynamics. In particular, one of these methods consists in using large initial learning rates, and we show that it is equivalent to a modification of the recently proposed maximal update parameterization µP. We confirm our results with numerical experiments on image classification tasks, which additionally show a strong difference in behavior between various choices of activation functions that is not yet captured by theory.},
  archive      = {J_JMLR},
  author       = {Karl Hajjar and Lénaïc Chizat and Christophe Giraud},
  journal      = {Journal of Machine Learning Research},
  number       = {196},
  pages        = {1-130},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Training integrable parameterizations of deep neural networks in the infinite-width limit},
  url          = {https://jmlr.org/papers/v25/21-1260.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sharp analysis of power iteration for tensor PCA.
<em>JMLR</em>, <em>25</em>(195), 1–42. (<a
href="https://jmlr.org/papers/v25/24-0006.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the power iteration algorithm for the tensor PCA model introduced in Richard and Montanari (2014). Previous work studying the properties of tensor power iteration is either limited to a constant number of iterations, or requires a non-trivial data-independent initialization. In this paper, we move beyond these limitations and analyze the dynamics of randomly initialized tensor power iteration up to polynomially many steps. Our contributions are threefold: First, we establish sharp bounds on the number of iterations required for power method to converge to the planted signal, for a broad range of the signal-to-noise ratios. Second, our analysis reveals that the actual algorithmic threshold for power iteration is smaller than the one conjectured in the literature by a $\mathrm{polylog}(n)$ factor, where $n$ is the ambient dimension. Finally, we propose a simple and effective stopping criterion for power iteration, which provably outputs a solution that is highly correlated with the true signal. Extensive numerical experiments verify our theoretical results.},
  archive      = {J_JMLR},
  author       = {Yuchen Wu and Kangjie Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {195},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sharp analysis of power iteration for tensor PCA},
  url          = {https://jmlr.org/papers/v25/24-0006.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the intrinsic structures of spiking neural networks.
<em>JMLR</em>, <em>25</em>(194), 1–74. (<a
href="https://jmlr.org/papers/v25/23-1526.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have emerged a surge of interest in spiking neural networks (SNNs). The performance of SNNs hinges not only on searching apposite architectures and connection weights, similar to conventional artificial neural networks, but also on the meticulous configuration of their intrinsic structures. However, there has been a dearth of comprehensive studies examining the impact of intrinsic structures; thus developers often feel challenging to apply a standardized configuration of SNNs across diverse datasets or tasks. This work delves deep into the intrinsic structures of SNNs. Initially, we draw two key conclusions: (1) the membrane time hyper-parameter is intimately linked to the eigenvalues of the integration operation, dictating the functional topology of spiking dynamics; (2) various hyper-parameters of the firing-reset mechanism govern the overall firing capacity of an SNN, mitigating the injection ratio or sampling density of input data. These findings elucidate why the efficacy of SNNs hinges heavily on the configuration of intrinsic structures and lead to a recommendation that enhancing the adaptability of these structures contributes to improving the overall performance and applicability of SNNs. Inspired by this recognition, we propose two feasible approaches to enhance SNN learning, involving developing self-connection architectures and stochastic spiking neurons to augment the adaptability of the integration operation and firing-reset mechanism, respectively. We theoretically prove that (1) both methods promote the expressive property for universal approximation, (2) the incorporation of self-connection architectures fosters ample solutions and structural stability for SNNs approximating adaptive dynamical systems, (3) the stochastic spiking neurons maintain generalization bounds with an exponential reduction in Rademacher complexity. Empirical experiments conducted on various real-world datasets affirm the effectiveness of our proposed methods.},
  archive      = {J_JMLR},
  author       = {Shao-Qun Zhang and Jia-Yi Chen and Jin-Hui Wu and Gao Zhang and Huan Xiong and Bin Gu and Zhi-Hua Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {194},
  pages        = {1-74},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the intrinsic structures of spiking neural networks},
  url          = {https://jmlr.org/papers/v25/23-1526.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Three-way trade-off in multi-objective learning:
Optimization, generalization and conflict-avoidance. <em>JMLR</em>,
<em>25</em>(193), 1–53. (<a
href="https://jmlr.org/papers/v25/23-1287.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective learning (MOL) often arises in machine learning problems when there are multiple data modalities or tasks. One critical challenge in MOL is the potential conflict among different objectives during the optimization process. Recent works have developed various dynamic weighting algorithms for MOL, where the central idea is to find an update direction that avoids conflicts among objectives. Albeit its appealing intuition, empirical studies show that dynamic weighting methods may not outperform static ones. To understand this theory-practice gap, we focus on a stochastic variant of MGDA, the Multi-objective gradient with Double sampling (MoDo), and study the generalization performance and its interplay with optimization through the lens of algorithmic stability in the framework of statistical learning theory. We find that the key rationale behind MGDA—updating along conflict-avoidant direction—may hinder dynamic weighting algorithms from achieving the optimal $O(1/\sqrt{n})$ population risk, where $n$ is the number of training samples. We further demonstrate the impact of dynamic weights on the three-way trade-off among optimization, generalization, and conflict avoidance unique in MOL. We showcase the generality of our theoretical framework by analyzing other algorithms under the framework. Experiments on various multi-task learning benchmarks are performed to demonstrate the practical applicability. Code is available at https://github.com/heshandevaka/Trade-Off-MOL.},
  archive      = {J_JMLR},
  author       = {Lisha Chen and Heshan Fernando and Yiming Ying and Tianyi Chen},
  journal      = {Journal of Machine Learning Research},
  number       = {193},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Three-way trade-off in multi-objective learning: Optimization, generalization and conflict-avoidance},
  url          = {https://jmlr.org/papers/v25/23-1287.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural collapse for unconstrained feature model under
cross-entropy loss with imbalanced data. <em>JMLR</em>,
<em>25</em>(192), 1–48. (<a
href="https://jmlr.org/papers/v25/23-1215.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Collapse (NC) is a fascinating phenomenon that arises during the terminal phase of training (TPT) of deep neural networks (DNNs). Specifically, for balanced training datasets (each class shares the same number of samples), it is observed that the feature vectors of samples from the same class converge to their corresponding in-class mean features and their pairwise angles are the same. In this paper, we study the extension of the NC phenomenon to imbalanced datasets under cross-entropy loss function in the context of the unconstrained feature model (UFM). Our contribution is multi-fold compared with the state-of-the-art results: (a) we show that the feature vectors within the same class still collapse to the same mean vector; (b) the mean feature vectors no longer share the same pairwise angle. Instead, those angles depend on sample sizes; (c) we also characterize the sharp threshold on which the minority collapse (the feature vectors of the minority groups collapse to one single vector) will happen; (d) finally, we argue that the effect of the imbalance in datasets diminishes as the sample size grows. Our results provide a complete picture of the NC under the cross-entropy loss for imbalanced datasets. Numerical experiments confirm our theories.},
  archive      = {J_JMLR},
  author       = {Wanli Hong and Shuyang Ling},
  journal      = {Journal of Machine Learning Research},
  number       = {192},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Neural collapse for unconstrained feature model under cross-entropy loss with imbalanced data},
  url          = {https://jmlr.org/papers/v25/23-1215.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized independent noise condition for estimating
causal structure with latent variables. <em>JMLR</em>, <em>25</em>(191),
1–61. (<a href="https://jmlr.org/papers/v25/23-1052.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the challenging task of learning causal structure in the presence of latent variables, including locating latent variables, determining their quantity, and identifying causal relationships among both latent and observed variables. To address this, we propose a Generalized Independent Noise (GIN) condition for linear non-Gaussian acyclic causal models that incorporate latent variables, which establishes the independence between a linear combination of certain measured variables and some other measured variables. Specifically, for two observed random vectors $\bf{Y}$ and $\bf{Z}$, GIN holds if and only if $\omega^{\intercal}\mathbf{Y}$ and $\mathbf{Z}$ are statistically independent, where $\omega$ is a non-zero parameter vector determined by the cross-covariance between $\mathbf{Y}$ and $\mathbf{Z}$. We then give necessary and sufficient graphical criteria of the GIN condition in linear non-Gaussian acyclic causal models. From a graphical perspective, roughly speaking, GIN implies the existence of a set $\mathcal{S}$ such that $\mathcal{S}$ is causally earlier (w.r.t. the causal ordering) than $\mathbf{Y}$, and that every active (collider-free) path between $\mathbf{Y}$ and $\mathbf{Z}$ must contain a node from $\mathcal{S}$. Interestingly, we find that the independent noise condition (i.e., if there is no confounder, causes are independent of the residual derived from regressing the effect on the causes) can be seen as a special case of GIN. With such a connection between GIN and latent causal structures, we further leverage the proposed GIN condition, together with a well-designed search procedure, to efficiently estimate Linear, Non-Gaussian Latent Hierarchical Models (LiNGLaHs), where latent confounders may also be causally related and may even follow a hierarchical structure. We show that the underlying causal structure of a LiNGLaH is identifiable in light of GIN conditions under mild assumptions. Experimental results on both synthetic and three real-world data sets show the effectiveness of the proposed approach.},
  archive      = {J_JMLR},
  author       = {Feng Xie and Biwei Huang and Zhengming Chen and Ruichu Cai and Clark Glymour and Zhi Geng and Kun Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {191},
  pages        = {1-61},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Generalized independent noise condition for estimating causal structure with latent variables},
  url          = {https://jmlr.org/papers/v25/23-1052.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classification of data generated by gaussian mixture models
using deep ReLU networks. <em>JMLR</em>, <em>25</em>(190), 1–54. (<a
href="https://jmlr.org/papers/v25/23-0957.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the binary classification of unbounded data from ${\mathbb R}^d$ generated under Gaussian Mixture Models (GMMs) using deep ReLU neural networks. We obtain — for the first time — non-asymptotic upper bounds and convergence rates of the excess risk (excess misclassification error) for the classification without restrictions on model parameters. While the majority of existing generalization analysis of classification algorithms relies on a bounded domain, we consider an unbounded domain by leveraging the analyticity and fast decay of Gaussian distributions. To facilitate our analysis, we give a novel approximation error bound for general analytic functions using ReLU networks, which may be of independent interest. Gaussian distributions can be adopted nicely to model data arising in applications, e.g., speeches, images, and texts; our results provide a theoretical verification of the observed efficiency of deep neural networks in practical classification problems.},
  archive      = {J_JMLR},
  author       = {Tian-Yi Zhou and Xiaoming Huo},
  journal      = {Journal of Machine Learning Research},
  number       = {190},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Classification of data generated by gaussian mixture models using deep ReLU networks},
  url          = {https://jmlr.org/papers/v25/23-0957.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentially private topological data analysis.
<em>JMLR</em>, <em>25</em>(189), 1–42. (<a
href="https://jmlr.org/papers/v25/23-0585.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is the first to attempt differentially private (DP) topological data analysis (TDA), producing near-optimal private persistence diagrams. We analyze the sensitivity of persistence diagrams in terms of the bottleneck distance, and we show that the commonly used Cech complex has sensitivity that does not decrease as the sample size $n$ increases. This makes it challenging for the persistence diagrams of Cech complexes to be privatized. As an alternative, we show that the persistence diagram obtained by the $L^1$-distance to measure (DTM) has sensitivity $O(1/n)$. Based on the sensitivity analysis, we propose using the exponential mechanism whose utility function is defined in terms of the bottleneck distance of the $L^1$-DTM persistence diagrams. We also derive upper and lower bounds of the accuracy of our privacy mechanism; the obtained bounds indicate that the privacy error of our mechanism is near-optimal. We demonstrate the performance of our privatized persistence diagrams through simulations as well as on a real data set tracking human movement.},
  archive      = {J_JMLR},
  author       = {Taegyu Kang and Sehwan Kim and Jinwon Sohn and Jordan Awan},
  journal      = {Journal of Machine Learning Research},
  number       = {189},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Differentially private topological data analysis},
  url          = {https://jmlr.org/papers/v25/23-0585.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the optimality of misspecified spectral algorithms.
<em>JMLR</em>, <em>25</em>(188), 1–50. (<a
href="https://jmlr.org/papers/v25/23-0383.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the misspecified spectral algorithms problem, researchers usually assume the underground true function $f_{\rho}^{*} \in [\mathcal{H}]^{s}$, a less-smooth interpolation space of a reproducing kernel Hilbert space (RKHS) $\mathcal{H}$ for some $s\in (0,1)$. The existing minimax optimal results require $\|f_{\rho}^{*}\|_{L^{\infty}} \alpha_{0}$ where $\alpha_{0}\in (0,1)$ is the embedding index, a constant depending on $\mathcal{H}$. Whether the spectral algorithms are optimal for all $s\in (0,1)$ is an outstanding problem lasting for years. In this paper, we show that spectral algorithms are minimax optimal for any $\alpha_{0}-\frac{1}{\beta} &lt; s &lt; 1$, where $\beta$ is the eigenvalue decay rate of $\mathcal{H}$. We also give several classes of RKHSs whose embedding index satisfies $ \alpha_0 = \frac{1}{\beta} $. Thus, the spectral algorithms are minimax optimal for all $s\in (0,1)$ on these RKHSs.},
  archive      = {J_JMLR},
  author       = {Haobo Zhang and Yicheng Li and Qian Lin},
  journal      = {Journal of Machine Learning Research},
  number       = {188},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the optimality of misspecified spectral algorithms},
  url          = {https://jmlr.org/papers/v25/23-0383.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An entropy-based model for hierarchical learning.
<em>JMLR</em>, <em>25</em>(187), 1–45. (<a
href="https://jmlr.org/papers/v25/23-0096.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning, the predominant approach in the field of artificial intelligence, enables computers to learn from data and experience. In the supervised learning framework, accurate and efficient learning of dependencies between data instances and their corresponding labels requires auxiliary information about the data distribution and the target function. This central concept aligns with the notion of regularization in statistical learning theory. Real-world datasets are often characterized by multiscale data instance distributions and well-behaved, smooth target functions. Scale-invariant probability distributions, such as power-law distributions, provide notable examples of multiscale data instance distributions in various contexts. This paper introduces a hierarchical learning model that leverages such a multiscale data structure with a multiscale entropy-based training procedure and explores its statistical and computational advantages. The hierarchical learning model is inspired by the logical progression in human learning from easy to complex tasks and features interpretable levels. In this model, the logarithm of any data instance’s norm can be construed as the data instance&#39;s complexity, and the allocation of computational resources is tailored to this complexity, resulting in benefits such as increased inference speed. Furthermore, our multiscale analysis of the statistical risk yields stronger guarantees compared to conventional uniform convergence bounds.},
  archive      = {J_JMLR},
  author       = {Amir R. Asadi},
  journal      = {Journal of Machine Learning Research},
  number       = {187},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {An entropy-based model for hierarchical learning},
  url          = {https://jmlr.org/papers/v25/23-0096.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal clustering with bandit feedback. <em>JMLR</em>,
<em>25</em>(186), 1–54. (<a
href="https://jmlr.org/papers/v25/22-1088.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of online clustering with bandit feedback. A set of arms (or items) can be partitioned into various groups that are unknown. Within each group, the observations associated to each of the arms follow the same distribution with the same mean vector. At each time step, the agent queries or pulls an arm and obtains an independent observation from the distribution it is associated to. Subsequent pulls depend on previous ones as well as the previously obtained samples. The agent&#39;s task is to uncover the underlying partition of the arms with the least number of arm pulls and with a probability of error not exceeding a prescribed constant $\delta$. The problem proposed finds numerous applications from clustering of variants of viruses to online market segmentation. We present an instance-dependent information-theoretic lower bound on the expected sample complexity for this task, and design a computationally efficient and asymptotically optimal algorithm, namely Bandit Online Clustering (BOC). The algorithm includes a novel stopping rule for adaptive sequential testing that circumvents the need to exactly solve any NP-hard weighted clustering problem as its subroutines. We show through extensive simulations on synthetic and real-world datasets that BOC&#39;s performance matches the lower bound asymptotically, and significantly outperforms a non-adaptive baseline algorithm.},
  archive      = {J_JMLR},
  author       = {Junwen Yang and Zixin Zhong and Vincent Y. F. Tan},
  journal      = {Journal of Machine Learning Research},
  number       = {186},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal clustering with bandit feedback},
  url          = {https://jmlr.org/papers/v25/22-1088.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A flexible empirical bayes approach to multiple linear
regression and connections with penalized regression. <em>JMLR</em>,
<em>25</em>(185), 1–59. (<a
href="https://jmlr.org/papers/v25/22-0953.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new empirical Bayes approach for large-scale multiple linear regression. Our approach combines two key ideas: (i) the use of flexible &quot;adaptive shrinkage&quot; priors, which approximate the nonparametric family of scale mixture of normal distributions by a finite mixture of normal distributions; and (ii) the use of variational approximations to efficiently estimate prior hyperparameters and compute approximate posteriors. Combining these two ideas results in fast and flexible methods, with computational speed comparable to fast penalized regression methods such as the Lasso, and with competitive prediction accuracy across a wide range of scenarios. Further, we provide new results that establish conceptual connections between our empirical Bayes methods and penalized methods. Specifically, we show that the posterior mean from our method solves a penalized regression problem, with the form of the penalty function being learned from the data by directly solving an optimization problem (rather than being tuned by cross-validation). Our methods are implemented in an R package, mr.ash.alpha, available from https://github.com/stephenslab/mr.ash.alpha.},
  archive      = {J_JMLR},
  author       = {Youngseok Kim and Wei Wang and Peter Carbonetto and Matthew Stephens},
  journal      = {Journal of Machine Learning Research},
  number       = {185},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A flexible empirical bayes approach to multiple linear regression and connections with penalized regression},
  url          = {https://jmlr.org/papers/v25/22-0953.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spectral analysis of the neural tangent kernel for deep
residual networks. <em>JMLR</em>, <em>25</em>(184), 1–49. (<a
href="https://jmlr.org/papers/v25/22-0597.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep residual network architectures have been shown to achieve superior accuracy over classical feed-forward networks, yet their success is still not fully understood. Focusing on massively over-parameterized, fully connected residual networks with ReLU activation through their respective neural tangent kernels (ResNTK), we provide here a spectral analysis of these kernels. Specifically, we show that, much like NTK for fully connected networks (FC-NTK), for input distributed uniformly on the hypersphere $S^d$, the eigenvalues of ResNTK corresponding to their spherical harmonics eigenfunctions decay polynomially with frequency $k$ as $k^{-d}$. These in turn imply that the set of functions in their Reproducing Kernel Hilbert Space are identical to those of both FC-NTK as well as the standard Laplace kernel. Our spectral analysis allows us to highlight several additional properties of ResNTK, which depend on the choice of a hyper-parameter that balances between the skip and residual connections. Specifically, (1) with no bias, deep ResNTK is significantly biased toward even frequency functions; (2) unlike FC-NTK for deep networks, which is spiky and therefore yields poor generalization, ResNTK is stable and yields small generalization errors. We finally demonstrate these with experiments showing further that these phenomena arise in real networks.},
  archive      = {J_JMLR},
  author       = {Yuval Belfer and Amnon Geifman and Meirav Galun and Ronen Basri},
  journal      = {Journal of Machine Learning Research},
  number       = {184},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Spectral analysis of the neural tangent kernel for deep residual networks},
  url          = {https://jmlr.org/papers/v25/22-0597.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Permuted and unlinked monotone regression in r^d: An
approach based on mixture modeling and optimal transport. <em>JMLR</em>,
<em>25</em>(183), 1–57. (<a
href="https://jmlr.org/papers/v25/22-0058.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suppose that we have a regression problem with response variable $Y \in \mathbb{R}^d$ and predictor $X \in \mathbb{R}^d$, for $d \ge 1$. In permuted or unlinked regression we have access to separate unordered data on $X$ and $Y$, as opposed to data on $(X,Y)$-pairs in usual regression. So far in the literature the case $d=1$ has received attention, see e.g., the recent papers by Rigollet and Weed [Information &amp; Inference, 8, 619-717] and Balabdaoui et al. [J. Mach. Learn. Res., 22 (172), 1-60]. In this paper, we consider the general multivariate setting with $d \geq 1$. We show that the notion of cyclical monotonicity of the regression function is sufficient for identification and estimation in the permuted/unlinked regression model. We study permutation recovery in the permuted regression setting and develop a computationally efficient and easy-to-use algorithm for denoising based on the Kiefer-Wolfowitz [Ann. Math. Statist., 27, 887-906] nonparametric maximum likelihood estimator and techniques from the theory of optimal transport. We provide explicit upper bounds on the associated mean squared denoising error for Gaussian noise. As in previous work on the case $d = 1$, the permuted/unlinked setting involves slow (logarithmic) rates of convergence rooted in the underlying deconvolution problem. We also provide an extension to a certain class of elliptic noise distributions that includes a multivariate generalization of the Laplace distribution, for which polynomial rates can be obtained. Numerical studies complement our theoretical analysis and show that the proposed approach performs at least on par with the methods in the aforementioned prior work in the case $d = 1$ while achieving substantial reductions in terms of computational complexity.},
  archive      = {J_JMLR},
  author       = {Martin Slawski and Bodhisattva Sen},
  journal      = {Journal of Machine Learning Research},
  number       = {183},
  pages        = {1-57},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Permuted and unlinked monotone regression in r^d: An approach based on mixture modeling and optimal transport},
  url          = {https://jmlr.org/papers/v25/22-0058.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Volterra neural networks (VNNs). <em>JMLR</em>,
<em>25</em>(182), 1–29. (<a
href="https://jmlr.org/papers/v25/21-1082.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of inference in Machine Learning (ML) has led to an explosive number of different proposals, particularly in Deep Learning. In an attempt to reduce the complexity of Convolutional Neural Networks, we propose a Volterra filter-inspired Network architecture. This architecture introduces controlled non-linearities in the form of interactions between the delayed input samples of data. We propose a cascaded implementation of Volterra Filtering so as to significantly reduce the number of parameters required to carry out the same classification task as that of a conventional Neural Network. We demonstrate an efficient parallel implementation of this Volterra Neural Network (VNN), along with its remarkable performance while retaining a relatively simpler and potentially more tractable structure. Furthermore, we show a rather sophisticated adaptation of this network to nonlinearly fuse the RGB (spatial) information and the Optical Flow (temporal) information of a video sequence for action recognition. The proposed approach is evaluated on UCF-101 and HMDB-51 datasets for action recognition, and is shown to outperform state of the art CNN approaches.},
  archive      = {J_JMLR},
  author       = {Siddharth Roheda and Hamid Krim and Bo Jiang},
  journal      = {Journal of Machine Learning Research},
  number       = {182},
  pages        = {1-29},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Volterra neural networks (VNNs)},
  url          = {https://jmlr.org/papers/v25/21-1082.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards optimal sobolev norm rates for the vector-valued
regularized least-squares algorithm. <em>JMLR</em>, <em>25</em>(181),
1–51. (<a href="https://jmlr.org/papers/v25/23-1663.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the first optimal rates for infinite-dimensional vector-valued ridge regression on a continuous scale of norms that interpolate between L2 and the hypothesis space, which we consider as a vector-valued reproducing kernel Hilbert space. These rates allow to treat the misspecified case in which the true regression function is not contained in the hypothesis space. We combine standard assumptions on the capacity of the hypothesis space with a novel tensor product construction of vector-valued interpolation spaces in order to characterize the smoothness of the regression function. Our upper bound not only attains the same rate as real-valued kernel ridge regression, but also removes the assumption that the target regression function is bounded. For the lower bound, we reduce the problem to the scalar setting using a projection argument. We show that these rates are optimal in most cases and independent of the dimension of the output space. We illustrate our results for the special case of vector-valued Sobolev spaces.},
  archive      = {J_JMLR},
  author       = {Zhu Li and Dimitri Meunier and Mattes Mollenhauer and Arthur Gretton},
  journal      = {Journal of Machine Learning Research},
  number       = {181},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Towards optimal sobolev norm rates for the vector-valued regularized least-squares algorithm},
  url          = {https://jmlr.org/papers/v25/23-1663.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian regression markets. <em>JMLR</em>,
<em>25</em>(180), 1–38. (<a
href="https://jmlr.org/papers/v25/23-1385.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although machine learning tasks are highly sensitive to the quality of input data, relevant datasets can often be challenging for firms to acquire, especially when held privately by a variety of owners. For instance, if these owners are competitors in a downstream market, they may be reluctant to share information. Focusing on supervised learning for regression tasks, we develop a regression market to provide a monetary incentive for data sharing. Our mechanism adopts a Bayesian framework, allowing us to consider a more general class of regression tasks. We present a thorough exploration of the market properties, and show that similar proposals in literature expose the market agents to sizeable financial risks, which can be mitigated in our setup.},
  archive      = {J_JMLR},
  author       = {Thomas Falconer and Jalal Kazempour and Pierre Pinson},
  journal      = {Journal of Machine Learning Research},
  number       = {180},
  pages        = {1-38},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bayesian regression markets},
  url          = {https://jmlr.org/papers/v25/23-1385.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sharpness-aware minimization and the edge of stability.
<em>JMLR</em>, <em>25</em>(179), 1–20. (<a
href="https://jmlr.org/papers/v25/23-1285.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent experiments have shown that, often, when training a neural network with gradient descent (GD) with a step size $\eta$, the operator norm of the Hessian of the loss grows until it approximately reaches $2/\eta$, after which it fluctuates around this value. The quantity $2/\eta$ has been called the “edge of stability” based on consideration of a local quadratic approximation of the loss. We perform a similar calculation to arrive at an “edge of stability” for Sharpness-Aware Minimization (SAM), a variant of GD which has been shown to improve its generalization. Unlike the case for GD, the resulting SAM-edge depends on the norm of the gradient. Using three deep learning training tasks, we see empirically that SAM operates on the edge of stability identified by this analysis.},
  archive      = {J_JMLR},
  author       = {Philip M. Long and Peter L. Bartlett},
  journal      = {Journal of Machine Learning Research},
  number       = {179},
  pages        = {1-20},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sharpness-aware minimization and the edge of stability},
  url          = {https://jmlr.org/papers/v25/23-1285.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimistic online mirror descent for bridging stochastic and
adversarial online convex optimization. <em>JMLR</em>, <em>25</em>(178),
1–62. (<a href="https://jmlr.org/papers/v25/23-1072.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastically extended adversarial (SEA) model, introduced by Sachs et al. (2022), serves as an interpolation between stochastic and adversarial online convex optimization. Under the smoothness condition on expected loss functions, it is shown that the expected static regret of optimistic follow-the-regularized-leader (FTRL) depends on the cumulative stochastic variance $\sigma_{1:T}^2$ and the cumulative adversarial variation $\Sigma_{1:T}^2$ for convex functions. Sachs et al. (2022) also provide a regret bound based on the maximal stochastic variance $\sigma_{\max}^2$ and the maximal adversarial variation $\Sigma_{\max}^2$ for strongly convex functions. Inspired by their work, we investigate the theoretical guarantees of optimistic online mirror descent (OMD) for the SEA model with smooth expected loss functions. For convex and smooth functions, we obtain the same $\mathcal{O}(\sqrt{\sigma_{1:T}^2}+\sqrt{\Sigma_{1:T}^2})$ regret bound, but with a relaxation of the convexity requirement from individual functions to expected functions. For strongly convex and smooth functions, we establish an $\mathcal{O}\left(\frac{1}{\lambda}\left(\sigma_{\max}^2+\Sigma_{\max}^2\right)\log \left(\left(\sigma_{1:T}^2 + \Sigma_{1:T}^2\right)/\left(\sigma_{\max}^2+\Sigma_{\max}^2\right)\right)\right)$ bound, better than their $\mathcal{O}((\sigma_{\max}^2$ $ + \Sigma_{\max}^2) \log T)$ result. For exp-concave and smooth functions, our approach yields a new $\mathcal{O}(d\log(\sigma_{1:T}^2+\Sigma_{1:T}^2))$ bound. Moreover, we introduce the first expected dynamic regret guarantee for the SEA model with convex and smooth expected functions, which is more favorable than static regret bounds in non-stationary environments. Furthermore, we expand our investigation to scenarios with non-smooth expected loss functions and propose novel algorithms built upon optimistic OMD with an implicit update, successfully attaining both static and dynamic regret guarantees.},
  archive      = {J_JMLR},
  author       = {Sijia Chen and Yu-Jie Zhang and Wei-Wei Tu and Peng Zhao and Lijun Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {178},
  pages        = {1-62},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimistic online mirror descent for bridging stochastic and adversarial online convex optimization},
  url          = {https://jmlr.org/papers/v25/23-1072.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective neural architecture search by learning
search space partitions. <em>JMLR</em>, <em>25</em>(177), 1–41. (<a
href="https://jmlr.org/papers/v25/23-1013.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying deep learning models requires taking into consideration neural network metrics such as model size, inference latency, and #FLOPs, aside from inference accuracy. This results in deep learning model designers leveraging multi-objective optimization to design effective deep neural networks in multiple criteria. However, applying multi-objective optimizations to neural architecture search (NAS) is nontrivial because NAS tasks usually have a huge search space, along with a non-negligible searching cost. This requires effective multi-objective search algorithms to alleviate the GPU costs. In this work, we implement a novel multi-objectives optimizer based on a recently proposed meta-algorithm called LaMOO on NAS tasks. In a nutshell, LaMOO speedups the search process by learning a model from observed samples to partition the search space and then focusing on promising regions likely to contain a subset of the Pareto frontier. Using LaMOO, we observe an improvement of more than 200% sample efficiency compared to Bayesian optimization and evolutionary-based multi-objective optimizers on different NAS datasets. For example, when combined with LaMOO, qEHVI achieves a 225% improvement in sample efficiency compared to using qEHVI alone in NasBench201. For real-world tasks, LaMOO achieves 97.36% accuracy with only 1.62M #Params on CIFAR10 in only 600 search samples. On ImageNet, our large model reaches 80.4% top-1 accuracy with only 522M #FLOPs.},
  archive      = {J_JMLR},
  author       = {Yiyang Zhao and Linnan Wang and Tian Guo},
  journal      = {Journal of Machine Learning Research},
  number       = {177},
  pages        = {1-41},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Multi-objective neural architecture search by learning search space partitions},
  url          = {https://jmlr.org/papers/v25/23-1013.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fermat distances: Metric approximation, spectral
convergence, and clustering algorithms. <em>JMLR</em>, <em>25</em>(176),
1–65. (<a href="https://jmlr.org/papers/v25/23-0939.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the convergence properties of Fermat distances, a family of density-driven metrics defined on Riemannian manifolds with an associated probability measure. Fermat distances may be defined either on discrete samples from the underlying measure, in which case they are random, or in the continuum setting, where they are induced by geodesics under a density-distorted Riemannian metric. We prove that discrete, sample-based Fermat distances converge to their continuum analogues in small neighborhoods with a precise rate that depends on the intrinsic dimensionality of the data and the parameter governing the extent of density weighting in Fermat distances. This is done by leveraging novel geometric and statistical arguments in percolation theory that allow for non-uniform densities and curved domains. Our results are then used to prove that discrete graph Laplacians based on discrete, sample-driven Fermat distances converge to corresponding continuum operators. In particular, we show the discrete eigenvalues and eigenvectors converge to their continuum analogues at a dimension-dependent rate, which allows us to interpret the efficacy of discrete spectral clustering using Fermat distances in terms of the resulting continuum limit. The perspective afforded by our discrete-to-continuum Fermat distance analysis leads to new clustering algorithms for data and related insights into efficient computations associated to density-driven spectral clustering. Our theoretical analysis is supported with numerical simulations and experiments on synthetic and real image data.},
  archive      = {J_JMLR},
  author       = {Nicolás García Trillos and Anna Little and Daniel McKenzie and James M. Murphy},
  journal      = {Journal of Machine Learning Research},
  number       = {176},
  pages        = {1-65},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fermat distances: Metric approximation, spectral convergence, and clustering algorithms},
  url          = {https://jmlr.org/papers/v25/23-0939.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spherical rotation dimension reduction with geometric loss
functions. <em>JMLR</em>, <em>25</em>(175), 1–55. (<a
href="https://jmlr.org/papers/v25/23-0547.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern datasets often exhibit high dimensionality, yet the data reside in low-dimensional manifolds that can reveal underlying geometric structures critical for data analysis. A prime example of such a dataset is a collection of cell cycle measurements, where the inherently cyclical nature of the process can be represented as a circle or sphere. Motivated by the need to analyze these types of datasets, we propose a nonlinear dimension reduction method, Spherical Rotation Component Analysis (SRCA), that incorporates geometric information to better approximate low-dimensional manifolds. SRCA is a versatile method designed to work in both high-dimensional and small sample size settings. By employing spheres or ellipsoids, SRCA provides a low-rank spherical representation of the data with general theoretic guarantees, effectively retaining the geometric structure of the dataset during dimensionality reduction. A comprehensive simulation study, along with a successful application to human cell cycle data, further highlights the advantages of SRCA compared to state-of-the-art alternatives, demonstrating its superior performance in approximating the manifold while preserving inherent geometric structures.},
  archive      = {J_JMLR},
  author       = {Hengrui Luo and Jeremy E. Purvis and Didong Li},
  journal      = {Journal of Machine Learning Research},
  number       = {175},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Spherical rotation dimension reduction with geometric loss functions},
  url          = {https://jmlr.org/papers/v25/23-0547.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A PDE-based explanation of extreme numerical sensitivities
and edge of stability in training neural networks. <em>JMLR</em>,
<em>25</em>(174), 1–40. (<a
href="https://jmlr.org/papers/v25/23-0137.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discover restrained numerical instabilities in current training practices of deep networks with stochastic gradient descent (SGD), and its variants. We show numerical error (on the order of the smallest floating point bit and thus the most extreme or limiting numerical perturbations induced from floating point arithmetic in training deep nets can be amplified significantly and result in significant test accuracy variance (sensitivities), comparable to the test accuracy variance due to stochasticity in SGD. We show how this is likely traced to instabilities of the optimization dynamics that are restrained, i.e., localized over iterations and regions of the weight tensor space. We do this by presenting a theoretical framework using numerical analysis of partial differential equations (PDE), and analyzing the gradient descent PDE of convolutional neural networks (CNNs). We show that it is stable only under certain conditions on the learning rate and weight decay. We show that rather than blowing up when the conditions are violated, the instability can be restrained. We show this is a consequence of the non-linear PDE associated with the gradient descent of the CNN, whose local linearization changes when over-driving the step size of the discretization, resulting in a stabilizing effect. We link restrained instabilities to the recently discovered Edge of Stability (EoS) phenomena, in which the stable step size predicted by classical theory is exceeded while continuing to optimize the loss and still converging. Because restrained instabilities occur at the EoS, our theory provides new insights and predictions about the EoS, in particular, the role of regularization and the dependence on the network complexity.},
  archive      = {J_JMLR},
  author       = {Yuxin Sun and Dong Lao and Anthony Yezzi and Ganesh Sundaramoorthi},
  journal      = {Journal of Machine Learning Research},
  number       = {174},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A PDE-based explanation of extreme numerical sensitivities and edge of stability in training neural networks},
  url          = {https://jmlr.org/papers/v25/23-0137.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two is better than one: Regularized shrinkage of large
minimum variance portfolios. <em>JMLR</em>, <em>25</em>(173), 1–32. (<a
href="https://jmlr.org/papers/v25/22-1337.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we construct a shrinkage estimator of the global minimum variance (GMV) portfolio by combining two techniques: Tikhonov regularization and direct shrinkage of portfolio weights. More specifically, we employ a double shrinkage approach, where the covariance matrix and portfolio weights are shrunk simultaneously. The ridge parameter controls the stability of the covariance matrix, while the portfolio shrinkage intensity shrinks the regularized portfolio weights to a predefined target. Both parameters simultaneously minimize, with probability one, the out-of-sample variance as the number of assets $p$ and the sample size $n$ tend to infinity, while their ratio $p/n$ tends to a constant $c &gt; 0$. This method can also be seen as the optimal combination of the well-established linear shrinkage approach of Ledoit and Wolf (2004) and the shrinkage of the portfolio weights by Bodnar, Parolya and Schmid (2018). No specific distribution is assumed for the asset returns, except for the assumption of finite moments of order $4 + \varepsilon$ for $\varepsilon &gt; 0$. The performance of the double shrinkage estimator is investigated via extensive simulation and empirical studies. The suggested method significantly outperforms its predecessor (without regularization) and the nonlinear shrinkage approach in terms of the out-of-sample variance, Sharpe ratio, and other empirical measures in the majority of scenarios. Moreover, it maintains the most stable portfolio weights with uniformly smallest turnover.},
  archive      = {J_JMLR},
  author       = {Taras Bodnar and Nestor Parolya and Erik Thorsen},
  journal      = {Journal of Machine Learning Research},
  number       = {173},
  pages        = {1-32},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Two is better than one: Regularized shrinkage of large minimum variance portfolios},
  url          = {https://jmlr.org/papers/v25/22-1337.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decentralized natural policy gradient with variance
reduction for collaborative multi-agent reinforcement learning.
<em>JMLR</em>, <em>25</em>(172), 1–49. (<a
href="https://jmlr.org/papers/v25/22-1036.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a policy optimization problem arising from collaborative multi-agent reinforcement learning in a decentralized setting where agents communicate with their neighbors over an undirected graph to maximize the sum of their cumulative rewards. A novel decentralized natural policy gradient method, dubbed Momentum-based Decentralized Natural Policy Gradient (MDNPG), is proposed, which incorporates natural gradient, momentum-based variance reduction, and gradient tracking into the decentralized stochastic gradient ascent framework. The $\mathcal{O}(n^{-1}\epsilon^{-3})$ sample complexity for MDNPG to converge to an $\epsilon$-stationary point has been established under standard assumptions, where $n$ is the number of agents. It indicates that MDNPG can achieve the optimal convergence rate for decentralized policy gradient methods and possesses a linear speedup in contrast to centralized optimization methods. Moreover, superior empirical performance of MDNPG over other state-of-the-art algorithms has been demonstrated by extensive numerical experiments.},
  archive      = {J_JMLR},
  author       = {Jinchi Chen and Jie Feng and Weiguo Gao and Ke Wei},
  journal      = {Journal of Machine Learning Research},
  number       = {172},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Decentralized natural policy gradient with variance reduction for collaborative multi-agent reinforcement learning},
  url          = {https://jmlr.org/papers/v25/22-1036.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Log barriers for safe black-box optimization with
application to safe reinforcement learning. <em>JMLR</em>,
<em>25</em>(171), 1–54. (<a
href="https://jmlr.org/papers/v25/22-0878.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing noisy functions online, when evaluating the objective requires experiments on a deployed system, is a crucial task arising in manufacturing, robotics and various other domains. Often, constraints on safe inputs are unknown ahead of time, and we only obtain noisy information, indicating how close we are to violating the constraints. Yet, safety must be guaranteed at all times, not only for the final output of the algorithm. We introduce a general approach for seeking a stationary point in high dimensional non-linear stochastic optimization problems in which maintaining safety during learning is crucial. Our approach called LB-SGD, is based on applying stochastic gradient descent (SGD) with a carefully chosen adaptive step size to a logarithmic barrier approximation of the original problem. We provide a complete convergence analysis of non-convex, convex, and strongly-convex smooth constrained problems, with first-order and zeroth-order feedback. Our approach yields efficient updates and scales better with dimensionality compared to existing approaches. We empirically compare the sample complexity and the computational cost of our method with existing safe learning approaches. Beyond synthetic benchmarks, we demonstrate the effectiveness of our approach on minimizing constraint violation in policy search tasks in safe reinforcement learning (RL).},
  archive      = {J_JMLR},
  author       = {Ilnura Usmanova and Yarden As and Maryam Kamgarpour and Andreas Krause},
  journal      = {Journal of Machine Learning Research},
  number       = {171},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Log barriers for safe black-box optimization with application to safe reinforcement learning},
  url          = {https://jmlr.org/papers/v25/22-0878.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cluster-adaptive network a/b testing: From randomization to
estimation. <em>JMLR</em>, <em>25</em>(170), 1–48. (<a
href="https://jmlr.org/papers/v25/22-0192.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of A/B testing in both online and offline experimental settings hinges on mitigating network interference and achieving covariate balancing. These experiments often involve an observable network with identifiable clusters, and measurable cluster-level and individual-level attributes. Exploiting these inherent characteristics holds potential for refining experimental design and subsequent statistical analyses. In this article, we propose a novel cluster-adaptive network A/B testing procedure, which contains a cluster-adaptive randomization (CLAR) and a cluster-adjusted estimator (CAE) to facilitate the design of the experiment and enhance the performance of ATE estimation. The CLAR sequentially assigns clusters to minimize the Mahalanobis distance, which further leads to the balance of the cluster-level covariates and the within-cluster-averaged individual-level covariates. The cluster-adjusted estimator (CAE) is tailored to offset biases caused by network interference. The proposed procedure has the following two folds of the desirable properties. First, we show that the Malanobis distance calculated for the two levels of covariates is $O_p(m^{-1})$, where $m$ represents the number of clusters. This result justifies the simultaneous balance of the cluster-level and individual-level covariates. Under mild conditions, we derive the asymptotic normality of CAE and demonstrate the benefit of covariate balancing on improving the precision for estimating ATE. The proposed A/B testing procedure is easy to calculate, consistent, and achieves higher accuracy. Extensive numerical studies are conducted to demonstrate the finite sample property of the proposed network A/B testing procedure.},
  archive      = {J_JMLR},
  author       = {Yang Liu and Yifan Zhou and Ping Li and Feifang Hu},
  journal      = {Journal of Machine Learning Research},
  number       = {170},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Cluster-adaptive network A/B testing: From randomization to estimation},
  url          = {https://jmlr.org/papers/v25/22-0192.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the computational and statistical complexity of
over-parameterized matrix sensing. <em>JMLR</em>, <em>25</em>(169),
1–47. (<a href="https://jmlr.org/papers/v25/21-1437.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider solving the low-rank matrix sensing problem with the Factorized Gradient Descent (FGD) method when the specified rank is larger than the true rank. We refer to this as over-parameterized matrix sensing. If the ground truth signal $\mathbf{X}^* \in \mathbb{R}^{d \times d}$ is of rank $r$, but we try to recover it using $\mathbf{F} \mathbf{F}^\top$ where $\mathbf{F} \in \mathbb{R}^{d \times k}$ and $k&gt;r$, the existing statistical analysis either no longer holds or produces a vacuous statistical error upper bound (infinity) due to the flat local curvature of the loss function around the global maxima. By decomposing the factorized matrix $\mathbf{F}$ into separate column spaces to capture the impact of using $k &gt; r$, we show that $\left\| {\mathbf{F}_t \mathbf{F}_t - \mathbf{X}^*} \right\|_F^2$ converges sub-linearly to a statistical error of $\tilde{\mathcal{O}} (k d \sigma^2/n)$ after $\tilde{\mathcal{O}}(\frac{\sigma_{r}}{\sigma}\sqrt{\frac{n}{d}})$ iterations, where $\mathbf{F}_t$ is the output of FGD after $t$ iterations, $\sigma^2$ is the variance of the observation noise, $\sigma_{r}$ is the $r$-th largest eigenvalue of $\mathbf{X}^*$, and $n$ is the number of samples. With a precise characterization of the convergence behavior and the statistical error, our results, therefore, offer a comprehensive picture of the statistical and computational complexity if we solve the over-parameterized matrix sensing problem with FGD.},
  archive      = {J_JMLR},
  author       = {Jiacheng Zhuo and Jeongyeol Kwon and Nhat Ho and Constantine Caramanis},
  journal      = {Journal of Machine Learning Research},
  number       = {169},
  pages        = {1-47},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the computational and statistical complexity of over-parameterized matrix sensing},
  url          = {https://jmlr.org/papers/v25/21-1437.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization-based causal estimation from heterogeneous
environments. <em>JMLR</em>, <em>25</em>(168), 1–44. (<a
href="https://jmlr.org/papers/v25/21-1028.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new optimization approach to causal estimation. Given data that contains covariates and an outcome, which covariates are causes of the outcome, and what is the strength of the causality? In classical machine learning (ML), the goal of optimization is to maximize predictive accuracy. However, some covariates might exhibit a non-causal association with the outcome. Such spurious associations provide predictive power for classical ML, but they prevent us from causally interpreting the result. This paper proposes CoCo, an optimization algorithm that bridges the gap between pure prediction and causal inference. CoCo leverages the recently-proposed idea of environments, datasets of covariates/response where the causal relationships remain invariant but where the distribution of the covariates changes from environment to environment. Given datasets from multiple environments—and ones that exhibit sufficient heterogeneity—CoCo maximizes an objective for which the only solution is the causal solution. We describe the theoretical foundations of this approach and demonstrate its effectiveness on simulated and real datasets. Compared to classical ML and existing methods, CoCo provides more accurate estimates of the causal model and more accurate predictions under interventions.},
  archive      = {J_JMLR},
  author       = {Mingzhang Yin and Yixin Wang and David M. Blei},
  journal      = {Journal of Machine Learning Research},
  number       = {168},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimization-based causal estimation from heterogeneous environments},
  url          = {https://jmlr.org/papers/v25/21-1028.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal locally private nonparametric classification with
public data. <em>JMLR</em>, <em>25</em>(167), 1–62. (<a
href="https://jmlr.org/papers/v25/23-1563.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate the problem of public data assisted non-interactive Local Differentially Private (LDP) learning with a focus on non-parametric classification. Under the posterior drift assumption, we for the first time derive the mini-max optimal convergence rate with LDP constraint. Then, we present a novel approach, the locally differentially private classification tree, which attains the mini-max optimal convergence rate. Furthermore, we design a data-driven pruning procedure that avoids parameter tuning and provides a fast converging estimator. Comprehensive experiments conducted on synthetic and real data sets show the superior performance of our proposed methods. Both our theoretical and experimental findings demonstrate the effectiveness of public data compared to private data, which leads to practical suggestions for prioritizing non-private data collection.},
  archive      = {J_JMLR},
  author       = {Yuheng Ma and Hanfang Yang},
  journal      = {Journal of Machine Learning Research},
  number       = {167},
  pages        = {1-62},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal locally private nonparametric classification with public data},
  url          = {https://jmlr.org/papers/v25/23-1563.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning to warm-start fixed-point optimization algorithms.
<em>JMLR</em>, <em>25</em>(166), 1–46. (<a
href="https://jmlr.org/papers/v25/23-1174.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a machine-learning framework to warm-start fixed-point optimization algorithms. Our architecture consists of a neural network mapping problem parameters to warm starts, followed by a predefined number of fixed-point iterations. We propose two loss functions designed to either minimize the fixed-point residual or the distance to a ground truth solution. In this way, the neural network predicts warm starts with the end-to-end goal of minimizing the downstream loss. An important feature of our architecture is its flexibility, in that it can predict a warm start for fixed-point algorithms run for any number of steps, without being limited to the number of steps it has been trained on. We provide PAC-Bayes generalization bounds on unseen data for common classes of fixed-point operators: contractive, linearly convergent, and averaged. Applying this framework to well-known applications in control, statistics, and signal processing, we observe a significant reduction in the number of iterations and solution time required to solve these problems, through learned warm starts.},
  archive      = {J_JMLR},
  author       = {Rajiv Sambharya and Georgina Hall and Brandon Amos and Bartolomeo Stellato},
  journal      = {Journal of Machine Learning Research},
  number       = {166},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning to warm-start fixed-point optimization algorithms},
  url          = {https://jmlr.org/papers/v25/23-1174.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonparametric regression using over-parameterized shallow
ReLU neural networks. <em>JMLR</em>, <em>25</em>(165), 1–35. (<a
href="https://jmlr.org/papers/v25/23-0918.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is shown that over-parameterized neural networks can achieve minimax optimal rates of convergence (up to logarithmic factors) for learning functions from certain smooth function classes, if the weights are suitably constrained or regularized. Specifically, we consider the nonparametric regression of estimating an unknown $d$-variate function by using shallow ReLU neural networks. It is assumed that the regression function is from the H\&quot;older space with smoothness $\alpha&lt;(d+3)/2$ or a variation space corresponding to shallow neural networks, which can be viewed as an infinitely wide neural network. In this setting, we prove that least squares estimators based on shallow neural networks with certain norm constraints on the weights are minimax optimal, if the network width is sufficiently large. As a byproduct, we derive a new size-independent bound for the local Rademacher complexity of shallow ReLU neural networks, which may be of independent interest.},
  archive      = {J_JMLR},
  author       = {Yunfei Yang and Ding-Xuan Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {165},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Nonparametric regression using over-parameterized shallow ReLU neural networks},
  url          = {https://jmlr.org/papers/v25/23-0918.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonparametric copula models for multivariate, mixed, and
missing data. <em>JMLR</em>, <em>25</em>(164), 1–50. (<a
href="https://jmlr.org/papers/v25/23-0495.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern data sets commonly feature both substantial missingness and many variables of mixed data types, which present significant challenges for estimation and inference. Complete case analysis, which proceeds using only the observations with fully-observed variables, is often severely biased, while model-based imputation of missing values is limited by the ability of the model to capture complex dependencies among (possibly many) variables of mixed data types. To address these challenges, we develop a novel Bayesian mixture copula for joint and nonparametric modeling of multivariate count, continuous, ordinal, and unordered categorical variables, and deploy this model for inference, prediction, and imputation of missing data. Most uniquely, we introduce a new and computationally efficient strategy for marginal distribution estimation that eliminates the need to specify any marginal models yet delivers posterior consistency for each marginal distribution and the copula parameters under missingness-at-random. Extensive simulation studies demonstrate exceptional modeling and imputation capabilities relative to competing methods, especially with mixed data types, complex missingness mechanisms, and nonlinear dependencies. We conclude with a data analysis that highlights how improper treatment of missing data can distort a statistical analysis, and how the proposed approach offers a resolution.},
  archive      = {J_JMLR},
  author       = {Joseph Feldman and Daniel R. Kowal},
  journal      = {Journal of Machine Learning Research},
  number       = {164},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Nonparametric copula models for multivariate, mixed, and missing data},
  url          = {https://jmlr.org/papers/v25/23-0495.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An analysis of quantile temporal-difference learning.
<em>JMLR</em>, <em>25</em>(163), 1–47. (<a
href="https://jmlr.org/papers/v25/23-0154.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyse quantile temporal-difference learning (QTD), a distributional reinforcement learning algorithm that has proven to be a key component in several successful large-scale applications of reinforcement learning. Despite these empirical successes, a theoretical understanding of QTD has proven elusive until now. Unlike classical TD learning, which can be analysed with standard stochastic approximation tools, QTD updates do not approximate contraction mappings, are highly non-linear, and may have multiple fixed points. The core result of this paper is a proof of convergence to the fixed points of a related family of dynamic programming procedures with probability 1, putting QTD on firm theoretical footing. The proof establishes connections between QTD and non-linear differential inclusions through stochastic approximation theory and non-smooth analysis.},
  archive      = {J_JMLR},
  author       = {Mark Rowland and Rémi Munos and Mohammad Gheshlaghi Azar and Yunhao Tang and Georg Ostrovski and Anna Harutyunyan and Karl Tuyls and Marc G. Bellemare and Will Dabney},
  journal      = {Journal of Machine Learning Research},
  number       = {163},
  pages        = {1-47},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {An analysis of quantile temporal-difference learning},
  url          = {https://jmlr.org/papers/v25/23-0154.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conformal inference for online prediction with arbitrary
distribution shifts. <em>JMLR</em>, <em>25</em>(162), 1–36. (<a
href="https://jmlr.org/papers/v25/22-1218.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of forming prediction sets in an online setting where the distribution generating the data is allowed to vary over time. Previous approaches to this problem suffer from over-weighting historical data and thus may fail to quickly react to the underlying dynamics. Here, we correct this issue and develop a novel procedure with provably small regret over all local time intervals of a given width. We achieve this by modifying the adaptive conformal inference (ACI) algorithm of Gibbs and Candès (2021) to contain an additional step in which the step-size parameter of ACI&#39;s gradient descent update is tuned over time. Crucially, this means that unlike ACI, which requires knowledge of the rate of change of the data-generating mechanism, our new procedure is adaptive to both the size and type of the distribution shift. Our methods are highly flexible and can be used in combination with any baseline predictive algorithm that produces point estimates or estimated quantiles of the target without the need for distributional assumptions. We test our techniques on two real-world datasets aimed at predicting stock market volatility and COVID-19 case counts and find that they are robust and adaptive to real-world distribution shifts.},
  archive      = {J_JMLR},
  author       = {Isaac Gibbs and Emmanuel J. Candès},
  journal      = {Journal of Machine Learning Research},
  number       = {162},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Conformal inference for online prediction with arbitrary distribution shifts},
  url          = {https://jmlr.org/papers/v25/22-1218.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). More efficient estimation of multivariate additive models
based on tensor decomposition and penalization. <em>JMLR</em>,
<em>25</em>(161), 1–27. (<a
href="https://jmlr.org/papers/v25/22-0578.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider parsimonious modeling of high-dimensional multivariate additive models using regression splines, with or without sparsity assumptions. The approach is based on treating the coefficients in the spline expansions as a third-order tensor. Note the data does not have tensor predictors or tensor responses, which distinguishes our study from the existing ones. A Tucker decomposition is used to reduce the number of parameters in the tensor. We also combined the Tucker decomposition with penalization to enable variable selection. The proposed method can avoid the statistical inefficiency caused by estimating a large number of nonparametric functions. We provide sufficient conditions under which the proposed tensor-based estimators achieve the optimal rate of convergence for the nonparametric regression components. We conduct simulation studies to demonstrate the effectiveness of the proposed novel approach in fitting high-dimensional multivariate additive models and illustrate its application on a breast cancer copy number variation and gene expression data set.},
  archive      = {J_JMLR},
  author       = {Xu Liu and Heng Lian and Jian Huang},
  journal      = {Journal of Machine Learning Research},
  number       = {161},
  pages        = {1-27},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {More efficient estimation of multivariate additive models based on tensor decomposition and penalization},
  url          = {https://jmlr.org/papers/v25/22-0578.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A kernel test for causal association via noise contrastive
backdoor adjustment. <em>JMLR</em>, <em>25</em>(160), 1–56. (<a
href="https://jmlr.org/papers/v25/21-1409.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference grows increasingly complex as the dimension of confounders increases. Given treatments $X$, outcomes $Y$, and measured confounders $Z$, we develop a non-parametric method to test the do-null hypothesis that, after an intervention on $X$, there is no marginal dependence of $Y$ on $X$, against the general alternative. Building on the Hilbert-Schmidt Independence Criterion (HSIC) for marginal independence testing, we propose backdoor-HSIC (bd-HSIC), an importance weighted HSIC which combines density ratio estimation with kernel methods. Experiments on simulated data verify the correct size and that the estimator has power for both binary and continuous treatments under a large number of confounding variables. Additionally, we establish convergence properties of the estimators of covariance operators used in bd-HSIC. We investigate the advantages and disadvantages of bd-HSIC against parametric tests as well as the importance of using the do-null testing in contrast to marginal or conditional independence testing. A complete implementation can be found at https://github.com/MrHuff/kgformula.},
  archive      = {J_JMLR},
  author       = {Robert Hu and Dino Sejdinovic and Robin J. Evans},
  journal      = {Journal of Machine Learning Research},
  number       = {160},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A kernel test for causal association via noise contrastive backdoor adjustment},
  url          = {https://jmlr.org/papers/v25/21-1409.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessing the overall and partial causal well-specification
of nonlinear additive noise models. <em>JMLR</em>, <em>25</em>(159),
1–41. (<a href="https://jmlr.org/papers/v25/23-1397.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a method to detect model misspecifications in nonlinear causal additive and potentially heteroscedastic noise models. We aim to identify predictor variables for which we can infer the causal effect even in cases of such misspecification. We develop a general framework based on knowledge of the multivariate observational data distribution. We then propose an algorithm for finite sample data, discuss its asymptotic properties, and illustrate its performance on simulated and real data.},
  archive      = {J_JMLR},
  author       = {Christoph Schultheiss and Peter Bühlmann},
  journal      = {Journal of Machine Learning Research},
  number       = {159},
  pages        = {1-41},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Assessing the overall and partial causal well-specification of nonlinear additive noise models},
  url          = {https://jmlr.org/papers/v25/23-1397.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Simple cycle reservoirs are universal. <em>JMLR</em>,
<em>25</em>(158), 1–28. (<a
href="https://jmlr.org/papers/v25/23-1075.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir computation models form a subclass of recurrent neural networks with fixed non-trainable input and dynamic coupling weights. Only the static readout from the state space (reservoir) is trainable, thus avoiding the known problems with propagation of gradient information backwards through time. Reservoir models have been successfully applied in a variety of tasks and were shown to be universal approximators of time-invariant fading memory dynamic filters under various settings. Simple cycle reservoirs (SCR) have been suggested as severely restricted reservoir architecture, with equal weight ring connectivity of the reservoir units and input-to-reservoir weights of binary nature with the same absolute value. Such architectures are well suited for hardware implementations without performance degradation in many practical tasks. In this contribution, we rigorously study the expressive power of SCR in the complex domain and show that they are capable of universal approximation of any unrestricted linear reservoir system (with continuous readout) and hence any time-invariant fading memory filter over uniformly bounded input streams.},
  archive      = {J_JMLR},
  author       = {Boyu Li and Robert Simon Fong and Peter Tino},
  journal      = {Journal of Machine Learning Research},
  number       = {158},
  pages        = {1-28},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Simple cycle reservoirs are universal},
  url          = {https://jmlr.org/papers/v25/23-1075.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the computational complexity of metropolis-adjusted
langevin algorithms for bayesian posterior sampling. <em>JMLR</em>,
<em>25</em>(157), 1–79. (<a
href="https://jmlr.org/papers/v25/23-0783.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we examine the computational complexity of sampling from a Bayesian posterior (or pseudo-posterior) using the Metropolis-adjusted Langevin algorithm (MALA). MALA first employs a discrete-time Langevin SDE to propose a new state, and then adjusts the proposed state using Metropolis-Hastings rejection. Most existing theoretical analyses of MALA rely on the smoothness and strong log-concavity properties of the target distribution, which are often lacking in practical Bayesian problems. Our analysis hinges on statistical large sample theory, which constrains the deviation of the Bayesian posterior from being smooth and log-concave in a very specific way. In particular, we introduce a new technique for bounding the mixing time of a Markov chain with a continuous state space via the $s$-conductance profile, offering improvements over existing techniques in several aspects. By employing this new technique, we establish the optimal parameter dimension dependence of $d^{1/3}$ and condition number dependence of $\kappa$ in the non-asymptotic mixing time upper bound for MALA after the burn-in period, under a standard Bayesian setting where the target posterior distribution is close to a $d$-dimensional Gaussian distribution with a covariance matrix having a condition number $\kappa$. We also prove a matching mixing time lower bound for sampling from a multivariate Gaussian via MALA to complement the upper bound.},
  archive      = {J_JMLR},
  author       = {Rong Tang and Yun Yang},
  journal      = {Journal of Machine Learning Research},
  number       = {157},
  pages        = {1-79},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the computational complexity of metropolis-adjusted langevin algorithms for bayesian posterior sampling},
  url          = {https://jmlr.org/papers/v25/23-0783.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalization and stability of interpolating neural
networks with minimal width. <em>JMLR</em>, <em>25</em>(156), 1–41. (<a
href="https://jmlr.org/papers/v25/23-0422.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the generalization and optimization properties of shallow neural-network classifiers trained by gradient descent in the interpolating regime. Specifically, in a realizable scenario where model weights can achieve arbitrarily small training error $\epsilon$ and their distance from initialization is $g(\epsilon)$, we demonstrate that gradient descent with $n$ training data achieves training error $O(g(1/T)^2\big/T)$ and generalization error $O(g(1/T)^2\big/n)$ at iteration $T$, provided there are at least $m=\Omega(g(1/T)^4)$ hidden neurons. We then show that our realizable setting encompasses a special case where data are separable by the model&#39;s neural tangent kernel. For this and logistic-loss minimization, we prove the training loss decays at a rate of $\tilde O(1/ T)$ given polylogarithmic number of neurons $m=\Omega(\log^4 (T))$. Moreover, with $m=\Omega(\log^{4} (n))$ neurons and $T\approx n$ iterations, we bound the test loss by $\tilde{O}(1/ n)$. Our results differ from existing generalization outcomes using the algorithmic-stability framework, which necessitate polynomial width and yield suboptimal generalization rates. Central to our analysis is the use of a new self-bounded weak-convexity property, which leads to a generalized local quasi-convexity property for sufficiently parameterized neural-network classifiers. Eventually, despite the objective&#39;s non-convexity, this leads to convergence and generalization-gap bounds that resemble those found in the convex setting of linear logistic regression.},
  archive      = {J_JMLR},
  author       = {Hossein Taheri and Christos Thrampoulidis},
  journal      = {Journal of Machine Learning Research},
  number       = {156},
  pages        = {1-41},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Generalization and stability of interpolating neural networks with minimal width},
  url          = {https://jmlr.org/papers/v25/23-0422.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Statistical optimality of divide and conquer kernel-based
functional linear regression. <em>JMLR</em>, <em>25</em>(155), 1–56. (<a
href="https://jmlr.org/papers/v25/22-1326.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous analysis of regularized functional linear regression in a reproducing kernel Hilbert space (RKHS) typically requires the target function to be contained in this kernel space. This paper studies the convergence performance of divide-and-conquer estimators in the scenario that the target function does not necessarily reside in the underlying RKHS. As a decomposition-based scalable approach, the divide-and-conquer estimators of functional linear regression can substantially reduce the algorithmic complexities in time and memory. We develop an integral operator approach to establish sharp finite sample upper bounds for prediction with divide-and-conquer estimators under various regularity conditions of explanatory variables and target function. We also prove the asymptotic optimality of the derived rates by building the mini-max lower bounds. Finally, we consider the convergence of noiseless estimators and show that the rates can be arbitrarily fast under mild conditions.},
  archive      = {J_JMLR},
  author       = {Jiading Liu and Lei Shi},
  journal      = {Journal of Machine Learning Research},
  number       = {155},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Statistical optimality of divide and conquer kernel-based functional linear regression},
  url          = {https://jmlr.org/papers/v25/22-1326.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifiability and asymptotics in learning homogeneous
linear ODE systems from discrete observations. <em>JMLR</em>,
<em>25</em>(154), 1–50. (<a
href="https://jmlr.org/papers/v25/22-1159.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinary Differential Equations (ODEs) have recently gained a lot of attention in machine learning. However, the theoretical aspects, for example, identifiability and asymptotic properties of statistical estimation are still obscure. This paper derives a sufficient condition for the identifiability of homogeneous linear ODE systems from a sequence of equally-spaced error-free observations sampled from a single trajectory. When observations are disturbed by measurement noise, we prove that under mild conditions, the parameter estimator based on the Nonlinear Least Squares (NLS) method is consistent and asymptotic normal with $n^{-1/2}$ convergence rate. Based on the asymptotic normality property, we construct confidence sets for the unknown system parameters and propose a new method to infer the causal structure of the ODE system, that is, inferring whether there is a causal link between system variables. Furthermore, we extend the results to degraded observations, including aggregated and time-scaled ones. To the best of our knowledge, our work is the first systematic study of the identifiability and asymptotic properties in learning linear ODE systems. We also construct simulations with various system dimensions to illustrate the established theoretical results.},
  archive      = {J_JMLR},
  author       = {Yuanyuan Wang and Wei Huang and Mingming Gong and Xi Geng and Tongliang Liu and Kun Zhang and Dacheng Tao},
  journal      = {Journal of Machine Learning Research},
  number       = {154},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Identifiability and asymptotics in learning homogeneous linear ODE systems from discrete observations},
  url          = {https://jmlr.org/papers/v25/22-1159.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust black-box optimization for stochastic search and
episodic reinforcement learning. <em>JMLR</em>, <em>25</em>(153), 1–44.
(<a href="https://jmlr.org/papers/v25/22-0564.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Black-box optimization is a versatile approach to solve complex problems where the objective function is not explicitly known and no higher order information is available. Due to its general nature, it finds widespread applications in function optimization as well as machine learning, especially episodic reinforcement learning tasks. While traditional black-box optimizers like CMA-ES may falter in noisy scenarios due to their reliance on ranking-based transformations, a promising alternative emerges in the form of the Model-based Relative Entropy Stochastic Search (MORE) algorithm. MORE can be derived from natural policy gradients and compatible function approximation and directly optimizes the expected fitness without resorting to rankings. However, in its original formulation, MORE often cannot achieve state of the art performance. In this paper, we improve MORE by decoupling the update of the search distribution&#39;s mean and covariance and an improved entropy scheduling technique based on an evolution path resulting in faster convergence, and a simplified model learning approach in comparison to the original paper. We show that our algorithm performs comparable to state-of-the-art black-box optimizers on standard benchmark functions. Further, it clearly outperforms ranking-based methods and other policy-gradient based black-box algorithms as well as state of the art deep reinforcement learning algorithms when used for episodic reinforcement learning tasks.},
  archive      = {J_JMLR},
  author       = {Maximilian Hüttenrauch and Gerhard Neumann},
  journal      = {Journal of Machine Learning Research},
  number       = {153},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Robust black-box optimization for stochastic search and episodic reinforcement learning},
  url          = {https://jmlr.org/papers/v25/22-0564.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Kernel thinning. <em>JMLR</em>, <em>25</em>(152), 1–77. (<a
href="https://jmlr.org/papers/v25/21-1334.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce kernel thinning, a new procedure for compressing a distribution $\mathbb{P}$ more effectively than i.i.d. sampling or standard thinning. Given a suitable reproducing kernel $\mathbf{k}_{\star}$ and $O(n^2)$ time, kernel thinning compresses an $n$-point approximation to $\mathbb{P}$ into a $\sqrt{n}$-point approximation with comparable worst-case integration error across the associated reproducing kernel Hilbert space. The maximum discrepancy in integration error is $O_d(n^{-1/2}\sqrt{\log n})$ in probability for compactly supported $\mathbb{P}$ and $O_d(n^{-\frac{1}{2}} (\log n)^{(d+1)/2}\sqrt{\log\log n})$ for sub-exponential $\mathbb{P}$ on $\mathbb{R}^d$. In contrast, an equal-sized i.i.d. sample from $\mathbb{P}$ suffers $\Omega(n^{-1/4})$ integration error. Our sub-exponential guarantees resemble the classical quasi-Monte Carlo error rates for uniform $\mathbb{P}$ on $[0,1]^d$ but apply to general distributions on $\mathbb{R}^d$ and a wide range of common kernels. Moreover, the same construction delivers near-optimal $L^\infty$ coresets in $O(n^2)$ time. We use our results to derive explicit non-asymptotic maximum mean discrepancy bounds for Gaussian, Mat\&#39;ern, and B-spline kernels and present two vignettes illustrating the practical benefits of kernel thinning over i.i.d. sampling and standard Markov chain Monte Carlo thinning, in dimensions $d=2$ through $100$.},
  archive      = {J_JMLR},
  author       = {Raaz Dwivedi and Lester Mackey},
  journal      = {Journal of Machine Learning Research},
  number       = {152},
  pages        = {1-77},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Kernel thinning},
  url          = {https://jmlr.org/papers/v25/21-1334.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal algorithms for stochastic bilevel optimization under
relaxed smoothness conditions. <em>JMLR</em>, <em>25</em>(151), 1–51.
(<a href="https://jmlr.org/papers/v25/23-1323.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider stochastic bilevel optimization problems involving minimizing an upper-level ($\texttt{UL}$) function that is dependent on the arg-min of a strongly-convex lower-level ($\texttt{LL}$) function. Several algorithms utilize Neumann series to approximate certain matrix inverses involved in estimating the implicit gradient of the $\texttt{UL}$ function (hypergradient). The state-of-the-art StOchastic Bilevel Algorithm ($\texttt{SOBA}$) instead uses stochastic gradient descent steps to solve the linear system associated with the explicit matrix inversion. This modification enables $\texttt{SOBA}$ to obtain a sample complexity of $\mathcal{O}(1/\epsilon^{2})$ for finding an $\epsilon$-stationary point. Unfortunately, the current analysis of $\texttt{SOBA}$ relies on the assumption of higher-order smoothness for the $\texttt{UL}$ and $\texttt{LL}$ functions to achieve optimality. In this paper, we introduce a novel fully single-loop and Hessian-inversion-free algorithmic framework for stochastic bilevel optimization and present a tighter analysis under standard smoothness assumptions (first-order Lipschitzness of the $\texttt{UL}$ function and second-order Lipschitzness of the $\texttt{LL}$ function). Furthermore, we show that a slight modification of our algorithm can handle a more general multi-objective robust bilevel optimization problem. For this case, we obtain the state-of-the-art oracle complexity results demonstrating the generality of both the proposed algorithmic and analytic frameworks. Numerical experiments demonstrate the performance gain of the proposed algorithms over existing ones.},
  archive      = {J_JMLR},
  author       = {Xuxing Chen and Tesi Xiao and Krishnakumar Balasubramanian},
  journal      = {Journal of Machine Learning Research},
  number       = {151},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal algorithms for stochastic bilevel optimization under relaxed smoothness conditions},
  url          = {https://jmlr.org/papers/v25/23-1323.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variational estimators of the degree-corrected latent block
model for bipartite networks. <em>JMLR</em>, <em>25</em>(150), 1–42. (<a
href="https://jmlr.org/papers/v25/23-0984.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipartite graphs are ubiquitous across various scientific and engineering fields. Simultaneously grouping the two types of nodes in a bipartite graph via biclustering represents a fundamental challenge in network analysis for such graphs. The latent block model (LBM) is a commonly used model-based tool for biclustering. However, the effectiveness of the LBM is often limited by the influence of row and column sums in the data matrix. To address this limitation, we introduce the degree-corrected latent block model (DC-LBM), which accounts for the varying degrees in row and column clusters, significantly enhancing performance on real-world data sets and simulated data. We develop an efficient variational expectation-maximization algorithm by creating closed-form solutions for parameter estimates in the M steps. Furthermore, we prove the label consistency and the rate of convergence of the variational estimator under the DC-LBM, allowing the expected graph density to approach zero as long as the average expected degrees of rows and columns approach infinity when the size of the graph increases.},
  archive      = {J_JMLR},
  author       = {Yunpeng Zhao and Ning Hao and Ji Zhu},
  journal      = {Journal of Machine Learning Research},
  number       = {150},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Variational estimators of the degree-corrected latent block model for bipartite networks},
  url          = {https://jmlr.org/papers/v25/23-0984.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Statistical inference for fairness auditing. <em>JMLR</em>,
<em>25</em>(149), 1–49. (<a
href="https://jmlr.org/papers/v25/23-0739.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Before deploying a black-box model in high-stakes problems, it is important to evaluate the model’s performance on sensitive subpopulations. For example, in a recidivism prediction task, we may wish to identify demographic groups for which our prediction model has unacceptably high false positive rates or certify that no such groups exist. In this paper, we frame this task, often referred to as “fairness auditing,” in terms of multiple hypothesis testing. We show how the bootstrap can be used to simultaneously bound performance disparities over a collection of groups with statistical guarantees. Our methods can be used to flag subpopulations affected by model underperformance, and certify subpopulations for which the model performs adequately. Crucially, our audit is model-agnostic and applicable to nearly any performance metric or group fairness criterion. Our methods also accommodate extremely rich---even infinite---collections of subpopulations. Further, we generalize beyond subpopulations by showing how to assess performance over certain distribution shifts. We test the proposed methods on benchmark datasets in predictive inference and algorithmic fairness and find that our audits can provide interpretable and trustworthy guarantees.},
  archive      = {J_JMLR},
  author       = {John J. Cherian and Emmanuel J. Candès},
  journal      = {Journal of Machine Learning Research},
  number       = {149},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Statistical inference for fairness auditing},
  url          = {https://jmlr.org/papers/v25/23-0739.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adjusted wasserstein distributionally robust estimator in
statistical learning. <em>JMLR</em>, <em>25</em>(148), 1–40. (<a
href="https://jmlr.org/papers/v25/23-0379.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an adjusted Wasserstein distributionally robust estimator---based on a nonlinear transformation of the Wasserstein distributionally robust (WDRO) estimator in statistical learning. The classic WDRO estimator is asymptotically biased, while our adjusted WDRO estimator is asymptotically unbiased, resulting in a smaller asymptotic mean squared error. Further, under certain conditions, our proposed adjustment technique provides a general principle to de-bias asymptotically biased estimators. Specifically, we will investigate how the adjusted WDRO estimator is developed in the generalized linear model, including logistic regression, linear regression, and Poisson regression. Numerical experiments demonstrate the favorable practical performance of the adjusted estimator over the classic one.},
  archive      = {J_JMLR},
  author       = {Yiling Xie and Xiaoming Huo},
  journal      = {Journal of Machine Learning Research},
  number       = {148},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Adjusted wasserstein distributionally robust estimator in statistical learning},
  url          = {https://jmlr.org/papers/v25/23-0379.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DoWhy-GCM: An extension of DoWhy for causal inference in
graphical causal models. <em>JMLR</em>, <em>25</em>(147), 1–7. (<a
href="https://jmlr.org/papers/v25/22-1258.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present DoWhy-GCM, an extension of the DoWhy Python library, which leverages graphical causal models. Unlike existing causality libraries, which mainly focus on effect estimation, DoWhy-GCM addresses diverse causal queries, such as identifying the root causes of outliers and distributional changes, attributing causal influences to the data generating process of each node, or diagnosis of causal structures. With DoWhy-GCM, users typically specify cause-effect relations via a causal graph, fit causal mechanisms, and pose causal queries---all with just a few lines of code. The general documentation is available at https://www.pywhy.org/dowhy and the DoWhy-GCM specific code at https://github.com/py-why/dowhy/tree/main/dowhy/gcm.},
  archive      = {J_JMLR},
  author       = {Patrick Blöbaum and Peter Götz and Kailash Budhathoki and Atalanti A. Mastakouri and Dominik Janzing},
  journal      = {Journal of Machine Learning Research},
  number       = {147},
  pages        = {1-7},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {DoWhy-GCM: An extension of DoWhy for causal inference in graphical causal models},
  url          = {https://jmlr.org/papers/v25/22-1258.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Flexible bayesian product mixture models for vector
autoregressions. <em>JMLR</em>, <em>25</em>(146), 1–52. (<a
href="https://jmlr.org/papers/v25/22-0717.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian non-parametric methods based on Dirichlet process mixtures have seen tremendous success in various domains and are appealing in being able to borrow information by clustering samples that share identical parameters. However, such methods can face hurdles in heterogeneous settings where objects are expected to cluster only along a subset of axes or where clusters of samples share only a subset of identical parameters. We overcome such limitations by developing a novel class of product of Dirichlet process location-scale mixtures that enables independent clustering at multiple scales, which results in varying levels of information sharing across samples. First, we develop the approach for independent multivariate data. Subsequently we generalize it to multivariate time-series data under the framework of multi-subject Vector Autoregressive (VAR) models that is our primary focus, which go beyond parametric single-subject VAR models. We establish posterior consistency and develop efficient posterior computation for implementation. Extensive numerical studies involving VAR models show distinct advantages over competing methods in terms of estimation, clustering, and feature selection accuracy. Our resting state fMRI analysis from the Human Connectome Project reveals biologically interpretable connectivity differences between distinct intelligence groups, while another air pollution application illustrates the superior forecasting accuracy compared to alternate methods.},
  archive      = {J_JMLR},
  author       = {Suprateek Kundu and Joshua Lukemire},
  journal      = {Journal of Machine Learning Research},
  number       = {146},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Flexible bayesian product mixture models for vector autoregressions},
  url          = {https://jmlr.org/papers/v25/22-0717.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A variational approach to bayesian phylogenetic inference.
<em>JMLR</em>, <em>25</em>(145), 1–56. (<a
href="https://jmlr.org/papers/v25/22-0348.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian phylogenetic inference is currently done via Markov chain Monte Carlo with simple proposal mechanisms. This hinders exploration efficiency and often requires long runs to deliver accurate posterior estimates. In this paper, we present an alternative approach: a variational framework for Bayesian phylogenetic analysis. We propose combining subsplit Bayesian networks, an expressive graphical model for tree topology distributions, and a structured amortization of the branch lengths over tree topologies for a suitable variational family of distributions. We train the variational approximation via stochastic gradient ascent and adopt gradient estimators for continuous and discrete variational parameters separately to deal with the composite latent space of phylogenetic models. We show that our variational approach provides competitive performance to MCMC, while requiring much fewer (though more costly) iterations due to a more efficient exploration mechanism enabled by variational inference. Experiments on a benchmark of challenging real data Bayesian phylogenetic inference problems demonstrate the effectiveness and efficiency of our methods.},
  archive      = {J_JMLR},
  author       = {Cheng Zhang and Frederick A. Matsen IV},
  journal      = {Journal of Machine Learning Research},
  number       = {145},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A variational approach to bayesian phylogenetic inference},
  url          = {https://jmlr.org/papers/v25/22-0348.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fat-shattering dimension of k-fold aggregations.
<em>JMLR</em>, <em>25</em>(144), 1–29. (<a
href="https://jmlr.org/papers/v25/21-1193.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide estimates on the fat-shattering dimension of aggregation rules of real-valued function classes. The latter consists of all ways of choosing k functions, one from each of the k classes, and computing pointwise an &quot;aggregate&quot; function of these, such as the median, mean, and maximum. The bounds are stated in terms of the fat-shattering dimensions of the component classes. For linear and affine function classes, we provide a considerably sharper upper bound and a matching lower bound, achieving, in particular, an optimal dependence on k. Along the way, we improve several known results in addition to pointing out and correcting a number of erroneous claims in the literature.},
  archive      = {J_JMLR},
  author       = {Idan Attias and Aryeh Kontorovich},
  journal      = {Journal of Machine Learning Research},
  number       = {144},
  pages        = {1-29},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fat-shattering dimension of k-fold aggregations},
  url          = {https://jmlr.org/papers/v25/21-1193.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified binary and multiclass margin-based classification.
<em>JMLR</em>, <em>25</em>(143), 1–51. (<a
href="https://jmlr.org/papers/v25/23-1599.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of margin loss has been central to the development and analysis of algorithms for binary classification. To date, however, there remains no consensus as to the analogue of the margin loss for multiclass classification. In this work, we show that a broad range of multiclass loss functions, including many popular ones, can be expressed in the relative margin form, a generalization of the margin form of binary losses. The relative margin form is broadly useful for understanding and analyzing multiclass losses as shown by our prior work (Wang and Scott, 2020, 2021). To further demonstrate the utility of this way of expressing multiclass losses, we use it to extend the seminal result of Bartlett et al. (2006) on classification-calibration of binary margin losses to multiclass. We then analyze the class of Fenchel-Young losses, and expand the set of these losses that are known to be classification-calibrated.},
  archive      = {J_JMLR},
  author       = {Yutong Wang and Clayton Scott},
  journal      = {Journal of Machine Learning Research},
  number       = {143},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Unified binary and multiclass margin-based classification},
  url          = {https://jmlr.org/papers/v25/23-1599.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural feature learning in function space. <em>JMLR</em>,
<em>25</em>(142), 1–76. (<a
href="https://jmlr.org/papers/v25/23-1202.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel framework for learning system design with neural feature extractors. First, we introduce the feature geometry, which unifies statistical dependence and feature representations in a function space equipped with inner products. This connection defines function-space concepts on statistical dependence, such as norms, orthogonal projection, and spectral decomposition, exhibiting clear operational meanings. In particular, we associate each learning setting with a dependence component and formulate learning tasks as finding corresponding feature approximations. We propose a nesting technique, which provides systematic algorithm designs for learning the optimal features from data samples with off-the-shelf network architectures and optimizers. We further demonstrate multivariate learning applications, including conditional inference and multimodal learning, where we present the optimal features and reveal their connections to classical approaches.},
  archive      = {J_JMLR},
  author       = {Xiangxiang Xu and Lizhong Zheng},
  journal      = {Journal of Machine Learning Research},
  number       = {142},
  pages        = {1-76},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Neural feature learning in function space},
  url          = {https://jmlr.org/papers/v25/23-1202.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PyGOD: A python library for graph outlier detection.
<em>JMLR</em>, <em>25</em>(141), 1–9. (<a
href="https://jmlr.org/papers/v25/23-0963.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PyGOD is an open-source Python library for detecting outliers in graph data. As the first comprehensive library of its kind, PyGOD supports a wide array of leading graph-based methods for outlier detection under an easy-to-use, well-documented API designed for use by both researchers and practitioners. PyGOD provides modularized components of the different detectors implemented so that users can easily customize each detector for their purposes. To ease the construction of detection workflows, PyGOD offers numerous commonly used utility functions. To scale computation to large graphs, PyGOD supports functionalities for deep models such as sampling and mini-batch processing. PyGOD uses best practices in fostering code reliability and maintainability, including unit testing, continuous integration, and code coverage. To facilitate accessibility, PyGOD is released under a BSD 2-Clause license at https://pygod.org and at the Python Package Index (PyPI).},
  archive      = {J_JMLR},
  author       = {Kay Liu and Yingtong Dou and Xueying Ding and Xiyang Hu and Ruitong Zhang and Hao Peng and Lichao Sun and Philip S. Yu},
  journal      = {Journal of Machine Learning Research},
  number       = {141},
  pages        = {1-9},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {PyGOD: A python library for graph outlier detection},
  url          = {https://jmlr.org/papers/v25/23-0963.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blessings and curses of covariate shifts: Adversarial
learning dynamics, directional convergence, and equilibria.
<em>JMLR</em>, <em>25</em>(140), 1–27. (<a
href="https://jmlr.org/papers/v25/23-0651.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covariate distribution shifts and adversarial perturbations present robustness challenges to the conventional statistical learning framework: mild shifts in the test covariate distribution can significantly affect the performance of the statistical model learned based on the training distribution. The model performance typically deteriorates when extrapolation happens: namely, covariates shift to a region where the training distribution is scarce, and naturally, the learned model has little information. For robustness and regularization considerations, adversarial perturbation techniques are proposed as a remedy; however, careful study needs to be carried out about what extrapolation region adversarial covariate shift will focus on, given a learned model. This paper precisely characterizes the extrapolation region, examining both regression and classification in an infinite-dimensional setting. We study the implications of adversarial covariate shifts to subsequent learning of the equilibrium---the Bayes optimal model---in a sequential game framework. We exploit the dynamics of the adversarial learning game and reveal the curious effects of the covariate shift to equilibrium learning and experimental design. In particular, we establish two directional convergence results that exhibit distinctive phenomena: (1) a blessing in regression, the adversarial covariate shifts in an exponential rate to an optimal experimental design for rapid subsequent learning; (2) a curse in classification, the adversarial covariate shifts in a subquadratic rate to the hardest experimental design trapping subsequent learning.},
  archive      = {J_JMLR},
  author       = {Tengyuan Liang},
  journal      = {Journal of Machine Learning Research},
  number       = {140},
  pages        = {1-27},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Blessings and curses of covariate shifts: Adversarial learning dynamics, directional convergence, and equilibria},
  url          = {https://jmlr.org/papers/v25/23-0651.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed points of nonnegative neural networks. <em>JMLR</em>,
<em>25</em>(139), 1–40. (<a
href="https://jmlr.org/papers/v25/23-0167.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We use fixed point theory to analyze nonnegative neural networks, which we define as neural networks that map nonnegative vectors to nonnegative vectors. We first show that nonnegative neural networks with nonnegative weights and biases can be recognized as monotonic and (weakly) scalable mappings within the framework of nonlinear Perron-Frobenius theory. This fact enables us to provide conditions for the existence of fixed points of nonnegative neural networks having inputs and outputs of the same dimension, and these conditions are weaker than those recently obtained using arguments in convex analysis. Furthermore, we prove that the shape of the fixed point set of nonnegative neural networks with nonnegative weights and biases is an interval, which under mild conditions degenerates to a point. These results are then used to obtain the existence of fixed points of more general nonnegative neural networks. From a practical perspective, our results contribute to the understanding of the behavior of autoencoders, and we also offer valuable mathematical machinery for future developments in deep equilibrium models.},
  archive      = {J_JMLR},
  author       = {Tomasz J. Piotrowski and Renato L. G. Cavalcante and Mateusz Gabor},
  journal      = {Journal of Machine Learning Research},
  number       = {139},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fixed points of nonnegative neural networks},
  url          = {https://jmlr.org/papers/v25/23-0167.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning with norm constrained, over-parameterized,
two-layer neural networks. <em>JMLR</em>, <em>25</em>(138), 1–42. (<a
href="https://jmlr.org/papers/v25/22-1250.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies show that a reproducing kernel Hilbert space (RKHS) is not a suitable space to model functions by neural networks as the curse of dimensionality (CoD) cannot be evaded when trying to approximate even a single ReLU neuron. In this paper, we study a suitable function space for over-parameterized two-layer neural networks with bounded norms (e.g., the path norm, the Barron norm) in the perspective of sample complexity and generalization properties. First, we show that the path norm (as well as the Barron norm) is able to obtain width-independence sample complexity bounds, which allows for uniform convergence guarantees. Based on this result, we derive the improved result of metric entropy for $\epsilon$-covering up to $O(\epsilon^{-\frac{2d}{d+2}})$ ($d$ is the input dimension and the depending constant is at most polynomial order of $d$) via the convex hull technique, which demonstrates the separation with kernel methods with $\Omega(\epsilon^{-d})$ to learn the target function in a Barron space. Second, this metric entropy result allows for building a sharper generalization bound under a general moment hypothesis setting, achieving the rate at $O(n^{-\frac{d+2}{2d+2}})$. Our analysis is novel in that it offers a sharper and refined estimation for metric entropy (with a clear dependence relationship on the dimension $d$) and unbounded sampling in the estimation of the sample error and the output error.},
  archive      = {J_JMLR},
  author       = {Fanghui Liu and Leello Dadi and Volkan Cevher},
  journal      = {Journal of Machine Learning Research},
  number       = {138},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning with norm constrained, over-parameterized, two-layer neural networks},
  url          = {https://jmlr.org/papers/v25/22-1250.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on multi-player bandits. <em>JMLR</em>,
<em>25</em>(137), 1–45. (<a
href="https://jmlr.org/papers/v25/22-0643.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due mostly to its application to cognitive radio networks, multiplayer bandits gained a lot of interest in the last decade. A considerable progress has been made on its theoretical aspect. However, the current algorithms are far from applicable and many obstacles remain between these theoretical results and a possible implementation of multiplayer bandits algorithms in real communication networks. This survey contextualizes and organizes the rich multiplayer bandits literature. In light of the existing works, some clear directions for future research appear. We believe that a further study of these different directions might lead to theoretical algorithms adapted to real-world situations.},
  archive      = {J_JMLR},
  author       = {Etienne Boursier and Vianney Perchet},
  journal      = {Journal of Machine Learning Research},
  number       = {137},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A survey on multi-player bandits},
  url          = {https://jmlr.org/papers/v25/22-0643.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transport-based counterfactual models. <em>JMLR</em>,
<em>25</em>(136), 1–59. (<a
href="https://jmlr.org/papers/v25/21-1440.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual frameworks have grown popular in machine learning for both explaining algorithmic decisions but also defining individual notions of fairness, more intuitive than typical group fairness conditions. However, state-of-the-art models to compute counterfactuals are either unrealistic or unfeasible. In particular, while Pearl&#39;s causal inference provides appealing rules to calculate counterfactuals, it relies on a model that is unknown and hard to discover in practice. We address the problem of designing realistic and feasible counterfactuals in the absence of a causal model. We define transport-based counterfactual models as collections of joint probability distributions between observable distributions, and show their connection to causal counterfactuals. More specifically, we argue that optimal-transport theory defines relevant transport-based counterfactual models, as they are numerically feasible, statistically-faithful, and can coincide under some assumptions with causal counterfactual models. Finally, these models make counterfactual approaches to fairness feasible, and we illustrate their practicality and efficiency on fair learning. With this paper, we aim at laying out the theoretical foundations for a new, implementable approach to counterfactual thinking.},
  archive      = {J_JMLR},
  author       = {Lucas De Lara and Alberto González-Sanz and Nicholas Asher and Laurent Risser and Jean-Michel Loubes},
  journal      = {Journal of Machine Learning Research},
  number       = {136},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Transport-based counterfactual models},
  url          = {https://jmlr.org/papers/v25/21-1440.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive latent feature sharing for piecewise linear
dimensionality reduction. <em>JMLR</em>, <em>25</em>(135), 1–42. (<a
href="https://jmlr.org/papers/v25/21-0146.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear Gaussian exploratory tools such as principal component analysis (PCA) and factor analysis (FA) are widely used for exploratory analysis, pre-processing, data visualization, and related tasks. Because the linear-Gaussian assumption is restrictive, for very high dimensional problems, they have been replaced by robust, sparse extensions or more flexible discrete-continuous latent feature models. Discrete-continuous latent feature models specify a dictionary of features dependent on subsets of the data and then infer the likelihood that each data point shares any of these features. This is often achieved using rich-get-richer assumptions about the feature allocation process where the dictionary tries to couple the feature frequency with the portion of total variance that it explains. In this work, we propose an alternative approach that allows for better control over the feature to data point allocation. This new approach is based on two-parameter discrete distribution models which decouple feature sparsity and dictionary size, hence capturing both common and rare features in a parsimonious way. The new framework is used to derive a novel adaptive variant of factor analysis (aFA), as well as an adaptive probabilistic principal component analysis (aPPCA) capable of flexible structure discovery and dimensionality reduction in a wide variety of scenarios. We derive both standard Gibbs sampling, as well as efficient expectation-maximisation inference approximations converging orders of magnitude faster, to a reasonable point estimate solution. The utility of the proposed aPPCA and aFA models is demonstrated on standard tasks such as feature learning, data visualization, and data whitening. We show that aPPCA and aFA can extract interpretable, high-level features for raw MNIST or COLI-20 images, or when applied to the analysis of autoencoder features. We also demonstrate that replacing common PCA pre-processing pipelines in the analysis of functional magnetic resonance imaging (fMRI) data with aPPCA, leads to more robust and better-localised blind source separation of neural activity.},
  archive      = {J_JMLR},
  author       = {Adam Farooq and Yordan P. Raykov and Petar Raykov and Max A. Little},
  journal      = {Journal of Machine Learning Research},
  number       = {135},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Adaptive latent feature sharing for piecewise linear dimensionality reduction},
  url          = {https://jmlr.org/papers/v25/21-0146.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Topological node2vec: Enhanced graph embedding via
persistent homology. <em>JMLR</em>, <em>25</em>(134), 1–26. (<a
href="https://jmlr.org/papers/v25/23-1185.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node2vec is a graph embedding method that learns a vector representation for each node of a weighted graph while seeking to preserve relative proximity and global structure. Numerical experiments suggest Node2vec struggles to recreate the topology of the input graph. To resolve this we introduce a topological loss term to be added to the training loss of Node2vec which tries to align the persistence diagram (PD) of the resulting embedding as closely as possible to that of the input graph. Following results in computational optimal transport, we carefully adapt entropic regularization to PD metrics, allowing us to measure the discrepancy between PDs in a differentiable way. Our modified loss function can then be minimized through gradient descent to reconstruct both the geometry and the topology of the input graph. We showcase the benefits of this approach using demonstrative synthetic examples.},
  archive      = {J_JMLR},
  author       = {Yasuaki Hiraoka and Yusuke Imoto and Théo Lacombe and Killian Meehan and Toshiaki Yachimura},
  journal      = {Journal of Machine Learning Research},
  number       = {134},
  pages        = {1-26},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Topological node2vec: Enhanced graph embedding via persistent homology},
  url          = {https://jmlr.org/papers/v25/23-1185.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Granger causal inference in multivariate hawkes processes by
minimum message length. <em>JMLR</em>, <em>25</em>(133), 1–26. (<a
href="https://jmlr.org/papers/v25/23-1066.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate Hawkes processes (MHPs) are versatile probabilistic tools used to model various real-life phenomena: earthquakes, operations on stock markets, neuronal activity, virus propagation and many others. In this paper, we focus on MHPs with exponential decay kernels and estimate connectivity graphs, which represent the Granger causal relations between their components. We approach this inference problem by proposing an optimization criterion and model selection algorithm based on the minimum message length (MML) principle. MML compares Granger causal models using the Occam&#39;s razor principle in the following way: even when models have a comparable goodness-of-fit to the observed data, the one generating the most concise explanation of the data is preferred. While most of the state-of-art methods using lasso-type penalization tend to overfitting in scenarios with short time horizons, the proposed MML-based method achieves high F1 scores in these settings. We conduct a numerical study comparing the proposed algorithm to other related classical and state-of-art methods, where we achieve the highest F1 scores in specific sparse graph settings. We illustrate the proposed method also on G7 sovereign bond data and obtain causal connections, which are in agreement with the expert knowledge available in the literature.},
  archive      = {J_JMLR},
  author       = {Katerina Hlaváčková-Schindler and Anna Melnykova and Irene Tubikanec},
  journal      = {Journal of Machine Learning Research},
  number       = {133},
  pages        = {1-26},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Granger causal inference in multivariate hawkes processes by minimum message length},
  url          = {https://jmlr.org/papers/v25/23-1066.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Representation learning via manifold flattening and
reconstruction. <em>JMLR</em>, <em>25</em>(132), 1–47. (<a
href="https://jmlr.org/papers/v25/23-0615.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common assumption for real-world, learnable data is its possession of some low-dimensional structure, and one way to formalize this structure is through the manifold hypothesis: that learnable data lies near some low-dimensional manifold. Deep learning architectures often have a compressive autoencoder component, where data is mapped to a lower-dimensional latent space, but often many architecture design choices are done by hand, since such models do not inherently exploit mathematical structure of the data. To utilize this geometric data structure, we propose an iterative process in the style of a geometric flow for explicitly constructing a pair of neural networks layer-wise that linearize and reconstruct an embedded submanifold, from finite samples of this manifold. Our such-generated neural networks, called Flattening Networks (FlatNet), are theoretically interpretable, computationally feasible at scale, and generalize well to test data, a balance not typically found in manifold-based learning methods. We present empirical results and comparisons to other models on synthetic high-dimensional manifold data and 2D image data. Our code is publicly available.},
  archive      = {J_JMLR},
  author       = {Michael Psenka and Druv Pai and Vishal Raman and Shankar Sastry and Yi Ma},
  journal      = {Journal of Machine Learning Research},
  number       = {132},
  pages        = {1-47},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Representation learning via manifold flattening and reconstruction},
  url          = {https://jmlr.org/papers/v25/23-0615.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bagging provides assumption-free stability. <em>JMLR</em>,
<em>25</em>(131), 1–35. (<a
href="https://jmlr.org/papers/v25/23-0536.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bagging is an important technique for stabilizing machine learning models. In this paper, we derive a finite-sample guarantee on the stability of bagging for any model. Our result places no assumptions on the distribution of the data, on the properties of the base algorithm, or on the dimensionality of the covariates. Our guarantee applies to many variants of bagging and is optimal up to a constant. Empirical results validate our findings, showing that bagging successfully stabilizes even highly unstable base algorithms.},
  archive      = {J_JMLR},
  author       = {Jake A. Soloff and Rina Foygel Barber and Rebecca Willett},
  journal      = {Journal of Machine Learning Research},
  number       = {131},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bagging provides assumption-free stability},
  url          = {https://jmlr.org/papers/v25/23-0536.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fairness guarantees in multi-class classification with
demographic parity. <em>JMLR</em>, <em>25</em>(130), 1–46. (<a
href="https://jmlr.org/papers/v25/23-0322.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithmic Fairness is an established area of machine learning, willing to reduce the influence of hidden bias in the data. Yet, despite its wide range of applications, very few works consider the multi-class classification setting from the fairness perspective. We focus on this question and extend the definition of approximate fairness in the case of Demographic Parity to multi-class classification. We specify the corresponding expressions of the optimal fair classifiers in the attribute-aware case and both for binary and multi-categorical sensitive attributes. This suggests a plug-in data-driven procedure, for which we establish theoretical guarantees. The enhanced estimator is proved to mimic the behavior of the optimal rule both in terms of fairness and risk. Notably, fairness guarantees are distribution-free. The approach is evaluated on both synthetic and real datasets and reveals very effective in decision making with a preset level of unfairness. In addition, our method is competitive (if not better) with the state-of-the-art in binary and multi-class tasks.},
  archive      = {J_JMLR},
  author       = {Christophe Denis and Romuald Elie and Mohamed Hebiri and François Hu},
  journal      = {Journal of Machine Learning Research},
  number       = {130},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fairness guarantees in multi-class classification with demographic parity},
  url          = {https://jmlr.org/papers/v25/23-0322.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regimes of no gain in multi-class active learning.
<em>JMLR</em>, <em>25</em>(129), 1–31. (<a
href="https://jmlr.org/papers/v25/23-0234.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider nonparametric classification with smooth regression functions, where it is well known that notions of margin in $\mathbb{P}(Y=y|X=x)$ determine fast or slow rates in both active and passive learning. Here we elucidate a striking distinction---most relevant in multi-class settings---between active and passive learning. Namely, we show that some seemingly benign nuances in notions of margin---involving the uniqueness of the Bayes classes, which have no apparent effect on rates in passive learning---determine whether or not any active learner can outperform passive learning rates. While a shorter conference version of this work already alluded to these nuances, it focused on the binary case and thus failed to be conclusive as to the source of difficulty in the multi-class setting: we show here that it suffices that the Bayes classifier fails to be unique, as opposed to needing all classes to be Bayes optimal, for active learning to yield no gain over passive learning.},
  archive      = {J_JMLR},
  author       = {Gan Yuan and Yunfan Zhao and Samory Kpotufe},
  journal      = {Journal of Machine Learning Research},
  number       = {129},
  pages        = {1-31},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Regimes of no gain in multi-class active learning},
  url          = {https://jmlr.org/papers/v25/23-0234.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning optimal dynamic treatment regimens subject to
stagewise risk controls. <em>JMLR</em>, <em>25</em>(128), 1–64. (<a
href="https://jmlr.org/papers/v25/23-0072.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic treatment regimens (DTRs) aim at tailoring individualized sequential treatment rules that maximize cumulative beneficial outcomes by accommodating patients&#39; heterogeneity in decision-making. For many chronic diseases including type 2 diabetes mellitus (T2D), treatments are usually multifaceted in the sense that aggressive treatments with a higher expected reward are also likely to elevate the risk of acute adverse events. In this paper, we propose a new weighted learning framework, namely benefit-risk dynamic treatment regimens (BR-DTRs), to address the benefit-risk trade-off. The new framework relies on a backward learning procedure by restricting the induced risk of the treatment rule to be no larger than a pre-specified risk constraint at each treatment stage. Computationally, the estimated treatment rule solves a weighted support vector machine problem with a modified smooth constraint. Theoretically, we show that the proposed DTRs are Fisher consistent, and we further obtain the convergence rates for both the value and risk functions. Finally, the performance of the proposed method is demonstrated via extensive simulation studies and application to a real study for T2D patients.},
  archive      = {J_JMLR},
  author       = {Mochuan Liu and Yuanjia Wang and Haoda Fu and Donglin Zeng},
  journal      = {Journal of Machine Learning Research},
  number       = {128},
  pages        = {1-64},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning optimal dynamic treatment regimens subject to stagewise risk controls},
  url          = {https://jmlr.org/papers/v25/23-0072.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Margin-based active learning of classifiers. <em>JMLR</em>,
<em>25</em>(127), 1–45. (<a
href="https://jmlr.org/papers/v25/22-1127.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study active learning of multiclass classifiers, focusing on the realizable transductive setting. The input is a finite subset $X$ of some metric space, and the concept to be learned is a partition $\mathcal{C}$ of $X$ into $k$ classes. The goal is to learn $\mathcal{C}$ by querying the labels of as few elements of $X$ as possible. This is a useful subroutine in pool-based active learning, and is motivated by applications where labels are expensive to obtain. Our main result is that, in very different settings, there exist interesting notions of margin that yield efficient active learning algorithms. First, we consider the case $X \subset \mathbb{R}^m$, assuming that each class has an unknown &quot;personalized&quot; margin separating it from the rest. Second, we consider the case where $X$ is a finite metric space, and the classes are convex with margin according to the geodesic distances in the thresholded connectivity graph. In both cases, we give algorithms that learn $\mathcal{C}$ exactly, in polynomial time, using $\mathcal{O}(\log n)$ label queries, where $\mathcal{O}(\cdot)$ hides a near-optimal dependence on the dimension of the metric spaces. Our results actually hold for or can be adapted to more general settings, such as pseudometric and semimetric spaces.},
  archive      = {J_JMLR},
  author       = {Marco Bressan and Nicolò Cesa-Bianchi and Silvio Lattanzi and Andrea Paudice},
  journal      = {Journal of Machine Learning Research},
  number       = {127},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Margin-based active learning of classifiers},
  url          = {https://jmlr.org/papers/v25/22-1127.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Random subgraph detection using queries. <em>JMLR</em>,
<em>25</em>(126), 1–25. (<a
href="https://jmlr.org/papers/v25/22-0395.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The planted densest subgraph detection problem refers to the task of testing whether in a given (random) graph there is a subgraph that is unusually dense. Specifically, we observe an undirected and unweighted graph on $n$ vertices. Under the null hypothesis, the graph is a realization of an Erdös-R{\&#39;e}nyi graph with edge probability (or, density) $q$. Under the alternative, there is a subgraph on $k$ vertices with edge probability $p&gt;q$. The statistical as well as the computational barriers of this problem are well-understood for a wide range of the edge parameters $p$ and $q$. In this paper, we consider a natural variant of the above problem, where one can only observe a relatively small part of the graph using adaptive edge queries. For this model, we determine the number of queries necessary and sufficient (accompanied with a quasi-polynomial optimal algorithm) for detecting the presence of the planted subgraph. We also propose a polynomial-time algorithm which is able to detect the planted subgraph, albeit with more queries compared to the above lower bound. We conjecture that in the leftover regime, no polynomial-time algorithms exist. Our results resolve two open questions posed in the past literature.},
  archive      = {J_JMLR},
  author       = {Wasim Huleihel and Arya Mazumdar and Soumyabrata Pal},
  journal      = {Journal of Machine Learning Research},
  number       = {126},
  pages        = {1-25},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Random subgraph detection using queries},
  url          = {https://jmlr.org/papers/v25/22-0395.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classification with deep neural networks and logistic loss.
<em>JMLR</em>, <em>25</em>(125), 1–117. (<a
href="https://jmlr.org/papers/v25/22-0049.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) trained with the logistic loss (also known as the cross entropy loss) have made impressive advancements in various binary classification tasks. Despite the considerable success in practice, generalization analysis for binary classification with deep neural networks and the logistic loss remains scarce. The unboundedness of the target function for the logistic loss in binary classification is the main obstacle to deriving satisfactory generalization bounds. In this paper, we aim to fill this gap by developing a novel theoretical analysis and using it to establish tight generalization bounds for training fully connected ReLU DNNs with logistic loss in binary classification. Our generalization analysis is based on an elegant oracle-type inequality which enables us to deal with the boundedness restriction of the target function. Using this oracle-type inequality, we establish generalization bounds for fully connected ReLU DNN classifiers $\hat{f}^{\text{FNN}}_n$ trained by empirical logistic risk minimization with respect to i.i.d. samples of size $n$, which lead to sharp rates of convergence as $n\to\infty$. In particular, we obtain optimal convergence rates for $\hat{f}^{\text{FNN}}_n$ (up to some logarithmic factor) only requiring the Hölder smoothness of the conditional class probability $\eta$ of data. Moreover, we consider a compositional assumption that requires $\eta$ to be the composition of several vector-valued multivariate functions of which each component function is either a maximum value function or a Hölder smooth function only depending on a small number of its input variables. Under this assumption, we can even derive optimal convergence rates for $\hat{f}^{\text{FNN}}_n$ (up to some logarithmic factor) which are independent of the input dimension of data. This result explains why in practice DNN classifiers can overcome the curse of dimensionality and perform well in high-dimensional classification problems. Furthermore, we establish dimension-free rates of convergence under other circumstances such as when the decision boundary is piecewise smooth and the input data are bounded away from it. Besides the novel oracle-type inequality, the sharp convergence rates presented in our paper also owe to a tight error bound for approximating the natural logarithm function near zero (where it is unbounded) by ReLU DNNs. In addition, we justify our claims for the optimality of rates by proving corresponding minimax lower bounds. All these results are new in the literature and will deepen our theoretical understanding of classification with deep neural networks.},
  archive      = {J_JMLR},
  author       = {Zihan Zhang and Lei Shi and Ding-Xuan Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {125},
  pages        = {1-117},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Classification with deep neural networks and logistic loss},
  url          = {https://jmlr.org/papers/v25/22-0049.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spectral learning of multivariate extremes. <em>JMLR</em>,
<em>25</em>(124), 1–36. (<a
href="https://jmlr.org/papers/v25/21-1367.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a spectral clustering algorithm for analyzing the dependence structure of multivariate extremes. More specifically, we focus on the asymptotic dependence of multivariate extremes characterized by the angular or spectral measure in extreme value theory. Our work studies the theoretical performance of spectral clustering based on a random $k$-nearest neighbor graph constructed from an extremal sample, i.e., the angular part of random vectors for which the radius exceeds a large threshold. In particular, we derive the asymptotic distribution of extremes arising from a linear factor model and prove that, under certain conditions, spectral clustering can consistently identify the clusters of extremes arising in this model. Leveraging this result we propose a simple consistent estimation strategy for learning the angular measure. Our theoretical findings are complemented with numerical experiments illustrating the finite sample performance of our methods.},
  archive      = {J_JMLR},
  author       = {Marco Avella Medina and Richard A Davis and Gennady Samorodnitsky},
  journal      = {Journal of Machine Learning Research},
  number       = {124},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Spectral learning of multivariate extremes},
  url          = {https://jmlr.org/papers/v25/21-1367.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sum-of-norms clustering does not separate nearby balls.
<em>JMLR</em>, <em>25</em>(123), 1–40. (<a
href="https://jmlr.org/papers/v25/21-0495.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sum-of-norms clustering is a popular convexification of $K$-means clustering. We show that, if the dataset is made of a large number of independent random variables distributed according to the uniform measure on the union of two disjoint balls of unit radius, and if the balls are sufficiently close to one another, then sum-of-norms clustering will typically fail to recover the decomposition of the dataset into two clusters. As the dimension tends to infinity, this happens even when the distance between the centers of the two balls is taken to be as large as $2\sqrt{2}$. In order to show this, we introduce and analyze a continuous version of sum-of-norms clustering, where the dataset is replaced by a general measure. In particular, we state and prove a local-global characterization of the clustering that seems to be new even in the case of discrete datapoints.},
  archive      = {J_JMLR},
  author       = {Alexander Dunlap and Jean-Christophe Mourrat},
  journal      = {Journal of Machine Learning Research},
  number       = {123},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sum-of-norms clustering does not separate nearby balls},
  url          = {https://jmlr.org/papers/v25/21-0495.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An algorithm with optimal dimension-dependence for
zero-order nonsmooth nonconvex stochastic optimization. <em>JMLR</em>,
<em>25</em>(122), 1–14. (<a
href="https://jmlr.org/papers/v25/23-1159.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the complexity of producing $(\delta,\epsilon)$-stationary points of Lipschitz objectives which are possibly neither smooth nor convex, using only noisy function evaluations. Recent works proposed several stochastic zero-order algorithms that solve this task, all of which suffer from a dimension-dependence of $\Omega(d^{3/2})$ where $d$ is the dimension of the problem, which was conjectured to be optimal. We refute this conjecture by providing a faster algorithm that has complexity $O(d\delta^{-1}\epsilon^{-3})$, which is optimal (up to numerical constants) with respect to $d$ and also optimal with respect to the accuracy parameters $\delta,\epsilon$, thus solving an open question due to Lin et al. (2022). Moreover, the convergence rate achieved by our algorithm is also optimal for smooth objectives, proving that in the nonconvex stochastic zero-order setting, nonsmooth optimization is as easy as smooth optimization. We provide algorithms that achieve the aforementioned convergence rate in expectation as well as with high probability. Our analysis is based on a simple yet powerful lemma regarding the Goldstein-subdifferential set, which allows utilizing recent advancements in first-order nonsmooth nonconvex optimization.},
  archive      = {J_JMLR},
  author       = {Guy Kornowski and Ohad Shamir},
  journal      = {Journal of Machine Learning Research},
  number       = {122},
  pages        = {1-14},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {An algorithm with optimal dimension-dependence for zero-order nonsmooth nonconvex stochastic optimization},
  url          = {https://jmlr.org/papers/v25/23-1159.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear distance metric learning with noisy labels.
<em>JMLR</em>, <em>25</em>(121), 1–53. (<a
href="https://jmlr.org/papers/v25/23-0791.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In linear distance metric learning, we are given data in one Euclidean metric space and the goal is to find an appropriate linear map to another Euclidean metric space which respects certain distance conditions as much as possible. In this paper, we formalize a simple and elegant method which reduces to a general continuous convex loss optimization problem, and for different noise models we derive the corresponding loss functions. We show that even if the data is noisy, the ground truth linear metric can be learned with any precision provided access to enough samples, and we provide a corresponding sample complexity bound. Moreover, we present an effective way to truncate the learned model to a low-rank model that can provably maintain the accuracy in the loss function and in parameters -- the first such results of this type. Several experimental observations on synthetic and real data sets support and inform our theoretical results.},
  archive      = {J_JMLR},
  author       = {Meysam Alishahi and Anna Little and Jeff M. Phillips},
  journal      = {Journal of Machine Learning Research},
  number       = {121},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Linear distance metric learning with noisy labels},
  url          = {https://jmlr.org/papers/v25/23-0791.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OpenBox: A python toolkit for generalized black-box
optimization. <em>JMLR</em>, <em>25</em>(120), 1–11. (<a
href="https://jmlr.org/papers/v25/23-0537.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Black-box optimization (BBO) has a broad range of applications, including automatic machine learning, experimental design, and database knob tuning. However, users still face challenges when applying BBO methods to their problems at hand with existing software packages in terms of applicability, performance, and efficiency. This paper presents OpenBox, an open-source BBO toolkit with improved usability. It implements user-friendly interfaces and visualization for users to define and manage their tasks. The modular design behind OpenBox facilitates its flexible deployment in existing systems. Experimental results demonstrate the effectiveness and efficiency of OpenBox over existing systems. The source code of OpenBox is available at https://github.com/PKU-DAIR/open-box.},
  archive      = {J_JMLR},
  author       = {Huaijun Jiang and Yu Shen and Yang Li and Beicheng Xu and Sixian Du and Wentao Zhang and Ce Zhang and Bin Cui},
  journal      = {Journal of Machine Learning Research},
  number       = {120},
  pages        = {1-11},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {OpenBox: A python toolkit for generalized black-box optimization},
  url          = {https://jmlr.org/papers/v25/23-0537.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative adversarial ranking nets. <em>JMLR</em>,
<em>25</em>(119), 1–35. (<a
href="https://jmlr.org/papers/v25/23-0461.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new adversarial training framework -- generative adversarial ranking networks (GARNet) to learn from user preferences among a list of samples so as to generate data meeting user-specific criteria. Verbosely, GARNet consists of two modules: a ranker and a generator. The generator fools the ranker to raise generated samples to the top; while the ranker learns to rank generated samples at the bottom. Meanwhile, the ranker learns to rank samples regarding the interested property by training with preferences collected on real samples. The adversarial ranking game between the ranker and the generator enables an alignment between the generated data distribution and the user-preferred data distribution with theoretical guarantees and empirical verification. Specifically, we first prove that when training with full preferences on a discrete property, the learned distribution of GARNet rigorously coincides with the distribution specified by the given score vector based on user preferences. The theoretical results are then extended to partial preferences on a discrete property and further generalized to preferences on a continuous property. Meanwhile, numerous experiments show that GARNet can retrieve the distribution of user-desired data based on full/partial preferences in terms of various interested properties (i.e., discrete/continuous property, single/multiple properties). Code is available at https://github.com/EvaFlower/GARNet.},
  archive      = {J_JMLR},
  author       = {Yinghua Yao and Yuangang Pan and Jing Li and Ivor W. Tsang and Xin Yao},
  journal      = {Journal of Machine Learning Research},
  number       = {119},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Generative adversarial ranking nets},
  url          = {https://jmlr.org/papers/v25/23-0461.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive inference with weak supervision. <em>JMLR</em>,
<em>25</em>(118), 1–45. (<a
href="https://jmlr.org/papers/v25/23-0253.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expense of acquiring labels in large-scale statistical machine learning makes partially and weakly-labeled data attractive, though it is not always apparent how to leverage such data for model fitting or validation. We present a methodology to bridge the gap between partial supervision and validation, developing a conformal prediction framework to provide valid predictive confidence sets---sets that cover a true label with a prescribed probability, independent of the underlying distribution---using weakly labeled data. To do so, we introduce a (necessary) new notion of coverage and predictive validity, then develop several application scenarios, providing efficient algorithms for classification and several large-scale structured prediction problems. We corroborate the hypothesis that the new coverage definition allows for tighter and more informative (but valid) confidence sets through several experiments.},
  archive      = {J_JMLR},
  author       = {Maxime Cauchois and Suyash Gupta and Alnur Ali and John C. Duchi},
  journal      = {Journal of Machine Learning Research},
  number       = {118},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Predictive inference with weak supervision},
  url          = {https://jmlr.org/papers/v25/23-0253.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Functions with average smoothness: Structure, algorithms,
and learning. <em>JMLR</em>, <em>25</em>(117), 1–54. (<a
href="https://jmlr.org/papers/v25/23-0182.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We initiate a program of average smoothness analysis for efficiently learning real-valued functions on metric spaces. Rather than using the Lipschitz constant as the regularizer, we define a local slope at each point and gauge the function complexity as the average of these values. Since the mean can be dramatically smaller than the maximum, this complexity measure can yield considerably sharper generalization bounds --- assuming that these admit a refinement where the Lipschitz constant is replaced by our average of local slopes. Our first major contribution is to obtain just such distribution-sensitive bounds. This required overcoming a number of technical challenges, perhaps the most formidable of which was bounding the empirical covering numbers, which can be much worse-behaved than the ambient ones. Our combinatorial results are accompanied by efficient algorithms for smoothing the labels of the random sample, as well as guarantees that the extension from the sample to the whole space will continue to be, with high probability, smooth on average. Along the way we discover a surprisingly rich combinatorial and analytic structure in the function class we define.},
  archive      = {J_JMLR},
  author       = {Yair Ashlagi and Lee-Ad Gottlieb and Aryeh Kontorovich},
  journal      = {Journal of Machine Learning Research},
  number       = {117},
  pages        = {1-54},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Functions with average smoothness: Structure, algorithms, and learning},
  url          = {https://jmlr.org/papers/v25/23-0182.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentially private data release for mixed-type data via
latent factor models. <em>JMLR</em>, <em>25</em>(116), 1–37. (<a
href="https://jmlr.org/papers/v25/22-1324.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy is a particular data privacy-preserving technology which enables synthetic data or statistical analysis results to be released with a minimum disclosure of private information from individual records. The tradeoff between privacy-preserving and utility guarantee is always a challenge for differential privacy technology, especially for synthetic data generation. In this paper, we propose a differentially private data synthesis algorithm for mixed-type data with correlation based on latent factor models. The proposed method can add a relatively small amount of noise to synthetic data under a given level of privacy protection while capturing correlation information. Moreover, the proposed algorithm can generate synthetic data preserving the same data type as mixed-type original data, which greatly improves the utility of synthetic data. The key idea of our method is to perturb the factor matrix and factor loading matrix to construct a synthetic data generation model, and to utilize link functions with privacy protection to ensure consistency of synthetic data type with original data. The proposed method can generate privacy-preserving synthetic data at low computation cost even when the original data is high-dimensional. In theory, we establish differentially private properties of the proposed method. Our numerical studies also demonstrate superb performance of the proposed method on the utility guarantee of the statistical analysis based on privacy-preserved synthetic data.},
  archive      = {J_JMLR},
  author       = {Yanqing Zhang and Qi Xu and Niansheng Tang and Annie Qu},
  journal      = {Journal of Machine Learning Research},
  number       = {116},
  pages        = {1-37},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Differentially private data release for mixed-type data via latent factor models},
  url          = {https://jmlr.org/papers/v25/22-1324.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The non-overlapping statistical approximation to overlapping
group lasso. <em>JMLR</em>, <em>25</em>(115), 1–70. (<a
href="https://jmlr.org/papers/v25/22-1105.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The group lasso penalty is widely used to introduce structured sparsity in statistical learning, characterized by its ability to eliminate predefined groups of parameters automatically. However, when the groups overlap, solving the group lasso problem can be time-consuming in high-dimensional settings due to groups’ non-separability. This computational challenge has limited the applicability of the overlapping group lasso penalty in cutting-edge areas, such as gene pathway selection and graphical model estimation. This paper introduces a non-overlapping and separable penalty designed to efficiently approximate the overlapping group lasso penalty. The approximation substantially enhances the computational efficiency in optimization, especially for large-scale and high-dimensional problems. We show that the proposed penalty is the tightest separable relaxation of the overlapping group lasso norm within the family of $\ell_{q_1}/\ell_{q_2}$ norms. Moreover, the estimators derived from our proposed norm are statistically equivalent to those derived from the overlapping group lasso penalty in terms of estimation error, support recovery, and minimax rate under the squared loss. The effectiveness of our method is demonstrated through extensive simulation examples and a predictive task of cancer tumors.},
  archive      = {J_JMLR},
  author       = {Mingyu Qi and Tianxi Li},
  journal      = {Journal of Machine Learning Research},
  number       = {115},
  pages        = {1-70},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {The non-overlapping statistical approximation to overlapping group lasso},
  url          = {https://jmlr.org/papers/v25/22-1105.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Faster rates of differentially private stochastic convex
optimization. <em>JMLR</em>, <em>25</em>(114), 1–41. (<a
href="https://jmlr.org/papers/v25/22-0079.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we revisit the problem of Differentially Private Stochastic Convex Optimization (DP-SCO) and provide excess population risks for some special classes of functions that are faster than the previous results of general convex and strongly convex functions. In the first part of the paper, we study the case where the population risk function satisfies the Tysbakov Noise Condition (TNC) with some parameter $\theta&gt;1$. Specifically, we first show that under some mild assumptions on the loss functions, there is an algorithm whose output could achieve an upper bound of $\tilde{O}((\frac{1}{\sqrt{n}}+\frac{d}{n\epsilon})^\frac{\theta}{\theta-1}) $ and $\tilde{O}((\frac{1}{\sqrt{n}}+\frac{\sqrt{d\log(1/\delta)}}{n\epsilon})^\frac{\theta}{\theta-1})$ for $\epsilon$-DP and $(\epsilon, \delta)$-DP, respectively when $\theta\geq 2$, where $n$ is the sample size and $d$ is the dimension of the space. Then we address the inefficiency issue, improve the upper bounds by $\text{Poly}(\log n)$ factors and extend to the case where $\theta\geq \bar{\theta}&gt;1$ for some known $\bar{\theta}$. Next, we show that the excess population risk of population functions satisfying TNC with parameter $\theta\geq 2$ is always lower bounded by $\Omega((\frac{d}{n\epsilon})^\frac{\theta}{\theta-1}) $ and $\Omega((\frac{\sqrt{d\log(1/\delta)}}{n\epsilon})^\frac{\theta}{\theta-1})$ for $\epsilon$-DP and $(\epsilon, \delta)$-DP, respectively, which matches our upper bounds. In the second part, we focus on a special case where the population risk function is strongly convex. Unlike the previous studies, here we assume the loss function is non-negative and the optimal value of population risk is sufficiently small. With these additional assumptions, we propose a new method whose output could achieve an upper bound of $O(\frac{d\log(1/\delta)}{n^2\epsilon^2}+\frac{1}{n^{\tau}})$ and $O(\frac{d^2}{n^2\epsilon^2}+\frac{1}{n^{\tau}})$ for any $\tau&gt; 1$ in $(\epsilon,\delta)$-DP and $\epsilon$-DP model respectively if the sample size $n$ is sufficiently large. These results circumvent their corresponding lower bounds in (Feldman et al., 2020) for general strongly convex functions. Finally, we conduct experiments of our new methods on real-world data. Experimental results also provide new insights into established theories.},
  archive      = {J_JMLR},
  author       = {Jinyan Su and Lijie Hu and Di Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {114},
  pages        = {1-41},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Faster rates of differentially private stochastic convex optimization},
  url          = {https://jmlr.org/papers/v25/22-0079.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonasymptotic analysis of stochastic gradient hamiltonian
monte carlo under local conditions for nonconvex optimization.
<em>JMLR</em>, <em>25</em>(113), 1–34. (<a
href="https://jmlr.org/papers/v25/21-1423.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a nonasymptotic analysis of the convergence of the stochastic gradient Hamiltonian Monte Carlo (SGHMC) to a target measure in Wasserstein-2 distance without assuming log-concavity. Our analysis quantifies key theoretical properties of the SGHMC as a sampler under local conditions which significantly improves the findings of previous results. In particular, we prove that the Wasserstein-2 distance between the target and the law of the SGHMC is uniformly controlled by the step-size of the algorithm, therefore demonstrate that the SGHMC can provide high-precision results uniformly in the number of iterations. The analysis also allows us to obtain nonasymptotic bounds for nonconvex optimization problems under local conditions and implies that the SGHMC, when viewed as a nonconvex optimizer, converges to a global minimum with the best known rates. We apply our results to obtain nonasymptotic bounds for scalable Bayesian inference and nonasymptotic generalization bounds.},
  archive      = {J_JMLR},
  author       = {O. Deniz Akyildiz and Sotirios Sabanis},
  journal      = {Journal of Machine Learning Research},
  number       = {113},
  pages        = {1-34},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Nonasymptotic analysis of stochastic gradient hamiltonian monte carlo under local conditions for nonconvex optimization},
  url          = {https://jmlr.org/papers/v25/21-1423.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time analysis of globally nonstationary multi-armed
bandits. <em>JMLR</em>, <em>25</em>(112), 1–56. (<a
href="https://jmlr.org/papers/v25/21-0916.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider nonstationary multi-armed bandit problems where the model parameters of the arms change over time. We introduce the adaptive resetting bandit (ADR-bandit), a bandit algorithm class that leverages adaptive windowing techniques from literature on data streams. We first provide new guarantees on the quality of estimators resulting from adaptive windowing techniques, which are of independent interest. Furthermore, we conduct a finite-time analysis of ADR-bandit in two typical environments: an abrupt environment where changes occur instantaneously and a gradual environment where changes occur progressively. We demonstrate that ADR-bandit has nearly optimal performance when abrupt or gradual changes occur in a coordinated manner that we call global changes. We demonstrate that forced exploration is unnecessary when we assume such global changes. Unlike the existing nonstationary bandit algorithms, ADR-bandit has optimal performance in stationary environments as well as nonstationary environments with global changes. Our experiments show that the proposed algorithms outperform the existing approaches in synthetic and real-world environments.},
  archive      = {J_JMLR},
  author       = {Junpei Komiyama and Edouard Fouché and Junya Honda},
  journal      = {Journal of Machine Learning Research},
  number       = {112},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Finite-time analysis of globally nonstationary multi-armed bandits},
  url          = {https://jmlr.org/papers/v25/21-0916.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stable implementation of probabilistic ODE solvers.
<em>JMLR</em>, <em>25</em>(111), 1–29. (<a
href="https://jmlr.org/papers/v25/20-1423.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic solvers for ordinary differential equations (ODEs) provide efficient quantification of numerical uncertainty associated with the simulation of dynamical systems. Their convergence rates have been established by a growing body of theoretical analysis. However, these algorithms suffer from numerical instability when run at high order or with small step sizes---that is, exactly in the regime in which they achieve the highest accuracy. The present work proposes and examines a solution to this problem. It involves three components: accurate initialisation, a coordinate change preconditioner that makes numerical stability concerns step-size-independent, and square-root implementation. Using all three techniques enables numerical computation of probabilistic solutions of ODEs with algorithms of order up to 11, as demonstrated on a set of challenging test problems. The resulting rapid convergence is shown to be competitive with high-order, state-of-the-art, classical methods. As a consequence, a barrier between analysing probabilistic ODE solvers and applying them to interesting machine learning problems is effectively removed.},
  archive      = {J_JMLR},
  author       = {Nicholas Krämer and Philipp Hennig},
  journal      = {Journal of Machine Learning Research},
  number       = {111},
  pages        = {1-29},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Stable implementation of probabilistic ODE solvers},
  url          = {https://jmlr.org/papers/v25/20-1423.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). More PAC-bayes bounds: From bounded losses, to losses with
general tail behaviors, to anytime validity. <em>JMLR</em>,
<em>25</em>(110), 1–43. (<a
href="https://jmlr.org/papers/v25/23-1360.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present new high-probability PAC-Bayes bounds for different types of losses. Firstly, for losses with a bounded range, we recover a strengthened version of Catoni&#39;s bound that holds uniformly for all parameter values. This leads to new fast-rate and mixed-rate bounds that are interpretable and tighter than previous bounds in the literature. In particular, the fast-rate bound is equivalent to the Seeger--Langford bound. Secondly, for losses with more general tail behaviors, we introduce two new parameter-free bounds: a PAC-Bayes Chernoff analogue when the loss&#39; cumulative generating function is bounded, and a bound when the loss&#39; second moment is bounded. These two bounds are obtained using a new technique based on a discretization of the space of possible events for the &quot;in probability&quot; parameter optimization problem. This technique is both simpler and more general than previous approaches optimizing over a grid on the parameters&#39; space. Finally, using a simple technique that is applicable to any existing bound, we extend all previous results to anytime-valid bounds.},
  archive      = {J_JMLR},
  author       = {Borja Rodríguez-Gálvez and Ragnar Thobaben and Mikael Skoglund},
  journal      = {Journal of Machine Learning Research},
  number       = {110},
  pages        = {1-43},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {More PAC-bayes bounds: From bounded losses, to losses with general tail behaviors, to anytime validity},
  url          = {https://jmlr.org/papers/v25/23-1360.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural hilbert ladders: Multi-layer neural networks in
function space. <em>JMLR</em>, <em>25</em>(109), 1–65. (<a
href="https://jmlr.org/papers/v25/23-1225.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To characterize the function space explored by neural networks (NNs) is an important aspect of learning theory. In this work, noticing that a multi-layer NN generates implicitly a hierarchy of reproducing kernel Hilbert spaces (RKHSs) -named a neural Hilbert ladder (NHL) - we define the function space as an infinite union of RKHSs, which generalizes the existing Barron space theory of two-layer NNs. We then establish several theoretical properties of the new space. First, we prove a correspondence between functions expressed by L-layer NNs and those belonging to L-level NHLs. Second, we prove generalization guarantees for learning an NHL with a controlled complexity measure. Third, we derive a non-Markovian dynamics of random fields that governs the evolution of the NHL which is induced by the training of multi-layer NNs in an infinite-width mean-field limit. Fourth, we show examples of depth separation in NHLs under the ReLU activation function. Finally, we perform numerical experiments to illustrate the feature learning aspect of NN training through the lens of NHLs.},
  archive      = {J_JMLR},
  author       = {Zhengdao Chen},
  journal      = {Journal of Machine Learning Research},
  number       = {109},
  pages        = {1-65},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Neural hilbert ladders: Multi-layer neural networks in function space},
  url          = {https://jmlr.org/papers/v25/23-1225.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). QDax: A library for quality-diversity and population-based
algorithms with hardware acceleration. <em>JMLR</em>, <em>25</em>(108),
1–16. (<a href="https://jmlr.org/papers/v25/23-1027.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {QDax is an open-source library with a streamlined and modular API for Quality-Diversity (QD) optimisation algorithms in Jax. The library serves as a versatile tool for optimisation purposes, ranging from black-box optimisation to continuous control. QDax offers implementations of popular QD, Neuroevolution, and Reinforcement Learning (RL) algorithms, supported by various examples. All the implementations can be just-in-time compiled with Jax, facilitating efficient execution across multiple accelerators, including GPUs and TPUs. These implementations effectively demonstrate the framework&#39;s flexibility and user-friendliness, easing experimentation for research purposes. Furthermore, the library is thoroughly documented and has 93% test coverage.},
  archive      = {J_JMLR},
  author       = {Felix Chalumeau and Bryan Lim and Raphaël Boige and Maxime Allard and Luca Grillotti and Manon Flageat and Valentin Macé and Guillaume Richard and Arthur Flajolet and Thomas Pierrot and Antoine Cully},
  journal      = {Journal of Machine Learning Research},
  number       = {108},
  pages        = {1-16},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {QDax: A library for quality-diversity and population-based algorithms with hardware acceleration},
  url          = {https://jmlr.org/papers/v25/23-1027.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Random forest weighted local fréchet regression with random
objects. <em>JMLR</em>, <em>25</em>(107), 1–69. (<a
href="https://jmlr.org/papers/v25/23-0811.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical analysis is increasingly confronted with complex data from metric spaces. Petersen and Müller (2019) established a general paradigm of Fréchet regression with complex metric space valued responses and Euclidean predictors. However, the local approach therein involves nonparametric kernel smoothing and suffers from the curse of dimensionality. To address this issue, we in this paper propose a novel random forest weighted local Fréchet regression paradigm. The main mechanism of our approach relies on a locally adaptive kernel generated by random forests. Our first method uses these weights as the local average to solve the conditional Fréchet mean, while the second method performs local linear Fréchet regression, both significantly improving existing Fréchet regression methods. Based on the theory of infinite order U-processes and infinite order $M_{m_n}$-estimator, we establish the consistency, rate of convergence, and asymptotic normality for our local constant estimator, which covers the current large sample theory of random forests with Euclidean responses as a special case. Numerical studies show the superiority of our methods with several commonly encountered types of responses such as distribution functions, symmetric positive-definite matrices, and sphere data. The practical merits of our proposals are also demonstrated through the application to New York taxi data and human mortality data.},
  archive      = {J_JMLR},
  author       = {Rui Qiu and Zhou Yu and Ruoqing Zhu},
  journal      = {Journal of Machine Learning Research},
  number       = {107},
  pages        = {1-69},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Random forest weighted local fréchet regression with random objects},
  url          = {https://jmlr.org/papers/v25/23-0811.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PhAST: Physics-aware, scalable, and task-specific GNNs for
accelerated catalyst design. <em>JMLR</em>, <em>25</em>(106), 1–26. (<a
href="https://jmlr.org/papers/v25/23-0680.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitigating the climate crisis requires a rapid transition towards lower-carbon energy. Catalyst materials play a crucial role in the electrochemical reactions involved in numerous industrial processes key to this transition, such as renewable energy storage and electrofuel synthesis. To reduce the energy spent on such activities, we must quickly discover more efficient catalysts to drive electrochemical reactions. Machine learning (ML) holds the potential to efficiently model materials properties from large amounts of data, accelerating electrocatalyst design. The Open Catalyst Project OC20 dataset was constructed to that end. However, ML models trained on OC20 are still neither scalable nor accurate enough for practical applications. In this paper, we propose task-specific innovations applicable to most architectures, enhancing both computational efficiency and accuracy. This includes improvements in (1) the graph creation step, (2) atom representations, (3) the energy prediction head, and (4) the force prediction head. We describe these contributions, referred to as PhAST, and evaluate them thoroughly on multiple architectures. Overall, PhAST improves energy MAE by 4 to 42% while dividing compute time by 3 to 8× depending on the targeted task/model. PhAST also enables CPU training, leading to 40× speedups in highly parallelized settings. Python package: https://phast.readthedocs.io.},
  archive      = {J_JMLR},
  author       = {Alexandre Duval and Victor Schmidt and Santiago Miret and Yoshua Bengio and Alex Hernández-García and David Rolnick},
  journal      = {Journal of Machine Learning Research},
  number       = {106},
  pages        = {1-26},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {PhAST: Physics-aware, scalable, and task-specific GNNs for accelerated catalyst design},
  url          = {https://jmlr.org/papers/v25/23-0680.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised anomaly detection algorithms on real-world
data: How many do we need? <em>JMLR</em>, <em>25</em>(105), 1–34. (<a
href="https://jmlr.org/papers/v25/23-0570.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study we evaluate 33 unsupervised anomaly detection algorithms on 52 real-world multivariate tabular data sets, performing the largest comparison of unsupervised anomaly detection algorithms to date. On this collection of data sets, the EIF (Extended Isolation Forest) algorithm significantly outperforms the most other algorithms. Visualizing and then clustering the relative performance of the considered algorithms on all data sets, we identify two clear clusters: one with &quot;local” data sets, and another with &quot;global” data sets. &quot;Local” anomalies occupy a region with low density when compared to nearby samples, while &quot;global” occupy an overall low density region in the feature space. On the local data sets the $k$NN ($k$-nearest neighbor) algorithm comes out on top. On the global data sets, the EIF (extended isolation forest) algorithm performs the best. Also taking into consideration the algorithms&#39; computational complexity, a toolbox with these two unsupervised anomaly detection algorithms suffices for finding anomalies in this representative collection of multivariate data sets. By providing access to code and data sets, our study can be easily reproduced and extended with more algorithms and/or data sets.},
  archive      = {J_JMLR},
  author       = {Roel Bouman and Zaharah Bukhsh and Tom Heskes},
  journal      = {Journal of Machine Learning Research},
  number       = {105},
  pages        = {1-34},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Unsupervised anomaly detection algorithms on real-world data: How many do we need?},
  url          = {https://jmlr.org/papers/v25/23-0570.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-class probabilistic bounds for majority vote
classifiers with partially labeled data. <em>JMLR</em>,
<em>25</em>(104), 1–47. (<a
href="https://jmlr.org/papers/v25/23-0121.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a probabilistic framework for analyzing a multi-class majority vote classifier in the case where training data is partially labeled. First, we derive a multi-class transductive bound over the risk of the majority vote classifier, which is based on the classifier&#39;s vote distribution over each class. Then, we introduce a mislabeling error model to analyze the error of the majority vote classifier in the case of the pseudo-labeled training data. We derive a generalization bound over the majority vote error when imperfect labels are given, taking into account the mean and the variance of the prediction margin. Finally, we demonstrate an application of the derived transductive bound for self-training to find automatically the confidence threshold used to determine unlabeled examples for pseudo-labeling. Empirical results on different data sets show the effectiveness of our framework compared to several state-of-the-art semi-supervised approaches.},
  archive      = {J_JMLR},
  author       = {Vasilii Feofanov and Emilie Devijver and Massih-Reza Amini},
  journal      = {Journal of Machine Learning Research},
  number       = {104},
  pages        = {1-47},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Multi-class probabilistic bounds for majority vote classifiers with partially labeled data},
  url          = {https://jmlr.org/papers/v25/23-0121.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Information processing equalities and the information–risk
bridge. <em>JMLR</em>, <em>25</em>(103), 1–53. (<a
href="https://jmlr.org/papers/v25/22-0988.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce two new classes of measures of information for statistical experiments which generalise and subsume φ-divergences, integral probability metrics, N-distances (MMD), and (f,Γ) divergences between two or more distributions. This enables us to derive a simple geometrical relationship between measures of information and the Bayes risk of a statistical decision problem, thus extending the variational φ-divergence representation to multiple distributions in an entirely symmetric manner. The new families of divergence are closed under the action of Markov operators which yields an information processing equality which is a refinement and generalisation of the classical information processing inequality. This equality gives insight into the significance of the choice of the hypothesis class in classical risk minimization.},
  archive      = {J_JMLR},
  author       = {Robert C. Williamson and Zac Cranko},
  journal      = {Journal of Machine Learning Research},
  number       = {103},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Information processing equalities and the Information–Risk bridge},
  url          = {https://jmlr.org/papers/v25/22-0988.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonparametric regression for 3D point cloud learning.
<em>JMLR</em>, <em>25</em>(102), 1–56. (<a
href="https://jmlr.org/papers/v25/22-0735.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been an exponentially increased amount of point clouds collected with irregular shapes in various areas. Motivated by the importance of solid modeling for point clouds, we develop a novel and efficient smoothing tool based on multivariate splines over the triangulation to extract the underlying signal and build up a 3D solid model from the point cloud. The proposed method can denoise or deblur the point cloud effectively, provide a multi-resolution reconstruction of the actual signal, and handle sparse and irregularly distributed point clouds to recover the underlying trajectory. In addition, our method provides a natural way of numerosity data reduction. We establish the theoretical guarantees of the proposed method, including the convergence rate and asymptotic normality of the estimator, and show that the convergence rate achieves optimal nonparametric convergence. We also introduce a bootstrap method to quantify the uncertainty of the estimators. Through extensive simulation studies and a real data example, we demonstrate the superiority of the proposed method over traditional smoothing methods in terms of estimation accuracy and efficiency of data reduction.},
  archive      = {J_JMLR},
  author       = {Xinyi Li and Shan Yu and Yueying Wang and Guannan Wang and Li Wang and Ming-Jun Lai},
  journal      = {Journal of Machine Learning Research},
  number       = {102},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Nonparametric regression for 3D point cloud learning},
  url          = {https://jmlr.org/papers/v25/22-0735.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AMLB: An AutoML benchmark. <em>JMLR</em>, <em>25</em>(101),
1–65. (<a href="https://jmlr.org/papers/v25/22-0493.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comparing different AutoML frameworks is notoriously challenging and often done incorrectly. We introduce an open and extensible benchmark that follows best practices and avoids common mistakes when comparing AutoML frameworks. We conduct a thorough comparison of 9 well-known AutoML frameworks across 71 classification and 33 regression tasks. The differences between the AutoML frameworks are explored with a multi-faceted analysis, evaluating model accuracy, its trade-offs with inference time, and framework failures. We also use Bradley-Terry trees to discover subsets of tasks where the relative AutoML framework rankings differ. The benchmark comes with an open-source tool that integrates with many AutoML frameworks and automates the empirical evaluation process end-to-end: from framework installation and resource allocation to in-depth evaluation. The benchmark uses public data sets, can be easily extended with other AutoML frameworks and tasks, and has a website with up-to-date results.},
  archive      = {J_JMLR},
  author       = {Pieter Gijsbers and Marcos L. P. Bueno and Stefan Coors and Erin LeDell and Sébastien Poirier and Janek Thomas and Bernd Bischl and Joaquin Vanschoren},
  journal      = {Journal of Machine Learning Research},
  number       = {101},
  pages        = {1-65},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {AMLB: An AutoML benchmark},
  url          = {https://jmlr.org/papers/v25/22-0493.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Materials discovery using max k-armed bandit. <em>JMLR</em>,
<em>25</em>(100), 1–40. (<a
href="https://jmlr.org/papers/v25/22-0186.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Search algorithms for bandit problems are applicable in materials discovery. However, objectives of the conventional bandit problem are different from those of materials discovery. The conventional bandit problem aims to maximize the total rewards, whereas materials discovery aims to achieve breakthroughs in material properties. The max $K$-armed bandit (MKB) problem, which aims to acquire the single best reward, matches with the discovery tasks better than the conventional bandit. However, typical MKB algorithms are not directly applicable to materials discovery due to some difficulties. The typical algorithms have many hyperparameters and some difficulty in the directly implementation for the materials discovery. Thus, we propose a new MKB algorithm using an upper confidence bound of expected improvement of the best reward. This approach is guaranteed to be asymptotic to greedy oracles, which does not depend on the time horizon. In addition, compared with other MKB algorithms, the proposed algorithm has only one hyperparameter, which is advantageous in materials discovery. We applied the proposed algorithm to synthetic problems and molecular-design demonstrations using a Monte Carlo tree search. According to the results, the proposed algorithm stably outperformed other bandit algorithms in the late stage of the search process, unless the optimal arm coincides in the MKB and conventional bandit settings.},
  archive      = {J_JMLR},
  author       = {Nobuaki Kikkawa and Hiroshi Ohno},
  journal      = {Journal of Machine Learning Research},
  number       = {100},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Materials discovery using max K-armed bandit},
  url          = {https://jmlr.org/papers/v25/22-0186.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised inference for block-wise missing data
without imputation. <em>JMLR</em>, <em>25</em>(99), 1–36. (<a
href="https://jmlr.org/papers/v25/21-1504.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider statistical inference for single or low-dimensional parameters in a high-dimensional linear model under a semi-supervised setting, wherein the data are a combination of a labelled block-wise missing data set of a relatively small size and a large unlabelled data set. The proposed method utilises both labelled and unlabelled data without any imputation or removal of the missing observations. The asymptotic properties of the estimator are established under regularity conditions. Hypothesis testing for low-dimensional coefficients are also studied. Extensive simulations are conducted to examine the theoretical results. The method is evaluated on the Alzheimer’s Disease Neuroimaging Initiative data.},
  archive      = {J_JMLR},
  author       = {Shanshan Song and Yuanyuan Lin and Yong Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {99},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Semi-supervised inference for block-wise missing data without imputation},
  url          = {https://jmlr.org/papers/v25/21-1504.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptivity and non-stationarity: Problem-dependent dynamic
regret for online convex optimization. <em>JMLR</em>, <em>25</em>(98),
1–52. (<a href="https://jmlr.org/papers/v25/21-0748.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate online convex optimization in non-stationary environments and choose dynamic regret as the performance measure, defined as the difference between cumulative loss incurred by the online algorithm and that of any feasible comparator sequence. Let $T$ be the time horizon and $P_T$ be the path length that essentially reflects the non-stationarity of environments, the state-of-the-art dynamic regret is $\mathcal{O}(\sqrt{T(1+P_T)})$. Although this bound is proved to be minimax optimal for convex functions, in this paper, we demonstrate that it is possible to further enhance the guarantee for some easy problem instances, particularly when online functions are smooth. Specifically, we introduce novel online algorithms that can exploit smoothness and replace the dependence on $T$ in dynamic regret with problem-dependent quantities: the variation in gradients of loss functions, the cumulative loss of the comparator sequence, and the minimum of these two terms. These quantities are at most $\mathcal{O}(T)$ while could be much smaller in benign environments. Therefore, our results are adaptive to the intrinsic difficulty of the problem, since the bounds are tighter than existing results for easy problems and meanwhile safeguard the same rate in the worst case. Notably, our proposed algorithms can achieve favorable dynamic regret with only one gradient per iteration, sharing the same gradient query complexity as the static regret minimization methods. To accomplish this, we introduce the collaborative online ensemble framework. The proposed framework employs a two-layer online ensemble to handle non-stationarity, and uses optimistic online learning and further introduces crucial correction terms to enable effective collaboration within the meta-base two layers, thereby attaining adaptivity. We believe the framework can be useful for broader problems.},
  archive      = {J_JMLR},
  author       = {Peng Zhao and Yu-Jie Zhang and Lijun Zhang and Zhi-Hua Zhou},
  journal      = {Journal of Machine Learning Research},
  number       = {98},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Adaptivity and non-stationarity: Problem-dependent dynamic regret for online convex optimization},
  url          = {https://jmlr.org/papers/v25/21-0748.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scaling speech technology to 1,000+ languages.
<em>JMLR</em>, <em>25</em>(97), 1–52. (<a
href="https://jmlr.org/papers/v25/23-1318.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expanding the language coverage of speech technology has the potential to improve access to information for many more people. However, current speech technology is restricted to about one hundred languages which is a small fraction of the over 7,000 languages spoken around the world. The Massively Multilingual Speech (MMS) project increases the number of supported languages by 10-40x, depending on the task while providing improved accuracy compared to prior work. The main ingredients are a new dataset based on readings of publicly available religious texts and effectively leveraging self-supervised learning. We built pre-trained wav2vec 2.0 models covering 1,406 languages, a single multilingual automatic speech recognition model for 1,107 languages, speech synthesis models for the same number of languages, as well as a language identification model for 4,017 languages. Experiments show that our multilingual speech recognition model more than halves the word error rate of Whisper on 54 languages of the FLEURS benchmark while being trained on a small fraction of the labeled data.},
  archive      = {J_JMLR},
  author       = {Vineel Pratap and Andros Tjandra and Bowen Shi and Paden Tomasello and Arun Babu and Sayani Kundu and Ali Elkahky and Zhaoheng Ni and Apoorv Vyas and Maryam Fazel-Zarandi and Alexei Baevski and Yossi Adi and Xiaohui Zhang and Wei-Ning Hsu and Alexis Conneau and Michael Auli},
  journal      = {Journal of Machine Learning Research},
  number       = {97},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Scaling speech technology to 1,000+ languages},
  url          = {https://jmlr.org/papers/v25/23-1318.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MAP- and MLE-based teaching. <em>JMLR</em>, <em>25</em>(96),
1–34. (<a href="https://jmlr.org/papers/v25/23-1086.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imagine a learner $L$ who tries to infer a hidden concept from a collection of observations. Building on the work of Ferri et al we assume the learner to be parameterized by priors $P(c)$ and by $c$-conditional likelihoods $P(z|c)$ where $c$ ranges over all concepts in a given class $C$ and $z$ ranges over all observations in an observation set $Z$. $L$ is called a MAP-learner (resp.~an MLE-learner) if it thinks of a collection $S$ of observations as a random sample and returns the concept with the maximum a-posteriori probability (resp.~the concept which maximizes the $c$-conditional likelihood of $S$). Depending on whether $L$ assumes that $S$ is obtained from ordered or unordered sampling resp.~from sampling with or without replacement, we can distinguish four different sampling modes. Given a target concept $c^* \in C$, a teacher for a MAP-learner $L$ aims at finding a smallest collection of observations that causes $L$ to return $c^*$. This approach leads in a natural manner to various notions of a MAP- or MLE-teaching dimension of a concept class $C$. Our main results are as follows. First, we show that this teaching model has some desirable monotonicity properties. Second we clarify how the four sampling modes are related to each other. As for the (important!) special case, where concepts are subsets of a domain and observations are 0,1-labeled examples, we obtain some additional results. First of all, we characterize the MAP- and MLE-teaching dimension associated with an optimally parameterized MAP-learner graph-theoretically. From this central result, some other ones are easy to derive. It is shown, for instance, that the MLE-teaching dimension is either equal to the MAP-teaching dimension or exceeds the latter by $1$. It is shown furthermore that these dimensions can be bounded from above by the so-called antichain number, the VC-dimension and related combinatorial parameters. Moreover they can be computed in polynomial time.},
  archive      = {J_JMLR},
  author       = {Hans Ulrich Simon and Jan Arne Telle},
  journal      = {Journal of Machine Learning Research},
  number       = {96},
  pages        = {1-34},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {MAP- and MLE-based teaching},
  url          = {https://jmlr.org/papers/v25/23-1086.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A general framework for the analysis of kernel-based tests.
<em>JMLR</em>, <em>25</em>(95), 1–40. (<a
href="https://jmlr.org/papers/v25/23-0985.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel-based tests provide a simple yet effective framework that uses the theory of reproducing kernel Hilbert spaces to design non-parametric testing procedures. In this paper, we propose new theoretical tools that can be used to study the asymptotic behaviour of kernel-based tests in various data scenarios and in different testing problems. Unlike current approaches, our methods avoid working with U and V-statistics expansions that usually lead to lengthy and tedious computations and asymptotic approximations. Instead, we work directly with random functionals on the Hilbert space to analyse kernel-based tests. By harnessing the use of random functionals, our framework leads to much cleaner analyses, involving less tedious computations. Additionally, it offers the advantage of accommodating pre-existing knowledge regarding test-statistics as many of the random functionals considered in applications are known statistics that have been studied comprehensively. To demonstrate the efficacy of our approach, we thoroughly examine two categories of kernel tests, along with three specific examples of kernel tests, including a novel kernel test for conditional independence testing.},
  archive      = {J_JMLR},
  author       = {Tamara Fernández and Nicolás Rivera},
  journal      = {Journal of Machine Learning Research},
  number       = {95},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A general framework for the analysis of kernel-based tests},
  url          = {https://jmlr.org/papers/v25/23-0985.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overparametrized multi-layer neural networks: Uniform
concentration of neural tangent kernel and convergence of stochastic
gradient descent. <em>JMLR</em>, <em>25</em>(94), 1–83. (<a
href="https://jmlr.org/papers/v25/23-0740.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There have been exciting progresses in understanding the convergence of gradient descent (GD) and stochastic gradient descent (SGD) in overparameterized neural networks through the lens of neural tangent kernel (NTK). However, there remain two significant gaps between theory and practice. First, the existing convergence theory only takes into account the contribution of the NTK from the last hidden layer, while in practice the intermediate layers also play an instrumental role. Second, most existing works assume that the training data are provided a priori in a batch, while less attention has been paid to the important setting where the training data arrive in a stream. In this paper, we close these two gaps. We first show that with random initialization, the NTK function converges to some deterministic function uniformly for all layers as the number of neurons tends to infinity. Then we apply the uniform convergence result to further prove that the prediction error of multi-layer neural networks under SGD converges in expectation in the streaming data setting. A key ingredient in our proof is to show the number of activation patterns of an $L$-layer neural network with width $m$ is only polynomial in $m$ although there are $mL$ neurons in total.},
  archive      = {J_JMLR},
  author       = {Jiaming Xu and Hanjing Zhu},
  journal      = {Journal of Machine Learning Research},
  number       = {94},
  pages        = {1-83},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Overparametrized multi-layer neural networks: Uniform concentration of neural tangent kernel and convergence of stochastic gradient descent},
  url          = {https://jmlr.org/papers/v25/23-0740.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse representer theorems for learning in reproducing
kernel banach spaces. <em>JMLR</em>, <em>25</em>(93), 1–45. (<a
href="https://jmlr.org/papers/v25/23-0645.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparsity of a learning solution is a desirable feature in machine learning. Certain reproducing kernel Banach spaces (RKBSs) are appropriate hypothesis spaces for sparse learning methods. The goal of this paper is to understand what kind of RKBSs can promote sparsity for learning solutions. We consider two typical learning models in an RKBS: the minimum norm interpolation (MNI) problem and the regularization problem. We first establish an explicit representer theorem for solutions of these problems, which represents the extreme points of the solution set by a linear combination of the extreme points of the subdifferential set, of the norm function, which is data-dependent. We then propose sufficient conditions on the RKBS that can transform the explicit representation of the solutions to a sparse kernel representation having fewer terms than the number of the observed data. Under the proposed sufficient conditions, we investigate the role of the regularization parameter on sparsity of the regularized solutions. We further show that two specific RKBSs, the sequence space $\ell_1(\mathbb{N})$ and the measure space, can have sparse representer theorems for both MNI and regularization models.},
  archive      = {J_JMLR},
  author       = {Rui Wang and Yuesheng Xu and Mingsong Yan},
  journal      = {Journal of Machine Learning Research},
  number       = {93},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sparse representer theorems for learning in reproducing kernel banach spaces},
  url          = {https://jmlr.org/papers/v25/23-0645.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploration of the search space of gaussian graphical models
for paired data. <em>JMLR</em>, <em>25</em>(92), 1–41. (<a
href="https://jmlr.org/papers/v25/23-0295.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of learning a Gaussian graphical model in the case where the observations come from two dependent groups sharing the same variables. We focus on a family of coloured Gaussian graphical models specifically suited for the paired data problem. Commonly, graphical models are ordered by the submodel relationship so that the search space is a lattice, called the model inclusion lattice. We introduce a novel order between models, named the twin order. We show that, embedded with this order, the model space is a lattice that, unlike the model inclusion lattice, is distributive. Furthermore, we provide the relevant rules for the computation of the neighbours of a model. The latter are more efficient than the same operations in the model inclusion lattice, and are then exploited to achieve a more efficient exploration of the search space. These results can be applied to improve the efficiency of both greedy and Bayesian model search procedures. Here, we implement a stepwise backward elimination procedure and evaluate its performance both on synthetic and real-world data.},
  archive      = {J_JMLR},
  author       = {Alberto Roverato and Dung Ngoc Nguyen},
  journal      = {Journal of Machine Learning Research},
  number       = {92},
  pages        = {1-41},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Exploration of the search space of gaussian graphical models for paired data},
  url          = {https://jmlr.org/papers/v25/23-0295.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The good, the bad and the ugly sides of data augmentation:
An implicit spectral regularization perspective. <em>JMLR</em>,
<em>25</em>(91), 1–85. (<a
href="https://jmlr.org/papers/v25/22-1312.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation (DA) is a powerful workhorse for bolstering performance in modern machine learning. Specific augmentations like translations and scaling in computer vision are traditionally believed to improve generalization by generating new (artificial) data from the same distribution. However, this traditional viewpoint does not explain the success of prevalent augmentations in modern machine learning (e.g. randomized masking, cutout, mixup), that greatly alter the training data distribution. In this work, we develop a new theoretical framework to characterize the impact of a general class of DA on underparameterized and overparameterized linear model generalization. Our framework reveals that DA induces implicit spectral regularization through a combination of two distinct effects: a) manipulating the relative proportion of eigenvalues of the data covariance matrix in a training-data-dependent manner, and b) uniformly boosting the entire spectrum of the data covariance matrix through ridge regression. These effects, when applied to popular augmentations, give rise to a wide variety of phenomena, including discrepancies in generalization between overparameterized and underparameterized regimes and differences between regression and classification tasks. Our framework highlights the nuanced and sometimes surprising impacts of DA on generalization, and serves as a testbed for novel augmentation design.},
  archive      = {J_JMLR},
  author       = {Chi-Heng Lin and Chiraag Kaushik and Eva L. Dyer and Vidya Muthukumar},
  journal      = {Journal of Machine Learning Research},
  number       = {91},
  pages        = {1-85},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {The good, the bad and the ugly sides of data augmentation: An implicit spectral regularization perspective},
  url          = {https://jmlr.org/papers/v25/22-1312.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic approximation with decision-dependent
distributions: Asymptotic normality and optimality. <em>JMLR</em>,
<em>25</em>(90), 1–49. (<a
href="https://jmlr.org/papers/v25/22-0832.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze a stochastic approximation algorithm for decision-dependent problems, wherein the data distribution used by the algorithm evolves along the iterate sequence. The primary examples of such problems appear in performative prediction and its multiplayer extensions. We show that under mild assumptions, the deviation between the average iterate of the algorithm and the solution is asymptotically normal, with a covariance that clearly decouples the effects of the gradient noise and the distributional shift. Moreover, building on the work of Hájek and Le Cam, we show that the asymptotic performance of the algorithm with averaging is locally minimax optimal.},
  archive      = {J_JMLR},
  author       = {Joshua Cutler and Mateo Díaz and Dmitriy Drusvyatskiy},
  journal      = {Journal of Machine Learning Research},
  number       = {90},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Stochastic approximation with decision-dependent distributions: Asymptotic normality and optimality},
  url          = {https://jmlr.org/papers/v25/22-0832.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimax rates for high-dimensional random tessellation
forests. <em>JMLR</em>, <em>25</em>(89), 1–32. (<a
href="https://jmlr.org/papers/v25/22-0673.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random forests are a popular class of algorithms used for regression and classification. The algorithm introduced by Breiman in 2001 and many of its variants are ensembles of randomized decision trees built from axis-aligned partitions of the feature space. One such variant, called Mondrian forests, was proposed to handle the online setting and is the first class of random forests for which minimax optimal rates were obtained in arbitrary dimension. However, the restriction to axis-aligned splits fails to capture dependencies between features, and random forests that use oblique splits have shown improved empirical performance for many tasks. This work shows that a large class of random forests with general split directions also achieve minimax optimal rates in arbitrary dimension. This class includes STIT forests, a generalization of Mondrian forests to arbitrary split directions, and random forests derived from Poisson hyperplane tessellations. These are the first results showing that random forest variants with oblique splits can obtain minimax optimality in arbitrary dimension. Our proof technique relies on the novel application of the theory of stationary random tessellations in stochastic geometry to statistical learning theory.},
  archive      = {J_JMLR},
  author       = {Eliza O&#39;Reilly and Ngoc Mai Tran},
  journal      = {Journal of Machine Learning Research},
  number       = {89},
  pages        = {1-32},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Minimax rates for high-dimensional random tessellation forests},
  url          = {https://jmlr.org/papers/v25/22-0673.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonparametric estimation of non-crossing quantile regression
process with deep ReQU neural networks. <em>JMLR</em>, <em>25</em>(88),
1–75. (<a href="https://jmlr.org/papers/v25/22-0488.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a penalized nonparametric approach to estimating the quantile regression process (QRP) in a nonseparable model using rectifier quadratic unit (ReQU) activated deep neural networks and introduce a novel penalty function to enforce non-crossing of quantile regression curves. We establish the non-asymptotic excess risk bounds for the estimated QRP and derive the mean integrated squared error for the estimated QRP under mild smoothness and regularity conditions. To establish these non-asymptotic risk and estimation error bounds, we also develop a new error bound for approximating $C^s$ smooth functions with $s &gt;1$ and their derivatives using ReQU activated neural networks. This is a new approximation result for ReQU networks and is of independent interest and may be useful in other problems. Our numerical experiments demonstrate that the proposed method is competitive with or outperforms two existing methods, including methods using reproducing kernels and random forests for nonparametric quantile regression.},
  archive      = {J_JMLR},
  author       = {Guohao Shen and Yuling Jiao and Yuanyuan Lin and Joel L. Horowitz and Jian Huang},
  journal      = {Journal of Machine Learning Research},
  number       = {88},
  pages        = {1-75},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Nonparametric estimation of non-crossing quantile regression process with deep ReQU neural networks},
  url          = {https://jmlr.org/papers/v25/22-0488.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial meshing for general bayesian multivariate models.
<em>JMLR</em>, <em>25</em>(87), 1–49. (<a
href="https://jmlr.org/papers/v25/22-0083.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying spatial and/or temporal associations in multivariate geolocated data of different types is achievable via spatial random effects in a Bayesian hierarchical model, but severe computational bottlenecks arise when spatial dependence is encoded as a latent Gaussian process (GP) in the increasingly common large scale data settings on which we focus. The scenario worsens in non-Gaussian models because the reduced analytical tractability leads to additional hurdles to computational efficiency. In this article, we introduce Bayesian models of spatially referenced data in which the likelihood or the latent process (or both) are not Gaussian. First, we exploit the advantages of spatial processes built via directed acyclic graphs, in which case the spatial nodes enter the Bayesian hierarchy and lead to posterior sampling via routine Markov chain Monte Carlo (MCMC) methods. Second, motivated by the possible inefficiencies of popular gradient-based sampling approaches in the multivariate contexts on which we focus, we introduce the simplified manifold preconditioner adaptation (SiMPA) algorithm which uses second order information about the target but avoids expensive matrix operations. We demostrate the performance and efficiency improvements of our methods relative to alternatives in extensive synthetic and real world remote sensing and community ecology applications with large scale data at up to hundreds of thousands of spatial locations and up to tens of outcomes. Software for the proposed methods is part of R package meshed, available on CRAN.},
  archive      = {J_JMLR},
  author       = {Michele Peruzzi and David B. Dunson},
  journal      = {Journal of Machine Learning Research},
  number       = {87},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Spatial meshing for general bayesian multivariate models},
  url          = {https://jmlr.org/papers/v25/22-0083.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semi-parametric estimation of personalized dose-response
function using instrumental variables. <em>JMLR</em>, <em>25</em>(86),
1–38. (<a href="https://jmlr.org/papers/v25/21-1181.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the application of instrumental variable analysis that conducts causal inference in the presence of unmeasured confounding, invalid instrumental variables and weak instrumental variables often exist which complicate the analysis. In this paper, we propose a model-free dimension reduction procedure to select the invalid instrumental variables and refine them into lower-dimensional linear combinations. The procedure also combines the weak instrumental variables into a few stronger instrumental variables that best condense their information. We then introduce the personalized dose-response function that incorporates the subject&#39;s personal characteristics into the conventional dose-response function, and use the reduced data from dimension reduction to propose a novel and easily implementable nonparametric estimator of this function. The proposed approach is suitable for both discrete and continuous treatment variables, and is robust to the dimensionality of data. Its effectiveness is illustrated by the simulation studies and the data analysis of ADNI-DoD study, where the causal relationship between depression and dementia is investigated.},
  archive      = {J_JMLR},
  author       = {Wei Luo and Yeying Zhu and Xuekui Zhang and Lin Lin},
  journal      = {Journal of Machine Learning Research},
  number       = {86},
  pages        = {1-38},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A semi-parametric estimation of personalized dose-response function using instrumental variables},
  url          = {https://jmlr.org/papers/v25/21-1181.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning non-gaussian graphical models via hessian scores
and triangular transport. <em>JMLR</em>, <em>25</em>(85), 1–46. (<a
href="https://jmlr.org/papers/v25/21-0022.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Undirected probabilistic graphical models represent the conditional dependencies, or Markov properties, of a collection of random variables. Knowing the sparsity of such a graphical model is valuable for modeling multivariate distributions and for efficiently performing inference. While the problem of learning graph structure from data has been studied extensively for certain parametric families of distributions, most existing methods fail to consistently recover the graph structure for non-Gaussian data. Here we propose an algorithm for learning the Markov structure of continuous and non-Gaussian distributions. To characterize conditional independence, we introduce a score based on integrated Hessian information from the joint log-density, and we prove that this score upper bounds the conditional mutual information for a general class of distributions. To compute the score, our algorithm SING estimates the density using a deterministic coupling, induced by a triangular transport map, and iteratively exploits sparse structure in the map to reveal sparsity in the graph. For certain non-Gaussian datasets, we show that our algorithm recovers the graph structure even with a biased approximation to the density. Among other examples, we apply SING to learn the dependencies between the states of a chaotic dynamical system with local interactions.},
  archive      = {J_JMLR},
  author       = {Ricardo Baptista and Youssef Marzouk and Rebecca Morrison and Olivier Zahm},
  journal      = {Journal of Machine Learning Research},
  number       = {85},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learning non-gaussian graphical models via hessian scores and triangular transport},
  url          = {https://jmlr.org/papers/v25/21-0022.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the learnability of out-of-distribution detection.
<em>JMLR</em>, <em>25</em>(84), 1–83. (<a
href="https://jmlr.org/papers/v25/23-1257.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised learning aims to train a classifier under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms, and corresponding learning theory is still an open problem. To study the generalization of OOD detection, this paper investigates the probably approximately correct (PAC) learning theory of OOD detection that fits the commonly used evaluation metrics in the literature. First, we find a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we find that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufficient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we offer theoretical support for representative OOD detection works based on our OOD theory.},
  archive      = {J_JMLR},
  author       = {Zhen Fang and Yixuan Li and Feng Liu and Bo Han and Jie Lu},
  journal      = {Journal of Machine Learning Research},
  number       = {84},
  pages        = {1-83},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the learnability of out-of-distribution detection},
  url          = {https://jmlr.org/papers/v25/23-1257.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Win: Weight-decay-integrated nesterov acceleration for
faster network training. <em>JMLR</em>, <em>25</em>(83), 1–74. (<a
href="https://jmlr.org/papers/v25/23-1073.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training deep networks on large-scale datasets is computationally challenging. This work explores the problem of “how to accelerate adaptive gradient algorithms in a general manner&quot;, and proposes an effective Weight-decay-Integrated Nesterov acceleration (Win) to accelerate adaptive algorithms. Taking AdamW and Adam as examples, per iteration, we construct a dynamical loss that combines the vanilla training loss and a dynamic regularizer inspired by proximal point method, and respectively minimize the first- and second-order Taylor approximations of dynamical loss to update variable. This yields our Win acceleration that uses a conservative step and an aggressive step to update, and linearly combines these two updates for acceleration. Next, we extend Win into Win2 which uses multiple aggressive update steps for faster convergence. Then we apply Win and Win2 to the popular LAMB and SGD optimizers. Our transparent derivation could provide insights for other accelerated methods and their integration into adaptive algorithms. Besides, we theoretically justify the faster convergence of Win- and Win2-accelerated AdamW, Adam and LAMB to their non-accelerated counterparts. Experimental results demonstrates the faster convergence speed and superior performance of our Win- and Win2-accelerated AdamW, Adam, LAMB and SGD over their vanilla counterparts on vision classification and language modeling tasks.},
  archive      = {J_JMLR},
  author       = {Pan Zhou and Xingyu Xie and Zhouchen Lin and Kim-Chuan Toh and Shuicheng Yan},
  journal      = {Journal of Machine Learning Research},
  number       = {83},
  pages        = {1-74},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Win: Weight-decay-integrated nesterov acceleration for faster network training},
  url          = {https://jmlr.org/papers/v25/23-1073.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the eigenvalue decay rates of a class of neural-network
related kernel functions defined on general domains. <em>JMLR</em>,
<em>25</em>(82), 1–47. (<a
href="https://jmlr.org/papers/v25/23-0866.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we provide a strategy to determine the eigenvalue decay rate (EDR) of a large class of kernel functions defined on a general domain rather than $\mathbb{S}^{d}$. This class of kernel functions include but are not limited to the neural tangent kernel associated with neural networks with different depths and various activation functions. After proving that the dynamics of training the wide neural networks uniformly approximated that of the neural tangent kernel regression on general domains, we can further illustrate the minimax optimality of the wide neural network provided that the underground truth function $f\in [\mathcal H_{\mathrm{NTK}}]^{s}$, an interpolation space associated with the RKHS $\mathcal{H}_{\mathrm{NTK}}$ of NTK. We also showed that the overfitted neural network can not generalize well. We believe our approach for determining the EDR of kernels might be also of independent interests.},
  archive      = {J_JMLR},
  author       = {Yicheng Li and Zixiong Yu and Guhan Chen and Qian Lin},
  journal      = {Journal of Machine Learning Research},
  number       = {82},
  pages        = {1-47},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the eigenvalue decay rates of a class of neural-network related kernel functions defined on general domains},
  url          = {https://jmlr.org/papers/v25/23-0866.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tight convergence rate bounds for optimization under power
law spectral conditions. <em>JMLR</em>, <em>25</em>(81), 1–78. (<a
href="https://jmlr.org/papers/v25/23-0698.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance of optimization on quadratic problems sensitively depends on the low-lying part of the spectrum. For large (effectively infinite-dimensional) problems, this part of the spectrum can often be naturally represented or approximated by power law distributions, resulting in power law convergence rates for iterative solutions of these problems by gradient-based algorithms. In this paper, we propose a new spectral condition providing tighter upper bounds for problems with power law optimization trajectories. We use this condition to build a complete picture of upper and lower bounds for a wide range of optimization algorithms - Gradient Descent, Steepest Descent, Heavy Ball, and Conjugate Gradients - with an emphasis on the underlying schedules of learning rate and momentum. In particular, we demonstrate how an optimally accelerated method, its schedule, and convergence upper bound can be obtained in a unified manner for a given shape of the spectrum. Also, we provide first proofs of tight lower bounds for convergence rates of Steepest Descent and Conjugate Gradients under spectral power laws with general exponents. Our experiments show that the obtained convergence bounds and acceleration strategies are not only relevant for exactly quadratic optimization problems, but also fairly accurate when applied to the training of neural networks.},
  archive      = {J_JMLR},
  author       = {Maksim Velikanov and Dmitry Yarotsky},
  journal      = {Journal of Machine Learning Research},
  number       = {81},
  pages        = {1-78},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Tight convergence rate bounds for optimization under power law spectral conditions},
  url          = {https://jmlr.org/papers/v25/23-0698.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ptwt - the PyTorch wavelet toolbox. <em>JMLR</em>,
<em>25</em>(80), 1–7. (<a
href="https://jmlr.org/papers/v25/23-0636.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast wavelet transform is an essential workhorse in signal processing. Wavelets are local in the spatial- or temporal- and the frequency-domain. This property enables frequency domain analysis while preserving some spatiotemporal information. Until recently, wavelets rarely appeared in the machine learning literature. We provide the PyTorch Wavelet Toolbox to make wavelet methods more accessible to the deep learning community. Our PyTorch Wavelet Toolbox is well documented. A pip package is installable with `pip install ptwt`.},
  archive      = {J_JMLR},
  author       = {Moritz Wolter and Felix Blanke and Jochen Garcke and Charles Tapley Hoyt},
  journal      = {Journal of Machine Learning Research},
  number       = {80},
  pages        = {1-7},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Ptwt - the PyTorch wavelet toolbox},
  url          = {https://jmlr.org/papers/v25/23-0636.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Choosing the number of topics in LDA models – a monte carlo
comparison of selection criteria. <em>JMLR</em>, <em>25</em>(79), 1–30.
(<a href="https://jmlr.org/papers/v25/23-0188.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting the number of topics in Latent Dirichlet Allocation (LDA) models is considered to be a difficult task, for which various approaches have been proposed. In this paper the performance of the recently developed singular Bayesian information criterion (sBIC) is evaluated and compared to the performance of alternative model selection criteria. The sBIC is a generalization of the standard BIC that can be applied to singular statistical models. The comparison is based on Monte Carlo simulations and carried out for several alternative settings, varying with respect to the number of topics, the number of documents and the size of documents in the corpora. Performance is measured using different criteria which take into account the correct number of topics, but also whether the relevant topics from the considered data generation processes (DGPs) are revealed. Practical recommendations for LDA model selection in applications are derived.},
  archive      = {J_JMLR},
  author       = {Victor Bystrov and Viktoriia Naboka-Krell and Anna Staszewska-Bystrova and Peter Winker},
  journal      = {Journal of Machine Learning Research},
  number       = {79},
  pages        = {1-30},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Choosing the number of topics in LDA models – a monte carlo comparison of selection criteria},
  url          = {https://jmlr.org/papers/v25/23-0188.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Functional directed acyclic graphs. <em>JMLR</em>,
<em>25</em>(78), 1–48. (<a
href="https://jmlr.org/papers/v25/22-1038.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce a new method to estimate a directed acyclic graph (DAG) from multivariate functional data. We build on the notion of faithfulness that relates a DAG with a set of conditional independences among the random functions. We develop two linear operators, the conditional covariance operator and the partial correlation operator, to characterize and evaluate the conditional independence. Based on these operators, we adapt and extend the PC-algorithm to estimate the functional directed graph, so that the computation time depends on the sparsity rather than the full size of the graph. We study the asymptotic properties of the two operators, derive their uniform convergence rates, and establish the uniform consistency of the estimated graph, all of which are obtained while allowing the graph size to diverge to infinity with the sample size. We demonstrate the efficacy of our method through both simulations and an application to a time-course proteomic dataset.},
  archive      = {J_JMLR},
  author       = {Kuang-Yao Lee and Lexin Li and Bing Li},
  journal      = {Journal of Machine Learning Research},
  number       = {78},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Functional directed acyclic graphs},
  url          = {https://jmlr.org/papers/v25/22-1038.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unlabeled principal component analysis and matrix
completion. <em>JMLR</em>, <em>25</em>(77), 1–38. (<a
href="https://jmlr.org/papers/v25/22-0816.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce robust principal component analysis from a data matrix in which the entries of its columns have been corrupted by permutations, termed Unlabeled Principal Component Analysis (UPCA). Using algebraic geometry, we establish that UPCA is a well-defined algebraic problem since we prove that the only matrices of minimal rank that agree with the given data are row-permutations of the ground-truth matrix, arising as the unique solutions of a polynomial system of equations. Further, we propose an efficient two-stage algorithmic pipeline for UPCA suitable for the practically relevant case where only a fraction of the data have been permuted. Stage-I employs outlier-robust PCA methods to estimate the ground-truth column-space. Equipped with the column-space, Stage-II applies recent methods for unlabeled sensing to restore the permuted data. Allowing for missing entries on top of permutations in UPCA leads to the problem of unlabeled matrix completion, for which we derive theory and algorithms of similar flavor. Experiments on synthetic data, face images, educational and medical records reveal the potential of our algorithms for applications such as data privatization and record linkage.},
  archive      = {J_JMLR},
  author       = {Yunzhen Yao and Liangzu Peng and Manolis C. Tsakiris},
  journal      = {Journal of Machine Learning Research},
  number       = {77},
  pages        = {1-38},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Unlabeled principal component analysis and matrix completion},
  url          = {https://jmlr.org/papers/v25/22-0816.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed estimation on semi-supervised generalized linear
model. <em>JMLR</em>, <em>25</em>(76), 1–41. (<a
href="https://jmlr.org/papers/v25/22-0670.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning is devoted to using unlabeled data to improve the performance of machine learning algorithms. In this paper, we study the semi-supervised generalized linear model (GLM) in the distributed setup. In the cases of single or multiple machines containing unlabeled data, we propose two distributed semi-supervised algorithms based on the distributed approximate Newton method. When the labeled local sample size is small, our algorithms still give a consistent estimation, while fully supervised methods fail to converge. Moreover, we theoretically prove that the convergence rate is greatly improved when sufficient unlabeled data exists. Therefore, the proposed method requires much fewer rounds of communications to achieve the optimal rate than its fully-supervised counterpart. In the case of the linear model, we prove the rate lower bound after one round of communication, which shows that rate improvement is essential. Finally, several simulation analyses and real data studies are provided to demonstrate the effectiveness of our method.},
  archive      = {J_JMLR},
  author       = {Jiyuan Tu and Weidong Liu and Xiaojun Mao},
  journal      = {Journal of Machine Learning Research},
  number       = {76},
  pages        = {1-41},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Distributed estimation on semi-supervised generalized linear model},
  url          = {https://jmlr.org/papers/v25/22-0670.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards explainable evaluation metrics for machine
translation. <em>JMLR</em>, <em>25</em>(75), 1–49. (<a
href="https://jmlr.org/papers/v25/22-0416.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike classical lexical overlap metrics such as BLEU, most current evaluation metrics for machine translation (for example, COMET or BERTScore) are based on black-box large language models. They often achieve strong correlations with human judgments, but recent research indicates that the lower-quality classical metrics remain dominant, one of the potential reasons being that their decision processes are more transparent. To foster more widespread acceptance of novel high-quality metrics, explainability thus becomes crucial. In this concept paper, we identify key properties as well as key goals of explainable machine translation metrics and provide a comprehensive synthesis of recent techniques, relating them to our established goals and properties. In this context, we also discuss the latest state-of-the-art approaches to explainable metrics based on generative models such as ChatGPT and GPT4. Finally, we contribute a vision of next-generation approaches, including natural language explanations. We hope that our work can help catalyze and guide future research on explainable evaluation metrics and, mediately, also contribute to better and more transparent machine translation systems.},
  archive      = {J_JMLR},
  author       = {Christoph Leiter and Piyawat Lertvittayakumjorn and Marina Fomicheva and Wei Zhao and Yang Gao and Steffen Eger},
  journal      = {Journal of Machine Learning Research},
  number       = {75},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Towards explainable evaluation metrics for machine translation},
  url          = {https://jmlr.org/papers/v25/22-0416.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentially private methods for managing model
uncertainty in linear regression. <em>JMLR</em>, <em>25</em>(74), 1–44.
(<a href="https://jmlr.org/papers/v25/21-1536.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose differentially private methods for hypothesis testing, model averaging, and model selection for normal linear models. We propose Bayesian methods based on mixtures of $g$-priors and non-Bayesian methods based on likelihood-ratio statistics and information criteria. The procedures are asymptotically consistent and straightforward to implement with existing software. We focus on practical issues such as adjusting critical values so that hypothesis tests have adequate type I error rates and quantifying the uncertainty introduced by the privacy-ensuring mechanisms.},
  archive      = {J_JMLR},
  author       = {Víctor Peña and Andrés F. Barrientos},
  journal      = {Journal of Machine Learning Research},
  number       = {74},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Differentially private methods for managing model uncertainty in linear regression},
  url          = {https://jmlr.org/papers/v25/21-1536.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data summarization via bilevel optimization. <em>JMLR</em>,
<em>25</em>(73), 1–53. (<a
href="https://jmlr.org/papers/v25/21-1132.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing availability of massive data sets poses various challenges for machine learning. Prominent among these is learning models under hardware or human resource constraints. In such resource-constrained settings, a simple yet powerful approach is operating on small subsets of the data. Coresets are weighted subsets of the data that provide approximation guarantees for the optimization objective. However, existing coreset constructions are highly model-specific and are limited to simple models such as linear regression, logistic regression, and k-means. In this work, we propose a generic coreset construction framework that formulates the coreset selection as a cardinality-constrained bilevel optimization problem. In contrast to existing approaches, our framework does not require model-specific adaptations and applies to any twice differentiable model, including neural networks. We show the effectiveness of our framework for a wide range of models in various settings, including training non-convex models online and batch active learning.},
  archive      = {J_JMLR},
  author       = {Zalán Borsos and Mojmír Mutný and Marco Tagliasacchi and Andreas Krause},
  journal      = {Journal of Machine Learning Research},
  number       = {73},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Data summarization via bilevel optimization},
  url          = {https://jmlr.org/papers/v25/21-1132.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pareto smoothed importance sampling. <em>JMLR</em>,
<em>25</em>(72), 1–58. (<a
href="https://jmlr.org/papers/v25/19-556.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Importance weighting is a general way to adjust Monte Carlo integration to account for draws from the wrong distribution, but the resulting estimate can be highly variable when the importance ratios have a heavy right tail. This routinely occurs when there are aspects of the target distribution that are not well captured by the approximating distribution, in which case more stable estimates can be obtained by modifying extreme importance ratios. We present a new method for stabilizing importance weights using a generalized Pareto distribution fit to the upper tail of the distribution of the simulated importance ratios. The method, which empirically performs better than existing methods for stabilizing importance sampling estimates, includes stabilized effective sample size estimates, Monte Carlo error estimates, and convergence diagnostics. The presented Pareto $\hat{k}$ finite sample convergence rate diagnostic is useful for any Monte Carlo estimator.},
  archive      = {J_JMLR},
  author       = {Aki Vehtari and Daniel Simpson and Andrew Gelman and Yuling Yao and Jonah Gabry},
  journal      = {Journal of Machine Learning Research},
  number       = {72},
  pages        = {1-58},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Pareto smoothed importance sampling},
  url          = {https://jmlr.org/papers/v25/19-556.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Policy gradient methods in the presence of symmetries and
state abstractions. <em>JMLR</em>, <em>25</em>(71), 1–57. (<a
href="https://jmlr.org/papers/v25/23-1415.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) on high-dimensional and complex problems relies on abstraction for improved efficiency and generalization. In this paper, we study abstraction in the continuous-control setting, and extend the definition of Markov decision process (MDP) homomorphisms to the setting of continuous state and action spaces. We derive a policy gradient theorem on the abstract MDP for both stochastic and deterministic policies. Our policy gradient results allow for leveraging approximate symmetries of the environment for policy optimization. Based on these theorems, we propose a family of actor-critic algorithms that are able to learn the policy and the MDP homomorphism map simultaneously, using the lax bisimulation metric. Finally, we introduce a series of environments with continuous symmetries to further demonstrate the ability of our algorithm for action abstraction in the presence of such symmetries. We demonstrate the effectiveness of our method on our environments, as well as on challenging visual control tasks from the DeepMind Control Suite. Our method&#39;s ability to utilize MDP homomorphisms for representation learning leads to improved performance, and the visualizations of the latent space clearly demonstrate the structure of the learned abstraction.},
  archive      = {J_JMLR},
  author       = {Prakash Panangaden and Sahand Rezaei-Shoshtari and Rosie Zhao and David Meger and Doina Precup},
  journal      = {Journal of Machine Learning Research},
  number       = {71},
  pages        = {1-57},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Policy gradient methods in the presence of symmetries and state abstractions},
  url          = {https://jmlr.org/papers/v25/23-1415.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scaling instruction-finetuned language models.
<em>JMLR</em>, <em>25</em>(70), 1–53. (<a
href="https://jmlr.org/papers/v25/23-0870.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finetuning language models on a collection of datasets phrased as instructions has been shown to improve model performance and generalization to unseen tasks. In this paper we explore instruction finetuning with a particular focus on (1) scaling the number of tasks, (2) scaling the model size, and (3) finetuning on chain-of-thought data. We find that instruction finetuning with the above aspects dramatically improves performance on a variety of model classes (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT), and evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation, RealToxicityPrompts). For instance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PaLM 540B by a large margin (+9.4% on average). Flan-PaLM 540B achieves state-of-the-art performance on several benchmarks (at time of release), such as 75.2% on five-shot MMLU. We also publicly release Flan-T5 checkpoints,1 which achieve strong few-shot performance even compared to much larger models, such as PaLM 62B. Overall, instruction finetuning is a general method for improving the performance and usability of pretrained language models.},
  archive      = {J_JMLR},
  author       = {Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
  journal      = {Journal of Machine Learning Research},
  number       = {70},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Scaling instruction-finetuned language models},
  url          = {https://jmlr.org/papers/v25/23-0870.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tangential wasserstein projections. <em>JMLR</em>,
<em>25</em>(69), 1–41. (<a
href="https://jmlr.org/papers/v25/23-0708.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a notion of projections between sets of probability measures using the geometric properties of the $2$-Wasserstein space. In contrast to existing methods, it is designed for multivariate probability measures that need not be regular, and is computationally efficient to implement via regression. The idea is to work on tangent cones of the Wasserstein space using generalized geodesics. Its structure and computational properties make the method applicable in a variety of settings where probability measures need not be regular, from causal inference to the analysis of object data. An application to estimating causal effects yields a generalization of the synthetic controls method for systems with general heterogeneity described via multivariate probability measures.},
  archive      = {J_JMLR},
  author       = {Florian Gunsilius and Meng Hsuan Hsieh and Myung Jin Lee},
  journal      = {Journal of Machine Learning Research},
  number       = {69},
  pages        = {1-41},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Tangential wasserstein projections},
  url          = {https://jmlr.org/papers/v25/23-0708.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learnability of linear port-hamiltonian systems.
<em>JMLR</em>, <em>25</em>(68), 1–56. (<a
href="https://jmlr.org/papers/v25/23-0450.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A complete structure-preserving learning scheme for single-input/single-output (SISO) linear port-Hamiltonian systems is proposed. The construction is based on the solution, when possible, of the unique identification problem for these systems, in ways that reveal fundamental relationships between classical notions in control theory and crucial properties in the machine learning context, like structure-preservation and expressive power. In the canonical case, it is shown that, {up to initializations,} the set of uniquely identified systems can be explicitly characterized as a smooth manifold endowed with global Euclidean coordinates, which allows concluding that the parameter complexity necessary for the replication of the dynamics is only $\mathcal{O}(n)$ and not $\mathcal{O}(n^2)$, as suggested by the standard parametrization of these systems. Furthermore, it is shown that linear port-Hamiltonian systems can be learned while remaining agnostic about the dimension of the underlying data-generating system. Numerical experiments show that this methodology can be used to efficiently estimate linear port-Hamiltonian systems out of input-output realizations, making the contributions in this paper the first example of a structure-preserving machine learning paradigm for linear port-Hamiltonian systems based on explicit representations of this model category.},
  archive      = {J_JMLR},
  author       = {Juan-Pablo Ortega and Daiying Yin},
  journal      = {Journal of Machine Learning Research},
  number       = {68},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Learnability of linear port-hamiltonian systems},
  url          = {https://jmlr.org/papers/v25/23-0450.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Off-policy action anticipation in multi-agent reinforcement
learning. <em>JMLR</em>, <em>25</em>(67), 1–31. (<a
href="https://jmlr.org/papers/v25/23-0413.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning anticipation in Multi-Agent Reinforcement Learning (MARL) is a reasoning paradigm where agents anticipate the learning steps of other agents to improve cooperation among themselves. As MARL uses gradient-based optimization, learning anticipation requires using Higher-Order Gradients (HOG), with so-called HOG methods. Existing HOG methods are based on policy parameter anticipation, i.e., agents anticipate the changes in policy parameters of other agents. Currently, however, these existing HOG methods have only been developed for differentiable games or games with small state spaces. In this work, we demonstrate that in the case of non-differentiable games with large state spaces, existing HOG methods do not perform well and are inefficient due to their inherent limitations related to policy parameter anticipation and multiple sampling stages. To overcome these problems, we propose Off-Policy Action Anticipation (OffPA2), a novel framework that approaches learning anticipation through action anticipation, i.e., agents anticipate the changes in actions of other agents, via off-policy sampling. We theoretically analyze our proposed OffPA2 and employ it to develop multiple HOG methods that are applicable to non-differentiable games with large state spaces. We conduct a large set of experiments and illustrate that our proposed HOG methods outperform the existing ones regarding efficiency and performance.},
  archive      = {J_JMLR},
  author       = {Ariyan Bighashdel and Daan de Geus and Pavol Jancura and Gijs Dubbelman},
  journal      = {Journal of Machine Learning Research},
  number       = {67},
  pages        = {1-31},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Off-policy action anticipation in multi-agent reinforcement learning},
  url          = {https://jmlr.org/papers/v25/23-0413.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On unbiased estimation for partially observed diffusions.
<em>JMLR</em>, <em>25</em>(66), 1–66. (<a
href="https://jmlr.org/papers/v25/23-0347.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of diffusion processes with finite-dimensional parameters and partially observed at discrete time instances. We propose a methodology to unbiasedly estimate the expectation of a given functional of the diffusion process conditional on parameters and data. When these unbiased estimators with appropriately chosen functionals are employed within an expectation-maximization algorithm or a stochastic gradient method, this enables statistical inference using the maximum likelihood or Bayesian framework. Compared to existing approaches, the use of our unbiased estimators allows one to remove any time-discretization bias and Markov chain Monte Carlo burn-in bias. Central to our methodology is a novel and natural combination of multilevel randomization schemes and unbiased Markov chain Monte Carlo methods, and the development of new couplings of multiple conditional particle filters. We establish under assumptions that our estimators are unbiased and have finite variance. We illustrate various aspects of our method on an Ornstein--Uhlenbeck model, a logistic diffusion model for population dynamics, and a neural network model for grid cells.},
  archive      = {J_JMLR},
  author       = {Jeremy Heng and Jeremie Houssineau and Ajay Jasra},
  journal      = {Journal of Machine Learning Research},
  number       = {66},
  pages        = {1-66},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On unbiased estimation for partially observed diffusions},
  url          = {https://jmlr.org/papers/v25/23-0347.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving lipschitz-constrained neural networks by learning
activation functions. <em>JMLR</em>, <em>25</em>(65), 1–30. (<a
href="https://jmlr.org/papers/v25/22-1347.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lipschitz-constrained neural networks have several advantages over unconstrained ones and can be applied to a variety of problems, making them a topic of attention in the deep learning community. Unfortunately, it has been shown both theoretically and empirically that they perform poorly when equipped with ReLU activation functions. By contrast, neural networks with learnable 1-Lipschitz linear splines are known to be more expressive. In this paper, we show that such networks correspond to global optima of a constrained functional optimization problem that consists of the training of a neural network composed of 1-Lipschitz linear layers and 1-Lipschitz freeform activation functions with second-order total-variation regularization. Further, we propose an efficient method to train these neural networks. Our numerical experiments show that our trained networks compare favorably with existing 1-Lipschitz neural architectures.},
  archive      = {J_JMLR},
  author       = {Stanislas Ducotterd and Alexis Goujon and Pakshal Bohra and Dimitris Perdios and Sebastian Neumayer and Michael Unser},
  journal      = {Journal of Machine Learning Research},
  number       = {65},
  pages        = {1-30},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Improving lipschitz-constrained neural networks by learning activation functions},
  url          = {https://jmlr.org/papers/v25/22-1347.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mathematical framework for online social media auditing.
<em>JMLR</em>, <em>25</em>(64), 1–40. (<a
href="https://jmlr.org/papers/v25/22-1112.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media platforms (SMPs) leverage algorithmic filtering (AF) as a means of selecting the content that constitutes a user&#39;s feed with the aim of maximizing their rewards. Selectively choosing the contents to be shown on the user&#39;s feed may yield a certain extent of influence, either minor or major, on the user&#39;s decision-making, compared to what it would have been under a natural/fair content selection. As we have witnessed over the past decade, algorithmic filtering can cause detrimental side effects, ranging from biasing individual decisions to shaping those of society as a whole, for example, diverting users&#39; attention from whether to get the COVID-19 vaccine or inducing the public to choose a presidential candidate. The government&#39;s constant attempts to regulate the adverse effects of AF are often complicated, due to bureaucracy, legal affairs, and financial considerations. On the other hand SMPs seek to monitor their own algorithmic activities to avoid being fined for exceeding the allowable threshold. In this paper, we mathematically formalize this framework and utilize it to construct a data-driven statistical auditing procedure to regulate AF from deflecting users&#39; beliefs over time, along with sample complexity guarantees. This state-of-the-art algorithm can be used either by authorities acting as external regulators or by SMPs for self-auditing.},
  archive      = {J_JMLR},
  author       = {Wasim Huleihel and Yehonathan Refael},
  journal      = {Journal of Machine Learning Research},
  number       = {64},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Mathematical framework for online social media auditing},
  url          = {https://jmlr.org/papers/v25/22-1112.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An embedding framework for the design and analysis of
consistent polyhedral surrogates. <em>JMLR</em>, <em>25</em>(63), 1–60.
(<a href="https://jmlr.org/papers/v25/22-0743.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We formalize and study the natural approach of designing convex surrogate loss functions via embeddings, for discrete problems such as classification, ranking, or structured prediction. In this approach, one embeds each of the finitely many predictions (e.g. rankings) as a point in $\mathbb{R}^d$, assigns the original loss values to these points, and “convexifies” the loss in some way to obtain a surrogate. We establish a strong connection between this approach and polyhedral (piecewise-linear convex) surrogate losses: every discrete loss is embedded by some polyhedral loss, and every polyhedral loss embeds some discrete loss. Moreover, an embedding gives rise to a consistent link function as well as linear surrogate regret bounds. Our results are constructive, as we illustrate with several examples. In particular, our framework gives succinct proofs of consistency or inconsistency for existing polyhedral surrogates, and for inconsistent surrogates, it further reveals the discrete losses for which these surrogates are consistent. We go on to show additional structure of embeddings, such as the equivalence of embedding and matching Bayes risks, and the equivalence of various notions of non-redudancy. Using these results, we establish that indirect elicitation, a necessary condition for consistency, is also sufficient when working with polyhedral surrogates.},
  archive      = {J_JMLR},
  author       = {Jessie Finocchiaro and Rafael M. Frongillo and Bo Waggoner},
  journal      = {Journal of Machine Learning Research},
  number       = {63},
  pages        = {1-60},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {An embedding framework for the design and analysis of consistent polyhedral surrogates},
  url          = {https://jmlr.org/papers/v25/22-0743.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Low-rank variational bayes correction to the laplace method.
<em>JMLR</em>, <em>25</em>(62), 1–25. (<a
href="https://jmlr.org/papers/v25/21-1405.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate inference methods like the Laplace method, Laplace approximations and variational methods, amongst others, are popular methods when exact inference is not feasible due to the complexity of the model or the abundance of data. In this paper we propose a hybrid approximate method called Low-Rank Variational Bayes correction (VBC), that uses the Laplace method and subsequently a Variational Bayes correction in a lower dimension, to the joint posterior mean. The cost is essentially that of the Laplace method which ensures scalability of the method, in both model complexity and data size. Models with fixed and unknown hyperparameters are considered, for simulated and real examples, for small and large data sets.},
  archive      = {J_JMLR},
  author       = {Janet van Niekerk and Haavard Rue},
  journal      = {Journal of Machine Learning Research},
  number       = {62},
  pages        = {1-25},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Low-rank variational bayes correction to the laplace method},
  url          = {https://jmlr.org/papers/v25/21-1405.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scaling the convex barrier with sparse dual algorithms.
<em>JMLR</em>, <em>25</em>(61), 1–51. (<a
href="https://jmlr.org/papers/v25/21-0076.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tight and efficient neural network bounding is crucial to the scaling of neural network verification systems. Many efficient bounding algorithms have been presented recently, but they are often too loose to verify more challenging properties. This is due to the weakness of the employed relaxation, which is usually a linear program of size linear in the number of neurons. While a tighter linear relaxation for piecewise-linear activations exists, it comes at the cost of exponentially many constraints and currently lacks an efficient customized solver. We alleviate this deficiency by presenting two novel dual algorithms: one operates a subgradient method on a small active set of dual variables, the other exploits the sparsity of Frank-Wolfe type optimizers to incur only a linear memory cost. Both methods recover the strengths of the new relaxation: tightness and a linear separation oracle. At the same time, they share the benefits of previous dual approaches for weaker relaxations: massive parallelism, GPU implementation, low cost per iteration and valid bounds at any time. As a consequence, we can obtain better bounds than off-the-shelf solvers in only a fraction of their running time, attaining significant formal verification speed-ups.},
  archive      = {J_JMLR},
  author       = {Alessandro De Palma and Harkirat Singh Behl and Rudy Bunel and Philip H.S. Torr and M. Pawan Kumar},
  journal      = {Journal of Machine Learning Research},
  number       = {61},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Scaling the convex barrier with sparse dual algorithms},
  url          = {https://jmlr.org/papers/v25/21-0076.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causal-learn: Causal discovery in python. <em>JMLR</em>,
<em>25</em>(60), 1–8. (<a
href="https://jmlr.org/papers/v25/23-0970.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery aims at revealing causal relations from observational data, which is a fundamental task in science and engineering. We describe causal-learn, an open-source Python library for causal discovery. This library focuses on bringing a comprehensive collection of causal discovery methods to both practitioners and researchers. It provides easy-to-use APIs for non-specialists, modular building blocks for developers, detailed documentation for learners, and comprehensive methods for all. Different from previous packages in R or Java, causal-learn is fully developed in Python, which could be more in tune with the recent preference shift in programming languages within related communities. The library is available at https://github.com/py-why/causal-learn.},
  archive      = {J_JMLR},
  author       = {Yujia Zheng and Biwei Huang and Wei Chen and Joseph Ramsey and Mingming Gong and Ruichu Cai and Shohei Shimizu and Peter Spirtes and Kun Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {60},
  pages        = {1-8},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Causal-learn: Causal discovery in python},
  url          = {https://jmlr.org/papers/v25/23-0970.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decomposed linear dynamical systems (dLDS) for learning the
latent components of neural dynamics. <em>JMLR</em>, <em>25</em>(59),
1–44. (<a href="https://jmlr.org/papers/v25/23-0777.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning interpretable representations of neural dynamics at a population level is a crucial first step to understanding how observed neural activity relates to perception and behavior. Models of neural dynamics often focus on either low-dimensional projections of neural activity or on learning dynamical systems that explicitly relate to the neural state over time. We discuss how these two approaches are interrelated by considering dynamical systems as representative of flows on a low-dimensional manifold. Building on this concept, we propose a new decomposed dynamical system model that represents complex non-stationary and nonlinear dynamics of time series data as a sparse combination of simpler, more interpretable components. Our model is trained through a dictionary learning procedure, where we leverage recent results in tracking sparse vectors over time. The decomposed nature of the dynamics is more expressive than previous switched approaches for a given number of parameters and enables modeling of overlapping and non-stationary dynamics. In both continuous-time and discrete-time instructional examples, we demonstrate that our model effectively approximates the original system, learns efficient representations, and captures smooth transitions between dynamical modes. Furthermore, we highlight our model’s ability to efficiently capture and demix population dynamics generated from multiple independent subnetworks, a task that is computationally impractical for switched models. Finally, we apply our model to neural “full brain” recordings of C. elegans data, illustrating a diversity of dynamics that is obscured when classified into discrete states.},
  archive      = {J_JMLR},
  author       = {Noga Mudrik and Yenho Chen and Eva Yezerets and Christopher J. Rozell and Adam S. Charles},
  journal      = {Journal of Machine Learning Research},
  number       = {59},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Decomposed linear dynamical systems (dLDS) for learning the latent components of neural dynamics},
  url          = {https://jmlr.org/papers/v25/23-0777.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Existence and minimax theorems for adversarial surrogate
risks in binary classification. <em>JMLR</em>, <em>25</em>(58), 1–41.
(<a href="https://jmlr.org/papers/v25/23-0456.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove existence, minimax, and complementary slackness theorems for adversarial surrogate risks in binary classification. These results extend recent work that established analogous minimax and existence theorems for the adversarial classification risk. We show that such statements continue to hold for a very general class of surrogate losses; moreover, we remove some of the technical restrictions present in prior work. Our results provide an explanation for the phenomenon of transfer attacks and inform new directions in algorithm development.},
  archive      = {J_JMLR},
  author       = {Natalie S. Frank and Jonathan Niles-Weed},
  journal      = {Journal of Machine Learning Research},
  number       = {58},
  pages        = {1-41},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Existence and minimax theorems for adversarial surrogate risks in binary classification},
  url          = {https://jmlr.org/papers/v25/23-0456.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data thinning for convolution-closed distributions.
<em>JMLR</em>, <em>25</em>(57), 1–35. (<a
href="https://jmlr.org/papers/v25/23-0446.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose data thinning, an approach for splitting an observation into two or more independent parts that sum to the original observation, and that follow the same distribution as the original observation, up to a (known) scaling of a parameter. This very general proposal is applicable to any convolution-closed distribution, a class that includes the Gaussian, Poisson, negative binomial, gamma, and binomial distributions, among others. Data thinning has a number of applications to model selection, evaluation, and inference. For instance, cross-validation via data thinning provides an attractive alternative to the usual approach of cross-validation via sample splitting, especially in settings in which the latter is not applicable. In simulations and in an application to single-cell RNA-sequencing data, we show that data thinning can be used to validate the results of unsupervised learning approaches, such as k-means clustering and principal components analysis, for which traditional sample splitting is unattractive or unavailable.},
  archive      = {J_JMLR},
  author       = {Anna Neufeld and Ameer Dharamshi and Lucy L. Gao and Daniela Witten},
  journal      = {Journal of Machine Learning Research},
  number       = {57},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Data thinning for convolution-closed distributions},
  url          = {https://jmlr.org/papers/v25/23-0446.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A projected semismooth newton method for a class of
nonconvex composite programs with strong prox-regularity. <em>JMLR</em>,
<em>25</em>(56), 1–32. (<a
href="https://jmlr.org/papers/v25/23-0371.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to develop a Newton-type method to solve a class of nonconvex composite programs. In particular, the nonsmooth part is possibly nonconvex. To tackle the nonconvexity, we develop a notion of strong prox-regularity which is related to the singleton property and Lipschitz continuity of the associated proximal operator, and we verify it in various classes of functions, including weakly convex functions, indicator functions of proximally smooth sets, and two specific sphere-related nonconvex nonsmooth functions. In this case, the problem class we are concerned with covers smooth optimization problems on manifold and certain composite optimization problems on manifold. For the latter, the proposed algorithm is the first second-order type method. Combining with the semismoothness of the proximal operator, we design a projected semismooth Newton method to find a root of the natural residual induced by the proximal gradient method. Due to the possible nonconvexity of the feasible domain, an extra projection is added to the usual semismooth Newton step and new criteria are proposed for the switching between the projected semismooth Newton step and the proximal step. The global convergence is then established under the strong prox-regularity. Based on the BD regularity condition, we establish local superlinear convergence. Numerical experiments demonstrate the effectiveness of our proposed method compared with state-of-the-art ones.},
  archive      = {J_JMLR},
  author       = {Jiang Hu and Kangkang Deng and Jiayuan Wu and Quanzheng Li},
  journal      = {Journal of Machine Learning Research},
  number       = {56},
  pages        = {1-32},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A projected semismooth newton method for a class of nonconvex composite programs with strong prox-regularity},
  url          = {https://jmlr.org/papers/v25/23-0371.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revisiting RIP guarantees for sketching operators on mixture
models. <em>JMLR</em>, <em>25</em>(55), 1–68. (<a
href="https://jmlr.org/papers/v25/23-0044.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of sketching for compressive mixture modeling, we revisit existing proofs of the Restricted Isometry Property of sketching operators with respect to certain mixtures models. After examining the shortcomings of existing guarantees, we propose an alternative analysis that circumvents the need to assume importance sampling when drawing random Fourier features to build random sketching operators. Our analysis is based on new deterministic bounds on the restricted isometry constant that depend solely on the set of frequencies used to define the sketching operator; then we leverage these bounds to establish concentration inequalities for random sketching operators that lead to the desired RIP guarantees. Our analysis also opens the door to theoretical guarantees for structured sketching with frequencies associated to fast random linear operators.},
  archive      = {J_JMLR},
  author       = {Ayoub Belhadji and Rémi Gribonval},
  journal      = {Journal of Machine Learning Research},
  number       = {55},
  pages        = {1-68},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Revisiting RIP guarantees for sketching operators on mixture models},
  url          = {https://jmlr.org/papers/v25/23-0044.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Monotonic risk relationships under distribution shifts for
regularized risk minimization. <em>JMLR</em>, <em>25</em>(54), 1–37. (<a
href="https://jmlr.org/papers/v25/22-1197.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning systems are often applied to data that is drawn from a different distribution than the training distribution. Recent work has shown that for a variety of classification and signal reconstruction problems, the out-of-distribution performance is strongly linearly correlated with the in-distribution performance. If this relationship or more generally a monotonic one holds, it has important consequences. For example, it allows to optimize performance on one distribution as a proxy for performance on the other. In this paper, we study conditions under which a monotonic relationship between the performances of a model on two distributions is expected. We prove an exact asymptotic linear relation for squared error and a monotonic relation for misclassification error for ridge-regularized general linear models under covariate shift, as well as an approximate linear relation for linear inverse problems.},
  archive      = {J_JMLR},
  author       = {Daniel LeJeune and Jiayu Liu and Reinhard Heckel},
  journal      = {Journal of Machine Learning Research},
  number       = {54},
  pages        = {1-37},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Monotonic risk relationships under distribution shifts for regularized risk minimization},
  url          = {https://jmlr.org/papers/v25/22-1197.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polygonal unadjusted langevin algorithms: Creating stable
and efficient adaptive algorithms for neural networks. <em>JMLR</em>,
<em>25</em>(53), 1–52. (<a
href="https://jmlr.org/papers/v25/22-0796.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new class of Langevin-based algorithms, which overcomes many of the known shortcomings of popular adaptive optimizers that are currently used for the fine tuning of deep learning models. Its underpinning theory relies on recent advances of Euler-Krylov polygonal approximations for stochastic differential equations (SDEs) with monotone coefficients. As a result, it inherits the stability properties of tamed algorithms, while it addresses other known issues, e.g. vanishing gradients in deep learning. In particular, we provide a nonasymptotic analysis and full theoretical guarantees for the convergence properties of an algorithm of this novel class, which we named TH$\varepsilon$O POULA (or, simply, TheoPouLa). Finally, several experiments are presented with different types of deep learning models, which show the superior performance of TheoPouLa over many popular adaptive optimization algorithms.},
  archive      = {J_JMLR},
  author       = {Dong-Young Lim and Sotirios Sabanis},
  journal      = {Journal of Machine Learning Research},
  number       = {53},
  pages        = {1-52},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Polygonal unadjusted langevin algorithms: Creating stable and efficient adaptive algorithms for neural networks},
  url          = {https://jmlr.org/papers/v25/22-0796.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Axiomatic effect propagation in structural causal models.
<em>JMLR</em>, <em>25</em>(52), 1–71. (<a
href="https://jmlr.org/papers/v25/22-0285.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study effect propagation in a causal directed acyclic graph (DAG), with the goal of providing a flow-based decomposition of the effect (i.e., change in the outcome variable) as a result of changes in the source variables. We first compare various ideas on causality to quantify effect propagation, such as direct and indirect effects, path-specific effects, and degree of responsibility. We discuss the shortcomings of such approaches and propose a flow-based methodology, which we call recursive Shapley value (RSV). By considering a broader set of counterfactuals than existing methods, RSV obeys a unique adherence to four desirable flow-based axioms. Further, we provide a general path-based characterization of RSV for an arbitrary non-parametric structural equations model (SEM) defined on the underlying DAG. Interestingly, for the special class of linear SEMs, RSV exhibits a simple and tractable characterization (and hence, computation), which recovers the classical method of path coefficients and is equivalent to path-specific effects. For non-parametric SEMs, we use our general characterization to develop an unbiased Monte-Carlo estimation procedure with an exponentially decaying sample complexity. We showcase the application of RSV on two challenging problems on causality (causal overdetermination and causal unfairness).},
  archive      = {J_JMLR},
  author       = {Raghav Singal and George Michailidis},
  journal      = {Journal of Machine Learning Research},
  number       = {52},
  pages        = {1-71},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Axiomatic effect propagation in structural causal models},
  url          = {https://jmlr.org/papers/v25/22-0285.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal first-order algorithms as a function of
inequalities. <em>JMLR</em>, <em>25</em>(51), 1–66. (<a
href="https://jmlr.org/papers/v25/21-1256.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a novel algorithm design methodology that finds the optimal algorithm as a function of inequalities. Specifically, we restrict convergence analyses of algorithms to use a prespecified subset of inequalities, rather than utilizing all true inequalities, and find the optimal algorithm subject to this restriction. This methodology allows us to design algorithms with certain desired characteristics. As concrete demonstrations of this methodology, we find new state-of-the-art accelerated first-order gradient methods using randomized coordinate updates and backtracking line searches.},
  archive      = {J_JMLR},
  author       = {Chanwoo Park and Ernest K. Ryu},
  journal      = {Journal of Machine Learning Research},
  number       = {51},
  pages        = {1-66},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal first-order algorithms as a function of inequalities},
  url          = {https://jmlr.org/papers/v25/21-1256.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Resource-efficient neural networks for embedded systems.
<em>JMLR</em>, <em>25</em>(50), 1–51. (<a
href="https://jmlr.org/papers/v25/18-566.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While machine learning is traditionally a resource intensive task, embedded systems, autonomous navigation, and the vision of the Internet of Things fuel the interest in resource-efficient approaches. These approaches aim for a carefully chosen trade-off between performance and resource consumption in terms of computation and energy. The development of such approaches is among the major challenges in current machine learning research and key to ensure a smooth transition of machine learning technology from a scientific environment with virtually unlimited computing resources into everyday&#39;s applications. In this article, we provide an overview of the current state of the art of machine learning techniques facilitating these real-world requirements. In particular, we focus on resource-efficient inference based on deep neural networks (DNNs), the predominant machine learning models of the past decade. We give a comprehensive overview of the vast literature that can be mainly split into three non-mutually exclusive categories: (i) quantized neural networks, (ii) network pruning, and (iii) structural efficiency. These techniques can be applied during training or as post-processing, and they are widely used to reduce the computational demands in terms of memory footprint, inference speed, and energy efficiency. We also briefly discuss different concepts of embedded hardware for DNNs and their compatibility with machine learning techniques as well as potential for energy and latency reduction. We substantiate our discussion with experiments on well-known benchmark data sets using compression techniques (quantization, pruning) for a set of resource-constrained embedded systems, such as CPUs, GPUs and FPGAs. The obtained results highlight the difficulty of finding good trade-offs between resource efficiency and prediction quality.},
  archive      = {J_JMLR},
  author       = {Wolfgang Roth and Günther Schindler and Bernhard Klein and Robert Peharz and Sebastian Tschiatschek and Holger Fröning and Franz Pernkopf and Zoubin Ghahramani},
  journal      = {Journal of Machine Learning Research},
  number       = {50},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Resource-efficient neural networks for embedded systems},
  url          = {https://jmlr.org/papers/v25/18-566.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trained transformers learn linear models in-context.
<em>JMLR</em>, <em>25</em>(49), 1–55. (<a
href="https://jmlr.org/papers/v25/23-1042.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention-based neural networks such as transformers have demonstrated a remarkable ability to exhibit in-context learning (ICL): Given a short prompt sequence of tokens from an unseen task, they can formulate relevant per-token and next-token predictions without any parameter updates. By embedding a sequence of labeled training data and unlabeled test data as a prompt, this allows for transformers to behave like supervised learning algorithms. Indeed, recent work has shown that when training transformer architectures over random instances of linear regression problems, these models&#39; predictions mimic those of ordinary least squares. Towards understanding the mechanisms underlying this phenomenon, we investigate the dynamics of ICL in transformers with a single linear self-attention layer trained by gradient flow on linear regression tasks. We show that despite non-convexity, gradient flow with a suitable random initialization finds a global minimum of the objective function. At this global minimum, when given a test prompt of labeled examples from a new prediction task, the transformer achieves prediction error competitive with the best linear predictor over the test prompt distribution. We additionally characterize the robustness of the trained transformer to a variety of distribution shifts and show that although a number of shifts are tolerated, shifts in the covariate distribution of the prompts are not. Motivated by this, we consider a generalized ICL setting where the covariate distributions can vary across prompts. We show that although gradient flow succeeds at finding a global minimum in this setting, the trained transformer is still brittle under mild covariate shifts. We complement this finding with experiments on large, nonlinear transformer architectures which we show are more robust under covariate shifts.},
  archive      = {J_JMLR},
  author       = {Ruiqi Zhang and Spencer Frei and Peter L. Bartlett},
  journal      = {Journal of Machine Learning Research},
  number       = {49},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Trained transformers learn linear models in-context},
  url          = {https://jmlr.org/papers/v25/23-1042.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adam-family methods for nonsmooth optimization with
convergence guarantees. <em>JMLR</em>, <em>25</em>(48), 1–53. (<a
href="https://jmlr.org/papers/v25/23-0576.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a comprehensive study on the convergence properties of Adam-family methods for nonsmooth optimization, especially in the training of nonsmooth neural networks. We introduce a novel two-timescale framework that adopts a two-timescale updating scheme, and prove its convergence properties under mild assumptions. Our proposed framework encompasses various popular Adam-family methods, providing convergence guarantees for these methods in training nonsmooth neural networks. Furthermore, we develop stochastic subgradient methods that incorporate gradient clipping techniques for training nonsmooth neural networks with heavy-tailed noise. Through our framework, we show that our proposed methods converge even when the evaluation noises are only assumed to be integrable. Extensive numerical experiments demonstrate the high efficiency and robustness of our proposed methods.},
  archive      = {J_JMLR},
  author       = {Nachuan Xiao and Xiaoyin Hu and Xin Liu and Kim-Chuan Toh},
  journal      = {Journal of Machine Learning Research},
  number       = {48},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Adam-family methods for nonsmooth optimization with convergence guarantees},
  url          = {https://jmlr.org/papers/v25/23-0576.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient modality selection in multimodal learning.
<em>JMLR</em>, <em>25</em>(47), 1–39. (<a
href="https://jmlr.org/papers/v25/23-0439.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal learning aims to learn from data of different modalities by fusing information from heterogeneous sources. Although it is beneficial to learn from more modalities, it is often infeasible to use all available modalities under limited computational resources. Modeling with all available modalities can also be inefficient and unnecessary when information across input modalities overlaps. In this paper, we study the modality selection problem, which aims to select the most useful subset of modalities for learning under a cardinality constraint. To that end, we propose a unified theoretical framework to quantify the learning utility of modalities, and we identify dependence assumptions to flexibly model the heterogeneous nature of multimodal data, which also allows efficient algorithm design. Accordingly, we derive a greedy modality selection algorithm via submodular maximization, which selects the most useful modalities with an optimality guarantee on learning performance. We also connect marginal-contribution-based feature importance scores, such as Shapley value, from the feature selection domain to the context of modality selection, to efficiently compute the importance of individual modality. We demonstrate the efficacy of our theoretical results and modality selection algorithms on 2 synthetic and 4 real-world data sets on a diverse range of multimodal data.},
  archive      = {J_JMLR},
  author       = {Yifei He and Runxiang Cheng and Gargi Balasubramaniam and Yao-Hung Hubert Tsai and Han Zhao},
  journal      = {Journal of Machine Learning Research},
  number       = {47},
  pages        = {1-39},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Efficient modality selection in multimodal learning},
  url          = {https://jmlr.org/papers/v25/23-0439.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multilabel classification framework for approximate
nearest neighbor search. <em>JMLR</em>, <em>25</em>(46), 1–51. (<a
href="https://jmlr.org/papers/v25/23-0286.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To learn partition-based index structures for approximate nearest neighbor (ANN) search, both supervised and unsupervised machine learning algorithms have been used. Existing supervised algorithms select all the points that belong to the same partition element as the query point as nearest neighbor candidates. Consequently, they formulate the learning task as finding a partition in which the nearest neighbors of a query point belong to the same partition element with it as often as possible. In contrast, we formulate the candidate set selection in ANN search directly as a multilabel classification problem where the labels correspond to the nearest neighbors of the query point. In the proposed framework, partition-based index structures are interpreted as partitioning classifiers for solving this classification problem. Empirical results suggest that, when combined with any partitioning strategy, the natural classifier based on the proposed framework leads to a strictly improved performance compared to the earlier candidate set selection methods. We also prove a sufficient condition for the consistency of a partitioning classifier for ANN search, and illustrate the result by verifying this condition for chronological $k$-d trees and (both dense and sparse) random projection trees.},
  archive      = {J_JMLR},
  author       = {Ville Hyvönen and Elias Jääsaari and Teemu Roos},
  journal      = {Journal of Machine Learning Research},
  number       = {46},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A multilabel classification framework for approximate nearest neighbor search},
  url          = {https://jmlr.org/papers/v25/23-0286.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probabilistic forecasting with generative networks via
scoring rule minimization. <em>JMLR</em>, <em>25</em>(45), 1–64. (<a
href="https://jmlr.org/papers/v25/23-0038.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic forecasting relies on past observations to provide a probability distribution for a future outcome, which is often evaluated against the realization using a scoring rule. Here, we perform probabilistic forecasting with generative neural networks, which parametrize distributions on high-dimensional spaces by transforming draws from a latent variable. Generative networks are typically trained in an adversarial framework. In contrast, we propose to train generative networks to minimize a predictive-sequential (or prequential) scoring rule on a recorded temporal sequence of the phenomenon of interest, which is appealing as it corresponds to the way forecasting systems are routinely evaluated. Adversarial-free minimization is possible for some scoring rules; hence, our framework avoids the cumbersome hyperparameter tuning and uncertainty underestimation due to unstable adversarial training, thus unlocking reliable use of generative networks in probabilistic forecasting. Further, we prove consistency of the minimizer of our objective with dependent data, while adversarial training assumes independence. We perform simulation studies on two chaotic dynamical models and a benchmark data set of global weather observations; for this last example, we define scoring rules for spatial data by drawing from the relevant literature. Our method outperforms state-of-the-art adversarial approaches, especially in probabilistic calibration, while requiring less hyperparameter tuning.},
  archive      = {J_JMLR},
  author       = {Lorenzo Pacchiardi and Rilwan A. Adewoyin and Peter Dueben and Ritabrata Dutta},
  journal      = {Journal of Machine Learning Research},
  number       = {45},
  pages        = {1-64},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Probabilistic forecasting with generative networks via scoring rule minimization},
  url          = {https://jmlr.org/papers/v25/23-0038.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple descent in the multiple random feature model.
<em>JMLR</em>, <em>25</em>(44), 1–49. (<a
href="https://jmlr.org/papers/v25/22-1389.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent works have demonstrated a double descent phenomenon in over-parameterized learning. Although this phenomenon has been investigated by recent works, it has not been fully understood in theory. In this paper, we investigate the multiple descent phenomenon in a class of multi-component prediction models. We first consider a &quot;double random feature model&quot; (DRFM) concatenating two types of random features, and study the excess risk achieved by the DRFM in ridge regression. We calculate the precise limit of the excess risk under the high dimensional framework where the training sample size, the dimension of data, and the dimension of random features tend to infinity proportionally. Based on the calculation, we further theoretically demonstrate that the risk curves of DRFMs can exhibit triple descent. We then provide a thorough experimental study to verify our theory. At last, we extend our study to the &quot;multiple random feature model&quot; (MRFM), and show that MRFMs ensembling $K$ types of random features may exhibit $(K+1)$-fold descent. Our analysis points out that risk curves with a specific number of descent generally exist in learning multi-component prediction models.},
  archive      = {J_JMLR},
  author       = {Xuran Meng and Jianfeng Yao and Yuan Cao},
  journal      = {Journal of Machine Learning Research},
  number       = {44},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Multiple descent in the multiple random feature model},
  url          = {https://jmlr.org/papers/v25/22-1389.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mean-square analysis of discretized itô diffusions for
heavy-tailed sampling. <em>JMLR</em>, <em>25</em>(43), 1–44. (<a
href="https://jmlr.org/papers/v25/22-1198.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the complexity of sampling from a class of heavy-tailed distributions by discretizing a natural class of Itô diffusions associated with weighted Poincaré inequalities. Based on a mean-square analysis, we establish the iteration complexity for obtaining a sample whose distribution is $\epsilon$ close to the target distribution in the Wasserstein-2 metric. In this paper, our results take the mean-square analysis to its limits, i.e., we invariably only require that the target density has finite variance, the minimal requirement for a mean-square analysis. To obtain explicit estimates, we compute upper bounds on certain moments associated with heavy-tailed targets under various assumptions. We also provide similar iteration complexity results for the case where only function evaluations of the unnormalized target density are available by estimating the gradients using a Gaussian smoothing technique. We provide illustrative examples based on the multivariate $t$-distribution.},
  archive      = {J_JMLR},
  author       = {Ye He and Tyler Farghly and Krishnakumar Balasubramanian and Murat A. Erdogdu},
  journal      = {Journal of Machine Learning Research},
  number       = {43},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Mean-square analysis of discretized itô diffusions for heavy-tailed sampling},
  url          = {https://jmlr.org/papers/v25/22-1198.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Invariant and equivariant reynolds networks. <em>JMLR</em>,
<em>25</em>(42), 1–36. (<a
href="https://jmlr.org/papers/v25/22-0891.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various data exhibit symmetry, including permutations in graphs and point clouds. Machine learning methods that utilize this symmetry have achieved considerable success. In this study, we explore learning models for data exhibiting group symmetry. Our focus is on transforming deep neural networks using Reynolds operators, which average over the group to convert a function into an invariant or equivariant form. While learning methods based on Reynolds operators are well-established, they often face computational complexity challenges. To address this, we introduce two new methods that reduce the computational burden associated with the Reynolds operator: (i) Although the Reynolds operator traditionally averages over the entire group, we demonstrate that it can be effectively approximated by averaging over specific subsets of the group, termed the Reynolds design. (ii) We reveal that the pre-model does not require all input variables. Instead, using a select number of partial inputs (Reynolds dimension) is sufficient to achieve a universally applicable model. Employing these methods, which hinge on the Reynolds design and Reynolds dimension concepts, allows us to construct universally applicable models with manageable computational complexity. Our experiments on benchmark data indicate that our approach is more efficient than existing methods.},
  archive      = {J_JMLR},
  author       = {Akiyoshi Sannai and Makoto Kawano and Wataru Kumagai},
  journal      = {Journal of Machine Learning Research},
  number       = {42},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Invariant and equivariant reynolds networks},
  url          = {https://jmlr.org/papers/v25/22-0891.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Personalized PCA: Decoupling shared and unique features.
<em>JMLR</em>, <em>25</em>(41), 1–82. (<a
href="https://jmlr.org/papers/v25/22-0810.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we tackle a significant challenge in PCA: heterogeneity. When data are collected from different sources with heterogeneous trends while still sharing some congruency, it is critical to extract shared knowledge while retaining the unique features of each source. To this end, we propose personalized PCA (PerPCA), which uses mutually orthogonal global and local principal components to encode both unique and shared features. We show that, under mild conditions, both unique and shared features can be identified and recovered by a constrained optimization problem, even if the covariance matrices are immensely different. Also, we design a fully federated algorithm inspired by distributed Stiefel gradient descent to solve the problem. The algorithm introduces a new group of operations called generalized retractions to handle orthogonality constraints, and only requires global PCs to be shared across sources. We prove the linear convergence of the algorithm under suitable assumptions. Comprehensive numerical experiments highlight PerPCA&#39;s superior performance in feature extraction and prediction from heterogeneous datasets. As a systematic approach to decouple shared and unique features from heterogeneous datasets, PerPCA finds applications in several tasks, including video segmentation, topic extraction, and feature clustering.},
  archive      = {J_JMLR},
  author       = {Naichen Shi and Raed Al Kontar},
  journal      = {Journal of Machine Learning Research},
  number       = {41},
  pages        = {1-82},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Personalized PCA: Decoupling shared and unique features},
  url          = {https://jmlr.org/papers/v25/22-0810.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survival kernets: Scalable and interpretable deep kernel
survival analysis with an accuracy guarantee. <em>JMLR</em>,
<em>25</em>(40), 1–78. (<a
href="https://jmlr.org/papers/v25/22-0667.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel survival analysis models estimate individual survival distributions with the help of a kernel function, which measures the similarity between any two data points. Such a kernel function can be learned using deep kernel survival models. In this paper, we present a new deep kernel survival model called a survival kernet, which scales to large datasets in a manner that is amenable to model interpretation and also theoretical analysis. Specifically, the training data are partitioned into clusters based on a recently developed training set compression scheme for classification and regression called kernel netting that we extend to the survival analysis setting. At test time, each data point is represented as a weighted combination of these clusters, and each such cluster can be visualized. For a special case of survival kernets, we establish a finite-sample error bound on predicted survival distributions that is, up to a log factor, optimal. Whereas scalability at test time is achieved using the aforementioned kernel netting compression strategy, scalability during training is achieved by a warm-start procedure based on tree ensembles such as XGBoost and a heuristic approach to accelerating neural architecture search. On four standard survival analysis datasets of varying sizes (up to roughly 3 million data points), we show that survival kernets are highly competitive compared to various baselines tested in terms of time-dependent concordance index. Our code is available at: https://github.com/georgehc/survival-kernets},
  archive      = {J_JMLR},
  author       = {George H. Chen},
  journal      = {Journal of Machine Learning Research},
  number       = {40},
  pages        = {1-78},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Survival kernets: Scalable and interpretable deep kernel survival analysis with an accuracy guarantee},
  url          = {https://jmlr.org/papers/v25/22-0667.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the sample complexity and metastability of heavy-tailed
policy search in continuous control. <em>JMLR</em>, <em>25</em>(39),
1–58. (<a href="https://jmlr.org/papers/v25/21-1343.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning is a framework for interactive decision-making with incentives sequentially revealed across time without a system dynamics model. Due to its scaling to continuous spaces, we focus on policy search where one iteratively improves a parameterized policy with stochastic policy gradient (PG) updates. In tabular Markov Decision Problems (MDPs), under persistent exploration and suitable parameterization, global optimality may be obtained. By contrast, in continuous space, the non-convexity poses a pathological challenge as evidenced by existing convergence results being mostly limited to stationarity or arbitrary local extrema. To close this gap, we step towards persistent exploration in continuous space through policy parameterizations defined by distributions of heavier tails defined by tail-index parameter $\alpha$, which increases the likelihood of jumping in state space. Doing so invalidates smoothness conditions of the score function common to PG. Thus, we establish how the convergence rate to stationarity depends on the policy&#39;s tail index $\alpha$, a Hölder continuity parameter, integrability conditions, and an exploration tolerance parameter introduced here for the first time. Further, we characterize the dependence of the set of local maxima on the tail index through an exit and transition time analysis of a suitably defined Markov chain, identifying that policies associated with Lévy Processes of a heavier tail converge to wider peaks. This phenomenon yields improved stability to perturbations in supervised learning, which we corroborate also manifests in improved performance of policy search, especially when myopic and farsighted incentives are misaligned.},
  archive      = {J_JMLR},
  author       = {Amrit Singh Bedi and Anjaly Parayil and Junyu Zhang and Mengdi Wang and Alec Koppel},
  journal      = {Journal of Machine Learning Research},
  number       = {39},
  pages        = {1-58},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the sample complexity and metastability of heavy-tailed policy search in continuous control},
  url          = {https://jmlr.org/papers/v25/21-1343.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence for nonconvex ADMM, with applications to CT
imaging. <em>JMLR</em>, <em>25</em>(38), 1–46. (<a
href="https://jmlr.org/papers/v25/21-0831.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The alternating direction method of multipliers (ADMM) algorithm is a powerful and flexible tool for complex optimization problems of the form $\min\{f(x)+g(y) : Ax+By=c\}$. ADMM exhibits robust empirical performance across a range of challenging settings including nonsmoothness and nonconvexity of the objective functions $f$ and $g$, and provides a simple and natural approach to the inverse problem of image reconstruction for computed tomography (CT) imaging. From the theoretical point of view, existing results for convergence in the nonconvex setting generally assume smoothness in at least one of the component functions in the objective. In this work, our new theoretical results provide convergence guarantees under a restricted strong convexity assumption without requiring smoothness or differentiability, while still allowing differentiable terms to be treated approximately if needed. We validate these theoretical results empirically, with a simulated example where both $f$ and $g$ are nondifferentiable---and thus outside the scope of existing theory---as well as a simulated CT image reconstruction problem.},
  archive      = {J_JMLR},
  author       = {Rina Foygel Barber and Emil Y. Sidky},
  journal      = {Journal of Machine Learning Research},
  number       = {38},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Convergence for nonconvex ADMM, with applications to CT imaging},
  url          = {https://jmlr.org/papers/v25/21-0831.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed gaussian mean estimation under communication
constraints: Optimal rates and communication-efficient algorithms.
<em>JMLR</em>, <em>25</em>(37), 1–63. (<a
href="https://jmlr.org/papers/v25/21-0316.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed estimation of a Gaussian mean under communication constraints is studied in a decision theoretical framework. Minimax rates of convergence, which characterize the tradeoff between communication costs and statistical accuracy, are established under the independent protocols. Communication-efficient and statistically optimal procedures are developed. In the univariate case, the optimal rate depends only on the total communication budget, so long as each local machine has at least one bit. However, in the multivariate case, the minimax rate depends on the specific allocations of the communication budgets among the local machines. Although optimal estimation of a Gaussian mean is relatively simple in the conventional setting, it is quite involved under communication constraints, both in terms of the optimal procedure design and the lower bound argument. An essential step is the decomposition of the minimax estimation problem into two stages, localization and refinement. This critical decomposition provides a framework for both the lower bound analysis and optimal procedure design. The optimality results and techniques developed in the present paper can be useful for solving other problems such as distributed nonparametric function estimation and sparse signal recovery.},
  archive      = {J_JMLR},
  author       = {T. Tony Cai and Hongji Wei},
  journal      = {Journal of Machine Learning Research},
  number       = {37},
  pages        = {1-63},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Distributed gaussian mean estimation under communication constraints: Optimal rates and communication-efficient algorithms},
  url          = {https://jmlr.org/papers/v25/21-0316.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse NMF with archetypal regularization: Computational and
robustness properties. <em>JMLR</em>, <em>25</em>(36), 1–62. (<a
href="https://jmlr.org/papers/v25/21-0233.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of sparse nonnegative matrix factorization (NMF) using archetypal regularization. The goal is to represent a collection of data points as nonnegative linear combinations of a few nonnegative sparse factors with appealing geometric properties, arising from the use of archetypal regularization. We generalize the notion of robustness studied in Javadi and Montanari (2019) (without sparsity) to the notions of (a) strong robustness that implies each estimated archetype is close to the underlying archetypes and (b) weak robustness that implies there exists at least one recovered archetype that is close to the underlying archetypes. Our theoretical results on robustness guarantees hold under minimal assumptions on the underlying data, and applies to settings where the underlying archetypes need not be sparse. We present theoretical results and illustrative examples to strengthen the insights underlying the notions of robustness. We propose new algorithms for our optimization problem; and present numerical experiments on synthetic and real data sets that shed further insights into our proposed framework and theoretical developments.},
  archive      = {J_JMLR},
  author       = {Kayhan Behdin and Rahul Mazumder},
  journal      = {Journal of Machine Learning Research},
  number       = {36},
  pages        = {1-62},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sparse NMF with archetypal regularization: Computational and robustness properties},
  url          = {https://jmlr.org/papers/v25/21-0233.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep network approximation: Beyond ReLU to diverse
activation functions. <em>JMLR</em>, <em>25</em>(35), 1–39. (<a
href="https://jmlr.org/papers/v25/23-0912.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the expressive power of deep neural networks for a diverse range of activation functions. An activation function set $\mathscr{A}$ is defined to encompass the majority of commonly used activation functions, such as $\mathtt{ReLU}$, $\mathtt{LeakyReLU}$, $\mathtt{ReLU}^2$, $\mathtt{ELU}$, $\mathtt{CELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$, $\mathtt{SiLU}$, $\mathtt{Swish}$, $\mathtt{Mish}$, $\mathtt{Sigmoid}$, $\mathtt{Tanh}$, $\mathtt{Arctan}$, $\mathtt{Softsign}$, $\mathtt{dSiLU}$, and $\mathtt{SRS}$. We demonstrate that for any activation function $\varrho\in \mathscr{A}$, a $\mathtt{ReLU}$ network of width $N$ and depth $L$ can be approximated to arbitrary precision by a $\varrho$-activated network of width $3N$ and depth $2L$ on any bounded set. This finding enables the extension of most approximation results achieved with $\mathtt{ReLU}$ networks to a wide variety of other activation functions, albeit with slightly increased constants. Significantly, we establish that the (width,$\,$depth) scaling factors can be further reduced from $(3,2)$ to $(1,1)$ if $\varrho$ falls within a specific subset of $\mathscr{A}$. This subset includes activation functions such as $\mathtt{ELU}$, $\mathtt{CELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$, $\mathtt{SiLU}$, $\mathtt{Swish}$, and $\mathtt{Mish}$.},
  archive      = {J_JMLR},
  author       = {Shijun Zhang and Jianfeng Lu and Hongkai Zhao},
  journal      = {Journal of Machine Learning Research},
  number       = {35},
  pages        = {1-39},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Deep network approximation: Beyond ReLU to diverse activation functions},
  url          = {https://jmlr.org/papers/v25/23-0912.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effect-invariant mechanisms for policy generalization.
<em>JMLR</em>, <em>25</em>(34), 1–36. (<a
href="https://jmlr.org/papers/v25/23-0802.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Policy learning is an important component of many real-world learning systems. A major challenge in policy learning is how to adapt efficiently to unseen environments or tasks. Recently, it has been suggested to exploit invariant conditional distributions to learn models that generalize better to unseen environments. However, assuming invariance of entire conditional distributions (which we call full invariance) may be too strong of an assumption in practice. In this paper, we introduce a relaxation of full invariance called effect-invariance (e-invariance for short) and prove that it is sufficient, under suitable assumptions, for zero-shot policy generalization. We also discuss an extension that exploits e-invariance when we have a small sample from the test environment, enabling few-shot policy generalization. Our work does not assume an underlying causal graph or that the data are generated by a structural causal model; instead, we develop testing procedures to test e-invariance directly from data. We present empirical results using simulated data and a mobile health intervention dataset to demonstrate the effectiveness of our approach.},
  archive      = {J_JMLR},
  author       = {Sorawit Saengkyongam and Niklas Pfister and Predrag Klasnja and Susan Murphy and Jonas Peters},
  journal      = {Journal of Machine Learning Research},
  number       = {34},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Effect-invariant mechanisms for policy generalization},
  url          = {https://jmlr.org/papers/v25/23-0802.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pygmtools: A python graph matching toolkit. <em>JMLR</em>,
<em>25</em>(33), 1–7. (<a
href="https://jmlr.org/papers/v25/23-0572.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph matching aims to find node-to-node matching among multiple graphs, which is a fundamental yet challenging problem. To facilitate graph matching in scientific research and industrial applications, pygmtools is released, which is a Python graph matching toolkit that implements a comprehensive collection of two-graph matching and multi-graph matching solvers, covering both learning-free solvers as well as learning-based neural graph matching solvers. Our implementation supports numerical backends including Numpy, PyTorch, Jittor, Paddle, runs on Windows, MacOS and Linux, and is friendly to install and configure. Comprehensive documentations covering beginner&#39;s guide, API reference and examples are available online. pygmtools is open-sourced under Mulan PSL v2 license.},
  archive      = {J_JMLR},
  author       = {Runzhong Wang and Ziao Guo and Wenzheng Pan and Jiale Ma and Yikai Zhang and Nan Yang and Qi Liu and Longxuan Wei and Hanxue Zhang and Chang Liu and Zetian Jiang and Xiaokang Yang and Junchi Yan},
  journal      = {Journal of Machine Learning Research},
  number       = {33},
  pages        = {1-7},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Pygmtools: A python graph matching toolkit},
  url          = {https://jmlr.org/papers/v25/23-0572.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous-agent reinforcement learning. <em>JMLR</em>,
<em>25</em>(32), 1–67. (<a
href="https://jmlr.org/papers/v25/23-0488.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The necessity for cooperation among intelligent machines has popularised cooperative multi-agent reinforcement learning (MARL) in AI research. However, many research endeavours heavily rely on parameter sharing among agents, which confines them to only homogeneous-agent setting and leads to training instability and lack of convergence guarantees. To achieve effective cooperation in the general heterogeneous-agent setting, we propose Heterogeneous-Agent Reinforcement Learning (HARL) algorithms that resolve the aforementioned issues. Central to our findings are the multi-agent advantage decomposition lemma and the sequential update scheme. Based on these, we develop the provably correct Heterogeneous-Agent Trust Region Learning (HATRL), and derive HATRPO and HAPPO by tractable approximations. Furthermore, we discover a novel framework named Heterogeneous-Agent Mirror Learning (HAML), which strengthens theoretical guarantees for HATRPO and HAPPO and provides a general template for cooperative MARL algorithmic designs. We prove that all algorithms derived from HAML inherently enjoy monotonic improvement of joint return and convergence to Nash Equilibrium. As its natural outcome, HAML validates more novel algorithms in addition to HATRPO and HAPPO, including HAA2C, HADDPG, and HATD3, which generally outperform their existing MA-counterparts. We comprehensively test HARL algorithms on six challenging benchmarks and demonstrate their superior effectiveness and stability for coordinating heterogeneous agents compared to strong baselines such as MAPPO and QMIX.},
  archive      = {J_JMLR},
  author       = {Yifan Zhong and Jakub Grudzien Kuba and Xidong Feng and Siyi Hu and Jiaming Ji and Yaodong Yang},
  journal      = {Journal of Machine Learning Research},
  number       = {32},
  pages        = {1-67},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Heterogeneous-agent reinforcement learning},
  url          = {https://jmlr.org/papers/v25/23-0488.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sample-efficient adversarial imitation learning.
<em>JMLR</em>, <em>25</em>(31), 1–32. (<a
href="https://jmlr.org/papers/v25/23-0314.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imitation learning, in which learning is performed by demonstration, has been studied and advanced for sequential decision-making tasks in which a reward function is not predefined. However, imitation learning methods still require numerous expert demonstration samples to successfully imitate an expert&#39;s behavior. To improve sample efficiency, we utilize self-supervised representation learning, which can generate vast training signals from the given data. In this study, we propose a self-supervised representation-based adversarial imitation learning method to learn state and action representations that are robust to diverse distortions and temporally predictive, on non-image control tasks. In particular, in comparison with existing self-supervised learning methods for tabular data, we propose a different corruption method for state and action representations that is robust to diverse distortions. We theoretically and empirically observe that making an informative feature manifold with less sample complexity significantly improves the performance of imitation learning. The proposed method shows a 39% relative improvement over existing adversarial imitation learning methods on MuJoCo in a setting limited to 100 expert state-action pairs. Moreover, we conduct comprehensive ablations and additional experiments using demonstrations with varying optimality to provide insights into a range of factors.},
  archive      = {J_JMLR},
  author       = {Dahuin Jung and Hyungyu Lee and Sungroh Yoon},
  journal      = {Journal of Machine Learning Research},
  number       = {31},
  pages        = {1-32},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sample-efficient adversarial imitation learning},
  url          = {https://jmlr.org/papers/v25/23-0314.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic modified flows, mean-field limits and dynamics of
stochastic gradient descent. <em>JMLR</em>, <em>25</em>(30), 1–27. (<a
href="https://jmlr.org/papers/v25/23-0220.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose new limiting dynamics for stochastic gradient descent in the small learning rate regime called stochastic modified flows. These SDEs are driven by a cylindrical Brownian motion and improve the so-called stochastic modified equations by having regular diffusion coefficients and by matching the multi-point statistics. As a second contribution, we introduce distribution dependent stochastic modified flows which we prove to describe the fluctuating limiting dynamics of stochastic gradient descent in the small learning rate - infinite width scaling regime.},
  archive      = {J_JMLR},
  author       = {Benjamin Gess and Sebastian Kassing and Vitalii Konarovskyi},
  journal      = {Journal of Machine Learning Research},
  number       = {30},
  pages        = {1-27},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Stochastic modified flows, mean-field limits and dynamics of stochastic gradient descent},
  url          = {https://jmlr.org/papers/v25/23-0220.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rates of convergence for density estimation with generative
adversarial networks. <em>JMLR</em>, <em>25</em>(29), 1–47. (<a
href="https://jmlr.org/papers/v25/23-0062.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we undertake a thorough study of the non-asymptotic properties of the vanilla generative adversarial networks (GANs). We prove an oracle inequality for the Jensen-Shannon (JS) divergence between the underlying density $\mathsf{p}^*$ and the GAN estimate with a significantly better statistical error term compared to the previously known results. The advantage of our bound becomes clear in application to nonparametric density estimation. We show that the JS-divergence between the GAN estimate and $\mathsf{p}^*$ decays as fast as $(\log{n}/n)^{2\beta/(2\beta + d)}$, where $n$ is the sample size and $\beta$ determines the smoothness of $\mathsf{p}^*$. This rate of convergence coincides (up to logarithmic factors) with minimax optimal for the considered class of densities.},
  archive      = {J_JMLR},
  author       = {Nikita Puchkin and Sergey Samsonov and Denis Belomestny and Eric Moulines and Alexey Naumov},
  journal      = {Journal of Machine Learning Research},
  number       = {29},
  pages        = {1-47},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Rates of convergence for density estimation with generative adversarial networks},
  url          = {https://jmlr.org/papers/v25/23-0062.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Additive smoothing error in backward variational inference
for general state-space models. <em>JMLR</em>, <em>25</em>(28), 1–33.
(<a href="https://jmlr.org/papers/v25/22-1392.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of state estimation in general state-space models using variational inference. For a generic variational family defined using the same backward decomposition as the actual joint smoothing distribution, we establish under mixing assumptions that the variational approximation of expectations of additive state functionals induces an error which grows at most linearly in the number of observations. This guarantee is consistent with the known upper bounds for the approximation of smoothing distributions using standard Monte Carlo methods. We illustrate our theoretical result with state-of-the art variational solutions based both on the backward parameterization and on alternatives using forward decompositions. This numerical study proposes guidelines for variational inference based on neural networks in state-space models.},
  archive      = {J_JMLR},
  author       = {Mathis Chagneux and Elisabeth Gassiat and Pierre Gloaguen and Sylvain Le Corff},
  journal      = {Journal of Machine Learning Research},
  number       = {28},
  pages        = {1-33},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Additive smoothing error in backward variational inference for general state-space models},
  url          = {https://jmlr.org/papers/v25/22-1392.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal bump functions for shallow ReLU networks: Weight
decay, depth separation, curse of dimensionality. <em>JMLR</em>,
<em>25</em>(27), 1–49. (<a
href="https://jmlr.org/papers/v25/22-1296.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this note, we study how neural networks with a single hidden layer and ReLU activation interpolate data drawn from a radially symmetric distribution with target labels 1 at the origin and 0 outside the unit ball, if no labels are known inside the unit ball. With weight decay regularization and in the infinite neuron, infinite data limit, we prove that a unique radially symmetric minimizer exists, whose average parameters and Lipschitz constant grow as $d$ and $\sqrt{d}$ respectively. We furthermore show that the average weight variable grows exponentially in $d$ if the label $1$ is imposed on a ball of radius $\varepsilon$ rather than just at the origin. By comparison, a neural networks with two hidden layers can approximate the target function without encountering the curse of dimensionality.},
  archive      = {J_JMLR},
  author       = {Stephan Wojtowytsch},
  journal      = {Journal of Machine Learning Research},
  number       = {27},
  pages        = {1-49},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal bump functions for shallow ReLU networks: Weight decay, depth separation, curse of dimensionality},
  url          = {https://jmlr.org/papers/v25/22-1296.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Numerically stable sparse gaussian processes via minimum
separation using cover trees. <em>JMLR</em>, <em>25</em>(26), 1–36. (<a
href="https://jmlr.org/papers/v25/22-1170.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian processes are frequently deployed as part of larger machine learning and decision-making systems, for instance in geospatial modeling, Bayesian optimization, or in latent Gaussian models. Within a system, the Gaussian process model needs to perform in a stable and reliable manner to ensure it interacts correctly with other parts of the system. In this work, we study the numerical stability of scalable sparse approximations based on inducing points. To do so, we first review numerical stability, and illustrate typical situations in which Gaussian process models can be unstable. Building on stability theory originally developed in the interpolation literature, we derive sufficient and in certain cases necessary conditions on the inducing points for the computations performed to be numerically stable. For low-dimensional tasks such as geospatial modeling, we propose an automated method for computing inducing points satisfying these conditions. This is done via a modification of the cover tree data structure, which is of independent interest. We additionally propose an alternative sparse approximation for regression with a Gaussian likelihood which trades off a small amount of performance to further improve stability. We provide illustrative examples showing the relationship between stability of calculations and predictive performance of inducing point methods on spatial tasks.},
  archive      = {J_JMLR},
  author       = {Alexander Terenin and David R. Burt and Artem Artemev and Seth Flaxman and Mark van der Wilk and Carl Edward Rasmussen and Hong Ge},
  journal      = {Journal of Machine Learning Research},
  number       = {26},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Numerically stable sparse gaussian processes via minimum separation using cover trees},
  url          = {https://jmlr.org/papers/v25/22-1170.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On tail decay rate estimation of loss function
distributions. <em>JMLR</em>, <em>25</em>(25), 1–47. (<a
href="https://jmlr.org/papers/v25/22-0846.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of loss-function distributions is critical to characterize a model&#39;s behaviour on a given machine-learning problem. While model quality is commonly measured by the average loss assessed on a testing set, this quantity does not ascertain the existence of the mean of the loss distribution. Conversely, the existence of a distribution&#39;s statistical moments can be verified by examining the thickness of its tails. Cross-validation schemes determine a family of testing loss distributions conditioned on the training sets. By marginalizing across training sets, we can recover the overall (marginal) loss distribution, whose tail-shape we aim to estimate. Small sample-sizes diminish the reliability and efficiency of classical tail-estimation methods like Peaks-Over-Threshold, and we demonstrate that this effect is notably significant when estimating tails of marginal distributions composed of conditional distributions with substantial tail-location variability. We mitigate this problem by utilizing a result we prove: under certain conditions, the marginal-distribution&#39;s tail-shape parameter is the maximum tail-shape parameter across the conditional distributions underlying the marginal. We label the resulting approach as `cross-tail estimation (CTE)&#39;. We test CTE in a series of experiments on simulated and real data showing the improved robustness and quality of tail estimation as compared to classical approaches.},
  archive      = {J_JMLR},
  author       = {Etrit Haxholli and Marco Lorenzi},
  journal      = {Journal of Machine Learning Research},
  number       = {25},
  pages        = {1-47},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On tail decay rate estimation of loss function distributions},
  url          = {https://jmlr.org/papers/v25/22-0846.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep nonparametric estimation of operators between infinite
dimensional spaces. <em>JMLR</em>, <em>25</em>(24), 1–67. (<a
href="https://jmlr.org/papers/v25/22-0719.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning operators between infinitely dimensional spaces is an important learning task arising in machine learning, imaging science, mathematical modeling and simulations, etc. This paper studies the nonparametric estimation of Lipschitz operators using deep neural networks. Non-asymptotic upper bounds are derived for the generalization error of the empirical risk minimizer over a properly chosen network class. Under the assumption that the target operator exhibits a low dimensional structure, our error bounds decay as the training sample size increases, with an attractive fast rate depending on the intrinsic dimension in our estimation. Our assumptions cover most scenarios in real applications and our results give rise to fast rates by exploiting low dimensional structures of data in operator estimation. We also investigate the influence of network structures (e.g., network width, depth, and sparsity) on the generalization error of the neural network estimator and propose a general suggestion on the choice of network structures to maximize the learning efficiency quantitatively.},
  archive      = {J_JMLR},
  author       = {Hao Liu and Haizhao Yang and Minshuo Chen and Tuo Zhao and Wenjing Liao},
  journal      = {Journal of Machine Learning Research},
  number       = {24},
  pages        = {1-67},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Deep nonparametric estimation of operators between infinite dimensional spaces},
  url          = {https://jmlr.org/papers/v25/22-0719.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Post-regularization confidence bands for ordinary
differential equations. <em>JMLR</em>, <em>25</em>(23), 1–51. (<a
href="https://jmlr.org/papers/v25/22-0487.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinary differential equation (ODE) is an important tool to study a system of biological and physical processes. A central question in ODE modeling is to infer the significance of individual regulatory effect of one signal variable on another. However, building confidence band for ODE with unknown regulatory relations is challenging, and it remains largely an open question. In this article, we construct the post-regularization confidence band for the individual regulatory function in ODE with unknown functionals and noisy data observations. Our proposal is the first of its kind, and is built on two novel ingredients. The first is a new localized kernel learning approach that combines reproducing kernel learning with local Taylor approximation, and the second is a new de-biasing method that tackles infinite-dimensional functionals and additional measurement errors. We show that the constructed confidence band has the desired asymptotic coverage probability, and the recovered regulatory network approaches the truth with probability tending to one. We establish the theoretical properties when the number of variables in the system can be either smaller or larger than the number of sampling time points, and we study the regime-switching phenomenon. We demonstrate the efficacy of the proposed method through both simulations and illustrations with two data applications.},
  archive      = {J_JMLR},
  author       = {Xiaowu Dai and Lexin Li},
  journal      = {Journal of Machine Learning Research},
  number       = {23},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Post-regularization confidence bands for ordinary differential equations},
  url          = {https://jmlr.org/papers/v25/22-0487.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the generalization of stochastic gradient descent with
momentum. <em>JMLR</em>, <em>25</em>(22), 1–56. (<a
href="https://jmlr.org/papers/v25/22-0068.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While momentum-based accelerated variants of stochastic gradient descent (SGD) are widely used when training machine learning models, there is little theoretical understanding on the generalization error of such methods. In this work, we first show that there exists a convex loss function for which the stability gap for multiple epochs of SGD with standard heavy-ball momentum (SGDM) becomes unbounded. Then, for smooth Lipschitz loss functions, we analyze a modified momentum-based update rule, i.e., SGD with early momentum (SGDEM) under a broad range of step-sizes, and show that it can train machine learning models for multiple epochs with a guarantee for generalization. Finally, for the special case of strongly convex loss functions, we find a range of momentum such that multiple epochs of standard SGDM, as a special form of SGDEM, also generalizes. Extending our results on generalization, we also develop an upper bound on the expected true risk, in terms of the number of training steps, sample size, and momentum. Our experimental evaluations verify the consistency between the numerical results and our theoretical bounds. SGDEM improves the generalization error of SGDM when training ResNet-18 on ImageNet in practical distributed settings.},
  archive      = {J_JMLR},
  author       = {Ali Ramezani-Kebrya and Kimon Antonakopoulos and Volkan Cevher and Ashish Khisti and Ben Liang},
  journal      = {Journal of Machine Learning Research},
  number       = {22},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the generalization of stochastic gradient descent with momentum},
  url          = {https://jmlr.org/papers/v25/22-0068.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pursuit of the cluster structure of network lasso: Recovery
condition and non-convex extension. <em>JMLR</em>, <em>25</em>(21),
1–42. (<a href="https://jmlr.org/papers/v25/21-1190.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network lasso (NL for short) is a technique for estimating models by simultaneously clustering data samples and fitting the models to them. It often succeeds in forming clusters thanks to the geometry of the sum of $\ell_2$ norm employed therein, but there may be limitations due to the convexity of the regularizer. This paper focuses on clustering generated by NL and strengthens it by creating a non-convex extension, called network trimmed lasso (NTL for short). Specifically, we initially investigate a sufficient condition that guarantees the recovery of the latent cluster structure of NL on the basis of the result of Sun et al. (2021) for convex clustering, which is a special case of NL for ordinary clustering. Second, we extend NL to NTL to incorporate a cardinality (or, $\ell_0$-)constraint and rewrite the constrained optimization problem defined with the $\ell_0$ norm, a discontinuous function, into an equivalent unconstrained continuous optimization problem. We develop ADMM algorithms to solve NTL and show their convergence results. Numerical illustrations indicate that the non-convex extension provides a more clear-cut cluster structure when NL fails to form clusters without incorporating prior knowledge of the associated parameters.},
  archive      = {J_JMLR},
  author       = {Shotaro Yagishita and Jun-ya Gotoh},
  journal      = {Journal of Machine Learning Research},
  number       = {21},
  pages        = {1-42},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Pursuit of the cluster structure of network lasso: Recovery condition and non-convex extension},
  url          = {https://jmlr.org/papers/v25/21-1190.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterate averaging in the quest for best test error.
<em>JMLR</em>, <em>25</em>(20), 1–55. (<a
href="https://jmlr.org/papers/v25/21-1125.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyse and explain the increased generalisation performance of iterate averaging using a Gaussian process perturbation model between the true and batch risk surface on the high dimensional quadratic. We derive three phenomena from our theoretical results: (1) The importance of combining iterate averaging (IA) with large learning rates and regularisation for improved generalisation. (2) Justification for less frequent averaging. (3) That we expect adaptive gradient methods to work equally well, or better, with iterate averaging than their non-adaptive counterparts. Inspired by these results, together with empirical investigations of the importance of appropriate regularisation for the solution diversity of the iterates, we propose two adaptive algorithms with iterate averaging. These give significantly better results compared to stochastic gradient descent (SGD), require less tuning and do not require early stopping or validation set monitoring. We showcase the efficacy of our approach on the CIFAR-10/100, ImageNet and Penn Treebank datasets on a variety of modern and classical network architectures.},
  archive      = {J_JMLR},
  author       = {Diego Granziol and Nicholas P. Baskerville and Xingchen Wan and Samuel Albanie and Stephen Roberts},
  journal      = {Journal of Machine Learning Research},
  number       = {20},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Iterate averaging in the quest for best test error},
  url          = {https://jmlr.org/papers/v25/21-1125.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonparametric inference under b-bits quantization.
<em>JMLR</em>, <em>25</em>(19), 1–68. (<a
href="https://jmlr.org/papers/v25/20-075.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical inference based on lossy or incomplete samples is often needed in research areas such as signal/image processing, medical image storage, remote sensing, signal transmission. In this paper, we propose a nonparametric testing procedure based on samples quantized to $B$ bits through a computationally efficient algorithm. Under mild technical conditions, we establish the asymptotic properties of the proposed test statistic and investigate how the testing power changes as $B$ increases. In particular, we show that if $B$ exceeds a certain threshold, the proposed nonparametric testing procedure achieves the classical minimax rate of testing (Shang and Cheng, 2015) for spline models. We further extend our theoretical investigations to a nonparametric linearity test and an adaptive nonparametric test, expanding the applicability of the proposed methods. Extensive simulation studies {together with a real-data analysis} are used to demonstrate the validity and effectiveness of the proposed tests.},
  archive      = {J_JMLR},
  author       = {Kexuan Li and Ruiqi Liu and Ganggang Xu and Zuofeng Shang},
  journal      = {Journal of Machine Learning Research},
  number       = {19},
  pages        = {1-68},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Nonparametric inference under B-bits quantization},
  url          = {https://jmlr.org/papers/v25/20-075.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Black box variational inference with a deterministic
objective: Faster, more accurate, and even more black box.
<em>JMLR</em>, <em>25</em>(18), 1–39. (<a
href="https://jmlr.org/papers/v25/23-1015.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic differentiation variational inference (ADVI) offers fast and easy-to-use posterior approximation in multiple modern probabilistic programming languages. However, its stochastic optimizer lacks clear convergence criteria and requires tuning parameters. Moreover, ADVI inherits the poor posterior uncertainty estimates of mean-field variational Bayes (MFVB). We introduce &quot;deterministic ADVI&quot; (DADVI) to address these issues. DADVI replaces the intractable MFVB objective with a fixed Monte Carlo approximation, a technique known in the stochastic optimization literature as the &quot;sample average approximation&quot; (SAA). By optimizing an approximate but deterministic objective, DADVI can use off-the-shelf second-order optimization, and, unlike standard mean-field ADVI, is amenable to more accurate posterior covariances via linear response (LR). In contrast to existing worst-case theory, we show that, on certain classes of common statistical problems, DADVI and the SAA can perform well with relatively few samples even in very high dimensions, though we also show that such favorable results cannot extend to variational approximations that are too expressive relative to mean-field ADVI. We show on a variety of real-world problems that DADVI reliably finds good solutions with default settings (unlike ADVI) and, together with LR covariances, is typically faster and more accurate than standard ADVI.},
  archive      = {J_JMLR},
  author       = {Ryan Giordano and Martin Ingram and Tamara Broderick},
  journal      = {Journal of Machine Learning Research},
  number       = {18},
  pages        = {1-39},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Black box variational inference with a deterministic objective: Faster, more accurate, and even more black box},
  url          = {https://jmlr.org/papers/v25/23-1015.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On sufficient graphical models. <em>JMLR</em>,
<em>25</em>(17), 1–64. (<a
href="https://jmlr.org/papers/v25/23-0893.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a sufficient graphical model by applying the recently developed nonlinear sufficient dimension reduction techniques to the evaluation of conditional independence. The graphical model is nonparametric in nature, as it does not make distributional assumptions such as the Gaussian or copula Gaussian assumptions. However, unlike a fully nonparametric graphical model, which relies on the high-dimensional kernel to characterize conditional independence, our graphical model is based on conditional independence given a set of sufficient predictors with a substantially reduced dimension. In this way we avoid the curse of dimensionality that comes with a high-dimensional kernel. We develop the population-level properties, convergence rate, and variable selection consistency of our estimate. By simulation comparisons and an analysis of the DREAM 4 Challenge data set, we demonstrate that our method outperforms the existing methods when the Gaussian or copula Gaussian assumptions are violated, and its performance remains excellent in the high-dimensional setting.},
  archive      = {J_JMLR},
  author       = {Bing Li and Kyongwon Kim},
  journal      = {Journal of Machine Learning Research},
  number       = {17},
  pages        = {1-64},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On sufficient graphical models},
  url          = {https://jmlr.org/papers/v25/23-0893.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Localized debiased machine learning: Efficient inference on
quantile treatment effects and beyond. <em>JMLR</em>, <em>25</em>(16),
1–59. (<a href="https://jmlr.org/papers/v25/23-0661.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider estimating a low-dimensional parameter in an estimating equation involving high-dimensional nuisance functions that depend on the target parameter as an input. A central example is the efficient estimating equation for the (local) quantile treatment effect ((L)QTE) in causal inference, which involves the covariate-conditional cumulative distribution function evaluated at the quantile to be estimated. Existing approaches based on flexibly estimating the nuisances and plugging in the estimates, such as debiased machine learning (DML), require we learn the nuisance at all possible inputs. For (L)QTE, DML requires we learn the whole covariate-conditional cumulative distribution function. We instead propose localized debiased machine learning (LDML), which avoids this burdensome step and needs only estimate nuisances at a single initial rough guess for the target parameter. For (L)QTE, LDML involves learning just two regression functions, a standard task for machine learning methods. We prove that under lax rate conditions our estimator has the same favorable asymptotic behavior as the infeasible estimator that uses the unknown true nuisances. Thus, LDML notably enables practically-feasible and theoretically-grounded efficient estimation of important quantities in causal inference such as (L)QTEs when we must control for many covariates and/or flexible relationships, as we demonstrate in empirical studies.},
  archive      = {J_JMLR},
  author       = {Nathan Kallus and Xiaojie Mao and Masatoshi Uehara},
  journal      = {Journal of Machine Learning Research},
  number       = {16},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Localized debiased machine learning: Efficient inference on quantile treatment effects and beyond},
  url          = {https://jmlr.org/papers/v25/23-0661.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the effect of initialization: The scaling path of 2-layer
neural networks. <em>JMLR</em>, <em>25</em>(15), 1–24. (<a
href="https://jmlr.org/papers/v25/23-0549.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In supervised learning, the regularization path is sometimes used as a convenient theoretical proxy for the optimization path of gradient descent initialized from zero. In this paper, we study a modification of the regularization path for infinite-width 2-layer ReLU neural networks with nonzero initial distribution of the weights at different scales. By exploiting a link with unbalanced optimal-transport theory, we show that, despite the non-convexity of the 2-layer network training, this problem admits an infinite-dimensional convex counterpart. We formulate the corresponding functional-optimization problem and investigate its main properties. In particular, we show that, as the scale of the initialization ranges between $0$ and $+\infty$, the associated path interpolates continuously between the so-called kernel and rich regimes. Numerical experiments confirm that, in our setting, the scaling path and the final states of the optimization path behave similarly, even beyond these extreme points.},
  archive      = {J_JMLR},
  author       = {Sebastian Neumayer and Lénaïc Chizat and Michael Unser},
  journal      = {Journal of Machine Learning Research},
  number       = {15},
  pages        = {1-24},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On the effect of initialization: The scaling path of 2-layer neural networks},
  url          = {https://jmlr.org/papers/v25/23-0549.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving physics-informed neural networks with meta-learned
optimization. <em>JMLR</em>, <em>25</em>(14), 1–26. (<a
href="https://jmlr.org/papers/v25/23-0356.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that the error achievable using physics-informed neural networks for solving differential equations can be substantially reduced when these networks are trained using meta-learned optimization methods rather than using fixed, hand-crafted optimizers as traditionally done. We choose a learnable optimization method based on a shallow multi-layer perceptron that is meta-trained for specific classes of differential equations. We illustrate meta-trained optimizers for several equations of practical relevance in mathematical physics, including the linear advection equation, Poisson&#39;s equation, the Korteweg-de Vries equation and Burgers&#39; equation. We also illustrate that meta-learned optimizers exhibit transfer learning abilities, in that a meta-trained optimizer on one differential equation can also be successfully deployed on another differential equation.},
  archive      = {J_JMLR},
  author       = {Alex Bihlo},
  journal      = {Journal of Machine Learning Research},
  number       = {14},
  pages        = {1-26},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Improving physics-informed neural networks with meta-learned optimization},
  url          = {https://jmlr.org/papers/v25/23-0356.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comparison of continuous-time approximations to stochastic
gradient descent. <em>JMLR</em>, <em>25</em>(13), 1–55. (<a
href="https://jmlr.org/papers/v25/23-0237.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying a stochastic gradient descent (SGD) method for minimizing an objective gives rise to a discrete-time process of estimated parameter values. In order to better understand the dynamics of the estimated values, many authors have considered continuous-time approximations of SGD. We refine existing results on the weak error of first-order ODE and SDE approximations to SGD for non-infinitesimal learning rates. In particular, we explicitly compute the linear term in the error expansion of gradient flow and two of its stochastic counterparts, with respect to a discretization parameter $h$. In the example of linear regression, we demonstrate the general inferiority of the deterministic gradient flow approximation in comparison to the stochastic ones, for batch sizes which are not too large. Further, we demonstrate that for Gaussian features an SDE approximation with state-independent noise (CC) is preferred over using a state-dependent coefficient (NCC). The same comparison holds true for features of low kurtosis or large batch sizes. However, the relationship reverses for highly leptokurtic features or small batch sizes.},
  archive      = {J_JMLR},
  author       = {Stefan Ankirchner and Stefan Perko},
  journal      = {Journal of Machine Learning Research},
  number       = {13},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A comparison of continuous-time approximations to stochastic gradient descent},
  url          = {https://jmlr.org/papers/v25/23-0237.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Critically assessing the state of the art in neural network
verification. <em>JMLR</em>, <em>25</em>(12), 1–53. (<a
href="https://jmlr.org/papers/v25/23-0119.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has proposed various methods to formally verify neural networks against minimal input perturbations; this verification task is also known as local robustness verification. The research area of local robustness verification is highly diverse, as verifiers rely on a multitude of techniques, including mixed integer programming and satisfiability modulo theories. At the same time, the problem instances encountered when performing local robustness verification differ based on the network to be verified, the property to be verified and the specific network input. This raises the question of which verification algorithm is most suitable for solving specific types of instances of the local robustness verification problem. To answer this question, we performed a systematic performance analysis of several CPU- and GPU-based local robustness verification systems on a newly and carefully assembled set of 79 neural networks, of which we verified a broad range of robustness properties, while taking a practitioner&#39;s point of view -- a perspective that complements the insights from initiatives such as the VNN competition, where the participating tools are carefully adapted to the given benchmarks by their developers. Notably, we show that no single best algorithm dominates performance across all verification problem instances. Instead, our results reveal complementarities in verifier performance and illustrate the potential of leveraging algorithm portfolios for more efficient local robustness verification. We quantify this complementarity using various performance measures, such as the Shapley value. Furthermore, we confirm the notion that most algorithms only support ReLU-based networks, while other activation functions remain under-supported.},
  archive      = {J_JMLR},
  author       = {Matthias König and Annelot W. Bosman and Holger H. Hoos and Jan N. van Rijn},
  journal      = {Journal of Machine Learning Research},
  number       = {12},
  pages        = {1-53},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Critically assessing the state of the art in neural network verification},
  url          = {https://jmlr.org/papers/v25/23-0119.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating the minimizer and the minimum value of a
regression function under passive design. <em>JMLR</em>,
<em>25</em>(11), 1–37. (<a
href="https://jmlr.org/papers/v25/22-1396.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method for estimating the minimizer $\boldsymbol{x}^*$ and the minimum value $f^*$ of a smooth and strongly convex regression function $f$ from the observations contaminated by random noise. Our estimator $\boldsymbol{z}_n$ of the minimizer $\boldsymbol{x}^*$ is based on a version of the projected gradient descent with the gradient estimated by a regularized local polynomial algorithm. Next, we propose a two-stage procedure for estimation of the minimum value $f^*$ of regression function $f$. At the first stage, we construct an accurate enough estimator of $\boldsymbol{x}^*$, which can be, for example, $\boldsymbol{z}_n$. At the second stage, we estimate the function value at the point obtained in the first stage using a rate optimal nonparametric procedure. We derive non-asymptotic upper bounds for the quadratic risk and optimization risk of $\boldsymbol{z}_n$, and for the risk of estimating $f^*$. We establish minimax lower bounds showing that, under certain choice of parameters, the proposed algorithms achieve the minimax optimal rates of convergence on the class of smooth and strongly convex functions.},
  archive      = {J_JMLR},
  author       = {Arya Akhavan and Davit Gogolashvili and Alexandre B. Tsybakov},
  journal      = {Journal of Machine Learning Research},
  number       = {11},
  pages        = {1-37},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Estimating the minimizer and the minimum value of a regression function under passive design},
  url          = {https://jmlr.org/papers/v25/22-1396.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling random networks with heterogeneous reciprocity.
<em>JMLR</em>, <em>25</em>(10), 1–40. (<a
href="https://jmlr.org/papers/v25/22-1317.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reciprocity, or the tendency of individuals to mirror behavior, is a key measure that describes information exchange in a social network. Users in social networks tend to engage in different levels of reciprocal behavior. Differences in such behavior may indicate the existence of communities that reciprocate links at varying rates. In this paper, we develop methodology to model the diverse reciprocal behavior in growing social networks. In particular, we present a preferential attachment model with heterogeneous reciprocity that imitates the attraction users have for popular users, plus the heterogeneous nature by which they reciprocate links. We compare Bayesian and frequentist model fitting techniques for large networks, as well as computationally efficient variational alternatives. Cases where the number of communities is known and unknown are both considered. We apply the presented methods to the analysis of Facebook and Reddit networks where users have non-uniform reciprocal behavior patterns. The fitted model captures the heavy-tailed nature of the empirical degree distributions in the datasets and identifies multiple groups of users that differ in their tendency to reply to and receive responses to wallposts and comments.},
  archive      = {J_JMLR},
  author       = {Daniel Cirkovic and Tiandong Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {10},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Modeling random networks with heterogeneous reciprocity},
  url          = {https://jmlr.org/papers/v25/22-1317.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploration, exploitation, and engagement in multi-armed
bandits with abandonment. <em>JMLR</em>, <em>25</em>(9), 1–55. (<a
href="https://jmlr.org/papers/v25/22-1251.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional multi-armed bandit (MAB) model for recommendation systems assumes the user stays in the system for the entire learning horizon. In new online education platforms such as ALEKS or new video recommendation systems such as TikTok, the amount of time a user spends on the app depends on how engaging the recommended contents are. Users may temporarily leave the system if the recommended items cannot engage the users. To understand the exploration, exploitation, and engagement in these systems, we propose a new model, called MAB-A where “A” stands for abandonment and the abandonment probability depends on the current recommended item and the user&#39;s past experience (called state). We propose two algorithms, ULCB and KL-ULCB, both of which do more exploration (being optimistic) when the user likes the previous recommended item and less exploration (being pessimistic) when the user does not. We prove that both ULCB and KL-ULCB achieve logarithmic regret, $O(\log K)$, where $K$ is the number of visits (or episodes). Furthermore, the regret bound under KL-ULCB is asymptotically sharp. We also extend the proposed algorithms to the general-state setting. Simulation results show that the proposed algorithms have significantly lower regret than the traditional UCB and KL-UCB, and Q-learning-based algorithms.},
  archive      = {J_JMLR},
  author       = {Zixian Yang and Xin Liu and Lei Ying},
  journal      = {Journal of Machine Learning Research},
  number       = {9},
  pages        = {1-55},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Exploration, exploitation, and engagement in multi-armed bandits with abandonment},
  url          = {https://jmlr.org/papers/v25/22-1251.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On efficient and scalable computation of the nonparametric
maximum likelihood estimator in mixture models. <em>JMLR</em>,
<em>25</em>(8), 1–46. (<a
href="https://jmlr.org/papers/v25/22-1120.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on the computation of the nonparametric maximum likelihood estimator (NPMLE) in multivariate mixture models. Our approach discretizes this infinite dimensional convex optimization problem by setting fixed support points for the NPMLE and optimizing over the mixing proportions. We propose an efficient and scalable semismooth Newton based augmented Lagrangian method (ALM). Our algorithm outperforms the state-of-the-art methods (Kim et al., 2020; Koenker and Gu, 2017), capable of handling $n \approx 10^6$ data points with $m \approx 10^4$ support points. A key advantage of our approach is its strategic utilization of the solution&#39;s sparsity, leading to structured sparsity in Hessian computations. As a result, our algorithm demonstrates better scaling in terms of $m$ when compared to the mixsqp method (Kim et al., 2020). The computed NPMLE can be directly applied to denoising the observations in the framework of empirical Bayes. We propose new denoising estimands in this context along with their consistent estimates. Extensive numerical experiments are conducted to illustrate the efficiency of our ALM. In particular, we employ our method to analyze two astronomy data sets: (i) Gaia-TGAS Catalog (Anderson et al., 2018) containing approximately $1.4 \times 10^6$ data points in two dimensions, and (ii) a data set from the APOGEE survey (Majewski et al., 2017) with approximately $2.7 \times 10^4$ data points.},
  archive      = {J_JMLR},
  author       = {Yangjing Zhang and Ying Cui and Bodhisattva Sen and Kim-Chuan Toh},
  journal      = {Journal of Machine Learning Research},
  number       = {8},
  pages        = {1-46},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On efficient and scalable computation of the nonparametric maximum likelihood estimator in mixture models},
  url          = {https://jmlr.org/papers/v25/22-1120.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decorrelated variable importance. <em>JMLR</em>,
<em>25</em>(7), 1–27. (<a
href="https://jmlr.org/papers/v25/22-0801.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the widespread use of black box prediction methods such as random forests and neural nets, there is renewed interest in developing methods for quantifying variable importance as part of the broader goal of interpretable prediction. A popular approach is to define a variable importance parameter --- known as LOCO (Leave Out COvariates) --- based on dropping covariates from a regression model. This is essentially a nonparametric version of $R^2$. This parameter is very general and can be estimated nonparametrically, but it can be hard to interpret because it is affected by correlation between covariates. We propose a method for mitigating the effect of correlation by defining a modified version of LOCO. This new parameter is difficult to estimate nonparametrically, but we show how to estimate it using semiparametric models.},
  archive      = {J_JMLR},
  author       = {Isabella Verdinelli and Larry Wasserman},
  journal      = {Journal of Machine Learning Research},
  number       = {7},
  pages        = {1-27},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Decorrelated variable importance},
  url          = {https://jmlr.org/papers/v25/22-0801.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-free representation learning and exploration in
low-rank MDPs. <em>JMLR</em>, <em>25</em>(6), 1–76. (<a
href="https://jmlr.org/papers/v25/22-0687.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-rank MDP has emerged as an important model for studying representation learning and exploration in reinforcement learning. With a known representation, several model-free exploration strategies exist. In contrast, all algorithms for the unknown representation setting are model-based, thereby requiring the ability to model the full dynamics. In this work, we present the first model-free representation learning algorithms for low-rank MDPs. The key algorithmic contribution is a new minimax representation learning objective, for which we provide variants with differing tradeoffs in their statistical and computational properties. We interleave this representation learning step with an exploration strategy to cover the state space in a reward-free manner. The resulting algorithms are provably sample efficient and can accommodate general function approximation to scale to complex environments.},
  archive      = {J_JMLR},
  author       = {Aditya Modi and Jinglin Chen and Akshay Krishnamurthy and Nan Jiang and Alekh Agarwal},
  journal      = {Journal of Machine Learning Research},
  number       = {6},
  pages        = {1-76},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Model-free representation learning and exploration in low-rank MDPs},
  url          = {https://jmlr.org/papers/v25/22-0687.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Seeded graph matching for the correlated gaussian wigner
model via the projected power method. <em>JMLR</em>, <em>25</em>(5),
1–43. (<a href="https://jmlr.org/papers/v25/22-0402.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the graph matching problem we observe two graphs $G,H$ and the goal is to find an assignment (or matching) between their vertices such that some measure of edge agreement is maximized. We assume in this work that the observed pair $G,H$ has been drawn from the Correlated Gaussian Wigner (CGW) model -- a popular model for correlated weighted graphs -- where the entries of the adjacency matrices of $G$ and $H$ are independent Gaussians and each edge of $G$ is correlated with one edge of $H$ (determined by the unknown matching) with the edge correlation described by a parameter $\sigma \in [0,1)$. In this paper, we analyse the performance of the projected power method (PPM) as a seeded graph matching algorithm where we are given an initial partially correct matching (called the seed) as side information. We prove that if the seed is close enough to the ground-truth matching, then with high probability, PPM iteratively improves the seed and recovers the ground-truth matching (either partially or exactly) in $O(\log n)$ iterations. Our results prove that PPM works even in regimes of constant $\sigma$, thus extending the analysis in (Mao et al., 2023) for the sparse Correlated Erdos-Renyi (CER) model to the (dense) CGW model. As a byproduct of our analysis, we see that the PPM framework generalizes some of the state-of-art algorithms for seeded graph matching. We support and complement our theoretical findings with numerical experiments on synthetic data.},
  archive      = {J_JMLR},
  author       = {Ernesto Araya and Guillaume Braun and Hemant Tyagi},
  journal      = {Journal of Machine Learning Research},
  number       = {5},
  pages        = {1-43},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Seeded graph matching for the correlated gaussian wigner model via the projected power method},
  url          = {https://jmlr.org/papers/v25/22-0402.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast policy extragradient methods for competitive games with
entropy regularization. <em>JMLR</em>, <em>25</em>(4), 1–48. (<a
href="https://jmlr.org/papers/v25/21-1205.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of computing the equilibrium of competitive games in the form of two-player zero-sum games, which is often modeled as a constrained saddle-point optimization problem with probability simplex constraints. Despite recent efforts in understanding the last-iterate convergence of extragradient methods in the unconstrained setting, the theoretical underpinnings of these methods in the constrained settings, especially those using multiplicative updates, remain highly inadequate, even when the objective function is bilinear. Motivated by the algorithmic role of entropy regularization in single-agent reinforcement learning and game theory, we develop provably efficient extragradient methods to find the quantal response equilibrium (QRE)---which are solutions to zero-sum two-player matrix games with entropy regularization---at a linear rate. The proposed algorithms can be implemented in a decentralized manner, where each player executes symmetric and multiplicative updates iteratively using its own payoff without observing the opponent&#39;s actions directly. In addition, by controlling the knob of entropy regularization, the proposed algorithms can locate an approximate Nash equilibrium of the unregularized matrix game at a sublinear rate without assuming the Nash equilibrium to be unique. Our methods also lead to efficient policy extragradient algorithms for solving (entropy-regularized) zero-sum Markov games at similar rates. All of our convergence rates are nearly dimension-free, which are independent of the size of the state and action spaces up to logarithm factors, highlighting the positive role of entropy regularization for accelerating convergence.},
  archive      = {J_JMLR},
  author       = {Shicong Cen and Yuting Wei and Yuejie Chi},
  journal      = {Journal of Machine Learning Research},
  number       = {4},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Fast policy extragradient methods for competitive games with entropy regularization},
  url          = {https://jmlr.org/papers/v25/21-1205.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Power of knockoff: The impact of ranking algorithm,
augmented design, and symmetric statistic. <em>JMLR</em>,
<em>25</em>(3), 1–67. (<a
href="https://jmlr.org/papers/v25/21-1137.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knockoff filter is a recent false discovery rate (FDR) control method for high-dimensional linear models. We point out that knockoff has three key components: ranking algorithm, augmented design, and symmetric statistic, and each component admits multiple choices. By considering various combinations of the three components, we obtain a collection of variants of knockoff. All these variants guarantee finite-sample FDR control, and our goal is to compare their power. We assume a Rare and Weak signal model on regression coeffi- cients and compare the power of different variants of knockoff by deriving explicit formulas of false positive rate and false negative rate. Our results provide new insights on how to improve power when controlling FDR at a targeted level. We also compare the power of knockoff with its propotype - a method that uses the same ranking algorithm but has access to an ideal threshold. The comparison reveals the additional price one pays by finding a data-driven threshold to control FDR.},
  archive      = {J_JMLR},
  author       = {Zheng Tracy Ke and Jun S. Liu and Yucong Ma},
  journal      = {Journal of Machine Learning Research},
  number       = {3},
  pages        = {1-67},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Power of knockoff: The impact of ranking algorithm, augmented design, and symmetric statistic},
  url          = {https://jmlr.org/papers/v25/21-1137.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lower complexity bounds of finite-sum optimization problems:
The results and construction. <em>JMLR</em>, <em>25</em>(2), 1–86. (<a
href="https://jmlr.org/papers/v25/21-0264.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the lower complexity bounds for finite-sum optimization problems, where the objective is the average of $n$ individual component functions. We consider a so-called proximal incremental first-order oracle (PIFO) algorithm, which employs the individual component function&#39;s gradient and proximal information provided by PIFO to update the variable. To incorporate loopless methods, we also allow the PIFO algorithm to obtain the full gradient infrequently. We develop a novel approach to constructing the hard instances, which partitions the tridiagonal matrix of classical examples into $n$ groups. This construction is friendly to the analysis of PIFO algorithms. Based on this construction, we establish the lower complexity bounds for finite-sum minimax optimization problems when the objective is convex-concave or nonconvex-strongly-concave and the class of component functions is $L$-average smooth. Most of these bounds are nearly matched by existing upper bounds up to log factors. We also derive similar lower bounds for finite-sum minimization problems as previous work under both smoothness and average smoothness assumptions. Our lower bounds imply that proximal oracles for smooth functions are not much more powerful than gradient oracles.},
  archive      = {J_JMLR},
  author       = {Yuze Han and Guangzeng Xie and Zhihua Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {2},
  pages        = {1-86},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Lower complexity bounds of finite-sum optimization problems: The results and construction},
  url          = {https://jmlr.org/papers/v25/21-0264.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On truthing issues in supervised classification.
<em>JMLR</em>, <em>25</em>(1), 1–91. (<a
href="https://jmlr.org/papers/v25/19-301.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ideal supervised classification assumes known correct labels, but various truthing issues can arise in practice: noisy labels; multiple, conflicting labels for a sample; missing labels; and different labeler combinations for different samples. Previous work introduced a noisy-label model, which views the observed noisy labels as random variables conditioned on the unobserved correct labels. It has mainly focused on estimating the conditional distribution of the noisy labels and the class prior, as well as estimating the correct labels or training with noisy labels. In a complementary manner, given the conditional distribution and class prior, we apply estimation theory to classifier testing, training, and comparison of different combinations of labelers. First, for binary classification, we construct a testing model and derive approximate marginal posteriors for accuracy, precision, recall, probability of false alarm, and F-score, and joint posteriors for ROC and precision-recall analysis. We propose minimum mean-square error (MMSE) testing, which employs empirical Bayes algorithms to estimate the testing-model parameters and then computes optimal point estimates and credible regions for the metrics. We extend the approach to multi-class classification to obtain optimal estimates of accuracy and individual confusion-matrix elements. Second, we present a unified view of training that covers probabilistic (i.e., discriminative or generative) and non-probabilistic models. For the former, we adjust maximum-likelihood or maximum a posteriori training for truthing issues; for the latter, we propose MMSE training, which minimizes the MMSE estimate of the empirical risk. We also describe suboptimal training that is compatible with existing infrastructure. Third, we observe that mutual information lets one express any labeler combination as an equivalent single labeler, implying that multiple mediocre labelers can be as informative as, or more informative than, a single expert labeler. Experiments demonstrate the effectiveness of the methods and confirm the implication.},
  archive      = {J_JMLR},
  author       = {Jonathan K. Su},
  journal      = {Journal of Machine Learning Research},
  number       = {1},
  pages        = {1-91},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {On truthing issues in supervised classification},
  url          = {https://jmlr.org/papers/v25/19-301.html},
  volume       = {25},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
