<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ECJ_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ecj---18">ECJ - 18</h2>
<ul>
<li><details>
<summary>
(2024). Virtual position guided strategy for particle swarm
optimization algorithms on multimodal problems. <em>ECJ</em>,
<em>32</em>(4), 427–458. (<a
href="https://doi.org/10.1162/evco_a_00352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Premature convergence is a thorny problem for particle swarm optimization (PSO) algorithms, especially on multimodal problems, where maintaining swarm diversity is crucial. However, most enhancement strategies for PSO, including the existing diversity-guided strategies, have not fully addressed this issue. This paper proposes the virtual position guided (VPG) strategy for PSO algorithms. The VPG strategy calculates diversity values for two different populations and establishes a diversity baseline. It then dynamically guides the algorithm to conduct different search behaviors, through three phases—divergence, normal, and acceleration—in each iteration, based on the relationships among these diversity values and the baseline. Collectively, these phases orchestrate different schemes to balance exploration and exploitation, collaboratively steering the algorithm away from local optima and towards enhanced solution quality. The introduction of “virtual position” caters to the strategy&#39;s adaptability across various PSO algorithms, ensuring the generality and effectiveness of the proposed VPG strategy. With a single hyperparameter and a recommended usual setup, VPG is easy to implement. The experimental results demonstrate that the VPG strategy is superior to several canonical and the state-of-the-art strategies for diversity guidance, and is effective in improving the search performance of most PSO algorithms on multimodal problems of various dimensionalities.},
  archive      = {J_ECJ},
  author       = {Li, Chao and Sun, Jun and Li, Li-Wei and Shan, Min and Palade, Vasile and Wu, Xiaojun},
  doi          = {10.1162/evco_a_00352},
  journal      = {Evolutionary Computation},
  month        = {12},
  number       = {4},
  pages        = {427-458},
  shortjournal = {Evol. Comput.},
  title        = {Virtual position guided strategy for particle swarm optimization algorithms on multimodal problems},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Territorial differential meta-evolution: An algorithm for
seeking all the desirable optima of a multivariable function.
<em>ECJ</em>, <em>32</em>(4), 399–426. (<a
href="https://doi.org/10.1162/evco_a_00337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Territorial Differential Meta-Evolution (TDME) is an efficient, versatile, and reliable algorithm for seeking all the global or desirable local optima of a multivariable function. It employs a progressive niching mechanism to optimize even challenging, high-dimensional functions with multiple global optima and misleading local optima. This paper introduces TDME and uses standard and novel benchmark problems to quantify its advantages over HillVallEA, which is the best-performing algorithm on the standard benchmark suite that has been used by all major multimodal optimization competitions since 2013. TDME matches HillVallEA on that benchmark suite and categorically outperforms it on a more comprehensive suite that better reflects the potential diversity of optimization problems. TDME achieves that performance without any problem-specific parameter tuning.},
  archive      = {J_ECJ},
  author       = {Wehr, Richard and Saleska, Scott R.},
  doi          = {10.1162/evco_a_00337},
  journal      = {Evolutionary Computation},
  month        = {12},
  number       = {4},
  pages        = {399-426},
  shortjournal = {Evol. Comput.},
  title        = {Territorial differential meta-evolution: An algorithm for seeking all the desirable optima of a multivariable function},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameterless gene-pool optimal mixing evolutionary
algorithms. <em>ECJ</em>, <em>32</em>(4), 371–397. (<a
href="https://doi.org/10.1162/evco_a_00338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When it comes to solving optimization problems with evolutionary algorithms (EAs) in a reliable and scalable manner, detecting and exploiting linkage information, that is, dependencies between variables, can be key. In this paper, we present the latest version of, and propose substantial enhancements to, the gene-pool optimal mixing evolutionary algorithm (GOMEA): an EA explicitly designed to estimate and exploit linkage information. We begin by performing a large-scale search over several GOMEA design choices to understand what matters most and obtain a generally best-performing version of the algorithm. Next, we introduce a novel version of GOMEA, called CGOMEA, where linkage-based variation is further improved by filtering solution mating based on conditional dependencies. We compare our latest version of GOMEA, the newly introduced CGOMEA, and another contending linkage-aware EA, DSMGA-II, in an extensive experimental evaluation, involving a benchmark set of nine black-box problems that can be solved efficiently only if their inherent dependency structure is unveiled and exploited. Finally, in an attempt to make EAs more usable and resilient to parameter choices, we investigate the performance of different automatic population management schemes for GOMEA and CGOMEA, de facto making the EAs parameterless. Our results show that GOMEA and CGOMEA significantly outperform the original GOMEA and DSMGA-II on most problems, setting a new state of the art for the field.},
  archive      = {J_ECJ},
  author       = {Dushatskiy, Arkadiy and Virgolin, Marco and Bouter, Anton and Thierens, Dirk and Bosman, Peter A. N.},
  doi          = {10.1162/evco_a_00338},
  journal      = {Evolutionary Computation},
  month        = {12},
  number       = {4},
  pages        = {371-397},
  shortjournal = {Evol. Comput.},
  title        = {Parameterless gene-pool optimal mixing evolutionary algorithms},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimation of distribution algorithm for grammar-guided
genetic programming. <em>ECJ</em>, <em>32</em>(4), 339–370. (<a
href="https://doi.org/10.1162/evco_a_00345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic variation operators in grammar-guided genetic programming are fundamental to guide the evolutionary process in search and optimization problems. However, they show some limitations, mainly derived from an unbalanced exploration and local-search trade-off. This paper presents an estimation of distribution algorithm for grammar-guided genetic programming to overcome this difficulty and thus increase the performance of the evolutionary algorithm. Our proposal employs an extended dynamic stochastic context-free grammar to encode and calculate the estimation of the distribution of the search space from some promising individuals in the population. Unlike traditional estimation of distribution algorithms, the proposed approach improves exploratory behavior by smoothing the estimated distribution model. Therefore, this algorithm is referred to as SEDA, smoothed estimation of distribution algorithm. Experiments have been conducted to compare overall performance using a typical genetic programming crossover operator, an incremental estimation of distribution algorithm, and the proposed approach after tuning their hyperparameters. These experiments involve challenging problems to test the local search and exploration features of the three evolutionary systems. The results show that grammar-guided genetic programming with SEDA achieves the most accurate solutions with an intermediate convergence speed.},
  archive      = {J_ECJ},
  author       = {Criado, Pablo Ramos and Rolanía, D. Barrios and de la Hoz, David and Manrique, Daniel},
  doi          = {10.1162/evco_a_00345},
  journal      = {Evolutionary Computation},
  month        = {12},
  number       = {4},
  pages        = {339-370},
  shortjournal = {Evol. Comput.},
  title        = {Estimation of distribution algorithm for grammar-guided genetic programming},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Informed down-sampled lexicase selection: Identifying
productive training cases for efficient problem solving. <em>ECJ</em>,
<em>32</em>(4), 307–337. (<a
href="https://doi.org/10.1162/evco_a_00346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic Programming (GP) often uses large training sets and requires all individuals to be evaluated on all training cases during selection. Random down-sampled lexicase selection evaluates individuals on only a random subset of the training cases, allowing for more individuals to be explored with the same number of program executions. However, sampling randomly can exclude important cases from the down-sample for a number of generations, while cases that measure the same behavior (synonymous cases) may be overused. In this work, we introduce Informed Down-Sampled Lexicase Selection. This method leverages population statistics to build down-samples that contain more distinct and therefore informative training cases. Through an empirical investigation across two different GP systems (PushGP and Grammar-Guided GP), we find that informed down-sampling significantly outperforms random down-sampling on a set of contemporary program synthesis benchmark problems. Through an analysis of the created down-samples, we find that important training cases are included in the down-sample consistently across independent evolutionary runs and systems. We hypothesize that this improvement can be attributed to the ability of Informed Down-Sampled Lexicase Selection to maintain more specialist individuals over the course of evolution, while still benefiting from reduced per-evaluation costs.},
  archive      = {J_ECJ},
  author       = {Boldi, Ryan and Briesch, Martin and Sobania, Dominik and Lalejini, Alexander and Helmuth, Thomas and Rothlauf, Franz and Ofria, Charles and Spector, Lee},
  doi          = {10.1162/evco_a_00346},
  journal      = {Evolutionary Computation},
  month        = {12},
  number       = {4},
  pages        = {307-337},
  shortjournal = {Evol. Comput.},
  title        = {Informed down-sampled lexicase selection: Identifying productive training cases for efficient problem solving},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discovering and exploiting sparse rewards in a learned
behavior space. <em>ECJ</em>, <em>32</em>(3), 275–305. (<a
href="https://doi.org/10.1162/evco_a_00343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning optimal policies in sparse rewards settings is difficult as the learning agent has little to no feedback on the quality of its actions. In these situations, a good strategy is to focus on exploration, hopefully leading to the discovery of a reward signal to improve on. A learning algorithm capable of dealing with this kind of setting has to be able to (1) explore possible agent behaviors and (2) exploit any possible discovered reward. Exploration algorithms have been proposed that require the definition of a low-dimension behavior space, in which the behavior generated by the agent&#39;s policy can be represented. The need to design a priori this space such that it is worth exploring is a major limitation of these algorithms. In this work, we introduce STAX, an algorithm designed to learn a behavior space on-the-fly and to explore it while optimizing any reward discovered (see Figure 1 ). It does so by separating the exploration and learning of the behavior space from the exploitation of the reward through an alternating two-step process. In the first step, STAX builds a repertoire of diverse policies while learning a low-dimensional representation of the high-dimensional observations generated during the policies evaluation. In the exploitation step, emitters optimize the performance of the discovered rewarding solutions. Experiments conducted on three different sparse reward environments show that STAX performs comparably to existing baselines while requiring much less prior information about the task as it autonomously builds the behavior space it explores.},
  archive      = {J_ECJ},
  author       = {Paolo, Giuseppe and Coninx, Miranda and Laflaquière, Alban and Doncieux, Stephane},
  doi          = {10.1162/evco_a_00343},
  journal      = {Evolutionary Computation},
  month        = {9},
  number       = {3},
  pages        = {275-305},
  shortjournal = {Evol. Comput.},
  title        = {Discovering and exploiting sparse rewards in a learned behavior space},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Preliminary analysis of simple novelty search. <em>ECJ</em>,
<em>32</em>(3), 249–273. (<a
href="https://doi.org/10.1162/evco_a_00340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novelty search is a powerful tool for finding diverse sets of objects in complicated spaces. Recent experiments on simplified versions of novelty search introduce the idea that novelty search happens at the level of the archive space, rather than individual points. The sparseness measure and archive update criterion create a process that is driven by a two measures: (1) spread out to cover the space while trying to remain as efficiently packed as possible, and (2) metrics inspired by k nearest neighbor theory. In this paper, we generalize previous simplifications of novelty search to include traditional population ( μ , λ ) dynamics for generating new search points, where the population and the archive are updated separately. We provide some theoretical guidance regarding balancing mutation and sparseness criteria and introduce the concept of saturation as a way of talking about fully covered spaces. We show empirically that claims that novelty search is inherently objectiveless are incorrect. We leverage the understanding of novelty search as an optimizer of archive coverage, suggest several ways to improve the search, and demonstrate one simple improvement—generating some new points directly from the archive rather than the parent population.},
  archive      = {J_ECJ},
  author       = {Wiegand, R. Paul},
  doi          = {10.1162/evco_a_00340},
  journal      = {Evolutionary Computation},
  month        = {9},
  number       = {3},
  pages        = {249-273},
  shortjournal = {Evol. Comput.},
  title        = {Preliminary analysis of simple novelty search},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A tri-objective method for bi-objective feature selection in
classification. <em>ECJ</em>, <em>32</em>(3), 217–248. (<a
href="https://doi.org/10.1162/evco_a_00339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimizing the number of selected features and maximizing the classification performance are two main objectives in feature selection, which can be formulated as a bi-objective optimization problem. Due to the complex interactions between features, a solution (i.e., feature subset) with poor objective values does not mean that all the features it selects are useless, as some of them combined with other complementary features can greatly improve the classification performance. Thus, it is necessary to consider not only the performance of feature subsets in the objective space, but also their differences in the search space, to explore more promising feature combinations. To this end, this paper proposes a tri-objective method for bi-objective feature selection in classification, which solves a bi-objective feature selection problem as a tri-objective problem by considering the diversity (differences) between feature subsets in the search space as the third objective. The selection based on the converted tri-objective method can maintain a balance between minimizing the number of selected features, maximizing the classification performance, and exploring more promising feature subsets. Furthermore, a novel initialization strategy and an offspring reproduction operator are proposed to promote the diversity of feature subsets in the objective space and improve the search ability, respectively. The proposed algorithm is compared with five multiobjective-based feature selection methods, six typical feature selection methods, and two peer methods with diversity as a helper objective. Experimental results on 20 real-world classification datasets suggest that the proposed method outperforms the compared methods in most scenarios.},
  archive      = {J_ECJ},
  author       = {Jiao, Ruwang and Xue, Bing and Zhang, Mengjie},
  doi          = {10.1162/evco_a_00339},
  journal      = {Evolutionary Computation},
  month        = {9},
  number       = {3},
  pages        = {217-248},
  shortjournal = {Evol. Comput.},
  title        = {A tri-objective method for bi-objective feature selection in classification},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pflacco: Feature-based landscape analysis of continuous and
constrained optimization problems in python. <em>ECJ</em>,
<em>32</em>(3), 211–216. (<a
href="https://doi.org/10.1162/evco_a_00341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The herein proposed Python package pflacco provides a set of numerical features to characterize single-objective continuous and constrained optimization problems. Thereby, pflacco addresses two major challenges in the area  of optimization. Firstly, it provides the means to develop an understanding of a given problem instance, which is crucial for designing, selecting, or configuring optimization algorithms in general. Secondly, these numerical features can be utilized in the research streams of automated algorithm selection and configuration. While the majority of these landscape features are already available in the R package flacco , our Python implementation offers these tools to an even wider audience and thereby promotes research interests and novel avenues in the area of optimization.},
  archive      = {J_ECJ},
  author       = {Prager, Raphael Patrick and Trautmann, Heike},
  doi          = {10.1162/evco_a_00341},
  journal      = {Evolutionary Computation},
  month        = {9},
  number       = {3},
  pages        = {211-216},
  shortjournal = {Evol. Comput.},
  title        = {Pflacco: Feature-based landscape analysis of continuous and constrained optimization problems in python},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IOHexperimenter: Benchmarking platform for iterative
optimization heuristics. <em>ECJ</em>, <em>32</em>(3), 205–210. (<a
href="https://doi.org/10.1162/evco_a_00342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present IOHexperimenter, the experimentation module of the IOHprofiler project. IOHexperimenter aims at providing an easy-to-use and customizable toolbox for benchmarking iterative optimization heuristics such as local search, evolutionary and genetic algorithms, and Bayesian optimization techniques. IOHexperimenter can be used as a stand-alone tool or as part of a benchmarking pipeline that uses other modules of the IOHprofiler environment. IOHexperimenter provides an efficient interface between optimization problems and their solvers while allowing for granular logging of the optimization process. Its logs are fully compatible with existing tools for interactive data analysis, which significantly speeds up the deployment of a benchmarking pipeline. The main components of IOHexperimenter are the environment to build customized problem suites and the various logging options that allow users to steer the granularity of the data records.},
  archive      = {J_ECJ},
  author       = {de Nobel, Jacob and Ye, Furong and Vermetten, Diederick and Wang, Hao and Doerr, Carola and Bäck, Thomas},
  doi          = {10.1162/evco_a_00342},
  journal      = {Evolutionary Computation},
  month        = {9},
  number       = {3},
  pages        = {205-210},
  shortjournal = {Evol. Comput.},
  title        = {IOHexperimenter: Benchmarking platform for iterative optimization heuristics},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural architecture search using covariance matrix
adaptation evolution strategy. <em>ECJ</em>, <em>32</em>(2), 177–204.
(<a href="https://doi.org/10.1162/evco_a_00331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolution-based neural architecture search methods have shown promising results, but they require high computational resources because these methods involve training each candidate architecture from scratch and then evaluating its fitness, which results in long search time. Covariance Matrix Adaptation Evolution Strategy (CMA-ES) has shown promising results in tuning hyperparameters of neural networks but has not been used for neural architecture search. In this work, we propose a framework called CMANAS which applies the faster convergence property of CMA-ES to the deep neural architecture search problem. Instead of training each individual architecture seperately, we used the accuracy of a trained one shot model (OSM) on the validation data as a prediction of the fitness of the architecture, resulting in reduced search time. We also used an architecture-fitness table (AF table) for keeping a record of the already evaluated architecture, thus further reducing the search time. The architectures are modeled using a normal distribution, which is updated using CMA-ES based on the fitness of the sampled population. Experimentally, CMANAS achieves better results than previous evolution-based methods while reducing the search time significantly. The effectiveness of CMANAS is shown on two different search spaces using four datasets: CIFAR-10, CIFAR-100, ImageNet, and ImageNet16-120. All the results show that CMANAS is a viable alternative to previous evolution-based methods and extends the application of CMA-ES to the deep neural architecture search field.},
  archive      = {J_ECJ},
  author       = {Sinha, Nilotpal and Chen, Kuan-Wen},
  doi          = {10.1162/evco_a_00331},
  journal      = {Evolutionary Computation},
  month        = {6},
  number       = {2},
  pages        = {177-204},
  shortjournal = {Evol. Comput.},
  title        = {Neural architecture search using covariance matrix adaptation evolution strategy},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On single-objective sub-graph-based mutation for solving the
bi-objective minimum spanning tree problem. <em>ECJ</em>,
<em>32</em>(2), 143–175. (<a
href="https://doi.org/10.1162/evco_a_00335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We contribute to the efficient approximation of the Pareto-set for the classical NP -hard multiobjective minimum spanning tree problem (moMST) adopting evolutionary computation. More precisely, by building upon preliminary work, we analyze the neighborhood structure of Pareto-optimal spanning trees and design several highly biased sub-graph-based mutation operators founded on the gained insights. In a nutshell, these operators replace (un)connected sub-trees of candidate solutions with locally optimal sub-trees. The latter (biased) step is realized by applying Kruskal&#39;s single-objective MST algorithm to a weighted sum scalarization of a sub-graph. We prove runtime complexity results for the introduced operators and investigate the desirable Pareto-beneficial property. This property states that mutants cannot be dominated by their parent. Moreover, we perform an extensive experimental benchmark study to showcase the operator&#39;s practical suitability. Our results confirm that the sub-graph-based operators beat baseline algorithms from the literature even with severely restricted computational budget in terms of function evaluations on four different classes of complete graphs with different shapes of the Pareto-front.},
  archive      = {J_ECJ},
  author       = {Bossek, Jakob and Grimme, Christian},
  doi          = {10.1162/evco_a_00335},
  journal      = {Evolutionary Computation},
  month        = {6},
  number       = {2},
  pages        = {143-175},
  shortjournal = {Evol. Comput.},
  title        = {On single-objective sub-graph-based mutation for solving the bi-objective minimum spanning tree problem},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The role of morphological variation in evolutionary
robotics: Maximizing performance and robustness. <em>ECJ</em>,
<em>32</em>(2), 125–142. (<a
href="https://doi.org/10.1162/evco_a_00336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exposing an evolutionary algorithm that is used to evolve robot controllers to variable conditions is necessary to obtain solutions which are robust and can cross the reality gap. However, we do not yet have methods for analyzing and understanding the impact of the varying morphological conditions which impact the evolutionary process, and therefore for choosing suitable variation ranges. By morphological conditions, we refer to the starting state of the robot, and to variations in its sensor readings during operation due to noise. In this paper, we introduce a method that permits us to measure the impact of these morphological variations and we analyze the relation between the amplitude of variations, the modality with which they are introduced, and the performance and robustness of evolving agents. Our results demonstrate that (i) the evolutionary algorithm can tolerate morphological variations which have a very high impact, (ii) variations affecting the actions of the agent are tolerated much better than variations affecting the initial state of the agent or of the environment, and (iii) improving the accuracy of the fitness measure through multiple evaluations is not always useful. Moreover, our results show that morphological variations permit generating solutions which perform better both in varying and non-varying conditions.},
  archive      = {J_ECJ},
  author       = {Carvalho, Jonata Tyska and Nolfi, Stefano},
  doi          = {10.1162/evco_a_00336},
  journal      = {Evolutionary Computation},
  month        = {6},
  number       = {2},
  pages        = {125-142},
  shortjournal = {Evol. Comput.},
  title        = {The role of morphological variation in evolutionary robotics: Maximizing performance and robustness},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparing robot controller optimization methods on evolvable
morphologies. <em>ECJ</em>, <em>32</em>(2), 105–124. (<a
href="https://doi.org/10.1162/evco_a_00334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we compare Bayesian Optimization, Differential Evolution, and an Evolution Strategy employed as a gait-learning algorithm in modular robots. The motivational scenario is the joint evolution of morphologies and controllers, where “newborn” robots also undergo a learning process to optimize their inherited controllers (without changing their bodies). This context raises the question: How do gait-learning algorithms compare when applied to various morphologies that are not known in advance (and thus need to be treated as without priors)? To answer this question, we use a test suite of twenty different robot morphologies to evaluate our gait-learners and compare their efficiency, efficacy, and sensitivity to morphological differences. The results indicate that Bayesian Optimization and Differential Evolution deliver the same solution quality (walking speed for the robot) with fewer evaluations than the Evolution Strategy. Furthermore, the Evolution Strategy is more sensitive for morphological differences (its efficacy varies more between different morphologies) and is more subject to luck (repeated runs on the same morphology show greater variance in the outcomes).},
  archive      = {J_ECJ},
  author       = {van Diggelen, Fuda and Ferrante, Eliseo and Eiben, A. E.},
  doi          = {10.1162/evco_a_00334},
  journal      = {Evolutionary Computation},
  month        = {6},
  number       = {2},
  pages        = {105-124},
  shortjournal = {Evol. Comput.},
  title        = {Comparing robot controller optimization methods on evolvable morphologies},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A practical methodology for reproducible experimentation: An
application to the double-row facility layout problem. <em>ECJ</em>,
<em>32</em>(1), 69–104. (<a
href="https://doi.org/10.1162/evco_a_00317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reproducibility of experiments is a complex task in stochastic methods such as evolutionary algorithms or metaheuristics in general. Many works from the literature give general guidelines to favor reproducibility. However, none of them provide both a practical set of steps or software tools to help in this process. In this article, we propose a practical methodology to favor reproducibility in optimization problems tackled with stochastic methods. This methodology is divided into three main steps, where the researcher is assisted by software tools which implement state-of-the-art techniques related to this process. The methodology has been applied to study the double-row facility layout problem (DRFLP) where we propose a new algorithm able to obtain better results than the state-of-the-art methods. To this aim, we have also replicated the previous methods in order to complete the study with a new set of larger instances. All the produced artifacts related to the methodology and the study of the target problem are available in Zenodo.},
  archive      = {J_ECJ},
  author       = {Martín-Santamaría, Raúl and Cavero, Sergio and Herrán, Alberto and Duarte, Abraham and Colmenar, J. Manuel},
  doi          = {10.1162/evco_a_00317},
  journal      = {Evolutionary Computation},
  month        = {3},
  number       = {1},
  pages        = {69-104},
  shortjournal = {Evol. Comput.},
  title        = {A practical methodology for reproducible experimentation: An application to the double-row facility layout problem},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using decomposed error for reproducing implicit
understanding of algorithms. <em>ECJ</em>, <em>32</em>(1), 49–68. (<a
href="https://doi.org/10.1162/evco_a_00321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reproducibility is important for having confidence in evolutionary machine learning algorithms. Although the focus of reproducibility is usually to recreate an aggregate prediction error score using fixed random seeds, this is not sufficient. Firstly, multiple runs of an algorithm, without a fixed random seed, should ideally return statistically equivalent results. Secondly, it should be confirmed whether the expected behaviour of an algorithm matches its actual behaviour, in terms of how an algorithm targets a reduction in prediction error. Confirming the behaviour of an algorithm is not possible when using a total error aggregate score. Using an error decomposition framework as a methodology for improving the reproducibility of results in evolutionary computation addresses both of these factors. By estimating decomposed error using multiple runs of an algorithm and multiple training sets, the framework provides a greater degree of certainty about the prediction error. Also, decomposing error into bias, variance due to the algorithm (internal variance), and variance due to the training data (external variance) more fully characterises evolutionary algorithms. This allows the behaviour of an algorithm to be confirmed. Applying the framework to a number of evolutionary algorithms shows that their expected behaviour can be different to their actual behaviour. Identifying a behaviour mismatch is important in terms of understanding how to further refine an algorithm as well as how to effectively apply an algorithm to a problem.},
  archive      = {J_ECJ},
  author       = {Owen, Caitlin A. and Dick, Grant and Whigham, Peter A.},
  doi          = {10.1162/evco_a_00321},
  journal      = {Evolutionary Computation},
  month        = {3},
  number       = {1},
  pages        = {49-68},
  shortjournal = {Evol. Comput.},
  title        = {Using decomposed error for reproducing implicit understanding of algorithms},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The importance of being constrained: Dealing with infeasible
solutions in differential evolution and beyond. <em>ECJ</em>,
<em>32</em>(1), 3–48. (<a
href="https://doi.org/10.1162/evco_a_00333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We argue that results produced by a heuristic optimisation algorithm cannot be considered reproducible unless the algorithm fully specifies what should be done with solutions generated outside the domain, even in the case of simple bound constraints. Currently, in the field of heuristic optimisation, such specification is rarely mentioned or investigated due to the assumed triviality or insignificance of this question. Here, we demonstrate that, at least in algorithms based on Differential Evolution, this choice induces notably different behaviours in terms of performance, disruptiveness, and population diversity. This is shown theoretically (where possible) for standard Differential Evolution in the absence of selection pressure and experimentally for the standard and state-of-the-art Differential Evolution variants, on a special test function and the BBOB benchmarking suite, respectively. Moreover, we demonstrate that the importance of this choice quickly grows with problem dimensionality. Differential Evolution is not at all special in this regard—there is no reason to presume that other heuristic optimisers are not equally affected by the aforementioned algorithmic choice. Thus, we urge the heuristic optimisation community to formalise and adopt the idea of a new algorithmic component in heuristic optimisers, which we refer to as the strategy of dealing with infeasible solutions. This component needs to be consistently: (a) specified in algorithmic descriptions to guarantee reproducibility of results, (b) studied to better understand its impact on an algorithm&#39;s performance in a wider sense (i.e., convergence time, robustness, etc.), and (c) included in the (automatic) design of algorithms. All of these should be done even for problems with bound constraints.},
  archive      = {J_ECJ},
  author       = {Kononova, Anna V. and Vermetten, Diederick and Caraffini, Fabio and Mitran, Madalina-A. and Zaharie, Daniela},
  doi          = {10.1162/evco_a_00333},
  journal      = {Evolutionary Computation},
  month        = {3},
  number       = {1},
  pages        = {3-48},
  shortjournal = {Evol. Comput.},
  title        = {The importance of being constrained: Dealing with infeasible solutions in differential evolution and beyond},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial for the special issue on reproducibility.
<em>ECJ</em>, <em>32</em>(1), 1–2. (<a
href="https://doi.org/10.1162/evco_e_00344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experimental research is an essential component in the field of evolutionary computation (EC). The scientific method requires that empirical results are reproducible. Reproducibility of experiments also helps later researchers build upon the work of previous researchers. Interest in improving reproducibility in computer science and other empirical sciences has grown in recent years and there is a growing number of works analyzing current and best practices, obstacles and guidelines, effectiveness of journal policies, etc. Reproducibility issues in the context of EC have been a topic of discussion for a long time in the context of best practices for empirical research, but there are few studies analyzing reproducibility in EC research, and reproducibility studies themselves are extremely rare. There is room for improvement to attain the minimum standards for reproducibility encouraged in other scientific fields. Reproducibility goes beyond making implementation of algorithms publicly available. Challenges for reproducibility in EC research arise from the stochastic nature of the algorithms and, sometimes, the problems, which require multiple runs to analyze expected behavior and variance; sensitivity of the results to the computational environment, parameter settings, or implementation details; and the generalizability of conclusions to different instances of the same or related problems.This special issue of Evolutionary Computation on reproducibility features three exceptional papers that highlight different aspects of reproducibility and how to achieve it in practice.In “Using Decomposed Error for Reproducing Implicit Understanding of Algorithms” (10.1162/evco_a_00321), Caitlin A. Owen, Grant Dick, and Peter A. Whigham propose an error decomposition framework to improve the reproducibility of experiments in evolutionary machine learning. This framework takes into account information about bias, variance due to internal algorithmic choices, and variance due to training data, from multiple runs. The authors examine the behavior of three evolutionary machine learning approaches with this framework, which provides a fine-grained analysis on the decomposition of errors, and allow them to pinpoint mismatched expectations about algorithm behavior.In “The Importance of Being Constrained: Dealing with Infeasible Solutions in Differential Evolution and Beyond” (10.1162/evco_a_00333), Anna V. Kononova, Diederick Vermetten, Fabio Caraffini, Madalina-A. Mitran, and Daniela Zaharie argue that the strategy for dealing with infeasible solutions in constrained optimization problems has a significant impact on the reproducibility of experiments in heuristic optimization, and this impact grows with the dimensionality of the problem.In “A Practical Methodology for Reproducible Experimentation: An Application to the Double-Row Facility Layout Problem” (10.1162/evco_a_00317), Raúl Martín-Santamaría, Sergio Cavero, Alberto Herrán, Abraham Duarte, and J. Manuel Colmenar provide a methodology, and the software implementing it, for carrying out experiments with stochastic optimization methods. They illustrate the methodology on the double-row facility layout problem, reproducing previous results and ensuring that their own new results are fully reproducible.We believe that there is an ongoing cultural shift within computer science in general and within EC in particular, with both reviewers and funding agencies expecting and rewarding reproducibility efforts. The submission guidelines of Evolutionary Computation encourage authors to “ensure reproducibility.” Other journals have adopted “reproducibility boards” and “reproducibility badges.” Some conferences and journals have already gone a step further and require that experiments are reproducible by reviewers before publication. As a result of these efforts, we expect that the good practice standards in EC regarding reproducibility will improve in the next decade.},
  archive      = {J_ECJ},
  author       = {López-Ibáñez, Manuel and Paquete, Luís and Preuss, Mike},
  doi          = {10.1162/evco_e_00344},
  journal      = {Evolutionary Computation},
  month        = {3},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Evol. Comput.},
  title        = {Editorial for the special issue on reproducibility},
  volume       = {32},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
