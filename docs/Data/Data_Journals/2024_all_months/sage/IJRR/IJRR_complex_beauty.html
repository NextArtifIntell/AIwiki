<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJRR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijrr---97">IJRR - 97</h2>
<ul>
<li><details>
<summary>
(2024). A geometric characterization of observability in inertial
parameter identification. <em>The International Journal of Robotics
Research</em>, <em>43</em>(14), 2274–2302. (<a
href="https://doi.org/10.1177/02783649241258215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper presents an algorithm to geometrically characterize inertial parameter identifiability for an articulated robot. The geometric approach tests identifiability across the infinite space of configurations using only a finite set of conditions and without approximation. It can be applied to general open-chain kinematic trees ranging from industrial manipulators to legged robots, and it is the first solution for this broad set of systems that is provably correct. The high-level operation of the algorithm is based on a key observation: Undetectable changes in inertial parameters can be represented as sequences of inertial transfers across the joints. Drawing on the exponential parameterization of rigid-body kinematics, undetectable inertial transfers are analyzed in terms of observability from linear systems theory. This analysis can be applied recursively, and lends an overall complexity of O ( N ) to characterize parameter identifiability for a system of N bodies. Matlab source code for the new algorithm is provided.},
  archive  = {J},
  author   = {Patrick M. Wensing and Günter Niemeyer and Jean-Jacques E. Slotine},
  doi      = {10.1177/02783649241258215},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {14},
  pages    = {2274-2302},
  title    = {A geometric characterization of observability in inertial parameter identification},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Group-k consistent measurement set maximization via maximum
clique over k-uniform hypergraphs for robust multi-robot map merging.
<em>The International Journal of Robotics Research</em>,
<em>43</em>(14), 2245–2273. (<a
href="https://doi.org/10.1177/02783649241256970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper unifies the theory of consistent-set maximization for robust outlier detection in a simultaneous localization and mapping framework. We first describe the notion of pairwise consistency before discussing how a consistency graph can be formed by evaluating pairs of measurements for consistency. Finding the largest set of consistent measurements is transformed into an instance of the maximum clique problem and can be solved relatively quickly using existing maximum-clique solvers. We then generalize our algorithm to check consistency on a group- k basis by using a generalized notion of consistency and using generalized graphs. We also present modified maximum clique algorithms that function over generalized graphs to find the set of measurements that is internally group- k consistent. We address the exponential nature of group- k consistency and present methods that can substantially decrease the number of necessary checks performed when evaluating consistency. We extend our prior work to perform data association, and to multi-agent systems in both simulation and hardware, and provide a comparison with other state-of-the-art methods.},
  archive  = {J},
  author   = {Brendon Forsgren and Michael Kaess and Ram Vasudevan and Timothy W. McLain and Joshua G. Mangelson},
  doi      = {10.1177/02783649241256970},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {14},
  pages    = {2245-2273},
  title    = {Group-k consistent measurement set maximization via maximum clique over k-uniform hypergraphs for robust multi-robot map merging},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal potential shaping on SE(3) via neural ordinary
differential equations on lie groups. <em>The International Journal of
Robotics Research</em>, <em>43</em>(14), 2221–2244. (<a
href="https://doi.org/10.1177/02783649241256044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This work presents a novel approach for the optimization of dynamic systems on finite-dimensional Lie groups. We rephrase dynamic systems as so-called neural ordinary differential equations (neural ODEs), and formulate the optimization problem on Lie groups. A gradient descent optimization algorithm is presented to tackle the optimization numerically. Our algorithm is scalable, and applicable to any finite-dimensional Lie group, including matrix Lie groups. By representing the system at the Lie algebra level, we reduce the computational cost of the gradient computation. In an extensive example, optimal potential energy shaping for control of a rigid body is treated. The optimal control problem is phrased as an optimization of a neural ODE on the Lie group SE (3), and the controller is iteratively optimized. The final controller is validated on a state-regulation task.},
  archive  = {J},
  author   = {Yannik P. Wotte and Federico Califano and Stefano Stramigioli},
  doi      = {10.1177/02783649241256044},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {14},
  pages    = {2221-2244},
  title    = {Optimal potential shaping on SE(3) via neural ordinary differential equations on lie groups},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Electrostatic brakes enable individual joint control of
underactuated, highly articulated robots. <em>The International Journal
of Robotics Research</em>, <em>43</em>(14), 2204–2220. (<a
href="https://doi.org/10.1177/02783649241250362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Highly articulated organisms serve as blueprints for incredibly dexterous mechanisms, but building similarly capable robotic counterparts has been hindered by the difficulties of developing electromechanical actuators with both the high strength and compactness of biological muscle. We develop a stackable electrostatic brake that has comparable specific tension and weight to that of muscles and integrate it into a robotic joint. High degree-of-freedom mechanisms composed of such electrostatic brake enabled joints can then employ established control algorithms to achieve hybrid motor-brake actuated dexterous manipulation. Specifically, our joint design enables a ten degree-of-freedom robot equipped with only one motor to manipulate multiple objects simultaneously. We also show that the use of brakes allows a two-fingered robot to perform in-hand re-positioning of an object 45% more quickly and with 53% lower positioning error than without brakes. Relative to fully actuated robots, robots equipped with such electrostatic brakes will have lower weight, volume, and power consumption yet retain the ability to reach arbitrary joint configurations.},
  archive  = {J},
  author   = {Patrick Lancaster and Christoforos Mavrogiannis and Siddhartha Srinivasa and Joshua R. Smith},
  doi      = {10.1177/02783649241250362},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {14},
  pages    = {2204-2220},
  title    = {Electrostatic brakes enable individual joint control of underactuated, highly articulated robots},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spiral complete coverage path planning based on conformal
slit mapping in multi-connected domains. <em>The International Journal
of Robotics Research</em>, <em>43</em>(14), 2183–2203. (<a
href="https://doi.org/10.1177/02783649241251385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The generation of smoother and shorter spiral complete coverage paths in multi-connected domains is a crucial research topic in path planning for robotic cavity machining and other related fields. Traditional methods for spiral path planning in multi-connected domains typically incorporate a subregion division procedure that leads to excessive subregion bridging, requiring longer, more sharply turning, and unevenly spaced spirals to achieve complete coverage. To address this issue, this paper proposes a novel spiral complete coverage path planning method using conformal slit mapping. It takes advantage of the fact that conformal slit mapping can transform multi-connected domains into regular disks or annuluses without the need for subregion division. Firstly, a slit mapping calculation technique is proposed for segmented cubic spline boundaries with corners. Secondly, a spiral path spacing control method is developed based on the maximum inscribed circle radius between adjacent conformal slit mapping iso-parameters. Thirdly, the spiral coverage path is derived by offsetting iso-parameters. Numerical experiments indicate that our method shares a comparable order-of-magnitude in computation time with the traditional PDE-based spiral complete coverage path method, but it excels in optimizing total path length, smoothness, and spacing consistency. Finally, we performed experiments on cavity milling and dry runs to compare the new method with the traditional PDE-based method in terms of machining duration and steering impact, respectively. The comparison reveals that, with both algorithms achieving complete coverage, the new algorithm reduces machining time and steering impact by 12.34% and 22.78%, respectively, compared with the traditional PDE-based method.},
  archive  = {J},
  author   = {Changqing Shen and Sihao Mao and Bingzhou Xu and Ziwei Wang and Xiaojian Zhang and Sijie Yan and Han Ding},
  doi      = {10.1177/02783649241251385},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {14},
  pages    = {2183-2203},
  title    = {Spiral complete coverage path planning based on conformal slit mapping in multi-connected domains},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed misbehavior monitors for socially organized
autonomous systems. <em>The International Journal of Robotics
Research</em>, <em>43</em>(14), 2145–2182. (<a
href="https://doi.org/10.1177/02783649241242812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In systems in which many heterogeneous agents operate autonomously, with competing goals and without a centralized planner or global information repository, safety and performance can only be guaranteed by “social” rules imposed on the behavior of individual agents. Social laws are structured in a way that they can be verified just by using local information made available to an agent by a small number of its neighbors. Automobile mobility with traffic rules and logistics robots in warehouses are canonical examples of such “regulated autonomy”, but many other fairly-competing autonomous systems are to be expected shortly. In these systems, detecting whether an agent is not abiding by the rules is crucial for raising an alert and taking appropriate countermeasures. However, the limited visibility due to the local nature of the information makes the problem of misbehavior detection hard for any single agent, and only an exchange of information between agents can provide sufficient clues to arrive at a decision. This paper attacks the misbehavior detection problem for a class of socially organized autonomous systems, where the behavior of agents depends on the presence or absence of other neighbors. We propose a solution involving a “local monitor”, which runs on each agent and includes a hybrid observer and a set-valued consensus node. Based on whatever visibility is available, it reconstructs a set-valued occupancy estimate of nearby regions and combines it with communicating neighbors to reach a shared view and a mismatch discovery. We provide a formal framework for describing social rules that unify many different applications and a tool to generate code automatically for local monitors. The technique is demonstrated in various systems, including self-driving cars, autonomous forklifts, and distributed power plants.},
  archive  = {J},
  author   = {Adriano Fagiolini and Gianluca Dini and Federico Massa and Lucia Pallottino and Antonio Bicchi},
  doi      = {10.1177/02783649241242812},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {14},
  pages    = {2145-2182},
  title    = {Distributed misbehavior monitors for socially organized autonomous systems},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified force-impedance control. <em>The International
Journal of Robotics Research</em>, <em>43</em>(13), 2112–2141. (<a
href="https://doi.org/10.1177/02783649241249194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Unified force-impedance control (UFIC) aims at integrating the advantages of impedance control and force control. Compliance and exact force regulation are equally important abilities in modern robot manipulation. The developed passivity-based framework builds on the energy tank concept and is suitable for serial rigid and flexible-joint robots. Furthermore, it is able to deal either with direct force measurements or model-based contact force estimation. Thus, in this theoretical framework, the most relevant practical systems are covered and shown to be stable for arbitrary passive environments. Particular focus is also laid on a robust impedance-based contact/non-contact stabilization methodology that prevents abrupt, unwanted, and potentially dangerous movements of the manipulator in case of contact loss, a well-known problem of both impedance and force control. The validity of the approach is shown in simulation and through various experiments. Our work roots in Haddadin (2015); Schindlbeck and Haddadin (2015), where the basic UFIC regulation controller was proposed. In the present paper, we significantly advance this idea into a complete theoretical UFIC tracking framework, including rigorous stability analysis and extensive experimental evidence.},
  archive  = {J},
  author   = {Sami Haddadin and Erfan Shahriari},
  doi      = {10.1177/02783649241249194},
  journal  = {The International Journal of Robotics Research},
  month    = {11},
  number   = {13},
  pages    = {2112-2141},
  title    = {Unified force-impedance control},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Planning for heterogeneous teams of robots with temporal
logic, capability, and resource constraints. <em>The International
Journal of Robotics Research</em>, <em>43</em>(13), 2089–2111. (<a
href="https://doi.org/10.1177/02783649241247285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper presents a comprehensive approach for planning for teams of heterogeneous robots with different capabilities and the transportation of resources. We use Capability Temporal Logic (CaTL), a formal language that helps express tasks involving robots with multiple capabilities with spatial, temporal, and logical constraints. We extend CaTL to also capture resource constraints, where resources can be divisible and indivisible, for instance, sand and bricks, respectively. Robots transport resources using various storage types, such as uniform (shared storage among resources) and compartmental (individual storage per resource). Robots’ resource transportation capacity is defined based on resource type and robot class. Robot and resource dynamics and the CaTL mission are jointly encoded in a Mixed Integer Linear Programming (MILP), which maximizes disjoint robot and resource robustness while minimizing spurious movement of both. We propose a multi-robustness approach for Multi-Class Signal Temporal Logic (mcSTL), allowing for generalized quantitative semantics across multiple predicate classes. Thus, we compute availability robustness scores for robots and resources separately. Finally, we conduct multiple experiments demonstrating functionality and time performance by varying resources and storage types.},
  archive  = {J},
  author   = {Gustavo A. Cardona and Cristian-Ioan Vasile},
  doi      = {10.1177/02783649241247285},
  journal  = {The International Journal of Robotics Research},
  month    = {11},
  number   = {13},
  pages    = {2089-2111},
  title    = {Planning for heterogeneous teams of robots with temporal logic, capability, and resource constraints},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A framework for collaborative multi-robot mapping using
spectral graph wavelets. <em>The International Journal of Robotics
Research</em>, <em>43</em>(13), 2070–2088. (<a
href="https://doi.org/10.1177/02783649241246847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The exploration of large-scale unknown environments can benefit from the deployment of multiple robots for collaborative mapping. Each robot explores a section of the environment and communicates onboard pose estimates and maps to a central server to build an optimized global multi-robot map. Naturally, inconsistencies can arise between onboard and server estimates due to onboard odometry drift, failures, or degeneracies. The mapping server can correct and overcome such failure cases using computationally expensive operations such as inter-robot loop closure detection and multi-modal mapping. However, the individual robots do not benefit from the collaborative map if the mapping server provides no feedback. Although server updates from the multi-robot map can greatly alleviate the robotic mission strategically, most existing work lacks them, due to their associated computational and bandwidth-related costs. Motivated by this challenge, this paper proposes a novel collaborative mapping framework that enables global mapping consistency among robots and the mapping server. In particular, we propose graph spectral analysis, at different spatial scales, to detect structural differences between robot and server graphs, and to generate necessary constraints for the individual robot pose graphs. Our approach specifically finds the nodes that correspond to the drift’s origin rather than the nodes where the error becomes too large. We thoroughly analyze and validate our proposed framework using several real-world multi-robot field deployments where we show improvements of the onboard system up to 90% and can recover the onboard estimation from localization failures and even from the degeneracies within its estimation.},
  archive  = {J},
  author   = {Lukas Bernreiter and Shehryar Khattak and Lionel Ott and Roland Siegwart and Marco Hutter and Cesar Cadena},
  doi      = {10.1177/02783649241246847},
  journal  = {The International Journal of Robotics Research},
  month    = {11},
  number   = {13},
  pages    = {2070-2088},
  title    = {A framework for collaborative multi-robot mapping using spectral graph wavelets},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reactive collision-free motion generation in joint space via
dynamical systems and sampling-based MPC. <em>The International Journal
of Robotics Research</em>, <em>43</em>(13), 2049–2069. (<a
href="https://doi.org/10.1177/02783649241246557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Dynamical system (DS) based motion planning offers collision-free motion, with closed-loop reactivity thanks to their analytical expression. It ensures that obstacles are not penetrated by reshaping a nominal DS through matrix modulation, which is constructed using continuously differentiable obstacle representations. However, state-of-the-art approaches may suffer from local minima induced by non-convex obstacles, thus failing to scale to complex, high-dimensional joint spaces. On the other hand, sampling-based Model Predictive Control (MPC) techniques provide feasible collision-free paths in joint-space, yet are limited to quasi-reactive scenarios due to computational complexity that grows cubically with space dimensionality and horizon length. To control the robot in the cluttered environment with moving obstacles, and to generate feasible and highly reactive collision-free motion in robots’ joint space, we present an approach for modulating joint-space DS using sampling-based MPC. Specifically, a nominal DS representing an unconstrained desired joint space motion to a target is locally deflected with obstacle-tangential velocity components navigating the robot around obstacles and avoiding local minima. Such tangential velocity components are constructed from receding horizon collision-free paths generated asynchronously by the sampling-based MPC. Notably, the MPC is not required to run constantly, but only activated when the local minima is detected. The approach is validated in simulation and real-world experiments on a 7-DoF robot demonstrating the capability of avoiding concave obstacles, while maintaining local attractor stability in both quasi-static and highly dynamic cluttered environments.},
  archive  = {J},
  author   = {Mikhail Koptev and Nadia Figueroa and Aude Billard},
  doi      = {10.1177/02783649241246557},
  journal  = {The International Journal of Robotics Research},
  month    = {11},
  number   = {13},
  pages    = {2049-2069},
  title    = {Reactive collision-free motion generation in joint space via dynamical systems and sampling-based MPC},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reactive optimal motion planning to anywhere in the presence
of moving obstacles. <em>The International Journal of Robotics
Research</em>, <em>43</em>(13), 2027–2048. (<a
href="https://doi.org/10.1177/02783649241245729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this paper, a novel optimal motion planning framework that enables navigating optimally from any initial, to any final position within confined workspaces with convex, moving obstacles is presented. Our method outputs a smooth velocity vector field, which is then employed as a reference controller in order to sub-optimally avoid moving obstacles. The proposed approach leverages and extends desirable properties of reactive methods in order to provide a provably convergent and safe solution. Our algorithm is evaluated with both static and moving obstacles in synthetic environments and is compared against a variety of existing methods. The efficacy and applicability of the proposed scheme is finally validated in a high-fidelity simulation environment.},
  archive  = {J},
  author   = {Panagiotis Rousseas and Charalampos Bechlioulis and Kostas Kyriakopoulos},
  doi      = {10.1177/02783649241245729},
  journal  = {The International Journal of Robotics Research},
  month    = {11},
  number   = {13},
  pages    = {2027-2048},
  title    = {Reactive optimal motion planning to anywhere in the presence of moving obstacles},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-visual-inertial system: Analysis, calibration, and
estimation. <em>The International Journal of Robotics Research</em>,
<em>43</em>(13), 1995–2026. (<a
href="https://doi.org/10.1177/02783649241245726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this paper, we study state estimation of multi-visual-inertial systems (MVIS) and develop sensor fusion algorithms to optimally fuse an arbitrary number of asynchronous inertial measurement units (IMUs) or gyroscopes and global and/or rolling shutter cameras. We are especially interested in the full calibration of the associated visual-inertial sensors, including the IMU/camera intrinsics and the IMU-IMU/camera spatiotemporal extrinsics as well as the image readout time of rolling-shutter cameras (if used). To this end, we develop a new analytic combined IMU integration with inertial intrinsics—termed ACI 3 —to pre-integrate IMU measurements, which is leveraged to fuse auxiliary IMUs and/or gyroscopes alongside a base IMU. We model the multi-inertial measurements to include all the necessary inertial intrinsic and IMU-IMU spatiotemporal extrinsic parameters, while leveraging IMU-IMU rigid-body constraints to eliminate the necessity of auxiliary inertial poses and thus reducing computational complexity. By performing observability analysis of MVIS, we prove that the standard four unobservable directions remain—no matter how many inertial sensors are used, and also identify, for the first time, degenerate motions for IMU-IMU spatiotemporal extrinsics and auxiliary inertial intrinsics. In addition to extensive simulations that validate our analysis and algorithms, we have built our own MVIS sensor rig and collected over 25 real-world datasets to experimentally verify the proposed calibration against the state-of-the-art calibration method Kalibr. We show that the proposed MVIS calibration is able to achieve competing accuracy with improved convergence and repeatability, which is open sourced to better benefit the community.},
  archive  = {J},
  author   = {Yulin Yang and Patrick Geneva and Guoquan Huang},
  doi      = {10.1177/02783649241245726},
  journal  = {The International Journal of Robotics Research},
  month    = {11},
  number   = {13},
  pages    = {1995-2026},
  title    = {Multi-visual-inertial system: Analysis, calibration, and estimation},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction notice. <em>The International Journal of Robotics
Research</em>, <em>43</em>(12), 1992. (<a
href="https://doi.org/10.1177/02783649241261054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  doi     = {10.1177/02783649241261054},
  journal = {The International Journal of Robotics Research},
  month   = {10},
  number  = {12},
  pages   = {1992},
  title   = {Retraction notice},
  volume  = {43},
  year    = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robot control based on motor primitives: A comparison of two
approaches. <em>The International Journal of Robotics Research</em>,
<em>43</em>(12), 1959–1991. (<a
href="https://doi.org/10.1177/02783649241258782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Motor primitives are fundamental building blocks of a controller which enable dynamic robot behavior with minimal high-level intervention. By treating motor primitives as basic “modules,” different modules can be sequenced or superimposed to generate a rich repertoire of motor behavior. In robotics, two distinct approaches have been proposed: Dynamic Movement Primitives (DMPs) and Elementary Dynamic Actions (EDAs). While both approaches instantiate similar ideas, significant differences also exist. This paper attempts to clarify the distinction and provide a unifying view by delineating the similarities and differences between DMPs and EDAs. We provide nine robot control examples, including sequencing or superimposing movements, managing kinematic redundancy and singularity, control of both position and orientation of the robot’s end-effector, obstacle avoidance, and managing physical interaction. We show that the two approaches clearly diverge in their implementation. We also provide a real-robot demonstration to show how DMPs and EDAs can be combined to get the best of both approaches. With this detailed comparison, we enable researchers to make informed decisions to select the most suitable approach for specific robot tasks and applications.},
  archive  = {J},
  author   = {Moses C. Nah and Johannes Lachner and Neville Hogan},
  doi      = {10.1177/02783649241258782},
  journal  = {The International Journal of Robotics Research},
  month    = {10},
  number   = {12},
  pages    = {1959-1991},
  title    = {Robot control based on motor primitives: A comparison of two approaches},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boundary-aware value function generation for safe stochastic
motion planning. <em>The International Journal of Robotics
Research</em>, <em>43</em>(12), 1936–1958. (<a
href="https://doi.org/10.1177/02783649241238766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Navigation safety is critical for many autonomous systems such as self-driving vehicles in an urban environment. It requires an explicit consideration of boundary constraints that describe the borders of any infeasible, non-navigable, or unsafe regions. We propose a principled boundary-aware safe stochastic planning framework with promising results. Our method generates a value function that can strictly distinguish the state values between free (safe) and non-navigable (boundary) spaces in the continuous state, naturally leading to a safe boundary-aware policy. At the core of our solution lies a seamless integration of finite elements and kernel-based functions, where the finite elements allow us to characterize safety-critical states’ borders accurately, and the kernel-based function speeds up computation for the non-safety-critical states. The proposed method was evaluated through extensive simulations and demonstrated safe navigation behaviors in mobile navigation tasks. Additionally, we demonstrate that our approach can maneuver safely and efficiently in cluttered real-world environments using a ground vehicle with strong external disturbances, such as navigating on a slippery floor and against external human intervention.},
  archive  = {J},
  author   = {Junhong Xu and Kai Yin and Jason M. Gregory and Kris Hauser and Lantao Liu},
  doi      = {10.1177/02783649241238766},
  journal  = {The International Journal of Robotics Research},
  month    = {10},
  number   = {12},
  pages    = {1936-1958},
  title    = {Boundary-aware value function generation for safe stochastic motion planning},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proprioceptive learning with soft polyhedral networks.
<em>The International Journal of Robotics Research</em>,
<em>43</em>(12), 1916–1935. (<a
href="https://doi.org/10.1177/02783649241238765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Proprioception is the “sixth sense” that detects limb postures with motor neurons. It requires a natural integration between the musculoskeletal systems and sensory receptors, which is challenging among modern robots that aim for lightweight, adaptive, and sensitive designs at low costs in mechanical design and algorithmic computation. Here, we present the Soft Polyhedral Network with an embedded vision for physical interactions, capable of adaptive kinesthesia and viscoelastic proprioception by learning kinetic features. This design enables passive adaptations to omni-directional interactions, visually captured by a miniature high-speed motion-tracking system embedded inside for proprioceptive learning. The results show that the soft network can infer real-time 6D forces and torques with accuracies of 0.25/0.24/0.35 N and 0.025/0.034/0.006 Nm in dynamic interactions. We also incorporate viscoelasticity in proprioception during static adaptation by adding a creep and relaxation modifier to refine the predicted results. The proposed soft network combines simplicity in design, omni-adaptation, and proprioceptive sensing with high accuracy, making it a versatile solution for robotics at a low material cost with more than one million use cycles for tasks such as sensitive and competitive grasping and touch-based geometry reconstruction. This study offers new insights into vision-based proprioception for soft robots in adaptive grasping, soft manipulation, and human-robot interaction.},
  archive  = {J},
  author   = {Xiaobo Liu and Xudong Han and Wei Hong and Fang Wan and Chaoyang Song},
  doi      = {10.1177/02783649241238765},
  journal  = {The International Journal of Robotics Research},
  month    = {10},
  number   = {12},
  pages    = {1916-1935},
  title    = {Proprioceptive learning with soft polyhedral networks},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling and control of a novel variable stiffness three
DoFs wrist. <em>The International Journal of Robotics Research</em>,
<em>43</em>(12), 1898–1915. (<a
href="https://doi.org/10.1177/02783649241236204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This study introduces an innovative design for a Variable Stiffness 3 Degrees of Freedom actuated wrist capable of actively and continuously adjusting its overall stiffness by modulating the active length of non-linear elastic elements. This modulation is akin to human muscular cocontraction and is achieved using only four motors. The mechanical configuration employed results in a compact and lightweight device with anthropomorphic characteristics, making it potentially suitable for applications such as prosthetics and humanoid robotics. This design aims to enhance performance in dynamic tasks, improve task adaptability, and ensure safety during interactions with both people and objects. The paper details the first hardware implementation of the proposed design, providing insights into the theoretical model, mechanical and electronic components, as well as the control architecture. System performance is assessed using a motion capture system. The results demonstrate that the prototype offers a broad range of motion ([55, −45]° for flexion/extension, ±48° for radial/ulnar deviation, and ±180° for pronation/supination) while having the capability to triple its stiffness. Furthermore, following proper calibration, the wrist posture can be reconstructed through multivariate linear regression using rotational encoders and the forward kinematic model. This reconstruction achieves an average Root Mean Square Error of 6.6°, with an R 2 value of 0.93.},
  archive  = {J},
  author   = {Giuseppe Milazzo and Manuel G. Catalano and Antonio Bicchi and Giorgio Grioli},
  doi      = {10.1177/02783649241236204},
  journal  = {The International Journal of Robotics Research},
  month    = {10},
  number   = {12},
  pages    = {1898-1915},
  title    = {Modeling and control of a novel variable stiffness three DoFs wrist},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ergonomically optimized path-planning for industrial
human–robot collaboration. <em>The International Journal of Robotics
Research</em>, <em>43</em>(12), 1884–1897. (<a
href="https://doi.org/10.1177/02783649241235670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper focuses on improving the ergonomics of industrial workers. It addresses the critical implications of poor ergonomics, which can lead to musculoskeletal disorders over time. A novel methodology for a path-planning algorithm designed for human–robot collaboration was introduced to tackle this challenge. The algorithm’s essential contribution lies in determining the most ergonomic path for a robot to guide a human’s hand during task execution, facilitating a transition toward an optimized body configuration. The algorithm effectively charts the ergonomic path by adopting a Cartesian path-planning approach and employing the cell decomposition method. The methodology was implemented on a dataset of ten individuals, representing a diverse group of male and female subjects aged between 20 and 35, with one participant being left-handed. The algorithm was applied to three different activities: “stacking an item,” “taking an object from a shelf,” and “assembling an object by sitting over a table.” The results demonstrated a significant improvement in the REBA score (as a measure of ergonomics condition) of the individuals after applying the algorithm. This outcome reinforces the efficacy of the methodology in enhancing the ergonomics of industrial workers. Furthermore, the study compared the performance of A* with three heuristic functions against Dijkstra’s algorithm, aiming to identify the most effective approach for achieving optimal ergonomic paths in human–robot collaboration. The findings revealed that A* with a specific heuristic function surpassed Dijkstra’s algorithm, underscoring its superiority in this context. The findings highlight the potential for optimizing human–robot collaboration and offer practical implications for designing more efficient industrial work environments.},
  archive  = {J},
  author   = {Atieh Merikh Nejadasl and Jihad Achaoui and Ilias El Makrini and Greet Van De Perre and Tom Verstraten and Bram Vanderborght},
  doi      = {10.1177/02783649241235670},
  journal  = {The International Journal of Robotics Research},
  month    = {10},
  number   = {12},
  pages    = {1884-1897},
  title    = {Ergonomically optimized path-planning for industrial human–robot collaboration},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HeLiPR: Heterogeneous LiDAR dataset for inter-LiDAR place
recognition under spatiotemporal variations. <em>The International
Journal of Robotics Research</em>, <em>43</em>(12), 1867–1883. (<a
href="https://doi.org/10.1177/02783649241242136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Place recognition is crucial for robot localization and loop closure in simultaneous localization and mapping (SLAM). Light Detection and Ranging (LiDAR), known for its robust sensing capabilities and measurement consistency even in varying illumination conditions, has become pivotal in various fields, surpassing traditional imaging sensors in certain applications. Among various types of LiDAR, spinning LiDARs are widely used, while non-repetitive scanning patterns have recently been utilized in robotics applications. Some LiDARs provide additional measurements such as reflectivity, Near Infrared (NIR), and velocity from Frequency modulated continuous wave (FMCW) LiDARs. Despite these advances, there is a lack of comprehensive datasets reflecting the broad spectrum of LiDAR configurations for place recognition. To tackle this issue, our paper proposes the HeLiPR dataset, curated especially for place recognition with heterogeneous LiDARs, embodying spatiotemporal variations. To the best of our knowledge, the HeLiPR dataset is the first heterogeneous LiDAR dataset supporting inter-LiDAR place recognition with both non-repetitive and spinning LiDARs, accommodating different field of view (FOV)s and varying numbers of rays. The dataset covers diverse environments, from urban cityscapes to high-dynamic freeways, over a month, enhancing adaptability and robustness across scenarios. Notably, HeLiPR dataset includes trajectories parallel to MulRan sequences, making it valuable for research in heterogeneous LiDAR place recognition and long-term studies. The dataset is accessible at https://sites.google.com/view/heliprdataset .},
  archive  = {J},
  author   = {Minwoo Jung and Wooseong Yang and Dongjae Lee and Hyeonjae Gil and Giseop Kim and Ayoung Kim},
  doi      = {10.1177/02783649241242136},
  journal  = {The International Journal of Robotics Research},
  month    = {10},
  number   = {12},
  pages    = {1867-1883},
  title    = {HeLiPR: Heterogeneous LiDAR dataset for inter-LiDAR place recognition under spatiotemporal variations},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MUN-FRL: A visual-inertial-LiDAR dataset for aerial
autonomous navigation and mapping. <em>The International Journal of
Robotics Research</em>, <em>43</em>(12), 1853–1866. (<a
href="https://doi.org/10.1177/02783649241238358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper presents a unique outdoor aerial visual-inertial-LiDAR dataset captured using a multi-sensor payload to promote the global navigation satellite system (GNSS)-denied navigation research. The dataset features flight distances ranging from 300 m to 5 km, collected using a DJI-M600 hexacopter drone and the National Research Council (NRC) Bell412 Advanced Systems Research Aircraft (ASRA). The dataset consists of hardware-synchronized monocular images, inertial measurement unit (IMU) measurements, 3D light detection and ranging (LiDAR) point-clouds, and high-precision real-time kinematic (RTK)-GNSS based ground truth. Nine data sequences were collected as robot operating system (ROS) bags over 100 mins of outdoor environment footage ranging from urban areas, highways, airports, hillsides, prairies, and waterfronts. The dataset was collected to facilitate the development of visual-inertial-LiDAR odometry and mapping algorithms, visual-inertial navigation algorithms, object detection, segmentation, and landing zone detection algorithms based on real-world drone and full-scale helicopter data. All the data sequences contain raw sensor measurements, hardware timestamps, and spatio-temporally aligned ground truth. The intrinsic and extrinsic calibrations of the sensors are also provided, along with raw calibration datasets. A performance summary of state-of-the-art methods applied on the data sequences is also provided.},
  archive  = {J},
  author   = {Ravindu G Thalagala and Oscar De Silva and Awantha Jayasiri and Arthur Gubbels and George KI Mann and Raymond G Gosine},
  doi      = {10.1177/02783649241238358},
  journal  = {The International Journal of Robotics Research},
  month    = {10},
  number   = {12},
  pages    = {1853-1866},
  title    = {MUN-FRL: A visual-inertial-LiDAR dataset for aerial autonomous navigation and mapping},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimal configuration point cloud odometry and mapping.
<em>The International Journal of Robotics Research</em>,
<em>43</em>(11), 1831–1850. (<a
href="https://doi.org/10.1177/02783649241235325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Simultaneous Localization and Mapping (SLAM) refers to the common requirement for autonomous platforms to estimate their pose and map their surroundings. There are many robust and real-time methods available for solving the SLAM problem. Most are divided into a front-end, which performs incremental pose estimation, and a back-end, which smooths and corrects the results. A low-drift front-end odometry solution is needed for robust and accurate back-end performance. Front-end methods employ various techniques, such as point cloud-to-point cloud (PC2PC) registration, key feature extraction and matching, and deep learning-based approaches. The front-end algorithms have become increasingly complex in the search for low-drift solutions and many now have large configuration parameter sets. It is desirable that the front-end algorithm should be inherently robust so that it does not need to be tuned by several, perhaps many, configuration parameters to achieve low drift in various environments. To address this issue, we propose Simple Mapping and Localization Estimation (SiMpLE), a front-end LiDAR-only odometry method that requires five low-sensitivity configurable parameters. SiMpLE is a scan-to-map point cloud registration algorithm that is straightforward to understand, configure, and implement. We evaluate SiMpLE using the KITTI, MulRan, UrbanNav, and a dataset created at the University of Queensland. SiMpLE performs among the top-ranked algorithms in the KITTI dataset and outperformed all prominent open-source approaches in the MulRan dataset whilst having the smallest configuration set. The UQ dataset also demonstrated accurate odometry with low-density point clouds using Velodyne VLP-16 and Livox Horizon LiDARs. SiMpLE is a front-end odometry solution that can be integrated with other sensing modalities and pose graph-based back-end methods for increased accuracy and long-term mapping. The lightweight and portable code for SiMpLE is available at: https://github.com/vb44/SiMpLE .},
  archive  = {J},
  author   = {Vedant Bhandari and Tyson Govan Phillips and Peter Ross McAree},
  doi      = {10.1177/02783649241235325},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {11},
  pages    = {1831-1850},
  title    = {Minimal configuration point cloud odometry and mapping},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scaling effects of manufacturing processes and actuation
sources on control of remotely powered micro actuators. <em>The
International Journal of Robotics Research</em>, <em>43</em>(11),
1809–1830. (<a href="https://doi.org/10.1177/02783649241235215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Over the past decade, remotely powered micro actuators have gained increased attention for biomedical and environmental remediation applications, owing to their ability to access confined regions and the nonintrusive nature of control. Recent studies focus on improving the functionality and versatility of micro actuators through the development of new fabrication and actuation techniques. However, there is a possibility that a limited understanding of the scaling impact of various physical principles governing design and control has affected the successful implementation of such devices in practical scenarios. Thus, the main focus of this review is to evaluate the most widely utilized manufacturing methods and remote actuation sources in light of various characteristics such as resolution, productivity, shape complexity, actuation speed, actuation mode, operating medium, and so on. State-of-the-art developments in each type of manufacturing and actuation are introduced and delineated. Finally, the limitations of current devices are reviewed, and the future direction to enable the full potential of this field is provided.},
  archive  = {J},
  author   = {Jae-Kyung Heo and Kausthubharam and Minyong Jung and Wonjin Kim and Suhwan Jeong and Dae-Seob Song and Ying-Jun Quan and Ji Ho Jeon and Rodrigo Ribeiro de Moura and Sung-Hoon Ahn},
  doi      = {10.1177/02783649241235215},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {11},
  pages    = {1809-1830},
  title    = {Scaling effects of manufacturing processes and actuation sources on control of remotely powered micro actuators},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AstroSLAM: Autonomous monocular navigation in the vicinity
of a celestial small body—theory and experiments. <em>The International
Journal of Robotics Research</em>, <em>43</em>(11), 1770–1808. (<a
href="https://doi.org/10.1177/02783649241234367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We propose AstroSLAM, a standalone vision-based solution for autonomous online navigation around an unknown celestial target small body. AstroSLAM is predicated on the formulation of the SLAM problem as an incrementally growing factor graph, facilitated by the use of the GTSAM library and the iSAM2 engine. By combining sensor fusion with orbital motion priors, we achieve improved performance over a baseline SLAM solution and outperform state-of-the-art methods predicated on pre-integrated inertial measurement unit factors. We incorporate orbital motion constraints into the factor graph by devising a novel relative dynamics—RelDyn—factor, which links the relative pose of the spacecraft to the problem of predicting trajectories stemming from the motion of the spacecraft in the vicinity of the small body. We demonstrate AstroSLAM’s performance and compare against the state-of-the-art methods using both real legacy mission imagery and trajectory data courtesy of NASA’s Planetary Data System, as well as real in-lab imagery data produced on a 3 degree-of-freedom spacecraft simulator test-bed.},
  archive  = {J},
  author   = {Mehregan Dor and Travis Driver and Kenneth Getzandanner and Panagiotis Tsiotras},
  doi      = {10.1177/02783649241234367},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {11},
  pages    = {1770-1808},
  title    = {AstroSLAM: Autonomous monocular navigation in the vicinity of a celestial small body—Theory and experiments},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Compliance while resisting: A shear-thickening fluid
controller for physical human-robot interaction. <em>The International
Journal of Robotics Research</em>, <em>43</em>(11), 1731–1769. (<a
href="https://doi.org/10.1177/02783649241234364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Physical human-robot interaction (pHRI) is widely needed in many fields, such as industrial manipulation, home services, and medical rehabilitation, and puts higher demands on the safety of robots. Due to the uncertainty of the working environment, the pHRI may receive unexpected impact interference, which affects the safety and smoothness of the task execution. The commonly used linear admittance control (L-AC) can cope well with high-frequency small-amplitude noise, but for medium-frequency high-intensity impact, the effect is not as good. Inspired by the solid-liquid phase change nature of shear-thickening fluid, we propose a shear-thickening fluid control (SFC) that can achieve both an easy human-robot collaboration and resistance to impact interference. The SFC’s stability, passivity, and phase trajectory are analyzed in detail, the frequency and time domain properties are quantified, and parameter constraints in discrete control and coupled stability conditions are provided. We conducted simulations to compare the frequency and time domain characteristics of L-AC, nonlinear admittance controller (N-AC), and SFC and validated their dynamic properties. In real-world experiments, we compared the performance of L-AC, N-AC, and SFC in both fixed and mobile manipulators. L-AC exhibits weak resistance to impact. N-AC can resist moderate impacts but not high-intensity ones and may exhibit self-excited oscillations. In contrast, SFC demonstrated superior impact resistance and maintained stable collaboration, enhancing comfort in cooperative water delivery tasks. Additionally, a case study was conducted in a factory setting, further affirming the SFC’s capability in facilitating human-robot collaborative manipulation and underscoring its potential in industrial applications.},
  archive  = {J},
  author   = {Lu Chen and Lipeng Chen and Xiangchi Chen and Haojian Lu and Yu Zheng and Jun Wu and Yue Wang and Zhengyou Zhang and Rong Xiong},
  doi      = {10.1177/02783649241234364},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {11},
  pages    = {1731-1769},
  title    = {Compliance while resisting: A shear-thickening fluid controller for physical human-robot interaction},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RoBUTCHER: A novel robotic meat factory cell platform.
<em>The International Journal of Robotics Research</em>,
<em>43</em>(11), 1711–1730. (<a
href="https://doi.org/10.1177/02783649241234035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Automation is critically important for sustainability in meat production, where heavy reliance on human labour is a growing challenge. In this work, a novel robotic Meat Factory Cell (MFC) platform presents the opportunity for unconventional automation in pork meat processing, particularly abattoirs. Instead of following line-based approaches, which are the main option today, it uses robotics and Artificial Intelligence (AI) to perform complex cutting and manipulation operations on entire unchilled pork carcasses, with awareness of biological variation and deformation. The long-term goal of the MFC is to take a pork carcass as an input and produce seven primal outputs: hams, shoulders, saddle, belly and entire organ set. However, the MFC platform is under continuous development – therefore, this paper aims to demonstrate it through a specific use-case: shoulder removal . The system is evaluated based on data from testing and development sessions (June–November 2022), with a total of 34 attempted shoulder removals. Data regarding the MFCs’ ability to handle variation, in addition to success rate and process timing models are presented. Qualitative feedback from skilled butchers is also discussed. The authors propose that, as well as technical development of the platform, it is important to consider new ways of comparing unconventional systems with their conventional counterparts. Innovative manufacturing systems have more to offer than raw speed and volume; traits such as flexibility, robustness and scalability – particularly economic scalability – should play a prominent role. Future legislation and standards must also encourage innovation rather than hinder innovative robotics solutions.},
  archive  = {J},
  author   = {Alex Mason and Ian de Medeiros Esper and Olga Korostynska and Luis Eduardo Cordova-Lopez and Dmytro Romanov and Michaela Pinceková and Per Håkon Bjørnstad and Ole Alvseike and Anton Popov and Oleh Smolkin and Maksym Manko and Lars Bager Christensen and Kristóf Takács and Tamás Haidegger},
  doi      = {10.1177/02783649241234035},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {11},
  pages    = {1711-1730},
  title    = {RoBUTCHER: A novel robotic meat factory cell platform},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Magnetic needle steering control using lyapunov redesign.
<em>The International Journal of Robotics Research</em>,
<em>43</em>(11), 1676–1692. (<a
href="https://doi.org/10.1177/02783649241231600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Using steerable needles to enable course correction and curved trajectories can improve surgical outcomes in numerous clinical interventions including electrode placement for deep brain stimulation. In this work, a physically motivated kinematic model for an actively steered magnetic-tipped needle is used in closed-loop control to perform insertion trajectories. The applied control law is derived using the Lyapunov redesign. Simulation results show this control method to be accurate for a wide range of conditions including randomized target trajectories. Control is performed experimentally in a brain tissue phantom for both initial position offset recovery and curved trajectories. Converged error results average 0.52 mm from target trajectory. Simulation results demonstrate the robustness of the control implementation, while experimental results exceed the accuracy required for the target application, encouraging future use in a clinical setting. Beyond needle insertion, this work has implications in general vehicle steering, as this model and control can apply to systems with similar kinematics such as boats and wheeled vehicles that could benefit from a relaxed slip constraint.},
  archive  = {J},
  author   = {Richard L. Pratt and Andrew J. Petruska},
  doi      = {10.1177/02783649241231600},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {11},
  pages    = {1676-1692},
  title    = {Magnetic needle steering control using lyapunov redesign},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A three degrees of freedom switchable impedance myoelectric
prosthetic wrist. <em>The International Journal of Robotics
Research</em>, <em>43</em>(11), 1649–1675. (<a
href="https://doi.org/10.1177/02783649241231298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Wrist mobility contributes significantly to the execution of upper limb motor tasks. Despite this, current prosthetic wrists are far less advanced than other artificial joints. Typically, prosthetic wrists offer limited degrees of freedom, if any, which forces users to execute compensatory movements during task performance. This addition increases weight and complexity, two unwelcome factors in upper limb prostheses. This article presents the design of a 3-degree-of-freedom friction-lockable prosthetic wrist actuated by a single motor. The design features adaptable behavior when unlocked, promoting a gentle interaction with the environment, and enables users to adjust the hand configuration during pre-grasping phases. The proposed system was tested, combined with a hand prosthesis, and compared to a commercial rotational wrist during the execution of functional movements. Experiments involved nine able-bodied subjects and one prosthesis user. Participants also performed the experiments with their biological wrist (the intact wrist for the prosthesis user) as a control. Results showed that the lockable wrist was used actively 20% more often than the commercial solution without compromising users’ execution time. Interaction tests reveal that compensatory movements are reduced when using the proposed design, resulting in closer resemblance to the control wrist’s performance. The average satisfaction and usability scores were significantly higher for the proposed wrist, indicating its potential acceptance. Finally, the system was validated in a set of activities of daily living performed by the prosthesis user. The study contributes to the development of more intuitive and adaptable prostheses that can improve the quality of life of amputees.},
  archive  = {J},
  author   = {Patricia Capsi-Morales and Cristina Piazza and Giorgio Grioli and Antonio Bicchi and Manuel G. Catalano},
  doi      = {10.1177/02783649241231298},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {11},
  pages    = {1649-1675},
  title    = {A three degrees of freedom switchable impedance myoelectric prosthetic wrist},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-linearity measure for POMDP-based motion planning.
<em>The International Journal of Robotics Research</em>,
<em>43</em>(10), 1629–1646. (<a
href="https://doi.org/10.1177/02783649241239077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Motion planning under uncertainty is essential for reliable robot operation. Despite substantial advances over the past decade, the problem remains difficult for systems with complex dynamics. Most state-of-the-art methods perform search that relies on a large number of forward simulations. For systems with complex dynamics, this generally requires costly numerical integrations, which significantly slows down the planning process. Linearization-based methods have been proposed that can alleviate the above problem. However, it is not clear how linearization affects the quality of the generated motion strategy, and when such simplifications are admissible. To answer these questions, we propose a non-linearity measure, called Statistical-distance-based Non-linearity Measure (SNM), that can identify where linearization is beneficial and where it should be avoided. We show that when the problem is framed as the Partially Observable Markov Decision Process, the value difference between the optimal strategy for the original model and the linearized model can be upper-bounded by a function linear in SNM. Comparisons with an existing measure on various scenarios indicate that SNM is more suitable in estimating the effectiveness of linearization-based solvers. To test the applicability of SNM in motion planning, we propose a simple online planner that uses SNM as a heuristic to switch between a general and a linearization-based solver. Results on a car-like robot with second order dynamics and 4-DOFs and 7-DOFs torque-controlled manipulators indicate that SNM can appropriately decide if and when a linearization-based solver should be used.},
  archive  = {J},
  author   = {Marcus Hoerger and Hanna Kurniawati and Alberto Elfes},
  doi      = {10.1177/02783649241239077},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10},
  pages    = {1629-1646},
  title    = {Non-linearity measure for POMDP-based motion planning},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Set-valued rigid-body dynamics for simultaneous, inelastic,
frictional impacts. <em>The International Journal of Robotics
Research</em>, <em>43</em>(10), 1594–1628. (<a
href="https://doi.org/10.1177/02783649241236860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Robotic manipulation and locomotion often entail nearly-simultaneous collisions—such as heel and toe strikes during a foot step—with outcomes that are extremely sensitive to the order in which impacts occur. Robotic simulators and state estimation commonly lack the fidelity and accuracy to predict this ordering, and instead pick one with a heuristic. This discrepancy degrades performance when model-based controllers and policies learned in simulation are placed on a real robot. We reconcile this issue with a set-valued rigid-body model which generates a broad set of outcomes to simultaneous frictional impacts with any impact ordering. We first extend Routh’s impact model to multiple impacts by reformulating it as a differential inclusion (DI), and show that any solution will resolve all impacts in finite time. By considering time as a state, we embed this model into another DI which captures the continuous-time evolution of rigid-body dynamics, and guarantee existence of solutions. We finally cast simulation of simultaneous impacts as a linear complementarity problem (LCP), and develop an algorithm for tight approximation of the post-impact velocity set with probabilistic guarantees. We demonstrate our approach on several examples drawn from manipulation and legged locomotion, and compare the predictions to other models of rigid and compliant collisions.},
  archive  = {J},
  author   = {Mathew Halm and Michael Posa},
  doi      = {10.1177/02783649241236860},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10},
  pages    = {1594-1628},
  title    = {Set-valued rigid-body dynamics for simultaneous, inelastic, frictional impacts},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decentralized state estimation: An approach using
pseudomeasurements and preintegration. <em>The International Journal of
Robotics Research</em>, <em>43</em>(10), 1573–1593. (<a
href="https://doi.org/10.1177/02783649241230993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper addresses the problem of decentralized, collaborative state estimation in robotic teams. In particular, this paper considers problems where individual robots estimate similar physical quantities, such as each other’s position relative to themselves. The use of pseudomeasurements is introduced as a means of modeling such relationships between robots’ state estimates and is shown to be a tractable way to approach the decentralized state estimation problem. Moreover, this formulation easily leads to a general-purpose observability test that simultaneously accounts for measurements that robots collect from their own sensors, as well as the communication structure within the team. Finally, input preintegration is proposed as a communication-efficient way of sharing odometry information between robots, and the entire theory is appropriate for both vector-space and Lie-group state definitions. To overcome the need for communicating preintegrated covariance information, a deep autoencoder is proposed that reconstructs the covariance information from the inputs, hence further reducing the communication requirements. The proposed framework is evaluated on three different simulated problems, and one experiment involving three quadcopters.},
  archive  = {J},
  author   = {Charles Champagne Cossette and Mohammed Ayman Shalaby and David Saussié and James Richard Forbes},
  doi      = {10.1177/02783649241230993},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10},
  pages    = {1573-1593},
  title    = {Decentralized state estimation: An approach using pseudomeasurements and preintegration},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on socially aware robot navigation: Taxonomy and
future challenges. <em>The International Journal of Robotics
Research</em>, <em>43</em>(10), 1533–1572. (<a
href="https://doi.org/10.1177/02783649241230562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Socially aware robot navigation is gaining popularity with the increase in delivery and assistive robots. The research is further fueled by a need for socially aware navigation skills in autonomous vehicles to move safely and appropriately in spaces shared with humans. Although most of these are ground robots, drones are also entering the field. In this paper, we present a literature survey of the works on socially aware robot navigation in the past 10 years. We propose four different faceted taxonomies to navigate the literature and examine the field from four different perspectives. Through the taxonomic review, we discuss the current research directions and the extending scope of applications in various domains. Further, we put forward a list of current research opportunities and present a discussion on possible future challenges that are likely to emerge in the field.},
  archive  = {J},
  author   = {Phani Teja Singamaneni and Pilar Bachiller-Burgos and Luis J. Manso and Anaís Garrell and Alberto Sanfeliu and Anne Spalanzani and Rachid Alami},
  doi      = {10.1177/02783649241230562},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10},
  pages    = {1533-1572},
  title    = {A survey on socially aware robot navigation: Taxonomy and future challenges},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The surface edge explorer (SEE): A measurement-direct
approach to next best view planning. <em>The International Journal of
Robotics Research</em>, <em>43</em>(10), 1506–1532. (<a
href="https://doi.org/10.1177/02783649241230098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {High-quality observations of the real world are crucial for a variety of applications, including producing 3D printed replicas of small-scale scenes and conducting inspections of large-scale infrastructure. These 3D observations are commonly obtained by combining multiple sensor measurements from different views. Guiding the selection of suitable views is known as the Next Best View (NBV) planning problem. Most NBV approaches reason about measurements using rigid data structures (e.g., surface meshes or voxel grids). This simplifies next best view selection but can be computationally expensive, reduces real-world fidelity and couples the selection of a next best view with the final data processing. This paper presents the Surface Edge Explorer (SEE), a NBV approach that selects new observations directly from previous sensor measurements without requiring rigid data structures. SEE uses measurement density to propose next best views that increase coverage of insufficiently observed surfaces while avoiding potential occlusions. Statistical results from simulated experiments show that SEE can attain similar or better surface coverage with less observation time and travel distance than evaluated volumetric approaches on both small- and large-scale scenes. Real-world experiments demonstrate SEE autonomously observing a deer statue using a 3D sensor affixed to a robotic arm.},
  archive  = {J},
  author   = {Rowan Border and Jonathan D. Gammell},
  doi      = {10.1177/02783649241230098},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10},
  pages    = {1506-1532},
  title    = {The surface edge explorer (SEE): A measurement-direct approach to next best view planning},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Foundations of spatial perception for robotics: Hierarchical
representations and real-time systems. <em>The International Journal of
Robotics Research</em>, <em>43</em>(10), 1457–1505. (<a
href="https://doi.org/10.1177/02783649241229725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {3D spatial perception is the problem of building and maintaining an actionable and persistent representation of the environment in real-time using sensor data and prior knowledge. Despite the fast-paced progress in robot perception, most existing methods either build purely geometric maps (as in traditional SLAM) or “flat” metric-semantic maps that do not scale to large environments or large dictionaries of semantic labels. The first part of this paper is concerned with representations: we show that scalable representations for spatial perception need to be hierarchical in nature. Hierarchical representations are efficient to store, and lead to layered graphs with small treewidth , which enable provably efficient inference. We then introduce an example of hierarchical representation for indoor environments, namely a 3D scene graph , and discuss its structure and properties. The second part of the paper focuses on algorithms to incrementally construct a 3D scene graph as the robot explores the environment. Our algorithms combine 3D geometry (e.g., to cluster the free space into a graph of places), topology (to cluster the places into rooms), and geometric deep learning (e.g., to classify the type of rooms the robot is moving across). The third part of the paper focuses on algorithms to maintain and correct 3D scene graphs during long-term operation. We propose hierarchical descriptors for loop closure detection and describe how to correct a scene graph in response to loop closures, by solving a 3D scene graph optimization problem . We conclude the paper by combining the proposed perception algorithms into Hydra , a real-time spatial perception system that builds a 3D scene graph from visual-inertial data in real-time. We showcase Hydra’s performance in photo-realistic simulations and real data collected by a Clearpath Jackal robots and a Unitree A1 robot. We release an open-source implementation of Hydra at https://github.com/MIT-SPARK/Hydra .},
  archive  = {J},
  author   = {Nathan Hughes and Yun Chang and Siyi Hu and Rajat Talak and Rumaia Abdulhai and Jared Strader and Luca Carlone},
  doi      = {10.1177/02783649241229725},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10},
  pages    = {1457-1505},
  title    = {Foundations of spatial perception for robotics: Hierarchical representations and real-time systems},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UTIL: An ultra-wideband time-difference-of-arrival indoor
localization dataset. <em>The International Journal of Robotics
Research</em>, <em>43</em>(10), 1443–1456. (<a
href="https://doi.org/10.1177/02783649241230640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Ultra-wideband (UWB) time-difference-of-arrival (TDOA)-based localization has emerged as a promising, low-cost, and scalable indoor localization solution, which is especially suited for multi-robot applications. However, there is a lack of public datasets to study and benchmark UWB TDOA positioning technology in cluttered indoor environments. We fill in this gap by presenting a comprehensive dataset using Decawave’s DWM1000 UWB modules. To characterize the UWB TDOA measurement performance under various line-of-sight (LOS) and non-line-of-sight (NLOS) conditions, we collected signal-to-noise ratio (SNR), power difference values, and raw UWB TDOA measurements during the identification experiments. We also conducted a cumulative total of around 150 min of real-world flight experiments on a customized quadrotor platform to benchmark the UWB TDOA localization performance for mobile robots. The quadrotor was commanded to fly with an average speed of 0.45 m/s in both obstacle-free and cluttered environments using four different UWB anchor constellations. Raw sensor data including UWB TDOA, inertial measurement unit (IMU), optical flow, time-of-flight (ToF) laser altitude, and millimeter-accurate ground truth robot poses were collected during the flights. The dataset and development kit are available at https://utiasdsl.github.io/util-uwb-dataset/ .},
  archive  = {J},
  author   = {Wenda Zhao and Abhishek Goudar and Xinyuan Qiao and Angela P. Schoellig},
  doi      = {10.1177/02783649241230640},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10},
  pages    = {1443-1456},
  title    = {UTIL: An ultra-wideband time-difference-of-arrival indoor localization dataset},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lane-level route planning for autonomous vehicles. <em>The
International Journal of Robotics Research</em>, <em>43</em>(9),
1425–1440. (<a href="https://doi.org/10.1177/02783649231225474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We present an algorithm that, given a representation of a road network in lane-level detail, computes a route that minimizes the expected cost to reach a given destination. In doing so, our algorithm allows us to solve for the complex trade-offs encountered when trying to decide not just which roads to follow, but also when to change between the lanes making up these roads, in order to—for example—reduce the likelihood of missing a left exit while not unnecessarily driving in the leftmost lane. This routing problem can naturally be formulated as a Markov Decision Process (MDP), in which lane change actions have stochastic outcomes. However, MDPs are known to be time-consuming to solve in general. In this paper, we show that—under reasonable assumptions—we can use a Dijkstra-like approach to solve this stochastic problem, and benefit from its efficient O ( n log n ) running time. This enables an autonomous vehicle to exhibit lane-selection behavior as it efficiently plans an optimal route to its destination.},
  archive  = {J},
  author   = {Mitchell Jones and Maximilian Haas-Heger and Jur van den Berg},
  doi      = {10.1177/02783649231225474},
  journal  = {The International Journal of Robotics Research},
  month    = {8},
  number   = {9},
  pages    = {1425-1440},
  title    = {Lane-level route planning for autonomous vehicles},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sample-efficient safety assurances using conformal
prediction. <em>The International Journal of Robotics Research</em>,
<em>43</em>(9), 1409–1424. (<a
href="https://doi.org/10.1177/02783649231221580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {When deploying machine learning models in high-stakes robotics applications, the ability to detect unsafe situations is crucial. Early warning systems can provide alerts when an unsafe situation is imminent (in the absence of corrective action). To reliably improve safety, these warning systems should have a provable false negative rate; that is, of the situations that are unsafe, fewer than ϵ will occur without an alert. In this work, we present a framework that combines a statistical inference technique known as conformal prediction with a simulator of robot/environment dynamics, in order to tune warning systems to provably achieve an ϵ false negative rate using as few as 1/ ϵ data points. We apply our framework to a driver warning system and a robotic grasping application, and empirically demonstrate the guaranteed false negative rate while also observing a low false detection (positive) rate.},
  archive  = {J},
  author   = {Rachel Luo and Shengjia Zhao and Jonathan Kuck and Boris Ivanovic and Silvio Savarese and Edward Schmerling and Marco Pavone},
  doi      = {10.1177/02783649231221580},
  journal  = {The International Journal of Robotics Research},
  month    = {8},
  number   = {9},
  pages    = {1409-1424},
  title    = {Sample-efficient safety assurances using conformal prediction},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Active uncertainty reduction for safe and efficient
interaction planning: A shielding-aware dual control approach. <em>The
International Journal of Robotics Research</em>, <em>43</em>(9),
1382–1408. (<a href="https://doi.org/10.1177/02783649231215371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The ability to accurately predict others’ behavior is central to the safety and efficiency of robotic systems in interactive settings, such as human–robot interaction and multi-robot teaming tasks. Unfortunately, robots often lack access to key information on which these predictions may hinge, such as other agents’ goals, attention, and willingness to cooperate. Dual control theory addresses this challenge by treating unknown parameters of a predictive model as stochastic hidden states and inferring their values at runtime using information gathered during system operation. While able to optimally and automatically trade off exploration and exploitation, dual control is computationally intractable for general interactive motion planning, mainly due to the fundamental coupling between the robot’s trajectory plan and its prediction of other agents’ intent. In this paper, we present a novel algorithmic approach to enable active uncertainty reduction for interactive motion planning based on the implicit dual control paradigm. Our approach relies on sampling-based approximation of stochastic dynamic programming, leading to a model predictive control problem that can be readily solved by real-time gradient-based optimization methods. The resulting policy is shown to preserve the dual control effect for a broad class of predictive models with both continuous and categorical uncertainty. To ensure the safe operation of the interacting agents, we use a runtime safety filter (also referred to as a “shielding” scheme), which overrides the robot’s dual control policy with a safety fallback strategy when a safety-critical event is imminent. We then augment the dual control framework with an improved variant of the recently proposed shielding-aware robust planning scheme, which proactively balances the nominal planning performance with the risk of high-cost emergency maneuvers triggered by low-probability agent behaviors. We demonstrate the efficacy of our approach with both simulated driving studies and hardware experiments using 1/10 scale autonomous vehicles.},
  archive  = {J},
  author   = {Haimin Hu and David Isele and Sangjae Bae and Jaime F Fisac},
  doi      = {10.1177/02783649231215371},
  journal  = {The International Journal of Robotics Research},
  month    = {8},
  number   = {9},
  pages    = {1382-1408},
  title    = {Active uncertainty reduction for safe and efficient interaction planning: A shielding-aware dual control approach},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The role of heterogeneity in autonomous perimeter defense
problems. <em>The International Journal of Robotics Research</em>,
<em>43</em>(9), 1363–1381. (<a
href="https://doi.org/10.1177/02783649241237544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {When is heterogeneity in the composition of an autonomous robotic team beneficial and when is it detrimental? We investigate and answer this question in the context of a minimally viable model that examines the role of heterogeneous speeds in perimeter defense problems, where defenders share a total allocated speed budget. We consider two distinct problem settings and develop strategies based on dynamic programming and on local interaction rules. We present a theoretical analysis of both approaches and our results are extensively validated using simulations. Interestingly, our results demonstrate that the viability of heterogeneous teams depends on the amount of information available to the defenders. Moreover, our results suggest a universality property: across a wide range of problem parameters the optimal ratio of the speeds of the defenders remains nearly constant.},
  archive  = {J},
  author   = {Aviv Adler and Oscar Mickelin and Ragesh K. Ramachandran and Gaurav S. Sukhatme and Sertac Karaman},
  doi      = {10.1177/02783649241237544},
  journal  = {The International Journal of Robotics Research},
  month    = {8},
  number   = {9},
  pages    = {1363-1381},
  title    = {The role of heterogeneity in autonomous perimeter defense problems},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A mathematical characterization of minimally sufficient
robot brains. <em>The International Journal of Robotics Research</em>,
<em>43</em>(9), 1342–1362. (<a
href="https://doi.org/10.1177/02783649231198898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper addresses the lower limits of encoding and processing the information acquired through interactions between an internal system (robot algorithms or software) and an external system (robot body and its environment) in terms of action and observation histories. Both are modeled as transition systems. We want to know the weakest internal system that is sufficient for achieving passive (filtering) and active (planning) tasks. We introduce the notion of an information transition system (ITS) for the internal system which is a transition system over a space of information states that reflect a robot’s or other observer’s perspective based on limited sensing, memory, computation, and actuation. An ITS is viewed as a filter and a policy or plan is viewed as a function that labels the states of this ITS. Regardless of whether internal systems are obtained by learning algorithms, planning algorithms, or human insight, we want to know the limits of feasibility for given robot hardware and tasks. We establish, in a general setting, that minimal information transition systems (ITSs) exist up to reasonable equivalence assumptions, and are unique under some general conditions. We then apply the theory to generate new insights into several problems, including optimal sensor fusion/filtering, solving basic planning tasks, and finding minimal representations for modeling a system given input-output relations.},
  archive  = {J},
  author   = {Basak Sakcak and Kalle G Timperi and Vadim Weinstein and Steven M LaValle},
  doi      = {10.1177/02783649231198898},
  journal  = {The International Journal of Robotics Research},
  month    = {8},
  number   = {9},
  pages    = {1342-1362},
  title    = {A mathematical characterization of minimally sufficient robot brains},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Certified polyhedral decompositions of collision-free
configuration space. <em>The International Journal of Robotics
Research</em>, <em>43</em>(9), 1322–1341. (<a
href="https://doi.org/10.1177/02783649231201437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Understanding the geometry of collision-free configuration space (C-free) in the presence of Cartesian-space obstacles is an essential ingredient for collision-free motion planning. While it is possible to check for collisions at a point using standard algorithms, to date no practical method exists for computing C-free regions with rigorous certificates due to the complexity of mapping Cartesian-space obstacles through the kinematics. In this work, we present the first to our knowledge rigorous method for approximately decomposing a rational parametrization of C-free into certified polyhedral regions. Our method, called C-Iris (C-space Iterative Regional Inflation by Semidefinite programming), generates large, convex polytopes in a rational parameterization of the configuration space which are rigorously certified to be collision-free. Such regions have been shown to be useful for both optimization-based and randomized motion planning. Based on convex optimization, our method works in arbitrary dimensions, only makes assumptions about the convexity of the obstacles in the 3D Cartesian space, and is fast enough to scale to realistic problems in manipulation. We demonstrate our algorithm’s ability to fill a non-trivial amount of collision-free C-space in several 2-DOF examples where the C-space can be visualized, as well as the scalability of our algorithm on a 7-DOF KUKA iiwa, a 6-DOF UR3e, and 12-DOF bimanual manipulators. An implementation of our algorithm is open-sourced in Drake . We furthermore provide examples of our algorithm in interactive Python notebooks .},
  archive  = {J},
  author   = {Hongkai Dai and Alexandre Amice and Peter Werner and Annan Zhang and Russ Tedrake},
  doi      = {10.1177/02783649231201437},
  journal  = {The International Journal of Robotics Research},
  month    = {8},
  number   = {9},
  pages    = {1322-1341},
  title    = {Certified polyhedral decompositions of collision-free configuration space},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Abstracting road traffic via topological braids:
Applications to traffic flow analysis and distributed control. <em>The
International Journal of Robotics Research</em>, <em>43</em>(9),
1299–1321. (<a href="https://doi.org/10.1177/02783649231188740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Despite the structure of road environments, imposed via geometry and rules, traffic flows exhibit complex multiagent dynamics. Reasoning about such dynamics is challenging due to the high dimensionality of possible behavior, the heterogeneity of agents, and the stochasticity of their decision-making. Modeling approaches learning associations in Euclidean spaces are often limited by their high sample complexity and the sparseness of available datasets. Our key insight is that the structure of traffic behavior could be effectively captured by lower-dimensional abstractions that emphasize critical interaction relationships. In this article, we abstract the space of behavior in traffic scenes into a discrete set of interaction modes, described in interpretable, symbolic form using topological braids. First, through a case study across real-world datasets, we show that braids can describe a wide range of complex behavior and uncover insights about the interactivity of vehicles. For instance, we find that high vehicle density does not always map to rich mixing patterns among them. Further, we show that our representation can effectively guide decision-making in traffic scenes. We describe a mechanism that probabilistically maps vehicles’ past behavior to modes of future interaction. We integrate this mechanism into a control algorithm that treats navigation as minimization of uncertainty over interaction modes, and investigate its performance on the task of traversing uncontrolled intersections in simulation. We show that our algorithm enables agents to coordinate significantly safer traversals for similar efficiency compared to baselines explicitly reasoning in the space of trajectories across a series of challenging scenarios.},
  archive  = {J},
  author   = {Christoforos Mavrogiannis and Jonathan A DeCastro and Siddhartha S Srinivasa},
  doi      = {10.1177/02783649231188740},
  journal  = {The International Journal of Robotics Research},
  month    = {8},
  number   = {9},
  pages    = {1299-1321},
  title    = {Abstracting road traffic via topological braids: Applications to traffic flow analysis and distributed control},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive discretization using voronoi trees for continuous
POMDPs. <em>The International Journal of Robotics Research</em>,
<em>43</em>(9), 1283–1298. (<a
href="https://doi.org/10.1177/02783649231188984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Solving continuous Partially Observable Markov Decision Processes (POMDPs) is challenging, particularly for high-dimensional continuous action spaces. To alleviate this difficulty, we propose a new sampling-based online POMDP solver, called A daptive D iscretization using V oronoi T rees (ADVT) . It uses Monte Carlo Tree Search in combination with an adaptive discretization of the action space as well as optimistic optimization to efficiently sample high-dimensional continuous action spaces and compute the best action to perform. Specifically, we adaptively discretize the action space for each sampled belief using a hierarchical partition called Voronoi tree , which is a Binary Space Partitioning that implicitly maintains the partition of a cell as the Voronoi diagram of two points sampled from the cell. ADVT uses the estimated diameters of the cells to form an upper-confidence bound on the action value function within the cell, guiding the Monte Carlo Tree Search expansion and further discretization of the action space. This enables ADVT to better exploit local information with respect to the action value function, allowing faster identification of the most promising regions in the action space, compared to existing solvers. Voronoi trees keep the cost of partitioning and estimating the diameter of each cell low, even in high-dimensional spaces where many sampled points are required to cover the space well. ADVT additionally handles continuous observation spaces, by adopting an observation progressive widening strategy, along with a weighted particle representation of beliefs. Experimental results indicate that ADVT scales substantially better to high-dimensional continuous action spaces, compared to state-of-the-art methods.},
  archive  = {J},
  author   = {Marcus Hoerger and Hanna Kurniawati and Dirk Kroese and Nan Ye},
  doi      = {10.1177/02783649231188984},
  journal  = {The International Journal of Robotics Research},
  month    = {8},
  number   = {9},
  pages    = {1283-1298},
  title    = {Adaptive discretization using voronoi trees for continuous POMDPs},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Selected papers from WAFR 2022. <em>The International
Journal of Robotics Research</em>, <em>43</em>(9), 1281–1282. (<a
href="https://doi.org/10.1177/02783649241274937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Jason M O’Kane and Michael Otte and Dorsa Sadigh and Pratap Tokekar},
  doi     = {10.1177/02783649241274937},
  journal = {The International Journal of Robotics Research},
  month   = {8},
  number  = {9},
  pages   = {1281-1282},
  title   = {Selected papers from WAFR 2022},
  volume  = {43},
  year    = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimotion visual odometry. <em>The International Journal
of Robotics Research</em>, <em>43</em>(8), 1250–1278. (<a
href="https://doi.org/10.1177/02783649241229095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Visual motion estimation is a well-studied challenge in autonomous navigation. Recent work has focused on addressing multimotion estimation in highly dynamic environments. These environments not only comprise multiple, complex motions but also tend to exhibit significant occlusion. Estimating third-party motions simultaneously with the sensor egomotion is difficult because an object’s observed motion consists of both its true motion and the sensor motion. Most previous works in multimotion estimation simplify this problem by relying on appearance-based object detection or application-specific motion constraints. These approaches are effective in specific applications and environments but do not generalize well to the full multimotion estimation problem (MEP). This paper presents Multimotion Visual Odometry (MVO), a multimotion estimation pipeline that estimates the full SE (3) trajectory of every motion in the scene, including the sensor egomotion, without relying on appearance-based information. MVO extends the traditional visual odometry (VO) pipeline with multimotion segmentation and tracking techniques. It uses physically founded motion priors to extrapolate motions through temporary occlusions and identify the reappearance of motions through motion closure . Evaluations on real-world data from the Oxford Multimotion Dataset (OMD) and the KITTI Vision Benchmark Suite demonstrate that MVO achieves good estimation accuracy compared to similar approaches and is applicable to a variety of multimotion estimation challenges.},
  archive  = {J},
  author   = {Kevin M. Judd and Jonathan D. Gammell},
  doi      = {10.1177/02783649241229095},
  journal  = {The International Journal of Robotics Research},
  month    = {7},
  number   = {8},
  pages    = {1250-1278},
  title    = {Multimotion visual odometry},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bearing-angle approach for unknown target motion analysis
based on visual measurements. <em>The International Journal of Robotics
Research</em>, <em>43</em>(8), 1228–1249. (<a
href="https://doi.org/10.1177/02783649241229172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Vision-based estimation of the motion of a moving target is usually formulated as a bearing-only estimation problem where the visual measurement is modeled as a bearing vector. Although the bearing-only approach has been studied for decades, a fundamental limitation of this approach is that it requires extra lateral motion of the observer to enhance the target’s observability. Unfortunately, the extra lateral motion conflicts with the desired motion of the observer in many tasks. It is well-known that, once a target has been detected in an image, a bounding box that surrounds the target can be obtained. Surprisingly, this common visual measurement especially its size information has not been well explored up to now. In this paper, we propose a new bearing-angle approach to estimate the motion of a target by modeling its image bounding box as bearing-angle measurements. Both theoretical analysis and experimental results show that this approach can significantly enhance the observability without relying on additional lateral motion of the observer. The benefit of the bearing-angle approach comes with no additional cost because a bounding box is a standard output of object detection algorithms. The approach simply exploits the information that has not been fully exploited in the past. No additional sensing devices or special detection algorithms are required.},
  archive  = {J},
  author   = {Zian Ning and Yin Zhang and Jianan Li and Zhang Chen and Shiyu Zhao},
  doi      = {10.1177/02783649241229172},
  journal  = {The International Journal of Robotics Research},
  month    = {7},
  number   = {8},
  pages    = {1228-1249},
  title    = {A bearing-angle approach for unknown target motion analysis based on visual measurements},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Theoretical and experimental investigation of variable
contact forces on the rollers of a mecanum wheeled mobile robot. <em>The
International Journal of Robotics Research</em>, <em>43</em>(8),
1208–1227. (<a href="https://doi.org/10.1177/02783649241228607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The modeling structures of rollers, mecanum wheels, and mecanum wheeled mobile robots presented in the literature use single contact force assumption. This assumption may give good results in a simulation environment; however, it is not strong enough to reflect reality. To make an improvement, a new aspect of mecanum wheel model is proposed in this study. The model takes the variable roller contact forces into account and investigates their effects on the performance of motion of a mecanum wheeled mobile robot. It uses all points on each roller’s curved shape so that the slippage phenomena is also taken into consideration which makes it possible to get less position estimation errors in real-time operations. The modeling structure introduced aims to reflect reality both in simulation and real applications. A simulation environment is developed for this study. To make verification, an experimental setup including a four-mecanum-wheeled mobile robot, its mechanical and electrical hardware and software infrastructures, and a ground-truth system is designed and constructed. A Robot Operating System (ROS) based control system is created and integrated into the experimental system. Different types of reference trajectories including straight-line, square-shaped, Z-shaped, and wave(S)-shaped are used to test the performance of the model proposed in both simulation and experimental studies. The tests are also conducted using the model that involves single contact force assumption to make comparisons. The details of the variable contact forces model proposed, simulation environment developed, experimental setup built, simulation and experimental studies, their results, and comparisons are given in this paper.},
  archive  = {J},
  author   = {Can Tezel and Gokhan Bayar},
  doi      = {10.1177/02783649241228607},
  journal  = {The International Journal of Robotics Research},
  month    = {7},
  number   = {8},
  pages    = {1208-1227},
  title    = {Theoretical and experimental investigation of variable contact forces on the rollers of a mecanum wheeled mobile robot},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lazy incremental search for efficient replanning with
bounded suboptimality guarantees. <em>The International Journal of
Robotics Research</em>, <em>43</em>(8), 1175–1207. (<a
href="https://doi.org/10.1177/02783649241227869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We present a lazy incremental search algorithm, Lifelong-GLS (L-GLS), along with its bounded suboptimal version, Bounded L-GLS (B-LGLS) that combine the search efficiency of incremental search algorithms with the evaluation efficiency of lazy search algorithms for fast replanning in problem domains where edge evaluations are more expensive than vertex expansions. The proposed algorithms generalize Lifelong Planning A* (LPA*) and its bounded suboptimal version, Truncated LPA* (TLPA*), within the Generalized Lazy Search (GLS) framework, so as to restrict expensive edge evaluations only to the current shortest subpath when the cost-to-come inconsistencies are propagated during repair. We also present dynamic versions of the L-GLS and B-LGLS algorithms, called Generalized D* (GD*) and Bounded Generalized D* (B-GD*), respectively, for efficient replanning with non-stationary queries, designed specifically for navigation of mobile robots. We prove that the proposed algorithms are complete and correct in finding a solution that is guaranteed not to exceed the optimal solution cost by a user-chosen factor. Our numerical and experimental results support the claim that the proposed integration of the incremental and lazy search frameworks can help find solutions faster compared to the regular incremental or regular lazy search algorithms when the underlying graph representation changes often.},
  archive  = {J},
  author   = {Jaein Lim and Mahdi Ghanei and R. Connor Lawson and Siddhartha Srinivasa and Panagiotis Tsiotras},
  doi      = {10.1177/02783649241227869},
  journal  = {The International Journal of Robotics Research},
  month    = {7},
  number   = {8},
  pages    = {1175-1207},
  title    = {Lazy incremental search for efficient replanning with bounded suboptimality guarantees},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cross-domain challenge with panoptic segmentation in
agriculture. <em>The International Journal of Robotics Research</em>,
<em>43</em>(8), 1151–1174. (<a
href="https://doi.org/10.1177/02783649241227448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Automation in agriculture is a growing area of research with fundamental societal importance as farmers are expected to produce more and better crop with fewer resources. A key enabling factor is robotic vision techniques allowing us to sense and then interact with the environment. A limiting factor for these robotic vision systems is their cross-domain performance, that is, their ability to operate in a large range of environments. In this paper, we propose the use of auxiliary tasks to enhance cross-domain performance without the need for extra data. We perform experiments using four datasets (two in a glasshouse and two in arable farmland) for four cross-domain evaluations. These experiments demonstrate the effectiveness of our auxiliary tasks to improve network generalisability. In glasshouse experiments, our approach improves the panoptic quality of things from 10.4 to 18.5 and in arable farmland from 16.0 to 27.5; where a score of 100 is the best. To further evaluate the generalisability of our approach, we perform an ablation study using the large Crop and Weed dataset (CAW) where we improve cross-domain performance (panoptic quality of things) from 12.8 to 30.6 for the CAW dataset to our novel WeedAI dataset, and 21.2 to 36.0 from CAW to the other arable farmland dataset. Although our proposed approaches considerably improve cross-domain performance we still do not generally outperform in-domain trained systems. This highlights the potential room for improvement in this area and the importance of cross-domain research for robotic vision systems.},
  archive  = {J},
  author   = {Michael Halstead and Patrick Zimmer and Chris McCool},
  doi      = {10.1177/02783649241227448},
  journal  = {The International Journal of Robotics Research},
  month    = {7},
  number   = {8},
  pages    = {1151-1174},
  title    = {A cross-domain challenge with panoptic segmentation in agriculture},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft modularized robotic arm for safe human–robot
interaction based on visual and proprioceptive feedback. <em>The
International Journal of Robotics Research</em>, <em>43</em>(8),
1128–1150. (<a href="https://doi.org/10.1177/02783649241227249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This study proposes a modularized soft robotic arm with integrated sensing of human touches for physical human–robot interactions. The proposed robotic arm is constructed by connecting multiple soft manipulator modules, each of which consists of three bellow-type soft actuators, pneumatic valves, and an on-board sensing and control circuit. By employing stereolithography three-dimensional (3D) printing technique, the bellow actuator is capable of incorporating embedded organogel channels in the thin wall of its body that are used for detecting human touches. The organogel thus serves as a soft interface for recognizing the intentions of the human operators, enabling the robot to interact with them while generating desired motions of the manipulator. In addition to the touch sensors, each manipulator module has compact, soft string sensors for detecting the displacements of the bellow actuators. When combined with an inertial measurement unit (IMU), the manipulator module has a capability of estimating its own pose or orientation internally. We also propose a localization method that allows us to estimate the location of the manipulator module and to acquire the 3D information of the target point in an uncontrolled environment. The proposed method uses only a single depth camera combined with a deep learning model and is thus much simpler than those of conventional motion capture systems that usually require multiple cameras in a controlled environment. Using the feedback information from the internal sensors and camera, we implemented closed-loop control algorithms to carry out tasks of reaching and grasping objects. The manipulator module shows structural robustness and the performance reliability over 5,000 cycles of repeated actuation. It shows a steady-state error and a standard deviation of 0.8 mm and 0.3 mm, respectively, using the proposed localization method and the string sensor data. We demonstrate an application example of human–robot interaction that uses human touches as triggers to pick up and manipulate target objects. The proposed soft robotic arm can be easily installed in a variety of human workspaces, since it has the ability to interact safely with humans, eliminating the need for strict control of the environments for visual perception. We believe that the proposed system has the potential to integrate soft robots into our daily lives.},
  archive  = {J},
  author   = {Subyeong Ku and Byung-Hyun Song and Taejun Park and Younghoon Lee and Yong-Lae Park},
  doi      = {10.1177/02783649241227249},
  journal  = {The International Journal of Robotics Research},
  month    = {7},
  number   = {8},
  pages    = {1128-1150},
  title    = {Soft modularized robotic arm for safe human–robot interaction based on visual and proprioceptive feedback},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MARS-LVIG dataset: A multi-sensor aerial robots SLAM dataset
for LiDAR-visual-inertial-GNSS fusion. <em>The International Journal of
Robotics Research</em>, <em>43</em>(8), 1114–1127. (<a
href="https://doi.org/10.1177/02783649241227968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In recent years, advancements in Light Detection and Ranging (LiDAR) technology have made 3D LiDAR sensors more compact, lightweight, and affordable. This progress has spurred interest in integrating LiDAR with sensors such as Inertial Measurement Units (IMUs) and cameras for Simultaneous Localization and Mapping (SLAM) research. Public datasets covering different scenarios, platforms, and viewpoints are crucial for multi-sensor fusion SLAM studies, yet most focus on handheld or vehicle-mounted devices with front or 360-degree views. Data from aerial vehicles with downward-looking views is scarce, existing relevant datasets usually feature low altitudes and are mostly limited to small campus environments. To fill this gap, we introduce the Multi-sensor Aerial Robots SLAM dataset (MARS-LVIG dataset), providing unique aerial downward-looking LiDAR-Visual-Inertial-GNSS data with viewpoints from altitudes between 80 m and 130 m. The dataset not only offers new aspects to test and evaluate existing SLAM algorithms, but also brings new challenges which can facilitate researches and developments of more advanced SLAM algorithms. The MARS-LVIG dataset contains 21 sequences, acquired across diversified large-area environments including an aero-model airfield, an island, a rural town, and a valley. Within these sequences, the UAV has speeds varying from 3 m/s to 12 m/s, a scanning area reaching up to 577,000 m 2 , and the max path length of 7.148 km in a single flight. This dataset encapsulates data collected by a lightweight, hardware-synchronized sensor package that includes a solid-state 3D LiDAR, a global-shutter RGB camera, IMUs, and a raw message receiver of the Global Navigation Satellite System (GNSS). For algorithm evaluation, this dataset releases ground truth of both localization and mapping, which are acquired by on-board Real-time Kinematic (RTK) and DJI L1 (post-processed by its supporting software DJI Terra), respectively. The dataset can be downloaded from: https://mars.hku.hk/dataset.html .},
  archive  = {J},
  author   = {Haotian Li and Yuying Zou and Nan Chen and Jiarong Lin and Xiyuan Liu and Wei Xu and Chunran Zheng and Rundong Li and Dongjiao He and Fanze Kong and Yixi Cai and Zheng Liu and Shunbo Zhou and Kaiwen Xue and Fu Zhang},
  doi      = {10.1177/02783649241227968},
  journal  = {The International Journal of Robotics Research},
  month    = {7},
  number   = {8},
  pages    = {1114-1127},
  title    = {MARS-LVIG dataset: A multi-sensor aerial robots SLAM dataset for LiDAR-visual-inertial-GNSS fusion},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The INSANE dataset: Large number of sensors for challenging
UAV flights in mars analog, outdoor, and out-/indoor transition
scenarios. <em>The International Journal of Robotics Research</em>,
<em>43</em>(8), 1083–1113. (<a
href="https://doi.org/10.1177/02783649241227245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {For real-world applications, autonomous mobile robotic platforms must be capable of navigating safely in a multitude of different and dynamic environments with accurate and robust localization being a key prerequisite. To support further research in this domain, we present the INSANE datasets (Increased Number of Sensors for developing Advanced and Novel Estimators)—a collection of versatile Micro Aerial Vehicle (MAV) datasets for cross-environment localization. The datasets provide various scenarios with multiple stages of difficulty for localization methods. These scenarios range from trajectories in the controlled environment of an indoor motion capture facility, to experiments where the vehicle performs an outdoor maneuver and transitions into a building, requiring changes of sensor modalities, up to purely outdoor flight maneuvers in a challenging Mars analog environment to simulate scenarios which current and future Mars helicopters would need to perform. The presented work aims to provide data that reflects real-world scenarios and sensor effects. The extensive sensor suite includes various sensor categories, including multiple Inertial Measurement Units (IMUs) and cameras. Sensor data is made available as unprocessed measurements and each dataset provides highly accurate ground truth, including the outdoor experiments where a dual Real-Time Kinematic (RTK) Global Navigation Satellite System (GNSS) setup provides sub-degree and centimeter accuracy (1-sigma). The sensor suite also includes a dedicated high-rate IMU to capture all the vibration dynamics of the vehicle during flight to support research on novel machine learning-based sensor signal enhancement methods for improved localization. The datasets and post-processing tools are available at: https://sst.aau.at/cns/datasets/insane-dataset/},
  archive  = {J},
  author   = {Christian Brommer and Alessandro Fornasier and Martin Scheiber and Jeff Delaune and Roland Brockers and Jan Steinbrener and Stephan Weiss},
  doi      = {10.1177/02783649241227245},
  journal  = {The International Journal of Robotics Research},
  month    = {7},
  number   = {8},
  pages    = {1083-1113},
  title    = {The INSANE dataset: Large number of sensors for challenging UAV flights in mars analog, outdoor, and out-/indoor transition scenarios},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Kernel-based diffusion approximated markov decision
processes for autonomous navigation and control on unstructured
terrains. <em>The International Journal of Robotics Research</em>,
<em>43</em>(7), 1056–1080. (<a
href="https://doi.org/10.1177/02783649231225977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We propose a diffusion approximation method to the continuous-state Markov decision processes that can be utilized to address autonomous navigation and control in unstructured off-road environments. In contrast to most decision-theoretic planning frameworks that assume fully known state transition models, we design a method that eliminates such a strong assumption that is often extremely difficult to engineer in reality. We first take the second-order Taylor expansion of the value function. The Bellman optimality equation is then approximated by a partial differential equation, which only relies on the first and second moments of the transition model. By combining the kernel representation of the value function, we design an efficient policy iteration algorithm whose policy evaluation step can be represented as a linear system of equations characterized by a finite set of supporting states. We first validate the proposed method through extensive simulations in 2 D obstacle avoidance and 2.5 D terrain navigation problems. The results show that the proposed approach leads to a much superior performance over several baselines. We then develop a system that integrates our decision-making framework with onboard perception and conduct real-world experiments in both cluttered indoor and unstructured outdoor environments. The results from the physical systems further demonstrate the applicability of our method in challenging real-world environments.},
  archive  = {J},
  author   = {Junhong Xu and Kai Yin and Zheng Chen and Jason M Gregory and Ethan A Stump and Lantao Liu},
  doi      = {10.1177/02783649231225977},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {7},
  pages    = {1056-1080},
  title    = {Kernel-based diffusion approximated markov decision processes for autonomous navigation and control on unstructured terrains},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pose-and-shear-based tactile servoing. <em>The International
Journal of Robotics Research</em>, <em>43</em>(7), 1024–1055. (<a
href="https://doi.org/10.1177/02783649231225811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Tactile servoing is an important technique because it enables robots to manipulate objects with precision and accuracy while adapting to changes in their environments in real-time. One approach for tactile servo control with high-resolution soft tactile sensors is to estimate the contact pose relative to an object surface using a convolutional neural network (CNN) for use as a feedback signal. In this paper, we investigate how the surface pose estimation model can be extended to include shear, and utilise these combined pose-and-shear models to develop a tactile robotic system that can be programmed for diverse non-prehensile manipulation tasks, such as object tracking, surface-following, single-arm object pushing and dual-arm object pushing. In doing this, two technical challenges had to be overcome. Firstly, the use of tactile data that includes shear-induced slippage can lead to error-prone estimates unsuitable for accurate control, and so we modified the CNN into a Gaussian-density neural network and used a discriminative Bayesian filter to improve the predictions with a state dynamics model that utilises the robot kinematics. Secondly, to achieve smooth robot motion in 3D space while interacting with objects, we used SE (3) velocity-based servo control, which required re-deriving the Bayesian filter update equations using Lie group theory, as many standard assumptions do not hold for state variables defined on non-Euclidean manifolds. In future, we believe that pose-and-shear-based tactile servoing will enable many object manipulation tasks and the fully-dexterous utilisation of multi-fingered tactile robot hands.},
  archive  = {J},
  author   = {John Lloyd and Nathan F. Lepora},
  doi      = {10.1177/02783649231225811},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {7},
  pages    = {1024-1055},
  title    = {Pose-and-shear-based tactile servoing},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-reflective terrain-aware robot adaptation for
consistent off-road ground navigation. <em>The International Journal of
Robotics Research</em>, <em>43</em>(7), 1003–1023. (<a
href="https://doi.org/10.1177/02783649231225243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Ground robots require the crucial capability of traversing unstructured and unprepared terrains and avoiding obstacles to complete tasks in real-world robotics applications such as disaster response. When a robot operates in off-road field environments such as forests, the robot’s actual behaviors often do not match its expected or planned behaviors, due to changes in the characteristics of terrains and the robot itself. Therefore, the capability of robot adaptation for consistent behavior generation is essential for maneuverability on unstructured off-road terrains. In order to address the challenge, we propose a novel method of self-reflective terrain-aware adaptation for ground robots to generate consistent controls to navigate over unstructured off-road terrains, which enables robots to more accurately execute the expected behaviors through robot self-reflection while adapting to varying unstructured terrains. To evaluate our method’s performance, we conduct extensive experiments using real ground robots with various functionality changes over diverse unstructured off-road terrains. The comprehensive experimental results have shown that our self-reflective terrain-aware adaptation method enables ground robots to generate consistent navigational behaviors and outperforms the compared previous and baseline techniques.},
  archive  = {J},
  author   = {Sriram Siva and Maggie Wigness and John G. Rogers and Long Quang and Hao Zhang},
  doi      = {10.1177/02783649231225243},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {7},
  pages    = {1003-1023},
  title    = {Self-reflective terrain-aware robot adaptation for consistent off-road ground navigation},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent robotic sonographer: Mutual information-based
disentangled reward learning from few demonstrations. <em>The
International Journal of Robotics Research</em>, <em>43</em>(7),
981–1002. (<a href="https://doi.org/10.1177/02783649231223547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Ultrasound (US) imaging is widely used for biometric measurement and diagnosis of internal organs due to the advantages of being real-time and radiation-free. However, due to inter-operator variations, resulting images highly depend on the experience of sonographers. This work proposes an intelligent robotic sonographer to autonomously “explore” target anatomies and navigate a US probe to standard planes by learning from the expert. The underlying high-level physiological knowledge from experts is inferred by a neural reward function, using a ranked pairwise image comparison approach in a self-supervised fashion. This process can be referred to as understanding the “language of sonography.” Considering the generalization capability to overcome inter-patient variations, mutual information is estimated by a network to explicitly disentangle the task-related and domain features in latent space. The robotic localization is carried out in coarse-to-fine mode based on the predicted reward associated with B-mode images. To validate the effectiveness of the proposed reward inference network, representative experiments were performed on vascular phantoms (“line” target), two types of ex vivo animal organ phantoms (chicken heart and lamb kidney representing “point” target), and in vivo human carotids. To further validate the performance of the autonomous acquisition framework, physical robotic acquisitions were performed on three phantoms (vascular, chicken heart, and lamb kidney). The results demonstrated that the proposed advanced framework can robustly work on a variety of seen and unseen phantoms as well as in vivo human carotid data. Code : https://github.com/yuan-12138/MI-GPSR . Video : https://youtu.be/u4ThAA9onE0 .},
  archive  = {J},
  author   = {Zhongliang Jiang and Yuan Bi and Mingchuan Zhou and Ying Hu and Michael Burke and Nassir Navab},
  doi      = {10.1177/02783649231223547},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {7},
  pages    = {981-1002},
  title    = {Intelligent robotic sonographer: Mutual information-based disentangled reward learning from few demonstrations},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A transhumeral prosthesis with an artificial neuromuscular
system: Sim2real-guided design, modeling, and control. <em>The
International Journal of Robotics Research</em>, <em>43</em>(7),
942–980. (<a href="https://doi.org/10.1177/02783649231218719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this work we introduce a new type of human-inspired upper-limb prostheses. The Artificial Neuromuscular Prosthesis (ANP) imitates the human neuromuscular system in the sense of its compliance, backdrivability, natural motion, proprioceptive sensing, and kinesthetics. To realize this challenging goal, we introduce a novel human-inspired and simulation-based development paradigm to design the prosthesis mechatronics in correspondence to the human body. The ANP provides body awareness, contact awareness, and human-like contact response, realized via floating base rigid-body models, disturbance observers, and joint impedance control—concepts known from established state-of-the-art robotics. The ANP mechatronics is characterized by a four degrees of freedom (dof) torque-controlled human-like kinematics, a tendon-driven 2-dof wrist, and spatial orientation sensing at a weight of 1.7 kg (without hand and battery). The paper deals with the rigorous mathematical modeling, control, design and evaluation of this device type along initially defined requirements within a single prototype only. The proposed systemic and grasping capabilities are verified under laboratory conditions by an unimpaired user. Future work will increase the technology readiness level of the next generation device, where human studies with impaired users will be done.},
  archive  = {J},
  author   = {Alexander Toedtheide and Edmundo Pozo Fortunić and Johannes Kühn and Elisabeth Jensen and Sami Haddadin},
  doi      = {10.1177/02783649231218719},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {7},
  pages    = {942-980},
  title    = {A transhumeral prosthesis with an artificial neuromuscular system: Sim2real-guided design, modeling, and control},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Active collision avoidance for teleoperated multi-segment
continuum robots toward minimally invasive surgery. <em>The
International Journal of Robotics Research</em>, <em>43</em>(7),
918–941. (<a href="https://doi.org/10.1177/02783649231220955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Collision avoidance presents a challenging problem for multi-segment continuum robots owing to their flexible structure, limited workspaces, and restricted visual feedback, particularly when they are used in teleoperated minimally invasive surgery. This study proposes a comprehensive control framework that allows these continuum robots to automatically avoid collision and self-collision without interfering with the surgeon’s control of the end effector’s movement. The framework implements the early detection of collisions and active avoidance strategies by expressing the body geometry of the multi-segment continuum robot and the differential kinematics of any cross-section using screw theory. With the robot’s parameterized shape and selected checkpoints on the obstacle’s surface, we can determine the minimum distance between the robot and arbitrary obstacle, and locate the nearest point on the robot. Furthermore, we expand the null-space-based control method to accommodate redundant, non-redundant, and multiple continuum robots. An assessment of the avoidance capability is provided through an instantaneous and global criterion based on ellipsoids and possible movement ranges. Simulations and physical experiments involving continuum robots of different degrees of freedom performing various tasks were conducted to thoroughly validate the proposed framework. The results demonstrated its feasibility and effectiveness in minimizing the risk of collisions while maintaining the surgeon’s control over the end effector.},
  archive  = {J},
  author   = {Jianhua Li and Dingjia Li and Chongyang Wang and Wei Guo and Zhidong Wang and Zhongtao Zhang and Hao Liu},
  doi      = {10.1177/02783649231220955},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {7},
  pages    = {918-941},
  title    = {Active collision avoidance for teleoperated multi-segment continuum robots toward minimally invasive surgery},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CID-SIMS: Complex indoor dataset with semantic information
and multi-sensor data from a ground wheeled robot viewpoint. <em>The
International Journal of Robotics Research</em>, <em>43</em>(7),
899–917. (<a href="https://doi.org/10.1177/02783649231222507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Simultaneous localization and mapping (SLAM) and 3D reconstruction have numerous applications for indoor ground wheeled robots such as floor sweeping and food delivery. To advance research in leveraging semantic information and multi-sensor data to enhance the performances of SLAM and 3D reconstruction in complex indoor scenes, we propose a novel and complex indoor dataset named CID-SIMS, where semantic annotated RGBD images, inertial measurement unit (IMU) measurements, and wheel odometer data are provided from a ground wheeled robot viewpoint. The dataset consists of 22 challenging sequences captured in nine different scenes including office building and apartment environments. Notably, our dataset achieves two significant breakthroughs. Firstly, semantic information and multi-sensor data are provided meanwhile for the first time. Secondly, GeoSLAM is utilized for the first time to generate ground truth trajectories and 3D point clouds within two-centimeter accuracy. With spatial-temporal synchronous ground truth trajectories and 3D point clouds, our dataset is capable of evaluating SLAM and 3D reconstruction algorithms in a unified global coordinate system. We evaluate state-of-the-art SLAM and 3D reconstruction approaches on our dataset, demonstrating that our benchmark is applicable. The dataset is publicly available on https://cid-sims.github.io .},
  archive  = {J},
  author   = {Yidi Zhang and Ning An and Chenhui Shi and Shuo Wang and Hao Wei and Pengju Zhang and Xinrui Meng and Zengpeng Sun and Jinke Wang and Wenliang Liang and Fulin Tang and Yihong Wu},
  doi      = {10.1177/02783649231222507},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {7},
  pages    = {899-917},
  title    = {CID-SIMS: Complex indoor dataset with semantic information and multi-sensor data from a ground wheeled robot viewpoint},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design and implementation of an underactuated gripper with
enhanced shape adaptability and lateral stiffness through semi-active
multi-degree-of-freedom endoskeletons. <em>The International Journal of
Robotics Research</em>, <em>43</em>(6), 873–896. (<a
href="https://doi.org/10.1177/02783649231220674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Grasping is a key task for robots to interact with humans and the environment. Soft grippers have been widely studied and some have been applied in industry and daily life. Typical soft grippers face two challenges: lack of stiffness and insufficient adaptability to various objects. Inspired by the human hand, this paper proposes a soft-rigid hybrid pneumatic gripper composed of fingers with soft skin and rigid endoskeletons, and an active palm. Through different combinations of the four joints’ locking states within the rigid endoskeleton, each finger obtains 9 different postures in its inflating state and 13 different postures in its deflating state, endowing the gripper with the capability of adapting to a wider variety of objects. Simultaneously, due to the endoskeletons, the lateral stiffness of the gripper is significantly enhanced (load-to-weight ratio∼7.5 for lateral grasping). We also propose a series of grasping strategies for grasping objects with different sizes and shapes to utilize the versatile configurations of the gripper. Experiments demonstrated that the gripper conformed well to the surfaces of cylindrical and prismatic objects and successfully grasped all tool items and shape items in the Yale–CMU–Berkeley object set.},
  archive  = {J},
  author   = {Yafeng Cui and Xin An and Zhonghan Lin and Zhibin Guo and Xin-Jun Liu and Huichan Zhao},
  doi      = {10.1177/02783649231220674},
  journal  = {The International Journal of Robotics Research},
  month    = {5},
  number   = {6},
  pages    = {873-896},
  title    = {Design and implementation of an underactuated gripper with enhanced shape adaptability and lateral stiffness through semi-active multi-degree-of-freedom endoskeletons},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertainty-aware visually-attentive navigation using deep
neural networks. <em>The International Journal of Robotics
Research</em>, <em>43</em>(6), 840–872. (<a
href="https://doi.org/10.1177/02783649231218720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Autonomous navigation and information gathering in challenging environments are demanding since the robot’s sensors may be susceptible to non-negligible noise, its localization and mapping may be subject to significant uncertainty and drift, and performing collision-checking or evaluating utility functions using a map often requires high computational costs. We propose a learning-based method to efficiently tackle this problem without relying on a map of the environment or the robot’s position. Our method utilizes a Collision Prediction Network (CPN) for predicting the collision scores of a set of action sequences, and an Information gain Prediction Network (IPN) for estimating their associated information gain. Both networks assume access to a) the depth image (CPN) or the depth image and the detection mask from any visual method (IPN), b) the robot’s partial state (including its linear velocities, z -axis angular velocity, and roll/pitch angles), and c) a library of action sequences. Specifically, the CPN accounts for the estimation uncertainty of the robot’s partial state and the neural network’s epistemic uncertainty by using the Unscented Transform and an ensemble of neural networks. The outputs of the networks are combined with a goal vector to identify the next-best-action sequence. Simulation studies demonstrate the method’s robustness against noisy robot velocity estimates and depth images, alongside its advantages compared to state-of-the-art methods and baselines in (visually-attentive) navigation tasks. Lastly, multiple real-world experiments are presented, including safe flights at 2.5 m/s in a cluttered corridor, and missions inside a dense forest alongside visually-attentive navigation in industrial and university buildings.},
  archive  = {J},
  author   = {Huan Nguyen and Rasmus Andersen and Evangelos Boukas and Kostas Alexis},
  doi      = {10.1177/02783649231218720},
  journal  = {The International Journal of Robotics Research},
  month    = {5},
  number   = {6},
  pages    = {840-872},
  title    = {Uncertainty-aware visually-attentive navigation using deep neural networks},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tensor train for global optimization problems in robotics.
<em>The International Journal of Robotics Research</em>, <em>43</em>(6),
811–839. (<a href="https://doi.org/10.1177/02783649231217527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The convergence of many numerical optimization techniques is highly dependent on the initial guess given to the solver. To address this issue, we propose a novel approach that utilizes tensor methods to initialize existing optimization solvers near global optima. Our method does not require access to a database of good solutions. We first transform the cost function, which depends on both task parameters and optimization variables, into a probability density function. Unlike existing approaches, the joint probability distribution of the task parameters and optimization variables is approximated using the Tensor Train model, which enables efficient conditioning and sampling. We treat the task parameters as random variables, and for a given task, we generate samples for decision variables from the conditional distribution to initialize the optimization solver. Our method can produce multiple solutions (when they exist) faster than existing methods. We first evaluate the approach on benchmark functions for numerical optimization that are hard to solve using gradient-based optimization solvers with a naive initialization. The results show that the proposed method can generate samples close to global optima and from multiple modes. We then demonstrate the generality and relevance of our framework to robotics by applying it to inverse kinematics with obstacles and motion planning problems with a 7-DoF manipulator.},
  archive  = {J},
  author   = {Suhan Shetty and Teguh Lembono and Tobias Löw and Sylvain Calinon},
  doi      = {10.1177/02783649231217527},
  journal  = {The International Journal of Robotics Research},
  month    = {5},
  number   = {6},
  pages    = {811-839},
  title    = {Tensor train for global optimization problems in robotics},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sim2Real neural controllers for physics-based robotic
deployment of deformable linear objects. <em>The International Journal
of Robotics Research</em>, <em>43</em>(6), 791–810. (<a
href="https://doi.org/10.1177/02783649231214553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Deformable linear objects (DLOs), such as rods, cables, and ropes, play important roles in daily life. However, manipulation of DLOs is challenging as large geometrically nonlinear deformations may occur during the manipulation process. This problem is made even more difficult as the different deformation modes (e.g., stretching, bending, and twisting) may result in elastic instabilities during manipulation. In this paper, we formulate a physics-guided data-driven method to solve a challenging manipulation task—accurately deploying a DLO (an elastic rod) onto a rigid substrate along various prescribed patterns. Our framework combines machine learning, scaling analysis, and physical simulations to develop a physics-based neural controller for deployment. We explore the complex interplay between the gravitational and elastic energies of the manipulated DLO and obtain a control method for DLO deployment that is robust against friction and material properties. Out of the numerous geometrical and material properties of the rod and substrate, we show that only three non-dimensional parameters are needed to describe the deployment process with physical analysis. Therefore, the essence of the controlling law for the manipulation task can be constructed with a low-dimensional model, drastically increasing the computation speed. The effectiveness of our optimal control scheme is shown through a comprehensive robotic case study comparing against a heuristic control method for deploying rods for a wide variety of patterns. In addition to this, we also showcase the practicality of our control scheme by having a robot accomplish challenging high-level tasks such as mimicking human handwriting, cable placement, and tying knots.},
  archive  = {J},
  author   = {Dezhong Tong and Andrew Choi and Longhui Qin and Weicheng Huang and Jungseock Joo and Mohammad Khalid Jawed},
  doi      = {10.1177/02783649231214553},
  journal  = {The International Journal of Robotics Research},
  month    = {5},
  number   = {6},
  pages    = {791-810},
  title    = {Sim2Real neural controllers for physics-based robotic deployment of deformable linear objects},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online control synthesis for uncertain systems under signal
temporal logic specifications. <em>The International Journal of Robotics
Research</em>, <em>43</em>(6), 765–790. (<a
href="https://doi.org/10.1177/02783649231212572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Signal temporal logic (STL) formulas have been widely used as a formal language to express complex robotic specifications, thanks to their rich expressiveness and explicit time semantics. Existing approaches for STL control synthesis suffer from limited scalability with respect to the task complexity and lack of robustness against the uncertainty, for example, external disturbances. In this paper, we study the online control synthesis problem for uncertain discrete-time systems subject to STL specifications. Different from existing techniques, we propose an approach based on STL, reachability analysis, and temporal logic trees. First, based on a real-time version of STL semantics, we develop the notion of tube-based temporal logic tree (tTLT) and its recursive (offline) construction algorithm. We show that the tTLT is an under-approximation of the STL formula, in the sense that a trajectory satisfying a tTLT also satisfies the corresponding STL formula. Then, an online control synthesis algorithm is designed using the constructed tTLT. It is shown that when the STL formula is robustly satisfiable and the initial state of the system belongs to the initial root node of the tTLT, it is guaranteed that the trajectory generated by the control synthesis algorithm satisfies the STL formula. We validate the effectiveness of the proposed approach by several simulation examples and further demonstrate its practical usability on a hardware experiment. These results show that our approach is able to handle complex STL formulas with long horizons and ensure the robustness against the disturbances, which is beyond the scope of the state-of-the-art STL control synthesis approaches.},
  archive  = {J},
  author   = {Pian Yu and Yulong Gao and Frank J. Jiang and Karl H. Johansson and Dimos V. Dimarogonas},
  doi      = {10.1177/02783649231212572},
  journal  = {The International Journal of Robotics Research},
  month    = {5},
  number   = {6},
  pages    = {765-790},
  title    = {Online control synthesis for uncertain systems under signal temporal logic specifications},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hypothesis selection with monte carlo tree search for
feature-based simultaneous localization and mapping in non-static
environments. <em>The International Journal of Robotics Research</em>,
<em>43</em>(6), 750–764. (<a
href="https://doi.org/10.1177/02783649231215095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {A static world assumption is often used when considering the simultaneous localization and mapping (SLAM) problem. In reality, especially when long-term autonomy is the objective, this is not a valid assumption. This paper studies a scenario where landmarks can occupy multiple discrete positions at different points in time, where each possible position is added to a multi-hypothesis map representation. A selector-mixture distribution is introduced and used in the observation model. Each landmark position hypothesis is associated with one component in the mixture. The landmark movements are modeled by a discrete Markov chain and the Monte Carlo tree search algorithm is suggested to be used as component selector. The non-static environment model is further incorporated into the factor graph formulation of the SLAM problem and is solved by iterating between estimating discrete variables with a component selector and optimizing continuous variables with an efficient state-of-the-art nonlinear least squares SLAM solver. The proposed non-static SLAM system is validated in numerical simulation and with a publicly available dataset by showing that a non-static environment can successfully be navigated.},
  archive  = {J},
  author   = {Kristin Nielsen and Gustaf Hendeby},
  doi      = {10.1177/02783649231215095},
  journal  = {The International Journal of Robotics Research},
  month    = {5},
  number   = {6},
  pages    = {750-764},
  title    = {Hypothesis selection with monte carlo tree search for feature-based simultaneous localization and mapping in non-static environments},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Under-canopy dataset for advancing simultaneous localization
and mapping in agricultural robotics. <em>The International Journal of
Robotics Research</em>, <em>43</em>(6), 739–749. (<a
href="https://doi.org/10.1177/02783649231215372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Simultaneous localization and mapping (SLAM) has been an active research problem over recent decades. Many leading solutions are available that can achieve remarkable performance in environments with familiar structure, such as indoors and cities. However, our work shows that these leading systems fail in an agricultural setting, particularly in under the canopy navigation in the largest-in-acreage crops of the world: corn ( Zea mays ) and soybean ( Glycine max ). The presence of plenty of visual clutter due to leaves, varying illumination, and stark visual similarity makes these environments lose the familiar structure on which SLAM algorithms rely on. To advance SLAM in such unstructured agricultural environments, we present a comprehensive agricultural dataset. Our open dataset consists of stereo images, IMUs, wheel encoders, and GPS measurements continuously recorded from a mobile robot in corn and soybean fields across different growth stages. In addition, we present best-case benchmark results for several leading visual-inertial odometry and SLAM systems. Our data and benchmark clearly show that there is significant research promise in SLAM for agricultural settings. The dataset is available online at: https://github.com/jrcuaranv/terrasentia-dataset .},
  archive  = {J},
  author   = {Jose Cuaran and Andres Eduardo Baquero Velasquez and Mateus Valverde Gasparino and Naveen Kumar Uppalapati and Arun Narenthiran Sivakumar and Justin Wasserman and Muhammad Huzaifa and Sarita Adve and Girish Chowdhary},
  doi      = {10.1177/02783649231215372},
  journal  = {The International Journal of Robotics Research},
  month    = {5},
  number   = {6},
  pages    = {739-749},
  title    = {Under-canopy dataset for advancing simultaneous localization and mapping in agricultural robotics},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TRansPose: Large-scale multispectral dataset for transparent
object. <em>The International Journal of Robotics Research</em>,
<em>43</em>(6), 731–738. (<a
href="https://doi.org/10.1177/02783649231213117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Transparent objects are encountered frequently in our daily lives, yet recognizing them poses challenges for conventional vision sensors due to their unique material properties, not being well perceived from RGB or depth cameras. Overcoming this limitation, thermal infrared cameras have emerged as a solution, offering improved visibility and shape information for transparent objects. In this paper, we present TRansPose, the first large-scale multispectral dataset that combines stereo RGB-D, thermal infrared (TIR) images, and object poses to promote transparent object research. The dataset includes 99 transparent objects, encompassing 43 household items, 27 recyclable trashes, 29 chemical laboratory equivalents, and 12 non-transparent objects. It comprises a vast collection of 333,819 images and 4,000,056 annotations, providing instance-level segmentation masks, ground-truth poses, and completed depth information. The data was acquired using an FLIR A65 thermal infrared camera, two Intel RealSense L515 RGB-D cameras, and a Franka Emika Panda robot manipulator. Spanning 87 sequences, TRansPose covers various challenging real-life scenarios, including objects filled with water, diverse lighting conditions, heavy clutter, non-transparent or translucent containers, objects in plastic bags, and multi-stacked objects. Supplementary material can be accessed from the following link: https://sites.google.com/view/transpose-dataset .},
  archive  = {J},
  author   = {Jeongyun Kim and Myung-Hwan Jeon and Sangwoo Jung and Wooseong Yang and Minwoo Jung and Jaeho Shin and Ayoung Kim},
  doi      = {10.1177/02783649231213117},
  journal  = {The International Journal of Robotics Research},
  month    = {5},
  number   = {6},
  pages    = {731-738},
  title    = {TRansPose: Large-scale multispectral dataset for transparent object},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonverbal social behavior generation for social robots using
end-to-end learning. <em>The International Journal of Robotics
Research</em>, <em>43</em>(5), 716–728. (<a
href="https://doi.org/10.1177/02783649231207974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Social robots facilitate improved human–robot interactions through nonverbal behaviors such as handshakes or hugs . However, the traditional methods, which rely on precoded motions, are predictable and can detract from the perception of robots as interactive agents. To address this issue, we have introduced a Seq2Seq-based neural network model that learns social behaviors from human–human interactions in an end-to-end manner. To mitigate the risk of invalid pose sequences during long-term behavior generation, we incorporated a generative adversarial network (GAN). This proposed method was tested using the humanoid robot, Pepper, in a simulated environment. Given the challenges in assessing the success of social behavior generation, we devised novel metrics to quantify the discrepancy between the generated and ground-truth behaviors. Our analysis reveals the impact of different networks on behavior generation performance and compares the efficacy of learning multiple behaviors versus a single behavior. We anticipate that our method will find application in various sectors, including home service, guide, delivery, educational, and virtual robots, thereby enhancing user interaction and enjoyment.},
  archive  = {J},
  author   = {Woo-Ri Ko and Minsu Jang and Jaeyeon Lee and Jaehong Kim},
  doi      = {10.1177/02783649231207974},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {5},
  pages    = {716-728},
  title    = {Nonverbal social behavior generation for social robots using end-to-end learning},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quatro++: Robust global registration exploiting ground
segmentation for loop closing in LiDAR SLAM. <em>The International
Journal of Robotics Research</em>, <em>43</em>(5), 685–715. (<a
href="https://doi.org/10.1177/02783649231207654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Global registration is a fundamental task that estimates the relative pose between two viewpoints of 3D point clouds. However, there are two issues that degrade the performance of global registration in LiDAR SLAM: one is the sparsity issue and the other is degeneracy. The sparsity issue is caused by the sparse characteristics of the 3D point cloud measurements in a mechanically spinning LiDAR sensor. The degeneracy issue sometimes occurs because the outlier-rejection methods reject too many correspondences, leaving less than three inliers. These two issues have become more severe as the pose discrepancy between the two viewpoints of 3D point clouds becomes greater. To tackle these problems, we propose a robust global registration framework, called Quatro++ . Extending our previous work that solely focused on the global registration itself, we address the robust global registration in terms of the loop closing in LiDAR SLAM. To this end, ground segmentation is exploited to achieve robust global registration. Through the experiments, we demonstrate that our proposed method shows a higher success rate than the state-of-the-art global registration methods, overcoming the sparsity and degeneracy issues. In addition, we show that ground segmentation significantly helps to increase the success rate for the ground vehicles. Finally, we apply our proposed method to the loop closing module in LiDAR SLAM and confirm that the quality of the loop constraints is improved, showing more precise mapping results. Therefore, the experimental evidence corroborated the suitability of our method as an initial alignment in the loop closing. Our code is available at https://quatro-plusplus.github.io .},
  archive  = {J},
  author   = {Hyungtae Lim and Beomsoo Kim and Daebeom Kim and Eungchang Mason Lee and Hyun Myung},
  doi      = {10.1177/02783649231207654},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {5},
  pages    = {685-715},
  title    = {Quatro++: Robust global registration exploiting ground segmentation for loop closing in LiDAR SLAM},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Active preference-based gaussian process regression for
reward learning and optimization. <em>The International Journal of
Robotics Research</em>, <em>43</em>(5), 665–684. (<a
href="https://doi.org/10.1177/02783649231208729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Designing reward functions is a difficult task in AI and robotics. The complex task of directly specifying all the desirable behaviors a robot needs to optimize often proves challenging for humans. A popular solution is to learn reward functions using expert demonstrations. This approach, however, is fraught with many challenges. Some methods require heavily structured models, for example, reward functions that are linear in some predefined set of features, while others adopt less structured reward functions that may necessitate tremendous amounts of data. Moreover, it is difficult for humans to provide demonstrations on robots with high degrees of freedom, or even quantifying reward values for given trajectories. To address these challenges, we present a preference-based learning approach, where human feedback is in the form of comparisons between trajectories. We do not assume highly constrained structures on the reward function. Instead, we employ a Gaussian process to model the reward function and propose a mathematical formulation to actively fit the model using only human preferences. Our approach enables us to tackle both inflexibility and data-inefficiency problems within a preference-based learning framework. We further analyze our algorithm in comparison to several baselines on reward optimization, where the goal is to find the optimal robot trajectory in a data-efficient way instead of learning the reward function for every possible trajectory. Our results in three different simulation experiments and a user study show our approach can efficiently learn expressive reward functions for robotic tasks, and outperform the baselines in both reward learning and reward optimization.},
  archive  = {J},
  author   = {Erdem Bıyık and Nicolas Huynh and Mykel J. Kochenderfer and Dorsa Sadigh},
  doi      = {10.1177/02783649231208729},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {5},
  pages    = {665-684},
  title    = {Active preference-based gaussian process regression for reward learning and optimization},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear electrostatic actuators with moiré-effect optical
proprioceptive sensing and electroadhesive braking. <em>The
International Journal of Robotics Research</em>, <em>43</em>(5),
646–664. (<a href="https://doi.org/10.1177/02783649231210593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Muscles in animals and actuation systems in advanced robots consist not of the actuation component alone; the motive, dissipative, and proprioceptive components exist in a complete set to achieve versatile and precise manipulation tasks. We present such a system as a linear electrostatic actuator package incorporated with sensing and braking components. Our modular actuator design is composed of these actuator films and a dielectric fluid, and we examine the performance of the proposed system both theoretically and experimentally. In addition, we introduce a mechanism of optical proprioceptive sensing utilizing the Moiré pattern innately generated on the actuator surface, which allows high-resolution reading of the position of the actuator without noise. The optical sensor is also capable of measuring the force exerted by the actuator. Lastly, we add an electroadhesive brake in the package in parallel with the actuator, introducing a method of mode switching that utilizes all three components and presenting control demonstrations with a robot arm. Our actuation system is compact and flexible and can be easily integrated with various robotic applications.},
  archive  = {J},
  author   = {Inrak Choi and Sohee John Yoon and Yong-Lae Park},
  doi      = {10.1177/02783649231210593},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {5},
  pages    = {646-664},
  title    = {Linear electrostatic actuators with moiré-effect optical proprioceptive sensing and electroadhesive braking},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The “fluid jacobian”: Modeling force-motion relationships in
fluid-driven soft robots. <em>The International Journal of Robotics
Research</em>, <em>43</em>(5), 628–645. (<a
href="https://doi.org/10.1177/02783649231210592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this paper, we introduce the concept of the Fluid Jacobian , which provides a description of the power transmission that operates between the fluid and mechanical domains in soft robotic systems. It can be understood as a generalization of the traditional kinematic Jacobian that relates the joint space torques and velocities to the task space forces and velocities of a robot. In a similar way, the Fluid Jacobian relates fluid pressure to task space forces and fluid flow to task space velocities. In addition, the Fluid Jacobian can also be regarded as a generalization of the piston cross-sectional area in a fluid-driven cylinder that extends to complex geometries and multiple dimensions. In the following, we present a theoretical derivation of this framework, focus on important special cases, and illustrate the meaning and practical applicability of the Fluid Jacobian in four brief examples.},
  archive  = {J},
  author   = {C. David Remy and Zachary Brei and Daniel Bruder and Jan Remy and Keith Buffinton and R. Brent Gillespie},
  doi      = {10.1177/02783649231210592},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {5},
  pages    = {628-645},
  title    = {The “Fluid jacobian”: Modeling force-motion relationships in fluid-driven soft robots},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal virtual tube planning and control for swarm
robotics. <em>The International Journal of Robotics Research</em>,
<em>43</em>(5), 602–627. (<a
href="https://doi.org/10.1177/02783649231210012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper presents a novel method for efficiently solving a trajectory planning problem for swarm robotics in cluttered environments. Recent research has demonstrated high success rates in real-time local trajectory planning for swarm robotics in cluttered environments, but optimizing trajectories for each robot is still computationally expensive, with a computational complexity from O ( k ( n t , ε ) n t 2 ) to O ( k ( n t , ε ) n t 3 ) where n t is the number of parameters in the parameterized trajectory, ε is precision, and k ( n t , ε ) is the number of iterations with respect to n t and ε . Furthermore, the swarm is difficult to move as a group. To address this issue, we define and then construct the optimal virtual tube , which includes infinite optimal trajectories. Under certain conditions, any optimal trajectory in the optimal virtual tube can be expressed as a convex combination of a finite number of optimal trajectories, with a computational complexity of O ( n t ) . Afterward, a hierarchical approach including a planning method of the optimal virtual tube with minimizing energy and distributed model predictive control is proposed. In simulations and experiments, the proposed approach is validated and its effectiveness over other methods is demonstrated through comparison.},
  archive  = {J},
  author   = {Pengda Mao and Rao Fu and Quan Quan},
  doi      = {10.1177/02783649231210012},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {5},
  pages    = {602-627},
  title    = {Optimal virtual tube planning and control for swarm robotics},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MAgro dataset: A dataset for simultaneous localization and
mapping in agricultural environments. <em>The International Journal of
Robotics Research</em>, <em>43</em>(5), 591–601. (<a
href="https://doi.org/10.1177/02783649231210011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The agricultural industry is being transformed, thanks to recent innovations in computer vision and deep learning. However, the lack of specific datasets collected in natural agricultural environments is, arguably, the main bottleneck for novel discoveries and benchmarking. The present work provides a novel dataset, Magro, and a framework to expand data collection. We present the first version of the Magro Dataset V1.0, consisting of nine ROS bags (and the corresponding raw data) containing data collected in apple and pear crops. Data were gathered, repeating a fixed trajectory on different days under different illumination and weather conditions. To support the evaluation of loop closure algorithms, the trajectories are designed to have loop closures, revisiting some places from different viewpoints. We use a Clearpath’s Jackal robot equipped with stereo cameras pointing to the front and left side, a 3D LIDAR, three inertial measurement units (IMU), and wheel encoders. Additionally, we provide calibrated RTK GPS data that can be used as ground truth. Our dataset is openly available, and it will be updated to have more data and variability. Finally, we tested two existing state-of-the-art algorithms for vision and point cloud-based localization and mapping on our novel dataset to validate the dataset’s usability.},
  archive  = {J},
  author   = {Mercedes Marzoa Tanco and Guillermo Trinidad Barnech and Federico Andrade and Javier Baliosian and Martin LLofriu and JM Di Martino and Gonzalo Tejera},
  doi      = {10.1177/02783649231210011},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {5},
  pages    = {591-601},
  title    = {MAgro dataset: A dataset for simultaneous localization and mapping in agricultural environments},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rapid locomotion via reinforcement learning. <em>The
International Journal of Robotics Research</em>, <em>43</em>(4),
572–587. (<a href="https://doi.org/10.1177/02783649231224053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Agile maneuvers such as sprinting and high-speed turning in the wild are challenging for legged robots. We present an end-to-end learned controller that achieves record agility for the MIT Mini Cheetah, sustaining speeds up to 3.9 m/s. This system runs and turns fast on natural terrains like grass, ice, and gravel and responds robustly to disturbances. Our controller is a neural network trained in simulation via reinforcement learning and transferred to the real world. The two key components are (i) an adaptive curriculum on velocity commands and (ii) an online system identification strategy for sim-to-real transfer. Videos of the robot’s behaviors are available at https://agility.csail.mit.edu/ .},
  archive  = {J},
  author   = {Gabriel B. Margolis and Ge Yang and Kartik Paigwar and Tao Chen and Pulkit Agrawal},
  doi      = {10.1177/02783649231224053},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4},
  pages    = {572-587},
  title    = {Rapid locomotion via reinforcement learning},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging symmetries in pick and place. <em>The
International Journal of Robotics Research</em>, <em>43</em>(4),
550–571. (<a href="https://doi.org/10.1177/02783649231225775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Robotic pick and place tasks are symmetric under translations and rotations of both the object to be picked and the desired place pose. For example, if the pick object is rotated or translated, then the optimal pick action should also rotate or translate. The same is true for the place pose; if the desired place pose changes, then the place action should also transform accordingly. A recently proposed pick and place framework known as Transporter Net (Zeng, Florence, Tompson, Welker, Chien, Attarian, Armstrong, Krasin, Duong, Sindhwani et al., 2021) captures some of these symmetries, but not all. This paper analytically studies the symmetries present in planar robotic pick and place and proposes a method of incorporating equivariant neural models into Transporter Net in a way that captures all symmetries. The new model, which we call Equivariant Transporter Net , is equivariant to both pick and place symmetries and can immediately generalize pick and place knowledge to different pick and place poses. We evaluate the new model empirically and show that it is much more sample-efficient than the non-symmetric version, resulting in a system that can imitate demonstrated pick and place behavior using very few human demonstrations on a variety of imitation learning tasks.},
  archive  = {J},
  author   = {Haojie Huang and Dian Wang and Arsh Tangri and Robin Walters and Robert Platt},
  doi      = {10.1177/02783649231225775},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4},
  pages    = {550-571},
  title    = {Leveraging symmetries in pick and place},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RoboCraft: Learning to see, simulate, and shape
elasto-plastic objects in 3D with graph networks. <em>The International
Journal of Robotics Research</em>, <em>43</em>(4), 533–549. (<a
href="https://doi.org/10.1177/02783649231219020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Modeling and manipulating elasto-plastic objects are essential capabilities for robots to perform complex industrial and household interaction tasks (e.g., stuffing dumplings, rolling sushi, and making pottery). However, due to the high degrees of freedom of elasto-plastic objects, significant challenges exist in virtually every aspect of the robotic manipulation pipeline, for example, representing the states, modeling the dynamics, and synthesizing the control signals. We propose to tackle these challenges by employing a particle-based representation for elasto-plastic objects in a model-based planning framework. Our system, RoboCraft, only assumes access to raw RGBD visual observations. It transforms the sensory data into particles and learns a particle-based dynamics model using graph neural networks (GNNs) to capture the structure of the underlying system. The learned model can then be coupled with model predictive control (MPC) algorithms to plan the robot’s behavior. We show through experiments that with just 10 min of real-world robot interaction data, our robot can learn a dynamics model that can be used to synthesize control signals to deform elasto-plastic objects into various complex target shapes, including shapes that the robot has never encountered before. We perform systematic evaluations in both simulation and the real world to demonstrate the robot’s manipulation capabilities.},
  archive  = {J},
  author   = {Haochen Shi and Huazhe Xu and Zhiao Huang and Yunzhu Li and Jiajun Wu},
  doi      = {10.1177/02783649231219020},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4},
  pages    = {533-549},
  title    = {RoboCraft: Learning to see, simulate, and shape elasto-plastic objects in 3D with graph networks},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning dexterity from human hand motion in internet
videos. <em>The International Journal of Robotics Research</em>,
<em>43</em>(4), 513–532. (<a
href="https://doi.org/10.1177/02783649241227559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {To build general robotic agents that can operate in many environments, it is often useful for robots to collect experience in the real world. However, unguided experience collection is often not feasible due to safety, time, and hardware restrictions. We thus propose leveraging the next best thing as real world experience: videos of humans using their hands. To utilize these videos, we develop a method that retargets any 1st person or 3rd person video of human hands and arms into the robot hand and arm trajectories. While retargeting is a difficult problem, our key insight is to rely on only internet human hand video to train it. We use this method to present results in two areas: First, we build a system that enables any human to control a robot hand and arm, simply by demonstrating motions with their own hand. The robot observes the human operator via a single RGB camera and imitates their actions in real-time . This enables the robot to collect real-world experience safely using supervision. See these results at https://robotic-telekinesis.github.io . Second, we retarget in-the-wild human internet video into task-conditioned pseudo-robot trajectories to use as artificial robot experience. This learning algorithm leverages action priors from human hand actions, visual features from the images, and physical priors from dynamical systems to pretrain typical human behavior for a particular robot task. We show that by leveraging internet human hand experience, we need fewer robot demonstrations compared to many other methods. See these results at https://video-dex.github.io},
  archive  = {J},
  author   = {Kenneth Shaw and Shikhar Bahl and Aravind Sivakumar and Aditya Kannan and Deepak Pathak},
  doi      = {10.1177/02783649241227559},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4},
  pages    = {513-532},
  title    = {Learning dexterity from human hand motion in internet videos},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-robot, multi-sensor exploration of multifarious
environments with full mission aerial autonomy. <em>The International
Journal of Robotics Research</em>, <em>43</em>(4), 485–512. (<a
href="https://doi.org/10.1177/02783649231203342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We present a coordinated autonomy pipeline for multi-sensor exploration of confined environments. We simultaneously address four broad challenges that are typically overlooked in prior work: (a) make effective use of both range and vision sensing modalities, (b) perform this exploration across a wide range of environments, (c) be resilient to adverse events, and (d) execute this onboard teams of physical robots. Our solution centers around a behavior tree architecture, which adaptively switches between various behaviors involving coordinated exploration and responding to adverse events. Our exploration strategy exploits the benefits of both visual and range sensors with a generalized frontier-based exploration algorithm and an OpenVDB-based map processing pipeline. Our local planner utilizes a dynamically feasible trajectory library and a GPU-based Euclidean distance transform map to allow fast and safe navigation through both tight doorways and expansive spaces. The autonomy pipeline is evaluated with an extensive set of field experiments, with teams of up to three robots that fly up to 3 m/s and distances exceeding 1 km in confined spaces. We provide a summary of various field experiments and detail resilient behaviors that arose: maneuvering narrow doorways, adapting to unexpected environment changes, and emergency landing. Experiments are also detailed from the DARPA Subterranean Challenge, where our proposed autonomy pipeline contributed to us winning the “Most Sectors Explored” award. We provide an extended discussion of lessons learned, release software as open source, and present a video that illustrates our extensive field trials.},
  archive  = {J},
  author   = {Graeme Best and Rohit Garg and John Keller and Geoffrey A. Hollinger and Sebastian Scherer},
  doi      = {10.1177/02783649231203342},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4},
  pages    = {485-512},
  title    = {Multi-robot, multi-sensor exploration of multifarious environments with full mission aerial autonomy},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Kernel-GPA: A globally optimal solution to deformable SLAM
in closed-form. <em>The International Journal of Robotics Research</em>,
<em>43</em>(4), 456–484. (<a
href="https://doi.org/10.1177/02783649231195380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We study the generalized Procrustes analysis (GPA), as a minimal formulation to the simultaneous localization and mapping (SLAM) problem. We propose Kernel-GPA, a novel global registration technique to solve SLAM in the deformable environment. We propose the concept of deformable transformation which encodes the entangled pose and deformation. We define deformable transformations using a kernel method and show that both the deformable transformations and the environment map can be solved globally in closed-form, up to global scale ambiguities. We solve the scale ambiguities by an optimization formulation that maximizes rigidity. We demonstrate Kernel-GPA using the Gaussian kernel and validate the superiority of Kernel-GPA with various datasets. Code and data are available at https://bitbucket.org/FangBai/deformableprocrustes .},
  archive  = {J},
  author   = {Fang Bai and Kanzhi Wu and Adrien Bartoli},
  doi      = {10.1177/02783649231195380},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4},
  pages    = {456-484},
  title    = {Kernel-GPA: A globally optimal solution to deformable SLAM in closed-form},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Action-conditional implicit visual dynamics for deformable
object manipulation. <em>The International Journal of Robotics
Research</em>, <em>43</em>(4), 437–455. (<a
href="https://doi.org/10.1177/02783649231191222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Manipulating volumetric deformable objects in the real world, like plush toys and pizza dough, brings substantial challenges due to infinite shape variations, non-rigid motions, and partial observability. We introduce ACID, an action-conditional visual dynamics model for volumetric deformable objects based on structured implicit neural representations. ACID integrates two new techniques: implicit representations for action-conditional dynamics and geodesics-based contrastive learning. To represent deformable dynamics from partial RGB-D observations, we learn implicit representations of occupancy and flow-based forward dynamics. To accurately identify state change under large non-rigid deformations, we learn a correspondence embedding field through a novel geodesics-based contrastive loss. To evaluate our approach, we develop a simulation framework for manipulating complex deformable shapes in realistic scenes and a benchmark containing over 17,000 action trajectories with six types of plush toys and 78 variants. Our model achieves the best performance in geometry, correspondence, and dynamics predictions over existing approaches. The ACID dynamics models are successfully employed for goal-conditioned deformable manipulation tasks, resulting in a 30% increase in task success rate over the strongest baseline. Furthermore, we apply the simulation-trained ACID model directly to real-world objects and show success in manipulating them into target configurations. https://b0ku1.github.io/acid/},
  archive  = {J},
  author   = {Bokui Shen and Zhenyu Jiang and Christopher Choy and Silvio Savarese and Leonidas J. Guibas and Anima Anandkumar and Yuke Zhu},
  doi      = {10.1177/02783649231191222},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4},
  pages    = {437-455},
  title    = {Action-conditional implicit visual dynamics for deformable object manipulation},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive robotic information gathering via non-stationary
gaussian processes. <em>The International Journal of Robotics
Research</em>, <em>43</em>(4), 405–436. (<a
href="https://doi.org/10.1177/02783649231184498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Robotic Information Gathering (RIG) is a foundational research topic that answers how a robot (team) collects informative data to efficiently build an accurate model of an unknown target function under robot embodiment constraints. RIG has many applications, including but not limited to autonomous exploration and mapping, 3D reconstruction or inspection, search and rescue, and environmental monitoring. A RIG system relies on a probabilistic model’s prediction uncertainty to identify critical areas for informative data collection. Gaussian processes (GPs) with stationary kernels have been widely adopted for spatial modeling. However, real-world spatial data is typically non-stationary —different locations do not have the same degree of variability. As a result, the prediction uncertainty does not accurately reveal prediction error, limiting the success of RIG algorithms. We propose a family of non-stationary kernels named Attentive Kernel (AK), which is simple and robust and can extend any existing kernel to a non-stationary one. We evaluate the new kernel in elevation mapping tasks, where AK provides better accuracy and uncertainty quantification over the commonly used stationary kernels and the leading non-stationary kernels. The improved uncertainty quantification guides the downstream informative planner to collect more valuable data around the high-error area, further increasing prediction accuracy. A field experiment demonstrates that the proposed method can guide an Autonomous Surface Vehicle (ASV) to prioritize data collection in locations with significant spatial variations, enabling the model to characterize salient environmental features.},
  archive  = {J},
  author   = {Weizhe Chen and Roni Khardon and Lantao Liu},
  doi      = {10.1177/02783649231184498},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4},
  pages    = {405-436},
  title    = {Adaptive robotic information gathering via non-stationary gaussian processes},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterative residual policy: For goal-conditioned dynamic
manipulation of deformable objects. <em>The International Journal of
Robotics Research</em>, <em>43</em>(4), 389–404. (<a
href="https://doi.org/10.1177/02783649231201201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper tackles the task of goal-conditioned dynamic manipulation of deformable objects. This task is highly challenging due to its complex dynamics (introduced by object deformation and high-speed action) and strict task requirements (defined by a precise goal specification). To address these challenges, we present Iterative Residual Policy (IRP), a general learning framework applicable to repeatable tasks with complex dynamics. IRP learns an implicit policy via delta dynamics—instead of modeling the entire dynamical system and inferring actions from that model, IRP learns delta dynamics that predict the effects of delta action on the previously observed trajectory. When combined with adaptive action sampling, the system can quickly optimize its actions online to reach a specified goal. We demonstrate the effectiveness of IRP on two tasks: whipping a rope to hit a target point and swinging a cloth to reach a target pose. Despite being trained only in simulation on a fixed robot setup, IRP is able to efficiently generalize to noisy real-world dynamics, new objects with unseen physical properties, and even different robot hardware embodiments, demonstrating its excellent generalization capability relative to alternative approaches.},
  archive  = {J},
  author   = {Cheng Chi and Benjamin Burchfiel and Eric Cousineau and Siyuan Feng and Shuran Song},
  doi      = {10.1177/02783649231201201},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4},
  pages    = {389-404},
  title    = {Iterative residual policy: For goal-conditioned dynamic manipulation of deformable objects},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Selected papers from RSS2022. <em>The International Journal
of Robotics Research</em>, <em>43</em>(4), 387–388. (<a
href="https://doi.org/10.1177/02783649241236273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Shoudong Huang and Kris Hauser and Dylan A. Shell},
  doi     = {10.1177/02783649241236273},
  journal = {The International Journal of Robotics Research},
  month   = {4},
  number  = {4},
  pages   = {387-388},
  title   = {Selected papers from RSS2022},
  volume  = {43},
  year    = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stiffness modelling and analysis of soft fluidic-driven
robots using lie theory. <em>The International Journal of Robotics
Research</em>, <em>43</em>(3), 354–384. (<a
href="https://doi.org/10.1177/02783649231200595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Soft robots have been investigated for various applications due to their inherently superior deformability and flexibility compared to rigid-link robots. However, these robots struggle to perform tasks that require on-demand stiffness, that is, exerting sufficient forces within allowable deflection. In addition, the soft and compliant materials also introduce large deformation and non-negligible nonlinearity, which makes the stiffness analysis and modelling of soft robots fundamentally challenging. This paper proposes a modelling framework to investigate the underlying stiffness and the equivalent compliance properties of soft robots under different configurations. Firstly, a modelling and analysis methodology is described based on Lie theory. Here, we derive two sets (the piecewise constant curvature and Cosserat rod model) of compliance models. Furthermore, the methodology can accommodate the nonlinear responses (e.g., bending angles) resulting from elongation of robots. Using this proposed methodology, the general Cartesian stiffness or compliance matrix can be derived and used for configuration-dependent stiffness analysis. The proposed framework is then instantiated and implemented on fluidic-driven soft continuum robots. The efficacy and modelling accuracy of the proposed methodology are validated using both simulations and experiments.},
  archive  = {J},
  author   = {Jialei Shi and Azadeh Shariati and Sara-Adela Abad and Yuanchang Liu and Jian S Dai and Helge A Wurdemann},
  doi      = {10.1177/02783649231200595},
  journal  = {The International Journal of Robotics Research},
  month    = {3},
  number   = {3},
  pages    = {354-384},
  title    = {Stiffness modelling and analysis of soft fluidic-driven robots using lie theory},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust planning for multi-stage forceful manipulation.
<em>The International Journal of Robotics Research</em>, <em>43</em>(3),
330–353. (<a href="https://doi.org/10.1177/02783649231198560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Multi-step forceful manipulation tasks, such as opening a push-and-twist childproof bottle, require a robot to make various planning choices that are substantially impacted by the requirement to exert force during the task. The robot must reason over discrete and continuous choices relating to the sequence of actions, such as whether to pick up an object, and the parameters of each of those actions, such how to grasp the object. To enable planning and executing forceful manipulation, we augment an existing task and motion planner with constraints that explicitly consider torque and frictional limits, captured through the proposed forceful kinematic chain constraint. In three domains, opening a childproof bottle, twisting a nut and cutting a vegetable, we demonstrate how the system selects from among a combinatorial set of strategies. We also show how cost-sensitive planning can be used to find strategies and parameters that are robust to uncertainty in the physical parameters.},
  archive  = {J},
  author   = {Rachel Holladay and Tomás Lozano-Pérez and Alberto Rodriguez},
  doi      = {10.1177/02783649231198560},
  journal  = {The International Journal of Robotics Research},
  month    = {3},
  number   = {3},
  pages    = {330-353},
  title    = {Robust planning for multi-stage forceful manipulation},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DUEL: Depth visUal ego-motion learning for autonomous robot
obstacle avoidance. <em>The International Journal of Robotics
Research</em>, <em>43</em>(3), 305–329. (<a
href="https://doi.org/10.1177/02783649231210325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Reliable obstacle avoidance, which is essential for safe autonomous robot interaction with the real world, raises various challenges such as difficulties with obstacle perception and latent factor cognition impacting multi-modal obstacle avoidance. In this paper, we propose a Depth visUal Ego-motion Learning (DUEL) model, consisting of a cognitive generation network, a policy decision network and a potential partition network, to learn autonomous obstacle avoidance from expert policies. The DUEL model takes advantage of binocular vision to perceive scene depth. This serves as the input to the cognitive generation network which generates obstacle avoidance policies by maximizing its causal entropy. The policy decision network then optimizes the generation of the policies referring to expert policies. The generated obstacle avoidance policies are simultaneously transferred to the potential partition network to capture the latent factors contained within expert policies and perform multi-modal obstacle avoidance. These three core networks iteratively optimize the multi-modal policies relying on causal entropy and mutual information theorems, which are proven theoretically. Experimental comparisons with state-of-the-art models on 7 metrics demonstrate the effectiveness of the DUEL model. It achieves the best performance with an average ADE (Average Displacement Error) of 0.29 and average FDE (Final Displacement Error) of 0.55 across five different scenarios. Results show that the DUEL model can maintain an average obstacle avoidance success rate of 97% for both simulated and real world scenarios with multiple obstacles, demonstrating its success at capturing latent factors from expert policies. Our source codes are available at https://github.com/ACoTAI/DUEL .},
  archive  = {J},
  author   = {Naiyao Wang and Bo Zhang and Haixu Chi and Hua Wang and Seán McLoone and Hongbo Liu},
  doi      = {10.1177/02783649231210325},
  journal  = {The International Journal of Robotics Research},
  month    = {3},
  number   = {3},
  pages    = {305-329},
  title    = {DUEL: Depth visUal ego-motion learning for autonomous robot obstacle avoidance},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transendoscopic flexible parallel continuum robotic
mechanism for bimanual endoscopic submucosal dissection. <em>The
International Journal of Robotics Research</em>, <em>43</em>(3),
281–304. (<a href="https://doi.org/10.1177/02783649231209338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In endoscopic submucosal dissection (ESD), the gastrointestinal (GI) tract warrants the surgical instruments to navigate through a long, narrow and tortuous endoscope. This poses a great challenge in developing ESD instruments with small dimensions, flexibility, and high distal dexterity. In this work, we propose the first Transendoscopic Flexible Parallel Continuum Robotic mechanism to develop a miniature dexterous flexible-stiff-balanced Wrist (FPCW). Besides, it can steer multifunctional instruments of diameters 2.5 mm to 3.5 mm, including the electrosurgical knife, injection needle, and forceps. Our FPCW instruments are adaptable to commercially available dual-channel endoscopes (diameter: &lt;12 mm, channel width: 2.8 mm and around 3.8 mm). Furthermore, we develop a surgical telerobotic system, called DREAMS (Dual-arm Robotic Endoscopic Assistant for Minimally Invasive Surgery), by using our smallest FPCW instruments for bimanual ESD procedures. First, we conduct a series of experiments to determine the FPCW’s design and kinematics parameters and to verify the mechanical properties of the FPCW instruments’ prototypes, including workspace, stiffness, strength, and teleoperation accuracy. Second, we validate the functionality of the FPCW instruments through ex-vivo tests by performing ESD steps on porcine stomachs. Finally, we perform an invivo test on a live porcine model and showcase that our developed DREAMS can be teleoperated intuitively to perform bimanual ESD efficiently with an average dissection speed of 108.95 mm 2 /min at the greater curvature in gastric body, which demonstrates that our DREAMS has satisfactory maneuverability as well as accuracy and is more competitive than counterpart robotic systems.},
  archive  = {J},
  author   = {Huxin Gao and Xiaoxiao Yang and Xiao Xiao and Xiaolong Zhu and Tao Zhang and Cheng Hou and Huicong Liu and Max Q.-H. Meng and Lining Sun and Xiuli Zuo and Yanqing Li and Hongliang Ren},
  doi      = {10.1177/02783649231209338},
  journal  = {The International Journal of Robotics Research},
  month    = {3},
  number   = {3},
  pages    = {281-304},
  title    = {Transendoscopic flexible parallel continuum robotic mechanism for bimanual endoscopic submucosal dissection},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trajectory generation and tracking control for aggressive
tail-sitter flights. <em>The International Journal of Robotics
Research</em>, <em>43</em>(3), 241–280. (<a
href="https://doi.org/10.1177/02783649231207655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We address the theoretical and practical problems related to the trajectory generation and tracking control of tail-sitter UAVs. Theoretically, we focus on the differential flatness property with full exploitation of actual UAV aerodynamic models, which lays a foundation for generating dynamically feasible trajectory and achieving high-performance tracking control. We have found that a tail-sitter is differentially flat with accurate (not simplified) aerodynamic models within the entire flight envelope, by specifying coordinate flight condition and choosing the vehicle position as the flat output. This fundamental property allows us to fully exploit the high-fidelity aerodynamic models in the trajectory planning and tracking control to achieve accurate tail-sitter flights. Particularly, an optimization-based trajectory planner for tail-sitters is proposed to design high-quality, smooth trajectories with consideration of kinodynamic constraints, singularity-free constraints, and actuator saturation. The planned trajectory of flat output is transformed into state trajectory in real time with optional consideration of wind in environments. To track the state trajectory, a global, singularity-free, and minimally parameterized on-manifold MPC is developed, which fully leverages the accurate aerodynamic model to achieve high-accuracy trajectory tracking within the whole flight envelope. The proposed algorithms are implemented on our quadrotor tail-sitter prototype, “Hong Hu,” and their effectiveness are demonstrated through extensive real-world experiments in both indoor and outdoor field tests, including agile SE(3) flight through consecutive narrow windows requiring specific attitude and with speed up to 10 m/s, typical tail-sitter maneuvers (transition, level flight, and loiter) with speed up to 20 m/s, and extremely aggressive aerobatic maneuvers (Wingover, Loop, Vertical Eight, and Cuban Eight) with acceleration up to 2.5 g . The video demonstration is available at https://youtu.be/2x_bLbVuyrk .},
  archive  = {J},
  author   = {Guozheng Lu and Yixi Cai and Nan Chen and Fanze Kong and Yunfan Ren and Fu Zhang},
  doi      = {10.1177/02783649231207655},
  journal  = {The International Journal of Robotics Research},
  month    = {3},
  number   = {3},
  pages    = {241-280},
  title    = {Trajectory generation and tracking control for aggressive tail-sitter flights},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formalizing and evaluating requirements of perception
systems for automated vehicles using spatio-temporal perception logic.
<em>The International Journal of Robotics Research</em>, <em>43</em>(2),
203–238. (<a href="https://doi.org/10.1177/02783649231223546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Automated vehicles (AV) heavily depend on robust perception systems. Current methods for evaluating vision systems focus mainly on frame-by-frame performance. Such evaluation methods appear to be inadequate in assessing the performance of a perception subsystem when used within an AV. In this paper, we present a logic—referred to as Spatio-Temporal Perception Logic (STPL)—which utilizes both spatial and temporal modalities. STPL enables reasoning over perception data using spatial and temporal operators. One major advantage of STPL is that it facilitates basic sanity checks on the functional performance of the perception system, even without ground truth data in some cases. We identify a fragment of STPL which is efficiently monitorable offline in polynomial time. Finally, we present a range of specifications for AV perception systems to highlight the types of requirements that can be expressed and analyzed through offline monitoring with STPL.},
  archive  = {J},
  author   = {Mohammad Hekmatnejad and Bardh Hoxha and Jyotirmoy V. Deshmukh and Yezhou Yang and Georgios Fainekos},
  doi      = {10.1177/02783649231223546},
  journal  = {The International Journal of Robotics Research},
  month    = {2},
  number   = {2},
  pages    = {203-238},
  title    = {Formalizing and evaluating requirements of perception systems for automated vehicles using spatio-temporal perception logic},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy-optimal trajectories for skid-steer rovers. <em>The
International Journal of Robotics Research</em>, <em>43</em>(2),
171–202. (<a href="https://doi.org/10.1177/02783649231216499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper presents the energy-optimal trajectories for skid-steer rovers on hard ground, without obstacles. We obtain 29 trajectory structures that are sufficient to describe minimum-energy motion, which are enumerated and described geometrically; 28 of these structures are composed of sequences of circular arcs and straight lines; there is also a special structure called whirls consisting of different circular arcs. Our analysis identifies that the turns in the trajectory structures (aside from whirls) are all circular arcs of a particular turning radius, R′, the turning radius at which the inner wheels of a skid-steer rover are not commanded to turn. This work demonstrates its paramount importance in energy-optimal path planning. There has been a lack of analytical energy-optimal trajectory generation for skid-steer rovers, and we address this problem by a novel approach. The equivalency theorem presented in this work shows that all minimum-energy solutions follow the same path irrespective of velocity constraints that may or may not be imposed. This non-intuitive result stems from the fact that with this model of the system the total energy is fully parameterized by the geometry of the path alone. With this equivalency in mind, one can choose velocity constraints to enforce constant power consumption, thus transforming the energy-optimal problem into an equivalent time-optimal problem. Pontryagin’s Minimum Principle can then be used to solve the problem. Accordingly, the extremal paths are obtained and enumerated to find the minimum-energy path. Furthermore, our experimental results by using Husky UGV provide the experimental support for the equivalency theorem.},
  archive  = {J},
  author   = {Meysam Effati and Krzysztof Skonieczny and Devin J. Balkcom},
  doi      = {10.1177/02783649231216499},
  journal  = {The International Journal of Robotics Research},
  month    = {2},
  number   = {2},
  pages    = {171-202},
  title    = {Energy-optimal trajectories for skid-steer rovers},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic constraints to represent common sense required in
household actions for multimodal learning-from-observation robot.
<em>The International Journal of Robotics Research</em>, <em>43</em>(2),
134–170. (<a href="https://doi.org/10.1177/02783649231212929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The learning-from-observation (LfO) paradigm allows a robot to learn how to perform actions by observing human actions. Previous research in top-down learning-from-observation has mainly focused on the industrial domain, which consists only of the real physical constraints between a manipulated tool and the robot’s working environment. To extend this paradigm to the household domain, which consists of imaginary constraints derived from human common sense, we introduce the idea of semantic constraints, which are represented similarly to the physical constraints by defining an imaginary contact with an imaginary environment. By studying the transitions between contact states under physical and semantic constraints, we derive a necessary and sufficient set of task representations that provides the upper bound of the possible task set. We then apply the task representations to analyze various actions in top-rated household YouTube videos and real home cooking recordings, classify frequently occurring constraint patterns into physical, semantic, and multi-step task groups, and determine a subset that covers standard household actions. Finally, we design and implement task models, corresponding to these task representations in the subset, with the necessary daemon functions to collect the necessary parameters to perform the corresponding household actions. Our results provide promising directions for incorporating common sense into the robot teaching literature.},
  archive  = {J},
  author   = {Katsushi Ikeuchi and Naoki Wake and Kazuhiro Sasabuchi and Jun Takamatsu},
  doi      = {10.1177/02783649231212929},
  journal  = {The International Journal of Robotics Research},
  month    = {2},
  number   = {2},
  pages    = {134-170},
  title    = {Semantic constraints to represent common sense required in household actions for multimodal learning-from-observation robot},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A structured prediction approach for robot imitation
learning. <em>The International Journal of Robotics Research</em>,
<em>43</em>(2), 113–133. (<a
href="https://doi.org/10.1177/02783649231204656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We propose a structured prediction approach for robot imitation learning from demonstrations. Among various tools for robot imitation learning, supervised learning has been observed to have a prominent role. Structured prediction is a form of supervised learning that enables learning models to operate on output spaces with complex structures. Through the lens of structured prediction, we show how robots can learn to imitate trajectories belonging to not only Euclidean spaces but also Riemannian manifolds. Exploiting ideas from information theory, we propose a class of loss functions based on the f -divergence to measure the information loss between the demonstrated and reproduced probabilistic trajectories. Different types of f -divergence will result in different policies, which we call imitation modes . Furthermore, our approach enables the incorporation of spatial and temporal trajectory modulation, which is necessary for robots to be adaptive to the change in working conditions. We benchmark our algorithm against state-of-the-art methods in terms of trajectory reproduction and adaptation. The quantitative evaluation shows that our approach outperforms other algorithms regarding both accuracy and efficiency. We also report real-world experimental results on learning manifold trajectories in a polishing task with a KUKA LWR robot arm, illustrating the effectiveness of our algorithmic framework.},
  archive  = {J},
  author   = {Anqing Duan and Iason Batzianoulis and Raffaello Camoriano and Lorenzo Rosasco and Daniele Pucci and Aude Billard},
  doi      = {10.1177/02783649231204656},
  journal  = {The International Journal of Robotics Research},
  month    = {2},
  number   = {2},
  pages    = {113-133},
  title    = {A structured prediction approach for robot imitation learning},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The effects of selected object features on a pick-and-place
task: A human multimodal dataset. <em>The International Journal of
Robotics Research</em>, <em>43</em>(1), 98–109. (<a
href="https://doi.org/10.1177/02783649231210965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We propose a dataset to study the influence of object-specific characteristics on human pick-and-place movements and compare the quality of the motion kinematics extracted by various sensors. This dataset is also suitable for promoting a broader discussion on general learning problems in the hand-object interaction domain, such as intention recognition or motion generation with applications in the Robotics field. The dataset consists of the recordings of 15 subjects performing 80 repetitions of a pick-and-place action under various experimental conditions, for a total of 1200 pick-and-places. The data has been collected thanks to a multimodal setup composed of multiple cameras, observing the actions from different perspectives, a motion capture system, and a wrist-worn inertial measurement unit. All the objects manipulated in the experiments are identical in shape, size, and appearance but differ in weight and liquid filling, which influences the carefulness required for their handling.},
  archive  = {J},
  author   = {Linda Lastrico and Valerio Belcamino and Alessandro Carfì and Alessia Vignolo and Alessandra Sciutti and Fulvio Mastrogiovanni and Francesco Rea},
  doi      = {10.1177/02783649231210965},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {98-109},
  title    = {The effects of selected object features on a pick-and-place task: A human multimodal dataset},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Topological belief space planning for active SLAM with
pairwise gaussian potentials and performance guarantees. <em>The
International Journal of Robotics Research</em>, <em>43</em>(1), 69–97.
(<a href="https://doi.org/10.1177/02783649231204898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Determining a globally optimal solution of belief space planning (BSP) in high-dimensional state spaces directly is computationally expensive, as it involves belief propagation and objective function evaluation for each candidate action. However, many problems of interest, such as active SLAM, exhibit structure that can be harnessed to expedite planning. Also, in order to choose an optimal action, an exact value of the objective function is not required as long as the actions can be sorted in the same way. In this paper we leverage these two key aspects and present the topological belief space planning (t-bsp) concept that uses topological signatures to perform this ranking for information-theoretic cost functions, considering only topologies of factor graphs that correspond to future posterior beliefs. In particular, we propose a highly efficient topological signature based on the von Neumann graph entropy that is a function of graph node degrees and supports an incremental update. We analyze it in the context of active pose SLAM and derive error bounds between the proposed topological signature and the original information-theoretic cost function. These bounds are then used to provide performance guarantees for t-bsp with respect to a given solver of the original information-theoretic BSP problem. Realistic and synthetic simulations demonstrate drastic speed-up of the proposed method with respect to the state-of-the-art methods while retaining the ability to select a near-optimal solution. A proof of concept of t-bsp is given in a small-scale real-world active SLAM experiment.},
  archive  = {J},
  author   = {Andrej Kitanov and Vadim Indelman},
  doi      = {10.1177/02783649231204898},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {69-97},
  title    = {Topological belief space planning for active SLAM with pairwise gaussian potentials and performance guarantees},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exceeding traditional curvature limits of concentric tube
robots through redundancy resolution. <em>The International Journal of
Robotics Research</em>, <em>43</em>(1), 53–68. (<a
href="https://doi.org/10.1177/02783649231202548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Understanding elastic instability has been a recent focus of concentric tube robot research. Modeling advances have enabled prediction of when instabilities will occur and produced metrics for the stability of the robot during use. In this paper, we show how these metrics can be used to resolve redundancy to avoid elastic instability, opening the door for the practical use of higher curvature designs than have previously been possible. We demonstrate the effectiveness of the approach using a three-tube robot that is stabilized by redundancy resolution when following trajectories that would otherwise result in elastic instabilities. We also show that it is stabilized when teleoperated in ways that otherwise produce elastic instabilities. Lastly, we show that the redundancy resolution framework presented here can be applied to other control objectives useful for surgical robots, such as maximizing or minimizing compliance in desired directions.},
  archive  = {J},
  author   = {Patrick L Anderson and Richard J Hendrick and Margaret F Rox and Robert J Webster, III},
  doi      = {10.1177/02783649231202548},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {53-68},
  title    = {Exceeding traditional curvature limits of concentric tube robots through redundancy resolution},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The matroid team surviving orienteers problem and its
variants: Constrained routing of heterogeneous teams with risky
traversal. <em>The International Journal of Robotics Research</em>,
<em>43</em>(1), 34–52. (<a
href="https://doi.org/10.1177/02783649231210326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Consider deploying a team of robots in order to visit sites in a risky environment (i.e., where a robot might be lost during a traversal), subject to team-based operational constraints such as limits on team composition, traffic throughputs, and launch constraints. We formalize this problem using a graph to represent the environment, enforcing probabilistic survival constraints for each robot, and using a matroid (which generalizes linear independence to sets) to capture the team-based operational constraints. The resulting “Matroid Team Surviving Orienteers” (MTSO) problem has broad applications for robotics such as informative path planning, resource delivery, and search and rescue. We demonstrate that the objective for the MTSO problem has submodular structure, which leads us to develop two polynomial time algorithms which are guaranteed to find a solution with value within a constant factor of the optimum. The second of our algorithms is an extension of the accelerated continuous greedy algorithm, and can be applied to much broader classes of constraints while maintaining bounds on suboptimality. In addition to in-depth analysis, we demonstrate the efficiency of our approaches by applying them to a scenario where a team of robots must gather information while avoiding dangers in the Coral Triangle and characterize scaling and parameter selection using a synthetic dataset.},
  archive  = {J},
  author   = {Stefan Jorgensen and Marco Pavone},
  doi      = {10.1177/02783649231210326},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {34-52},
  title    = {The matroid team surviving orienteers problem and its variants: Constrained routing of heterogeneous teams with risky traversal},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multilevel motion planning: A fiber bundle formulation.
<em>The International Journal of Robotics Research</em>, <em>43</em>(1),
3–33. (<a href="https://doi.org/10.1177/02783649231209337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {High-dimensional motion planning problems can often be solved significantly faster by using multilevel abstractions. While there are various ways to formally capture multilevel abstractions, we formulate them in terms of fiber bundles. Fiber bundles essentially describe lower-dimensional projections of the state space using local product spaces, which allows us to concisely describe and derive novel algorithms in terms of bundle restrictions and bundle sections. Given such a structure and a corresponding admissible constraint function, we develop highly efficient and asymptotically optimal sampling-based motion planning methods for high-dimensional state spaces. Those methods exploit the structure of fiber bundles through the use of bundle primitives. Those primitives are used to create novel bundle planners, the rapidly-exploring quotient space trees (QRRT*), and the quotient space roadmap planner (QMP*). Both planners are shown to be probabilistically complete and almost-surely asymptotically optimal. To evaluate our bundle planners, we compare them against classical sampling-based planners on benchmarks of four low-dimensional scenarios, and eight high-dimensional scenarios, ranging from 21 to 100 degrees of freedom, including multiple robots and nonholonomic constraints. Our findings show improvements up to two to six orders of magnitude and underline the efficiency of multilevel motion planners and the benefit of exploiting multilevel abstractions using the terminology of fiber bundles.},
  archive  = {J},
  author   = {Andreas Orthey and Sohaib Akbar and Marc Toussaint},
  doi      = {10.1177/02783649231209337},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {3-33},
  title    = {Multilevel motion planning: A fiber bundle formulation},
  volume   = {43},
  year     = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
