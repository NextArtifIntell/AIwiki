<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JRSSSB_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jrsssb---147">JRSSSB - 147</h2>
<ul>
<li><details>
<summary>
(2024). Contents of volume 86, 2024. <em>JRSSSB</em>,
<em>86</em>(5), 1484–1486. (<a
href="https://doi.org/10.1093/jrsssb/qkae104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  doi          = {10.1093/jrsssb/qkae104},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1484-1486},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Contents of volume 86, 2024},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction to: Holdout predictive checks for bayesian model
criticism. <em>JRSSSB</em>, <em>86</em>(5), 1483. (<a
href="https://doi.org/10.1093/jrsssb/qkae090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  doi          = {10.1093/jrsssb/qkae090},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1483},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Correction to: Holdout predictive checks for bayesian model criticism},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correlation adjusted debiased lasso: Debiasing the lasso
with inaccurate covariate model. <em>JRSSSB</em>, <em>86</em>(5),
1455–1482. (<a href="https://doi.org/10.1093/jrsssb/qkae039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of estimating a low-dimensional parameter in high-dimensional linear regression. Constructing an approximately unbiased estimate of the parameter of interest is a crucial step towards performing statistical inference. Several authors suggest to orthogonalize both the variable of interest and the outcome with respect to the nuisance variables, and then regress the residual outcome with respect to the residual variable. This is possible if the covariance structure of the regressors is perfectly known, or is sufficiently structured that it can be estimated accurately from data (e.g. the precision matrix is sufficiently sparse). Here we consider a regime in which the covariate model can only be estimated inaccurately, and hence existing debiasing approaches are not guaranteed to work. We propose the correlation adjusted debiased Lasso , which nearly eliminates this bias in some cases, including cases in which the estimation errors are neither negligible nor orthogonal.},
  archive      = {J_JRSSSB},
  author       = {Celentano, Michael and Montanari, Andrea},
  doi          = {10.1093/jrsssb/qkae039},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1455-1482},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Correlation adjusted debiased lasso: Debiasing the lasso with inaccurate covariate model},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural networks meet random forests. <em>JRSSSB</em>,
<em>86</em>(5), 1435–1454. (<a
href="https://doi.org/10.1093/jrsssb/qkae038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks and random forests are popular and promising tools for machine learning. This article explores the proper integration of these two approaches for nonparametric regression to improve the performance of a single approach. Specifically, we propose a neural network estimator with local enhancement provided by random forests. It naturally synthesizes the local relation adaptivity of random forests and the strong global approximation ability of neural networks. Based on the classical empirical risk minimization framework, we establish a nonasymptotic error bound for the estimator. By utilizing advanced U -process theory and an appropriate network structure, we can further improve the convergence rate to the nearly minimax rate. Also with the assistance of random forests, we can implement gradient learning with neural networks. Comprehensive simulation studies and real data applications demonstrate the superiority of our proposal.},
  archive      = {J_JRSSSB},
  author       = {Qiu, Rui and Xu, Shuntuo and Yu, Zhou},
  doi          = {10.1093/jrsssb/qkae038},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1435-1454},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Neural networks meet random forests},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proximal survival analysis to handle dependent right
censoring. <em>JRSSSB</em>, <em>86</em>(5), 1414–1434. (<a
href="https://doi.org/10.1093/jrsssb/qkae037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many epidemiological and clinical studies aim to analyse a time-to-event endpoint. A common complication is right censoring. In some cases, right censoring occurs when subjects are still surviving after the study terminates or move out of the study area. In such cases, right censoring is typically treated as independent or noninformative. This assumption can be further relaxed to conditional independent censoring by leveraging possibly time-varying covariate information, if available, and assuming censoring and failure time are independent within covariate strata. In yet other instances, events may be censored by other competing events like death and are associated with censoring possibly through prognoses. Realistically, measured covariates can rarely capture all such associations with absolute certainty. In cases of dependent censoring, covariate measurements are often, at best, proxies of underlying prognoses. In this article, we establish a nonparametric identification framework by formally admitting that conditional independent censoring may fail in practice and accounting for covariate measurements as imperfect proxies of underlying association. The framework suggests adaptive estimators, and we provide generic assumptions under which they are consistent, asymptotically normal, and doubly robust. We examine the finite-sample performance of our proposed estimators via a Monte Carlo simulation and apply them to the SEER-Medicare dataset.},
  archive      = {J_JRSSSB},
  author       = {Ying, Andrew},
  doi          = {10.1093/jrsssb/qkae037},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1414-1434},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Proximal survival analysis to handle dependent right censoring},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CP factor model for dynamic tensors. <em>JRSSSB</em>,
<em>86</em>(5), 1383–1413. (<a
href="https://doi.org/10.1093/jrsssb/qkae036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Observations in various applications are frequently represented as a time series of multidimensional arrays, called tensor time series, preserving the inherent multidimensional structure. In this paper, we present a factor model approach, in a form similar to tensor CANDECOMP/PARAFAC (CP) decomposition, to the analysis of high-dimensional dynamic tensor time series. As the loading vectors are uniquely defined but not necessarily orthogonal, it is significantly different from the existing tensor factor models based on Tucker-type tensor decomposition. The model structure allows for a set of uncorrelated one-dimensional latent dynamic factor processes, making it much more convenient to study the underlying dynamics of the time series. A new high-order projection estimator is proposed for such a factor model, utilizing the special structure and the idea of the higher order orthogonal iteration procedures commonly used in Tucker-type tensor factor model and general tensor CP decomposition procedures. Theoretical investigation provides statistical error bounds for the proposed methods, which shows the significant advantage of utilizing the special model structure. Simulation study is conducted to further demonstrate the finite sample properties of the estimators. Real data application is used to illustrate the model and its interpretations.},
  archive      = {J_JRSSSB},
  author       = {Han, Yuefeng and Yang, Dan and Zhang, Cun-Hui and Chen, Rong},
  doi          = {10.1093/jrsssb/qkae036},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1383-1413},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {CP factor model for dynamic tensors},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spherical random projection. <em>JRSSSB</em>,
<em>86</em>(5), 1364–1382. (<a
href="https://doi.org/10.1093/jrsssb/qkae035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method for dimension reduction of high-dimensional spherical data based on the nonlinear projection of sphere-valued data to a randomly chosen subsphere. The proposed method, spherical random projection, leads to a probabilistic lower-dimensional mapping of spherical data into a subsphere of the original. In this paper, we investigate some properties of spherical random projection, including expectation preservation and distance concentration, from which we derive an analogue of the Johnson–Lindenstrauss Lemma for spherical random projection. Clustering model selection is discussed as an application of spherical random projection, and numerical experiments are conducted using real and simulated data.},
  archive      = {J_JRSSSB},
  author       = {Kang, Seungwoo and Oh, Hee-Seok},
  doi          = {10.1093/jrsssb/qkae035},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1364-1382},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Spherical random projection},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-assisted sensitivity analysis for treatment effects
under unmeasured confounding via regularized calibrated estimation.
<em>JRSSSB</em>, <em>86</em>(5), 1339–1363. (<a
href="https://doi.org/10.1093/jrsssb/qkae034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider sensitivity analysis for estimating average treatment effects under unmeasured confounding, assumed to satisfy a marginal sensitivity model. At the population level, we provide new representations for the sharp population bounds and doubly robust estimating functions. We also derive new, relaxed population bounds, depending on weighted linear outcome quantile regression. At the sample level, we develop new methods and theory for obtaining not only doubly robust point estimators for the relaxed population bounds with respect to misspecification of a propensity score model or an outcome mean regression model, but also model-assisted confidence intervals which are valid if the propensity score model is correctly specified, but the outcome quantile and mean regression models may be misspecified. The relaxed population bounds reduce to the sharp bounds if outcome quantile regression is correctly specified. For a linear outcome mean regression model, the confidence intervals are also doubly robust. Our methods involve regularized calibrated estimation, with Lasso penalties but carefully chosen loss functions, for fitting propensity score and outcome mean and quantile regression models. We present a simulation study and an empirical application to an observational study on the effects of right-heart catheterization. The proposed method is implemented in the R package RCALsa .},
  archive      = {J_JRSSSB},
  author       = {Tan, Zhiqiang},
  doi          = {10.1093/jrsssb/qkae034},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1339-1363},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Model-assisted sensitivity analysis for treatment effects under unmeasured confounding via regularized calibrated estimation},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Covariate-adaptive randomization inference in matched
designs. <em>JRSSSB</em>, <em>86</em>(5), 1312–1338. (<a
href="https://doi.org/10.1093/jrsssb/qkae033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is common to conduct causal inference in matched observational studies by proceeding as though treatment assignments within matched sets are assigned uniformly at random and using this distribution as the basis for inference. This approach ignores observed discrepancies in matched sets that may be consequential for the distribution of treatment, which are succinctly captured by within-set differences in the propensity score. We address this problem via covariate-adaptive randomization inference, which modifies the permutation probabilities to vary with estimated propensity score discrepancies and avoids requirements to exclude matched pairs or model an outcome variable. We show that the test achieves type I error control arbitrarily close to the nominal level when large samples are available for propensity score estimation. We characterize the large-sample behaviour of the new randomization test for a difference-in-means estimator of a constant additive effect. We also show that existing methods of sensitivity analysis generalize effectively to covariate-adaptive randomization inference. Finally, we evaluate the empirical value of combining matching and covariate-adaptive randomization procedures using simulations and analyses of genetic damage among welders and right-heart catheterization in surgical patients.},
  archive      = {J_JRSSSB},
  author       = {Pimentel, Samuel D and Huang, Yaxuan},
  doi          = {10.1093/jrsssb/qkae033},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1312-1338},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Covariate-adaptive randomization inference in matched designs},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sandwich boosting for accurate estimation in partially
linear models for grouped data. <em>JRSSSB</em>, <em>86</em>(5),
1286–1311. (<a href="https://doi.org/10.1093/jrsssb/qkae032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study partially linear models in settings where observations are arranged in independent groups but may exhibit within-group dependence. Existing approaches estimate linear model parameters through weighted least squares, with optimal weights (given by the inverse covariance of the response, conditional on the covariates) typically estimated by maximizing a (restricted) likelihood from random effects modelling or by using generalized estimating equations. We introduce a new ‘sandwich loss’ whose population minimizer coincides with the weights of these approaches when the parametric forms for the conditional covariance are well-specified, but can yield arbitrarily large improvements in linear parameter estimation accuracy when they are not. Under relatively mild conditions, our estimated coefficients are asymptotically Gaussian and enjoy minimal variance among estimators with weights restricted to a given class of functions, when user-chosen regression methods are used to estimate nuisance functions. We further expand the class of functional forms for the weights that may be fitted beyond parametric models by leveraging the flexibility of modern machine learning methods within a new gradient boosting scheme for minimizing the sandwich loss. We demonstrate the effectiveness of both the sandwich loss and what we call ‘sandwich boosting’ in a variety of settings with simulated and real-world data.},
  archive      = {J_JRSSSB},
  author       = {Young, Elliot H and Shah, Rajen D},
  doi          = {10.1093/jrsssb/qkae032},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1286-1311},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Sandwich boosting for accurate estimation in partially linear models for grouped data},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Green’s matching: An efficient approach to parameter
estimation in complex dynamic systems. <em>JRSSSB</em>, <em>86</em>(5),
1266–1285. (<a href="https://doi.org/10.1093/jrsssb/qkae031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameters of differential equations are essential to characterize intrinsic behaviours of dynamic systems. Numerous methods for estimating parameters in dynamic systems are computationally and/or statistically inadequate, especially for complex systems with general-order differential operators, such as motion dynamics. This article presents Green’s matching, a computationally tractable and statistically efficient two-step method, which only needs to approximate trajectories in dynamic systems but not their derivatives due to the inverse of differential operators by Green’s function. This yields a statistically optimal guarantee for parameter estimation in general-order equations, a feature not shared by existing methods, and provides an efficient framework for broad statistical inferences in complex dynamic systems.},
  archive      = {J_JRSSSB},
  author       = {Tan, Jianbin and Zhang, Guoyu and Wang, Xueqin and Huang, Hui and Yao, Fang},
  doi          = {10.1093/jrsssb/qkae031},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1266-1285},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Green’s matching: An efficient approach to parameter estimation in complex dynamic systems},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Statistical inference for multivariate extremes via a
geometric approach. <em>JRSSSB</em>, <em>86</em>(5), 1243–1265. (<a
href="https://doi.org/10.1093/jrsssb/qkae030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A geometric representation for multivariate extremes, based on the shapes of scaled sample clouds in light-tailed margins and their so-called limit sets, has recently been shown to connect several existing extremal dependence concepts. However, these results are purely probabilistic, and the geometric approach itself has not been fully exploited for statistical inference. We outline a method for parametric estimation of the limit set shape, which includes a useful non-/semi-parametric estimate as a pre-processing step. More fundamentally, our approach provides a new class of asymptotically motivated statistical models for the tails of multivariate distributions, and such models can accommodate any combination of simultaneous or non-simultaneous extremes through appropriate parametric forms for the limit set shape. Extrapolation further into the tail of the distribution is possible via simulation from the fitted model. A simulation study confirms that our methodology is very competitive with existing approaches and can successfully allow estimation of small probabilities in regions where other methods struggle. We apply the methodology to two environmental datasets, with diagnostics demonstrating a good fit.},
  archive      = {J_JRSSSB},
  author       = {Wadsworth, Jennifer L and Campbell, Ryan},
  doi          = {10.1093/jrsssb/qkae030},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1243-1265},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Statistical inference for multivariate extremes via a geometric approach},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimax detection boundary and sharp optimal test for
gaussian graphical models. <em>JRSSSB</em>, <em>86</em>(5), 1221–1242.
(<a href="https://doi.org/10.1093/jrsssb/qkae029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we derive the minimax detection boundary for testing a sub-block of variables in a precision matrix under the Gaussian distribution. Compared to the results on the minimum rate of signals for testing precision matrices in literature, our result gives the exact minimum signal strength in a precision matrix that can be detected. We propose a thresholding test that is able to achieve the minimax detection boundary under certain cases by adaptively choosing the threshold level. The asymptotic distribution of the thresholding statistic for precision matrices is derived. Power analysis is conducted to show the proposed test is powerful against sparse and weak signals, which cannot be detected by the existing L m a x and L 2 tests. Simulation studies show the proposed test has an accurate size around the nominal level and is more powerful than the existing tests for detecting sparse and weak signals in precision matrices. Real data analysis on brain imaging data is carried out to illustrate the utility of the proposed test in practice, which reveals functional connectivity between brain regions for Alzheimer’s disease patients and normal healthy people.},
  archive      = {J_JRSSSB},
  author       = {Qiu, Yumou and Guo, Bin},
  doi          = {10.1093/jrsssb/qkae029},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1221-1242},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Minimax detection boundary and sharp optimal test for gaussian graphical models},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Broadcasted nonparametric tensor regression.
<em>JRSSSB</em>, <em>86</em>(5), 1197–1220. (<a
href="https://doi.org/10.1093/jrsssb/qkae027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel use of a broadcasting operation, which distributes univariate functions to all entries of the tensor covariate, to model the nonlinearity in tensor regression nonparametrically. A penalized estimation and the corresponding algorithm are proposed. Our theoretical investigation, which allows the dimensions of the tensor covariate to diverge, indicates that the proposed estimation yields a desirable convergence rate. We also provide a minimax lower bound, which characterizes the optimality of the proposed estimator for a wide range of scenarios. Numerical experiments are conducted to confirm the theoretical findings, and they show that the proposed model has advantages over its existing linear counterparts.},
  archive      = {J_JRSSSB},
  author       = {Zhou, Ya and Wong, Raymond K W and He, Kejun},
  doi          = {10.1093/jrsssb/qkae027},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1197-1220},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Broadcasted nonparametric tensor regression},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonparametric measure-transportation-based methods for
directional data. <em>JRSSSB</em>, <em>86</em>(5), 1172–1196. (<a
href="https://doi.org/10.1093/jrsssb/qkae026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes various nonparametric tools based on measure transportation for directional data. We use optimal transports to define new notions of distribution and quantile functions on the hypersphere, with meaningful quantile contours and regions and closed-form formulas under the classical assumption of rotational symmetry. The empirical versions of our distribution functions enjoy the expected Glivenko–Cantelli property of traditional distribution functions. They provide fully distribution-free concepts of ranks and signs and define data-driven systems of (curvilinear) parallels and (hyper)meridians. Based on this, we also construct a universally consistent test of uniformity and a class of fully distribution-free and universally consistent tests for directional MANOVA which, in simulations, outperform all their existing competitors. A real-data example involving the analysis of sunspots concludes the article.},
  archive      = {J_JRSSSB},
  author       = {Hallin, M and Liu, H and Verdebout, T},
  doi          = {10.1093/jrsssb/qkae026},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1172-1196},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Nonparametric measure-transportation-based methods for directional data},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Authors’ reply to the discussion of “safe testing.”
<em>JRSSSB</em>, <em>86</em>(5), 1163–1171. (<a
href="https://doi.org/10.1093/jrsssb/qkae069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Grünwald, Peter and de Heide, Rianne and Koolen, Wouter},
  doi          = {10.1093/jrsssb/qkae069},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1163-1171},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Authors’ reply to the discussion of ‘Safe testing’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zihao wen and david l. Dowe’s contribution to the discussion
of “safe testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1161–1162. (<a
href="https://doi.org/10.1093/jrsssb/qkae067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Wen, Zihao and Dowe, David L},
  doi          = {10.1093/jrsssb/qkae067},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1161-1162},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Zihao wen and david l. dowe’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maozai tian, keming yu and jiangfeng wang’s contribution to
the discussion of “safe testing” by grünwald, de heide, and koolen.
<em>JRSSSB</em>, <em>86</em>(5), 1160. (<a
href="https://doi.org/10.1093/jrsssb/qkae076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Tian, Maozai and Yu, Keming and Wang, Jiangfeng},
  doi          = {10.1093/jrsssb/qkae076},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1160},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Maozai tian, keming yu and jiangfeng wang’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Andrej srakar’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1159. (<a
href="https://doi.org/10.1093/jrsssb/qkae062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Srakar, Andrej},
  doi          = {10.1093/jrsssb/qkae062},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1159},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Andrej srakar’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Judith ter schure’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1157–1159. (<a
href="https://doi.org/10.1093/jrsssb/qkae065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {ter Schure, Judith},
  doi          = {10.1093/jrsssb/qkae065},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1157-1159},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Judith ter schure’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Christian p. Robert and joshua bon’s contribution to the
discussion of “safe testing” by grünwald, de heide, and koolen.
<em>JRSSSB</em>, <em>86</em>(5), 1156–1157. (<a
href="https://doi.org/10.1093/jrsssb/qkae072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Robert, Christian P and Bon, Joshua},
  doi          = {10.1093/jrsssb/qkae072},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1156-1157},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Christian p. robert and joshua bon’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stefano rizzelli’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1155–1156. (<a
href="https://doi.org/10.1093/jrsssb/qkae075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Rizzelli, Stefano},
  doi          = {10.1093/jrsssb/qkae075},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1155-1156},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Stefano rizzelli’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Samuel pawel and leonhard held’s contribution to the
discussion of “safe testing” by grünwald, de heide, and koolen.
<em>JRSSSB</em>, <em>86</em>(5), 1153–1155. (<a
href="https://doi.org/10.1093/jrsssb/qkae064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Pawel, Samuel and Held, Leonhard},
  doi          = {10.1093/jrsssb/qkae064},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1153-1155},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Samuel pawel and leonhard held’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Luigi pace and alessandra salvan’s contribution to the
discussion of “safe testing” by grünwald, de heide, and koolen.
<em>JRSSSB</em>, <em>86</em>(5), 1152–1153. (<a
href="https://doi.org/10.1093/jrsssb/qkae078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Pace, Luigi and Salvan, Alessandra},
  doi          = {10.1093/jrsssb/qkae078},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1152-1153},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Luigi pace and alessandra salvan’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Alexander ly’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1150. (<a
href="https://doi.org/10.1093/jrsssb/qkae073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Ly, Alexander},
  doi          = {10.1093/jrsssb/qkae073},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1150},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Alexander ly’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joris mulder’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1150–1152. (<a
href="https://doi.org/10.1093/jrsssb/qkae080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Mulder, Joris},
  doi          = {10.1093/jrsssb/qkae080},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1150-1152},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Joris mulder’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sander greenland’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1148–1149. (<a
href="https://doi.org/10.1093/jrsssb/qkae068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Greenland, Sander},
  doi          = {10.1093/jrsssb/qkae068},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1148-1149},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Sander greenland’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neil dey, ryan martin, and jonathan p. Williams’
contribution to the discussion of “safe testing” by grünwald, de heide,
and koolen. <em>JRSSSB</em>, <em>86</em>(5), 1147–1148. (<a
href="https://doi.org/10.1093/jrsssb/qkae063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Dey, Neil and Martin, Ryan and Williams, Jonathan P},
  doi          = {10.1093/jrsssb/qkae063},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1147-1148},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Neil dey, ryan martin, and jonathan p. williams’ contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Christine p. Chai’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1146–1147. (<a
href="https://doi.org/10.1093/jrsssb/qkae081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Chai, Christine P},
  doi          = {10.1093/jrsssb/qkae081},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1146-1147},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Christine p. chai’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Marco cattaneo’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1145. (<a
href="https://doi.org/10.1093/jrsssb/qkae074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Cattaneo, Marco E G V},
  doi          = {10.1093/jrsssb/qkae074},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1145},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Marco cattaneo&#39;s contribution to the discussion of “Safe testing” by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joshua bon and christian p. Robert’s contribution to the
discussion of “safe testing” by grünwald, de heide, and koolen.
<em>JRSSSB</em>, <em>86</em>(5), 1143–1145. (<a
href="https://doi.org/10.1093/jrsssb/qkae070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Bon, Joshua and Robert, Christian P},
  doi          = {10.1093/jrsssb/qkae070},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1143-1145},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Joshua bon and christian p. robert’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Vladimir vovk’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1142. (<a
href="https://doi.org/10.1093/jrsssb/qkae066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Vovk, Vladimir},
  doi          = {10.1093/jrsssb/qkae066},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1142},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Vladimir vovk’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wenkai xu’s contribution to the discussion of “safe testing”
by grünwald, de heide and koolen. <em>JRSSSB</em>, <em>86</em>(5),
1139–1141. (<a href="https://doi.org/10.1093/jrsssb/qkae087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Xu, Wenkai},
  doi          = {10.1093/jrsssb/qkae087},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1139-1141},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Wenkai xu’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Christian hennig’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1138–1139. (<a
href="https://doi.org/10.1093/jrsssb/qkae077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Hennig, Christian},
  doi          = {10.1093/jrsssb/qkae077},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1138-1139},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Christian hennig’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Glenn shafer’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1137–1138. (<a
href="https://doi.org/10.1093/jrsssb/qkae079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Shafer, Glenn},
  doi          = {10.1093/jrsssb/qkae079},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1137-1138},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Glenn shafer’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Thorsten dickhaus’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1136–1137. (<a
href="https://doi.org/10.1093/jrsssb/qkae059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Dickhaus, Thorsten},
  doi          = {10.1093/jrsssb/qkae059},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1136-1137},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Thorsten dickhaus’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Martin larsson, aaditya ramdas, and johannes ruf’s
contribution to the discussion of “safe testing” by grünwald, de heide,
and koolen. <em>JRSSSB</em>, <em>86</em>(5), 1135–1136. (<a
href="https://doi.org/10.1093/jrsssb/qkae061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Larsson, Martin and Ramdas, Aaditya and Ruf, Johannes},
  doi          = {10.1093/jrsssb/qkae061},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1135-1136},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Martin larsson, aaditya ramdas, and johannes ruf’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). David r. Bickel’s contribution to the discussion of “safe
testing” by grünwald, de heide, and koolen. <em>JRSSSB</em>,
<em>86</em>(5), 1133–1134. (<a
href="https://doi.org/10.1093/jrsssb/qkae089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Bickel, David R},
  doi          = {10.1093/jrsssb/qkae089},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1133-1134},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {David r. bickel’s contribution to the discussion of ‘Safe testing’ by grünwald, de heide, and koolen},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Seconder of the vote of thanks to grünwald, de heide, and
koolen and contribution to the discussion of “safe testing.”
<em>JRSSSB</em>, <em>86</em>(5), 1131–1133. (<a
href="https://doi.org/10.1093/jrsssb/qkae060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Martin, Ryan},
  doi          = {10.1093/jrsssb/qkae060},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1131-1133},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Seconder of the vote of thanks to grünwald, de heide, and koolen and contribution to the discussion of ‘Safe testing’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Proposer of the vote of thanks to grünwald, de heide, and
koolen and contribution to the discussion of “safe testing.”
<em>JRSSSB</em>, <em>86</em>(5), 1129–1131. (<a
href="https://doi.org/10.1093/jrsssb/qkae071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Wang, Ruodu},
  doi          = {10.1093/jrsssb/qkae071},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1129-1131},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Proposer of the vote of thanks to grünwald, de heide, and koolen and contribution to the discussion of ‘Safe testing’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Safe testing. <em>JRSSSB</em>, <em>86</em>(5), 1091–1128.
(<a href="https://doi.org/10.1093/jrsssb/qkae011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop the theory of hypothesis testing based on the e -value, a notion of evidence that, unlike the p -value, allows for effortlessly combining results from several studies in the common scenario where the decision to perform a new study may depend on previous outcomes. Tests based on e -values are safe, i.e. they preserve type-I error guarantees, under such optional continuation . We define growth rate optimality (GRO) as an analogue of power in an optional continuation context, and we show how to construct GRO e -variables for general testing problems with composite null and alternative, emphasizing models with nuisance parameters. GRO e -values take the form of Bayes factors with special priors. We illustrate the theory using several classic examples including a 1-sample safe t -test and the 2 × 2 contingency table. Sharing Fisherian, Neymanian, and Jeffreys–Bayesian interpretations, e -values may provide a methodology acceptable to adherents of all three schools.},
  archive      = {J_JRSSSB},
  author       = {Grünwald, Peter and de Heide, Rianne and Koolen, Wouter},
  doi          = {10.1093/jrsssb/qkae011},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {11},
  number       = {5},
  pages        = {1091-1128},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Safe testing},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Correction to: Optimal and maximin procedures for multiple
testing problems. <em>JRSSSB</em>, <em>86</em>(4), 1089. (<a
href="https://doi.org/10.1093/jrsssb/qkae058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  doi          = {10.1093/jrsssb/qkae058},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {1089},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Correction to: Optimal and maximin procedures for multiple testing problems},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the instrumental variable estimation with many weak and
invalid instruments. <em>JRSSSB</em>, <em>86</em>(4), 1068–1088. (<a
href="https://doi.org/10.1093/jrsssb/qkae025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss the fundamental issue of identification in linear instrumental variable (IV) models with unknown IV validity. With the assumption of the ‘sparsest rule’, which is equivalent to the plurality rule but becomes operational in computation algorithms, we investigate and prove the advantages of non-convex penalized approaches over other IV estimators based on two-step selections, in terms of selection consistency and accommodation for individually weak IVs. Furthermore, we propose a surrogate sparsest penalty that aligns with the identification condition and provides oracle sparse structure simultaneously. Desirable theoretical properties are derived for the proposed estimator with weaker IV strength conditions compared to the previous literature. Finite sample properties are demonstrated using simulations and the selection and estimation method is applied to an empirical study concerning the effect of body mass index on diastolic blood pressure.},
  archive      = {J_JRSSSB},
  author       = {Lin, Yiqi and Windmeijer, Frank and Song, Xinyuan and Fan, Qingliang},
  doi          = {10.1093/jrsssb/qkae025},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {1068-1088},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {On the instrumental variable estimation with many weak and invalid instruments},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GENIUS-MAWII: For robust mendelian randomization with many
weak invalid instruments. <em>JRSSSB</em>, <em>86</em>(4), 1045–1067.
(<a href="https://doi.org/10.1093/jrsssb/qkae024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mendelian randomization (MR) addresses causal questions using genetic variants as instrumental variables. We propose a new MR method, G-Estimation under No Interaction with Unmeasured Selection (GENIUS)-MAny Weak Invalid IV, which simultaneously addresses the 2 salient challenges in MR: many weak instruments and widespread horizontal pleiotropy. Similar to MR-GENIUS, we use heteroscedasticity of the exposure to identify the treatment effect. We derive influence functions of the treatment effect, and then we construct a continuous updating estimator and establish its asymptotic properties under a many weak invalid instruments asymptotic regime by developing novel semiparametric theory. We also provide a measure of weak identification, an overidentification test, and a graphical diagnostic tool.},
  archive      = {J_JRSSSB},
  author       = {Ye, Ting and Liu, Zhonghua and Sun, Baoluo and Tchetgen Tchetgen, Eric},
  doi          = {10.1093/jrsssb/qkae024},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {1045-1067},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {GENIUS-MAWII: For robust mendelian randomization with many weak invalid instruments},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpretable discriminant analysis for functional data
supported on random nonlinear domains with an application to alzheimer’s
disease. <em>JRSSSB</em>, <em>86</em>(4), 1013–1044. (<a
href="https://doi.org/10.1093/jrsssb/qkae023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel framework for the classification of functional data supported on nonlinear, and possibly random, manifold domains. The motivating application is the identification of subjects with Alzheimer’s disease from their cortical surface geometry and associated cortical thickness map. The proposed model is based upon a reformulation of the classification problem as a regularized multivariate functional linear regression model. This allows us to adopt a direct approach to the estimation of the most discriminant direction while controlling for its complexity with appropriate differential regularization. Our approach does not require prior estimation of the covariance structure of the functional predictors, which is computationally prohibitive in our application setting. We provide a theoretical analysis of the out-of-sample prediction error of the proposed model and explore the finite sample performance in a simulation setting. We apply the proposed method to a pooled dataset from Alzheimer’s Disease Neuroimaging Initiative and Parkinson’s Progression Markers Initiative. Through this application, we identify discriminant directions that capture both cortical geometric and thickness predictive features of Alzheimer’s disease that are consistent with the existing neuroscience literature.},
  archive      = {J_JRSSSB},
  author       = {Lila, Eardi and Zhang, Wenbo and Rane Levendovszky, Swati and Alzheimer’s Disease Neuroimaging Initiative and Weiner, Michael W and Aisen, Paul and Petersen, Ronald and Jack, Clifford R and Jagust, William and Trojanowki, John Q and Toga, Arthur W and Beckett, Laurel and Green, Robert C and Saykin, Andrew J and Morris, John C and Perrin, Richard J and Shaw, Leslie M and Khachaturian, Zaven and Carrillo, Maria and Potter, William and Barnes, Lisa and Bernard, Marie and Ho, Carole and Hsiao, John K and Jackson, Jonathan and Masliah, Eliezer and Masterman, Donna and Okonkwo, Ozioma and Perrin, Richard and Ryan, Laurie and Silverberg, Nina and Fleisher, Adam and Fockler, Juliet and Conti, Cat and Veitch, Dallas and Neuhaus, John and Jin, Chengshi and Nosheny, Rachel and Ashford, Miriam and Flenniken, Derek and Kormos, Adrienne and Montine, Tom and Rafii, Michael and Raman, Rema and Jimenez, Gustavo and Donohue, Michael and Gessert, Devon and Salazar, Jennifer and Zimmerman, Caileigh and Cabrera, Yuliana and Walter, Sarah and Miller, Garrett and Coker, Godfrey and Clanton, Taylor and Hergesheimer, Lindsey and Smith, Stephanie and Adegoke, Olusegun and Mahboubi, Payam and Moore, Shelley and Pizzola, Jeremy and Shaffer, Elizabeth and Sloan, Brittany and Harvey, Danielle and Forghanian-Arani, Arvin and Borowski, Bret and Ward, Chad and Schwarz, Christopher and Jones, David and Gunter, Jeff and Kantarci, Kejal and Senjem, Matthew and Vemuri, Prashanthi and Reid, Robert and Fox, Nick C and Malone, Ian and Thompson, Paul and Thomopoulos, Sophia I and Nir, Talia M and Jahanshad, Neda and DeCarli, Charles and Knaack, Alexander and Fletcher, Evan and Tosun-Turgut, Duygu and Chen, Stephanie Rossi and Choe, Mark and Crawford, Karen and Yushkevich, Paul A and Das, Sandhitsu and Koeppe, Robert A and Reiman, Eric M and Chen, Kewei and Mathis, Chet and Landau, Susan and Cairns, Nigel J and Householder, Erin and Franklin, Erin and Bernhardt, Haley and Taylor-Reinwald, Lisa and Korecka, Magdalena and Figurski, Michal and Neu, Scott and Nho, Kwangsik and Risacher, Shannon L and Apostolova, Liana G and Shen, Li and Foroud, Tatiana M and Nudelman, Kelly and Faber, Kelley and Wilmes, Kristi and Thal, Leon and Silbert, Lisa C and Lind, Betty and Crissey, Rachel and Kaye, Jeffrey A and Carter, Raina and Dolen, Sara and Quinn, Joseph and Schneider, Lon S and Pawluczyk, Sonia and Becerra, Mauricio and Teodoro, Liberty and Dagerman, Karen and Spann, Bryan M and Brewer, James and Vanderswag, Helen and Ziolkowski, Jaimie and Heidebrink, Judith L and Zbizek-Nulph, Lisa and Lord, Joanne L and Mason, Sara S and Albers, Colleen S and Knopman, David and Johnson, Kris and Villanueva-Meyer, Javier and Pavlik, Valory and Pacini, Nathaniel and Lamb, Ashley and Kass, Joseph S and Doody, Rachelle S and Shibley, Victoria and Chowdhury, Munir and Rountree, Susan and Dang, Mimi and Stern, Yaakov and Honig, Lawrence S and Mintz, Akiva and Ances, Beau and Winkfield, David and Carroll, Maria and Stobbs-Cucchi, Georgia and Oliver, Angela and Creech, Mary L and Mintun, Mark A and Schneider, Stacy and Geldmacher, David and Love, Marissa Natelson and Griffith, Randall and Clark, David and Brockington, John and Marson, Daniel and Grossman, Hillel and Goldstein, Martin A and Greenberg, Jonathan and Mitsis, Effie and Shah, Raj C and Lamar, Melissa and Samuels, Patricia and Duara, Ranjan and Greig-Custo, Maria T and Rodriguez, Rosemarie and Albert, Marilyn and Onyike, Chiadi and Farrington, Leonie and Rudow, Scott and Brichko, Rottislav and Kielb, Stephanie and Smith, Amanda and Raj, Balebail Ashok and Fargher, Kristin and Sadowski, Martin and Wisniewski, Thomas and Shulman, Melanie and Faustin, Arline and Rao, Julia and Castro, Karen M and Ulysse, Anaztasia and Chen, Shannon and Sheikh, Mohammed O and Singleton-Garvin, Jamika and Doraiswamy, P Murali and Petrella, Jeffrey R and James, Olga and Wong, Terence Z and Borges-Neto, Salvador and Karlawish, Jason H and Wolk, David A and Vaishnavi, Sanjeev and Clark, Christopher M and Arnold, Steven E and Smith, Charles D and Jicha, Gregory A and El Khouli, Riham and Raslau, Flavius D and Lopez, Oscar L and Oakley, MaryAnn and Simpson, Donna M and Porsteinsson, Anton P and Martin, Kim and Kowalski, Nancy and Keltz, Melanie and Goldstein, Bonnie S and Makino, Kelly M and Ismail, M Saleem and Brand, Connie and Thai, Gaby and Pierce, Aimee and Yanez, Beatriz and Sosa, Elizabeth and Witbracht, Megan and Kelley, Brendan and Nguyen, Trung and Womack, Kyle and Mathews, Dana and Quiceno, Mary and Levey, Allan I and Lah, James J and Hajjar, Ihab and Cellar, Janet S and Burns, Jeffrey M and Swerdlow, Russell H and Brooks, William M and Silverman, Daniel H S and Kremen, Sarah and Apostolova, Liana and Tingus, Kathleen and Lu, Po H and Bartzokis, George and Woo, Ellen and Teng, Edmond and Graff-Radford, Neill R and Parfitt, Francine and Poki-Walker, Kim and Farlow, Martin R and Hake, Ann Marie and Matthews, Brandy R and Brosch, Jared R and Herring, Scott and van Dyck, Christopher H and Mecca, Adam P and Good, Susan P and MacAvoy, Martha G and Carson, Richard E and Varma, Pradeep and Chertkow, Howard and Vaitekunis, Susan and Hosein, Chris and Black, Sandra and Stefanovic, Bojana and Heyn, Chris (Chinthaka) and Hsiung, Ging-Yuek Robin and Kim, Ellen and Mudge, Benita and Sossi, Vesna and Feldman, Howard and Assaly, Michele and Finger, Elizabeth and Pasternak, Stephen and Rachinsky, Irina and Kertesz, Andrew and Drost, Dick and Rogers, John and Grant, Ian and Muse, Brittanie and Rogalski, Emily and Robson, Jordan and Mesulam, M -Marsel and Kerwin, Diana and Wu, Chuang-Kuo and Johnson, Nancy and Lipowski, Kristine and Weintraub, Sandra and Bonakdarpour, Borna and Pomara, Nunzio and Hernando, Raymundo and Sarrael, Antero and Rosen, Howard J and Miller, Bruce L and Perry, David and Turner, Raymond Scott and Johnson, Kathleen and Reynolds, Brigid and MCCann, Kelly and Poe, Jessica and Sperling, Reisa A and Johnson, Keith A and Marshall, Gad A and Yesavage, Jerome and Taylor, Joy L and Chao, Steven and Coleman, Jaila and White, Jessica D and Lane, Barton and Rosen, Allyson and Tinklenberg, Jared and Belden, Christine M and Atri, Alireza and Clark, Kelly A and Zamrini, Edward and Sabbagh, Marwan and Killiany, Ronald and Stern, Robert and Mez, Jesse and Kowall, Neil and Budson, Andrew E and Obisesan, Thomas O and Ntekim, Oyonumo E and Wolday, Saba and Khan, Javed I and Nwulia, Evaristus and Nadarajah, Sheeba and Lerner, Alan and Ogrocki, Paula and Tatsuoka, Curtis and Fatica, Parianne and Maillard, Pauline and Olichney, John and Carmichael, Owen and Bates, Vernice and Capote, Horacio and Rainka, Michelle and Borrie, Michael and Lee, T-Y and Bartha, Rob and Johnson, Sterling and Asthana, Sanjay and Carlsson, Cynthia M and Perrin, Allison and Burke, Anna and Scharre, Douglas W and Kataki, Maria and Tarawneh, Rawan and Hart, David and Zimmerman, Earl A and Celmins, Dzintra and Miller, Delwyn D and Ponto, Laura L Boles and Smith, Karen Ekstam and Koleva, Hristina and Shim, Hyungsub and Nam, Ki Won and Schultz, Susan K and Williamson, Jeff D and Craft, Suzanne and Cleveland, Jo and Yang, Mia and Sink, Kaycee M and Ott, Brian R and Drake, Jonathan and Tremont, Geoffrey and Daiello, Lori A and Drake, Jonathan D and Ritter, Aaron and Bernick, Charles and Munic, Donna and O’Connelll, Abigail and Mintzer, Jacobo and Wiliams, Arthur and Masdeu, Joseph and Shi, Jiong and Garcia, Angelica and Newhouse, Paul and Potkin, Steven and Salloway, Stephen and Malloy, Paul and Correia, Stephen and Kittur, Smita and Pearlson, Godfrey D and Blank, Karen and Anderson, Karen and Flashman, Laura A and Seltzer, Marc and Hynes, Mary L and Santulli, Robert B and Relkin, Norman and Chiang, Gloria and Lin, Michael and Ravdin, Lisa and Lee, Athena and Neylan, Thomas and Grafman, Jordan and Danowski, Sarah and Nguyen-Barrera, Catherine and Hayes, Jacqueline and Finley, Shannon and Bernstein, Matthew and Senjem, Matt and Foster, Norm and Kim, Sungeun and Sood, Ajay and Blanchard, Kimberly S and Fleischman, Debra and Arfanakis, Konstantinos and Varon, Daniel and Greig, Maria T and Goldstein, Bonnie and Martin, Kimberly S and Reist, Christopher and Sadowsky, Carl and Martinez, Walter and Villena, Teresa and Rosen, Howard and Marshall, Gad and Peskind, Elaine R and Petrie, Eric C and Li, Gail and Mackin, Scott and Jimenez-Maggiora, Gustavo and Drake, Erin and Donohue, Mike and Nelson, Craig and Bickford, David and Butters, Meryl and Zmuda, Michelle and Reyes, Denise and Faber, Kelley M and Nudelman, Kelly N and Au, Yiu Ho and Scherer, Kelly and Catalinotto, Daniel and Stark, Samuel and Ong, Elise and Fernandez, Dariella},
  doi          = {10.1093/jrsssb/qkae023},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {1013-1044},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Interpretable discriminant analysis for functional data supported on random nonlinear domains with an application to alzheimer’s disease},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Testing many constraints in possibly irregular models using
incomplete u-statistics. <em>JRSSSB</em>, <em>86</em>(4), 987–1012. (<a
href="https://doi.org/10.1093/jrsssb/qkae022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of testing a null hypothesis defined by equality and inequality constraints on a statistical parameter. Testing such hypotheses can be challenging because the number of relevant constraints may be on the same order or even larger than the number of observed samples. Moreover, standard distributional approximations may be invalid due to irregularities in the null hypothesis. We propose a general testing methodology that aims to circumvent these difficulties. The constraints are estimated by incomplete U -statistics, and we derive critical values by Gaussian multiplier bootstrap. We show that the bootstrap approximation of incomplete U -statistics is valid for kernels that we call mixed degenerate when the number of combinations used to compute the incomplete U -statistic is of the same order as the sample size. It follows that our test controls type I error even in irregular settings. Furthermore, the bootstrap approximation covers high-dimensional settings making our testing strategy applicable for problems with many constraints. The methodology is applicable, in particular, when the constraints to be tested are polynomials in U-estimable parameters. As an application, we consider goodness-of-fit tests of latent-tree models for multivariate data.},
  archive      = {J_JRSSSB},
  author       = {Sturma, Nils and Drton, Mathias and Leung, Dennis},
  doi          = {10.1093/jrsssb/qkae022},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {987-1012},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Testing many constraints in possibly irregular models using incomplete U-statistics},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simultaneous false discovery proportion bounds via knockoffs
and closed testing. <em>JRSSSB</em>, <em>86</em>(4), 966–986. (<a
href="https://doi.org/10.1093/jrsssb/qkae012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose new methods to obtain simultaneous false discovery proportion bounds for knockoff-based approaches. We first investigate an approach based on Janson and Su’s k -familywise error rate control method and interpolation. We then generalize it by considering a collection of k values, and show that the bound of Katsevich and Ramdas is a special case of this method and can be uniformly improved. Next, we further generalize the method by using closed testing with a multi-weighted-sum local test statistic. This allows us to obtain a further uniform improvement and other generalizations over previous methods. We also develop an efficient shortcut for its implementation. We compare the performance of our proposed methods in simulations and apply them to a data set from the UK Biobank.},
  archive      = {J_JRSSSB},
  author       = {Li, Jinzhou and Maathuis, Marloes H and Goeman, Jelle J},
  doi          = {10.1093/jrsssb/qkae012},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {966-986},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Simultaneous false discovery proportion bounds via knockoffs and closed testing},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Doubly robust calibration of prediction sets under covariate
shift. <em>JRSSSB</em>, <em>86</em>(4), 943–965. (<a
href="https://doi.org/10.1093/jrsssb/qkae009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal prediction has received tremendous attention in recent years and has offered new solutions to problems in missing data and causal inference; yet these advances have not leveraged modern semi-parametric efficiency theory for more efficient uncertainty quantification. We consider the problem of obtaining well-calibrated prediction regions that can data adaptively account for a shift in the distribution of covariates between training and test data. Under a covariate shift assumption analogous to the standard missing at random assumption, we propose a general framework based on efficient influence functions to construct well-calibrated prediction regions for the unobserved outcome in the test sample without compromising coverage.},
  archive      = {J_JRSSSB},
  author       = {Yang, Yachong and Kuchibhotla, Arun Kumar and Tchetgen Tchetgen, Eric},
  doi          = {10.1093/jrsssb/qkae009},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {943-965},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Doubly robust calibration of prediction sets under covariate shift},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Testing high-dimensional multinomials with applications to
text analysis. <em>JRSSSB</em>, <em>86</em>(4), 922–942. (<a
href="https://doi.org/10.1093/jrsssb/qkae003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by applications in text mining and discrete distribution inference, we test for equality of probability mass functions of K groups of high-dimensional multinomial distributions. Special cases of this problem include global testing for topic models, two-sample testing in authorship attribution, and closeness testing for discrete distributions. A test statistic, which is shown to have an asymptotic standard normal distribution under the null hypothesis, is proposed. This parameter-free limiting null distribution holds true without requiring identical multinomial parameters within each group or equal group sizes. The optimal detection boundary for this testing problem is established, and the proposed test is shown to achieve this optimal detection boundary across the entire parameter space of interest. The proposed method is demonstrated in simulation studies and applied to analyse two real-world datasets to examine, respectively, variation among customer reviews of Amazon movies and the diversity of statistical paper abstracts.},
  archive      = {J_JRSSSB},
  author       = {Cai, T Tony and Ke, Zheng T and Turner, Paxton},
  doi          = {10.1093/jrsssb/qkae003},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {922-942},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Testing high-dimensional multinomials with applications to text analysis},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Full-model estimation for non-parametric multivariate finite
mixture models. <em>JRSSSB</em>, <em>86</em>(4), 896–921. (<a
href="https://doi.org/10.1093/jrsssb/qkae002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of full-model estimation for non-parametric finite mixture models. It presents an approach for selecting the number of components and the subset of discriminative variables (i.e. the subset of variables having different distributions among the mixture components) by considering an upper bound on the number of components (this number being allowed to increase with the sample size). The proposed approach considers a discretization of each variable into B bins and a penalization of the resulting log-likelihood. Considering that the number of bins tends to infinity as the sample size tends to infinity, we prove that our estimator of the model (number of components and subset of relevant variables for clustering) is consistent under a suitable choice of the penalty term. The relevance of our proposal is illustrated on simulated and benchmark data.},
  archive      = {J_JRSSSB},
  author       = {Du Roy de Chaumaray, Marie and Marbac, Matthieu},
  doi          = {10.1093/jrsssb/qkae002},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {896-921},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Full-model estimation for non-parametric multivariate finite mixture models},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Authors’ reply to the discussion of “root and community
inference on the latent growth process of a network.” <em>JRSSSB</em>,
<em>86</em>(4), 885–895. (<a
href="https://doi.org/10.1093/jrsssb/qkae052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Crane, Harry and Xu, Min},
  doi          = {10.1093/jrsssb/qkae052},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {885-895},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Authors’ reply to the discussion of ‘Root and community inference on the latent growth process of a network’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Jason wyse, james ng, arthur white and michael fop’s
contribution to the discussion of ‘root and community inference on the
latent growth process of a network’ by crane and xu. <em>JRSSSB</em>,
<em>86</em>(4), 884–885. (<a
href="https://doi.org/10.1093/jrsssb/qkae049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Wyse, Jason and Ng, James and White, Arthur and Fop, Michael},
  doi          = {10.1093/jrsssb/qkae049},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {884-885},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Jason wyse, james ng, arthur white and michael fop&#39;s contribution to the discussion of ‘Root and community inference on the latent growth process of a network&#39; by crane and xu},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fan wang, yi yu and alessandro rinaldo’s contribution to the
discussion of “root and community inference on the latent growth process
of a network” by crane and xu. <em>JRSSSB</em>, <em>86</em>(4), 883–884.
(<a href="https://doi.org/10.1093/jrsssb/qkae054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Wang, Fan and Yu, Yi and Rinaldo, Alessandro},
  doi          = {10.1093/jrsssb/qkae054},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {883-884},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Fan wang, yi yu and alessandro rinaldo&#39;s contribution to the discussion of ‘Root and community inference on the latent growth process of a network’ by crane and xu},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Qing yang and xin tong’s contribution to the discussion of
“root and community inference on the latent growth process of a network”
by crane and xu. <em>JRSSSB</em>, <em>86</em>(4), 881–882. (<a
href="https://doi.org/10.1093/jrsssb/qkae050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Yang, Qing and Tong, Xin},
  doi          = {10.1093/jrsssb/qkae050},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {881-882},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Qing yang and xin tong’s contribution to the discussion of ‘Root and community inference on the latent growth process of a network’ by crane and xu},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tianxi li’s contribution to the discussion of “root and
community inference on the latent growth process of a network” by crane
and xu. <em>JRSSSB</em>, <em>86</em>(4), 880–881. (<a
href="https://doi.org/10.1093/jrsssb/qkae046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Li, Tianxi},
  doi          = {10.1093/jrsssb/qkae046},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {880-881},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Tianxi li’s contribution to the discussion of ‘Root and community inference on the latent growth process of a network’ by crane and xu},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Yicong jiang and zheng tracy ke’s contribution to the
discussion of “root and community inference on the latent growth process
of a network” by crane and xu. <em>JRSSSB</em>, <em>86</em>(4), 878–880.
(<a href="https://doi.org/10.1093/jrsssb/qkae048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Jiang, Yicong and Ke, Zheng Tracy},
  doi          = {10.1093/jrsssb/qkae048},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {878-880},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Yicong jiang and zheng tracy ke’s contribution to the discussion of ‘Root and community inference on the latent growth process of a network’ by crane and xu},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Yang feng and jiajin sun’s contribution to the discussion of
“root and community inference on the latent growth process of a network”
by crane and xu. <em>JRSSSB</em>, <em>86</em>(4), 875–878. (<a
href="https://doi.org/10.1093/jrsssb/qkae055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Feng, Yang and Sun, Jiajin},
  doi          = {10.1093/jrsssb/qkae055},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {875-878},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Yang feng and jiajin sun’s contribution to the discussion of ‘Root and community inference on the latent growth process of a network’ by crane and xu},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Marta catalano, augusto fasano, matteo giordano, and
giovanni rebaudo’s contribution to the discussion of “root and community
inference on the latent growth process of a network” by crane and xu.
<em>JRSSSB</em>, <em>86</em>(4), 874–875. (<a
href="https://doi.org/10.1093/jrsssb/qkae051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Catalano, Marta and Fasano, Augusto and Giordano, Matteo and Rebaudo, Giovanni},
  doi          = {10.1093/jrsssb/qkae051},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {874-875},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Marta catalano, augusto fasano, matteo giordano, and giovanni rebaudo’s contribution to the discussion of ‘Root and community inference on the latent growth process of a network’ by crane and xu},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sayan banerjee’s contribution to the discussion of “root and
community inference on the latent growth process of a network” by crane
and xu. <em>JRSSSB</em>, <em>86</em>(4), 873–874. (<a
href="https://doi.org/10.1093/jrsssb/qkae047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Banerjee, Sayan},
  doi          = {10.1093/jrsssb/qkae047},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {873-874},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Sayan banerjee’s contribution to the discussion of ‘Root and community inference on the latent growth process of a network’ by crane and xu},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Filippo ascolani, antonio lijoi and igor prünster’s
contribution to the discussion of “root and community inference on the
latent growth process of a network” by crane and xu. <em>JRSSSB</em>,
<em>86</em>(4), 871–872. (<a
href="https://doi.org/10.1093/jrsssb/qkae045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Ascolani, Filippo and Lijoi, Antonio and Prünster, Igor},
  doi          = {10.1093/jrsssb/qkae045},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {871-872},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Filippo ascolani, antonio lijoi and igor prünster’s contribution to the discussion of ‘Root and community inference on the latent growth process of a network’ by crane and xu},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Andrej srakar’s contribution to the discussion of “root and
community inference on the latent growth process of a network” by crane
and xu. <em>JRSSSB</em>, <em>86</em>(4), 870–871. (<a
href="https://doi.org/10.1093/jrsssb/qkae044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Srakar, Andrej},
  doi          = {10.1093/jrsssb/qkae044},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {870-871},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Andrej srakar’s contribution to the discussion of ‘Root and community inference on the latent growth process of a network’ by crane and xu},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Seconder of the vote of thanks to crane and xu and
contribution to the discussion of “root and community inference on the
latent growth process of a network.” <em>JRSSSB</em>, <em>86</em>(4),
867–870. (<a href="https://doi.org/10.1093/jrsssb/qkae053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Rubin-Delanchy, Patrick},
  doi          = {10.1093/jrsssb/qkae053},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {867-870},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Seconder of the vote of thanks to crane and xu and contribution to the discussion of ‘Root and community inference on the latent growth process of a network’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proposers of the vote of thanks to crane and xu and
contribution to the discussion of “root and community inference on the
latent growth process of a network.” <em>JRSSSB</em>, <em>86</em>(4),
866–867. (<a href="https://doi.org/10.1093/jrsssb/qkae043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Jog, Varun and Loh, Po-Ling},
  doi          = {10.1093/jrsssb/qkae043},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {866-867},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Proposers of the vote of thanks to crane and xu and contribution to the discussion of ‘Root and community inference on the latent growth process of a network’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Root and community inference on the latent growth process
of a network. <em>JRSSSB</em>, <em>86</em>(4), 825–865. (<a
href="https://doi.org/10.1093/jrsssb/qkad102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many statistical models for networks overlook the fact that most real-world networks are formed through a growth process. To address this, we introduce the Preferential Attachment Plus Erdős–Rényi model, where we let a random network G be the union of a preferential attachment (PA) tree T and additional Erdős–Rényi (ER) random edges. The PA tree captures the underlying growth process of a network where vertices/edges are added sequentially, while the ER component can be regarded as noise. Given only one snapshot of the final network G ⁠ , we study the problem of constructing confidence sets for the root node of the unobserved growth process; the root node can be patient zero in an infection network or the source of fake news in a social network. We propose inference algorithms based on Gibbs sampling that scales to networks with millions of nodes and provide theoretical analysis showing that the size of the confidence set is small if the noise level of the ER edges is not too large. We also propose variations of the model in which multiple growth processes occur simultaneously, reflecting the growth of multiple communities; we use these models to provide a new approach to community detection.},
  archive      = {J_JRSSSB},
  author       = {Crane, Harry and Xu, Min},
  doi          = {10.1093/jrsssb/qkad102},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {9},
  number       = {4},
  pages        = {825-865},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Root and community inference on the latent growth process of a network},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Correction to: Ruodu wang’s contribution to the discussion
of “estimating means of bounded random variables by betting” by
waudby-smith and ramdas. <em>JRSSSB</em>, <em>86</em>(3), 824. (<a
href="https://doi.org/10.1093/jrsssb/qkae028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  doi          = {10.1093/jrsssb/qkae028},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {824},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Correction to: Ruodu wang&#39;s contribution to the discussion of ‘Estimating means of bounded random variables by betting’ by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-parametric tensor factor analysis by iteratively
projected singular value decomposition. <em>JRSSSB</em>, <em>86</em>(3),
793–823. (<a href="https://doi.org/10.1093/jrsssb/qkae001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a general framework of Semi-parametric TEnsor Factor Analysis (STEFA) that focuses on the methodology and theory of low-rank tensor decomposition with auxiliary covariates. Semi-parametric TEnsor Factor Analysis models extend tensor factor models by incorporating auxiliary covariates in the loading matrices. We propose an algorithm of iteratively projected singular value decomposition (IP-SVD) for the semi-parametric estimation. It iteratively projects tensor data onto the linear space spanned by the basis functions of covariates and applies singular value decomposition on matricized tensors over each mode. We establish the convergence rates of the loading matrices and the core tensor factor. The theoretical results only require a sub-exponential noise distribution, which is weaker than the assumption of sub-Gaussian tail of noise in the literature. Compared with the Tucker decomposition, IP-SVD yields more accurate estimators with a faster convergence rate. Besides estimation, we propose several prediction methods with new covariates based on the STEFA model. On both synthetic and real tensor data, we demonstrate the efficacy of the STEFA model and the IP-SVD algorithm on both the estimation and prediction tasks.},
  archive      = {J_JRSSSB},
  author       = {Chen, Elynn Y and Xia, Dong and Cai, Chencheng and Fan, Jianqing},
  doi          = {10.1093/jrsssb/qkae001},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {793-823},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Semi-parametric tensor factor analysis by iteratively projected singular value decomposition},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating a directed tree for extremes. <em>JRSSSB</em>,
<em>86</em>(3), 771–792. (<a
href="https://doi.org/10.1093/jrsssb/qkad165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method to estimate a root-directed spanning tree from extreme data. Prominent example is a river network, to be discovered from extreme flow measured at a set of stations. Our new algorithm utilizes qualitative aspects of a max-linear Bayesian network, which has been designed for modelling causality in extremes. The algorithm estimates bivariate scores and returns a root-directed spanning tree. It performs extremely well on benchmark data and on new data. We prove that the new estimator is consistent under a max-linear Bayesian network model with noise. We also assess its strengths and limitations in a small simulation study.},
  archive      = {J_JRSSSB},
  author       = {Tran, Ngoc Mai and Buck, Johannes and Klüppelberg, Claudia},
  doi          = {10.1093/jrsssb/qkad165},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {771-792},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Estimating a directed tree for extremes},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian model selection via mean-field variational
approximation. <em>JRSSSB</em>, <em>86</em>(3), 742–770. (<a
href="https://doi.org/10.1093/jrsssb/qkad164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers Bayesian model selection via mean-field (MF) variational approximation. Towards this goal, we study the non-asymptotic properties of MF inference that allows latent variables and model misspecification. Concretely, we show a Bernstein–von Mises (BvM) theorem for the variational distribution from MF under possible model misspecification, which implies the distributional convergence of MF variational approximation to a normal distribution centring at the maximal likelihood estimator. Motivated by the BvM theorem, we propose a model selection criterion using the evidence lower bound (ELBO), and demonstrate that the model selected by ELBO tends to asymptotically agree with the one selected by the commonly used Bayesian information criterion (BIC) as the sample size tends to infinity. Compared to BIC, ELBO tends to incur smaller approximation error to the log-marginal likelihood (a.k.a. model evidence) due to a better dimension dependence and full incorporation of the prior information. Moreover, we show the geometric convergence of the coordinate ascent variational inference algorithm, which provides a practical guidance on how many iterations one typically needs to run when approximating the ELBO. These findings demonstrate that variational inference is capable of providing a computationally efficient alternative to conventional approaches in tasks beyond obtaining point estimates.},
  archive      = {J_JRSSSB},
  author       = {Zhang, Yangfan and Yang, Yun},
  doi          = {10.1093/jrsssb/qkad164},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {742-770},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Bayesian model selection via mean-field variational approximation},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal individualized treatment rule for combination
treatments under budget constraints. <em>JRSSSB</em>, <em>86</em>(3),
714–741. (<a href="https://doi.org/10.1093/jrsssb/qkad141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The individualized treatment rule (ITR), which recommends an optimal treatment based on individual characteristics, has drawn considerable interest from many areas such as precision medicine, personalized education, and personalized marketing. Existing ITR estimation methods mainly adopt 1 of 2 or more treatments. However, a combination of multiple treatments could be more powerful in various areas. In this paper, we propose a novel double encoder model (DEM) to estimate the ITR for combination treatments. The proposed double encoder model is a nonparametric model which not only flexibly incorporates complex treatment effects and interaction effects among treatments but also improves estimation efficiency via the parameter-sharing feature. In addition, we tailor the estimated ITR to budget constraints through a multi-choice knapsack formulation, which enhances our proposed method under restricted-resource scenarios. In theory, we provide the value reduction bound with or without budget constraints, and an improved convergence rate with respect to the number of treatments under the DEM. Our simulation studies show that the proposed method outperforms the existing ITR estimation in various settings. We also demonstrate the superior performance of the proposed method in patient-derived xenograft data that recommends optimal combination treatments to shrink the tumour size of the colorectal cancer.},
  archive      = {J_JRSSSB},
  author       = {Xu, Qi and Fu, Haoda and Qu, Annie},
  doi          = {10.1093/jrsssb/qkad141},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {714-741},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Optimal individualized treatment rule for combination treatments under budget constraints},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gradient synchronization for multivariate functional data,
with application to brain connectivity. <em>JRSSSB</em>, <em>86</em>(3),
694–713. (<a href="https://doi.org/10.1093/jrsssb/qkad140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying the association between components of multivariate random curves is of general interest and is a ubiquitous and basic problem that can be addressed with functional data analysis. An important application is the problem of assessing functional connectivity based on functional magnetic resonance imaging (fMRI), where one aims to determine the similarity of fMRI time courses that are recorded on anatomically separated brain regions. In the functional brain connectivity literature, the static temporal Pearson correlation has been the prevailing measure for functional connectivity. However, recent research has revealed temporally changing patterns of functional connectivity, leading to the study of dynamic functional connectivity. This motivates new similarity measures for pairs of random curves that reflect the dynamic features of functional similarity. Specifically, we introduce gradient synchronization measures in a general setting. These similarity measures are based on the concordance and discordance of the gradients between paired smooth random functions. Asymptotic normality of the proposed estimates is obtained under regularity conditions. We illustrate the proposed synchronization measures via simulations and an application to resting-state fMRI signals from the Alzheimer’s Disease Neuroimaging Initiative and they are found to improve discrimination between subjects with different disease status.},
  archive      = {J_JRSSSB},
  author       = {Chen, Yaqing and Lin, Shu-Chin and Zhou, Yang and Carmichael, Owen and Müller, Hans-Georg and Wang, Jane-Ling and Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1093/jrsssb/qkad140},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {694-713},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Gradient synchronization for multivariate functional data, with application to brain connectivity},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrative conformal p-values for out-of-distribution
testing with labelled outliers. <em>JRSSSB</em>, <em>86</em>(3),
671–693. (<a href="https://doi.org/10.1093/jrsssb/qkad138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a conformal inference method for out-of-distribution testing that leverages side information from labelled outliers, which are commonly underutilized or even discarded by conventional conformal p -values. This solution is practical and blends inductive and transductive inference strategies to adaptively weight conformal p -values, while also automatically leveraging the most powerful model from a collection of one-class and binary classifiers. Further, this approach leads to rigorous false discovery rate control in multiple testing when combined with a conditional calibration strategy. Extensive numerical simulations show that the proposed method outperforms existing approaches.},
  archive      = {J_JRSSSB},
  author       = {Liang, Ziyi and Sesia, Matteo and Sun, Wenguang},
  doi          = {10.1093/jrsssb/qkad138},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {671-693},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Integrative conformal p-values for out-of-distribution testing with labelled outliers},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simultaneous directional inference. <em>JRSSSB</em>,
<em>86</em>(3), 650–670. (<a
href="https://doi.org/10.1093/jrsssb/qkad137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of inference on the signs of n &gt; 1 parameters. We aim to provide 1 − α post hoc confidence bounds on the number of positive and negative (or non-positive) parameters, with a simultaneous guarantee, for all subsets of parameters. We suggest to start by using the data to select the direction of the hypothesis test for each parameter; then, adjust the p -values of the one-sided hypotheses for the selection, and use the adjusted p -values for simultaneous inference on the selected n one-sided hypotheses. The adjustment is straightforward assuming the p -values of one-sided hypotheses have densities with monotone likelihood ratio, and are mutually independent. We show the bounds we provide are tighter (often by a great margin) than existing alternatives, and that they can be obtained by at most a polynomial time. We demonstrate their usefulness in the evaluation of treatment effects across studies or subgroups. Specifically, we provide a tight lower bound on the number of studies which are beneficial, as well as on the number of studies which are harmful (or non-beneficial), and in addition conclude on the effect direction of individual studies, while guaranteeing that the probability of at least one wrong inference is at most 0.05.},
  archive      = {J_JRSSSB},
  author       = {Heller, Ruth and Solari, Aldo},
  doi          = {10.1093/jrsssb/qkad137},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {650-670},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Simultaneous directional inference},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Policy evaluation for temporal and/or spatial dependent
experiments. <em>JRSSSB</em>, <em>86</em>(3), 623–649. (<a
href="https://doi.org/10.1093/jrsssb/qkad136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this article is to establish a causal link between the policies implemented by technology companies and the outcomes they yield within intricate temporal and/or spatial dependent experiments. We propose a novel temporal/spatio-temporal Varying Coefficient Decision Process model, capable of effectively capturing the evolving treatment effects in situations characterized by temporal and/or spatial dependence. Our methodology encompasses the decomposition of the average treatment effect into the direct effect (DE) and the indirect effect (IE). We subsequently devise comprehensive procedures for estimating and making inferences about both DE and IE. Additionally, we provide a rigorous analysis of the statistical properties of these procedures, such as asymptotic power. To substantiate the effectiveness of our approach, we carry out extensive simulations and real data analyses.},
  archive      = {J_JRSSSB},
  author       = {Luo, Shikai and Yang, Ying and Shi, Chengchun and Yao, Fang and Ye, Jieping and Zhu, Hongtu},
  doi          = {10.1093/jrsssb/qkad136},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {623-649},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Policy evaluation for temporal and/or spatial dependent experiments},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The HulC: Confidence regions from convex hulls.
<em>JRSSSB</em>, <em>86</em>(3), 586–622. (<a
href="https://doi.org/10.1093/jrsssb/qkad134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop and analyse the HulC, an intuitive and general method for constructing confidence sets using the convex hull of estimates constructed from subsets of the data. Unlike classical methods which are based on estimating the (limiting) distribution of an estimator, the HulC is often simpler to use and effectively bypasses this step. In comparison to the bootstrap, the HulC requires fewer regularity conditions and succeeds in many examples where the bootstrap provably fails. Unlike sub-sampling, the HulC does not require knowledge of the rate of convergence of the estimators on which it is based. The validity of the HulC requires knowledge of the (asymptotic) median bias of the estimators. We further analyse a variant of our basic method, called the Adaptive HulC, which is fully data-driven and estimates the median bias using sub-sampling. We discuss these methods in the context of several challenging inferential problems which arise in parametric, semi-parametric, and non-parametric inference. Although our focus is on validity under weak regularity conditions, we also provide some general results on the width of the HulC confidence sets, showing that in many cases the HulC confidence sets have near-optimal width.},
  archive      = {J_JRSSSB},
  author       = {Kuchibhotla, Arun Kumar and Balakrishnan, Sivaraman and Wasserman, Larry},
  doi          = {10.1093/jrsssb/qkad134},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {586-622},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {The HulC: Confidence regions from convex hulls},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Authors’ reply to the discussion of “parameterizing and
simulating from causal models.” <em>JRSSSB</em>, <em>86</em>(3),
582–585. (<a href="https://doi.org/10.1093/jrsssb/qkae057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Evans, Robin J and Didelez, Vanessa},
  doi          = {10.1093/jrsssb/qkae057},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {582-585},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Authors’ reply to the discussion of ‘Parameterizing and simulating from causal models’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gregor steiner and mark steel’s contribution to the
discussion of “parameterizing and simulating from causal models” by
evans and didelez. <em>JRSSSB</em>, <em>86</em>(3), 580–582. (<a
href="https://doi.org/10.1093/jrsssb/qkae021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Steiner, Gregor and Steel, Mark F J},
  doi          = {10.1093/jrsssb/qkae021},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {580-582},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Gregor steiner and mark steel’s contribution to the discussion of ‘Parameterizing and simulating from causal models’ by evans and didelez},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Thomas s. Richardson and james m. Robins’ contribution to
the discussion of “parameterizing and simulating from causal models” by
evans and didelez. <em>JRSSSB</em>, <em>86</em>(3), 578–580. (<a
href="https://doi.org/10.1093/jrsssb/qkae020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Richardson, Thomas S and Robins, James M},
  doi          = {10.1093/jrsssb/qkae020},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {578-580},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Thomas s. richardson and james m. robins’ contribution to the discussion of ‘Parameterizing and simulating from causal models’ by evans and didelez},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Torben martinussen’s contribution to the discussion of
“parameterizing and simulating from causal models” by evans and didelez.
<em>JRSSSB</em>, <em>86</em>(3), 577–578. (<a
href="https://doi.org/10.1093/jrsssb/qkae017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Martinussen, Torben},
  doi          = {10.1093/jrsssb/qkae017},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {577-578},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Torben martinussen’s contribution to the discussion of ‘Parameterizing and simulating from causal models’ by evans and didelez},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A. Philip dawid’s contribution to the discussion of
“parameterizing and simulating from causal models” by evans and didelez.
<em>JRSSSB</em>, <em>86</em>(3), 576–577. (<a
href="https://doi.org/10.1093/jrsssb/qkae016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Dawid, A Philip},
  doi          = {10.1093/jrsssb/qkae016},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {576-577},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {A. philip dawid’s contribution to the discussion of ‘Parameterizing and simulating from causal models’ by evans and didelez},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heather battey’s contribution to the discussion of
“parameterizing and simulating from causal models” by evans and didelez.
<em>JRSSSB</em>, <em>86</em>(3), 575–576. (<a
href="https://doi.org/10.1093/jrsssb/qkae019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Battey, Heather S},
  doi          = {10.1093/jrsssb/qkae019},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {575-576},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Heather battey’s contribution to the discussion of ‘Parameterizing and simulating from causal models’ by evans and didelez},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rajendra bhansali’s contribution to the discussion of
“parameterizing and simulating from causal models” by evans and didelez.
<em>JRSSSB</em>, <em>86</em>(3), 575. (<a
href="https://doi.org/10.1093/jrsssb/qkae014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Bhansali, Rajendra},
  doi          = {10.1093/jrsssb/qkae014},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {575},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Rajendra bhansali’s contribution to the discussion of ‘Parameterizing and simulating from causal models’ by evans and didelez},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Richard guo’s contribution to the discussion of
“parameterizing and simulating from causal models” by evans and didelez.
<em>JRSSSB</em>, <em>86</em>(3), 572–574. (<a
href="https://doi.org/10.1093/jrsssb/qkae018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Guo, F Richard},
  doi          = {10.1093/jrsssb/qkae018},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {572-574},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Richard guo’s contribution to the discussion of ‘Parameterizing and simulating from causal models’ by evans and didelez},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Seconder of the vote of thanks to evans and didelez and
contribution to the discussion of “parameterizing and simulating from
causal models.” <em>JRSSSB</em>, <em>86</em>(3), 571–572. (<a
href="https://doi.org/10.1093/jrsssb/qkae013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Silva, Ricardo},
  doi          = {10.1093/jrsssb/qkae013},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {571-572},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Seconder of the vote of thanks to evans and didelez and contribution to the discussion of ‘Parameterizing and simulating from causal models’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proposer of the vote of thanks to evans and didelez and
contribution to the discussion of “parameterizing and simulating from
causal models.” <em>JRSSSB</em>, <em>86</em>(3), 569–570. (<a
href="https://doi.org/10.1093/jrsssb/qkae015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Seaman, Shaun R},
  doi          = {10.1093/jrsssb/qkae015},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {569-570},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Proposer of the vote of thanks to evans and didelez and contribution to the discussion of ‘Parameterizing and simulating from causal models’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Parameterizing and simulating from causal models.
<em>JRSSSB</em>, <em>86</em>(3), 535–568. (<a
href="https://doi.org/10.1093/jrsssb/qkad058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many statistical problems in causal inference involve a probability distribution other than the one from which data are actually observed; as an additional complication, the object of interest is often a marginal quantity of this other probability distribution. This creates many practical complications for statistical inference, even where the problem is non-parametrically identified. In particular, it is difficult to perform likelihood-based inference, or even to simulate from the model in a general way. We introduce the ‘frugal parameterization’, which places the causal effect of interest at its centre, and then builds the rest of the model around it. We do this in a way that provides a recipe for constructing a regular, non-redundant parameterization using causal quantities of interest. In the case of discrete variables, we can use odds ratios to complete the parameterization, while in the continuous case copulas are the natural choice; other possibilities are also discussed. Our methods allow us to construct and simulate from models with parametrically specified causal distributions, and fit them using likelihood-based methods, including fully Bayesian approaches. Our proposal includes parameterizations for the average causal effect and effect of treatment on the treated, as well as other causal quantities of interest.},
  archive      = {J_JRSSSB},
  author       = {Evans, Robin J and Didelez, Vanessa},
  doi          = {10.1093/jrsssb/qkad058},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {7},
  number       = {3},
  pages        = {535-568},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Parameterizing and simulating from causal models},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Least squares estimation of a quasiconvex regression
function. <em>JRSSSB</em>, <em>86</em>(2), 512–534. (<a
href="https://doi.org/10.1093/jrsssb/qkad133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a new approach for the estimation of a multivariate function based on the economic axioms of quasiconvexity (and monotonicity). On the computational side, we prove the existence of the quasiconvex constrained least squares estimator (LSE) and provide a characterisation of the function space to compute the LSE via a mixed-integer quadratic programme. On the theoretical side, we provide finite sample risk bounds for the LSE via a sharp oracle inequality. Our results allow for errors to depend on the covariates and to have only two finite moments. We illustrate the superior performance of the LSE against some competing estimators via simulation. Finally, we use the LSE to estimate the production function for the Japanese plywood industry and the cost function for hospitals across the US.},
  archive      = {J_JRSSSB},
  author       = {Mukherjee, Somabha and Patra, Rohit K and Johnson, Andrew L and Morita, Hiroshi},
  doi          = {10.1093/jrsssb/qkad133},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {512-534},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Least squares estimation of a quasiconvex regression function},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identification and estimation of causal peer effects using
double negative controls for unmeasured network confounding.
<em>JRSSSB</em>, <em>86</em>(2), 487–511. (<a
href="https://doi.org/10.1093/jrsssb/qkad132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identification and estimation of causal peer effects are challenging in observational studies for two reasons. The first is the identification challenge due to unmeasured network confounding, for example, homophily bias and contextual confounding. The second is network dependence of observations. We establish a framework that leverages a pair of negative control outcome and exposure variables (double negative controls) to non-parametrically identify causal peer effects in the presence of unmeasured network confounding. We then propose a generalised method of moments estimator and establish its consistency and asymptotic normality under an assumption about ψ -network dependence. Finally, we provide a consistent variance estimator.},
  archive      = {J_JRSSSB},
  author       = {Egami, Naoki and Tchetgen Tchetgen, Eric J},
  doi          = {10.1093/jrsssb/qkad132},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {487-511},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Identification and estimation of causal peer effects using double negative controls for unmeasured network confounding},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ensemble methods for testing a global null. <em>JRSSSB</em>,
<em>86</em>(2), 461–486. (<a
href="https://doi.org/10.1093/jrsssb/qkad131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Testing a global null is a canonical problem in statistics and has a wide range of applications. In view of the fact that no uniformly most powerful test exists, prior and/or domain knowledge are commonly used to focus on a certain class of alternatives to improve the testing power. However, it is generally challenging to develop tests that are particularly powerful against a certain class of alternatives. In this paper, motivated by the success of ensemble learning methods for prediction or classification, we propose an ensemble framework for testing that mimics the spirit of random forests to deal with the challenges. Our ensemble testing framework aggregates a collection of weak base tests to form a final ensemble test that maintains strong and robust power for global nulls. We apply the framework to four problems about global testing in different classes of alternatives arising from whole-genome sequencing (WGS) association studies. Specific ensemble tests are proposed for each of these problems, and their theoretical optimality is established in terms of Bahadur efficiency. Extensive simulations and an analysis of a real WGS dataset are conducted to demonstrate the type I error control and/or power gain of the proposed ensemble tests.},
  archive      = {J_JRSSSB},
  author       = {Liu, Yaowu and Liu, Zhonghua and Lin, Xihong},
  doi          = {10.1093/jrsssb/qkad131},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {461-486},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Ensemble methods for testing a global null},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-agency interventions for causal mediation in the
presence of intermediate confounding. <em>JRSSSB</em>, <em>86</em>(2),
435–460. (<a href="https://doi.org/10.1093/jrsssb/qkad130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent approaches to causal inference have focused on causal effects defined as contrasts between the distribution of counterfactual outcomes under hypothetical interventions on the nodes of a graphical model. In this article, we develop theory for causal effects defined with respect to a different type of intervention, one which alters the information propagated through the edges of the graph. These information transfer interventions may be more useful than node interventions in settings in which causes are non-manipulable, for example when considering race or genetics as a causes. Furthermore, information transfer interventions allow us to define path-specific decompositions which are identified in the presence of treatment-induced mediator-outcome confounding, a practical problem whose general solution remains elusive. We prove that the proposed effects provide valid statistical tests of mechanisms, unlike popular methods based on randomised interventions on the mediator. We propose efficient non-parametric estimators for a covariance version of the proposed effects, using data-adaptive regression coupled with semi-parametric efficiency theory to address model misspecification bias while retaining n -consistency and asymptotic normality. We illustrate the use of our methods in two examples using publicly available data.},
  archive      = {J_JRSSSB},
  author       = {Díaz, Iván},
  doi          = {10.1093/jrsssb/qkad130},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {435-460},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Non-agency interventions for causal mediation in the presence of intermediate confounding},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive bootstrap tests for composite null hypotheses in
the mediation pathway analysis. <em>JRSSSB</em>, <em>86</em>(2),
411–434. (<a href="https://doi.org/10.1093/jrsssb/qkad129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mediation analysis aims to assess if, and how, a certain exposure influences an outcome of interest through intermediate variables. This problem has recently gained a surge of attention due to the tremendous need for such analyses in scientific fields. Testing for the mediation effect (ME) is greatly challenged by the fact that the underlying null hypothesis (i.e. the absence of MEs) is composite. Most existing mediation tests are overly conservative and thus underpowered. To overcome this significant methodological hurdle, we develop an adaptive bootstrap testing framework that can accommodate different types of composite null hypotheses in the mediation pathway analysis. Applied to the product of coefficients test and the joint significance test, our adaptive testing procedures provide type I error control under the composite null, resulting in much improved statistical power compared to existing tests. Both theoretical properties and numerical examples of the proposed methodology are discussed.},
  archive      = {J_JRSSSB},
  author       = {He, Yinqiu and Song, Peter X K and Xu, Gongjun},
  doi          = {10.1093/jrsssb/qkad129},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {411-434},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Adaptive bootstrap tests for composite null hypotheses in the mediation pathway analysis},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Controlling the false discovery rate in transformational
sparsity: Split knockoffs. <em>JRSSSB</em>, <em>86</em>(2), 386–410. (<a
href="https://doi.org/10.1093/jrsssb/qkad126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling the False Discovery Rate (FDR) in a variable selection procedure is critical for reproducible discoveries, and it has been extensively studied in sparse linear models. However, it remains largely open in scenarios where the sparsity constraint is not directly imposed on the parameters but on a linear transformation of the parameters to be estimated. Examples of such scenarios include total variations, wavelet transforms, fused LASSO, and trend filtering. In this paper, we propose a data-adaptive FDR control method, called the Split Knockoff method, for this transformational sparsity setting. The proposed method exploits both variable and data splitting. The linear transformation constraint is relaxed to its Euclidean proximity in a lifted parameter space, which yields an orthogonal design that enables the orthogonal Split Knockoff construction. To overcome the challenge that exchangeability fails due to the heterogeneous noise brought by the transformation, new inverse supermartingale structures are developed via data splitting for provable FDR control without sacrificing power. Simulation experiments demonstrate that the proposed methodology achieves the desired FDR and power. We also provide an application to Alzheimer’s Disease study, where atrophy brain regions and their abnormal connections can be discovered based on a structural Magnetic Resonance Imaging dataset.},
  archive      = {J_JRSSSB},
  author       = {Cao, Yang and Sun, Xinwei and Yao, Yuan},
  doi          = {10.1093/jrsssb/qkad126},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {386-410},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Controlling the false discovery rate in transformational sparsity: Split knockoffs},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stratification pattern enumerator and its applications.
<em>JRSSSB</em>, <em>86</em>(2), 364–385. (<a
href="https://doi.org/10.1093/jrsssb/qkad125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space-filling designs are widely used in computer experiments. A minimum aberration-type space-filling criterion was recently proposed to rank and assess a family of space-filling designs including orthogonal array-based Latin hypercubes and strong orthogonal arrays. However, it is difficult to apply the criterion in practice because it requires intensive computation for determining the space-filling pattern, which measures the stratification properties of designs on various subregions. In this article, we propose a stratification pattern enumerator to characterise the stratification properties. The enumerator is easy to compute and can efficiently rank space-filling designs. We show that the stratification pattern enumerator is a linear combination of the space-filling pattern. Based on the connection, we develop efficient algorithms for calculating the space-filling pattern. In addition, we establish a lower bound for the stratification pattern enumerator and present construction methods for designs that achieve the lower bound using multiplication tables over Galois fields. The constructed designs have good space-filling properties in low-dimensional projections and are robust under various criteria.},
  archive      = {J_JRSSSB},
  author       = {Tian, Ye and Xu, Hongquan},
  doi          = {10.1093/jrsssb/qkad125},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {364-385},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Stratification pattern enumerator and its applications},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian predictive decision synthesis. <em>JRSSSB</em>,
<em>86</em>(2), 340–363. (<a
href="https://doi.org/10.1093/jrsssb/qkad109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-guided perspectives on model uncertainty expand traditional statistical thinking about managing, comparing, and combining inferences from sets of models. Bayesian predictive decision synthesis (BPDS) advances conceptual and theoretical foundations, and defines new methodology that explicitly integrates decision-analytic outcomes into the evaluation, comparison, and potential combination of candidate models. BPDS extends recent theoretical and practical advances based on both Bayesian predictive synthesis and empirical goal-focused model uncertainty analysis. This is enabled by the development of a novel subjective Bayesian perspective on model weighting in predictive decision settings. Illustrations come from applied contexts including optimal design for regression prediction and sequential time series forecasting for financial portfolio decisions.},
  archive      = {J_JRSSSB},
  author       = {Tallman, Emily and West, Mike},
  doi          = {10.1093/jrsssb/qkad109},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {340-363},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Bayesian predictive decision synthesis},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Authors’ reply to the discussion of “from denoising
diffusions to denoising markov models” at the discussion meeting on
“probabilistic and statistical aspects of machine learning.”
<em>JRSSSB</em>, <em>86</em>(2), 335–339. (<a
href="https://doi.org/10.1093/jrsssb/qkae010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Benton, Joe and Shi, Yuyang and De Bortoli, Valentin and Deligiannidis, George and Doucet, Arnaud},
  doi          = {10.1093/jrsssb/qkae010},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {335-339},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Authors’ reply to the discussion of ‘From denoising diffusions to denoising markov models’ at the discussion meeting on ‘Probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Authors’ reply to the discussion of “automatic change-point
detection in time series via deep learning” at the discussion meeting on
“probabilistic and statistical aspects of machine learning.”
<em>JRSSSB</em>, <em>86</em>(2), 332–334. (<a
href="https://doi.org/10.1093/jrsssb/qkae008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Li, Jie and Fearnhead, Paul and Fryzlewicz, Piotr and Wang, Tengyao},
  doi          = {10.1093/jrsssb/qkae008},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {332-334},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Authors’ reply to the discussion of ‘Automatic change-point detection in time series via deep learning’ at the discussion meeting on ‘Probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Yingnian wu and weng kee wong’s contribution to the
discussion of “the discussion meeting on probabilistic and statistical
aspects of machine learning.” <em>JRSSSB</em>, <em>86</em>(2), 331. (<a
href="https://doi.org/10.1093/jrsssb/qkad163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Wu, Ying Nian and Wong, Weng Kee},
  doi          = {10.1093/jrsssb/qkad163},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {331},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Yingnian wu and weng kee wong’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Frederic schoenberg and weng kee wong’s contribution to the
discussion of “the discussion meeting on probabilistic and statistical
aspects of machine learning.” <em>JRSSSB</em>, <em>86</em>(2), 330. (<a
href="https://doi.org/10.1093/jrsssb/qkad158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Schoenberg, Frederic and Wong, Weng Kee},
  doi          = {10.1093/jrsssb/qkad158},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {330},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Frederic schoenberg and weng kee wong’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Johannes schmidt-hieber’s contribution to the discussion of
“the discussion meeting on probabilistic and statistical aspects of
machine learning.” <em>JRSSSB</em>, <em>86</em>(2), 329. (<a
href="https://doi.org/10.1093/jrsssb/qkae007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Schmidt-Hieber, Johannes},
  doi          = {10.1093/jrsssb/qkae007},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {329},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Johannes schmidt-hieber’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sam power’s contribution to the discussion of “the
discussion meeting on probabilistic and statistical aspects of machine
learning.” <em>JRSSSB</em>, <em>86</em>(2), 328. (<a
href="https://doi.org/10.1093/jrsssb/qkad155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Power, Sam},
  doi          = {10.1093/jrsssb/qkad155},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {328},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Sam power’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tamás p. Papp, paul fearnhead, and chris sherlock’s
contribution to the discussion of “the discussion meeting on
probabilistic and statistical aspects of machine learning.”
<em>JRSSSB</em>, <em>86</em>(2), 327–328. (<a
href="https://doi.org/10.1093/jrsssb/qkae006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Papp, Tamás P and Fearnhead, Paul and Sherlock, Chris},
  doi          = {10.1093/jrsssb/qkae006},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {327-328},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Tamás p. papp, paul fearnhead, and chris sherlock’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hernando ombao’s contribution to the discussion of “the
discussion meeting on probabilistic and statistical aspects of machine
learning.” <em>JRSSSB</em>, <em>86</em>(2), 326. (<a
href="https://doi.org/10.1093/jrsssb/qkad159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Ombao, Hernando},
  doi          = {10.1093/jrsssb/qkad159},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {326},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Hernando ombao’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Jorge mateu’s contribution to the discussion of “the
discussion meeting on probabilistic and statistical aspects of machine
learning.” <em>JRSSSB</em>, <em>86</em>(2), 325–326. (<a
href="https://doi.org/10.1093/jrsssb/qkad153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Mateu, Jorge},
  doi          = {10.1093/jrsssb/qkad153},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {325-326},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Jorge mateu&#39;s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). John kent’s contribution to the discussion of the
“discussion meeting on probabilistic and statistical aspects of machine
learning.” <em>JRSSSB</em>, <em>86</em>(2), 324. (<a
href="https://doi.org/10.1093/jrsssb/qkad156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Kent, John T},
  doi          = {10.1093/jrsssb/qkad156},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {324},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {John kent’s contribution to the discussion of the ‘Discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). James jackson’s contribution to the discussion of “the
discussion meeting on probabilistic and statistical aspects of machine
learning.” <em>JRSSSB</em>, <em>86</em>(2), 322. (<a
href="https://doi.org/10.1093/jrsssb/qkad157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Jackson, James},
  doi          = {10.1093/jrsssb/qkad157},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {322},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {James jackson’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ayla jungbluth and johannes lederer’s contribution to the
discussion of “the discussion meeting on probabilistic and statistical
aspects of machine learning.” <em>JRSSSB</em>, <em>86</em>(2), 322–323.
(<a href="https://doi.org/10.1093/jrsssb/qkad154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Jungbluth, Ayla and Lederer, Johannes},
  doi          = {10.1093/jrsssb/qkad154},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {322-323},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Ayla jungbluth and johannes lederer’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Yongmiao hong, oliver linton, jiajing sun, and meiting zhu’s
contribution to the discussion of “the discussion meeting on
probabilistic and statistical aspects of machine learning.”
<em>JRSSSB</em>, <em>86</em>(2), 320–321. (<a
href="https://doi.org/10.1093/jrsssb/qkad152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Hong, Yongmiao and Linton, Oliver and Sun, Jiajing and Zhu, Meiting},
  doi          = {10.1093/jrsssb/qkad152},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {320-321},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Yongmiao hong, oliver linton, jiajing sun, and meiting zhu’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Daniela cialfi’s contribution to the discussion of “the
discussion meeting on probabilistic and statistical aspects of machine
learning.” <em>JRSSSB</em>, <em>86</em>(2), 318. (<a
href="https://doi.org/10.1093/jrsssb/qkad147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Cialfi, Daniela},
  doi          = {10.1093/jrsssb/qkad147},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {318},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Daniela cialfi’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pierre-aurelien gilliot, christophe andrieu, anthony lee,
song liu, and michael whitehouse’s contribution to the discussion of
“the discussion meeting on probabilistic and statistical aspects of
machine learning.” <em>JRSSSB</em>, <em>86</em>(2), 318–320. (<a
href="https://doi.org/10.1093/jrsssb/qkad161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Gilliot, Pierre-Aurelien and Andrieu, Christophe and Lee, Anthony and Liu, Song and Whitehouse, Michael},
  doi          = {10.1093/jrsssb/qkad161},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {318-320},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Pierre-aurelien gilliot, christophe andrieu, anthony lee, song liu, and michael whitehouse’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Yudong chen and yining chen’s contribution to the discussion
of “the discussion meeting on probabilistic and statistical aspects of
machine learning.” <em>JRSSSB</em>, <em>86</em>(2), 316–317. (<a
href="https://doi.org/10.1093/jrsssb/qkad145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Chen, Yudong and Chen, Yining},
  doi          = {10.1093/jrsssb/qkad145},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {316-317},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Yudong chen and yining chen’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dean bodenham and niall adams’s contribution to the
discussion of “the discussion meeting on probabilistic and statistical
aspects of machine learning.” <em>JRSSSB</em>, <em>86</em>(2), 315. (<a
href="https://doi.org/10.1093/jrsssb/qkad151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Bodenham, Dean and Adams, Niall},
  doi          = {10.1093/jrsssb/qkad151},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {315},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Dean bodenham and niall adams’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ivor cribben and anastasiou andreas’s contribution to the
discussion of “the discussion meeting on probabilistic and statistical
aspects of machine learning.” <em>JRSSSB</em>, <em>86</em>(2), 313–314.
(<a href="https://doi.org/10.1093/jrsssb/qkad149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Anastasiou, Andreas and Cribben, Ivor},
  doi          = {10.1093/jrsssb/qkad149},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {313-314},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Ivor cribben and anastasiou andreas’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shakeel gavioli-akilagun’s contribution to the discussion of
“the discussion meeting on probabilistic and statistical aspects of
machine learning.” <em>JRSSSB</em>, <em>86</em>(2), 312–313. (<a
href="https://doi.org/10.1093/jrsssb/qkad142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Gavioli-Akilagun, Shakeel},
  doi          = {10.1093/jrsssb/qkad142},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {312-313},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Shakeel gavioli-akilagun’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Kanti mardia’s contribution to the discussion of “the
discussion meeting on probabilistic and statistical aspects of machine
learning.” <em>JRSSSB</em>, <em>86</em>(2), 311–312. (<a
href="https://doi.org/10.1093/jrsssb/qkad144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Mardia, Kanti V},
  doi          = {10.1093/jrsssb/qkad144},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {311-312},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Kanti mardia’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Andi wang’s contribution to the discussion of “the
discussion meeting on probabilistic and statistical aspects of machine
learning.” <em>JRSSSB</em>, <em>86</em>(2), 310–311. (<a
href="https://doi.org/10.1093/jrsssb/qkad143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Wang, Andi Q},
  doi          = {10.1093/jrsssb/qkad143},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {310-311},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Andi wang’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bo zhang’s contribution to the discussion of “the discussion
meeting on probabilistic and statistical aspects of machine learning.”
<em>JRSSSB</em>, <em>86</em>(2), 309–310. (<a
href="https://doi.org/10.1093/jrsssb/qkad146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Zhang, Bo},
  doi          = {10.1093/jrsssb/qkad146},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {309-310},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Bo zhang’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gilbert MacKenzie’s contribution to the discussion of “the
discussion meeting on probabilistic and statistical aspects of machine
learning.” <em>JRSSSB</em>, <em>86</em>(2), 307–308. (<a
href="https://doi.org/10.1093/jrsssb/qkad148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {MacKenzie, Gilbert},
  doi          = {10.1093/jrsssb/qkad148},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {307-308},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Gilbert MacKenzie’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). M.n.m. Van lieshout and c. Lu’s contribution to the
discussion of “the discussion meeting on probabilistic and statistical
aspects of machine learning.” <em>JRSSSB</em>, <em>86</em>(2), 306–307.
(<a href="https://doi.org/10.1093/jrsssb/qkad150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {van Lieshout, Marie-Colette and Lu, Changqing},
  doi          = {10.1093/jrsssb/qkad150},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {306-307},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {M.N.M. van lieshout and c. lu’s contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Seconder of the vote of thanks and contribution to the
discussion of “the discussion meeting on probabilistic and statistical
aspects of machine learning.” <em>JRSSSB</em>, <em>86</em>(2), 304–306.
(<a href="https://doi.org/10.1093/jrsssb/qkad162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Nemeth, Christopher},
  doi          = {10.1093/jrsssb/qkad162},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {304-306},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Seconder of the vote of thanks and contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proposer of the vote of thanks and contribution to the
discussion of “the discussion meeting on probabilistic and statistical
aspects of machine learning.” <em>JRSSSB</em>, <em>86</em>(2), 302–304.
(<a href="https://doi.org/10.1093/jrsssb/qkad160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Wilkinson, Darren},
  doi          = {10.1093/jrsssb/qkad160},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {302-304},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Proposer of the vote of thanks and contribution to the discussion of ‘the discussion meeting on probabilistic and statistical aspects of machine learning’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). From denoising diffusions to denoising markov models.
<em>JRSSSB</em>, <em>86</em>(2), 286–301. (<a
href="https://doi.org/10.1093/jrsssb/qkae005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Denoising diffusions are state-of-the-art generative models exhibiting remarkable empirical performance. They work by diffusing the data distribution into a Gaussian distribution and then learning to reverse this noising process to obtain synthetic datapoints. The denoising diffusion relies on approximations of the logarithmic derivatives of the noised data densities using score matching. Such models can also be used to perform approximate posterior simulation when one can only sample from the prior and likelihood. We propose a unifying framework generalizing this approach to a wide class of spaces and leading to an original extension of score matching. We illustrate the resulting models on various applications.},
  archive      = {J_JRSSSB},
  author       = {Benton, Joe and Shi, Yuyang and De Bortoli, Valentin and Deligiannidis, George and Doucet, Arnaud},
  doi          = {10.1093/jrsssb/qkae005},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {286-301},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {From denoising diffusions to denoising markov models},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Automatic change-point detection in time series via deep
learning. <em>JRSSSB</em>, <em>86</em>(2), 273–285. (<a
href="https://doi.org/10.1093/jrsssb/qkae004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting change points in data is challenging because of the range of possible types of change and types of behaviour of data when there is no change. Statistically efficient methods for detecting a change will depend on both of these features, and it can be difficult for a practitioner to develop an appropriate detection method for their application of interest. We show how to automatically generate new offline detection methods based on training a neural network. Our approach is motivated by many existing tests for the presence of a change point being representable by a simple neural network, and thus a neural network trained with sufficient data should have performance at least as good as these methods. We present theory that quantifies the error rate for such an approach, and how it depends on the amount of training data. Empirical results show that, even with limited training data, its performance is competitive with the standard cumulative sum (CUSUM) based classifier for detecting a change in mean when the noise is independent and Gaussian, and can substantially outperform it in the presence of auto-correlated or heavy-tailed noise. Our method also shows strong results in detecting and localizing changes in activity based on accelerometer data.},
  archive      = {J_JRSSSB},
  author       = {Li, Jie and Fearnhead, Paul and Fryzlewicz, Piotr and Wang, Tengyao},
  doi          = {10.1093/jrsssb/qkae004},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {4},
  number       = {2},
  pages        = {273-285},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Automatic change-point detection in time series via deep learning},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Another look at bandwidth-free inference: A sample splitting
approach. <em>JRSSSB</em>, <em>86</em>(1), 246–272. (<a
href="https://doi.org/10.1093/jrsssb/qkad108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bandwidth-free tests for a multi-dimensional parameter have attracted considerable attention in econometrics and statistics literature. These tests can be conveniently implemented due to their tuning-parameter free nature and possess more accurate size as compared to the traditional heteroskedasticity and autocorrelation consistent-based approaches. However, when sample size is small/medium, these bandwidth-free tests exhibit large size distortion when both the dimension of the parameter and the magnitude of temporal dependence are moderate, making them unreliable to use in practice. In this paper, we propose a sample splitting-based approach to reduce the dimension of the parameter to one for the subsequent bandwidth-free inference. Our SS–SN (sample splitting plus self-normalisation) idea is broadly applicable to many testing problems for time series, including mean testing, testing for zero autocorrelation, and testing for a change point in multivariate mean, among others. Specifically, we propose two types of SS–SN test statistics and derive their limiting distributions under both the null and alternatives and show their effectiveness in alleviating size distortion via simulations. In addition, we obtain the limiting distributions for both SS–SN test statistics in the multivariate mean testing problem when the dimension is allowed to diverge.},
  archive      = {J_JRSSSB},
  author       = {Zhang, Yi and Shao, Xiaofeng},
  doi          = {10.1093/jrsssb/qkad108},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {246-272},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Another look at bandwidth-free inference: A sample splitting approach},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GRASP: A goodness-of-fit test for classification learning.
<em>JRSSSB</em>, <em>86</em>(1), 215–245. (<a
href="https://doi.org/10.1093/jrsssb/qkad106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance of classifiers is often measured in terms of average accuracy on test data. Despite being a standard measure, average accuracy fails in characterising the fit of the model to the underlying conditional law of labels given the features vector ( ⁠ Y ∣ X ⁠ ), e.g. due to model misspecification, over fitting, and high-dimensionality. In this paper, we consider the fundamental problem of assessing the goodness-of-fit for a general binary classifier. Our framework does not make any parametric assumption on the conditional law Y ∣ X and treats that as a black-box oracle model which can be accessed only through queries. We formulate the goodness-of-fit assessment problem as a tolerance hypothesis testing of the form H 0 : E [ D f ( B e r n ( η ( X ) ) ‖ B e r n ( η ^ ( X ) ) ) ] ≤ τ where D f represents an f -divergence function, and η ( x ) ⁠ , η ^ ( x ) ⁠ , respectively, denote the true and an estimate likelihood for a feature vector x admitting a positive label. We propose a novel test, called G oodness-of-fit with Ra ndomisation and S coring P rocedure (GRASP) for testing H 0 ⁠ , which works in finite sample settings, no matter the features (distribution-free). We also propose model-X GRASP designed for model-X settings where the joint distribution of the features vector is known. Model-X GRASP uses this distributional information to achieve better power. We evaluate the performance of our tests through extensive numerical experiments.},
  archive      = {J_JRSSSB},
  author       = {Javanmard, Adel and Mehrabi, Mohammad},
  doi          = {10.1093/jrsssb/qkad106},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {215-245},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {GRASP: A goodness-of-fit test for classification learning},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Holdout predictive checks for bayesian model criticism.
<em>JRSSSB</em>, <em>86</em>(1), 194–214. (<a
href="https://doi.org/10.1093/jrsssb/qkad105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian modelling helps applied researchers to articulate assumptions about their data and develop models tailored for specific applications. Thanks to good methods for approximate posterior inference, researchers can now easily build, use, and revise complicated Bayesian models for large and rich data. These capabilities, however, bring into focus the problem of model criticism. Researchers need tools to diagnose the fitness of their models, to understand where they fall short, and to guide their revision. In this paper, we develop a new method for Bayesian model criticism, the holdout predictive check (HPC). Holdout predictive check are built on posterior predictive check (PPC), a seminal method that checks a model by assessing the posterior predictive distribution on the observed data. However, PPC use the data twice—both to calculate the posterior predictive and to evaluate it—which can lead to uncalibrated p -values. Holdout predictive check, in contrast, compare the posterior predictive distribution to a draw from the population distribution, a heldout dataset. This method blends Bayesian modelling with frequentist assessment. Unlike the PPC, we prove that the HPC is properly calibrated. Empirically, we study HPC on classical regression, a hierarchical model of text data, and factor analysis.},
  archive      = {J_JRSSSB},
  author       = {Moran, Gemma E and Blei, David M and Ranganath, Rajesh},
  doi          = {10.1093/jrsssb/qkad105},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {194-214},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Holdout predictive checks for bayesian model criticism},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial confidence regions for combinations of excursion
sets in image analysis. <em>JRSSSB</em>, <em>86</em>(1), 177–193. (<a
href="https://doi.org/10.1093/jrsssb/qkad104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of excursion sets in imaging data is essential to a wide range of scientific disciplines such as neuroimaging, climatology, and cosmology. Despite growing literature, there is little published concerning the comparison of processes that have been sampled across the same spatial region but which reflect different study conditions. Given a set of asymptotically Gaussian random fields, each corresponding to a sample acquired for a different study condition, this work aims to provide confidence statements about the intersection, or union, of the excursion sets across all fields. Such spatial regions are of natural interest as they directly correspond to the questions ‘Where do all random fields exceed a predetermined threshold?’, or ‘Where does at least one random field exceed a predetermined threshold?’. To assess the degree of spatial variability present, our method provides, with a desired confidence, subsets and supersets of spatial regions defined by logical conjunctions (i.e. set intersections) or disjunctions (i.e. set unions), without any assumption on the dependence between the different fields. The method is verified by extensive simulations and demonstrated using task-fMRI data to identify brain regions with activation common to four variants of a working memory task.},
  archive      = {J_JRSSSB},
  author       = {Maullin-Sapey, Thomas and Schwartzman, Armin and Nichols, Thomas E},
  doi          = {10.1093/jrsssb/qkad104},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {177-193},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Spatial confidence regions for combinations of excursion sets in image analysis},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic synthetic control method for evaluating treatment
effects in auto-regressive processes. <em>JRSSSB</em>, <em>86</em>(1),
155–176. (<a href="https://doi.org/10.1093/jrsssb/qkad103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by evaluating the effects of air pollution alerts on air quality, we propose the dynamic synthetic control method for micro-level data with time-varying confounders and spatial dependence under an auto-regressive model setting. We employ the empirical likelihood to define the synthetic control weights, which ensures a unique solution and permits theoretical analysis. The dynamic matching increases the feasibility of matching and enables us to assess the unconfoundedness assumption using pre-treatment data. For statistical inference, we develop a normalised placebo test to address the asymmetry issue. The method is illustrated and evaluated on numerical simulations and a case study on air pollution alerts.},
  archive      = {J_JRSSSB},
  author       = {Zheng, Xiangyu and Chen, Song Xi},
  doi          = {10.1093/jrsssb/qkad103},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {155-176},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Dynamic synthetic control method for evaluating treatment effects in auto-regressive processes},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Derandomised knockoffs: Leveraging e-values for false
discovery rate control. <em>JRSSSB</em>, <em>86</em>(1), 122–154. (<a
href="https://doi.org/10.1093/jrsssb/qkad085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-X knockoffs is a flexible wrapper method for high-dimensional regression algorithms, which provides guaranteed control of the false discovery rate (FDR). Due to the randomness inherent to the method, different runs of model-X knockoffs on the same dataset often result in different sets of selected variables, which is undesirable in practice. In this article, we introduce a methodology for derandomising model-X knockoffs with provable FDR control. The key insight of our proposed method lies in the discovery that the knockoffs procedure is in essence an e-BH procedure. We make use of this connection and derandomise model-X knockoffs by aggregating the e -values resulting from multiple knockoff realisations. We prove that the derandomised procedure controls the FDR at the desired level, without any additional conditions (in contrast, previously proposed methods for derandomisation are not able to guarantee FDR control). The proposed method is evaluated with numerical experiments, where we find that the derandomised procedure achieves comparable power and dramatically decreased selection variability when compared with model-X knockoffs.},
  archive      = {J_JRSSSB},
  author       = {Ren, Zhimei and Barber, Rina Foygel},
  doi          = {10.1093/jrsssb/qkad085},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {122-154},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Derandomised knockoffs: Leveraging e-values for false discovery rate control},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Monte carlo goodness-of-fit tests for degree corrected and
related stochastic blockmodels. <em>JRSSSB</em>, <em>86</em>(1), 90–121.
(<a href="https://doi.org/10.1093/jrsssb/qkad084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct Bayesian and frequentist finite-sample goodness-of-fit tests for three different variants of the stochastic blockmodel for network data. Since all of the stochastic blockmodel variants are log-linear in form when block assignments are known, the tests for the latent block model versions combine a block membership estimator with the algebraic statistics machinery for testing goodness-of-fit in log-linear models. We describe Markov bases and marginal polytopes of the variants of the stochastic blockmodel and discuss how both facilitate the development of goodness-of-fit tests and understanding of model behaviour. The general testing methodology developed here extends to any finite mixture of log-linear models on discrete data, and as such is the first application of the algebraic statistics machinery for latent-variable models.},
  archive      = {J_JRSSSB},
  author       = {Karwa, Vishesh and Pati, Debdeep and Petrović, Sonja and Solus, Liam and Alexeev, Nikita and Raič, Mateja and Wilburne, Dane and Williams, Robert and Yan, Bowei},
  doi          = {10.1093/jrsssb/qkad084},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {90-121},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Monte carlo goodness-of-fit tests for degree corrected and related stochastic blockmodels},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Empirical bias-reducing adjustments to estimating functions.
<em>JRSSSB</em>, <em>86</em>(1), 62–89. (<a
href="https://doi.org/10.1093/jrsssb/qkad083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a novel, general framework for reduced-bias M -estimation from asymptotically unbiased estimating functions. The framework relies on an empirical approximation of the bias by a function of derivatives of estimating function contributions. Reduced-bias M -estimation operates either implicitly, solving empirically adjusted estimating equations, or explicitly, subtracting the estimated bias from the original M -estimates, and applies to partially or fully specified models with likelihoods or surrogate objectives. Automatic differentiation can abstract away the algebra required to implement reduced-bias M -estimation. As a result, the bias-reduction methods, we introduce have broader applicability, straightforward implementation, and less algebraic or computational effort than other established bias-reduction methods that require resampling or expectations of products of log-likelihood derivatives. If M -estimation is by maximising an objective, then there always exists a bias-reducing penalised objective. That penalised objective relates to information criteria for model selection and can be enhanced with plug-in penalties to deliver reduced-bias M -estimates with extra properties, like finiteness for categorical data models. Inferential procedures and model selection procedures for M -estimators apply unaltered with the reduced-bias M -estimates. We demonstrate and assess the properties of reduced-bias M -estimation in well-used, prominent modelling settings of varying complexity.},
  archive      = {J_JRSSSB},
  author       = {Kosmidis, Ioannis and Lunardon, Nicola},
  doi          = {10.1093/jrsssb/qkad083},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {62-89},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Empirical bias-reducing adjustments to estimating functions},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Authors’ reply to the discussion of “estimating means of
bounded random variables by betting.” <em>JRSSSB</em>, <em>86</em>(1),
53–61. (<a href="https://doi.org/10.1093/jrsssb/qkad127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Waudby-Smith, Ian and Ramdas, Aaditya},
  doi          = {10.1093/jrsssb/qkad127},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {53-61},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Authors&#39; reply to the discussion of ‘Estimating means of bounded random variables by betting’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Vladimir vovk’s contribution to the discussion of
“estimating means of bounded random variables by betting” by
waudby-smith and ramdas. <em>JRSSSB</em>, <em>86</em>(1), 52–53. (<a
href="https://doi.org/10.1093/jrsssb/qkad113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Vovk, Vladimir},
  doi          = {10.1093/jrsssb/qkad113},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {52-53},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Vladimir vovk&#39;s contribution to the discussion of “Estimating means of bounded random variables by betting” by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Philip s thomas, erik learned-miller and my phan’s
contribution to the discussion of “estimating means of bounded random
variables by betting” by waudby-smith and ramdas. <em>JRSSSB</em>,
<em>86</em>(1), 51–52. (<a
href="https://doi.org/10.1093/jrsssb/qkad124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Thomas, Philip S and Learned-Miller, Erik and Phan, My},
  doi          = {10.1093/jrsssb/qkad124},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {51-52},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Philip s thomas, erik learned-miller and my phan&#39;s contribution to the discussion of ‘Estimating means of bounded random variables by betting’ by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Philip b. Stark’s contribution to the discussion of
“estimating means of bounded random variables by betting” by
waudby-smith and ramdas. <em>JRSSSB</em>, <em>86</em>(1), 49–51. (<a
href="https://doi.org/10.1093/jrsssb/qkad122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Stark, Philip B},
  doi          = {10.1093/jrsssb/qkad122},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {49-51},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Philip b. stark’s contribution to the discussion of ‘Estimating means of bounded random variables by betting’ by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). David siegmund’s contribution to the discussion of
“estimating means of bounded random variables by betting” by
waudby-smith and ramdas. <em>JRSSSB</em>, <em>86</em>(1), 48–49. (<a
href="https://doi.org/10.1093/jrsssb/qkad117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Siegmund, David},
  doi          = {10.1093/jrsssb/qkad117},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {48-49},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {David siegmund&#39;s contribution to the discussion of “Estimating means of bounded random variables by betting” by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Art owen’s contribution to the discussion of “estimating
means of bounded random variables by betting” by waudby-smith and
ramdas. <em>JRSSSB</em>, <em>86</em>(1), 47–48. (<a
href="https://doi.org/10.1093/jrsssb/qkad116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Owen, Art B},
  doi          = {10.1093/jrsssb/qkad116},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {47-48},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Art owen’s contribution to the discussion of ‘Estimating means of bounded random variables by betting’ by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hien nguyen’s contribution to the discussion of “estimating
means of bounded random variables by betting” by waudby-smith and
ramdas. <em>JRSSSB</em>, <em>86</em>(1), 45–46. (<a
href="https://doi.org/10.1093/jrsssb/qkad121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Nguyen, Hien},
  doi          = {10.1093/jrsssb/qkad121},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {45-46},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Hien nguyen’s contribution to the discussion of “Estimating means of bounded random variables by betting” by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Ryan martin’s contribution to the discussion of “estimating
means of bounded random variables by betting” by waudby-smith and
ramdas. <em>JRSSSB</em>, <em>86</em>(1), 43–44. (<a
href="https://doi.org/10.1093/jrsssb/qkad112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Martin, Ryan},
  doi          = {10.1093/jrsssb/qkad112},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {43-44},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Ryan martin’s contribution to the discussion of ‘Estimating means of bounded random variables by betting’ by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Jiayi li, yuantong li and xiaowu dai’s contribution to the
discussion of ‘estimating means of bounded random variables by betting’
by waudby-smith and ramdas. <em>JRSSSB</em>, <em>86</em>(1), 41–43. (<a
href="https://doi.org/10.1093/jrsssb/qkad111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Li, Jiayi and Li, Yuantong and Dai, Xiaowu},
  doi          = {10.1093/jrsssb/qkad111},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {41-43},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Jiayi li, yuantong li and xiaowu dai&#39;s contribution to the discussion of ‘Estimating means of bounded random variables by betting&#39; by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Martin larsson and johannes ruf’s contribution to the
discussion of “estimating means of bounded random variables by betting”
by waudby-smith and ramdas. <em>JRSSSB</em>, <em>86</em>(1), 39–40. (<a
href="https://doi.org/10.1093/jrsssb/qkad120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Larsson, Martin and Ruf, Johannes},
  doi          = {10.1093/jrsssb/qkad120},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {39-40},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Martin larsson and johannes ruf’s contribution to the discussion of ‘Estimating means of bounded random variables by betting’ by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rong jiang and keming yu’s contribution to the discussion of
“estimating means of bounded random variables by betting” by
waudby-smith and ramdas. <em>JRSSSB</em>, <em>86</em>(1), 38–39. (<a
href="https://doi.org/10.1093/jrsssb/qkad119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Jiang, Rong and Yu, Keming},
  doi          = {10.1093/jrsssb/qkad119},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {38-39},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Rong jiang and keming yu&#39;s contribution to the discussion of ‘Estimating means of bounded random variables by betting’ by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Steven r howard’s contribution to the discussion of
“estimating means of bounded random variables by betting” by
waudby-smith and ramdas. <em>JRSSSB</em>, <em>86</em>(1), 36–38. (<a
href="https://doi.org/10.1093/jrsssb/qkad114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Howard, Steven R},
  doi          = {10.1093/jrsssb/qkad114},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {36-38},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Steven r howard&#39;s contribution to the discussion of ‘Estimating means of bounded random variables by betting’ by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anthony c davison and igor rodionov’s contribution to the
discussion of “estimating means of bounded random variables by betting”
by waudby-smith and ramdas. <em>JRSSSB</em>, <em>86</em>(1), 35–36. (<a
href="https://doi.org/10.1093/jrsssb/qkad118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Davison, Anthony C and Rodionov, Igor},
  doi          = {10.1093/jrsssb/qkad118},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {35-36},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Anthony c davison and igor rodionov’s contribution to the discussion of ‘Estimating means of bounded random variables by betting’ by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anastasios n. Angelopoulos’ contribution to the discussion
of “estimating means of bounded random variables by betting” by
waudby-smith and ramdas. <em>JRSSSB</em>, <em>86</em>(1), 33–34. (<a
href="https://doi.org/10.1093/jrsssb/qkad115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Angelopoulos, Anastasios N},
  doi          = {10.1093/jrsssb/qkad115},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {33-34},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Anastasios n. angelopoulos’ contribution to the discussion of ‘Estimating means of bounded random variables by betting’ by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Ruodu wang’s contribution to the discussion of “estimating
means of bounded random variables by betting” by waudby-smith and
ramdas. <em>JRSSSB</em>, <em>86</em>(1), 32–33. (<a
href="https://doi.org/10.1093/jrsssb/qkad110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Wang, Ruodu},
  doi          = {10.1093/jrsssb/qkad110},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {32-33},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Ruodu wang&#39;s contribution to the discussion of ‘Estimating means of bounded random variables by betting’ by waudby-smith and ramdas},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Seconder of the vote of thanks to waudby-smith and ramdas
and contribution to the discussion of “estimating means of bounded
random variables by betting.” <em>JRSSSB</em>, <em>86</em>(1), 30–32.
(<a href="https://doi.org/10.1093/jrsssb/qkad123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Neu, Gergely},
  doi          = {10.1093/jrsssb/qkad123},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {30-32},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Seconder of the vote of thanks to waudby-smith and ramdas and contribution to the discussion of ‘Estimating means of bounded random variables by betting’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proposer of the vote of thanks to waudy-smith and ramdas and
contribution to the discussion of “estimating means of bounded random
variables by betting.” <em>JRSSSB</em>, <em>86</em>(1), 28–30. (<a
href="https://doi.org/10.1093/jrsssb/qkad128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JRSSSB},
  author       = {Grünwald, Peter},
  doi          = {10.1093/jrsssb/qkad128},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {28-30},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Proposer of the vote of thanks to waudy-smith and ramdas and contribution to the discussion of ‘Estimating means of bounded random variables by betting’},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Estimating means of bounded random variables by betting.
<em>JRSSSB</em>, <em>86</em>(1), 1–27. (<a
href="https://doi.org/10.1093/jrsssb/qkad009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive confidence intervals (CIs) and confidence sequences (CSs) for the classical problem of estimating a bounded mean. Our approach generalizes and improves on the celebrated Chernoff method, yielding the best closed-form &quot;empirical-Bernstein&quot; CSs and CIs (converging exactly to the oracle Bernstein width) as well as non-closed-form &quot;betting&quot; CSs and CIs. Our method combines new composite nonnegative (super)martingales with Ville&#39;s maximal inequality, with strong connections to testing by betting and the method of mixtures. We also show how these ideas can be extended to sampling without replacement. In all cases, our bounds are adaptive to the unknown variance, and empirically vastly outperform prior approaches, establishing a new state-of-the-art for four fundamental problems: CSs and CIs for bounded means, when sampling with and without replacement.},
  archive      = {J_JRSSSB},
  author       = {Waudby-Smith, Ian and Ramdas, Aaditya},
  doi          = {10.1093/jrsssb/qkad009},
  journal      = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  month        = {2},
  number       = {1},
  pages        = {1-27},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  title        = {Estimating means of bounded random variables by betting},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
