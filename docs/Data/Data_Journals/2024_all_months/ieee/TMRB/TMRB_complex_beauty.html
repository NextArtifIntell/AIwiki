<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMRB_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmrb---159">TMRB - 159</h2>
<ul>
<li><details>
<summary>
(2024). Soft crawling robot with a dual-morphing origami
configuration. <em>TMRB</em>, <em>6</em>(4), 1771–1780. (<a
href="https://doi.org/10.1109/TMRB.2024.3472858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft crawling robots demonstrated high compliance and effectiveness in performing complex tasks in unstructured and harsh environments. They can navigate inside constrained spaces and provide superior adaptability. This paper presents a soft crawling robot with a modified Yoshimura origami-based central chamber (elongation/contraction actuator) and four electrostatic adhesion feet (anchoring elements). It was designed to perform linear and steering locomotion under specific actuation sequences to avoid obstacles autonomously; it features a height-adjustable ability to squeeze under low gaps. A dual-morphing mechanism, enabling the origami-based chamber to operate with two locomotion modalities, was investigated to provide a simple but effective actuation method. Tests were carried out to validate the dual-morphing mechanism and to characterise the crawling robot’s performance. Experimental tests successfully demonstrated the robot’s capabilities, e.g., locomotion under low gaps (i.e., 20 mm, 66% of the height of the robot), obstacle avoidance, climbing on a sloped surface (i.e., 15 deg), and lifting and carrying objects (i.e., 80 g, ten times its weight).},
  archive      = {J_TMRB},
  author       = {Xuyang Ren and Yu Huan and Matteo Cianchetti and Shuxin Wang and Paolo Dario and Gastone Ciuti},
  doi          = {10.1109/TMRB.2024.3472858},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1771-1780},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Soft crawling robot with a dual-morphing origami configuration},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rehabilitation glove with soft inflatable actuators for
precision grasping: Design, fabrication, modeling and preliminary
evaluation. <em>TMRB</em>, <em>6</em>(4), 1760–1770. (<a
href="https://doi.org/10.1109/TMRB.2024.3464115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hand is essential to a human’s daily activities. To rehabilitate patients with hand function disorders, the first step is the extension and flexion of fingers and then regaining the ability to pinch objects. A device suitable for pinch grasping rehabilitation has to be lightweight, small relative to a hand, work in a safe air pressure range, and produce enough range of motion and force. In this paper, a glove with the mentioned characteristics is designed, fabricated, and evaluated. The actuators used in the glove have undergone force and range of motion tests that show promising outputs, such as 3N of force at the tip of the finger, that is enough to pick a 240g object and sufficient range of motion for each joint to perform the box and block test. A model has been developed to be used in designing the device in accordance with the patient’s needs. This model can also be used to identify the stiffness of each knuckle to conduct better rehabilitation methods. The model was verified by being applied to a dummy finger. Furthermore, an actuation pack was developed and evaluated to enable device portability in everyday use conditions.},
  archive      = {J_TMRB},
  author       = {Mohammad Mahdi Dalaee and Mohammad Zareinejad and Abdolreza Ohadi and Parsa Kabir},
  doi          = {10.1109/TMRB.2024.3464115},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1760-1770},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Rehabilitation glove with soft inflatable actuators for precision grasping: Design, fabrication, modeling and preliminary evaluation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A scorpion-inspired 5-DOF miniature remote actuation robotic
endoscope for minimally invasive surgery. <em>TMRB</em>, <em>6</em>(4),
1748–1759. (<a href="https://doi.org/10.1109/TMRB.2024.3464114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote Actuation Mechanisms (RAMs) play a vital role in minimally invasive surgery (MIS) by providing motion capabilities within limited spaces. This paper first focused on analyzing commonly employed RAMs to understand their strengths and limitations. Then, drawing inspiration from bionics and the biological structure of scorpions, we proposed a novel approach by integrating three RAMs-a magnet pair, a torque coil, and a soft bellow-to create a 5-degree-of-freedom (5-DOF) miniature remote actuation robot. In the design phase, we established the robot’s parameters using the magnetic dipole model and related constraints. A functional prototype of the robot, along with an external controller and user interface, was fabricated and assembled. Experimental investigations demonstrated motion performance across the 5 DOF, validating the robot’s feasibility. To assess the practicality of the system, the interaction interface was evaluated under controlled laboratory conditions and through a cadaver test. In conclusion, our innovative approach combines multiple RAMs into a 5-DOF remote actuation robot. Comprehensive tests validated its motion capabilities and highlighted its potential to advance MIS procedures.},
  archive      = {J_TMRB},
  author       = {Jixiu Li and Truman Cheng and Wai Shing Chan and Zixiao Chen and Yehui Li and Calvin Sze Hang Ng and Philip Wai Yan Chiu and Zheng Li},
  doi          = {10.1109/TMRB.2024.3464114},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1748-1759},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A scorpion-inspired 5-DOF miniature remote actuation robotic endoscope for minimally invasive surgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proximity servoed minimally invasive continuum robot for
endoscopic interventions. <em>TMRB</em>, <em>6</em>(4), 1738–1747. (<a
href="https://doi.org/10.1109/TMRB.2024.3464127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimally invasive continuum robots face limitations in accessing environmental and spatial information on the situs. However, such information would often be necessary for control and automation features in surgical use. Centering an endoscopic system within a hollow organ can be such a feature, providing the benefit of reduced risk of injury and assistance for navigation. To leverage such an application, this work investigates a proximity servoed continuum robot. A sensorized tip combines capacitive electrodes, a camera, and illumination and uses capacitive proximity sensing to determine the enclosing environment’s center point. A controller is presented that uses this information to center the robot’s tip. The system is evaluated in a dynamic phantom, where an average accuracy of 10.0 mm could be demonstrated and contact to the phantom’s wall was avoided during 98% of the experiment time. In a second phantom experiment, it is demonstrated how this controller can be applied to follow the center line of a bent anatomical structure. Future work should focus on improving accuracy and versatility of the system, aiming for application in more challenging and irregular environments, such as ex vivo or in vivo organs.},
  archive      = {J_TMRB},
  author       = {Christian Marzi and Maximilian Themistocli and Björn Hein and Franziska Mathis-Ullrich},
  doi          = {10.1109/TMRB.2024.3464127},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1738-1747},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Proximity servoed minimally invasive continuum robot for endoscopic interventions},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-steering catheters for neuroendovascular interventions.
<em>TMRB</em>, <em>6</em>(4), 1726–1737. (<a
href="https://doi.org/10.1109/TMRB.2024.3464123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The size limitations and tortuosity of the neurovasculature currently exceed the capabilities of existing robotic systems. Furthermore, safety considerations require a fail-safe design whereby some passive compliance is used for an added layer of safety and for sensing the lateral load on the steerable portion of the catheter. To address these needs, we propose a novel multi-articulated robotic catheter technology that aims to increase technical precision, reduce procedural time and radiation exposure, and enable the semi-automation of catheters during neuroendovascular procedures. This catheter uses joint-level sensing and fluoroscopic imaging to actively bend in two separate planes. Its design also uses series-elastic actuation for increased safety and active compliance (self-steering). We present the design, kinematic modeling, and calibration of this system. A multi-mode real-time control architecture of the system was implemented and experimentally validated. We demonstrate the use of the robotic catheter for branch selection, insertion in an unknown channel under active compliance, and autonomous deployment within a 2D vasculature model. Furthermore, we developed algorithms for intra-operative catheter tracking and pose filtering. Methods presented in this paper make significant strides towards the future goal of enabling semi-autonomous navigation for neuroendovascular procedures.},
  archive      = {J_TMRB},
  author       = {Colette Abah and Jared P. Lawson and Rohan Chitale and Nabil Simaan},
  doi          = {10.1109/TMRB.2024.3464123},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1726-1737},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Self-steering catheters for neuroendovascular interventions},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Selectively tunable joints with variable stiffness for a
magnetically-steerable 6-DOF manipulator. <em>TMRB</em>, <em>6</em>(4),
1713–1725. (<a href="https://doi.org/10.1109/TMRB.2024.3464668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic manipulators are used across various surgical tasks, including endoscopic and laparoscopic procedures. Operating in small and constrained spaces during these procedures requires the manipulators to have high dexterity and control over the motion path but with a small footprint. In this work, we propose a modular design of a magnetically-guided small-sized robotic manipulator. The manipulator has discrete universal joints that allow ease of actuation. Variable stiffness is incorporated into the joints to allow the locking and unlocking of individual degrees of freedom (DOFs). The design is modular and allows extension to additional DOFs. The range of each DOF is 60° and is controlled by a pair of shape memory polymer flexures; four flexures comprise one joint. With rolling-contact elements, the design eliminates problems with buckling and pushability. A custom-designed heating element triggers the flexures to switch from a high (0.57Nmm/°) to a low stiffness (0.06Nmm/°) state within 14(±0.8)s. Ambient cooling secures shape-locking within 64(±3.7)s. In an experiment, a 6-DOF version of the manipulator navigates around obstacles in confined spaces and remains shape-locked for stable operation. Practical application is demonstrated through simulated gastroscopy and polypectomy using inserted surgical tools.},
  archive      = {J_TMRB},
  author       = {Simon Frieler and Sarthak Misra and Venkatasubramanian Kalpathy Venkiteswaran},
  doi          = {10.1109/TMRB.2024.3464668},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1713-1725},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Selectively tunable joints with variable stiffness for a magnetically-steerable 6-DOF manipulator},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An ultrasound-guided system for autonomous marking of tumor
boundaries during robot-assisted surgery. <em>TMRB</em>, <em>6</em>(4),
1699–1712. (<a href="https://doi.org/10.1109/TMRB.2024.3468397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While only a limited number of procedures have image guidance available during robotically guided surgery, they still require the surgeon to manually reference the obtained scans to their projected location on the tissue surface. While the surgeon may mark the boundaries on the organ surface via electrosurgery, the precise margin around the tumor is likely to remain variable and not guaranteed before a pathological analysis. This paper presents a first attempt to autonomously extract and mark tumor boundaries with a specified margin on the tissue surface. It presents a first concept for tool-tissue interaction control via Inertial Measurement Unit (IMU) sensor fusion and contact detection from the electrical signals of the Electrosurgical Unit (ESU), requiring no force sensing. We develop and assess our approach on Ultrasound (US) phantoms with anatomical surface geometries, comparing different strategies for projecting the tumor onto the surface and assessing its accuracy in repeated trials. Finally, we demonstrate the feasibility of translating the approach to an ex-vivo porcine liver. We achieve mean true positive rates above $\mathbf {0.84}$ and false detection rates below $\mathbf {0.12}$ compared to a tracked reference for each calculation and execution of the marking trajectory for dummy and ex-vivo experiments.},
  archive      = {J_TMRB},
  author       = {Nils Marahrens and Dominic Jones and Nikita Murasovs and Chandra Shekhar Biyani and Pietro Valdastri},
  doi          = {10.1109/TMRB.2024.3468397},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1699-1712},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {An ultrasound-guided system for autonomous marking of tumor boundaries during robot-assisted surgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of a high-precision and large-range FBG-based
sensor inspired by a crank-slider mechanism for wearable measurement of
human knee joint angles. <em>TMRB</em>, <em>6</em>(4), 1688–1698. (<a
href="https://doi.org/10.1109/TMRB.2024.3464096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a fiber Bragg grating (FBG) based angle sensor with an extensive measurement range and high precision for human knee joint measurement. The proposed sensor mainly comprises an angle-linear displacement conversion cam, a crank-slider mechanism-inspired conversion flexure, an optical fiber embedded with an FBG element, and a sensor package. The cam transforms the wide-range knee angle input into vertical linear displacement output. The conversion flexure further converts such vertical displacement into a reduced horizontal displacement/stretching applied to the optical fiber with a motion scale ratio of 6:1. The flexure design features a symmetrical structure to improve stability and depress hysteresis. The fiber is suspended on the flexure’s output beams with a two-point pasting configuration. Both theory analysis and finite element method (FEM)-based simulations revealed the linear relationship between the input angle and the fiber strain. Static and dynamic experiments have verified the performance of the proposed sensor, demonstrating a sensitivity of 62.03 pm/° with a small linearity error of 1.36% within [0, 140°]. The root mean square errors (RMSE) were 0.72° and 0.84° for angle velocities of 80°/s and 350°/s, respectively. Wearable experiments during sitting and walking have been performed to validate the effectiveness of the proposed sensor.},
  archive      = {J_TMRB},
  author       = {Kaifeng Wang and Aofei Tian and Yupeng Hao and Chengzhi Hu and Chaoyang Shi},
  doi          = {10.1109/TMRB.2024.3464096},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1688-1698},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Development of a high-precision and large-range FBG-based sensor inspired by a crank-slider mechanism for wearable measurement of human knee joint angles},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic reconfiguration for multi-magnet tracking in
myokinetic prosthetic interfaces. <em>TMRB</em>, <em>6</em>(4),
1678–1687. (<a href="https://doi.org/10.1109/TMRB.2024.3464093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently myokinetic interfaces have been proposed to exploit magnet tracking for controlling bionic prostheses. This interface derives information about muscle contractions from permanent magnets implanted into the amputee’s forearm muscles. Machine learning models have been mapped on Field Programmable Gate Arrays (FPGAs) to track a single magnet, achieving good precision and computational efficiency, but consuming a large area and hardware resources. To track several magnets, here we propose a novel solution based on dynamic partial reconfiguration, switching three prediction models: a linear regressor, a radial basis function neural network, and a multi-layer perceptron neural network. A system with five magnets and 128 magnetic sensor inputs was used and experimental data were collected to train a system with five hardware predictors. To reduce the complexity of the models, we applied principal component analysis, ranking by correlation the number of inputs of each model. This run-time reconfigurable solution allows the circuits to be reconfigured in order to select the most reliable predictor model for each magnet while the rest of the circuit continues to operate extracting the most significant information from the captured signals. Thus, the proposed solution remarkably reduces the hardware occupation and improves the computational efficiency compared to previous solutions.},
  archive      = {J_TMRB},
  author       = {Sergio A. Pertuz Mendez and Davi De Alencar Mendes and Marta Gherardini and Daniel M. Muñoz and Helon Vicente Hultmann Ayala and Christian Cipriani},
  doi          = {10.1109/TMRB.2024.3464093},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1678-1687},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Dynamic reconfiguration for multi-magnet tracking in myokinetic prosthetic interfaces},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single-motor ultraflexible robotic (SMUFR) humanoid hand.
<em>TMRB</em>, <em>6</em>(4), 1666–1677. (<a
href="https://doi.org/10.1109/TMRB.2024.3464107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanoid robotic hands have significant potential in easing human burden and augmenting human labor. This paper introduces the SMUFR hand, a compliant and dexterous robotic humanoid hand powered by tendon-driven mechanisms, and features flexible beam-based bending joints serving as rotary joints with bidirectional bending compliance that ensure safety during human-robot interaction. Despite its light weight of only 363 g without remote transmission and actuation components, the SMUFR hand can grasp and support loads of up to 4.2 kg in various orientations, manipulate objects of different sizes and shapes, and even operate underwater. Of particular note is the SMUFR hand’s lightweight and compact one-to-more actuation system, comprising six rotary pneumatic clutches (RPC) for six active Degrees of Freedom (DoFs), all powered by a single motor. Each RPC, weighing 75 g, can exert up to 23 N force on the tendon. This innovative transmission system distributes the power of a single motor across five fingers and holds potential for configuring additional RPCs. We also integrated all the components on a compact wearable vest for potential mobile humanoid robotic applications. Additionally, a mathematical model was developed to predict tendon force and joint bending using the constant curvature deformation hypothesis. Experimental validation demonstrates the durability of both the RPC and the beam-based fingers of the SMUFR hand, which are capable of enduring up to 22,000 and 30,000 cycles, respectively.},
  archive      = {J_TMRB},
  author       = {Quan Xiong and Dannuo Li and Xuanyi Zhou and Wenci Xin and Chao Wang and Jonathan William Ambrose and Raye Chen-Hua Yeow},
  doi          = {10.1109/TMRB.2024.3464107},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1666-1677},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Single-motor ultraflexible robotic (SMUFR) humanoid hand},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Therapists’ force-profile teach-and-mimic approach for
upper-limb rehabilitation exoskeletons. <em>TMRB</em>, <em>6</em>(4),
1658–1665. (<a href="https://doi.org/10.1109/TMRB.2024.3464697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a framework enabling upper-limb rehabilitation exoskeletons to mimic the personalised haptic guidance of therapists. Current exoskeletons face acceptability issues as they limit physical interaction between clinicians and patients and offer only predefined levels of support that cannot be tuned during the movements, when needed. To increase acceptance, we first developed a method to estimate the therapist’s force contribution while manipulating a patient’s arm using an upper-limb exoskeleton. We achieved a precision of $0.31Nm$ without using direct sensors. Then, we exploited the Learning-by-demonstration paradigm to learn from the therapist’s interactions. Single-joint experiments on ANYexo demonstrate that our framework, applying the Vector-search approach, can record the joint-level therapist’s interaction forces during simple tasks, link them to the kinematics of the robot, and then provide support to the user’s limb. The support is coherent with what is learnt and changes with the real-time arm kinematic configuration of the robot, assisting whatever movement the patient executes in the end-effector space without the need for manual regulation. In this way, robotic therapy sessions can exploit therapists’ expertise while reducing their manual workload.},
  archive      = {J_TMRB},
  author       = {Beatrice Luciani and Michael Sommerhalder and Marta Gandolla and Peter Wolf and Francesco Braghin and Robert Riener},
  doi          = {10.1109/TMRB.2024.3464697},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1658-1665},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Therapists’ force-profile teach-and-mimic approach for upper-limb rehabilitation exoskeletons},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimized impedance control of a lightweight gait
rehabilitation exoskeleton based on accurate knee joint torque
estimation. <em>TMRB</em>, <em>6</em>(4), 1648–1657. (<a
href="https://doi.org/10.1109/TMRB.2024.3464671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the increasing problem of an aging population, there has been a significant increase in the number of stroke patients presenting with motor dysfunction of the lower limbs. In this study, a knee exoskeleton rehabilitation robot driven by a quasi-direct driver actuator is designed. The torque generation model is constructed based on the TCN-LSTM hybrid neural network, and the knee joint torque is generated by sEMG and angle signal. A joint attention mechanism is introduced to enhance the accuracy of torque generation model. The impedance control parameters are adaptively adjusted in accordance with the joint torque. The experimental results demonstrate that the TCN-LSTM hybrid neural network is capable of effectively estimating torque, the mean MAE and CC of the proposed model are 1.141Nm and 93.7%, respectively. The optimized impedance control can optimize the initial value of the impedance parameter, which reduced the torque error by 5.54% and 50.64% at uphill tasks and walking task, respectively, and adaptively adjust the impedance parameter to ensure the coordination of the gait rehabilitation and the friendly human-robot interaction.},
  archive      = {J_TMRB},
  author       = {Wei Meng and Zunmei Tian and Chang Zhu and Qingsong Ai and Quan Liu},
  doi          = {10.1109/TMRB.2024.3464671},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1648-1657},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Optimized impedance control of a lightweight gait rehabilitation exoskeleton based on accurate knee joint torque estimation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Homogeneous dynamic control for stair ascent in a
swing-assist knee prosthesis. <em>TMRB</em>, <em>6</em>(4), 1637–1647.
(<a href="https://doi.org/10.1109/TMRB.2024.3465024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stair ascent is a challenging task for people with transfemoral amputation. It can be made substantially easier with a swing-assist prosthesis, actively supplementing the prosthesis nominally passive behavior to help the user place their foot on the next stair tread. A significant control challenge is providing power without competing with the user’s agency during the swing-phase movement. This paper presents a new control approach for stair ascent swing-phase assistance in swing-assist prostheses. The approach is designed to supplement swing-phase movement with power without introducing an additional exogenous control input, leaving the user as the sole source of prosthesis movement. Namely, this is achieved by adding power to modify the homogeneous dynamics of the prosthesis’s passive behavior. This control approach is developed in the paper, implemented on an experimental prosthesis, and assessed in stair ascent trials with three unilateral transfemoral amputees, comparing it with their daily-use device. Experimental results demonstrate, for step-over stair ascent aggregated across participants, the proposed approach: 1) increased peak knee angle by a factor of 2.5; 2) improved symmetry from 41% to 84% (where 100% is perfectly symmetric); and 3) required 2 times less hip effort to achieve a given knee motion, all relative to daily-use prostheses.},
  archive      = {J_TMRB},
  author       = {Marco Puliti and David M. Marsh and Michael Goldfarb},
  doi          = {10.1109/TMRB.2024.3465024},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1637-1647},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Homogeneous dynamic control for stair ascent in a swing-assist knee prosthesis},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight powered elbow exoskeleton for manual handling
tasks. <em>TMRB</em>, <em>6</em>(4), 1627–1636. (<a
href="https://doi.org/10.1109/TMRB.2024.3464690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel lightweight elbow joint exoskeleton designed to enhance the safety and efficiency of industrial workers engaged in manual handling tasks. Our design leveraged a Bowden cable transmission system and a practical control strategy utilizing instrumented gloves to deliver reactive bi-directional support for dynamic box lifting and pressing activities. The primary focus of this work was to (1) to present an engineering validation analysis and (2) assess the exoskeleton’s impact on reducing muscle activity, increasing endurance, and maintaining overall user comfort during upper-extremity lifting or carrying tasks. We observed significant and consistent reductions in muscle activity and an increase in endurance (e.g., 2.4x more repetitions) during box lifting tasks, without compromising user comfort. These findings provide promising evidence of the exoskeleton’s effectiveness and represent a crucial first step working towards demonstrating efficacy in real-world workplace environments.},
  archive      = {J_TMRB},
  author       = {Daniel Colley and Collin D. Bowersock and Zachary F. Lerner},
  doi          = {10.1109/TMRB.2024.3464690},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1627-1636},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A lightweight powered elbow exoskeleton for manual handling tasks},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design of a cable-suspended robot for early stage gait
rehabilitation. <em>TMRB</em>, <em>6</em>(4), 1616–1626. (<a
href="https://doi.org/10.1109/TMRB.2024.3468381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practicing walking motions while supine might help accelerate recovery after neurologic injury. This paper presents the design, modeling, and initial testing of a novel cable-driven device called AirStep that compensates for the weight of the legs, facilitating air-stepping practice while supine. AirStep integrates multiple mass-spring counterbalancing mechanisms to minimize the effect of gravity throughout the entire gait cycle such that patients can perform active or passive stepping motions in a near-zero gravity environment. Handles allow a rehabilitation therapist to manually assist leg motion through the cables as needed. Data acquired from an optical motion capture system validated the mathematical model of the AirStep, showing that the leg trajectories in air-stepping resembled those from running. In pilot testing, two individuals with spinal cord injury (SCI) required manual assistance at the hips from a physical therapist to achieve step-like motions through the AirStep interface. AirStep can apply low-forces, allow stepping in the supine position, and can quantify changes in patient-generated force production. Compared to other rehabilitation robots, AirStep offers the advantages of a low-cost mechanical structure, high acceptability by the patient and easy transportability aside a hospital bed, making the AirStep a good candidate for adoption in the early-stage gait rehabilitation.},
  archive      = {J_TMRB},
  author       = {Giacomo Zuccon and Alberto Doria and Giulio Rosati and Christopher A. Johnson and Lee McEligot and Kohl Hertz and Kyle Fernan and Ishaq Khan and V. Reggie Edgerton and David J. Reinkensmeyer},
  doi          = {10.1109/TMRB.2024.3468381},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1616-1626},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Design of a cable-suspended robot for early stage gait rehabilitation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling human upper limb trajectories for reaching motions
on CLEVERarm. <em>TMRB</em>, <em>6</em>(4), 1603–1615. (<a
href="https://doi.org/10.1109/TMRB.2024.3464097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the significant potential for robot-assisted rehabilitation, developing well-planned trajectories plays a crucial role in enhancing the effectiveness of such rehabilitation methods. A critical aspect of this field, particularly concerning the movement of the human upper limb, is the redundancy resolution. In this study, we introduce a novel trajectory planning method aimed at addressing the redundancy resolution in reaching motions related to Activities of Daily Living (ADL). This method is inspired by prior studies on maximum manipulability while emphasizing the natural upper limb posture, particularly the human preference for maintaining a nearly steady elbow position during ADL movements unless, of course, the range of the desired motion requires otherwise. A trajectory-combining approach is developed for generating trajectories in the human configuration space. Additionally, we present a configuration transformation model for human-robot configuration alignment. Experimental results validate the hypothesis of a steady elbow position and combine features from the Minimum Jerk (MJ) and Minimum Angular Jerk (MAJ) methods, demonstrating more natural reaching motions. The configuration transformation model has been successfully tested on the TAMU CLEVERarm, a lightweight and compact upper limb exoskeleton.},
  archive      = {J_TMRB},
  author       = {Kuang Nie and Reza Langari},
  doi          = {10.1109/TMRB.2024.3464097},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1603-1615},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Modeling human upper limb trajectories for reaching motions on CLEVERarm},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robot-assisted reduction of the ankle joint via multi-body
3D–2D image registration. <em>TMRB</em>, <em>6</em>(4), 1591–1602. (<a
href="https://doi.org/10.1109/TMRB.2024.3464095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot-assisted orthopaedic joint reduction offers enhanced precision and control across multiple axes of motion, enabling precise realignment according to predefined plans. However, the high levels of forces encountered may induce unintended anatomical motion and flex mechanical components. To address this, this work presents an approach that uses 2D fluoroscopic imaging to verify and readjust the 3D reduction path by tracking deviations from the planned trajectory. The proposed method involves a 3D-2D registration algorithm using a pair of fluoroscopic images, along with prior models of each body in the radiographic scene. This objective is formulated to couple and constrain multiple object poses (fibula, tibia, talus, and robot end effector), and incorporate novel methods for automatic view and hyperparameter selection to improve robustness. The algorithms were refined through cadaver studies and evaluated in a preclinical trial, employing a robotic system to manipulate a dislocated fibula. Studies with cadaveric specimens highlighted the joint-specific formulation’s high registration accuracy ( $\Delta _{x} {=} 0.3~\pm ~1$ .5 mm), further improved with the use of automatic view and hyperparameter selection ( $\Delta _{x} {=} 0.2~\pm ~0$ .8 mm). Preclinical studies demonstrated a high deviation between the intended and the actual path of the robotic system, which was accurately captured ( $\Delta _{x}$ 1 mm) using the proposed techniques. The solution offers to close the loop on image-based guidance of robot-assisted joint reduction by tracking the robot and bones to dynamically correct the course. The approach uses standard clinical images and is expected to lower radiation exposure by providing 3D information and allowing the staff to stay clear of the x-ray beam.},
  archive      = {J_TMRB},
  author       = {R. C. Vijayan and N. M. Sheth and J. Wei and K. Venkataraman and D. Ghanem and B. Shafiq and J. H. Siewerdsen and W. Zbijewski and G. Li and K. Cleary and A. Uneri},
  doi          = {10.1109/TMRB.2024.3464095},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1591-1602},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Robot-assisted reduction of the ankle joint via multi-body 3D–2D image registration},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Repetitive control of knee interaction torque via a lower
extremity exoskeleton for improved transparency during walking.
<em>TMRB</em>, <em>6</em>(4), 1581–1590. (<a
href="https://doi.org/10.1109/TMRB.2024.3464119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We developed, implemented, and assessed the performance of two forms of plug-in type repetitive controllers (RC) for enhancing the transparency of a lower extremity exoskeleton that operates to support walking function. One controller is a first order RC (SING) consisting of a single period matched to the self-selected cadence of the participant. The second is a novel ‘parallel’ RC (PARA) which consists of a library of integrated RCs with varying periods, intended to accommodate a wider range of gait cycle times. We assessed the effects of both RCs under free cadence walking (FREE) and when walking with a metronome prescribing a consistent cadence matching the participants’ self-selected value. Both conditions were evaluated both at fixed speed and under user-driven treadmill control (UDT), where the treadmill speed was regulated by the user’s anterior/posterior position on the treadmill. The implementation of RC to the knee joint of the ALEX II exoskeleton lead to a significant reduction in torque error of 10-15% at the knee joint during swing and smaller, non-significant effects at the hip joint. While the PARA RC reduced knee torque error more than the SING RC during the FREE cadence condition, a 15% reduction vs. 10% reduction, the difference between the two controllers was not statistically significant. During the UDT sections of walking conditions, participants increased GS under both the SING and PARA RC types. After controlling for the increase in torque error associated with speed, both the PARA and the SING controller reduced TE at the knee joint during swing relative to baseline by 13% and 14%, respectively, with no significant effects to the hip joint. Our work presents a novel formulation of RC and demonstrates the feasibility of applying RC to a robotic exoskeleton joint to assist walking. Future work should be geared toward improving the gait cycle prediction algorithm and developing robust methods for accounting for impact dynamics.},
  archive      = {J_TMRB},
  author       = {Robert L. McGrath and Fabrizio Sergi},
  doi          = {10.1109/TMRB.2024.3464119},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1581-1590},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Repetitive control of knee interaction torque via a lower extremity exoskeleton for improved transparency during walking},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imitation learning of compression pattern in
robotic-assisted ultrasound examination using kernelized movement
primitives. <em>TMRB</em>, <em>6</em>(4), 1567–1580. (<a
href="https://doi.org/10.1109/TMRB.2024.3472856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vascular diseases are commonly diagnosed using Ultrasound (US) imaging, which can be inconsistent due to its high dependence on the operator’s skill. Among these, Deep Vein Thrombosis (DVT) is a common yet potentially fatal condition, often leading to critical complications like pulmonary embolism. Robotic US Systems (RUSs) aim to improve diagnostic test consistency but face challenges with the complex scanning pattern requiring precise control over US probe pressure, such as the one needed for indirectly detecting occlusions during DVT assessment. This work introduces an imitation learning method based on Kernelized Movement Primitives (KMP) to standardize the contact force profile during US exams by training a robotic controller using sonographer demonstrations. A new recording device design enhances demonstration acquisition, integrating with US probes and enabling seamless force and position data recording. KMPs are used to link scan trajectory and interaction force, enabling generalization beyond the demonstrations. Our approach, evaluated on synthetic models and volunteers, shows that the KMP-based RUS can replicate an expert’s force control and US image quality, even under conditions requiring compression during scanning. It outperforms previous methods using manually defined force profiles, improving exam standardization and reducing reliance on specialized sonographers.},
  archive      = {J_TMRB},
  author       = {Diego Dall’Alba and Lorenzo Busellato and Thiusius Rajeeth Savarimuthu and Zhuoqi Cheng and Iñigo Iturrate},
  doi          = {10.1109/TMRB.2024.3472856},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1567-1580},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Imitation learning of compression pattern in robotic-assisted ultrasound examination using kernelized movement primitives},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel augmented reality assisted orthopedic surgical
robotic system with bidirectional surface registration algorithms.
<em>TMRB</em>, <em>6</em>(4), 1555–1566. (<a
href="https://doi.org/10.1109/TMRB.2024.3472844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel augmented reality (AR)-assisted orthopedic surgical robotic system based on Head-Mounted Display (HMD) devices. The proposed system can overlay the preoperative plans over the patient’s anatomy and provide useful guidance for surgeons during interventions, with integrated calibration and registration components. A novel bi-directional generalised point set registration algorithm that utilises robust features is developed to accurately align the pre-operative CT and intra-operative patient spaces, which has been demonstrated to outperform existing registration methods. The efficacy of the system is both qualitatively and quantitatively assessed with an in vitro study representing a total knee arthroplasty (TKA) procedure. The experimental results showed that 1) the system can successfully align the preoperative and intraoperative spaces, with the mean target registration error (TRE) being $2.78 \; \pm \; 2.51$ mm; 2) the models can be properly overlaid to the physical scenarios with the mean AR visualization accuracy being $6.97 \; \pm \; 1.57$ mm.},
  archive      = {J_TMRB},
  author       = {Ang Zhang and Zhe Min and Zhengyan Zhang and Yingying Wang and Max Q.-H. Meng},
  doi          = {10.1109/TMRB.2024.3472844},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1555-1566},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A novel augmented reality assisted orthopedic surgical robotic system with bidirectional surface registration algorithms},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual-branch fusion network for surgical instrument
segmentation. <em>TMRB</em>, <em>6</em>(4), 1542–1554. (<a
href="https://doi.org/10.1109/TMRB.2024.3464748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical robots have become integral to contemporary surgical procedures, with the precise segmentation of surgical instruments constituting a crucial prerequisite for ensuring their stable functionality. However, numerous factors continue to influence segmentation outcomes, including intricate surgical environments, varying viewpoints, diminished contrast between surgical instruments and surroundings, divergent sizes and shapes of instruments, and imbalanced categories. In this paper, a novel dual-branch fusion network, designated DBF-Net, is presented, which integrates both convolutional neural network (CNN) and Transformer architectures to facilitate automatic segmentation of surgical instruments. For addressing the deficiencies in feature extraction capacity in CNNs or Transformer architectures, a dual-path encoding unit is introduced to proficiently represent local detail features and global context. Meanwhile, to enhance the fusion of features extracted from the dual paths, a CNN-Transformer fusion (CTF) module is proposed, to efficiently merge features from the CNN and Transformer structures, contributing to the effective representation of both local detail features and global contextual features. Further refinement is pursued through an multi-scale feature aggregation (MFAG) module and a local feature enhancement (LFE) module, to refine local contextual features at each layer. In addition, an attention-guided enhancement (AGE) module is incorporated for feature refinement of local feature maps. Finally, an multi-scale global feature representation (MGFR) module is introduced, facilitating the extraction and aggregation of multi-scale features, and a progressive fusion module (PFM) culminates in the aggregation of full-scale features from the decoder. Experimental results underscore the superior segmentation performance of proposed network compared to other state-of-the-art (SOTA) segmentation models for surgical instruments, which have well validated the efficacy of proposed network architecture in advancing the field of surgical instrument segmentation.},
  archive      = {J_TMRB},
  author       = {Lei Yang and Chenxu Zhai and Hongyong Wang and Yanhong Liu and Guibin Bian},
  doi          = {10.1109/TMRB.2024.3464748},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1542-1554},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A dual-branch fusion network for surgical instrument segmentation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SLAM-TKA: Simultaneously localizing x-ray device and mapping
pins in conventional total knee arthroplasty. <em>TMRB</em>,
<em>6</em>(4), 1526–1541. (<a
href="https://doi.org/10.1109/TMRB.2024.3465565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel simultaneous localization and mapping (SLAM) technique, termed SLAM-TKA, for assisting total knee arthroplasty (TKA), a highly effective orthopaedic surgery that replaces arthritic or dysfunctional joint surfaces with knee prostheses. Our proposed SLAM algorithm uses information from a pre-operative tibia CT scan, intra-operative 2D X-ray images, and a trocar pin 3D mesh model to simultaneously localise the X-ray device and map the two trocar pins. Then, the estimated pins are used to evaluate the accuracy of the bone resection plane before the actual bone cutting, which plays a crucial role in precisely implanting the knee prostheses. To ensure high accuracy and robustness of the proposed SLAM algorithm, three energy terms are proposed and used together to align the edge observations of the tibia, fibula and pins on the intra-operative X-ray images and their corresponding pre-operative 3D mesh models in both 2D and 3D space. To enable the proposed iteration-based SLAM algorithm to be implemented in real-time such that the evaluation processing does not interrupt much on the workflow of TKA, the data association of edge correspondences matching and exhausted points-to-mesh distance calculation are pre-computed using the signed distance field method. Simulations are used to evaluate the accuracy and robustness of the proposed algorithm, and the experiments using in-vivo datasets from five patients demonstrate the high accuracy and efficiency in practice. The code and datasets are released at https://github.com/zsustc/SLAM-TKA.},
  archive      = {J_TMRB},
  author       = {Shuai Zhang and Liang Zhao and Shoudong Huang and Hua Wang and Qi Luo and Qi Hao and Danail Stoyanov},
  doi          = {10.1109/TMRB.2024.3465565},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1526-1541},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {SLAM-TKA: Simultaneously localizing X-ray device and mapping pins in conventional total knee arthroplasty},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Telemanipulated vascular intervention system for minimally
invasive surgery. <em>TMRB</em>, <em>6</em>(4), 1512–1525. (<a
href="https://doi.org/10.1109/TMRB.2024.3473299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimally invasive surgery, as a promising treatment method for coronary heart disease and intracranial aneurysm, has received extensive research interest due to its appealing characteristics, e.g., the little surgical trauma, short rehabilitation time, determined curative effect, and less pain. However, the accumulated X-ray radiation during the percutaneous coronary intervention (PCI) and neurovascular intervention (NVI) greatly increases the probability of medical staff suffering from cataracts and brain tumors. In this article, the telemanipulated vascular intervention (TVI) system is presented, a compact and versatile vascular interventional system. The TVI system comprised of a leader joystick, a follower delivery device, and a graphical user interface is designed for intravascular delivery during the robot-assisted PCI and robot-assisted NVI. The performance of the TVI system is evaluated by demonstrating its ability to achieve telemanipulated navigation in the real-sized 3D cardio-cerebrovascular model with coronary stenosis and intracranial aneurysms. The experimental results demonstrate that the TVI system can navigate to 3 types of coronary stenosis, 6 types of cerebral artery, and an intracranial aneurysm with a diameter of 8 mm. To further demonstrate the performance of the TVI system, the robot-assisted renal artery angioplasty is conducted in a rabbit model for preclinical evaluation. These promising results indicate that the TVI system is capable of precisely manipulating the guidewire remotely, mitigating the health risks associated with prolonged exposure to X-ray radiation for interventionists.},
  archive      = {J_TMRB},
  author       = {Siyi Wei and Zhiwei Wu and Jinhui Zhang and Shaomeng Gu and Zhanxin Geng and Jiahao Luo and Yueyang Gao and Zheng Li},
  doi          = {10.1109/TMRB.2024.3473299},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1512-1525},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Telemanipulated vascular intervention system for minimally invasive surgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast OCT-based needle tracking for retinal microsurgery
using dynamic spiral scanning. <em>TMRB</em>, <em>6</em>(4), 1502–1511.
(<a href="https://doi.org/10.1109/TMRB.2024.3464693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal microsurgery is crucial for treating various ocular diseases, but challenging due to the structure size, physiological tremor and limited depth perception. This study aims to develop an innovative real-time needle tracking system that utilizes only a small amount of Optical Coherence Tomography (OCT) A-scans. We introduce a spiral scanning pattern, that is dynamically updated to efficiently capture the needle tip and the retina area with 2000 A-scans. An imaging pipeline is proposed that initiates with an initial Region of Interest (ROI) identification, followed by image segmentation, 3D reconstruction, and needle pose estimation. The ROI is dynamically adjusted to keep the needle tip centrally within the spiral scan, facilitating tracking at clinically relevant speeds. Preliminary testing on phantom eye models demonstrated that our system can maintain an average tracking error of 0.04 mm in spatial coordinates and an error of 0.06 mm in estimating the distance between the needle tip and the retina. These results suggest the system’s potential to enhance surgical outcomes by providing surgeons with improved depth perception and precise, real-time feedback. By efficiently utilizing spirally sampled OCT data, this system sets the groundwork for future integrations of real-time 4D imaging and physiological motion detection capabilities.},
  archive      = {J_TMRB},
  author       = {Pengwei Xu and Mouloud Ourak and Gianni Borghesan and Emmanuel Vander Poorten},
  doi          = {10.1109/TMRB.2024.3464693},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1502-1511},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Fast OCT-based needle tracking for retinal microsurgery using dynamic spiral scanning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hands collaboration evaluation for surgical skills
assessment: An information theoretical approach. <em>TMRB</em>,
<em>6</em>(4), 1490–1501. (<a
href="https://doi.org/10.1109/TMRB.2024.3464110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bimanual tasks, where the brain must simultaneously control and plan the movements of both hands, such as needle passing and tissue cutting, commonly exist in surgeries, e.g., robot-assisted minimally invasive surgery. In this study, we present a novel approach for quantifying the quality of hands coordination and correspondence in bimanual tasks by utilizing information theory concepts to build a mathematical framework for measuring the collaboration strength between the two hands. The introduced method makes no assumption about the dynamics and couplings within the robotic platform, executive task, or human motor control. We implemented the proposed approach on MEELS and JIGSAWS datasets, corresponding to conventional minimally invasive surgery (MIS) and robot-assisted MIS, respectively. We analyzed the advantages of hands collaboration features in the skills assessment and style recognition of robotic surgery tasks. Furthermore, we demonstrated that incorporating intuitive domain knowledge of bimanual tasks potentially paves the way for other complex applications, including, but not limited to, autonomous surgery with a high level of model explainability and interpretability. Finally, we presented preliminary results to argue that incorporating hands collaboration features in deep learning-based classifiers reduces uncertainty, improves accuracy, and enhances the out-of-distribution robustness of the final model.},
  archive      = {J_TMRB},
  author       = {Abed Soleymani and Mahdi Tavakoli and Farzad Aghazadeh and Yafei Ou and Hossein Rouhani and Bin Zheng and Xingyu Li},
  doi          = {10.1109/TMRB.2024.3464110},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1490-1501},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Hands collaboration evaluation for surgical skills assessment: An information theoretical approach},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic centroid angle measurement from CT image for
preoperative rod design of robotic-assisted screw-rod system
implantation. <em>TMRB</em>, <em>6</em>(4), 1478–1489. (<a
href="https://doi.org/10.1109/TMRB.2024.3464106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic-assisted implantation of screw-rod systems serves as an advanced therapy for spinal diseases. A precise curvature fit between rods and spines is critical to postoperative spinal stability. Currently, rod curvature is determined intraoperatively to accommodate screw positions, which is hardly conducive to optimal rod bending and is vulnerable to surgeons’ expertise. To address this challenge, we propose an automated and efficient method for measuring the centroid angle to guide preoperative rod design from CT images. The centroid angle is defined by lines connecting centroids of the upper and lower vertebrae pairs, providing a reliable measurement for spinal deformities. The proposed pipeline includes (1) 3D spine segmentation with multiscale multitask deep learning; (2) vertebrae recognition using graphical morphology; (3) automatic and reproducible centroid angle measurement. Our method is evaluated on both healthy and pathological spines. Compared to manual measurements by professional surgeons, our method achieves an accuracy of 94.50% and 91.93% on adjacent and non-adjacent vertebrae, respectively. A Slicer-based plugin for robotic-assisted screw-rod systems implantation is built, providing a new clinical tool to personalize screw-rod systems consistent with the natural spinal curvature, thereby enhancing biomechanical properties.},
  archive      = {J_TMRB},
  author       = {Jiajing Zhang and Wenqing Zhang and Haodong Liu and Yingying Liu and Ningning Chen and Jianjia Zhang and Changhong Wang},
  doi          = {10.1109/TMRB.2024.3464106},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1478-1489},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Automatic centroid angle measurement from CT image for preoperative rod design of robotic-assisted screw-rod system implantation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MPC for suturing stitch automation. <em>TMRB</em>,
<em>6</em>(4), 1468–1477. (<a
href="https://doi.org/10.1109/TMRB.2024.3472796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot-assisted surgery (RAS) requires effective control strategies to ensure safety and accuracy while respecting the physical limits of the robot during tasks such as suturing and tissue manipulation. Model Predictive Control (MPC), with its inherent capability to handle complex dynamic systems, predict the future response and enforce constraints, is well-suited for these tasks. In this paper, MPC is employed to automate the suturing stitch task by mapping the operational space trajectory to the joint space while ensuring compliance with system kinematics constraints and safety requirements. To address varying requirements during suturing sub-tasks, two different objective functions and their corresponding constraint sets are used. The proposed framework is implemented using the ACADO toolkit to solve the Optimal Control Problem (OCP) and ROS to connect ACADO to CoppeliaSim/DVRK. Validation through simulations in CoppeliaSim and real-time experiments on the DVRK demonstrated that our approach achieved a positional/orientational accuracy of less than $1mm/4 ^{\circ }$ in simulations, and an error norm of approximately $1.9mm$ in real world implementations, confirming its effectiveness in automating suturing task.},
  archive      = {J_TMRB},
  author       = {Pasquale Marra and Sajjad Hussain and Marco Caianiello and Fanny Ficuciello},
  doi          = {10.1109/TMRB.2024.3472796},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1468-1477},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {MPC for suturing stitch automation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A reinforcement learning approach for real-time articulated
surgical instrument 3-d pose reconstruction. <em>TMRB</em>,
<em>6</em>(4), 1458–1467. (<a
href="https://doi.org/10.1109/TMRB.2024.3464089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D pose reconstruction of surgical instruments from images stands as a critical component in environment perception within robotic minimally invasive surgery (RMIS). The current deep learning methods rely on complex networks to enhance accuracy, making real-time implementation difficult. Moreover, diverging from a singular rigid body, surgical instruments exhibit an articulation structure, making the annotation of 3D poses more challenging. In this paper, we present a novel approach to formulate the 3D pose reconstruction of articulated surgical instruments as a Markov Decision Process (MDP). A Reinforcement Learning (RL) agent employs 2D image labels to control a virtual articulated skeleton to reproduce the 3D pose of the real surgical instrument. Firstly, a convolutional neural network is used to estimate the 2D pixel positions of joint nodes of the surgical instrument skeleton. Subsequently, the agent controls the 3D virtual articulated skeleton to align its joint nodes’ projections on the image plane with those in the real image. Validation of our proposed method is conducted using a semi-synthetic dataset with precise 3D pose labels and two real datasets, demonstrating the accuracy and efficacy of our approach. The results indicate the potential of our method in achieving real-time 3D pose reconstruction for articulated surgical instruments in the context of RMIS, addressing the challenges posed by low-texture surfaces and articulated structures.},
  archive      = {J_TMRB},
  author       = {Ke Fan and Ziyang Chen and Qiaoling Liu and Giancarlo Ferrigno and Elena De Momi},
  doi          = {10.1109/TMRB.2024.3464089},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1458-1467},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A reinforcement learning approach for real-time articulated surgical instrument 3-D pose reconstruction},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visuomotor policy learning for task automation of surgical
robot. <em>TMRB</em>, <em>6</em>(4), 1448–1457. (<a
href="https://doi.org/10.1109/TMRB.2024.3464090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing adoption of robotic surgery systems, the need for automated surgical tasks has become more pressing. Recent learning-based approaches provide solutions to surgical automation but typically rely on low-dimensional observations. To further imitate the actions of surgeons in an end-to-end paradigm, this paper introduces a novel visual-based approach to automating surgical tasks using generative imitation learning for robotic systems. We develop a hybrid model integrating state space models transformer, and conditional variational autoencoders (CVAE) to enhance performance and generalization called ACMT. The proposed model, leveraging the Mamba block and multi-head cross-attention mechanisms for sequential modeling, achieves a 75-100% success rate with just 100 demonstrations for most of the tasks. This work significantly advances data-driven automation in surgical robotics, aiming to alleviate the burden on surgeons and improve surgical outcomes.},
  archive      = {J_TMRB},
  author       = {Junhui Huang and Qingxin Shi and Dongsheng Xie and Yiming Ma and Xiaoming Liu and Changsheng Li and Xingguang Duan},
  doi          = {10.1109/TMRB.2024.3464090},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1448-1457},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Visuomotor policy learning for task automation of surgical robot},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autonomous robotic system for carotid artery ultrasound
scanning with visual servo navigation. <em>TMRB</em>, <em>6</em>(4),
1436–1447. (<a href="https://doi.org/10.1109/TMRB.2024.3464109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound (US) examination is widely used to diagnose carotid artery plaque, which requires the sonographer to guide the probe to scan along a specific path for complete coverage of the carotid artery region. Meanwhile, stable probe-neck interaction is important for high-quality image acquisition. In this study, a robotic system for autonomous carotid US scanning is proposed. To realize the autonomous visual servo movement of the probe, an object tracking method based on improved Siamese network is proposed. Meanwhile, a local quality assessment algorithm is proposed to ensure that carotid ultrasound images are clear and desirable for diagnosis. To address the issue of poor probe-neck contact and loss of carotid object during ultrasound scanning, an automatic recovery control method is proposed to ensure the continuity of the scanning process without the need to stop and restart the scanning. Experimental results show that the robotic system can successfully navigate the probe to move along a path that meets the clinical standard. In addition, the robot can autonomously rediscover the object and return to the normal scanning state if a stuck condition occurs.},
  archive      = {J_TMRB},
  author       = {Ziwen Wang and Yingying Han and Baoliang Zhao and Haiqin Xie and Liang Yao and Bing Li and Max Q.-H. Meng and Ying Hu},
  doi          = {10.1109/TMRB.2024.3464109},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1436-1447},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Autonomous robotic system for carotid artery ultrasound scanning with visual servo navigation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Auto-CALM: Autonomous computer-assisted laser microsurgery.
<em>TMRB</em>, <em>6</em>(4), 1423–1435. (<a
href="https://doi.org/10.1109/TMRB.2024.3468385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new controller for real-time dynamic laser ablation: the autonomous computer-assisted laser microsurgery system (Auto-CALM). Auto-CALM allows the surgeon to define the ablation area, which is then precisely ablated by the system while compensating for tissue motions and deformations. This is achieved based on three control blocks: target tracking, laser tracking, and ablation control algorithm. The ablation area, i.e., the target, is defined by the surgeon using a graphics tablet and graphics overlay on the surgical video. This target is then tracked in real-time using improved optical flow and a novel scaling strategy that makes the system robust against tissue deformations. Laser tracking is based on a pretrained Segment Anything Model that localizes the position of the laser in the surgical video. The ablation algorithm generates a trajectory to ablate the target given the dynamically updated laser position and target position. This enables motion compensation, which increases the accuracy of the system. Auto-CALM was validated through laser ablation experiments based on a porcine larynx fixed to a breathing motion simulation stage. The obtained results were also compared with those achieved under manual operation of CALM, and under autonomous ablation using the Track Anything Model as the target tracking algorithm. Furthermore, four different parts of the ex-vivo porcine larynx were tested to investigate different tracking features and the robustness of the system. Auto-CALM achieved a Dice Similarity Coefficient of 95.49% under the most challenging conditions (including tissue motion and no feature), reaching an ablation speed of $1.43~mm^{2}/s$ . The accuracy and usability of the integrated platform bear potential for the accurate ablation of tissue volumes in clinical settings. Further ex-vivo and in-vivo animal studies shall help translate these findings to clinical use.},
  archive      = {J_TMRB},
  author       = {Shunlei Li and Ajay Gunalan and Muhammad Adeel Azam and Veronica Penza and Darwin G. Caldwell and Leonardo S. Mattos},
  doi          = {10.1109/TMRB.2024.3468385},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1423-1435},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Auto-CALM: Autonomous computer-assisted laser microsurgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancements and challenges in the development of robotic
lower limb prostheses: A systematic review. <em>TMRB</em>,
<em>6</em>(4), 1409–1422. (<a
href="https://doi.org/10.1109/TMRB.2024.3464126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lower limb prosthetics, essential for restoring mobility in individuals with limb loss, have witnessed significant advancements in recent years. This systematic review reports the recent research advancements in the field of semi-active and active lower limb prostheses. The review focuses on the mechatronic features of the devices, the sensing and control strategies, and the performance verification with end-users. A total of 53 prosthetic prototypes were identified and analyzed, including 16 knee-ankle prostheses, 18 knee prostheses, and 19 ankle prostheses. The review highlights some of the open challenges in the field of prosthetic research.},
  archive      = {J_TMRB},
  author       = {Ilaria Fagioli and Alessandro Mazzarini and Chiara Livolsi and Emanuele Gruppioni and Nicola Vitiello and Simona Crea and Emilio Trigili},
  doi          = {10.1109/TMRB.2024.3464126},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1409-1422},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Advancements and challenges in the development of robotic lower limb prostheses: A systematic review},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ENTRI: Enhanced navigational toolkit for robotic
interventions. <em>TMRB</em>, <em>6</em>(4), 1405–1408. (<a
href="https://doi.org/10.1109/TMRB.2024.3475827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-guided robotic interventions represent a transformative frontier in surgery, blending advanced imaging and robotics for improved precision and outcomes. This paper addresses the critical need for integrating open-source platforms to enhance situational awareness in image-guided robotic research. We present an open-source toolkit, named ENTRI, that seamlessly combines a physics-based constraint formulation framework, AMBF, with a state-of-the-art imaging platform application, 3D Slicer. ENTRI facilitates the creation of highly customizable interactive digital twins, that incorporate processing and visualization of medical imaging, robot kinematics, and scene dynamics for real-time robot control. Through a feasibility study, we showcase real-time synchronization of a physical robotic interventional environment in both 3D Slicer and AMBF, highlighting low-latency updates and improved visualization. The source code and supplementary materials for this study are available at https://github.com/LCSR-CIIS/ENTRI.},
  archive      = {J_TMRB},
  author       = {Manish Sahu and Hisashi Ishida and Laura Connolly and Hongyi Fan and Anton Deguet and Peter Kazanzides and Francis X. Creighton and Russell H. Taylor and Adnan Munawar},
  doi          = {10.1109/TMRB.2024.3475827},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1405-1408},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {ENTRI: Enhanced navigational toolkit for robotic interventions},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulating surgical robot cutting of thin deformable
materials using a rope grid structure. <em>TMRB</em>, <em>6</em>(4),
1401–1404. (<a href="https://doi.org/10.1109/TMRB.2024.3475509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods for autonomous cutting in surgical robotics have relied on trajectory-based planning algorithms. These methods fail to compensate for dynamic changes in soft materials such as deformation and topological change. To apply recent advances such as reinforcement learning (RL), a simulation is needed that models the cutting of soft materials. In this work, we develop a surgical robotics simulation environment for cutting deformable meshes with the da Vinci Research Kit (dVRK). Our environment is built using a particle-based physics simulation to simulate a rope grid structure to create realistic physics behavior and visual rendering. Cutting is implemented with the EndoWrist Round Tip Scissors (RTS) through a system of collision checking and callbacks to detect and update cuts. To showcase the deformable mesh cutting simulation, we design a cutting task of cutting along a desired path that can be solved through manual control. The grid structure can be adapted to render different materials, and we highlight how it can be made to resemble deformable tissue or fabric while being stable with no visible artifacts. This environment is a stepping stone towards training autonomous agents for cutting 2D deformable materials and building towards cutting more complex deformable shapes.},
  archive      = {J_TMRB},
  author       = {Mustafa Haiderbhai and Lueder A. Kahrs},
  doi          = {10.1109/TMRB.2024.3475509},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1401-1404},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Simulating surgical robot cutting of thin deformable materials using a rope grid structure},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design, analysis, and preliminary validation of magnetic
anchored and cable driven endoscope for minimally invasive surgery.
<em>TMRB</em>, <em>6</em>(4), 1397–1400. (<a
href="https://doi.org/10.1109/TMRB.2024.3472833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic anchored and guided system(MAGS) is a promising solution for minimally invasive surgery, particularly in the realm of endoscope robotics. However, the inherent tight tissue contact in MAGS limits certain degrees of freedom, constraining the surgeon’s ability to adjust the field of view. To address this, we propose a novel solution by combining magnetic actuation with a cable-driven flexible link. Our study encompasses the design, analysis of magnetic force/torque, and kinematics of the flexible link. One prototype was fabricated, and experiments, including the evaluation of magnetic coupling performance and the motion of the flexible link, were conducted. These experiments validated both the theoretical modeling and the functionality of the magnetic endoscope system.},
  archive      = {J_TMRB},
  author       = {Jixiu Li and Tao Zhang and Truman Cheng and Yehui Li and Calvin Sze Hang Ng and Philip Wai Yan Chiu and Zheng Li},
  doi          = {10.1109/TMRB.2024.3472833},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1397-1400},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Design, analysis, and preliminary validation of magnetic anchored and cable driven endoscope for minimally invasive surgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coaching a robotic sonographer: Learning robotic ultrasound
with sparse expert’s feedback. <em>TMRB</em>, <em>6</em>(4), 1391–1396.
(<a href="https://doi.org/10.1109/TMRB.2024.3464698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound is widely employed for clinical intervention and diagnosis, due to its advantages of offering non-invasive, radiation-free, and real-time imaging. However, the accessibility of this dexterous procedure is limited due to the substantial training and expertise required of operators. The robotic ultrasound (RUS) offers a viable solution to address this limitation; nonetheless, achieving human-level proficiency remains challenging. Learning from demonstrations (LfD) methods have been explored in RUS, which learns the policy prior from a dataset of offline demonstrations to encode the mental model of the expert sonographer. However, active engagement of experts, i.e., Coaching, during the training of RUS has not been explored thus far. Coaching is known for enhancing efficiency and performance in human training. This paper proposes a coaching framework for RUS to amplify its performance. The framework combines DRL (self-supervised practice) with sparse expert’s feedback through coaching. The DRL employs an off-policy Soft Actor-Critic (SAC) network, with a reward based on image quality rating. The coaching by experts is modeled as a Partially Observable Markov Decision Process (POMDP), which updates the policy parameters based on the correction by the expert. The validation study on phantoms showed that coaching increases the learning rate by 25% and the number of high-quality image acquisition by 74.5%.},
  archive      = {J_TMRB},
  author       = {Deepak Raina and Mythra V. Balakuntala and Byung Wook Kim and Juan Wachs and Richard Voyles},
  doi          = {10.1109/TMRB.2024.3464698},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1391-1396},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Coaching a robotic sonographer: Learning robotic ultrasound with sparse expert’s feedback},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic focus adjustment for single-spot tissue
temperature control in robotic laser surgery. <em>TMRB</em>,
<em>6</em>(4), 1386–1390. (<a
href="https://doi.org/10.1109/TMRB.2024.3464670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reports on a study whose goal is to control the tissue temperature at a specific spot during laser surgery, for the purpose of, inducing coagulation or sealing blood vessels. We propose a solution that relies on the automatic adjustment of the laser focus (and thus how concentrated the laser beam is), combined with the use of an infrared thermal camera for non-contact temperature monitoring. One of the main challenges in the control of thermal laser-tissue interactions is that these interactions can be hard to predict due to the inherent variability in the molecular composition of biological tissue. To tackle this challenge, we explore two different control approaches: (1) a model-less controller using a Proportional-Integral (PI) formulation, whose gains are set via a tuning procedure performed on laboratory-made tissue phantoms; and (2) a model-based controller using an adaptive formulation that makes it robust to tissue variability. We report on experiments, performed on four types of tissue specimens, showing that both controllers can consistently achieve temperature tracking with a Root-Mean-Square Error (RMSE) $\approx$ 1 °C.},
  archive      = {J_TMRB},
  author       = {Nicholas E. Pacheco and Chaitanya S. Gaddipati and Siavash Farzan and Loris Fichera},
  doi          = {10.1109/TMRB.2024.3464670},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1386-1390},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Automatic focus adjustment for single-spot tissue temperature control in robotic laser surgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global versus local kinematic skills assessment on
robotic-assisted hysterectomies. <em>TMRB</em>, <em>6</em>(4),
1382–1385. (<a href="https://doi.org/10.1109/TMRB.2024.3464669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different methods have been proposed to evaluate surgical skills from observer-based scoring to recent data-driven approaches. However, most of these methods assess the surgical performance considering the procedure as a whole, avoiding detailed performance insights. In this study, we focused on the most challenging phases of robotic-assisted hysterectomies to compare the performance of expert and intermediate surgeons using the surgical process model methodology. We recorded surgical video and kinematic data of fifty-two robotic-assisted laparoscopic hysterectomies performed by five experts and three intermediate surgeons. We annotated the video in eight phases. We computed twenty-five automated performance metrics (APMs); seven for each of the right, left, and endoscope robotic arms, and four global ones. For the global analysis, only four APMs differed significantly between experts and intermediates. However, interpreting these APMs was difficult. For local analysis, we observed that 23 APMs were significantly different for at least one phase. We found that the two most challenging phases had APMs that highlighted difficulty due to the presence of the uterus, lack of confidence in anatomical knowledge, and difficulty in moving the endoscope. Such results of the local analysis allow us to propose appropriate training for surgeons.},
  archive      = {J_TMRB},
  author       = {Arnaud Huaulmé and Krystel Nyangoh Timoh and Victor Jan and Sonia Guerin and Pierre Jannin},
  doi          = {10.1109/TMRB.2024.3464669},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1382-1385},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Global versus local kinematic skills assessment on robotic-assisted hysterectomies},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward variable-friction catheters using ultrasonic
lubrication. <em>TMRB</em>, <em>6</em>(4), 1375–1381. (<a
href="https://doi.org/10.1109/TMRB.2024.3464672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimally invasive endovascular procedures use catheters that are guided through blood vessels to perform interventions, resulting in an inevitable frictional interaction between the catheter and the vessel walls. While this friction enhances stability during the intervention, it poses a risk of damaging the inner layer of the blood vessel wall during navigation, leading to post-operative complications including infectious diseases and thrombus formation. To mitigate the risk of adverse complications, we propose a new concept of a variable-friction catheter capable of transitioning from low friction during navigation to high friction for increased stability while performing the intervention. This variable-friction catheter leverages ultrasonic lubrication to actively control the frictional forces experienced by the catheter during the procedure. In this paper, we demonstrate a proof-of-concept for a friction control module, a pivotal component of the proposed catheter design. Our experiments demonstrate that the prototype effectively reduce friction by up to 11% and 60%, on average, on soft and rigid surfaces, representing its potential performance on healthy and calcified tissue, respectively. This result underscores the feasibility of the design and its potential to improve the safety and efficacy of minimally invasive endovascular procedures.},
  archive      = {J_TMRB},
  author       = {Mostafa A. Atalla and Jeroen J. Tuijp and Michaël Wiertlewski and Aimée Sakes},
  doi          = {10.1109/TMRB.2024.3464672},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1375-1381},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Toward variable-friction catheters using ultrasonic lubrication},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Embedded force sensor for soft robots with deep
transformation calibration. <em>TMRB</em>, <em>6</em>(4), 1363–1374. (<a
href="https://doi.org/10.1109/TMRB.2024.3479878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel soft sensor calibration method is proposed for minimally invasive surgery, based on our developed gelatin-graphite sensor with high compliance and adaptability. This approach uses convolutional deep learning that accounts for a sensor’s non-linear behavior and reduces noise amplification. This technique offers a smaller minimum detectable force than other approaches and is particularly useful in sensitive surgical scenarios. The sensor’s performance is characterized by its fine resolution ( $\leq 1$ mN) and accurate force estimation, especially for forces below 400 mN of amplitude. The best calibration (Morse) scheme provides high performance, with a Mean Absolute Error of $\leq 7.9$ mN. This work was validated through comparison among other representative studies and offered a path toward future directions for optimizing and implementing soft robotic sensors in minimally invasive surgeries. The application of this sensor can revolutionize surgical procedures and capitalize on the benefits of soft robotics, potentially enhancing precision and reducing trauma in surgeries.},
  archive      = {J_TMRB},
  author       = {Navid Masoumi and Andrés C. Ramos and Tannaz Torkaman and Liane S. Feldman and Jake Barralet and Javad Dargahi and Amir Hooshiar},
  doi          = {10.1109/TMRB.2024.3479878},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1363-1374},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Embedded force sensor for soft robots with deep transformation calibration},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-based tracking control of a soft growing robot for
colonoscopy. <em>TMRB</em>, <em>6</em>(4), 1354–1362. (<a
href="https://doi.org/10.1109/TMRB.2024.3474059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the model based tracking control of soft growing robots with pneumatic actuation that extend according to the principle known as eversion. A model of the system which accounts for the pressure dynamics is presented. A new control law is constructed with a high-order sliding-mode approach and a nonlinear observer is employed to compensate for the effect of external forces. Numerical simulations and experiments demonstrate the effectiveness of the proposed controller compared to our former energy-shaping implementation and to a baseline sliding-mode controller. Experiments with a training phantom demonstrate that the new controller resulted in a reduced peak pressure, approximately 14.8% lower, a reduced tracking error, approximately 4.9% lower RMSE, and a reduced consumption of compressed air, approximately 3.9% lower, compared to a baseline sliding-mode algorithm.},
  archive      = {J_TMRB},
  author       = {Korn Borvorntanajanya and Shen Treratanakulchai and Ferdinando Rodriguez y Rodriguez and Enrico Franco},
  doi          = {10.1109/TMRB.2024.3474059},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1354-1362},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Model-based tracking control of a soft growing robot for colonoscopy},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SLAM-based breast reconstruction system for surgical
guidance using a low-cost camera. <em>TMRB</em>, <em>6</em>(4),
1345–1353. (<a href="https://doi.org/10.1109/TMRB.2024.3464739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mastectomy is often coupled with breast reconstruction surgery (BRS) to reconstruct the breast mound. However, BRS is challenging and subject to the judgement of the surgeon in determining the amount of tissue to be harvested and the shape of reconstructed breast. To date, the existing tools aimed at maintaining symmetry and appearance of the reconstructed breast are costly. In this paper, we have developed an intuitive breast reconstruction system comprising a software application integrated with the simultaneous localization and mapping (SLAM) algorithm, and a low-cost RGB-D camera. Our SLAM-based breast reconstruction system will be used to scan and reconstruct the patient’s breast using our customized mesh-generating method prior to mastectomy. Using this reconstructed model, a patient-specific 3D printed mold is created to help shape the harvested tissue that is inserted into the mastectomy site during BRS. Validation experiments show that the mean repeatability and accuracy errors for the surface reconstruction are less than 1.5 mm. The software application has been tested on 20 patients under an IRB-approved protocol including intraoperative guidance for 4 patients. The results show the consistent and accurate reconstruction of the breasts including the inframammary fold for different breast shapes and skin tones.},
  archive      = {J_TMRB},
  author       = {Elise Fu and Haoyin Zhou and Ángela Alarcón de la Lastra and Ruisi Zhang and Haripriya Ayyala and Justin Broyles and Bohdan Pomahac and Jayender Jagadeesan},
  doi          = {10.1109/TMRB.2024.3464739},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1345-1353},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {SLAM-based breast reconstruction system for surgical guidance using a low-cost camera},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SlicerROS2: A research and development module for
image-guided robotic interventions. <em>TMRB</em>, <em>6</em>(4),
1334–1344. (<a href="https://doi.org/10.1109/TMRB.2024.3464683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-guided robotic interventions involve the use of medical imaging in tandem with robotics. SlicerROS2 is a software module that combines 3D Slicer and robot operating system (ROS) in pursuit of a standard integration approach for medical robotics research. The first release of SlicerROS2 demonstrated the feasibility of using the C++ API from 3D Slicer and ROS to load and visualize robots in real time. Since this initial release, we’ve rewritten and redesigned the module to offer greater modularity, access to low-level features, access to 3D Slicer’s Python API, and better data transfer protocols. In this paper, we introduce this new design as well as four applications that leverage the core functionalities of SlicerROS2 in realistic image-guided robotics scenarios.},
  archive      = {J_TMRB},
  author       = {Laura Connolly and Aravind S. Kumar and Kapi Ketan Mehta and Lidia Al-Zogbi and Peter Kazanzides and Parvin Mousavi and Gabor Fichtinger and Axel Krieger and Junichi Tokuda and Russell H. Taylor and Simon Leonard and Anton Deguet},
  doi          = {10.1109/TMRB.2024.3464683},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1334-1344},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {SlicerROS2: A research and development module for image-guided robotic interventions},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Magnetic ball chain robots for cardiac arrhythmia treatment.
<em>TMRB</em>, <em>6</em>(4), 1322–1333. (<a
href="https://doi.org/10.1109/TMRB.2024.3465828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel magnetic navigation system for cardiac ablation. The system is formed from two key elements: a magnetic ablation catheter consisting of a chain of spherical permanent magnets; and an actuation system comprised of two cart-mounted permanent magnets undergoing pure rotation. The catheter design enables a large magnetic content with the goal of minimizing the footprint of the actuation system for easier integration with the clinical workflow. We present a quasi-static model of the catheter, the design of the actuation units, and their control modalities. Experimental validation shows that we can use small rotating magnets (119mm diameter) to reach cardiac ablation targets while generating clinically-relevant forces. Catheter control using a joystick is compared with manual catheter control. While total task completion time is similar, smoother navigation is observed using the proposed robotic system. We also demonstrate that the ball chain can ablate heart tissue and generate lesions comparable to the current clinical ablation catheters.},
  archive      = {J_TMRB},
  author       = {Giovanni Pittiglio and Fabio Leuenberger and Margherita Mencattelli and Max McCandless and Edward O’Leary and Pierre E. Dupont},
  doi          = {10.1109/TMRB.2024.3465828},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1322-1333},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Magnetic ball chain robots for cardiac arrhythmia treatment},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-cavity touch interface for a flexible soft
laparoscopy device: Design and evaluation. <em>TMRB</em>, <em>6</em>(4),
1309–1321. (<a href="https://doi.org/10.1109/TMRB.2024.3464676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical instruments made of compliant materials provide increased safety and dexterity when interacting with anatomical environments. Beyond the development of hardware, the maneuverability of these medical instruments presents significant challenges, especially in practical applications like minimally invasive surgery. Consequently, developing efficient and intuitive interfaces for operating these soft instruments is crucial. This study focuses on creating a flexible, soft robotic handheld laparoscopy device featuring a multi-cavity touch interface. The pneumatically driven soft robotic device has a continuum structure and an outermost diameter of 11.5 mm. The laparoscopy device is equipped with a silicone-cast touch interface that includes five air-filled cavities. Monitoring the pressure within these cavities facilitates the identification of user inputs, offering an intuitive and cost-effective way to operate the device. To evaluate the laparoscopy device’s performance, in vitro tests were conducted using a test rig and a phantom environment. The device’s usability was assessed by participants, providing valuable insights into its functionality and practicality in a controlled setting. These evaluations lay the groundwork for future advancements in soft robotic medical instruments for minimally invasive procedures.},
  archive      = {J_TMRB},
  author       = {Jialei Shi and Ge Shi and Yu Wu and Helge A. Wurdemann},
  doi          = {10.1109/TMRB.2024.3464676},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1309-1321},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A multi-cavity touch interface for a flexible soft laparoscopy device: Design and evaluation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A chemical reaction-driven untethered volume changing
robotic capsule for tissue dilation. <em>TMRB</em>, <em>6</em>(4),
1300–1308. (<a href="https://doi.org/10.1109/TMRB.2024.3464728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic capsules provide an alternative route of entry to the gastrointestinal tract with minimal discomfort to patients. As capabilities of milli to micro robots progress, the potential of using robotic capsules not just for inspection, but for surgical procedures increase. To aid operations in the intestine, the capsule could be used to expand the site of surgery and anchoring to the intestinal walls to keep itself in place. This paper presents an untethered robotic capsule that can provide volumetric expansion using a chemical reaction without on-board electronic components. The expansion is based on the reaction between chemicals that are safe for ingestion, operated with magnetic fields and temperatures that are within safe limits. The capsule was able to expand greater than the diameter of the small intestine for 44 minutes and provided 0.27N of anchoring force. A theoretical model of the reaction process was built and simulated to predict the behavior of the capsule expansion and validated through the experiments. The design and the simulation presented in this paper can be used for fabricating capsules to specific clinical needs. The work also opens up the possibility of untethered technologies that are remotely and chemically programmed for in-vivo surgical applications.},
  archive      = {J_TMRB},
  author       = {Kaan Esendag and Mark E. McAlindon and Daniela Rus and Shuhei Miyashita and Dana D. Damian},
  doi          = {10.1109/TMRB.2024.3464728},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1300-1308},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A chemical reaction-driven untethered volume changing robotic capsule for tissue dilation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guest editorial special section on the hamlyn symposium
2023—immersive tech: The future of medicine. <em>TMRB</em>,
<em>6</em>(4), 1298–1299. (<a
href="https://doi.org/10.1109/TMRB.2024.3484068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TMRB},
  author       = {Alan Kuntz and Blake Hannaford and Robert J. Webster},
  doi          = {10.1109/TMRB.2024.3484068},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {11},
  number       = {4},
  pages        = {1298-1299},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Guest editorial special section on the hamlyn symposium 2023—Immersive tech: The future of medicine},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GHMM: Learning generative hybrid mixture models for
generalized point set registration in computer-assisted orthopedic
surgery. <em>TMRB</em>, <em>6</em>(3), 1285–1295. (<a
href="https://doi.org/10.1109/TMRB.2024.3407362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In computer-assisted orthopedic surgery (CAOS), the overlay of pre-operative information onto the surgical scene is achieved through the registration of pre-operative 3D models with the intra-operative surface. The accuracy and robustness of this registration are crucial for effective interventional guidance. To enhance these qualities in CAOS, we explore the use of normal vectors and the concept of joint registration of two point sets, to simultaneously utilize more useful geometrical information and consider noise and outliers in both pre-operative and intra-operative spaces. We present a novel end-to-end hybrid learning-based registration method for CAOS by utilizing generalized point sets that consist of positional and normal vectors, which are considered to be generated from an unknown Generative Hybrid Mixture Model (GHMM) composed of Gaussian Mixture Models (GMMs) and Fisher Mixture Models (FMMs). The joint registration is cast as a maximum likelihood estimation (MLE) problem that aims to minimize the distances between the generalized points and the hybrid distributions. Our proposed approach, termed GHMM, has been extensively validated on various medical data sets (i.e., 291 human femur and 260 hip models) and the public dataset ModelNet40, outperforming state-of-the-art registration methods significantly $(\text {p-value}\lt 0.01)$ . This suggests the potential of GHMM for applications in orthopedic surgical navigation and object localization. Furthermore, even under different noises and lower overlap ratio conditions, all evaluation metrics of GHMM are superior to other probabilistic methods, demonstrating GHMM’s great capability to handle the partial-to-full registration problem and robustness to disturbances.},
  archive      = {J_TMRB},
  author       = {Zhengyan Zhang and Ang Zhang and Jiewen Lai and Hongliang Ren and Rui Song and Yibin Li and Max Q.-H. Meng and Zhe Min},
  doi          = {10.1109/TMRB.2024.3407362},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1285-1295},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {GHMM: Learning generative hybrid mixture models for generalized point set registration in computer-assisted orthopedic surgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fourier decomposition-based automated classification of
healthy, COPD, and asthma using single-channel lung sounds.
<em>TMRB</em>, <em>6</em>(3), 1270–1284. (<a
href="https://doi.org/10.1109/TMRB.2024.3408325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subjective discrimination of asthma and Chronic Obstructive Pulmonary Disease (COPD) is challenging as they share overlapping symptoms and are subject to personal interpretation. Hence, there is a demand for an alternative diagnostic system devoid of any subjective interference. The current study introduces Fourier Decomposition Method (FDM) based models utilizing Discrete Cosine Transform (DCT) and Discrete Fourier Transform (DFT) to identify patients with asthma and COPD by analyzing lung sound signals. The signals were decomposed into Fourier intrinsic band functions (FIBF) using three filter banks: dyadic, equal energy, and uniform band. Four statistical attributes, namely: Shannon entropy, log entropy, median absolute deviation and kurtosis, are calculated from relevant FIBF. Support vector machine (SVM), k-nearest neighbor (kNN) and ensemble classifier (EC) optimized with Bayesian optimization are used for classification of asthma vs COPD and normal vs adventitious sound, respectively. The highest accuracies achieved using DCT with 10-fold cross-validation are as follows: 99.4% (Asthma vs COPD), 99.1% (Asthma vs COPD vs Normal), 99.4% (COPD vs Normal) and 99.7% (Asthma vs Normal). Similarly, the highest accuracies reported by DFT with 10-fold cross-validation are: 99.4% (Asthma vs COPD), 99.6% (Asthma vs COPD vs Normal), 99.4% (COPD vs Normal) and 99.8% (Asthma vs Normal).},
  archive      = {J_TMRB},
  author       = {Vaibhav Koshta and Bikesh Kumar Singh and Ajoy K. Behera and Ranganath T. G.},
  doi          = {10.1109/TMRB.2024.3408325},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1270-1284},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Fourier decomposition-based automated classification of healthy, COPD, and asthma using single-channel lung sounds},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Needle steering controller design for flexible steerable
needle utilizing robust backstepping control strategy. <em>TMRB</em>,
<em>6</em>(3), 1256–1269. (<a
href="https://doi.org/10.1109/TMRB.2024.3421593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Minimal Invasive Surgery (MIS), steerable flexible needles are commonly utilized as surgical tools to improve target-reaching accuracy. Nevertheless, challenges like tissue deformation, tissue inhomogeneity, and noisy sensory measurements can lead to inaccuracies in needle-tip positioning within the tissue domain. Therefore, to ensure precise needle placement in tissue region, designing a robust non-linear closed-loop needle steering control becomes a crucial aspect in percutaneous intervention procedures. Consequently, in pursuit of accurate and precise needle placement within tissue, various controller methodologies are evident in current literature. However, to address the complexity associated with the design of existing control strategies, this study introduces a robust non-linear needle steering controller within the tissue environment, with the goal of stabilizing the needle within a designated plane. Our proposed needle steering technique incorporates the backstepping based controller that involves the splitting of entire needle kinematic model into several smaller designs while ensuring closed-loop stability through Lyapunov stability analyses. Efficacy of the devised needle steering approach is validated by comparing it with existing control techniques through extensive simulation studies, specifically focusing on needle placement in both 2D and 3D planes. Furthermore, experimental validation is performed involving brachytherapy needle with both artificial tissue phantom and biological tissue.},
  archive      = {J_TMRB},
  author       = {Kaushik Halder and M. Felix Orlando},
  doi          = {10.1109/TMRB.2024.3421593},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1256-1269},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Needle steering controller design for flexible steerable needle utilizing robust backstepping control strategy},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time insertion depth tracking of cochlear implant
electrode array with bipolar complex impedance and machine intelligence.
<em>TMRB</em>, <em>6</em>(3), 1245–1255. (<a
href="https://doi.org/10.1109/TMRB.2024.3407355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cochlear implants have significantly improved hearing for many as the most successful prosthesis, however, hearing outcomes vary. Uncertainty during electrode array (EA) insertion, including trauma and depth control, is one factor. To minimize radiation exposure from imaging methods like CT scans, this in-vitro study investigates the use of bipolar electrode impedance and artificial intelligent models to determine EA insertion depth. Complex impedance data was collected by inserting a commercial EA into a scaled-up 2D scala tympani model using a robotic feeder system. A support vector machine model produced a 98% classification accuracy for final insertion depth estimation. A CNN-LSTM hybrid model yielded 0.85 R-squared and 1.72 mm mean absolute error in depth estimation at each millimeter during a 25 mm insertion. This approach to depth assessment based on impedance may help with cochlear implant procedures and find use in other medical implant applications.},
  archive      = {J_TMRB},
  author       = {Nauman Hafeez and Nikolaos Boulgouris and Philip Begg and Richard Irving and Chris Coulson and Hao Wu and Huan Jia and Xinli Du},
  doi          = {10.1109/TMRB.2024.3407355},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1245-1255},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Real-time insertion depth tracking of cochlear implant electrode array with bipolar complex impedance and machine intelligence},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian algorithm-based force profiles optimization of
hip-assistive soft exosuits under variable walking speeds.
<em>TMRB</em>, <em>6</em>(3), 1232–1244. (<a
href="https://doi.org/10.1109/TMRB.2024.3408308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relevant research highlights humans’ capacity to continuously adapt their walking speed to minimize metabolic energy consumption during overground free walking. Past studies have shown that soft exosuits assisting in hip flexion and extension can reduce metabolic costs and regulate gait parameters during human locomotion. This emphasizes the need to fine-tune hip exosuit parameters to align with walking speed, thereby enhancing metabolic efficiency. This study aims to optimize assistive force parameters of hip exosuits across different walking speeds, providing insights for optimizing force profiles in outdoor walking. We employed a human-in-the-loop approach with Bayesian optimization to determine optimal force profiles for hip assistance. Six subjects performed treadmill walking at four fixed speeds (0.84, 1.16, 1.48, and 1.8 m/s), optimizing control parameters for each speed and establishing a Bayesian experience (BXE) linking walking speed to optimal parameters. Furthermore, we developed a real-time force optimization controller based on the BXE for adjusting the force parameters of assistance. Outdoor walking experiments with the same subjects showed that BXE-optimized profiles significantly reduced metabolic costs compared to fixed profiles. This study underscores the importance of optimizing assistive forces for varying walking speeds in humans.},
  archive      = {J_TMRB},
  author       = {Qiang Chen and Jiaxin Wang and Qian Xiang and Shijie Guo},
  doi          = {10.1109/TMRB.2024.3408308},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1232-1244},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Bayesian algorithm-based force profiles optimization of hip-assistive soft exosuits under variable walking speeds},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cable-driven light-weighting and portable system for robotic
medical ultrasound imaging. <em>TMRB</em>, <em>6</em>(3), 1220–1231. (<a
href="https://doi.org/10.1109/TMRB.2024.3422608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic ultrasound imaging systems (RUSs) have captured significant interest owing to their potential to facilitate autonomous ultrasound imaging. However, existing RUSs built upon robotic systems oriented towards conventional manufacturing struggle to navigate the variable and dynamic clinical environments. We introduce a portable and lightweight RUS designed to enhance adaptability for ultrasound imaging tasks. The proposed system features multiple parallel rings and bearings, affording it four degrees-of-freedom for precise posture control. Further enhancing its adaptability, the actuators are isolated from the mechanism and connected by a cable-sheath mechanism, resulting in a mere 519g lightweight structure that attaches to the body. Quantitative assessments indicate that within a vast workspace of 981 cm3, the posture control precision of the probe is measured at $1.32\pm 0.1$ mm and [ $1.8\pm 1.1^{\circ }$ , $1.9\pm 2.2^{\circ }$ , $0.8~\pm 0.8^{\circ }$ ]. The maximum compression force measured for the probe is 14.5 N. The quantitative evaluation results show that the system can attach to various parts of the human body for image acquisition. In addition, the proposed system excels in performing stable scanning procedures even in rapidly changing dynamic environments. Our system can realize imaging tasks with a much lighter structure and has the potential to be applied to more complex scenarios.},
  archive      = {J_TMRB},
  author       = {Guochen Ning and Jie Wang and Hongen Liao},
  doi          = {10.1109/TMRB.2024.3422608},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1220-1231},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Cable-driven light-weighting and portable system for robotic medical ultrasound imaging},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Training explainable and effective multi-DoF EMG decoder
using additive 1-DoF EMG. <em>TMRB</em>, <em>6</em>(3), 1212–1219. (<a
href="https://doi.org/10.1109/TMRB.2024.3408312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human hands can execute intricate and dexterous control of diverse objects. Decoding hand motions, especially estimating the force of each individual finger via surface electromyography (sEMG), is an essential step in intuitive and dexterous control of prosthetics, exoskeletons and more various human-machine systems. Previous sEMG decoders lack explainability and show degraded performances in decoding finger forces with multiple degrees-of-freedom (DoFs). When developing a multi-DoF EMG decoder, the combinations of various forces levels exerted by different fingers are too numerous to be exhaustively enumerate. In our work, we utilized the data of 1-DoF finger activation to generate synthetic N-DoF sEMG data with a straightforward additive mixup data augmentation approach, which overlays 1-DoF sEMG signals and finger force labels. The basic assumption of our method is the additive property of sEMG associated with different DoFs. With the synthetic N-DoF sEMG data, we then developed N-DoF EMG-force models via the highly explainable deep forest built on simple and transparent decision trees. With data augmentation using only 1-DoF sEMG data, the regression error reduced by ~20% of the baseline level (without data augmentation). More significantly, the explainability of the deep forest suggested that, the crucial electrodes in the decision making process of the 2-DoF deep forest are essentially a linear superposition of the counterparts in the 1-DoF deep forest.},
  archive      = {J_TMRB},
  author       = {Yangyang Yuan and Chenyun Dai and Jiahao Fan and Chihhong Chou and Jionghui Liu and Xinyu Jiang},
  doi          = {10.1109/TMRB.2024.3408312},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1212-1219},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Training explainable and effective multi-DoF EMG decoder using additive 1-DoF EMG},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced EMG-based hand gesture classification in real-world
scenarios: Mitigating dynamic factors with tempo-spatial wavelet
transform and deep learning. <em>TMRB</em>, <em>6</em>(3), 1202–1211.
(<a href="https://doi.org/10.1109/TMRB.2024.3408896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic factors, like limb position changes and electrode shifting, significantly impact the performance of EMG-based hand gesture classification as the transition is made from a laboratory-controlled environment to real-life scenarios. Traditionally, researchers have employed conventional wavelet transform methods to improve classification performance. This study compares a tempo-spatial technique that utilizes the wavelet multiresolution method and compares it with the conventional wavelet transform using eight machine learning algorithms. Two public datasets are utilized. DB1 comprising ideal conditions with a range of limb positions, while DB2 incorporates dynamic factors like electrode shifting and muscle fatigue. The training/testing involves two cases: one using single-position data and other with multiple positions. Results demonstrate that the Deep Neural Network (DNN) classifier outperforms others in classification accuracy. Proposed technique achieves mean accuracies of 84.07% (DB1) and 68.15% (DB2), while conventional wavelet transform methods achieve 79.39% (DB1) and 53.48% (DB2) for single-position DNN training. For multiple positions, particularly two limb positions, the proposed technique achieves mean accuracies of 94.43% (DB1) and 73.79% (DB2), compared to conventional wavelet transform, which achieves 84.38% (DB1) and 51.98% (DB2) with DNN. Paired t-tests (p-value&lt;0.001) show significant improvement over conventional wavelet transformation, indicating the proposed technique’s potential to enhance gesture classification in real-world scenarios.},
  archive      = {J_TMRB},
  author       = {Parul Rani and Sidharth Pancholi and Vikash Shaw and Manfredo Atzori and Sanjeev Kumar},
  doi          = {10.1109/TMRB.2024.3408896},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1202-1211},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Enhanced EMG-based hand gesture classification in real-world scenarios: Mitigating dynamic factors with tempo-spatial wavelet transform and deep learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MyKnee: Mechatronic design of a novel powered variable
stiffness prosthetic knee. <em>TMRB</em>, <em>6</em>(3), 1190–1201. (<a
href="https://doi.org/10.1109/TMRB.2024.3407194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Powered prosthetic legs have the potential of significantly enhancing the mobility, independence, and overall quality of life of individuals with lower-limb amputation. Unfortunately, powered prosthesis are followed by the issue of their weight and limited battery life when compared to passive or semi-active prosthesis, which, conversely, lack of complex movement capabilities. In this paper, we present an innovative design and the development of a powered prosthetic knee joint, which is actuated by means of a compact variable stiffness actuator. This innovative and promising technology can provide adaptability to different activities of daily living, while also ensuring energy efficiency and maintaining a lightweight design. The key feature of this novel powered knee joint lies in the use of a mechanism that can vary the stiffness of the joint through newly designed non-linear elastic elements. By applying advanced finite element analysis in the design process, a robust device has been realized that could readily comply with the ISO 10328.2016 standard for structural integrity. This made the knee joint suitable for future clinical trials with people with above-knee amputation.},
  archive      = {J_TMRB},
  author       = {Gregorio Tagliabue and Vishal Raveendranathan and Amedeo Gariboldi and Lennard Y. Hut and Andrea Zucchelli and Raffaella Carloni},
  doi          = {10.1109/TMRB.2024.3407194},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1190-1201},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {MyKnee: Mechatronic design of a novel powered variable stiffness prosthetic knee},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid rigid-soft and pneumatic-electromechanical
exoskeleton for multi-joint lower limb assistance. <em>TMRB</em>,
<em>6</em>(3), 1180–1189. (<a
href="https://doi.org/10.1109/TMRB.2024.3421547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human augmentation typically employs either rigid exoskeletons or soft exosuits. Rigid exoskeletons enhance stability and weight support through load-bearing frames and direct joint torque. Conversely, soft exosuits, devoid of rigid frames, utilize proximally positioned actuators and tendons to transmit forces to textile parts affixed to limbs, thereby enhancing adaptability and simplifying mechanics. To exploit the benefits of both, this study introduces a multi-joint hybrid-assisted device that combines a soft tendon-driven hip exosuit with a rigid pneumatic knee exoskeleton. The hip joint, featuring three active degrees of freedom, is assisted during the swing by the exosuit to minimize kinematic restrictions, mechanical complexity, and weight. The knee joint, with its single active degree of freedom, receives assistance during the stance from the rigid knee exoskeleton, pneumatically actuated, ensuring inherent knee compliance during load response. The study investigates the hybrid system’s impact on metabolic cost, muscle activity, and kinematics in four conditions (unassisted, hip-assisted, knee-assisted, and hybrid-assisted) with seven healthy subjects on an inclined treadmill (15° at 3 km/h). Findings indicate that hybrid assistance yields the greatest significant metabolic reductions, followed by hip assistance and knee-only assistance, with assisted muscles exhibiting significantly reduced activity and minimal impact on kinematics.},
  archive      = {J_TMRB},
  author       = {Luka Mišković and Enrica Tricomi and Xiaohui Zhang and Francesco Missiroli and Kristina Krstanović and Tadej Petrič and Lorenzo Masia},
  doi          = {10.1109/TMRB.2024.3421547},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1180-1189},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Hybrid rigid-soft and pneumatic-electromechanical exoskeleton for multi-joint lower limb assistance},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combining functional electrical stimulation (FES) to elicit
hand movements and a mechanical orthosis to passively maintain wrist and
fingers position in individuals with tetraplegia: A feasibility test.
<em>TMRB</em>, <em>6</em>(3), 1170–1179. (<a
href="https://doi.org/10.1109/TMRB.2024.3421667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have developed a new approach to assist prehension by combining functional electrical stimulation (FES) and a motorized orthosis: ORTHYB. The aim was to induce movements of fingers, thumb, and wrist joints by activating muscles using surface FES and locking joints in desired positions using electric motors, to reduce muscle fatigue and enable prolonged grasping of objects. Another hypothesis was that the mechanical orthosis would improve grip quality by constraining joint positioning and guiding movements. The functionality and acceptability of this hybrid orthosis were tested on five participants with upper-limb paralysis due to spinal cord injury. The evaluation was carried out by monitoring the quality of grip for 30 seconds on 3 different objects; perceived effort using the Borg RPE (Rating of Perceived Exertion) scale; pain using visual analog scale (VAS); acceptability using QUEST (Quebec User Evaluation of Satisfaction Technology with Assistive Technology) scale and SUS (System Usability Scale). Preliminary results indicate that the hybrid orthosis provides added value compared to FES alone. The scores obtained in terms of functionality were in most of the trials greater than or equal to those obtained with FES alone. Object grasping was possible for 30 seconds without muscular fatigue affecting grip quality.},
  archive      = {J_TMRB},
  author       = {Clément Trotobas and Fernanda M. Rodrigues Martins Ferreira and João Paulo Fernandes Bonfim and Maria Rosália de Faria Moraes and Adriana Maria Valladão Novais Van Pette and Henrique Resende Martins and Charles Fattal and Christine Azevedo Coste},
  doi          = {10.1109/TMRB.2024.3421667},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1170-1179},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Combining functional electrical stimulation (FES) to elicit hand movements and a mechanical orthosis to passively maintain wrist and fingers position in individuals with tetraplegia: A feasibility test},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the OTHER hand: A bilateral, reconfigurable hand
exoskeleton with opposable thumbs for use with upper limb exoskeletons.
<em>TMRB</em>, <em>6</em>(3), 1158–1169. (<a
href="https://doi.org/10.1109/TMRB.2024.3421513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to document the design of the OTHER Hand: a novel bilateral, reconfigurable, hand exoskeleton with opposable thumbs for use with upper limb exoskeletons. Intended for grasp research and rehabilitation with an emphasis on stroke, the OTHER Hand is designed as a one-size-fits-all system that can enable most of the common prehensile grasps and hand postures performed in activities of daily living. The capacity of the system to perform such grasps and postures is experimentally demonstrated by an average 94% normalized Grasping Ability Score across thirteen subjects using the Anthropomorphic Hand Assessment Protocol. This score demonstrates near-unhindered grasping performance for individuals without hand impairments wearing the OTHER Hand.},
  archive      = {J_TMRB},
  author       = {Peter Walker Ferguson and Jianwei Sun and Ji Ma and Joel Perry and Jacob Rosen},
  doi          = {10.1109/TMRB.2024.3421513},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1158-1169},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {On the OTHER hand: A bilateral, reconfigurable hand exoskeleton with opposable thumbs for use with upper limb exoskeletons},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of fatigue-induced compensatory movements in bicep
curls: Gaining insights for the deployment of wearable sensors.
<em>TMRB</em>, <em>6</em>(3), 1147–1157. (<a
href="https://doi.org/10.1109/TMRB.2024.3407239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common challenge in Bicep Curls rehabilitation is muscle compensation, where patients adopt alternative movement patterns when the primary muscle group cannot act due to injury or fatigue, significantly decreasing the effectiveness of rehabilitation efforts. The problem is exacerbated by the growing trend toward transitioning from in-clinic to home-based rehabilitation, where constant monitoring and correction by physiotherapists are limited. Developing wearable sensors capable of detecting muscle compensation becomes crucial to address this challenge. This study aims to gain insights into the optimal deployment of wearable sensors through a comprehensive study of muscle compensation in Bicep Curls. We collect upper limb joint kinematics and surface electromyography signals (sEMG) from eight muscles in 12 healthy subjects during standard and fatigue stages. Two muscle synergies are derived from sEMG signals and are analyzed comprehensively along with joint kinematics. Our findings reveal a shift in the relative contribution of forearm muscles to shoulder muscles, accompanied by a significant increase in activation amplitude for both synergies. Additionally, more pronounced movement was observed at the shoulder joint during fatigue. These results suggest focusing on the shoulder muscle activities and joint motions when deploying wearable sensors to effectively detect compensatory movements.},
  archive      = {J_TMRB},
  author       = {Ming Xuan Chua and Yoshiro Okubo and Shuhua Peng and Thanh Nho Do and Chun Hui Wang and Liao Wu},
  doi          = {10.1109/TMRB.2024.3407239},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1147-1157},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Analysis of fatigue-induced compensatory movements in bicep curls: Gaining insights for the deployment of wearable sensors},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wearable continuous gait phase estimation during walking,
running, turning, stairs, and over uneven terrain. <em>TMRB</em>,
<em>6</em>(3), 1135–1146. (<a
href="https://doi.org/10.1109/TMRB.2024.3407366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable continuous gait phase estimation is essential for walking assistance, clinical rehabilitation, and clinical assessment; however, most algorithms have only been validated for straight-line and constant-speed walking, and it is unclear how performance will change in real-life locomotion scenarios. A generalized paradigm is needed to comprehensively assess and recommend wearable continuous gait phase estimation strategies for the diverse array of walking situations. We thus propose a comprehensive evaluation indicator system for eight typical gait activities in daily life including slow walking, standard walking, running, walking with turns, stair descent, stair ascent, stop-and-go, and uneven terrain walking.The indicator system was used to evaluate four commonly used continuous gait phase estimation strategies: adaptive oscillators, phase oscillator, neural network, and time-based estimation. Eleven healthy participants were enrolled in the evaluation. All estimation strategies performed well for constant-speed walking but performance varied for other activities. Time-based estimation was most accurate for slowwalking ( $0.094~\pm ~0.011$ rad root mean square error, $1.50~\pm ~0.18$ % of one gait cycle), running ( $0.167~\pm ~0.028$ rad, $2.66~\pm ~0.44$ %) and walking with turns ( $0.124~\pm ~0.047$ rad, $2.00~\pm ~0.75$ %). Adaptive oscillators were most accurate for standard walking( $0.115~\pm ~0.037$ rad, $1.83~\pm ~0.59$ %). Phase oscillator was most accurate for stair climbing( $0.280~\pm ~0.063$ rad, $4.46~\pm ~1.00$ %) and uneven terrain ( $0.204~\pm ~0.069$ rad, $4.30~\pm ~1.10$ %). Neural network was most accurate for stop-and-go( $0.27~\pm ~0.114$ rad, $4.30~\pm ~1.81$ %). These results can potentially provide guidance for determining suitable gait phase estimation strategies in realistic locomotion scenarios, and in comparing and optimizing the current proposed strategies.},
  archive      = {J_TMRB},
  author       = {Linghui Xu and Yuting Chen and Bingfei Fan and Canjun Yang and Wei Yang},
  doi          = {10.1109/TMRB.2024.3407366},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1135-1146},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Wearable continuous gait phase estimation during walking, running, turning, stairs, and over uneven terrain},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A kinematically informed approach to near-future joint angle
estimation at the ankle. <em>TMRB</em>, <em>6</em>(3), 1125–1134. (<a
href="https://doi.org/10.1109/TMRB.2024.3408892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elevated runtimes of machine learning algorithms and neural networks make their inclusion in near-future joint angle estimation difficult. The purpose of this study was to develop simple, analytical models that prioritize historical joint kinematics when estimating near-future joint angles. Five kinematically-informed and extrapolation-based methods were developed for joint angle estimation at three near-future estimation horizons: $t_{pred} = 50$ ms, 75 ms, and 100 ms. The estimation error and required runtimes of each prediction algorithm were evaluated on the sagittal-plane ankle angles of 24 individual subjects who performed three level-ground walking trials. Results showed that the kinematically-informed models had significantly faster estimation runtimes than Random Forest (RF) machine learning models trained and tested on identical datasets (kinematic models: $t_{run}\lt 0.62$ ms, RF models: $t_{run}\gt 8.19$ ms for all estimation horizons). The RF models exhibited significantly lower prediction errors than the kinematic models for estimation horizons of $t_{pred} = 75$ ms and 100 ms, but no significance was found between the top-performing kinematic model and RF models for a $t_{pred} = 50$ ms. These results indicate that a kinematically-informed approach to joint angle estimation can serve as a simple alternative to complex machine learning models for very near-future applications ( $t_{pred} \leq 50$ ms) while serving as a comparison baseline for more distant estimation horizons ( $t_{pred} \geq 75$ ms).},
  archive      = {J_TMRB},
  author       = {Ryan S. Pollard and David S. Hollinger and Iván E. Nail-Ulloa and Michael E. Zabala},
  doi          = {10.1109/TMRB.2024.3408892},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1125-1134},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A kinematically informed approach to near-future joint angle estimation at the ankle},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward human-out-of-the-loop endoscope navigation based on
context awareness for enhanced autonomy in robotic surgery.
<em>TMRB</em>, <em>6</em>(3), 1116–1124. (<a
href="https://doi.org/10.1109/TMRB.2024.3422618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the da Vinci surgical system enhances manipulation dexterity and restores 3D vision in robotic surgery, it requires surgeons to asynchronously control surgical instruments and the endoscope, which hinders a smooth operation. Surgeons frequently position the endoscope to maintain a good field of view during operation, potentially increasing surgical time and workload. In this paper, a Human-Out-Of-The-Loop (HOOTL) endoscope navigation control with the assistance of context awareness is proposed to enhance surgical autonomy. A comprehensive comparison study using 8 state-of-the-art networks was conducted to find out the best model for surgical phase recognition. Ten human subjects were invited to participate in a classic ring transferring task based on three different endoscope navigation pipelines on a da Vinci research kit platform, including standard endoscope navigation, semi-autonomous endoscope navigation with manual pedal control, and HOOTL endoscope navigation supported by vision-based phase recognition. The experimental results showed that the proposed endoscope navigation approach releases the operation need of controlling the pedals, and it significantly reduces the execution time compared to the other two navigation pipelines. The result of the NASA Task Load Index (NASA-TLX) questionnaire indicates that the proposed endoscope navigation can reduce the physical and mental load for the users.},
  archive      = {J_TMRB},
  author       = {Ziyang Chen and Ke Fan and Laura Cruciani and Matteo Fontana and Lorenzo Muraglia and Francesco Ceci and Laura Travaini and Giancarlo Ferrigno and Elena De Momi},
  doi          = {10.1109/TMRB.2024.3422618},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1116-1124},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Toward human-out-of-the-loop endoscope navigation based on context awareness for enhanced autonomy in robotic surgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A digital twin-based large-area robot skin system for safer
human-centered healthcare robots toward healthcare 4.0. <em>TMRB</em>,
<em>6</em>(3), 1104–1115. (<a
href="https://doi.org/10.1109/TMRB.2024.3421635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fourth revolution of healthcare technologies, i.e., Healthcare 4.0, is putting robotics into human-dominated environments. In such a context, one of the main challenges is to develop human-centered robotics technologies that enable safe and reliable human-robot interaction toward human-robot symbiosis. Herein, robot skin is developed to endow healthcare robots with on-body proximity perception so as to fulfill the promise of safe and reliable robotic systems alongside humans. The sensing performance of the robot skin is evaluated by extensive experiments, providing important guidance on its effective implementation into a specific robot platform. Results show that the developed robot skin has a detection range of 0–50 mm, a maximum sensitivity of 0.7 pF/mm, a minimum resolution of 0.05 mm, a repeatability error of 6.6%, a hysteresis error of 7.1%, and bending durability of 2000 cycles. The robot skin is further customized and scaled up to form a large-area sensing system on the exterior of robot arms to support functional safety, which is experimentally validated by approaching distance monitoring and reactive collision avoidance. During the validation, the sensing feedback of the robot skin and the motion of the host robot are visualized remotely in the robot digital twin in a real-time manner via a cloud server. The cloud-based monitoring interface bridges the gap between local healthcare robots and remote professionals, illustrating promising applications where professionals monitor the robot state and intervene in challenging situations to provide instant support for emergent safety issues in human-robot interaction.},
  archive      = {J_TMRB},
  author       = {Geng Yang and Zhiqiu Ye and Haiteng Wu and Chen Li and Ruohan Wang and Depeng Kong and Zeyang Hou and Huafen Wang and Xiaoyan Huang and Zhibo Pang and Na Dong and Gaoyang Pang},
  doi          = {10.1109/TMRB.2024.3421635},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1104-1115},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A digital twin-based large-area robot skin system for safer human-centered healthcare robots toward healthcare 4.0},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label-free adaptive gaussian sample consensus framework for
learning from perfect and imperfect demonstrations. <em>TMRB</em>,
<em>6</em>(3), 1093–1103. (<a
href="https://doi.org/10.1109/TMRB.2024.3422652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous robotic surgery represents one of the most groundbreaking advancements in medical technology. Learning from human demonstrations is promising in this domain, which facilitates the transfer of skills from humans to robots. However, the practical application of this method is challenged by the difficulty of acquiring high-quality demonstrations. Surgical tasks often involve complex manipulations and stringent precision requirements, leading to frequent errors in the demonstrations. These imperfect demonstrations adversely affect the performance of controller policies learned from the data. Unlike existing methods that rely on extensive human labeling of demonstrated trajectories, we present a novel label-free adaptive Gaussian sample consensus framework to progressively refine the control policy. We demonstrate the efficacy and practicality of our approach through two experimental studies: a handwriting classification task, providing reproducible ground-truth labels for evaluation, and an endoscopy scanning task, demonstrating the feasibility of our method in a real-world clinical context. Both experiments highlight our method’s capacity to efficiently adapt to and learn from an ongoing stream of imperfect demonstrations.},
  archive      = {J_TMRB},
  author       = {Yi Hu and Zahra Samadikhoshkho and Jun Jin and Mahdi Tavakoli},
  doi          = {10.1109/TMRB.2024.3422652},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1093-1103},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Label-free adaptive gaussian sample consensus framework for learning from perfect and imperfect demonstrations},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Breach detection in spine surgery based on cutting torque.
<em>TMRB</em>, <em>6</em>(3), 1084–1092. (<a
href="https://doi.org/10.1109/TMRB.2024.3421543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate placement of pedicle screws is crucial for various spinal interventions, demanding precise geometric alignment while carrying inherent risks. Studies show that the rate of complications can reach up to 18% in case of imprecise placement of pedicle screws. To enhance the precision and safety of pedicle screw placement, we have developed a robotic system equipped with several sensors and paired with a breach detection algorithm capable of identifying potential breaches in the spinal canal. The breach detection algorithm was conceptualized through an analysis of the cutting torque of the drill system. An ex-vivo experiment was conducted to assess the effectiveness of the developed robotic solution and breach detection algorithm. The data (e.g., cutting torque, position, velocity, etc.) used during the validation were collected by drilling 80 pedicles in fresh porcine vertebrae. The results demonstrated that the proposed algorithm could predict breaches in 96.42% of cases, i.e., the distance between the detected point (drilling stop) and the point of the breach is within 2 mm. In a single instance, the detection occurred earlier than anticipated due to the trajectory being oriented significantly medially, resulting in an initial interaction with the cortical bone at an earlier point.},
  archive      = {J_TMRB},
  author       = {E. Saghbiny and L. Leblanc and A. Harlé and C. Bobbio and R. Vialle and G. Morel and B. Tamadazte},
  doi          = {10.1109/TMRB.2024.3421543},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1084-1092},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Breach detection in spine surgery based on cutting torque},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulation-based flexible needle control with single-core
FBG feedback for spinal injections. <em>TMRB</em>, <em>6</em>(3),
1073–1083. (<a href="https://doi.org/10.1109/TMRB.2024.3421630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective: We present a general framework of simultaneous needle shape reconstruction and control input generation for robot-assisted spinal injection procedures, without continuous imaging feedback. Methods: System input-output mapping is generated with a real-time needle-tissue interaction simulation, and single-core FBG sensor readings are used as local needle shape feedback within the same simulation framework. FBG wavelength shifts due to temperature variation is removed by exploiting redundancy in fiber arrangement. Results: Targeting experiments performed on both plastisol lumbar phantoms as well as an ex vivo porcine lumbar section achieved in-plane tip errors of $0.6 \pm 0.3$ mm and $1.6 \pm 0.9$ mm, and total tip errors of $0.9 \pm 0.7$ mm and $2.1 \pm 0.8$ mm for the two testing environments. Significance: Our clinically inspired control strategy and workflow is self-contained and not dependent on the modality of imaging guidance. The generalizability of the proposed approach can be applied to other needle-based interventions where medical imaging cannot be reliably utilized as part of a closed-loop control system for needle guidance.},
  archive      = {J_TMRB},
  author       = {Yanzhou Wang and Yangsheng Xu and Jiarong Kang and Jan Fritz and Iulian Iordachita},
  doi          = {10.1109/TMRB.2024.3421630},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1073-1083},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Simulation-based flexible needle control with single-core FBG feedback for spinal injections},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft robotic gastroscope for low/middle-income countries:
Design and preliminary validation. <em>TMRB</em>, <em>6</em>(3),
1063–1072. (<a href="https://doi.org/10.1109/TMRB.2024.3407364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce incidence and mortality, screening of the gastric cavity is crucial to diagnose early-stage cancers. Most cases are concentrated in low/middle-income countries (LMICs), where medical resources are limited. In this paper, we propose a miniaturized, disposable, and low-cost soft robotic gastroscope designed for screening in LMICs. The robotic platform is composed of i) a frontal soft-core module, ii) a flexible multi-lumen tether, and iii) an intuitive control handle, to provide a) a 180 deg bending angle, b) a 360 deg axial rotation, and c) linear movements with a 15 mm fine adjustment. Thanks to a single internal bending chamber, the diameter of the soft-core module and the tether are reduced to 7.2 mm and 4.3 mm, respectively. Mechanical performance, operational functionalities, and clinical dependability were successfully evaluated through in-vitro and ex-vivo experiments. In summary, given i) low-cost (i.e., ~25 USD), ii) low invasiveness, iii) high portability, and iv) intuitive control, the disposable soft gastroscope might have considerable clinical potential for widening gastric cancer screening in LMICs.},
  archive      = {J_TMRB},
  author       = {Xuyang Ren and Yu Huan and Martina Finocchiaro and Matteo Cianchetti and Giacomo Lo Secco and Shuxin Wang and Paolo Dario and Anastasios Koulaouzidis and Alberto Arezzo and Gastone Ciuti},
  doi          = {10.1109/TMRB.2024.3407364},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1063-1072},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Soft robotic gastroscope for Low/Middle-income countries: Design and preliminary validation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-based offline reinforcement learning for autonomous
delivery of guidewire. <em>TMRB</em>, <em>6</em>(3), 1054–1062. (<a
href="https://doi.org/10.1109/TMRB.2024.3407349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Guidewire delivery is a fundamental procedure in percutaneous coronary intervention. The inherent flexibility of the guidewire poses challenges in precise control, necessitating long-term training and substantial expertise. In response, this paper proposes a novel offline reinforcement learning (RL) algorithm, Conservative Offline Reinforcement Learning with Variational Environment Model (CORVE), for autonomous delivery of guidewire. CORVE first uses offline data to train an environment model and then optimizes the policy with both offline and model-generated data. The proposed method shares an encoder between the environmental model, policy, and Q-function, mitigating the common sample inefficiency in image-based RL. Besides, CORVE utilizes model prediction errors to forecast wrong deliveries in inference, which is an attribute absent in existing methods. The experimental results show that CORVE obtains superior performance in guidewire deliveries, achieving notably higher success rates and smoother movements than existing methods. These findings suggest that CORVE holds significant potential for enhancing the autonomy of vascular robotic systems in clinical settings.},
  archive      = {J_TMRB},
  author       = {Hao Li and Xiao-Hu Zhou and Xiao-Liang Xie and Shi-Qi Liu and Zhen-Qiu Feng and Mei-Jiang Gui and Tian-Yu Xiang and De-Xing Huang and Zeng-Guang Hou},
  doi          = {10.1109/TMRB.2024.3407349},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1054-1062},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Model-based offline reinforcement learning for autonomous delivery of guidewire},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A series-parallel hybrid pelvic fracture reduction surgical
robotic system based on novel 6-DOF force amplification mechanism.
<em>TMRB</em>, <em>6</em>(3), 1042–1053. (<a
href="https://doi.org/10.1109/TMRB.2024.3407370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot-assisted closed reduction surgery is recognized as the optimal approach for pelvic fractures. However, existing surgical robotic systems often lack the necessary output force to overcome soft tissue tension. To address this limitation, we propose a novel surgical robotic system to deliver high output force with required workspace. Our approach includes the design of a 6-DOF parallel mechanism that utilizes the lever principle for force amplification. The distribution laws of its effective workspace and force amplification gain coefficient are investigated. Additionally, a series-parallel hybrid surgical robot system is developed, which demonstrates the amplification effect on the output force through the force amplification mechanism. To ensure smooth operation of the system, a comprehensive surgical operation framework isdevised that encompasses target pose planning, reduction path planning, real-time intraoperative navigation and control. Modeling experiments show promising results, with an average reduction accuracy of 0.31 mm and 0.24° under no load, and 1.03 mm and 0.34° under loads ranging from 0N to 475N. These findings highlight the effectiveness of our proposed force amplification mechanism in achieving substantial output force amplification while alleviating the surgeon’s burden. Moreover, our robotic system demonstrates the capability to achieve precise pelvic fracture reduction, significantly enhancing surgical outcomes.},
  archive      = {J_TMRB},
  author       = {Qianxin Wang and Shaolin Lu and Pengyun Liu and Yuanyuan Yang and Qiong Wang and Bing Li and Shibo Cai and Lihai Zhang and Jianwei Zhang and Ying Hu},
  doi          = {10.1109/TMRB.2024.3407370},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1042-1053},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A series-parallel hybrid pelvic fracture reduction surgical robotic system based on novel 6-DOF force amplification mechanism},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ENeRF-SLAM: #A dense endoscopic SLAM with neural implicit
representation. <em>TMRB</em>, <em>6</em>(3), 1030–1041. (<a
href="https://doi.org/10.1109/TMRB.2024.3407369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative calculations of camera poses and dense anatomical reconstructions from endoscopic videos are essential for applications such as intraoperative navigation and robotic surgery automation. Prior studies on this task either overlook the unique characteristics of endoscopic scenes or produce reconstructions with numerous gaps due to limited observations, significantly limiting their practical application. Inspired by recent advancements in neural rendering, we develop a dense visual SLAM system that employs neural implicit representations, specifically designed for endoscopic sequences. By incorporating 3D geometric scene priors, our system effectively predicts and fills in unseen areas, ensuring the continuous and complete reconstruction of the scene. Taking into account the dynamic nature of the light source and the confined anatomy of the human body, we propose a neural implicit representation method designed for endoscopic scenes. Additionally, we introduce a hybrid tracking method that merges Gauss-Newton and gradient-based pose optimization, improving geometric consistency across frames. This reduces reliance on precise data matching and significantly enhances camera tracking accuracy. Extensive experiments on both synthetic and real medical endoscopic datasets demonstrate that our method outperforms existing systems in terms of scene reconstruction quality, camera tracking accuracy, and image rendering quality. Code is available at: https://github.com/Mar-lll/ENeRF-SLAM},
  archive      = {J_TMRB},
  author       = {Jiwei Shan and Yirui Li and Ting Xie and Hesheng Wang},
  doi          = {10.1109/TMRB.2024.3407369},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1030-1041},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {ENeRF-SLAM: #A dense endoscopic SLAM with neural implicit representation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Triple-supervised convolutional transformer aggregation for
robust monocular endoscopic dense depth estimation. <em>TMRB</em>,
<em>6</em>(3), 1017–1029. (<a
href="https://doi.org/10.1109/TMRB.2024.3407384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate deeply learned dense depth prediction remains a challenge to monocular vision reconstruction. Compared to monocular depth estimation from natural images, endoscopic dense depth prediction is even more challenging. While it is difficult to annotate endoscopic video data for supervised learning, endoscopic video images certainly suffer from illumination variations (limited lighting source, limited field of viewing, and specular highlight), smooth and textureless surfaces in surgical complex fields. This work explores a new deep learning framework of triple-supervised convolutional transformer aggregation (TSCTA) for monocular endoscopic dense depth recovery without annotating any data. Specifically, TSCTA creates convolutional transformer aggregation networks with a new hybrid encoder that combines dense convolution and scalable transformers to parallel extract local texture features and global spatial-temporal features, while it builds a local and global aggregation decoder to effectively aggregate global features and local features from coarse to fine. Moreover, we develop a self-supervised learning framework with triple supervision, which integrates minimum photometric consistency and depth consistency with sparse depth self-supervision to train our model by unannotated data. We evaluated TSCTA on unannotated monocular endoscopic images collected from various surgical procedures, with the experimental results showing that our methods can achieve more accurate depth range, more complete depth distribution, more sufficient textures, better qualitative and quantitative assessment results than state-of-the-art deeply learned monocular dense depth estimation methods.},
  archive      = {J_TMRB},
  author       = {Wenkang Fan and Wenjing Jiang and Hong Shi and Hui-Qing Zeng and Yinran Chen and Xiongbiao Luo},
  doi          = {10.1109/TMRB.2024.3407384},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1017-1029},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Triple-supervised convolutional transformer aggregation for robust monocular endoscopic dense depth estimation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine-learning-based multi-modal force estimation for
steerable ablation catheters. <em>TMRB</em>, <em>6</em>(3), 1004–1016.
(<a href="https://doi.org/10.1109/TMRB.2024.3407590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catheter-based cardiac ablation is a minimally invasive procedure for treating atrial fibrillation (AF). Electrophysiologists perform the procedure under image guidance during which the contact force between the heart tissue and the catheter tip determines the quality of lesions created. This paper describes a novel multi-modal contact force estimator based on Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). The estimator takes the shape and optical flow of the deflectable distal section as two modalities since frames and motion between frames complement each other to capture the long context in the video frames of the catheter. The angle between the tissue and the catheter tip is considered a complement of the extracted shape. The data acquisition platform measures the two-degrees-of-freedom contact force and video data as the catheter motion is constrained in the imaging plane. The images are captured via a camera that simulates single-view fluoroscopy for experimental purposes. In this sensor-free procedure, the features of the images and optical flow modalities are extracted through transfer learning. Long Short-Term Memory Networks (LSTMs) with a memory fusion network (MFN) are implemented to consider time dependency and hysteresis due to friction. The architecture integrates spatial and temporal networks. Late fusion with the concatenation of LSTMs, transformer decoders, and Gated Recurrent Units (GRUs) are implemented to verify the feasibility of the proposed network-based approach and its superiority over single-modality networks. The resulting mean absolute error, which accounted for only 2.84% of the total magnitude, was obtained by collecting data under more realistic circumstances in contrast to previous research studies. The decrease in error is considerably better than that achieved by individual modalities and late fusion with concatenation. These results emphasize the practicality and relevance of utilizing a multi-modal network in real-world scenarios.},
  archive      = {J_TMRB},
  author       = {Elaheh Arefinia and Jayender Jagadeesan and Rajni V. Patel},
  doi          = {10.1109/TMRB.2024.3407590},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {1004-1016},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Machine-learning-based multi-modal force estimation for steerable ablation catheters},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Low-profile 6-axis differential magnetic force/torque
sensing. <em>TMRB</em>, <em>6</em>(3), 992–1003. (<a
href="https://doi.org/10.1109/TMRB.2024.3407350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Force/torque sensing on hand-held tools enables control of applied forces, which is often essential in both tele-robotics and remote guidance of people. However, existing force sensors are either bulky, complex, or have insufficient load rating. This paper presents a novel 6 axis force-torque sensor based on differential magnetic field readings in a collection of low-profile sensor modules placed around a tool or device. The instrumentation is easy to install but nonetheless achieves good performance. A detailed mathematical model and optimization-based design procedure are also introduced. The modeling, simulation, and optimization of the force sensor are described and then used in the electrical and mechanical design and integration of the sensor into an ultrasound probe. Through a neural network-based nonlinear calibration, the sensor achieves average root-mean-square test errors of 0.41 N and 0.027 Nm compared to an off-the-shelf ATI Nano25 sensor, which are 0.80% and 1.16% of the full-scale range respectively. The sensor has an average noise power spectral density of less than 0.0001 N/ $\sqrt {\text {Hz}}$ , and a 95% confidence interval resolution of 0.0086 N and 0.063 Nmm. The practical readout rate is 1.3 kHz over USB serial and it can also operate over Bluetooth or Wi-Fi. This sensor can enable instrumentation of manual tools to improve the performance and transparency of teleoperated or autonomous systems.},
  archive      = {J_TMRB},
  author       = {David G. Black and Amir Hossein Hadi Hosseinabadi and Nicholas Rangga Pradnyawira and Mika Nogami and Septimu E. Salcudean},
  doi          = {10.1109/TMRB.2024.3407350},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {992-1003},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Low-profile 6-axis differential magnetic Force/Torque sensing},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Electromagnets under the table: An unobtrusive magnetic
navigation system for microsurgery. <em>TMRB</em>, <em>6</em>(3),
980–991. (<a href="https://doi.org/10.1109/TMRB.2024.3421249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Miniature magnetic tools have the potential to enable minimally invasive surgical techniques to be applied to space-restricted surgical procedures in areas such as neurosurgery. However, typical magnetic navigation systems, which create the magnetic fields to drive such tools, either cannot generate large enough fields, or surround the patient in a way that obstructs surgeon access to the patient. This paper introduces the design of a magnetic navigation system with eight electromagnets arranged completely under the operating table, to endow the system with maximal workspace accessibility, which allows the patient to lie down on the top surface of the system without any constraints. The found geometric layout of the electromagnets maximizes the field strength and uniformity over a reasonable neurosurgical operating volume. The system can generate non-uniform magnetic fields up to 38 mT along the x and y axes and 47 mT along the z axis at a working distance of 120 mm away from the actuation system workbench, deep enough to deploy magnetic microsurgical tools in the brain. The forces which can be exerted on millimeter-scale magnets used in prototype neurosurgical tools are validated experimentally. Due to its large workspace, this system could be used to control milli-robots in a variety of surgical applications.},
  archive      = {J_TMRB},
  author       = {Adam Schonewille and Changyan He and Cameron Forbrigger and Nancy Wu and James Drake and Thomas Looi and Eric Diller},
  doi          = {10.1109/TMRB.2024.3421249},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {980-991},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Electromagnets under the table: An unobtrusive magnetic navigation system for microsurgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CathSim: An open-source simulator for endovascular
intervention. <em>TMRB</em>, <em>6</em>(3), 971–979. (<a
href="https://doi.org/10.1109/TMRB.2024.3421256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous robots in endovascular operations have the potential to navigate circulatory systems safely and reliably while decreasing the susceptibility to human errors. However, there are numerous challenges involved with the process of training such robots, such as long training duration and safety issues arising from the interaction between the catheter and the aorta. Recently, endovascular simulators have been employed for medical training but generally do not conform to autonomous catheterization due to the lack of standardization and RL framework compliance. Furthermore, most current simulators are closed-source, which hinders the collaborative development of safe and reliable autonomous systems through shared learning and community-driven enhancements. In this work, we introduce CathSim, an open-source simulation environment that accelerates the development of machine learning algorithms for autonomous endovascular navigation. We first simulate the high-fidelity catheter and aorta with a state-of-the-art endovascular robot. We then provide the capability of real-time force sensing between the catheter and the aorta in simulation. Furthermore, we validate our simulator by conducting two different catheterization tasks using two popular reinforcement learning algorithms, namely SAC and PPO. The experimental results show that our open-source simulator can mimic the behavior of real-world endovascular robots and facilitate the development of different autonomous catheterization tasks. Our simulator is publicly available at https://github.com/airvlab/cathsim.},
  archive      = {J_TMRB},
  author       = {Tudor Jianu and Baoru Huang and Minh Nhat Vu and Mohamed E. M. K. Abdelaziz and Sebastiano Fichera and Chun-Yi Lee and Pierre Berthet-Rayne and Ferdinando Rodriguez y Baena and Anh Nguyen},
  doi          = {10.1109/TMRB.2024.3421256},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {971-979},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {CathSim: An open-source simulator for endovascular intervention},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pose-independent interaction distance adjustment for
magnetically driven robotic capsules. <em>TMRB</em>, <em>6</em>(3),
961–970. (<a href="https://doi.org/10.1109/TMRB.2024.3408324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safe capsule-colon interaction for magnetically driven robotic capsules is important in clinical applications. This work presents a solution based on the amplitude information of the magnetic field to adjust the distance between the interacting magnets, in order to prevent the magnetic forces exerted on the capsule robot and the pressure on the intestine walls from being overlarge, which may cause large deformation of the colon. As the first step, the geometry of the internal magnet embedded in the capsule is optimized to approach a near-spherical amplitude of the magnetic field based on the dipole model. Next, mathematical mapping from magnetic field amplitude to the interaction distance between the magnets is presented with constraint derivation and implementation. Then, a strategy to adjust the distance between the interacting magnets is provided based on the mapping using the magnetic field information. Finally, experiments are designed to validate the pose-independent interaction distance adjustment. Compared with the previous work, the proposed solution enables the quick interaction distance adjustment between the magnets to enhance the safety of capsule-colon interaction in the magnetically driven capsule endoscopies, since the interaction distance is derived straightforwardly from the magnetic field signals, without requiring the prerequisite implementation of capsule localization.},
  archive      = {J_TMRB},
  author       = {Guoqing Li and Jing Li and Gastone Ciuti and Paolo Dario and Qiang Huang},
  doi          = {10.1109/TMRB.2024.3408324},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {961-970},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Pose-independent interaction distance adjustment for magnetically driven robotic capsules},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A pneumatic driven MRI-guided robot system for prostate
interventions. <em>TMRB</em>, <em>6</em>(3), 951–960. (<a
href="https://doi.org/10.1109/TMRB.2024.3389490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the guidance of high-resolution Magnetic Resonance Imaging (MRI), robotic devices offer a great advantage for prostate intervention. This paper presents an MR-safe robot, where a needle is attached to the needle guide to obtain prostate biopsies during surgeries. The robot is powered by three actuators, two of them are customized to function as a work plane that allows the needle to move horizontally and vertically, and the third actuator controls the rotation of the work plane, allowing the needle to be inserted into the prostate from different directions. All the actuators are pneumatically actuated to allow them to work in a Magnetic Resonance (MR) environment. The kinematics and mechanism of the robot are analyzed. A user interface developed using LabView is created to calculate the target position and generate a control signal for the valves. In the open-air test, the needle can reach the target with an accuracy of 1.3 mm. The signal-to-noise ratio (SNR) variation was measured below 5% under a 3T MR scanner.},
  archive      = {J_TMRB},
  author       = {Haipeng Liang and Wanli Zuo and Dimitri Kessler and Tristan Barrett and Zion Tsz Ho Tse},
  doi          = {10.1109/TMRB.2024.3389490},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {951-960},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A pneumatic driven MRI-guided robot system for prostate interventions},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design and evaluation for a soft intra-abdominal wireless
laparoscope. <em>TMRB</em>, <em>6</em>(3), 940–950. (<a
href="https://doi.org/10.1109/TMRB.2024.3391048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In single-incision laparoscopic surgery (SILS), magnetic anchoring and guidance system (MAGS) is a promising technique to prevent clutter in the surgical workspace and provide a larger vision field. Existing camera designs mainly rely on a rigid structure and sliding motion, which may cause stress concentration and tissue damage on curved abdominal walls. Meanwhile, the insertion procedure is also challenging. In this paper, we proposed a wireless MAGS consisting of soft material and wheel structure design. The camera can passively bend and adapt to the curved tissue surface to relieve stress concentration. The wheel structure transfers the sliding motion to rolling motion when the camera tilts and translates, avoiding tissue rupture due to dry friction and facilitating smooth motion. The experiments show the novel laparoscope has dexterous locomotion and bendability with 20° in bending angle and $16.4mm$ in displacement. The maximum stress is reduced by 64% compared with rigid designs. An easy and safe insertion procedure based on soft property is also introduced, which takes less than 2 minutes on average without the assistance of additional instruments.},
  archive      = {J_TMRB},
  author       = {Hui Liu and Ning Li and Shuai Li and Gregory J. Mancini and Jindong Tan},
  doi          = {10.1109/TMRB.2024.3391048},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {940-950},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Design and evaluation for a soft intra-abdominal wireless laparoscope},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of proprioceptive feedback strategies for
upper-limb myoelectric prostheses. <em>TMRB</em>, <em>6</em>(3),
930–939. (<a href="https://doi.org/10.1109/TMRB.2024.3407532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Upper extremity prostheses have seen significant technological advances in recent years, primarily with the advent of myoelectric prostheses and other designs incorporating mechatronic elements. Although they do not replicate the functionality of the natural hand, users now have a way of communicating their movement intentions to the prosthesis. However, the lack of physiological feedback from the device to the user can hinder proper integration of the prosthesis, and can be a contributing factor in the rejection of the technology. This is why experts point out that sensory feedback is one of the main missing features of commercial prostheses. The literature surrounding the restoration of somatosensation primarily discusses strategies to emulate tactile perception, but few address proprioceptive perception, which is the ability to perceive limb position and movement. Yet, proprioception has been shown to be a crucial element in object manipulation. This article offers an in-depth look into the literature surrounding proprioceptive perception restoration strategies for users of upper limb prostheses by identifying and comparing the documented strategies in relation to the concept of an optimal sensory feedback restoration device.},
  archive      = {J_TMRB},
  author       = {Olivier Lecompte and Sofiane Achiche and Abolfazl Mohebbi},
  doi          = {10.1109/TMRB.2024.3407532},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {930-939},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A review of proprioceptive feedback strategies for upper-limb myoelectric prostheses},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancements in soft wearable robots: A systematic review of
actuation mechanisms and physical interfaces. <em>TMRB</em>,
<em>6</em>(3), 903–929. (<a
href="https://doi.org/10.1109/TMRB.2024.3407374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft actuators and robotic devices designed for rehabilitation and assistance are a rapidly growing field of research. Their inherent flexibility enhances comfort and usability without restricting the user’s natural range of motion. However, despite these advantages, there are still several challenges that need to be addressed before these systems can be commercialized. This paper presents a comprehensive review of the latest developments in soft wearable robots, also known as exosuits. Soft exosuits are composed of two main components: actuation mechanisms (how forces/torques are generated) and physical interfaces (how and where the robot is anchored to the body). This paper reviews the advances in these two areas, while categorizing exosuits based on the intended assisted joint, assisted degrees of freedom (DOF), and device type. The systematic literature review follows the PRISMA guidelines to summarize the relevant studies and investigate their related physical interface, actuation mechanism and its design. Several limitations were identified in these areas, and insights into potential future research directions are presented. In the future, the goal should be to develop an untethered assistive device that can provide assistance to multiple joints while having a low form factor, an intuitive and natural interface, and being comfortable for the user.},
  archive      = {J_TMRB},
  author       = {Sajjad Hussain and Fanny Ficuciello},
  doi          = {10.1109/TMRB.2024.3407374},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {903-929},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Advancements in soft wearable robots: A systematic review of actuation mechanisms and physical interfaces},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Technologies for the automation of anatomic pathology
processes: A review. <em>TMRB</em>, <em>6</em>(3), 888–902. (<a
href="https://doi.org/10.1109/TMRB.2024.3421611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the primary roles of an anatomic pathology laboratory (APL) is the identification of tissue abnormalities, which is crucial for diagnosing diseases and defining a suitable therapy. To date, a considerable number of human errors and artifacts affect the APL test cycle in all its phases (pre-analytical, intra-analytical, analytical, and post-analytical), mainly due to manual and non-standardized procedures. An extensive use of technologies (among which robotic ones) aimed at favoring laboratory automation procedures, would be key in decreasing these errors and their clinical consequences. However, several improvements in workflow, technology and standardization still need to occur. In this review, we discuss the current level of automation currently available in the APL histopathologic production workflow in all phases of the test cycle, highlighting the legal and ethical issues related to their adoption.},
  archive      = {J_TMRB},
  author       = {Sabrina Ciancia and Lorenzo Vannozzi and Aliria Poliziani and Lorena Guachi-Guachi and Denise Amram and Dario Lunni and Alessandra Zucca and Marco Bellini and Luigi Spagnoli and Gian Andrea Pedrazzini and Andrea Cavazzana and Leonardo Ricotti},
  doi          = {10.1109/TMRB.2024.3421611},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {888-902},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Technologies for the automation of anatomic pathology processes: A review},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of force sensing techniques for robot-assisted
laparoscopic surgery: A review. <em>TMRB</em>, <em>6</em>(3), 868–887.
(<a href="https://doi.org/10.1109/TMRB.2024.3407238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot-assisted laparoscopic surgery (RALS) has been widely investigated and developed as a routine and preferred minimally invasive surgery (MIS) because of enhanced operational precision and dexterity, improved visualization, and reduced surgeon stress and fatigue. However, the lack of force feedback poses challenges to accurate interaction force perception, lowered surgical errors, improved patient safety, and upgraded surgical outcomes. The solutions to force sensing can empower surgeons with a more intuitive and natural surgical experience with accurate perception capacity of interaction forces, efficient motor skill acquisition, enhanced surgical quality, and support the development of high-level techniques for surgical intelligence and autonomy. Although extensive research has been investigated in this field, effective and solid solutions are still unavailable for actual surgical scenarios. This review provides a comprehensive investigation from starting implementations to recent advances in emerging techniques for physical force sensors in laparoscopic surgery and RALS and focuses on the following categories: strain gauge-based, capacitive-based, and optical fiber-based principles. The design of force-sensitive structures from the mechanism perspective has been emphasized to provide possible and valuable design guidance for force sensor implementations with expected performance. Merits and limitations of existing technologies and prospects of new technologies are also discussed.},
  archive      = {J_TMRB},
  author       = {Yupeng Hao and Han Zhang and Zhiqiang Zhang and Chengzhi Hu and Chaoyang Shi},
  doi          = {10.1109/TMRB.2024.3407238},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {868-887},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Development of force sensing techniques for robot-assisted laparoscopic surgery: A review},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robotics application in dentistry: A review. <em>TMRB</em>,
<em>6</em>(3), 851–867. (<a
href="https://doi.org/10.1109/TMRB.2024.3408321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital dentistry and afterwards intelligent dentistry have been considered a trend in the development of both dental research and clinical practice. Robotics enhances precision and efficiency in medicine. In particular, robotics in dentistry is revolutionizing patient care with advanced technological integration, minimally invasive procedures, and improved outcomes and patient experiences. This review presents an in-depth concept of robots in digital dentistry, highlighting major contributions and impact in clinical scenarios. We first present the motivation behind dental robots and then will discuss the limitations and gaps between the research and applications of dental robots in different fields of dentistry. These robots are clinically involved in oral and maxillofacial surgery, dental implants, prosthodontics, orthognathic surgery, endodontics, and dental education treatments. The literature suggest that these robots are efficient, making quick decision, and maximize the benefit of digital dentistry. It fully automate the surgical procedure for diagnostic and treatment system. By integrating Artificial Intelligence (AI) to these robots eliminates the clinical decision making approach for predictive analysis for early detection and prevention. Finally, the key technologies and potential developments in robotics across various fields of dentistry were demonstrated. It is also discussed carefully how aspects such as mechanical design, recognition sensors, manipulation planning, and state monitoring can significantly influence the future impact of dental robots. These components play a crucial role in enhancing the functionality and efficiency of dental robotics, paving the way for advanced dental care. This review paper will enable researchers to gain better understanding of current status, challenges and future directions of dental robots.},
  archive      = {J_TMRB},
  author       = {Zeyang Xia and Faizan Ahmad and Hao Deng and Lin Jiang and Wenlong Qin and Qunfei Zhao and Jing Xiong},
  doi          = {10.1109/TMRB.2024.3408321},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {851-867},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Robotics application in dentistry: A review},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semi-autonomous control mode for flexible steerable
intraluminal platforms. <em>TMRB</em>, <em>6</em>(3), 839–850. (<a
href="https://doi.org/10.1109/TMRB.2024.3385990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible steerable intraluminal robot platforms allow treatment and screening of colorectal cancer at an early stage, potentially reducing the associated incidence and mortality rates. Such robotic platforms often rely on a tree-like flexible architecture, with a flexible robotized body carrying both the endoscope camera and two robotized flexible surgical arms at its distal end. Telemanipulating these robotic platforms to correctly perform surgical tasks is technically difficult due to their kinematic complexity and the demanding nature of the task, which leads to potential interruptions in the surgical workflow. In this paper, a technique to efficiently control the arms and body and correctly perform complex surgical steps during the endoscopic submucosal dissection procedure is proposed. The technique, referred to as semi-autonomous arm-body control, is based on a quadratic programming controller. Custom-defined tasks synergistically control the arms and body, while avoiding unsafe positions for the arms. Experiments in a mixed physical-simulated setup with eight users show an increased performance on the task and smoother movements compared to manual telemanipulation, at the expense of a slightly longer operating time. Further study will look at validating the approach in more realistic scenarios.},
  archive      = {J_TMRB},
  author       = {Fernando Gonzalez-Herrera and Florent Nageotte and Philippe Zanne and Gianni Borghesan and Michel de Mathelin and Emmanuel Vander Poorten and Benoit Rosa},
  doi          = {10.1109/TMRB.2024.3385990},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {839-850},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A semi-autonomous control mode for flexible steerable intraluminal platforms},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-sensorization approach to improve safety in
transesophageal echocardiography. <em>TMRB</em>, <em>6</em>(3), 829–838.
(<a href="https://doi.org/10.1109/TMRB.2024.3407378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time 3D transesophageal echocardiography (RT-3D TEE) allows 3D visualization of patient heart and catheters without exposing patient and operators to ionizing radiations. Nonetheless, during such procedures esophageal injuries occur due to improper probe manipulation and probe overheating. To tackle these problems, we propose a multisensorization approach to provide information on probe pose and temperature throughout the procedure. Electromagnetic (EM) tracking is fused with inertial sensing thanks to a finite state machine integrating Extended and Incremental Kalman filters. This approach allows for a statistically significant improvement in static tracking with respect to standard EM, as reported by the Mann-Withney test. A novel sensor fault detection based on angular velocities discrepancy allows for robust tracking under different electromagnetic interferences, such as the one provided by ferro-, dia- and paramagnetic materials occupying the interventional room. Fiber optic technology is exploited for temperature estimation, taking advantage of its immunity to EM fields and the possibility of distributed sensing. Performances are compared with a commercial thermistor to guarantee feasibility and a root mean square error of $1.59~^{\circ }$ C is finally reported. We believe that these results demonstrate how sensing technologies can be integrated in TEE-guided surgical procedures to improve overall outcome and safety.},
  archive      = {J_TMRB},
  author       = {Giovanni Faoro and Izadyar Tamadon and Selene Tognarelli and Arianna Menciassi},
  doi          = {10.1109/TMRB.2024.3407378},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {829-838},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A multi-sensorization approach to improve safety in transesophageal echocardiography},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ultrasound-based robot-assisted drilling for minimally
invasive pedicle screw placement. <em>TMRB</em>, <em>6</em>(3), 818–828.
(<a href="https://doi.org/10.1109/TMRB.2024.3385793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimally invasive pedicle screw placement (MIPSP) is a widely used treatment for spine diseases. When coupled with intraoperative navigation modalities, robots may help improve surgical outcomes and reduce complications. With such a system, the application of pedicle screws has been expanded from needle insertion to the spine surgery. This paper investigates the possibility and feasibility of robot-assisted MIPSP based on ultrasound (US) guidance. The proposed system is non-radiative and fiducial-free, using purely image information to close the registration loop. Then the system automatically positions the drill tip to a planned screw trajectory and executes the drilling operation. Experiments were conducted on both ex-vivo lamb and human cadaver spines. An entry point accuracy of $2.39\pm 1.41$ mm, and orientation accuracy of $2.82\pm 1.85^{\circ }$ was found for 24 drilled trajectories on three lamb spines. On the ex-vivo human spine, the position error averaged $3.08\pm 2.43$ mm at the entry point and $4.05\pm 2.62$ mm at the stop point across 16 drilling instances. Moreover, a $87.5\%$ success rate was reported by using Gertzbein-Robbins grade. The experimental results demonstrate the potential for offering a radiation-free alternative. Although restricted to cadaver trials, this work encourages further exploration of this technology to assist surgeons in maximizing performance in clinical practice.},
  archive      = {J_TMRB},
  author       = {Ruixuan Li and Ayoob Davoodi and Maikel Timmermans and Kaat Van Assche and Orçun Taylan and Lennart Scheys and Matthias Tummers and Gianni Borghesan and Emmanuel Vander Poorten},
  doi          = {10.1109/TMRB.2024.3385793},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {818-828},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Ultrasound-based robot-assisted drilling for minimally invasive pedicle screw placement},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robotic ultrasound-guided instrument localization in
fetoscopy. <em>TMRB</em>, <em>6</em>(3), 806–817. (<a
href="https://doi.org/10.1109/TMRB.2024.3407330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fetoscopic Endoluminal Tracheal Occlusion (FETO) is a minimally invasive fetal surgery (MIFS) aimed at mitigating the effects of Congenital Diaphragmatic Hernia (CDH). During FETO, a latex balloon is introduced in the fetal trachea using a fetoscope. Typically, this surgery is performed under ultrasound guidance which is provided by a sonographer who manually operates the ultrasound probe. This manual operation imposes a considerable physical and cognitive demand, placing a burden on the sonographer. This paper proposes a robotic ultrasound-based instrument tracking system that automates the probe position control while ensuring continuous visibility of the fetoscope in ultrasound images. The development of the proposed system is achieved with the completion of two tasks. Firstly, a series of fetoscope localization algorithms are developed and compared. Secondly, a task-based control for a robotic ultrasound system is developed. The localization algorithms’ performance is evaluated on annotated ultrasound datasets. The OEU-Net algorithm is selected based on this evaluation and is implemented in the instrument tracking system. The performance assessment of the tracking system shows that it is capable of tracking the fetoscope with a mean error below 4 mm. Thus, the developed system represents a significant advancement toward automatic robotic assistance for ultrasound guidance during FETO.},
  archive      = {J_TMRB},
  author       = {Daniel Costa and Gianni Borghesan and Mouloud Ourak and António Pedro Aguiar and Yuyu Cai and Emmanuel Vander Poorten},
  doi          = {10.1109/TMRB.2024.3407330},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {806-817},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Robotic ultrasound-guided instrument localization in fetoscopy},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of a robotic ultrasound system to assist
ultrasound examination of pregnant women. <em>TMRB</em>, <em>6</em>(3),
796–805. (<a href="https://doi.org/10.1109/TMRB.2024.3387047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research paper centers on addressing a common issue faced by clinicians during ultrasound examinations, namely work-related musculoskeletal disorders (WRMSDs). The implementation of robotic ultrasound has the potential to reduce these disorders using teleoperated assistance, collaborative support, or even autonomous systems. In this study, we introduce a new collaborative assisting system specifically designed for ultrasound examinations involving pregnant, obese patients. The primary objective is to devise a transparent co-manipulation strategy that enables clinicians to maintain their natural gestures during the procedure. The key principle behind this approach is to ensure that the robot functions as a helpful tool without interfering with the examination process. To achieve this, a novel co-manipulation control strategy is developed, which involves the computation of a virtual solid’s path based on the operator’s interaction. This approach presents numerous benefits in comparison to conventional control techniques. It demonstrates improvements in terms of accuracy, diminishes task execution time, facilitates a more intuitive parameter adjustment process, and necessitates less exertion of force by the operator. Consequently, it could potentially serve as a viable solution for addressing the challenges faced by sonographers. Hence, the potential benefit of this new co-manipulation method is demonstrated experimentally by comparison with impedance and active compliance control strategies.},
  archive      = {J_TMRB},
  author       = {Maria Bamaarouf and Flavien Paccot and Laurent Sarry and Hélène Chanal},
  doi          = {10.1109/TMRB.2024.3387047},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {796-805},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Development of a robotic ultrasound system to assist ultrasound examination of pregnant women},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Experimental assessment of positioning precision during
free-hand and robot-assisted tool manipulation in transoral microsurgery
model. <em>TMRB</em>, <em>6</em>(3), 787–795. (<a
href="https://doi.org/10.1109/TMRB.2024.3421596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transoral laser microsurgery (TLM) is a vocal cord cancer treatment where surgical tools reach the targeted region through the mouth. A robot-assisted system could aid in such operation yet there is limited understanding of the precision that is reachable at the level of the vocal folds. Therefore, this paper analyzed the baseline of human tool positioning capability during simulated TLM. In a simulated TLM environment, 31 participants navigated a probe to reach the target region of variable diameter ranging from 2.0 mm to 0.1 mm. The total execution time and the number of incorrect contacts were recorded. To assess the positioning potential under robotic assistance, 5 volunteers conducted the same tasks with the help of a co-manipulation robot. The minimum target diameter humans can precisely achieve at the vocal fold is 1.5 mm (time: mean ${=} \,\, 13$ .92 s, SD ${=} \,\, 12$ .30 s, incorrect contact: mean ${=} \,\, 2.71$ , SD ${=} \,\, 4.53$ ) while with the co-manipulation system, the precision can be improved to 0.2 mm (time: mean ${=} \,\, 21$ .20 s, SD ${=} \,\, 12$ .31 s, incorrect contact: mean ${=} \,\, 3.84$ , SD ${=} \,\, 2.95$ ). The experiments successfully established a baseline for free-hand precision reachable at the vocal fold and potential improvement through robot assistance.},
  archive      = {J_TMRB},
  author       = {Sukrit Prasarnkleo and Jeroen Meulemans and Mouloud Ourak and Leonardo S. Mattos and Vincent Vander Poorten and Emmanuel Vander Poorten},
  doi          = {10.1109/TMRB.2024.3421596},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {787-795},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Experimental assessment of positioning precision during free-hand and robot-assisted tool manipulation in transoral microsurgery model},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guest editorial joining efforts moving faster in surgical
robotics. <em>TMRB</em>, <em>6</em>(3), 784–786. (<a
href="https://doi.org/10.1109/TMRB.2024.3426732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The IEEE Transactions on Medical Robotics and Bionics (T-MRB) is an initiative shared by the two IEEE Societies of Robotics and Automation – RAS – and Engineering in Medicine and Biology – EMBS.},
  archive      = {J_TMRB},
  author       = {Emmanuel Vander Poorten and Leonardo S. Mattos and Guillaume Morel and Paolo Fiorini and Alicia Casals and Arianna Menciassi},
  doi          = {10.1109/TMRB.2024.3426732},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {8},
  number       = {3},
  pages        = {784-786},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Guest editorial joining efforts moving faster in surgical robotics},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prognosis of tissue stiffness through multilayer perceptron
technique with adaptive learning rate in minimal invasive surgical
procedures. <em>TMRB</em>, <em>6</em>(2), 769–781. (<a
href="https://doi.org/10.1109/TMRB.2024.3377371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible needles are navigated through anatomical pathways to reach deep seated tissues for minimally invasive surgical procedures. During such risky navigation, anatomical obstacles and the target malignant tissue regions could be dislodged due to excessive stress upon needle-tissue interaction. Hence, knowledge about the interactive forces is essential to execute a safe needle steering procedure during percutaneous cancerous treatments. This paper proposes an adaptive learning rate based multilayer perceptron technique for determining Young’s modulus of tissue at each stage of navigation and then utilizing this value to predict the deflection of flexible needle in tissue environment. To validate the accuracy of predictions, an energy-based model is incorporated into the analysis. Simulation results demonstrate that the proposed model can efficiently predict Young’s modulus in just 0.59 secs. To further validate the efficacy of this novel methodology, extensive experimental studies are conducted, including rigorous statistical analysis using ANOVA with a 5% accuracy level. The effectiveness of neural networks is underscored through a two-sample t-test across 5 different trials, revealing consistently low mean absolute errors, typically below 1.5 kPa, except in trial 3. These findings highlight the reliability of the proposed novel technique in predicting Young’s modulus and ensuring accurate needle deflection predictions.},
  archive      = {J_TMRB},
  author       = {Bulbul Behera and M. Felix Orlando and R. S. Anand},
  doi          = {10.1109/TMRB.2024.3377371},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {769-781},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Prognosis of tissue stiffness through multilayer perceptron technique with adaptive learning rate in minimal invasive surgical procedures},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Investigating the benefits of multivariable proprioceptive
feedback for upper-limb prostheses. <em>TMRB</em>, <em>6</em>(2),
757–768. (<a href="https://doi.org/10.1109/TMRB.2024.3385983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restoration of somatosensory feedback can improve prosthesis control and user experience. Although modern prosthesis allows movement in multiple degrees of freedom, few studies have attempted to restore multiple proprioceptive feedback variables to give the user awareness of the prosthesis state without excessive visual attention. This study presents and evaluates a feedback system containing four vibration motors embedded in the prosthesis socket to convey hand aperture or wrist rotation angle during sequential prosthesis control. Ten able-bodied and two amputee subjects performed a functional task that involved manipulating fragile objects with varying compliance (with vibrotactile and/or visual or neither). The results indicated that for able-bodied subjects, vibrotactile feedback alone allowed the grasping and rotation with almost the same quality as with visual feedback (no statistically significant difference). In addition, vibrotactile feedback significantly outperformed incidental feedback during wrist rotation control. Similar findings were observed for the amputee subjects. All subjects rated vibrotactile feedback as useful, reliable, and easy to perceive and exploit. Exploiting the vibrotactile feedback, however, required more time than for visual feedback. In conclusion, the proposed feedback system represents an efficient and practical solution to facilitate object manipulation in multiple degrees of freedom, even when visual feedback is not fully available.},
  archive      = {J_TMRB},
  author       = {Jakob Dideriksen and Eleonore Siebold and Strahinja Dosen and Marko Markovic},
  doi          = {10.1109/TMRB.2024.3385983},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {757-768},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Investigating the benefits of multivariable proprioceptive feedback for upper-limb prostheses},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FEEBY: A flexible framework for fast prototyping and
assessment of vibrotactile feedback for hand prostheses. <em>TMRB</em>,
<em>6</em>(2), 746–756. (<a
href="https://doi.org/10.1109/TMRB.2024.3385790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing a myoelectric prosthesis with artificial somatosensory feedback is important for providing a complete bionic replacement. The development of feedback comprises several steps, from the selection of stimulation interface, variables, and encoding schemes to testing in non-disabled and amputee subjects. In most cases, specific configurations are implemented and tested. To support a more flexible approach to the development of feedback, where an interface can be iteratively tested and gradually refined, we developed FEEBY - a software and hardware framework for fast prototyping and assessment of feedback both in and out of the lab. FEEBY comprises a PC application for feedback design and subject training, an embedded system for clinical testing, and a smaller version of the system for home use. The system capabilities and the feedback design process were demonstrated by conducting illustrative experiments on 6 non-disabled participants and 1 transradial amputee, who also used the system at home. The results of the present study demonstrated that FEEBY is a compact, low-power, and robust system that can enable the systematic development of feedback and its assessment in ecological conditions. The latter aspect is particularly important to reach the ultimate goal, i.e., a feedback system that matters in daily life.},
  archive      = {J_TMRB},
  author       = {Nikolina Maravic and Strahinja Dosen and Filip Gasparic and Christian Hofer and Michael Russold and Mario Koppe and Jose Gonzalez-Vargas and Nikola Jorgovanovic and Darko Stanisic},
  doi          = {10.1109/TMRB.2024.3385790},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {746-756},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {FEEBY: A flexible framework for fast prototyping and assessment of vibrotactile feedback for hand prostheses},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A mechatronic thumb for grasping and in-hand manipulation
tasks. <em>TMRB</em>, <em>6</em>(2), 733–745. (<a
href="https://doi.org/10.1109/TMRB.2024.3369762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the design, kinematic modeling, and control of a wearable mechatronic thumb device, which is intended to seamlessly integrate with the human hand. The device exhibits lightweight construction, portability, robustness, and safety during use. Initially, we describe the mechanical design of the thumb and an accompanying custom-made data glove that is utilized as a user interface. The kinematic analysis of the mechatronic thumb in conjunction with the human hand is then derived. We subsequently propose intuitive control methods to effectively oppose and coordinate the mechatronic thumb with the remaining fingers, so as to facilitate tasks such as envelope or precision tip grasping, as well as in-hand object manipulation. The potential of the proposed mechatronic thumb to compensate for thumb loss or disability is demonstrated through a series of experiments involving stable grasp and in-hand manipulation tasks of various objects. Grasp quality measures are utilized to assess the experimental results, focusing on the cooperative grasp of the designed mechatronic thumb and the other fingers, in comparison to a non-impaired human hand.},
  archive      = {J_TMRB},
  author       = {John Fasoulas and Michael Sfakiotakis and Vasileios Bekas},
  doi          = {10.1109/TMRB.2024.3369762},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {733-745},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A mechatronic thumb for grasping and in-hand manipulation tasks},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft wrist exosuit actuated by fabric pneumatic artificial
muscles. <em>TMRB</em>, <em>6</em>(2), 718–732. (<a
href="https://doi.org/10.1109/TMRB.2024.3385795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, soft actuator-based exosuits have gained interest, due to their high strength-to-weight ratio, inherent safety, and low cost. We present a novel wrist exosuit actuated by fabric pneumatic artificial muscles that has lightweight wearable components (160 g) and can move the wrist in flexion/extension and ulnar/radial deviation. We derive a model representing the torque exerted by the exosuit and demonstrate the use of the model to choose an optimal design for an example user. We evaluate the accuracy of the model by measuring the exosuit torques throughout the full range of wrist flexion/extension. We show the importance of accounting for the displacement of the mounting points, as this helps to achieve the smallest mean absolute error (0.283 Nm) compared to other models. Furthermore, we present the measurement of the exosuit-actuated range of motion on a passive human wrist. Finally, we demonstrate the device controlling the passive human wrist to move to a desired orientation along a one and a two-degree-of-freedom trajectory. The evaluation results show that, compared to other pneumatically actuated wrist exosuits, the presented exosuit is lightweight and strong (with peak torque of 3.3 Nm) but has a limited range of motion.},
  archive      = {J_TMRB},
  author       = {Katalin Schäffer and Yasemin Ozkan-Aydin and Margaret M. Coad},
  doi          = {10.1109/TMRB.2024.3385795},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {718-732},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Soft wrist exosuit actuated by fabric pneumatic artificial muscles},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transradial amputee reaching: Compensatory motion
quantification versus unaffected individuals including bracing.
<em>TMRB</em>, <em>6</em>(2), 706–717. (<a
href="https://doi.org/10.1109/TMRB.2024.3381339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint absence in people with upper-limb-difference leads to compensatory motions. Such compensation has long been a topic of study, but typically only for a single object/user layout, which is unlikely to spatially generalize. We seek to understand how motion varies over a planar workspace for different target orientations and wrist mobility conditions. We therefore present a study that records arm and torso pose during grasping of 49 equally spaced cylindrical targets. Furthermore, we seek to validate the research practice of using wrist-immobilizing bypass sockets on able-bodied participants to simulate prostheses without wrists. Participants were 2 transradial amputees and 7 able-bodied individuals who conducted the study with and without wrist braces, generating 2450 trajectories. Heat-maps illustrate variation over the workspace in Mean Joint Angle, Range of Joint Motion and Distance Travelled by Body Segment. Results indicate that greater wrist restriction primarily exacerbated shoulder internal rotation and elbow flexion, not the trunk. We observed that bypass sockets do not fully simulate amputee behavior. Furthermore, amputee reaching with their intact limb is different to the reaching motion of normative participants, implying that transradial limb-difference affects both sides of the body. Differences in participant behavior were also observed between horizontal and vertical target orientations.},
  archive      = {J_TMRB},
  author       = {Adam J. Spiers and Yuri Gloumakov and Aaron M. Dollar},
  doi          = {10.1109/TMRB.2024.3381339},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {706-717},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Transradial amputee reaching: Compensatory motion quantification versus unaffected individuals including bracing},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A data-driven fuzzy logic method for psychophysiological
assessment: An application to exoskeleton-assisted walking.
<em>TMRB</em>, <em>6</em>(2), 695–705. (<a
href="https://doi.org/10.1109/TMRB.2024.3377453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal physiological monitoring and related estimation of the PsychoPhysiological (PP) state play an essential role in investigating the physical and cognitive workload of people executing a motor task. The aim of this work was to develop a data-driven Fuzzy Logic method to estimate four PP indicators, i.e., Energy Expenditure, Fatigue, Attention, and Stress, and test it in a study including ten healthy participants walking while assisted by a lower limb treadmill-based exoskeleton. PP indicators were compared with participants’ self-reported evaluation of the human-robot interaction experience following the administration of a dedicated questionnaire. Results from a correlation analysis demonstrated that the output of the Fuzzy Logic method was consistent with the participants’ subjective assessment.},
  archive      = {J_TMRB},
  author       = {Christian Tamantini and Francesca Cordella and Nevio Luigi Tagliamonte and Ilenia Pecoraro and Iolanda Pisotta and Alessandra Bigioni and Federica Tamburella and Matteo Lorusso and Marco Molinari and Loredana Zollo},
  doi          = {10.1109/TMRB.2024.3377453},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {695-705},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A data-driven fuzzy logic method for psychophysiological assessment: An application to exoskeleton-assisted walking},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explorations of autonomous prosthetic grasping via proximity
vision and deep learning. <em>TMRB</em>, <em>6</em>(2), 685–694. (<a
href="https://doi.org/10.1109/TMRB.2024.3377530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traumatic loss of a hand is usually followed by significant psychological, functional and rehabilitation challenges. Even though much progress has been reached in the past decades, the prosthetic challenge of restoring the human hand functionality is still far from being achieved. Autonomous prosthetic hands showed promising results and wide potential benefit, a benefit that must be still explored and deployed. Here, we hypothesized that a combination of a radar sensor and a low-resolution time-of-flight camera can be sufficient for object recognition in both static and dynamic scenarios. To test this hypothesis, we analyzed via deep learning algorithms HANDdata, a human-object interaction dataset with particular focus on reach-to-grasp actions. Inference testing was also performed on unseen data purposely acquired. The analyses reported here, broken down to gradually increasing levels of complexity, showed a great potential of using such proximity sensors as alternative or complementary solution to standard camera-based systems. In particular, integrated and low-power radar can be a potential key technology for next generation intelligent and autonomous prostheses.},
  archive      = {J_TMRB},
  author       = {E. Mastinu and A. Coletti and J. van den Berg and C. Cipriani},
  doi          = {10.1109/TMRB.2024.3377530},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {685-694},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Explorations of autonomous prosthetic grasping via proximity vision and deep learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SmartStim: An artificial intelligence enabled deep brain
stimulation device. <em>TMRB</em>, <em>6</em>(2), 674–684. (<a
href="https://doi.org/10.1109/TMRB.2024.3381341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep brain stimulation (DBS) has demonstrated therapeutic efficacy in the treatment of neurological and psychiatric disorders. Currently, DBS devices employ an ‘open-loop’ configuration, requiring manual adjustment of electrical stimulation to address patient needs. For this reason, closed-loop DBS is being developed, delivering appropriate treatment on-demand based on internal signal monitoring. A key challenge in current research is the complexity of interpreting the measured signals and delivering appropriate interventions, currently no miniaturised closed-loop DBS device has on-board artificial intelligence (AI) to meet this need. This paper presents a new miniaturised device, named SmartStim, that uses AI to monitor dynamically changing brain biomarkers. In addition, the AI decides if the output stimulator is required for treatment. This device has two key components: the hardware module (neural sensor unit, processor, and neurostimulator) and a software module (data processing, AI, and firmware). The neural sensor unit is comprised of two subcomponents. The first is a potentiostat that can perform impedance analysis, and the second is a dedicated fast scan cyclic voltammetry (FSCV) front-end that can perform scan rates up to 1000 V/s. This device can output current-controlled stimulation waveforms in a frequency range of 5 Hz – 200 Hz, a current range of $1~\mu \text{A}$ to 10 mA, with active charge balancing. Five experiments were conducted to validate SmartStim: static resistive load test, emulated brain resistance test, static electrochemical cell test, impedance test, and dynamic serotonin test. These experiments confirm the potential for SmartStim to identify neurochemical patterns in a mouse brain using AI.},
  archive      = {J_TMRB},
  author       = {Dean M. Corva and Brenna Parke and Alyssa West and Egan H. Doeven and Scott D. Adams and Susannah J. Tye and Parastoo Hashemi and Michael Berk and Abbas Z. Kouzani},
  doi          = {10.1109/TMRB.2024.3381341},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {674-684},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {SmartStim: An artificial intelligence enabled deep brain stimulation device},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Examination of biofeedback to support the use of
upper-extremity exoskeletons under proportional myoelectric control.
<em>TMRB</em>, <em>6</em>(2), 662–673. (<a
href="https://doi.org/10.1109/TMRB.2024.3377278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exoskeletons have the potential to assist individuals in completing daily tasks and augment industrial workers in labor-intensive jobs. While previous studies have shown the capability of powered upper limb exoskeletons to reduce muscle effort and maintain task performance in continuous cyclical movements, their effectiveness in natural movements that contain both dynamic and static tasks remains uncertain. This study aimed to investigate the impact of visual and haptic electromyography (EMG) biofeedback on participants $(n=36)$ while they performed a target position matching task with a powered upper limb exoskeleton. Our hypothesis was that users could benefit from the biofeedback to minimize muscle effort and use the exoskeleton more effectively. However, the results indicated that the biofeedback did not reduce muscle effort in participants, but it had a positive impact on the smoothness of participants’ extension movements. The challenge of reducing muscle effort appeared to stem from participants experiencing difficulty in relaxing their muscles, even when the exoskeleton provided support for the task or maintained the desired posture. Nevertheless, participant feedback supported that biofeedback might enhance their satisfaction with exoskeleton usage, which is a crucial factor in promoting long-term acceptance. These findings provide a foundation for future research in user training methods and controller development for exoskeletons.},
  archive      = {J_TMRB},
  author       = {Xiangyu Peng and Leia Stirling},
  doi          = {10.1109/TMRB.2024.3377278},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {662-673},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Examination of biofeedback to support the use of upper-extremity exoskeletons under proportional myoelectric control},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Influence of forearm postures on hand-wrist gesture
recognition with forearm deformation measurements. <em>TMRB</em>,
<em>6</em>(2), 652–661. (<a
href="https://doi.org/10.1109/TMRB.2024.3377364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hand-wrist gesture recognition based on biosignal, the negative influence of forearm posture variation on recognition accuracy is a common problem. Although the elbow/forearm-rotation angle influence has been investigated in several previous studies, the combined influence of these angles is still unclear. Therefore, we investigated the influence of forearm postures (both elbow and forearm rotation angles) by comparing the accuracies under various data configurations in which the posture combinations used for training the recognition model were different. We collected forearm deformation as biosignal for seven hand-wrist gestures under nine different forearm postures (combinations of three elbow and forearm rotation angles). The accuracy comparison results showed that the forearm rotation angle strongly affected recognition compared with the elbow angle, and the complex combination of elbow and forearm rotation angles had a stronger influence. The results of this study suggest that data collection can be made efficient by considering variations in the forearm postures. If time is available for data collection, it is effective to focus on the interpolation of forearm deformation to the untrained forearm postures based on those of the trained posture. If the time for data collection is limited, it is preferable to focus on variations in forearm rotation angle.},
  archive      = {J_TMRB},
  author       = {Sung-Gwi Cho and Muhammad Akmal Bin Mohammed Zaffir and Masahiro Yoshikawa and Jun Takamatsu and Takahiro Wada},
  doi          = {10.1109/TMRB.2024.3377364},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {652-661},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Influence of forearm postures on hand-wrist gesture recognition with forearm deformation measurements},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessment of a fault-tolerant control-based wearable tremor
suppression glove under faults and disturbances. <em>TMRB</em>,
<em>6</em>(2), 643–651. (<a
href="https://doi.org/10.1109/TMRB.2024.3350769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pathological tremor severely impacts the quality of life of affected individuals. The need for tremor management approaches that are free of side effects and surgical complications has sparked research in wearable tremor suppression technology. The existing wearable tremor suppression devices have achieved suppression ratios of up to 90%. Although the achieved performance is promising, the safety of using these devices outside of a lab environment, where faults and disturbances exist, has not been studied. It was recently discovered that existing tremor suppression systems are not effective and safe for users when faults and disturbances are present. Therefore, this study proposes and evaluates a novel fault-tolerant control system for tremor suppression. Using 18 tremor datasets previously recorded, the performance of the proposed system under three simulated common faults was evaluated on a bench-top mechatronic tremor simulator. The assessment showed that the proposed system remained safe and functional after introducing the faults, maintaining at least a 60% tremor suppression rate, and root mean square tracking error lower than 2.7° (compared to 80.5° without the proposed system). This study improves the robustness and safety of wearable tremor suppression devices, providing strong evidence to facilitate the transition of these devices from the lab to real-life applications.},
  archive      = {J_TMRB},
  author       = {Yue Zhou and Parisa Daemi and Mary E. Jenkins and Michael D. Naish and Ana Luisa Trejos},
  doi          = {10.1109/TMRB.2024.3350769},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {643-651},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Assessment of a fault-tolerant control-based wearable tremor suppression glove under faults and disturbances},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Functional resistance training during walking: Do
biomechanical and neural effects differ based on targeted joints?
<em>TMRB</em>, <em>6</em>(2), 632–642. (<a
href="https://doi.org/10.1109/TMRB.2024.3369894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Devices for functional resistance training (FRT) during walking are often configured to resist the knee or both the hip and knee joints. Adding resistance to the hip in addition to the knee should alter the effects of training; however, these configurations have not been directly compared. We examined how FRT during walking differs during the knee or hip and knee conditions. Fourteen non-disabled individuals received FRT during treadmill walking with a device configured to provide a viscous resistance to the knee or the hip and knee during separate visits. Between these configurations, we compared gait kinetics, muscle activation, kinematic aftereffects, peripheral fatigue, and corticospinal excitability. Adding resistance to the hip increased hip flexion moment and concentric power during the swing phase. However, this did not result in significant differences in muscle activation, aftereffects, peripheral fatigue, or corticospinal excitability between the configurations. Instead, both configurations produced similar changes in these variables. These results indicate that, aside from kinetics, walking with resistance at the hip and knee was not different from resisting the knee in the acute setting. However, further research is needed to determine if long-term training with resistance at the hip induces differential effects than resisting the knee alone.},
  archive      = {J_TMRB},
  author       = {Edward P. Washabaugh and Chandramouli Krishnan},
  doi          = {10.1109/TMRB.2024.3369894},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {632-642},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Functional resistance training during walking: Do biomechanical and neural effects differ based on targeted joints?},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel robotic healthcare device for treating chronic
venous insufficiency in people who sit for prolonged periods.
<em>TMRB</em>, <em>6</em>(2), 618–631. (<a
href="https://doi.org/10.1109/TMRB.2024.3373909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deterioration of the lower limb venous circulation can cause several health problems (e.g., varicose veins, deep vein thrombosis, and cardiac arrhythmia). However, it is not easy to avoid owing to a sedentary life, which is one of the characteristics of modern people. Several studies have focused on improving lower limb blood circulation, and some have used robotic devices. These robots, however, not only the lead to poor blood circulation, but also are too bulky and heavy to use in daily life. In this study, a new type of lower limb venous circulation robot called Healthy-CAL is proposed. By applying the semi auto locking linkage mechanism, the size of Healthy-CAL was reduced while the operating range of the robot was maximized. In addition, a foot mapping algorithm was applied to Healthy-CAL, which autonomously recognizes the user’s ankle joint range of motion and allows users to perform maximized ankle exercises regardless of the sitting position. An experiment was conducted with eight participants to demonstrate the effectiveness of the proposed foot-mapping algorithm. We also used Doppler ultrasound in five participants to confirm the improvement in venous circulation with Healthy-CAL.},
  archive      = {J_TMRB},
  author       = {Hyeoncheol Kim and Donghyun Kwon and Jangwon Son and Jungsu Choi},
  doi          = {10.1109/TMRB.2024.3373909},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {618-631},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A novel robotic healthcare device for treating chronic venous insufficiency in people who sit for prolonged periods},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On optimal tendon routing-based design of biologically
inspired underactuated hand exoskeleton for gross grasping.
<em>TMRB</em>, <em>6</em>(2), 600–617. (<a
href="https://doi.org/10.1109/TMRB.2024.3387334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a compact, portable fingertip-to-elbow hand exoskeleton (F-EL-EX) designed to assist in gross grasping activities involving hand opening and closing movements. The design mimics a biological tendon pulley system (TPS) for finger flexion, optimized for the maximum range of flexion while keeping bowstringing and maximum pulley stress under check. The exoskeleton finger integrates a jointless system of phalanges, designed with care to house the TPS while allowing unrestricted motion of the respective finger joints, each with variable centers of rotation. The exoskeleton is hybrid – fabricated with plastic, natural rubber, and metal, with individual or combination of materials used for different palm and forearm regions. Rigid components used for tendon routing help in modeling a relation between tendon excursion and flexion and provide high grasping force capabilities. The soft material on the palm region ensures retaining flexibility during grasping of objects with varied shapes and supports thumb carpometacarpal (CMC) adjustment. Compactness and portability are ensured through a sliding pulley based slack-tolerant differential mechanism (SPDM), driving all fingers with a single actuator and employing a separate actuator for the thumb. The experimental and functional results of the exoskeleton on a healthy subject demonstrate its adaptive, gross grasping abilities with everyday objects through power grasp, lateral pinch, and parallel extension. These findings encourage further exploration in clinical trials, especially for individuals with hand muscle weaknesses.},
  archive      = {J_TMRB},
  author       = {Vitthal Khatik and Anupam Saxena},
  doi          = {10.1109/TMRB.2024.3387334},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {600-617},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {On optimal tendon routing-based design of biologically inspired underactuated hand exoskeleton for gross grasping},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DaVinci research kit patient side manipulator dynamic model
using augmented lagrangian particle swarm optimization. <em>TMRB</em>,
<em>6</em>(2), 589–599. (<a
href="https://doi.org/10.1109/TMRB.2024.3387070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In surgical robotics, accurate characterization of the dynamic model is crucial. It serves as a foundation for developing robust control algorithms that effectively handle the complex dynamics of the robot and its interactions with the environment. Additionally, an accurate dynamic model aids in estimating external forces and disturbances, enhancing the safety and stability of the control. Among surgical robots, the da Vinci Research Kit (dVRK) is one of the most used, and it has been a crucial instrument in removing a barrier to entry for new research groups in surgical robotics by facilitating the development of improved control algorithms. This paper presents a method for dynamic model identification of the dVRK *psm robot that employs a novel friction model definition. The model formulation has been modified by including the Stribeck effect at low velocities, and the friction has been estimated using the superposition method. The dynamic parameters are identified utilizing a restricted optimization method with physical consistency requirements in an Augmented Lagrangian Particle Swarm Algorithm (ALPSO) methodology. The identified model is thoroughly evaluated, and the results are compared with existing literature methods. Also, a model-based sensorless force estimation method was used to test the dynamic model.},
  archive      = {J_TMRB},
  author       = {Omer Faruk Argin and Rocco Moccia and Cristina Iacono and Fanny Ficuciello},
  doi          = {10.1109/TMRB.2024.3387070},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {589-599},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {DaVinci research kit patient side manipulator dynamic model using augmented lagrangian particle swarm optimization},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward MR-guided robotic intracerebral hemorrhage
evacuation: Aiming device design and ex vivo ovine head trial.
<em>TMRB</em>, <em>6</em>(2), 577–588. (<a
href="https://doi.org/10.1109/TMRB.2024.3385794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stereotactic neurosurgery is a well-established surgical technique for navigation and guidance during treatment of intracranial pathologies. Intracerebral hemorrhage (ICH) is an example of various neurosurgical conditions that can benefit from stereotactic neurosurgery. As a part of our ongoing work toward real-time MR-guided ICH evacuation, we aim to address an unmet clinical need for a skull-mounted frameless stereotactic aiming device that can be used with minimally invasive robotic systems for MR-guided interventions. In this paper, we present NICE-Aiming, a Neurosurgical, Interventional, Configurable device for Effective-Aiming in MR-guided robotic neurosurgical interventions. A kinematic model was developed and the system was used with a concentric tube robot (CTR) for ICH evacuation in (i) a skull phantom and (ii) in the first ever reported ex vivo CTR ICH evacuation using an ex vivo ovine head. The NICE-Aiming prototype provided a tip accuracy of 1.41±0.35 mm in free-space. In the MR-guided gel phantom experiment, the targeting accuracy was 2.07±0.42 mm and the residual hematoma volume was 12.87 mL (24.32% of the original volume). In the MR-guided ex vivo ovine head experiment, the targeting accuracy was 2.48±0.48 mm and the residual hematoma volume was 1.42 mL (25.08% of the original volume).},
  archive      = {J_TMRB},
  author       = {Anthony L. Gunderman and Saikat Sengupta and Zhefeng Huang and Dimitri Sigounas and Chima Oluigbo and Isuru S. Godage and Kevin Cleary and Yue Chen},
  doi          = {10.1109/TMRB.2024.3385794},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {577-588},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Toward MR-guided robotic intracerebral hemorrhage evacuation: Aiming device design and ex vivo ovine head trial},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancements in temporal fusion: A new horizon for EEG-based
motor imagery classification. <em>TMRB</em>, <em>6</em>(2), 567–576. (<a
href="https://doi.org/10.1109/TMRB.2024.3387092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BCIs facilitate seamless engagement between individuals with motor disabilities and their surrounding environment by translating electroencephalography (EEG) signals generated from Motor Imagery (MI). Crucial to this process is the accurate classification of different types of MI tasks - a challenge that calls for the consistent evolution and refinement of reliable methodologies for EEG signal classification. This paper introduces three innovative approaches: M1, employing a temporal block technique combined with Filter Bank Common Spatial Pattern (FBCSP) and mutual information-based feature selection with a Random Forest classifier; and M2 and M3, extending M1 using Temporal Probability Fusion (TPF) and Probability Difference-based Temporal Fusion (PDTF) respectively. These methods aim to enhance MI EEG signal classification. The effectiveness of M1, M2, and M3 was scrutinized under differing scenarios including changing overlap sizes and channel choices. The analysis highlights that our methods exhibit enhanced performance under particular conditions, underlining the crucial role of temporal information and channel selection. Comparison with established methodologies verifies the superior efficiency of our proposed strategies. This study foregrounds the considerable potential of TPF and PDTF in MI EEG classification tasks, with significant implications for the future development of BCI systems.},
  archive      = {J_TMRB},
  author       = {Saran Kundu and Aman Singh Tomar and Anirban Chowdhury and Gargi Thakur and Aruna Tomar},
  doi          = {10.1109/TMRB.2024.3387092},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {567-576},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Advancements in temporal fusion: A new horizon for EEG-based motor imagery classification},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design, modeling and optimization of a magnetic resonance
conditional 3-RRR spherical parallel robot for neurosurgery.
<em>TMRB</em>, <em>6</em>(2), 556–566. (<a
href="https://doi.org/10.1109/TMRB.2024.3387114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In neurosurgery, magnetic resonance (MR) imaging is extensively utilized for preoperative diagnosis and postoperative evaluation due to its superior soft tissue contrast. However, the strong magnetic field poses a challenge to the real-time utilization of MR for intraoperative navigation. To facilitate neurosurgery in the MR environment, this paper develops a MR conditional robot featuring nonferrous materials and ultrasonic motor actuation. The robot consists of a 3-degree-of-freedom (3-DOF) translational module and a 3-DOF remote center of motion (RCM) module. The RCM module incorporates a 3-RRR spherical parallel mechanism. The mechanical design and kinematic modeling of the RCM module is completed. This paper further conducts the optimization for the RCM module. Additionally, a path-planning algorithm, focusing on the maximization of dexterity, is introduced, and the feasible workspace of the optimized RCM module is evaluated. A prototype is fabricated, and the orientation repeatability of the RCM module is measured to be 0.055±0.0016°, and the absolute orientation error is 2.05±0.019°. Needle insertion experiments are performed on an agarose phantom to evaluate the feasibility of the robot. The impact on signal-to-noise ratio in MRI images caused by the robot is less than 4%, indicating a highly promising applicability in MR conditional neurosurgery.},
  archive      = {J_TMRB},
  author       = {Yanding Qin and Yueyang Shi and Longxin Wang and Hongpeng Wang and Jianda Han},
  doi          = {10.1109/TMRB.2024.3387114},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {556-566},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Design, modeling and optimization of a magnetic resonance conditional 3-RRR spherical parallel robot for neurosurgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PPFormer: A novel model for polyp segmentation in digestive
endoscopy. <em>TMRB</em>, <em>6</em>(2), 548–555. (<a
href="https://doi.org/10.1109/TMRB.2024.3381330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polyp segmentation is a pivotal task in the field of medical image processing. We devised a more effective deep learning model (PPFormer) that seamlessly integrates pyramid pooling module with transformer. This integration significantly improves the model’s ability to restore intricate details during the decoding phase. Additionally, we rethinked the importance of multi-scale feature maps within the model and thoughtfully designed two pruning strategies to target the elimination of redundant and mis-segmented feature maps, resulting in improved segmentation quality. In this paper, we aim to explore methods to enhance the performance of the polyp segmentation model. We conducted experiments on three different polyp segmentation datasets, and the model presented in this paper consistently exhibited exceptional performance. Through visual experiments, the model demonstrated an enhanced capacity to handle the edge of the polyp, indicating an improved capability to restore image details during the decoding process. In terms of quantitative metrics, PPFormer achieved outstanding results in segmentation-related indicators. For example, it obtained mIoU scores of 91.67%, 92.09%, and 93.19% on the Kvasir-SEG, CVC-ClinicDB, and CVC-300 datasets, respectively.},
  archive      = {J_TMRB},
  author       = {Wenxin Chen and Kaifeng Wang and Chao Qian and Xue Li and Changsheng Li and Xingguang Duan},
  doi          = {10.1109/TMRB.2024.3381330},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {548-555},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {PPFormer: A novel model for polyp segmentation in digestive endoscopy},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft transfemoral prosthetic socket with sensing and
augmenting feedback: A case study. <em>TMRB</em>, <em>6</em>(2),
536–547. (<a href="https://doi.org/10.1109/TMRB.2024.3381378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In lower limb prostheses, the physical interface constituted by the socket is a crucial component for the device success. This work proposes a new design based on a rigid frame integrated into a silicone structure which allows for a more comfortable biomechanical coupling with the residual limb and facilitates the integration of smart technologies. This paves the way for new possibilities for prosthetic bidirectional interfaces or user health monitoring. Thus, four surface EMG sensors, three vibrotactile units, and nine temperature and humidity sensors have been integrated into the socket. These components enable the user’s motor intention decoding, provide augmenting feedback, and measure the residual limb thermal condition when wearing the prosthesis. The new socket was tested on a partecipant with a transfemoral amputation. The sEMG signals were registered during five different tasks in a circuit training and the classification median accuracy of an intention decoding algorithm was found to always be higher than 73%. The user’s perception of vibrotactile feedback was assessed through a psychophysical experiment and revealed vibrations from singularly activated units were the best perceived. Questionnaire results confirmed a high satisfaction level. However, tests on temperature and humidity suggest more efforts are still required in terms of skin perspiration.},
  archive      = {J_TMRB},
  author       = {Linda Paternò and Mariangela Filosa and Eugenio Anselmino and Alessio Cecere and Filippo Dell’Agnello and Emanuele Gruppioni and Alberto Mazzoni and Silvestro Micera and Calogero Oddo and Arianna Menciassi},
  doi          = {10.1109/TMRB.2024.3381378},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {536-547},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Soft transfemoral prosthetic socket with sensing and augmenting feedback: A case study},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of a 4-DoF surgical instrument with a universal
joint and 6-axis force sensation. <em>TMRB</em>, <em>6</em>(2), 524–535.
(<a href="https://doi.org/10.1109/TMRB.2024.3381369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot-assisted endoscopic surgery (RES) has overcome the shortcomings of traditional laparoscopic surgery in observation, comfort, operation, and flexibility. However, existing systems still lack force feedback which limits the quality and efficiency of RES. This paper develops a surgical instrument with 6-axis force sensation, mechanism of the instrument includes a universal joint wrist, a gripper, and the instrument shaft, which provide the surgical instrument with 4 degrees of freedom (DoFs) in roll, pitch, yaw and gripping. A 6-axis miniature force/torque sensor (FTS) is integrated into the gripper mechanism before the wrist. The coupling between the gripping force and external force is eliminated through a decoupling pulley in the force sensing unit. The transmission, drive, and interface unit complete the system assembly of the surgical instrument prototype. A dedicated static calibration platform is designed to apply standard weight loading for the force sensing unit. The static calibration matrix is obtained based on the least square method, and technical indicators such as the measurement ranges and resolutions are analyzed. Motion performance of the surgical instrument is tested through the wrist trajectory tracking experiment and the simplified leader/follower teleoperation to verify the feasibility of applying this surgical instrument prototype in the RES system.},
  archive      = {J_TMRB},
  author       = {Kun Li and Yue Zhuo and Dingjia Li and Xinyu Liu and Xiao Wang and Hao Liu},
  doi          = {10.1109/TMRB.2024.3381369},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {524-535},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Development of a 4-DoF surgical instrument with a universal joint and 6-axis force sensation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward automatic stomach screening using a wireless
magnetically actuated capsule endoscope. <em>TMRB</em>, <em>6</em>(2),
512–523. (<a href="https://doi.org/10.1109/TMRB.2024.3387040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stomach cancer remains one of the primary health challenges with a high incidence and motility. Magnetically actuated capsule endoscope (MACE) provides a noninvasive and practical solution for stomach screening, due to its contactless actuation and high maneuverability. In this work, with an aim of shortening procedure duration and lowering surgeon workload, we propose an automatic stomach screening strategy by using a MACE to automatically detect and capture specific gastric features for mapping the whole stomach. To achieve this, an electromagnetic actuation system and a wireless MACE with real-time video transmission and orientation feedback are developed. Magnetic actuation modeling and kinematics analysis of the MACE are conducted, based on which an optimization-based position controller and a visual-servo-based orientation controller are designed. Simulative and experimental validation are conducted for proof-of-concept, with attractive results showing that the MACE can be accurately and stably controlled with a mean absolute position error of around 2.56 mm and an average convergent time of about 1.1 s for visual servoing and that automatic stomach screening is successfully demonstrated in a stomach phantom. The proposed stomach screening strategy using a MACE indicates high potential in clinical practice.},
  archive      = {J_TMRB},
  author       = {Heng Zhang and Yehui Li and Xinfa Shi and Yichong Sun and Jixiu Li and Yisen Huang and Wing Yin Ng and Chengxiang Liu and Philip Wai Yan Chiu and Chi-Kwan Lee and Zheng Li},
  doi          = {10.1109/TMRB.2024.3387040},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {512-523},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Toward automatic stomach screening using a wireless magnetically actuated capsule endoscope},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A steerable cross-axis notched continuum manipulator for
endobronchial intervention. <em>TMRB</em>, <em>6</em>(2), 498–511. (<a
href="https://doi.org/10.1109/TMRB.2024.3377359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving the balance between stiffness and range of motion (ROM) in continuum manipulators is a primary design challenge. To tackle this design trade-off, this paper introduces a novel notched-tube continuum manipulator (NTCM) called the Steerable Cross-axis Notched (SCAN) manipulator. It achieves this by integrating asymmetric cross-axis notches into a pair of concentric nitinol tubes. Two pairs of cross-tilted beams are positioned within each segment, thereby extending the length of the flexural members. When compared to traditional NTCM with vertically configured beams (termed as v-NTCM), the SCAN manipulator (SCANM) exhibits a greater maximum bending angle for the same level of bending stiffness. Furthermore, the SCANM exhibits greater bending stiffness in comparison to the v-NTCM with the same maximum bending angle. Subsequently, a mechanical model for the SCANM, accounting for external tip load and tendon friction, is developed. Additionally, a multi-objective optimization is carried out to identify the optimal structural performance. Through model analysis and comparisons, this paper also elucidates the distinct advantages offered by the SCANM. Model verification experiments and stiffness testing experiments are conducted to quantify both the model’s accuracy and stiffness of the SCANM. Finally, an endobronchial grasping and a laser ablation experiment are conducted to demonstrate the practical feasibility of the SCANM for clinical applications.},
  archive      = {J_TMRB},
  author       = {Xiaojie Ai and Yilin Cai and Anzhu Gao and Weidong Chen},
  doi          = {10.1109/TMRB.2024.3377359},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {498-511},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A steerable cross-axis notched continuum manipulator for endobronchial intervention},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shared control of tendon-driven continuum robots using
visibility-guaranteed optimization for endoscopic surgery.
<em>TMRB</em>, <em>6</em>(2), 487–497. (<a
href="https://doi.org/10.1109/TMRB.2024.3381371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tendon-driven continuum robots (TDCRs) with mechanical compliance have gained popularity in natural orifice transluminal endoscopic surgery (NOTES). Teleoperation problems of the TDCRs involve performance objectives in addition to the visibility constraint. Handling the coupling between potentially conflicting objectives and the visibility constraint remains challenging for surgeons when operating TDCRs. This paper presents a shared control method to assist in the teleoperation of the TDCRs, which guarantees visual targets remain within the field of view (FoV) of the TDCR. The visibility constraint is explicitly defined using a zeroing control barrier function, which is specified in terms of the forward invariance of a visible set. To ensure accuracy, the Jacobian matrix of the system is approximated online using sensing data. Then, the visibility constraint, along with the robot’s physical constraints, is integrated into a quadratic program (QP) framework. This allows for the optimization of the control input of the operator subject to constraints, thus preserving visibility. Finally, simulations and experiments were conducted to demonstrate the effectiveness of the proposed approach under two teleoperation modes. The results show that the proposed method achieved a reduction of approximately 70% in ITP and 43% in MAE compared to direct teleoperation.},
  archive      = {J_TMRB},
  author       = {Zhen Deng and Xiaoxiao Wei and Chuanchuan Pan and Guotao Li and Ying Hu},
  doi          = {10.1109/TMRB.2024.3381371},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {487-497},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Shared control of tendon-driven continuum robots using visibility-guaranteed optimization for endoscopic surgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of a 7-DoF haptic operator interface based on
redundantly actuated parallel mechanism. <em>TMRB</em>, <em>6</em>(2),
475–486. (<a href="https://doi.org/10.1109/TMRB.2024.3377376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel 7-DoF operator interface based on a redundantly actuated parallel architecture of 2(RRRS)-RRRSP. This design effectively avoids the workspace-internal singularities, thereby addressing the limitations associated with the orientational workspace of traditional parallel operator interfaces. Furthermore, the redundantly actuated mechanism enables 3-DoF full actuation of each branch chain, and the motors are specially positioned near the base, significantly reducing the operating inertia without the need for gravity compensation. This arrangement contributes to a reduction in operator fatigue during prolonged operation. A hybrid tendon-linkage transmission is utilized in the operator interface to enhance its positioning accuracy. A prototype of the operator interface has been developed, and its kinematics along with the Jacobian have been derived. Optimization of structural parameters has been executed to enhance operational dexterity and relative workspace. Static force analysis has been conducted, and a strategy for static force output has been implemented to effectively decouple the interference between the clamping feedback force and the six-dimensional spatial feedback force. Experimental investigations on the translational and orientational workspace are carried out. The results demonstrate an expansive translational workspace measuring 315 mm (X), 248.5 mm, and 133.8 mm (Z), along with a wide range of orientation angles [−108°, 98°] $(\alpha)$ , [−134°, 134°] $(\beta)$ and [−115°, 115°] $(\gamma)$ . Trajectory tracking experiments have been performed and yielded an average error value of 1.021mm. The accuracy of the feedback force output has been studied, with average errors in output force recorded as 0.084 N (X), 0.124 N (Y), and 0.237 N (Z). Investigations into decoupling capability have been carried out, with average output errors of the clamping force at 5 N and 7 N operating forces in X and Y directions recorded as 0.095 N and 0.081 N, respectively. The experimental results demonstrate its potential for integration into RAMIS systems to align with diverse configurations of slave manipulators.},
  archive      = {J_TMRB},
  author       = {Jichen Li and Ziyan Huang and Chengzhi Hu and Zhiqiang Zhang and Chaoyang Shi},
  doi          = {10.1109/TMRB.2024.3377376},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {475-486},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Development of a 7-DoF haptic operator interface based on redundantly actuated parallel mechanism},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the monocular 3-d pose estimation for arbitrary shaped
needle in dynamic scenes: An efficient visual learning and geometry
modeling approach. <em>TMRB</em>, <em>6</em>(2), 460–474. (<a
href="https://doi.org/10.1109/TMRB.2024.3377357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-guided needle pose estimation is crucial for robotic autonomous suturing, but it poses significant challenges due to the needle’s slender visual projection and dynamic surgical environments. Current state-of-the-art methods rely on additional prior information (e.g., in-hand grasp, accurate kinematics, etc.) to achieve sub-millimeter accuracy, hindering their applicability in varying surgical scenes. This paper presents a new generic framework for monocular needle pose estimation: Visual learning network for efficient geometric primitives extraction and novel geometry model for accurate pose recovery. To capture needle’s primitives precisely, we introduce a morphology-based mask contour fusion mechanism in a multi-scale manner. We then establish a novel state representation for needle pose and develop a physical projection model to derive its relationship with the primitives. An anti-occlusion objective is formulated to jointly optimize the pose and bias of inference primitives, achieving sub-millimeter accuracy under occlusion scenarios. Our approach requires neither CAD model nor circular shape assumption and can extensively estimate poses of other small planar axisymmetric objects. Experiments on ex-/in-vivo scenarios validate the accuracy of estimated intermediate primitives and final poses of needles. We further deploy our framework on the dVRK platform for automatic and precise needle manipulations, demonstrating the feasibility for use in robotic surgery.},
  archive      = {J_TMRB},
  author       = {Bin Li and Bo Lu and Hongbin Lin and Yaxiang Wang and Fangxun Zhong and Qi Dou and Yun-Hui Liu},
  doi          = {10.1109/TMRB.2024.3377357},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {460-474},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {On the monocular 3-D pose estimation for arbitrary shaped needle in dynamic scenes: An efficient visual learning and geometry modeling approach},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The LINGCAI-II system: A sampling robotic system for
autonomous oropharyngeal swab sampling. <em>TMRB</em>, <em>6</em>(2),
448–459. (<a href="https://doi.org/10.1109/TMRB.2024.3377360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fight against infectious diseases is a permanent theme in the history of humans, especially the pandemic of COVID-19 made a severe impact on the world. The sampling robot which can instead of medical staff in the oropharyngeal swab(OP-swab) sampling is a new form of medical robot that emerged during the pandemic. Robot with continuous automatic sampling capability, which can maximize the value of robots. In this paper, we presented the LINGCAI-II robot, which is the upgrade of the LINGCAI-I robot and can realize the automatic OP-swab sampling in clinical application. Based on the intraoral image and contact force, we proposed an automatic sampling method for robots which includes a three-level visual identification algorithm, trajectory planner, force position hybrid controller, and quality evaluator. By cooperating with other function stations inside the robot, the LINGCAI-II robot can complete the whole process of the sample without manual assistance. The volunteer trial results show that the robot sampling can get more cells in the swab tip than the manual sample. We set up a robot sampling workstation and carried out the clinical trial for 116 COVID-19 patients. Our clinical trials achieved 96 COVID-19 patients diagnosed by robot sampling. This is the first time that the sampling robot achieved application for confirmed patients automatically. The results demonstrated the feasibility of automatic robot sampling in infectious diseases.},
  archive      = {J_TMRB},
  author       = {Zhenxing Wang and Shaoqiang Li and Xiao He and Ruchong Chen and Lianqing Liu and Shiyue Li and Hao Liu},
  doi          = {10.1109/TMRB.2024.3377360},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {448-459},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {The LINGCAI-II system: A sampling robotic system for autonomous oropharyngeal swab sampling},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-lateral branched network for tool segmentation during
robot-assisted endovascular interventions. <em>TMRB</em>, <em>6</em>(2),
433–447. (<a href="https://doi.org/10.1109/TMRB.2024.3369765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot-assisted endovascular intervention has emerged for improving the outcomes of cardiovascular interventions. However, the current segmentation methods are affected with low and varied contrast values of endovascular tools in the angiogram, and background noise, both of which affect segmentation performance. Thus, surgical scene analytics are characterized with slow tool visualization and response during endovascular navigation. In this study, a multi-lateral branched network (MLB-Net) is proposed for pixel-level segmentation of guidewire in angiograms recorded during robot-assisted cardiovascular catheterization. The network has an encoder with lateral separable convolutions and depth-wise attention, and decoder with improved loss function. Feature maps extracted during end-to-end fully supervised training were optimized for guidewire segmentation. The MLB-Net was trained and validated with multiple angiogram sequences obtained during series of robot-assisted catheterization in rabbit model. Validation studies show a robust performance, characterized with mean IoU of 84.89% and area under curve of 90.64%. In addition, the model offered fast (15.28 frame/second) and reliable segmentation performance in new angiograms obtained during additional trials carried out in pig and human phantom models. Furthermore, we evaluated the MLB-Net by comparing it with existing state-of-the-art networks. Based on our rabbit dataset, the MLB-Net offers better segmentation experience over DeepLabV3+, SegNet, and U-Net which are commonly used for medical image segmentation. Also, MLB-Net generalized well under incremental training. This study contributes a new model for fast tool segmentation, tracking and visualization and during endovascular catheterization.},
  archive      = {J_TMRB},
  author       = {Olatunji Mumini Omisore and Toluwanimi Oluwadara Akinyemi and Wenke Duan and Wenjing Du and Lei Wang},
  doi          = {10.1109/TMRB.2024.3369765},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {433-447},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Multi-lateral branched network for tool segmentation during robot-assisted endovascular interventions},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A very fast and robust method for refinement of putative
matches of features in MIS images for robotic-assisted surgery.
<em>TMRB</em>, <em>6</em>(2), 419–432. (<a
href="https://doi.org/10.1109/TMRB.2024.3369769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic-assisted minimally invasive surgery (MIS) has a very important place in the landscape of modern surgical practices. Simultaneous localization and mapping (SLAM), 3D visualization, augmented reality, image registration and mosaicking are some of the image processing operations, which are often feature-based, used in robotic-assisted surgery. Feature matching refinement (FMR) is a crucial task in such operations. FMR is more critical, in cases where the percentage of true matches is very low, which is generally the case for MIS images. Since real-time is a requisite of MIS tasks, an FMR scheme must be very fast. In this paper we propose a very fast and accurate FMR scheme. The main idea used in developing the proposed scheme is on deciding the size of a local neighborhood and on devising a mechanism for checking feature topology preservation in the local neighborhood. To assess the effectiveness of the proposed scheme, we compare its performance with that of several state-of-the-art methods on different MIS image datasets, which shows its superiority in terms of both the processing time and performance.},
  archive      = {J_TMRB},
  author       = {Muhammad Reza Pourshahabi and M. Omair Ahmad and M. N. S. Swamy},
  doi          = {10.1109/TMRB.2024.3369769},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {419-432},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A very fast and robust method for refinement of putative matches of features in MIS images for robotic-assisted surgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robotic repositioning of photoacoustic tomography for
reproducible long-term monitoring of peripheral artery in vivo.
<em>TMRB</em>, <em>6</em>(2), 410–418. (<a
href="https://doi.org/10.1109/TMRB.2024.3371542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a robotic arm assisted photoacoustic tomography imager that employs a direct visual servoing-enabled repositioning strategy designed for reproducible surveillance of peripheral arterial disease (PAD) progression. The system ensures precise repositioning of the cross-sectional location of the vessel of interest, allowing consistent measurements to track PAD progression and response to treatment. This strategy overcomes the difficulty of obtaining cross-sectional images of the same vessel at different monitoring intervals due to operator variability. In addition, the acquisition of high-resolution, high-contrast vessel images helps to clearly delineate long-term changes in the vasculature. To evaluate the effectiveness of the proposed experimental configurations and algorithms, we performed two sets of vascular phantom experiments and one set of servo-imaging experiments on human lower extremity vessels. The experimental results show 100% similarity for all three sets of grid segmentation comparisons, while the pixel-wise comparison similarity is 99.3% for the first set, 97.4% for the second set, and 98.9% for the in vivo experimental set. These results are important for monitoring the progression of PAD and predicting the risk of cardiovascular disease.},
  archive      = {J_TMRB},
  author       = {Yongjian Zhao and Handi Deng and Xianghu Yu and Yisong Zhao and Ao Xu and Yuhan Chen and Cheng Ma and Li Liu},
  doi          = {10.1109/TMRB.2024.3371542},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {410-418},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Robotic repositioning of photoacoustic tomography for reproducible long-term monitoring of peripheral artery in vivo},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-scene semantic segmentation for medical surgical
instruments using structural similarity-based partial activation
networks. <em>TMRB</em>, <em>6</em>(2), 399–409. (<a
href="https://doi.org/10.1109/TMRB.2024.3359303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot-assisted minimally invasive surgery requires accurate segmentation for surgical instruments in order to guide surgical robots on tracking the target instruments. Nevertheless, it is difficult to perform surgical-instrument semantic segmentation in unknown scenes with extremely insufficient intra-scene surgical data, despite of the attempts for general semantic segmentation tasks. To address this issue, we propose a cross-scene semantic segmentation approach for medical surgical instruments using structural similarity based partial activation networks in this paper. The proposed approach includes a main branch for multi-level feature extraction, a segmentation head global consistency, and a structural similarity based loss function to provide high-level information acquisition, which improves the generalisation performance for the cross-scene segmentation task. Then, the experimental results in cross-scene surgical-instrument semantic segmentation cases show the effectiveness of the proposed approach compared with state-of-the-art semantic segmentation ones, using the newly established endoscopic simulation dataset.},
  archive      = {J_TMRB},
  author       = {Zhengyu Wang and Ziqian Li and Xiang Yu and Zirui Jia and Xinzhou Xu and Björn W. Schuller},
  doi          = {10.1109/TMRB.2024.3359303},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {399-409},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Cross-scene semantic segmentation for medical surgical instruments using structural similarity-based partial activation networks},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft ankle-foot exoskeleton for rehabilitation: A systematic
review of actuation, sensing, mechanical design, and control strategy.
<em>TMRB</em>, <em>6</em>(2), 384–398. (<a
href="https://doi.org/10.1109/TMRB.2024.3385798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot-assisted rehabilitation therapy has become a mainstream trend for the treatment of stroke patients. It can not only relieve physiotherapists from heavy physical duties, but also provide patients with effective ankle-foot rehabilitation and walking assistance. Soft ankle-foot exoskeletons have rapidly evolved in the last decade. This article presents a compressive review of soft ankle-foot exoskeletons in terms of robot actuation, wearable sensor, mechanical design, and control strategy. Representative commercial and laboratory ankle-foot exoskeletons are demonstrated. Special attention is paid to the emerging soft actuators, wearable sensing techniques, and human-in-the-loop and hierarchical control methods. Finally, essential challenges and possible future directions are also analyzed and highlighted in this paper, which can provide reliable guidance on the development of next-generation soft ankle-foot exoskeletons.},
  archive      = {J_TMRB},
  author       = {Wei Meng and Chang Zhu and Haojie Liu and Quan Liu and Sheng Xie},
  doi          = {10.1109/TMRB.2024.3385798},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {384-398},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Soft ankle-foot exoskeleton for rehabilitation: A systematic review of actuation, sensing, mechanical design, and control strategy},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robotic systems design in endovascular treatment.
<em>TMRB</em>, <em>6</em>(2), 367–383. (<a
href="https://doi.org/10.1109/TMRB.2024.3377374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimally invasive endovascular interventional surgery has become the primary surgical method for treating cardiovascular and cerebrovascular diseases. Robotic technology has been proposed as a means to enhance surgical procedures and improve physician experience. Despite the development of related technologies and the proposal of many robotic endovascular intervention systems and commercially available products in recent decades, widespread adoption in routine practice has been obstructed. To mature commercial robotic endovascular intervention systems, improvements in structure design, haptic feedback, autonomy, and other areas are crucial. Autonomous navigation and untethered microrobots have the potential to revolutionize the future of robotic endovascular intervention system innovation. This review highlights the challenges in the design of robotic systems for endovascular treatment, offers perspectives for future robotic system design, and encourages collaboration between engineers and physicians to expedite the use of these systems in clinical practice and explore new possibilities.},
  archive      = {J_TMRB},
  author       = {Naner Li and Yiwei Wang and Huan Zhao and Han Ding},
  doi          = {10.1109/TMRB.2024.3377374},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {5},
  number       = {2},
  pages        = {367-383},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Robotic systems design in endovascular treatment},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A force-limiting mechanism for needle insertions.
<em>TMRB</em>, <em>6</em>(1), 362–365. (<a
href="https://doi.org/10.1109/TMRB.2023.3336961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Needle bending is a significant cause of error in biopsies, leading to lesion missampling and consequent cancer misdiagnosis. This paper presents the design of a new mechanism that detects the needle bending as soon as it occurs and immediately reduces the insertion force. Importantly, this is achieved without employing external sensors or electromechanical actuators. Experiments on a silicone-rubber phantom indicate that the proposed device can help to avoid deep insertions with bent needles, thus potentially reducing the associated risks and improving patient safety in biopsies and percutaneous interventions.},
  archive      = {J_TMRB},
  author       = {Ayhan Aktas and E. Franco},
  doi          = {10.1109/TMRB.2023.3336961},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {362-365},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A force-limiting mechanism for needle insertions},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward the smooth mesh climbing of a miniature robot using
bioinspired soft and expandable claws. <em>TMRB</em>, <em>6</em>(1),
351–361. (<a href="https://doi.org/10.1109/TMRB.2023.3336966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike most micro robots that struggle to navigate rugged and uneven terrain, beetles exhibit remarkable agility, traversing complex substrates with ease. This remarkable locomotion is attributed to their unique adaptations, including stiffness-variable tarsi and expandable hooks at the tip of their tarsi, which prevent slipping and ensure a secure grip on the surface. In this study, we found that beetles actively bent and expanded their claws regularly to crawl freely on mesh surfaces. Inspired by the crawling mechanism of the beetles, a micro cable-and-pully-driven mechanism was designed and demonstrated to be most effective among four several different climbing strategies. After that, an 8-cm miniature climbing robot was assembled, equipping artificial claws to open and bend in the same cyclic manner as natural beetles. The robot can climb freely with a controllable gait on the mesh surface, steep incline of the angle of 60°, and even transition surface. To our best knowledge, this is the first micro-scale robot that can climb both the mesh surface and cliffy incline.},
  archive      = {J_TMRB},
  author       = {Hong Wang and Peng Liu and Hao Chen and Phuoc Thanh Tran Ngoc and Bing Li and Yao Li and Hirotaka Sato},
  doi          = {10.1109/TMRB.2023.3336966},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {351-361},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Toward the smooth mesh climbing of a miniature robot using bioinspired soft and expandable claws},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Highly interpretable representation for multi-dimensional
tactile perception. <em>TMRB</em>, <em>6</em>(1), 340–350. (<a
href="https://doi.org/10.1109/TMRB.2024.3349622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic tactile perception systems have received increasing attention owing to their simple wiring framework and large-area sensing capabilities. However, existing systems often rely on data-driven methods, which is challenging to extract appropriate tactile representations, especially in complex interaction scenarios. To address such a challenge, this paper realizes a highly interpretable representation of the system’s two-stage conversion process (i.e., from changes in magnetic fields to spatial displacements and subsequently into tactile information) with the magnetic dipole model and dynamic Young’s modulus. Furthermore, the proposed representation method is incorporated into a novel spherical-array-based system for multi-dimensional tactile perception. Comprehensive experiments in simulated and real environments are conducted on four systems with various array arrangements. The proposed method can achieve relative errors of 0.54% and 1.75% under normal and tangential deformations, outperforming traditional data-driven approaches. It is envisaged that this study would benefit a wide range of industrial and domestic applications, such as remote surgery, dexterous manipulation, and human-robot interaction.},
  archive      = {J_TMRB},
  author       = {Mei-Jiang Gui and Xiao-Hu Zhou and Xiao-Liang Xie and Shi-Qi Liu and Zhen-Qiu Feng and Hao Li and Tian-Yu Xiang and De-Xing Huang and Bo-Xian Yao and Yong-Gen Ling and Zeng-Guang Hou},
  doi          = {10.1109/TMRB.2024.3349622},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {340-350},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Highly interpretable representation for multi-dimensional tactile perception},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human-in-the-loop personalization of a bi-articular wearable
robot’s assistance for downhill walking. <em>TMRB</em>, <em>6</em>(1),
328–339. (<a href="https://doi.org/10.1109/TMRB.2023.3328654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable robots hold great promise in supporting people during activities of daily living. Personalizing the assistance provided by this technology for not just level ground walking, but also other real-life activities like uphill and downhill walking, will foster its wider adoption. In this paper, we propose an approach to personalize the assistance delivered by a wearable robot – the Myosuit, a tendon-driven soft robot for mobility assistance – for downhill walking. We use a human-in-the-loop method with candidate profiles of 15-steps which aims to minimize knee extensor muscle activity, utilizing the covariance matrix adaptation evolution strategy algorithm (CMA-ES) and a cost function based on normalized RMS of surface EMG signals. By utilizing CMA-ES, we vary the magnitude and timing of Myosuit’s support to find the most appropriate assistance profiles. We compared the optimal profiles to assistance off (transparency) condition and a general trajectory derived using a model-based approach. Relative to the transparency condition, the average muscle activity was reduced by 12.67% (SD: ±8.73; t(20) = 5.25, $p\leq.01$ ) across all participants and muscle groups. The results of our study may support future development of personalized assistance algorithms for wearable robots and lead to better adoption of this technology.},
  archive      = {J_TMRB},
  author       = {Gleb Koginov and Lukas Bergmann and Michele Xiloyannis and Neala Rohner and Chuong Ngo and Jaime E. Duarte and Steffen Leonhardt and Robert Riener},
  doi          = {10.1109/TMRB.2023.3328654},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {328-339},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Human-in-the-loop personalization of a bi-articular wearable robot’s assistance for downhill walking},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design of layer jamming liver retractor for surgical access,
deployment, and removal. <em>TMRB</em>, <em>6</em>(1), 317–327. (<a
href="https://doi.org/10.1109/TMRB.2024.3349611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retractors for laparoscopic surgery face competing challenges: they must be sufficiently soft/small to be (1) deployed and removed through a small opening and (2) manipulated into a desired configuration, but also (3) sufficiently rigid/wide to affix tissue atraumatically. Existing rigid designs are functional, but present the need for additional incisions and external anchoring. We developed a jamming-based foldable retractor capable of deployment, atraumatic anchoring within the body, retraction, and removal without the need for any additional incisions or surgeon involvement. Through FEA and experiments, including mechanical testing and in-porcine testing, we assessed the effect of different device cross-sectional areas on their ability to retract a liver. A patterned high-friction surface on one side of the device provides atraumatic anchoring to the abdominal wall, we compared different patterns, surface conditions, and preloads experimentally. To facilitate easy (i.e., low-force) removal, the device has a tapered end. When removed via the trocar, the taper causes the device to self-fold, with different tapers resulting in different removal forces. Validated by experimental testing and a in-porcine case study, our device demonstrates the ability of layer-jamming-based approaches to fill a hole in the current surgical toolkit and presents applicability beyond liver retraction.},
  archive      = {J_TMRB},
  author       = {W. P. Weston-Dawkes and M. R. A. Majit and J. Sandoval and E. Ochoa and S. Liu and S. Horgan and M. T. Tolley},
  doi          = {10.1109/TMRB.2024.3349611},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {317-327},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Design of layer jamming liver retractor for surgical access, deployment, and removal},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Brace-type wearable robot for adaptive lumbar stabilization:
A pilot experimental study. <em>TMRB</em>, <em>6</em>(1), 302–316. (<a
href="https://doi.org/10.1109/TMRB.2024.3349606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lumbar braces are recommended for lumbar diseases or low back pain, particularly for use in activities of daily living. However, prolonged use of lumbar braces can lead to functional limitations and side effects such as muscle atrophy and psychological dependence due to their static nature. To address these limitations, this study proposes a wearable robot in the form of a lumbar brace to provide adaptive lumbar stabilization. The proposed robot uses an actuator to drive a tension wire, which applies force to the pulley mechanism located on both sides of the brace. This mechanism provides dynamic abdominal pressure to the torso. The assisting force is determined based on the lumbar motion, which is measured using inertial sensors. By providing abdominal pressure and dynamic support, the proposed robot is able to compensate for the shortcomings of current braces and increase lumbar stability. To assess the effectiveness, a pilot experiment was conducted with five healthy subjects. The subjects performed lumbar-specific exercises, Electromyography and linear acceleration were taken to evaluate the impact on muscle activity and lumbar stability. The results indicated that proposed device is possible to reduce the burden on the muscles and increase the spine stability by dynamically providing abdominal pressure.},
  archive      = {J_TMRB},
  author       = {Joowan Kim and Woosup Cho and Jaehoon Sim and Keewon Kim and Sungun Chung and Jaeheung Park},
  doi          = {10.1109/TMRB.2024.3349606},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {302-316},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Brace-type wearable robot for adaptive lumbar stabilization: A pilot experimental study},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stylohyoid and posterior digastric potential evaluation for
a swallowing detection with intramuscular EMG. <em>TMRB</em>,
<em>6</em>(1), 292–301. (<a
href="https://doi.org/10.1109/TMRB.2023.3336960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Total laryngectomy consists of the removal of the larynx and requires a tracheostomy to allow breathing, where the trachea is sewn on the anterior throat. This permanently separates the airway from the esophagus and any attempt to set it back in place would require to emulate the protective mechanism of the larynx, to avoid any aspiration during swallowing. So, with the aim to allow for the feasibility of an implantable active artificial larynx, and based on our previous investigations (Mialland et al., n.d.; 2023; 2023; 2022) this paper focuses on the stylohyoid and the posterior digastric muscles to evaluate their potential for a real-time and implantable swallowing detection algorithm. Indeed, we have shown that they activate at the beginning of swallowing, predominantly for swallowing, and that they are easily accessible, with no further impairment required during any sensor implantation. So, we measured them with intramuscular electromyography (EMG), along with the surface EMG of the submental muscles, to provide a basis for comparison. The swallowing sound was also measured with an accelerometer, to measure the vibration it generates through the skin, and define a temporal limit for the detection. 4 swallowing tasks and 13 non-swallowing tasks were investigated, to assess the muscles in terms of detection performances and abilities to provide early detection. Sub-groups of participants with similar swallowing, based on the Euclidean distance, were also explored. Thus, we found that the stylohyoid and the posterior digastric outperform the submental muscles and previously reported results in the literature, with increased performances when combined. Besides, the tasks that are the most related to the oral preparatory stage of swallowing tend to provide similar activity than the swallowing tasks, and are responsible for the most drastic drop in performances. Finally, even though we found promising results in terms of earliness, a real-time swallowing detection would benefit both from a stratified approach and from the development of an algorithm that is inherently built around a temporal constraint.},
  archive      = {J_TMRB},
  author       = {Adrien Mialland and Ihab Atallah and Agnès Bonvilain},
  doi          = {10.1109/TMRB.2023.3336960},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {292-301},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Stylohyoid and posterior digastric potential evaluation for a swallowing detection with intramuscular EMG},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Terrain-adaptive exoskeleton control with predictive gait
mode recognition: A pilot study during level walking and stair ascent.
<em>TMRB</em>, <em>6</em>(1), 281–291. (<a
href="https://doi.org/10.1109/TMRB.2024.3349624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different gait modes and transitions correspond to different lower-limb kinetic and kinematic characteristics. To provide suitable assistance during multimodal locomotion on various terrains, finite state machine-based exoskeleton controls are widely adopted, but smooth and safe transitions between different gait modes are still challenging due to the gait mode recognition delay. In view of this, a novel terrain-adaptive, phase-based exoskeleton control is proposed in this study, which features predictive gait mode recognition and accurate gait phase estimation during gait mode transitions. Experiments in real-world terrains indicated that gait mode transitions can be reliably recognized at least 0.232 ± 0.040 gait cycle prior to the beginning of the transitional gait cycle with high accuracy (above 98.5%), enabling the exoskeleton control to predictively modulate the exoskeleton assistance and ensure the user’s safety during gait mode transitions. In addition, a pilot study during level ground walking and stair ascent was also performed in a biomechanical testing environment, and peak hip extension and flexion torques were utilized as performance criteria. Experimental results showed that the exoskeleton assistance significantly reduced the requirements for peak hip extension and flexion torques during both steady-state walking and gait mode transitions, making multimodal locomotion on various terrains less challenging for individuals with physical limitations.},
  archive      = {J_TMRB},
  author       = {Yuepeng Qian and Chuheng Chen and Jingfeng Xiong and Yining Wang and Yuquan Leng and Haoyong Yu and Chenglong Fu},
  doi          = {10.1109/TMRB.2024.3349624},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {281-291},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Terrain-adaptive exoskeleton control with predictive gait mode recognition: A pilot study during level walking and stair ascent},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development and mobile deployment of a stair recognition
system for human–robot locomotion. <em>TMRB</em>, <em>6</em>(1),
271–280. (<a href="https://doi.org/10.1109/TMRB.2024.3349602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environment sensing and recognition can improve the safety and autonomy of human-robot locomotion, especially during transitions between environmental states such as walking to and from stairs. However, accurate and real-time perception on edge devices with limited computational resources is an open problem. Here we present the development and mobile deployment of StairNet, a vision-based stair recognition system powered by deep learning. Building on ExoNet, the largest open-source dataset of egocentric images of real-world walking environments, we designed a new dataset for stair recognition with over 515,000 images. We trained a lightweight and efficient convolutional neural network for image classification, which predicted complex stair environments with 98.4% accuracy. We also studied different model compression optimization methods and deployed our system on several mobile devices running a custom-designed iOS application with onboard accelerators using CPU, GPU, and/or NPU backend computing. Of the designs that we studied, our highest performing system showed negligible reductions in classification accuracy due to model conversion for mobile deployment and achieved an inference time of 2.75 ms. The high speed and accuracy of StairNet on edge devices opens new opportunities for environment-adaptive control of robotic prosthetic legs, exoskeletons, and other assistive technologies for human locomotion.},
  archive      = {J_TMRB},
  author       = {Andrew Garrett Kurbis and Alex Mihailidis and Brokoslaw Laschowski},
  doi          = {10.1109/TMRB.2024.3349602},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {271-280},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Development and mobile deployment of a stair recognition system for Human–Robot locomotion},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of a 2-DoFs actuated wrist for enhancing the
dexterity of myoelectric hands. <em>TMRB</em>, <em>6</em>(1), 257–270.
(<a href="https://doi.org/10.1109/TMRB.2023.3336993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing a prosthetic system that emulates the complexity of the human upper limb is a formidable challenge. Unfortunately, abandonment rates for such devices remain high, primarily due to the limited intuitiveness of control and poor dexterity. Specifically, inadequate wrist mobility, i.e., the absence of actively controllable flexion-extension and pronation-supination degrees of freedom, often results in subpar dexterity in upper limb prostheses. This work introduces an anthropomorphic wrist prosthesis featuring active flexion-extension and pronation-supination capabilities, integrated with the poly-articulated Hannes hand. The central focus of this study is to compare the functionality of this prosthetic system with the natural wrist movement of healthy participants, demonstrating that the biomechanical range of motion falls within that of the mechatronic system. The overarching goal is to improve the performance of trans-radial prostheses by enhancing their dexterity and overall functionality. Our preliminary findings from healthy subjects demonstrate that the incorporation of a 2 Degrees-of-Freedom active biomimetic wrist into the prosthesis can approximate human-like capabilities in upper limb prostheses. Moreover, the resulting development confirm its enhanced dexterity when operated by amputees. These results provide valuable insights into the potential applications of this technology for amputees, offering a basis for future investigations.},
  archive      = {J_TMRB},
  author       = {Nicolò Boccardo and Michele Canepa and Samuel Stedman and Lorenzo Lombardi and Andrea Marinelli and Dario Di Domenico and Riccardo Galviati and Emanuele Gruppioni and Lorenzo De Michieli and Matteo Laffranchi},
  doi          = {10.1109/TMRB.2023.3336993},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {257-270},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Development of a 2-DoFs actuated wrist for enhancing the dexterity of myoelectric hands},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling and assessing hip-knee joint coordination based on
cyclograms using a portable motion capture system. <em>TMRB</em>,
<em>6</em>(1), 245–256. (<a
href="https://doi.org/10.1109/TMRB.2023.3336970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyclograms are useful for describing interjoint coordination in clinical gait analyses. In this paper, we establish a model for generating hip-knee cyclograms at different walking speeds by using B-Spline curves, which could provide reference standards for evaluating hip-knee joint coordination. We use the shape similarity between individual and reference cyclograms to develop a hip-knee joint coordination assessment metric: the dynamic time warping-shape context (DTW-SC). The DTW algorithm is used to match corresponding points between the hip-knee cyclograms, and the matched results are visualized to show abnormal changes in gait patterns. The distance between corresponding points is determined through shape context descriptors and applied to quantify the hip-knee joint coordination of the subjects. To verify the effectiveness of the proposed approach, a stereo vision-based portable lower limb motion capture system is developed to collect hip and knee joint angle data from five healthy and five hemiplegic subjects walking at comfortable speeds. Experimental results show that the range of the modeling error is [0.84°, 2.76°]. DTW-SC metric can visualize and quantify the abnormal patterns of the subject’s hip-knee joint coordination. The work is meaningful in evaluating the hip-knee joint coordination of hemiplegic patients.},
  archive      = {J_TMRB},
  author       = {Ningcun Xu and Chen Wang and Liang Peng and Xiwei Peng and Zeng-Guang Hou and Pu Zhang and Zejia He and Jingyao Chen},
  doi          = {10.1109/TMRB.2023.3336970},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {245-256},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Modeling and assessing hip-knee joint coordination based on cyclograms using a portable motion capture system},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive oscillator-based gait feature extraction method of
hip exoskeleton for stroke patients. <em>TMRB</em>, <em>6</em>(1),
235–244. (<a href="https://doi.org/10.1109/TMRB.2023.3329585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a lower-limb exoskeleton, accurate and timely extraction of gait features, such as the timing of important gait events and walking state transitions, is a fundamental requirement to provide appropriate assistive action, and this becomes much more challenging for stroke patients due to the existence of hemiplegic gait. In view of this, this study develops an adaptive oscillator-based gait feature extraction method only using thigh-worn inertial measurement units (IMUs) for assisting stroke patients with portable hip exoskeletons. The algorithm is capable of 1) estimating the zero position of the thigh during locomotion, 2) estimating the timing of heel strike, and 3) detecting the walking state transition timely. To validate the proposed method, an experimental study with both healthy subjects and stroke patients has been performed, suggesting accurate estimations of the zero position of the thigh and the timing of heel strike, and a lower detection delay of walking state transitions compared to state-of-the-art studies. To the best of the authors’ knowledge, this study represents the first proof of feasibility to extract these gait features of stroke patients with hemiplegic gait only using thigh-worn IMUs, paving the way for future clinical applications of portable hip exoskeletons.},
  archive      = {J_TMRB},
  author       = {Yuepeng Qian and Yining Wang and Hongli Geng and Hao Du and Jingfeng Xiong and Yuquan Leng and Chenglong Fu},
  doi          = {10.1109/TMRB.2023.3329585},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {235-244},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Adaptive oscillator-based gait feature extraction method of hip exoskeleton for stroke patients},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparing metabolic cost and muscle activation for knee and
back exoskeletons in lifting. <em>TMRB</em>, <em>6</em>(1), 224–234. (<a
href="https://doi.org/10.1109/TMRB.2023.3329567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performing heavy manual lifting jobs can be extremely strenuous, often resulting in high rates of injury at overloaded joints. Lower-body exoskeletons have potential to mitigate this fatigue and injury through targeted joint assistance. A variety of current wearable devices aim to provide this kind of support, but their effects on both directly and indirectly targeted joints have not been fully investigated. In this study, a powered bilateral knee exoskeleton (research device), and passive back exosuit (HeroWear Apex) were compared across 10 individuals through a battery of manual lifting tasks. Metabolic, electromyographic, and subject-reported outcome measure data were used to determine which exoskeleton provided the best assistance for each task type. It was found that the knee exoskeleton significantly reduced metabolic cost by $\mathbf {9.6\%}$ compared to the no-exoskeleton baseline $(\mathbf {p &amp;lt; .05})$ . Both the knee and back exoskeletons reduced activation in up to 6 of the muscles measured (out of 16). Importantly, each device primarily reduced muscle activation around the joint it targeted, not around adjacent joints. These findings suggest that exoskeletons that target the knee or lower back joint during lifting can provide significant assistance in reducing exertion.},
  archive      = {J_TMRB},
  author       = {Christoph Nuesslein and Krishan Bhakta and Joshua Fernandez and Felicia Davenport and Jennifer Leestma and Raymond Kim and Dawit Lee and Anirban Mazumdar and Gregory Sawicki and Aaron Young},
  doi          = {10.1109/TMRB.2023.3329567},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {224-234},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Comparing metabolic cost and muscle activation for knee and back exoskeletons in lifting},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel underactuated robotic orthosis for individualized
gait rehabilitation. <em>TMRB</em>, <em>6</em>(1), 213–223. (<a
href="https://doi.org/10.1109/TMRB.2023.3328633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It was observed that repetitive and task-oriented movements can strengthen muscles and improve the walking capabilities among patients experiencing gait impairments due to neurological disorders. However, the traditional physiotherapy is laborious, may not provide desired cadence and gait patterns, and due to the lack of therapists, it remains inaccessible to many patients.In the present work, we propose a novel low-cost treadmill-based underactuated gait rehabilitation exoskeleton that can provide naturalistic lower limb movements during walking. The exoskeleton mechanism has been devised by constraining a planar serial chain formed by revolute joints to resemble the Stephenson III six-bar linkage satisfying the adaptability and the end-effector trajectory requirements. The synthesized mechanism matches the concurrent knee and ankle joint movements during human walking relative to the hip, in terms of position and time. The kinematics and dynamic force analysis of the mechanism formulating the position, velocity, acceleration, and static torque have been presented. A full working lightweight exoskeleton prototype with a single actuated joint has been constructed. A pilot study with a healthy human subject has been performed. As a result, it is found that the proposed exoskeleton can provide naturalistic human motion trajectories suitable for rehabilitation purposes.},
  archive      = {J_TMRB},
  author       = {Akim Kapsalyamov and Shahid Hussain and Nicholas A. T. Brown and Roland Goecke and Prashant K. Jamwal},
  doi          = {10.1109/TMRB.2023.3328633},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {213-223},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A novel underactuated robotic orthosis for individualized gait rehabilitation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Walking on real-world terrain with an ankle exoskeleton in
cerebral palsy. <em>TMRB</em>, <em>6</em>(1), 202–212. (<a
href="https://doi.org/10.1109/TMRB.2023.3328649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite medical treatment focused on addressing walking disability, many millions of people with neurological conditions, like cerebral palsy (CP), struggle to maintain independent mobility. Lower limb exoskeletons and exosuits may hold potential for augmenting walking ability. However, it remains unknown whether these wearable robots are safe and beneficial for use outside of highly controlled laboratory environments, the demonstration of which is necessary for clinical translation. Here, we show that a lightweight, portable, ankle exoskeleton with an adaptable one-size-works-for-all assistance controller can improve energy efficiency and walking speed for individuals with CP spanning a wide spectrum of lower limb impairment in a multi-terrain real-world environment. Tested on an outdoor walking route with level, sloped, and stair terrain, robotic assistance resulted in a 15–18% (p ${=}$ 0.013–0.026) reduction in estimated energy cost and a 7–8% (p ${=}$ 0.001–0.004) increase in average walking speed across “shorter” 6-minute and “longer” 20-minute walking durations relative to unassisted walking. This study provides evidence that wearable robots may soon improve mobility in neighborhood, school, and community settings for individuals with CP.},
  archive      = {J_TMRB},
  author       = {Emmanuella A. Tagoe and Ying Fang and Jack R. Williams and Zachary F. Lerner},
  doi          = {10.1109/TMRB.2023.3328649},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {202-212},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Walking on real-world terrain with an ankle exoskeleton in cerebral palsy},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modulating wrist-hand kinematics in motorized-assisted
grasping with c5-6 spinal cord injury. <em>TMRB</em>, <em>6</em>(1),
189–201. (<a href="https://doi.org/10.1109/TMRB.2023.3328639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loss of hand function severely impacts the independence of people with spinal cord injuries (SCI) between C5 and C7. To achieve limited grasps or strengthen grip around small objects, these individuals commonly employ a compensatory technique to passively induce finger flexion by extending their wrist. Passive body-powered devices using wrist-driven actuation have been developed to assist this function, in addition to advancements in active robotic devices aimed at finger articulation for dexterous manipulation. Nevertheless, neither passive nor active devices see wide adoption and retention in the long-term. Here we present an unconventional system for combining aspects of both passive and active actuation and show that actively modulating the relationship between passive wrist and finger movement can impact both performance and kinematic metrics of upper body compensation. This study comprises six unique case studies of individuals with C5-6 SCI because morphology and response can vary widely across this population. While only some individuals’ performance improved with the shared system over passive-only operation, all six participants stated that they preferred the shared system, regarding added motorization with a sense of trust and embodiment. This outcome motivates the ongoing study of how motors can alter body kinematics to augment body-power without replacing it.},
  archive      = {J_TMRB},
  author       = {Erin Y. Chang and Andrew I. W. McPherson and Ryan C. Adolf and Yuri Gloumakov and Hannah S. Stuart},
  doi          = {10.1109/TMRB.2023.3328639},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {189-201},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Modulating wrist-hand kinematics in motorized-assisted grasping with c5-6 spinal cord injury},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven phase-based control of a powered knee-ankle
prosthesis for variable-incline stair ascent and descent. <em>TMRB</em>,
<em>6</em>(1), 175–188. (<a
href="https://doi.org/10.1109/TMRB.2023.3328656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Powered knee-ankle prostheses can offer benefits over conventional passive devices during stair locomotion by providing biomimetic net-positive work and active control of joint angles. However, many modern control approaches for stair ascent and descent are often limited by time-consuming hand-tuning of user/task-specific parameters, predefined trajectories that remove user volition, or heuristic approaches that cannot be applied to both stair ascent and descent. This work presents a phase-based hybrid kinematic and impedance controller (HKIC) that allows for semi-volitional, biomimetic stair ascent and descent at a variety of step heights. We define a unified phase variable for both stair ascent and descent that utilizes lower-limb geometry to adjust to different users and step heights. We extend our prior data-driven impedance model for variable-incline walking, modifying the cost function and constraints to create a continuously-varying impedance parameter model for stair ascent and descent over a continuum of step heights. Experiments with above-knee amputee participants ( $\text{N}=$ 2) validate that our HKIC controller produces biomimetic ascent and descent joint kinematics, kinetics, and work across four step height configurations. We also show improved kinematic performance with our HKIC controller in comparison to a passive microprocessor-controlled device during stair locomotion.},
  archive      = {J_TMRB},
  author       = {Ross J. Cortino and T. Kevin Best and Robert D. Gregg},
  doi          = {10.1109/TMRB.2023.3328656},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {175-188},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Data-driven phase-based control of a powered knee-ankle prosthesis for variable-incline stair ascent and descent},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simultaneous polyp and lumen detection framework toward
autonomous robotic colonoscopy. <em>TMRB</em>, <em>6</em>(1), 163–174.
(<a href="https://doi.org/10.1109/TMRB.2024.3349623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal Cancer is one of the deadliest diseases with a high incidence and mortality worldwide. Robotic colonoscopes have been extensively developed to provide alternative solutions for colon screening. Nevertheless, most robotic colonoscopes remain a low autonomy level, which leads to non-intuitive manipulation and limits their clinical translation. This paper proposes a deep learning-based framework for simultaneous polyp and lumen detection, which aims to automates robotic colonoscopes to achieve intelligent and autonomous manipulations in two aspects of navigation and diagnosis. Two fully annotated datasets, including a real colon dataset, with 40186 images, and a colon phantom dataset, are developed to facilitate polyp and lumen detection in both clinical and laboratory environments. Benchmarking of various object detection models achieve an average precision of 0.827, and an average recall of 0.866. Experimental validation is conducted in both a commercialized colon phantom and an ex-vivo porcine colon using an electromagnetically actuated soft-tethered colonoscope as a case study, with the results indicate that the colonoscope can successfully perform autonomous navigation and automatic polyp detection under the proposed unified framework. This work promotes clinical applications of robotic colonoscopy by enhancing its autonomy level with artificial intelligence techniques.},
  archive      = {J_TMRB},
  author       = {Wing Yin Ng and Yehui Li and Tianle Pan and Yichong Sun and Qi Dou and Pheng Ann Heng and Philip Wai Yan Chiu and Zheng Li},
  doi          = {10.1109/TMRB.2024.3349623},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {163-174},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {A simultaneous polyp and lumen detection framework toward autonomous robotic colonoscopy},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image-based force localization and estimation of a
micro-scale continuum guidewire robot. <em>TMRB</em>, <em>6</em>(1),
153–162. (<a href="https://doi.org/10.1109/TMRB.2024.3349598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many intravascular procedures are prefaced by the placement of a slender wire called a guidewire. Steering these guidewires is met with challenges in controlling the distal end along with the possibility of damaging vessel walls, or even perforation, which can be fatal. To this end, utilizing robotic guidewires can improve steerability and enable force feedback through intrinsic force sensing. Enabling force sensing contains challenges such as discrete sensor placements in continuous structures and non-unique force distributions for a given deflection. In this work, we utilize image feedback and a Cosserat rod model to estimate and localize forces along the body of a micro-scale tendon-driven guidewire robot. This includes additional modeling of friction and hysteresis that is often neglected for force sensing. The model is tested on a variety of notched nitinol tubes under gravity loading with the shape predictions having an average RMSE of 0.46 mm. Utilization of friction and hysteresis models provide shape predictions with an RMSE of 1.22 mm compared to an uncompensated model (RMSE ${=}$ 1.62 mm) for approximately 180° bends. The methods presented are able to localize forces with an average error of 4.79 mm (5.15% of the length) while force magnitudes are estimated with an average error of 13.03 mN.},
  archive      = {J_TMRB},
  author       = {Timothy A. Brumfiel and Ronghuai Qi and Sharan Ravigopal and Jaydev P. Desai},
  doi          = {10.1109/TMRB.2024.3349598},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {153-162},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Image-based force localization and estimation of a micro-scale continuum guidewire robot},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The SATA-drive: A modular robotic drive for reusable
steerable laparoscopic instruments. <em>TMRB</em>, <em>6</em>(1),
146–152. (<a href="https://doi.org/10.1109/TMRB.2023.3339846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Most robotic instruments and their drives still risk residual contamination due to cleaning complexities, rendering them limited reusable, and tend to have larger instruments than the 5mm laparoscopic standard. The novel steerable laparoscopic SATA-LRS uses modularity for cleanability and exchangeability. The SATA-Drive: a robotic driver designed for the actuation of a 3mm scaled version of the SATA-LRS is presented. Methods: A modular, expandable gear mechanism was designed to efficiently rotate and translate the instrument shafts. The 3mm SATA-LRS is controlled as proof. An user-experiment is conducted to test the (de)coupling of the instrument to and from the drive. Results: A video shows the SATA-Driver successfully articulating, rotating and grasping the end-effector. End-effector dis- and reassembly is possible in 36 (13 SD) seconds, while complete instrument coupling requires 28(8 SD) seconds and de-coupling requires 16 (7 SD) seconds. Discussion: A non-surgical robot arm, mounted with the SATA-drive has effectively been transformed into a system similar to robot assisted laparoscopy. The modularity of the drive’s segmented build can easily be adapted and could benefit the adoption of future instruments. The SATA-LRS’s cleanability features and its end-effector changes without disassembly are expected to benefit medical robotics. The 3mm SATA-LRS shows the instrument’s potential for mini-laparoscopy.},
  archive      = {J_TMRB},
  author       = {Tomas Lenssen and Jenny Dankelman and Tim Horeman},
  doi          = {10.1109/TMRB.2023.3339846},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {146-152},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {The SATA-drive: A modular robotic drive for reusable steerable laparoscopic instruments},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Steady-hand eye robot 3.0: Optimization and benchtop
evaluation for subretinal injection. <em>TMRB</em>, <em>6</em>(1),
135–145. (<a href="https://doi.org/10.1109/TMRB.2023.3336975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subretinal injection methods and other procedures for treating retinal conditions and diseases (many considered incurable) have been limited in scope due to limited human motor control. This study demonstrates the next generation, cooperatively controlled Steady-Hand Eye Robot (SHER 3.0), a precise and intuitive-to-use robotic platform achieving clinical standards for targeting accuracy and resolution for subretinal injections. The system design and basic kinematics are reported and a deflection model for the incorporated delta stage and validation experiments are presented. This model optimizes the delta stage parameters, maximizing the global conditioning index and minimizing torsional compliance. Five tests measuring accuracy, repeatability, and deflection show the optimized stage design achieves a tip accuracy of $ { &amp;lt; 30} {\mu }\text{m}$ , tip repeatability of $ {9.3} {\mu }\text{m}$ and 0.02°, and deflections between 20–350 $ {\mu }\text{m}$ /N. Future work will use updated control models to refine tip positioning outcomes and will be tested on in vivo animal models.},
  archive      = {J_TMRB},
  author       = {Alireza Alamdar and David E. Usevitch and Jiahao Wu and Russell H. Taylor and Peter Gehlbach and Iulian Iordachita},
  doi          = {10.1109/TMRB.2023.3336975},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {135-145},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Steady-hand eye robot 3.0: Optimization and benchtop evaluation for subretinal injection},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating control torque for postural balance among
unilateral lower limb amputees during different visual environments.
<em>TMRB</em>, <em>6</em>(1), 120–134. (<a
href="https://doi.org/10.1109/TMRB.2023.3336969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lower limb impairment leads to the loss of sensory feedback and, as a result, poor postural abnormalities compared to able-bodied individuals. To maintain postural balance during gait initiation, individuals with lower extremity amputation over-depend on visual inputs and somatosensory information from the sound limb. This additional demand leads to higher cognitive load and additional extension and flexion torque in the healthy limb, leading to the unacceptability of current prostheses. In this study, a biomechanically relevant ankle-foot prosthesis model with a fractional order filter-based internal model control-based proportional integral derivative approach was explored to estimate the required control torque on the prosthetic ankle joint during dynamic weight-shifting activities in different visual environments. The results indicate the effectiveness of the proposed approach in adapting the balance uncertainties in different visual conditions. Pilot findings during weight shifting exercises show that the proposed ${f}$ -IMC-PID and traditional IMC-PID controllers present a maximum RMSE between the experimental and achieved lean angles of 0.01371° and 0.08414°, respectively. In addition, the present work compares the two baseline postural models: the shock absorption inverted pendulum model and the inverted pendulum-based virtual model. The present work could potentially reduce the rehabilitation duration by addressing the design-oriented challenges in prosthetic solutions.},
  archive      = {J_TMRB},
  author       = {Sirsendu Sekhar Mishra and Deepak Joshi and Bijaya Ketan Panigrahi},
  doi          = {10.1109/TMRB.2023.3336969},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {120-134},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Estimating control torque for postural balance among unilateral lower limb amputees during different visual environments},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward robotics-assisted endomicroscopy in percutaneous
needle-based interventions. <em>TMRB</em>, <em>6</em>(1), 110–119. (<a
href="https://doi.org/10.1109/TMRB.2023.3337869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Endomicroscopy uses the properties of light to obtain microscopic images of tissue in real-time and provide insights into disease processes. To date, endomicroscopy has primarily been directed against surface/near-surface inflammatory and other conditions, as there is an absence of an integrated technology for directed and automated optical fibre delivery. In this paper, we propose a robotic platform that offers controlled optical imaging in percutaneous interventions. The platform incorporates a concentric tube robot (CTR) to steer a fluorescent imaging probe with cellular and bacterial imaging capability inside soft tissue. Moreover, we develop motion planning algorithms that accept pre-operatively defined regions of interest for imaging and calculate desired insertion configuration and trajectory for reaching the target. Finally, we refine our previous control algorithm to autonomously steer the robot on the pre-planned path toward the target region for endomicroscopic imaging. The platform is tested on phantom tissue with embedded targets. Results demonstrate the feasibility of controlled imaging of target regions at tissue surfaces equal to or bigger than 3 mm and reaching targets inside tissue at a maximum depth of 50 mm. Combining emerging endomicroscopic imaging modalities with continuum robots can enable future research in on-site diagnosis and treatment of infectious diseases.},
  archive      = {J_TMRB},
  author       = {Balint Thamo and Vasiliki Voulgaridou and Harry Wood and James Stone and Kevin Dhaliwal and Mohsen Khadem},
  doi          = {10.1109/TMRB.2023.3337869},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {110-119},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Toward robotics-assisted endomicroscopy in percutaneous needle-based interventions},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design and accuracy assessment of an automated image-guided
robotic osteotomy system. <em>TMRB</em>, <em>6</em>(1), 96–109. (<a
href="https://doi.org/10.1109/TMRB.2023.3339876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-guided robotic spine surgery systems, currently used only for pedicle screw placement, have been in clinical use since 2004. Robotic spine osteotomy (bone removal and shaping), however, is still in the research phase. This article presents the development and evaluation of a KUKA-based image-guided robotic system that automates the osteotomy process, from automatic milling path determination to milling execution, using laminectomy as the experimental paradigm. An approach to quantify milling (overall path) and margin (from thecal sac penetration) accuracy is also described. System accuracy was evaluated in two experiments. In the first, common preoperative images and image fiducial points were used to perform a bilateral laminectomy on 10 identical 3D-printed vertebrae phantoms. In the second, individual preoperative images with individually identified fiducial points were used to perform a bilateral laminectomy on 4 identical 3D-printed vertebrae phantoms. The accuracy results for the first experiment were 0.19 ± 0.16 mm (milling) and 0.69 ± 0.37 mm (margin). For the second, the accuracy results were 0.24 ± 0.15 mm and 0.42 ± 0.26 mm, respectively. The results compare favorably to current accepted clinical standards for laminectomy. The system developed here implements a valuable new role for robotics in spinal surgery.},
  archive      = {J_TMRB},
  author       = {Prathamesh V. Bhagvath and Philippe Mercier and Andrew F. Hall},
  doi          = {10.1109/TMRB.2023.3339876},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {96-109},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Design and accuracy assessment of an automated image-guided robotic osteotomy system},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anatomy-specific optimization of a multi-contact-aided
continuum manipulator. <em>TMRB</em>, <em>6</em>(1), 84–95. (<a
href="https://doi.org/10.1109/TMRB.2023.3328631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgical endoscopes deployable through natural orifices are necessary to facilitate further reduction in invasiveness. However, the constant curvature deflection shapes of conventional instruments may result in tissue damage while navigating narrow tortuous variable curvature anatomy. A multi-contact-aided (MCA) continuum manipulator comprising spatial anisotropic bending shapes was developed previously. In this paper, an efficient numerical solution of the inverse kinematics considering variable joint limitations for real-time motion planning is proposed. Then, an anatomy-specific design optimization framework of the MCA continuum manipulator is also proposed to lower intraoperative injury further. Structure parameters optimization is implemented to obtain the most similar shape to the anatomical airways. The optimized single-section MCA continuum manipulator is capable of executing ”path-following” motion in three dimensional airways with minimal path deviation. Simulated and experimental deployments toward targeted bronchus are conducted to validate the feasibility of the optimization framework of the MCA continuum manipulator. Consequently, the endobronchial intervention experiments over the targeted airway indicate a mean tip deviation error of 6.2% with respect to manipulator length.},
  archive      = {J_TMRB},
  author       = {Xiaojie Ai and Anzhu Gao and Weidong Chen},
  doi          = {10.1109/TMRB.2023.3328631},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {84-95},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Anatomy-specific optimization of a multi-contact-aided continuum manipulator},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anchor-free convolutional neural network application to
enhance real-time surgical tool detection in computer-aided surgery.
<em>TMRB</em>, <em>6</em>(1), 73–83. (<a
href="https://doi.org/10.1109/TMRB.2023.3328658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-aided surgery requires efficient real-time detection of surgical tools. The respective technology should furnish real-time positions of different surgical tools for surgeons or auxiliary robots, improving surgical efficiency and reducing complications. At present, most detection methods of surgical instruments rely on predefined anchor boxes to obtain good detection accuracy. However, they require many complex calculations related to anchor boxes, which may not strike a good balance between detection accuracy and speed. Given the above problem, this study proposes an anchor-free convolutional neural network architecture that avoids complex calculations related to anchor frames and reduces network parameters. It uses the Bridge Network (BriNet18) and the Multiple Cross Stage Path Aggregation Network (MCSPAN) for feature extraction and feature fusion, respectively. In addition, the attention mechanism is incorporated into the output header to enhance the expression ability of the network and improve the network detection performance. This method shows excellent performance on the ATLAS Dione and Cholec80-six datasets, achieving 98.51% mAP@0.5 and 97.60% mAP@0.5 at 56 frames per second, respectively. The experimental results prove that the proposed method is superior to the existing detection methods and truly realizes fast, accurate, and end-to-end detection of surgical tools.},
  archive      = {J_TMRB},
  author       = {He Song and Zijian Zhao and Kaidi Liu and Yanbing Wu and Feng Li},
  doi          = {10.1109/TMRB.2023.3328658},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {73-83},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Anchor-free convolutional neural network application to enhance real-time surgical tool detection in computer-aided surgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite element and fluid-structure interaction modeling of a
balloon catheter. <em>TMRB</em>, <em>6</em>(1), 68–72. (<a
href="https://doi.org/10.1109/TMRB.2023.3332434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intervention treatments for aortic stenosis strongly rely on the use of a medical balloon catheter which is utilized for dilating the narrowed aortic valve or the deployment of the implanted devices. However, the complete inflation of the balloon will block the blood outflow and cause instability. This paper demonstrates a computational analysis method to examine the influence of the amount of balloon inflation volume on balloon movement within a pulsating fluid environment. A tri-folded typical shape of the balloon model was inflated by pressurization. The balloon’s front projection area changes during both simulation and experiment were recorded. To address the interaction between the balloon model with varying inflation levels and the introduction of fluid into the arched aorta, a Fluid-Structure Interaction (FSI) model was developed. Compared with the experimental data, the front projection area in the simulation showed a similar increment, which can be used to validate the balloon model. For FSI simulation, the balloon catheter’s maximum displacement rises with the inflation level, with a slight rise at about 10 ml and a substantial rise at 20 ml volume. This work showed a significant advancement in the ability to replicate balloon movement during valvuloplasty using an FSI model.},
  archive      = {J_TMRB},
  author       = {Junke Yao and Jacob Salmonsmith and Giorgia Maria Bosi and Gaetano Burriesci and Helge Wurdemann},
  doi          = {10.1109/TMRB.2023.3332434},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {68-72},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Finite element and fluid-structure interaction modeling of a balloon catheter},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward safe and collaborative robotic ultrasound tissue
scanning in neurosurgery. <em>TMRB</em>, <em>6</em>(1), 64–67. (<a
href="https://doi.org/10.1109/TMRB.2024.3349626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intraoperative ultrasound imaging is used to facilitate safe brain tumour resection. However, due to challenges with image interpretation and the physical scanning, this tool has yet to achieve widespread adoption in neurosurgery. In this paper, we introduce the components and workflow of a novel, versatile robotic platform for intraoperative ultrasound tissue scanning in neurosurgery. An RGB-D camera attached to the robotic arm allows for automatic object localisation with ArUco markers, and 3D surface reconstruction as a triangular mesh using the ImFusion Suite software solution. Impedance controlled guidance of the US probe along arbitrary surfaces, represented as a mesh, enables collaborative US scanning, i.e., autonomous, teleoperated and hands-on guided data acquisition. A preliminary experiment evaluates the suitability of the conceptual workflow and system components for probe landing on a custom-made soft-tissue phantom. Further assessment in future experiments will be necessary to prove the effectiveness of the presented platform.},
  archive      = {J_TMRB},
  author       = {Michael Dyck and Alistair Weld and Julian Klodmann and Alexander Kirst and Luke Dixon and Giulio Anichini and Sophie Camp and Alin Albu-Schäffer and Stamatia Giannarou},
  doi          = {10.1109/TMRB.2024.3349626},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {64-67},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Toward safe and collaborative robotic ultrasound tissue scanning in neurosurgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation of communication and human response latency for
(human) teleoperation. <em>TMRB</em>, <em>6</em>(1), 53–63. (<a
href="https://doi.org/10.1109/TMRB.2024.3349612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We previously introduced a novel mixed reality teleguidance system dubbed human teleoperation (David Black et al., 2023 and Black and Salcudean, 2023), in which a human (expert) leader and a human (novice) follower are tightly coupled through mixed reality and haptics. Our first evaluation of human teleoperation is in the context of tele ultrasound, in which a sonographer or radiologist’s gestures are copied by a remote novice to carry out an ultrasound examination. In this paper, a communication system suitable for implementation of human teleoperation is presented and characterized in various network conditions, over Ethernet, Wi-Fi, 4G LTE, and 5G. To obtain a full understanding of latency in the system, the human response time is additionally characterized through a series of step response tests with 11 volunteers. The step responses were obtained by tracking the position of, and force exerted by, the human hand in response to a change in the mixed reality target. Different rendering methods were evaluated. The round-trip communication latency is 40 ± 10 ms over 5G, and down to 1 ± 0.6 ms over Ethernet for typical throughputs. The human response time to a step change in position depends on the step magnitude, but is between 485 to 535 ms, while the reaction time to a change in force is 150 to 200 ms. Both lag times are greatly decreased when tracking a smooth motion. Thus, we demonstrate that the system is network agnostic and can achieve good teleoperation performance and secure, low latency communication in appropriate network conditions. This brings the human teleoperation concept a step closer to human trials in a clinical environment, and the presented tools and concepts are applicable to any high-performance teleoperation system, and especially for mixed reality guidance.},
  archive      = {J_TMRB},
  author       = {David G. Black and Dragan Andjelic and Septimiu E. Salcudean},
  doi          = {10.1109/TMRB.2024.3349612},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {53-63},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Evaluation of communication and human response latency for (Human) teleoperation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ultrasound plane pose regression: Assessing generalized pose
coordinates in the fetal brain. <em>TMRB</em>, <em>6</em>(1), 41–52. (<a
href="https://doi.org/10.1109/TMRB.2023.3328638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In obstetric ultrasound (US) scanning, the learner’s ability to mentally build a three-dimensional (3D) map of the fetus from a two-dimensional (2D) US image represents a significant challenge in skill acquisition. We aim to build a US plane localization system for 3D visualization, training, and guidance without integrating additional sensors. This work builds on top of our previous work, which predicts the six-dimensional (6D) pose of arbitrarily oriented US planes slicing the fetal brain with respect to a normalized reference frame using a convolutional neural network (CNN) regression network. Here, we analyze in detail the assumptions of the normalized fetal brain reference frame and quantify its accuracy with respect to the acquisition of transventricular (TV) standard plane (SP) for fetal biometry. We investigate the impact of registration quality in the training and testing data and its subsequent effect on trained models. Finally, we introduce data augmentations and larger training sets that improve the results of our previous work, achieving median errors of $2.97~mm$ and 6.63° for translation and rotation, respectively.},
  archive      = {J_TMRB},
  author       = {Chiara Di Vece and Maela Le Lous and Brian Dromey and Francisco Vasconcelos and Anna L. David and Donald Peebles and Danail Stoyanov},
  doi          = {10.1109/TMRB.2023.3328638},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {41-52},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Ultrasound plane pose regression: Assessing generalized pose coordinates in the fetal brain},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design of an MRI compatible steerable guide for MRI-guided
laser interstitial thermal therapy. <em>TMRB</em>, <em>6</em>(1), 30–40.
(<a href="https://doi.org/10.1109/TMRB.2023.3332433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser interstitial thermal therapy (LITT) may generate precise ablative lesions under real-time magnetic resonance imaging (MRI) for the treatment of epilepsy and brain tumors. The Visualase Thermal Therapy System (Medtronic, Inc, MN, USA) is a minimally-invasive LITT platform that delivers laser light through a fiber-optic cable ensheathed in a cooling catheter. Currently, the system may create ablation lesions of a 1cm sphere along a linear trajectory. However, lesions larger than 1cm in diameter, small irregularly shaped lesions, or targets surrounded by critical structures may require multiple probe placements for complete treatment. In this paper, the design and prototype of a novel ‘Steerable Guide for the Visualase LITT system’ is presented. The system enables deployment of the laser fiber along a controlled curved trajectory and may treat lesions up to 5cm in diameter through a single insertion. Catheter insertion experiments were performed in tissue-mimicking phantoms to investigate the safety and accuracy of system. The system was able to achieve a curved trajectory with up to 25 mm tip displacement and allowed the optical fiber to be inserted along the curved trajectory. The average and standard deviation of tip position error between predicted and actual position was 0.33mm and 0.22mm, respectively.},
  archive      = {J_TMRB},
  author       = {Jin Seob Kim and Ryan R. Fischer and Iahn Cajigas and Michael E. Ivan and Doyoung Chang},
  doi          = {10.1109/TMRB.2023.3332433},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {30-40},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Design of an MRI compatible steerable guide for MRI-guided laser interstitial thermal therapy},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep reinforcement learning for concentric tube robot path
following. <em>TMRB</em>, <em>6</em>(1), 18–29. (<a
href="https://doi.org/10.1109/TMRB.2023.3310037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As surgical interventions trend towards minimally invasive approaches, Concentric Tube Robots (CTRs) have been explored for various interventions such as brain, eye, fetoscopic, lung, cardiac, and prostate surgeries. Arranged concentrically, each tube is rotated and translated independently to move the robot end-effector position, making kinematics and control challenging. Classical model-based approaches have been previously investigated with developments in deep learning-based approaches outperforming more classical approaches in both forward kinematics and shape estimation. We propose a deep reinforcement learning approach to control where we generalize across two to four systems, an element not yet achieved in any other deep learning approach for CTRs. In this way, we explore the likely robustness of the control approach. Also investigated is the impact of rotational constraints applied on tube actuation and the effects on error metrics. We evaluate inverse kinematics errors and tracking errors for path-following tasks and compare the results to those achieved using state-of-the-art methods. Additionally, as current results are performed in simulation, we also investigate a domain transfer approach known as domain randomization and evaluate error metrics as an initial step toward hardware implementation. Finally, we compare our method to a Jacobian approach found in the literature.},
  archive      = {J_TMRB},
  author       = {Keshav Iyengar and Sarah Spurgeon and Danail Stoyanov},
  doi          = {10.1109/TMRB.2023.3310037},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {18-29},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Deep reinforcement learning for concentric tube robot path following},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Screw-tip soft magnetically steerable needles.
<em>TMRB</em>, <em>6</em>(1), 4–17. (<a
href="https://doi.org/10.1109/TMRB.2023.3265721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new paradigm in steerable needles comprising flexible tubing with a screw tip and a permanent magnet near the tip. The needle is rotated at its proximal end as the primary mechanism of insertion, rather than being pushed, enabling the screw tip to pull itself through the tissue as it is steered via magnetic torque. Our design enables turns with tighter curvature than previous designs, and it circumvents a well-known problem with existing steerable needles: it is challenging to turn more than 90degrees without inducing damage. We evaluate our needle via human-in-the-loop robot-assisted magnetic steering in a brain-simulating gel tissue phantom, wherein we achieve a radius of curvature of 29 mm with 210degrees of turning for a needle with a functional lumen. In a needle without the lumen we achieve a minimum radius of curvature of 10.1 mm. We further evaluate the needle in ex-vivo ovine brain via open-loop steering. We characterize the steerability of the needles as a function of independent parameters. The results demonstrate a needle that promises significantly improved steerability and safety, particularly for use in delicate tissues that create the greatest challenges for existing designs.},
  archive      = {J_TMRB},
  author       = {Adam J. Sperry and Trevor J. Schwehr and Emma K. Pinegar and Olivia B. Richards and John D. Rolston and Matthew D. Alexander and Brittany Coats and Jake J. Abbott and Alan Kuntz},
  doi          = {10.1109/TMRB.2023.3265721},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {4-17},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Screw-tip soft magnetically steerable needles},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guest editorial special section on the hamlyn symposium
2022—MedTech reimagined. <em>TMRB</em>, <em>6</em>(1), 2–3. (<a
href="https://doi.org/10.1109/TMRB.2024.3352951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of medical robotics is rapidly evolving, and many new concepts and developments have recently been proposed. New surgical robotic systems, like the latest da Vinci Surgical system, can provide high precision and dexterity enabling surgeons to perform highly complex procedures with small incisions or a single incision which can greatly reduce the trauma to patients. The next generation of robotic surgery will be centered in three main areas: i) Miniaturization: Continued efforts to miniaturize surgical robots allowing for less invasive procedures and greater maneuverability within the human body, and which can further reduce trauma, the risk of post-operative complications and shorten the recovery time; ii) Artificial Intelligence (AI): Given the recent advances in AI, more intelligent assistive and automated functions will be provided by surgical robotic systems and which can greatly enhance the surgical precision and real-time decision making; iii) Sensory and haptic feedback: New sensing and haptic feedback technologies will be integrated into the miniaturized surgical robotic systems providing the surgeons with a sense of touch and texture during the robot-assisted surgery, and which can improve the accuracy and safety of the operations.},
  archive      = {J_TMRB},
  author       = {Benny P. L. Lo and Kwok Wai Samuel Au and Philip Wai Yan Chiu},
  doi          = {10.1109/TMRB.2024.3352951},
  journal      = {IEEE Transactions on Medical Robotics and Bionics},
  month        = {2},
  number       = {1},
  pages        = {2-3},
  shortjournal = {IEEE Tran. Med. Robot. Bionics},
  title        = {Guest editorial special section on the hamlyn symposium 2022—MedTech reimagined},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
