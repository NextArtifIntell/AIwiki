<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TROB_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="trob---269">TROB - 269</h2>
<ul>
<li><details>
<summary>
(2024). Radar instance transformer: Reliable moving instance
segmentation in sparse radar point clouds. <em>TROB</em>, <em>40</em>,
2357–2372. (<a href="https://doi.org/10.1109/TRO.2023.3338972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The perception of moving objects is crucial for autonomous robots performing collision avoidance in dynamic environments. LiDARs and cameras tremendously enhance scene interpretation but do not provide direct motion information and face limitations under adverse weather. Radar sensors overcome these limitations and provide Doppler velocities, delivering direct information on dynamic objects. In this article, we address the problem of moving instance segmentation in radar point clouds to enhance scene interpretation for safety-critical tasks. Our radar instance transformer enriches the current radar scan with temporal information without passing aggregated scans through a neural network. We propose a full-resolution backbone to prevent information loss in sparse point cloud processing. Our instance transformer head incorporates essential information to enhance segmentation but also enables reliable, class-agnostic instance assignments. In sum, our approach shows superior performance on the new moving instance segmentation benchmarks, including diverse environments, and provides model-agnostic modules to enhance scene interpretation.},
  archive      = {J_TROB},
  author       = {Matthias Zeller and Vardeep S. Sandhu and Benedikt Mersch and Jens Behley and Michael Heidingsfeld and Cyrill Stachniss},
  doi          = {10.1109/TRO.2023.3338972},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {2357-2372},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Radar instance transformer: Reliable moving instance segmentation in sparse radar point clouds},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiagent reinforcement learning: Rollout and policy
iteration for POMDP with application to multirobot problems.
<em>TROB</em>, <em>40</em>, 2003–2023. (<a
href="https://doi.org/10.1109/TRO.2023.3347128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider the computational and communication challenges of partially observable multiagent sequential decision-making problems. We present algorithms that simultaneously or sequentially optimize the agents&#39; controls by using multistep lookahead, truncated rollout with a known base policy, and a terminal cost function approximation. In particular: 1) we consider multiagent rollout algorithms that dramatically reduce required computation while preserving the key policy improvement property of the standard rollout method. We improve our multiagent rollout policy by incorporating it in an offline approximate policy iteration scheme, and we apply an additional “online play” scheme enhancing offline approximation architectures; 2) we consider the imperfect communication case and provide various extensions to our rollout methods to deal with this case; and 3) we demonstrate the performance of our methods in extensive simulations by applying our method to a challenging partially observable multiagent sequential repair problem (state space size $10^{37}$ and control space size $10^{7}$ ). Our extensive simulations demonstrate that our methods produce better policies for large and complex multiagent problems in comparison with existing methods, including POMCP, MADDPG, and work well where other methods fail to scale up.},
  archive      = {J_TROB},
  author       = {Sushmita Bhattacharya and Siva Kailas and Sahil Badyal and Stephanie Gil and Dimitri Bertsekas},
  doi          = {10.1109/TRO.2023.3347128},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {2003-2023},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Multiagent reinforcement learning: Rollout and policy iteration for POMDP with application to multirobot problems},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Avoidance of concave obstacles through rotation of nonlinear
dynamics. <em>TROB</em>, <em>40</em>, 1983–2002. (<a
href="https://doi.org/10.1109/TRO.2023.3344034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling complex tasks in robotic systems, such as circular motion for cleaning or following curvy lines, can be dealt with using nonlinear vector fields. This article introduces a novel approach called the rotational obstacle avoidance method (ROAM) for adapting the initial dynamics when obstacles partially occlude the workspace. ROAM presents a closed-form solution that effectively avoids star-shaped obstacles in spaces of arbitrary dimensions by rotating the initial dynamics toward the tangent space. The algorithm enables navigation within obstacle hulls and can be customized to actively move away from surfaces while guaranteeing the presence of only a single saddle point on the boundary of each obstacle. We introduce a sequence of mappings to extend the approach for general nonlinear dynamics. Moreover, ROAM extends its capabilities to handle multiobstacle environments and provides the ability to constrain dynamics within a safe tube. By utilizing weighted vector-tree summation, we successfully navigate around general concave obstacles represented as a tree-of-stars. Through experimental evaluation, ROAM demonstrates superior performance in minimizing occurrences of local minima and maintaining similarity to the initial dynamics, outperforming existing approaches in multiobstacle simulations. Due to its simplicity, the proposed method is highly reactive and can be applied effectively in dynamic environments. This was demonstrated during the collision-free navigation of a 7-degree-of-freedom robot arm around dynamic obstacles.},
  archive      = {J_TROB},
  author       = {Lukas Huber and Jean-Jacques Slotine and Aude Billard},
  doi          = {10.1109/TRO.2023.3344034},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {1983-2002},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Avoidance of concave obstacles through rotation of nonlinear dynamics},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simplified continuous high-dimensional belief space planning
with adaptive probabilistic belief-dependent constraints. <em>TROB</em>,
<em>40</em>, 1684–1705. (<a
href="https://doi.org/10.1109/TRO.2023.3341625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online decision making under uncertainty in partially observable domains, also known as Belief Space Planning, is a fundamental problem in Robotics and Artificial Intelligence. Due to an abundance of plausible future unravelings, calculating an optimal course of action inflicts an enormous computational burden on the agent. Moreover, in many scenarios, e.g., Information gathering, it is required to introduce a belief-dependent constraint. Prompted by this demand, in this article, we consider a recently introduced probabilistic belief-dependent constrained partially observable Markov decision process (POMDP). We present a technique to adaptively accept or discard a candidate action sequence with respect to a probabilistic belief-dependent constraint, before expanding a complete set of sampled future observations episodes and without any loss in accuracy. Moreover, using our proposed framework, we contribute an adaptive method to find a maximal feasible return (e.g., Information Gain) in terms of Value at Risk and a corresponding action sequence, given a set of candidate action sequences, with substantial acceleration. On top of that, we introduce an adaptive simplification technique for a probabilistically constrained setting. Such an approach provably returns an identical-quality solution while dramatically accelerating the online decision making. Our universal framework applies to any belief-dependent constrained continuous POMDP with parameteric beliefs, as well as nonparameteric beliefs represented by particles. In the context of an information-theoretic constraint, our presented framework stochastically quantifies if a cumulative Information Gain along the planning horizon is sufficiently significant (for e.g., Information Gathering, active simultaneous localization and mapping (SLAM)). As a case study, we apply our method to two challenging problems of high dimensional belief space planning: active SLAM and sensor deployment. Extensive realistic simulations corroborate the superiority of our proposed ideas.},
  archive      = {J_TROB},
  author       = {Andrey Zhitnikov and Vadim Indelman},
  doi          = {10.1109/TRO.2023.3341625},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {1684-1705},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Simplified continuous high-dimensional belief space planning with adaptive probabilistic belief-dependent constraints},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed coverage hole prevention for visual
environmental monitoring with quadcopters via nonsmooth control barrier
functions. <em>TROB</em>, <em>40</em>, 1546–1565. (<a
href="https://doi.org/10.1109/TRO.2023.3347132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a distributed coverage control strategy for quadcopters equipped with downward-facing cameras that prevents the appearance of unmonitored areas in between the quadcopters&#39; fields of view (FOVs). We derive a necessary and sufficient condition for eliminating any unsurveilled area that may arise in between the FOVs among a trio of quadcopters by utilizing a power diagram, i.e., a weighted Voronoi diagram defined by radii of FOVs. Because this condition can be described as logically combined constraints, we leverage nonsmooth control barrier functions (NCBFs) to prevent the appearance of unmonitored areas among a team&#39;s FOV. We then investigate the symmetric properties of the proposed NCBFs to develop a distributed algorithm. The proposed algorithm can support the switching of the NCBFs caused by changes of the quadcopters composing trios. The existence of the control input satisfying NCBF conditions is analyzed by employing the characteristics of the power diagram. The proposed framework is synthesized with a coverage control law that maximizes the monitoring quality while reducing overlaps of FOVs. The proposed method is demonstrated in simulation and experiment.},
  archive      = {J_TROB},
  author       = {Riku Funada and María Santos and Ryuichi Maniwa and Junya Yamauchi and Masayuki Fujita and Mitsuji Sampei and Magnus Egerstedt},
  doi          = {10.1109/TRO.2023.3347132},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {1546-1565},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Distributed coverage hole prevention for visual environmental monitoring with quadcopters via nonsmooth control barrier functions},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online camera–LiDAR calibration monitoring and rotational
drift tracking. <em>TROB</em>, <em>40</em>, 1527–1545. (<a
href="https://doi.org/10.1109/TRO.2023.3347130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relative poses of visual perception sensors distributed over a vehicle&#39;s body may vary due to dynamic forces, thermal dilations, or minor accidents. This article proposes two methods, Online CAlibration MOnitoring (OCAMO) and LTO, that monitor and track the LiDAR–camera extrinsic calibration parameters online. Calibration monitoring provides a certificate for reference-calibration parameters validity. Tracking follows the calibration parameters drift in time. OCAMO is based on an adaptive online stochastic optimization with a memory of past evolution. LTO uses a fixed-grid search for the optimal parameters per frame and without memory. Both methods use low-level point-like features, a robust kernel-based loss function, and work with a small memory footprint and computational overhead. Both include a preselection of informative data, which limits their divergence. The statistical accuracy of both calibration monitoring methods is over 98%, whereas OCAMO monitoring can detect small decalibrations better, and LTO monitoring reacts faster on abrupt decalibrations. The tracking variants of both methods follow random calibration drift with an accuracy of about $\mathbf {0.03^\circ }$ in the yaw angle.},
  archive      = {J_TROB},
  author       = {Jaroslav Moravec and Radim Šára},
  doi          = {10.1109/TRO.2023.3347130},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {1527-1545},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Online Camera–LiDAR calibration monitoring and rotational drift tracking},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Singularity-free lagrange-poincaré equations on lie groups
for vehicle-manipulator systems. <em>TROB</em>, <em>40</em>, 1393–1409.
(<a href="https://doi.org/10.1109/TRO.2023.3347136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been long known that the Euler–Lagrange dynamical equations of fixed-base manipulators with single-degree-of-freedom joints can be formulated on Lie groups following exponential joint parameterizations. Whereas, dynamics of symmetric vehicles can be captured using the Euler–Poincaré equations on Lie groups, with no need to choose any local parameterization. We utilize a combined form of these two geometric approaches called the Lagrange–Poincaré Equations (LPE) to develop a singularity-free Lagrangian formalism for the dynamics of vehicle-manipulator systems. We consider vehicles whose configuration manifolds are Lie subgroups of the special Euclidean group, encompassing arbitrary base vehicle motions corresponding to, e.g., ball, planar, or free joints. We revisit the Lagrange-d&#39;Alembert principle for systems on principal bundles to derive the LPE for vehicle-manipulators with possibly symmetry-breaking externally applied wrenches. These equations effectively separate the external (locked-arm system) and internal dynamics (arm&#39;s motion) by introducing a block-diagonalized inertia matrix. We then incorporate the exponential parameterization of manipulators to explicitly formulate the reduced dynamics on Lie groups. The resulting equations are in matrix form and can be immediately implemented in simulations and model-based control strategies. The geometrical significance of the proposed formalism is further demonstrated via the step-by-step presentation of a case study.},
  archive      = {J_TROB},
  author       = {Borna Monazzah Moghaddam and Robin Chhabra},
  doi          = {10.1109/TRO.2023.3347136},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {1393-1409},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Singularity-free lagrange-poincaré equations on lie groups for vehicle-manipulator systems},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Receding horizon re-ordering of multi-agent execution
schedules. <em>TROB</em>, <em>40</em>, 1356–1372. (<a
href="https://doi.org/10.1109/TRO.2023.3344051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trajectory planning for a fleet of automated guided vehicles (AGVs) on a roadmap is commonly referred to as the multi-agent path finding (MAPF) problem, the solution to which dictates each AGV&#39;s spatial and temporal location until it reaches its goal without collision. When executing MAPF plans in dynamic workspaces, AGVs can be frequently delayed, e.g., due to encounters with humans or third-party vehicles. If the remainder of the AGVs keeps following their individual plans, synchrony of the fleet is lost and some AGVs may pass through roadmap intersections in a different order than originally planned. Although this could reduce the cumulative route completion time of the AGVs, generally, a change in the original ordering can cause conflicts, such as deadlocks. In practice, synchrony is therefore often enforced by using a MAPF execution policy employing, e.g., an action dependency graph (ADG) to maintain ordering. To safely re-order without introducing deadlocks, we present the concept of the switchable action dependency graph (SADG). Using the SADG, we formulate a comparatively low-dimensional mixed-integer linear program that repeatedly re-orders AGVs in a recursively feasible manner, thus maintaining deadlock-free guarantees, while dynamically minimizing the cumulative route completion time of all AGVs. Various simulations validate the efficiency of our approach when compared to the original ADG method as well as robust MAPF solution approaches.},
  archive      = {J_TROB},
  author       = {Alexander Berndt and Niels van Duijkeren and Luigi Palmieri and Alexander Kleiner and Tamás Keviczky},
  doi          = {10.1109/TRO.2023.3344051},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {1356-1372},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Receding horizon re-ordering of multi-agent execution schedules},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient global trajectory planner for highly dynamical
nonholonomic autonomous vehicles on 3-d terrains. <em>TROB</em>,
<em>40</em>, 1309–1326. (<a
href="https://doi.org/10.1109/TRO.2023.3344030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel hierarchical global trajectory planner is presented to allow highly dynamical nonholonomic off-road autonomous vehicles to achieve high mobility on 3-D terrains. On complex terrains with uneven topology, designing safe and feasible vehicle trajectories often demands an understanding of the vehicle&#39;s dynamical and nonholonomic constraints. Prior research, however, treats the global planning problem as a path planning problem without effectively accounting for topology or dynamical constraints. To address this gap, this article presents a three-phase trajectory planning algorithm composed of an A*, a rapidly exploring random tree (RRT), and a local trajectory refining (LTR) phase to incorporate dynamical and nonholonomic constraints on uneven terrain. The algorithm is tested in scenarios with randomized terrain fields and obstacles to demonstrate the necessity for all three phases. The algorithm is shown to have lower cost, higher success rate, and higher computational efficiency compared to state-of-the-art methods. The algorithm is then tested by controlling a simulated MRZR vehicle on a 3-D terrain along with a local controller, with comparisons to state-of-the-art algorithms. It is demonstrated that the new algorithm is capable of planning dynamically feasible trajectories with lower cost where the state-of-the-art algorithms fail to perform due to neglecting dynamical vehicle limitations.},
  archive      = {J_TROB},
  author       = {Congkai Shen and Siyuan Yu and Bogdan I. Epureanu and Tulga Ersal},
  doi          = {10.1109/TRO.2023.3344030},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {1309-1326},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An efficient global trajectory planner for highly dynamical nonholonomic autonomous vehicles on 3-D terrains},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simultaneous localization and actuation using
electromagnetic navigation systems. <em>TROB</em>, <em>40</em>,
1292–1308. (<a href="https://doi.org/10.1109/TRO.2023.3340324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote magnetic navigation provides a promising approach for improving the maneuverability and safety of surgical tools, such as catheters and endoscopes, in complex anatomies. The lack of existing localization systems compatible with this modality, beyond fluoroscopy and its harmful ionizing radiation, impedes its translation to clinical practice. To address this challenge, we propose a localization method that achieves full pose estimation by superimposing oscillating magnetic fields for localization onto actuation fields generated by an electromagnetic navigation system. The resulting magnetic field is measured using a three-axis magnetic field sensor embedded in the magnetic device to be localized. The method is evaluated on a three-coil system, and simultaneous actuation and localization is demonstrated with a magnetic catheter prototype with a Hall effect sensor embedded at its tip. We demonstrate position estimation with mean accuracy and precision below 1 mm, and orientation estimation with mean errors below 2 $^\circ$ at 10 Hz in a workspace of 80 × 80 × 60 mm. This contribution aims to advance the clinical adoption of remote magnetic navigation in minimally invasive surgery.},
  archive      = {J_TROB},
  author       = {Denis von Arx and Cedric Fischer and Harun Torlakcik and Salvador Pané and Bradley J. Nelson and Quentin Boehler},
  doi          = {10.1109/TRO.2023.3340324},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {1292-1308},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Simultaneous localization and actuation using electromagnetic navigation systems},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Active learning of discrete-time dynamics for
uncertainty-aware model predictive control. <em>TROB</em>, <em>40</em>,
1273–1291. (<a href="https://doi.org/10.1109/TRO.2023.3339543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based control requires an accurate model of the system dynamics for precisely and safely controlling the robot in complex and dynamic environments. Moreover, in presence of variations in the operating conditions, the model should be continuously refined to compensate for dynamics changes. In this article, we present a self-supervised learning approach that actively models the dynamics of nonlinear robotic systems. We combine offline learning from past experience and online learning from current robot interaction with the unknown environment. These two ingredients enable a highly sample-efficient and adaptive learning process, capable of accurately inferring model dynamics in real-time even in operating regimes that greatly differ from the training distribution. Moreover, we design an uncertainty-aware model predictive controller that is heuristically conditioned to the aleatoric (data) uncertainty of the learned dynamics. This controller actively chooses the optimal control actions that i) optimize the control performance, and ii) improve the efficiency of online learning sample collection. We demonstrate the effectiveness of our method through a series of challenging real-world experiments using a quadrotor system. Our approach showcases high resilience and generalization capabilities by consistently adapting to unseen flight conditions, while it significantly outperforms classical and adaptive control baselines. 1 1Video: https://youtu.be/QmEhSTcWob4},
  archive      = {J_TROB},
  author       = {Alessandro Saviolo and Jonathan Frey and Abhishek Rathod and Moritz Diehl and Giuseppe Loianno},
  doi          = {10.1109/TRO.2023.3339543},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {1273-1291},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Active learning of discrete-time dynamics for uncertainty-aware model predictive control},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Magnetorheological-actuators: An enabling technology for
fast, safe, and practical collaborative robots. <em>TROB</em>,
<em>40</em>, 1261–1272. (<a
href="https://doi.org/10.1109/TRO.2023.3341573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative robots are more and more used in applications requiring robots and humans to work in proximity or direct contact. However, conventional collaborative robots powered by servo-geared actuators are intrinsically dangerous due to their high reflected inertia. Recent studies have shown that low inertia and high bandwidth (&gt; 30 Hz) magnetorheological (MR) actuators have the potential to improve the safety of collaborative robots without reducing their force and speed capabilities. The main contribution of this article is to provide a quantitative assessment of how MR actuators can contribute to reducing the impact forces with humans, and thus increase the safety of collaborative robots. Dynamic models, validated with simplified 1 degrees-of-freedom (experiments, show that the safety level of collaborative robots can be increased by a factor up to 3 only by changing the conventional servo-geared actuator architectures for MR actuators with no other changes. The article also presents a simple, reliable, and fast collision detection method based on joint angular velocity band-pass filtering, a method exploiting the unique low inertia and clean dynamics properties of MR actuators. Finally, an experimental comparison of representative collaborative robots demonstrates an impact force reduction of 10 times using MR actuators, fast collision detection, and passive foam padding.},
  archive      = {J_TROB},
  author       = {Alexandre St-Jean and Francis Dorval and Jean-Sébastien Plante and Alexis Lussier-Desbiens},
  doi          = {10.1109/TRO.2023.3341573},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {1261-1272},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Magnetorheological-actuators: An enabling technology for fast, safe, and practical collaborative robots},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Millimeter-level pick and peg-in-hole task achieved by
aerial manipulator. <em>TROB</em>, <em>40</em>, 1242–1260. (<a
href="https://doi.org/10.1109/TRO.2023.3338956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving accurate control performance of the end-effector is critical for practical applications of aerial manipulator. However, due to the presence of floating-base disturbance from the unmanned aerial vehicle (UAV) platform and the kinematic error amplification effect from multilink structure of the manipulator, it is extremely challenging to ensure the high-precision performance of aerial manipulator. Building upon the philosophy of disturbance rejection, we propose a predictive optimization scheme that allows aerial manipulator to successfully execute millimeter-level flying pick and peg-in-hole task. First, the error amplification effect of the floating base is quantitatively analyzed by virtue of the aerial manipulator kinematics. Intuitively, it is found that if the further motion of the UAV platform is well predicted, the manipulator can directly counteract the floating disturbance by following a modified reference trajectory. Hence, a learning-based prediction approach is leveraged to rapidly forecast the UAV platform motion online. Subsequently, an optimization controller is formulated to follow the reference trajectory by incorporating multiple practical constraints of aerial manipulator. Flight tests demonstrate that this study goes a step further to achieve higher accuracy of the end-effector than the existing results (centimeter-level).},
  archive      = {J_TROB},
  author       = {Meng Wang and Zeshuai Chen and Kexin Guo and Xiang Yu and Youmin Zhang and Lei Guo and Wei Wang},
  doi          = {10.1109/TRO.2023.3338956},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {1242-1260},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Millimeter-level pick and peg-in-hole task achieved by aerial manipulator},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multihypotheses importance density for SLAM in cluttered
scenarios. <em>TROB</em>, <em>40</em>, 1019–1035. (<a
href="https://doi.org/10.1109/TRO.2023.3338975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most fundamental problems in simultaneous localization and mapping (SLAM) is the ability to take into account data association (DA) uncertainties. In this article, this problem is addressed by proposing a multihypotheses sampling distribution for particle filtering-based SLAM algorithms. By modeling the measurements and landmarks as random finite sets, an importance density approximation that incorporates DA uncertainties is derived. Then, a tractable Gaussian mixture model approximation of the multihypotheses importance density is proposed, in which each mixture component represents a different DA. Finally, an iterative method for approximating the mixture components of the sampling distribution is utilized and a partitioned update strategy is developed. Using synthetic and experimental data, it is demonstrated that the proposed importance density improves the accuracy and robustness of landmark-based SLAM in cluttered scenarios over state-of-the-art methods. At the same time, the partitioned update strategy makes it possible to include multiple DA hypotheses in the importance density approximation, leading to a favorable linear complexity scaling, in terms of the number of landmarks in the field-of-view.},
  archive      = {J_TROB},
  author       = {Ossi Kaltiokallio and Roland Hostettler and Yu Ge and Hyowon Kim and Jukka Talvitie and Henk Wymeersch and Mikko Valkama},
  doi          = {10.1109/TRO.2023.3338975},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {1019-1035},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A multihypotheses importance density for SLAM in cluttered scenarios},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Delayed self-reinforcement to reduce deformation during
decentralized flexible-object transport. <em>TROB</em>, <em>40</em>,
999–1018. (<a href="https://doi.org/10.1109/TRO.2023.3343997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent works have investigated bio-inspired strategies to transport objects using decentralized robot networks that only use local measurements without the need for communication between robots. Typically, there is an inverse relationship between the object deformation and the transport time, i.e., reducing the object deformation requires an increase in the transport time needed for transitioning from the initial configuration to the final configuration of the object. In contrast, the main contribution in this article is the development of a delayed self-reinforcement (DSR) approach that seeks to decentralize the ideal centralized transport that has no object deformation, and thereby, reduces the object deformation without increasing the transport time for the same specified transport trajectory. In the DSR method, each robot only uses already available prior-information to reinforce each robot&#39;s actions, and thus, the DSR implementation does not require additional information or changes in the network structure. Another contribution in this article is to analyze the potentially time-varying dynamics to establish conditions on the control parameters for stability and quantify the performance of the proposed DSR-based transport. Furthermore, experimental results are presented to show that the proposed cohesive transport method can reduce the deformation by at least 72% for the same transport time, when compared with the case without DSR.},
  archive      = {J_TROB},
  author       = {Yoshua Gombo and Anuj Tiwari and Mohamed Safwat and Henry Chang and Santosh Devasia},
  doi          = {10.1109/TRO.2023.3343997},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {999-1018},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Delayed self-reinforcement to reduce deformation during decentralized flexible-object transport},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cutaneous/tactile haptic feedback in robotic teleoperation:
Motivation, survey, and perspectives. <em>TROB</em>, <em>40</em>,
978–998. (<a href="https://doi.org/10.1109/TRO.2023.3344027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cutaneous haptic feedback has recently received great attention from researchers in the robotic teleoperation field, as it has been proven to convey rich information to the human operator while guaranteeing the safety and stability of the control loop. In fact, delivering ungrounded cutaneous cues keeps the teleoperation system stable even in the presence of time-varying destabilizing factors such as hard contacts or communication delays. This aspect is particularly relevant for all the applications and scenarios where the safety of the system is of paramount importance, as in medical robotics. This article presents an overview on cutaneous haptic interaction followed by a review of the literature on cutaneous/tactile feedback systems for robotic teleoperation, categorizing the considered systems according to the type of cutaneous stimuli they can provide to the human operator. This article ends with a discussion on the role of cutaneous haptics in robotics and the perspectives of the field.},
  archive      = {J_TROB},
  author       = {Claudio Pacchierotti and Domenico Prattichizzo},
  doi          = {10.1109/TRO.2023.3344027},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {978-998},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Cutaneous/Tactile haptic feedback in robotic teleoperation: Motivation, survey, and perspectives},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel dual-robot accurate calibration method using convex
optimization and lie derivative. <em>TROB</em>, <em>40</em>, 960–977.
(<a href="https://doi.org/10.1109/TRO.2023.3344025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Calibrating unknown transformation relationships is an essential task for multirobot cooperative systems. Traditional linear methods are inadequate to decouple and simultaneously solve the unknown matrices due to their intercoupling. This article proposes a novel dual-robot accurate calibration method that uses convex optimization and Lie derivative to solve the dual-robot calibration problem simultaneously. The key idea is that a convex optimization model based on dual-robot transformation chain is established using Lie representation of special Euclidean group in 3 dimensions [ SE (3)]. The Jacobian matrix of the established optimization model is explicitly derived using the corresponding Lie derivative of SE (3). To balance the influence of the magnitudes of the rotational and translational optimization variables, a weight coefficient is defined. Due to the closure and smoothness of Lie group, the optimization model can be solved simultaneously using Newton-like iterative methods without additional orthogonalization processing. The performance of the proposed method is verified through simulation and actual calibration experiments. The results show that the proposed method outperforms the previous calibration methods in terms of accuracy and stability. The actual experiments are used to compare the proposed method with two existing calibration methods, and the mean measurement error of a certified ceramic sphere is reduced from 0.9205 and 0.5363 to 0.4381 mm, respectively.},
  archive      = {J_TROB},
  author       = {Cheng Jiang and Wen-long Li and Wen-pan Li and Dong-fang Wang and Li-jun Zhu and Wei Xu and Huan Zhao and Han Ding},
  doi          = {10.1109/TRO.2023.3344025},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {960-977},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A novel dual-robot accurate calibration method using convex optimization and lie derivative},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A generalized motion control framework of dielectric
elastomer actuators: Dynamic modeling, sliding-mode control and
experimental evaluation. <em>TROB</em>, <em>40</em>, 919–935. (<a
href="https://doi.org/10.1109/TRO.2023.3338973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous electromechanical deformation of dielectric elastomer actuators (DEAs) suffers from rate-dependent viscoelasticity, mechanical vibration, and configuration dependency, making the generalized dynamic modeling and precise control elusive. In this work, we present a generalized motion control framework for DEAs capable of accommodating different configurations, materials and degrees of freedom (DOFs). First, a generalized, control-enabling dynamic model is developed for DEAs by taking both nonlinear electromechanical coupling, mechanical vibration and rate-dependent viscoelasticity into consideration. Further, a state observer is introduced to predict the unobservable viscoelasticity. Then, an enhanced exponential reaching law-based sliding-mode controller (EERLSMC) is proposed to minimize the viscoelasticity of DEAs. Its stability is also proved mathematically. The experimental results obtained for different DEAs (four configurations, two materials, and multi-DOFs) demonstrate that our dynamic model can precisely describe their complex dynamic responses and the EERLSMC can achieve precise tracking control; verifying the generality and versatility of our motion control framework.},
  archive      = {J_TROB},
  author       = {Jiang Zou and Shakiru Olajide Kassim and Jieji Ren and Vahid Vaziri and Sumeet S. Aphale and Guoying Gu},
  doi          = {10.1109/TRO.2023.3338973},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {919-935},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A generalized motion control framework of dielectric elastomer actuators: Dynamic modeling, sliding-mode control and experimental evaluation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autogeneration of mission-oriented robot controllers using
bayesian-based koopman operator. <em>TROB</em>, <em>40</em>, 903–918.
(<a href="https://doi.org/10.1109/TRO.2023.3344033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based robot controllers require customized control-oriented models, involving expert knowledge and trial and error. Remarkably, the Koopman operator enables the control-oriented model identification through the input–output mapping set, breaking through the barriers of the customization services. However, in recent years, research on Koopman-based robot control has mostly focused on lifting function construction, deviating from the original intention of improving the controller performance. Thus, we propose a robot controller autogeneration framework using the Bayesian-based Koopman operator, significantly releasing labor and eliminating the design obstacle. First, we introduce the Koopman-based system identification method and offer the basic lifting function design criteria. Then, a Bayesian-based optimization strategy with resource allocation is designed, which allows for the simultaneous optimization of the lifting function and the controller. Next, taking model-predictive control (MPC) as an example, a mission-oriented controller autogeneration framework is developed. Simulation and experimental results indicate that, under various robots and data sources, the proposed framework can effectively generate the robot controllers and perform with a far greater level of mission accuracy than the unoptimized Koopman-based MPC. Meanwhile, the proposed technique exhibits an obvious compensation effect against disturbances, demonstrating its practicability in robot control.},
  archive      = {J_TROB},
  author       = {Jie Pan and Dongyue Li and Jian Wang and Pengfei Zhang and Jinyan Shao and Junzhi Yu},
  doi          = {10.1109/TRO.2023.3344033},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {903-918},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Autogeneration of mission-oriented robot controllers using bayesian-based koopman operator},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Persistent homology meets object unity: Object recognition
in clutter. <em>TROB</em>, <em>40</em>, 886–902. (<a
href="https://doi.org/10.1109/TRO.2023.3343994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognition of occluded objects in unseen and unstructured indoor environments is a challenging problem for mobile robots. To address this challenge, we propose a new descriptor, Topological features Of Point cloud Slices (TOPS), for point clouds generated from depth images and an accompanying recognition framework, TOPS for Human-inspired Object Recognition (THOR), inspired by human reasoning. The descriptor employs a novel slicing-based approach to compute topological features from filtrations of simplicial complexes using persistent homology and facilitates reasoning-based recognition using object unity. Apart from a benchmark dataset, we report performance on a new dataset, the UW Indoor Scenes (UW-IS) Occluded dataset, curated using commodity hardware to reflect real-world scenarios with different environmental conditions and degrees of object occlusion. THOR outperforms state-of-the-art methods on both the datasets and achieves substantially higher recognition accuracy for all the scenarios of the UW-IS Occluded dataset. Therefore, THOR is a promising step toward robust recognition in low-cost robots, meant for everyday use in indoor settings.},
  archive      = {J_TROB},
  author       = {Ekta U. Samani and Ashis G. Banerjee},
  doi          = {10.1109/TRO.2023.3343994},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {886-902},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Persistent homology meets object unity: Object recognition in clutter},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive multi-agent-based planning and landing controller
for reactive dual-arm manipulation. <em>TROB</em>, <em>40</em>, 864–885.
(<a href="https://doi.org/10.1109/TRO.2023.3341689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future robots operating in fast-changing anthropomorphic environments need to be reactive, safe, flexible, and intuitively use both arms (comparable to humans) to handle task-space constrained manipulation scenarios. Furthermore, dynamic environments pose additional challenges for motion planning due to a continual requirement for validation and refinement of plans. This work addresses the issues with vector-field-based motion generation strategies, which are often prone to local-minima problems. We aim to bridge the gap between reactive solutions, global planning, and constrained cooperative (two-arm) manipulation in partially known surroundings. To this end, we introduce novel planning and real-time control strategies leveraging the geometry of the task space that are inherently coupled for seamless operation in dynamic scenarios. Our integrated multiagent global planning and control scheme explores controllable sets in the previously introduced cooperative dual task space and flexibly controls them by exploiting the redundancy of the high degree-of-freedom (DOF) system. The planning and control framework is extensively validated in complex, cluttered, and nonstationary simulation scenarios where our framework is able to complete constrained tasks in a reliable manner, whereas existing solutions fail. We also perform additional real-world experiments with a two-armed 14 DOF torque-controlled KoBo robot. Our rigorous simulation studies and real-world experiments reinforce the claim that the framework is able to run robustly within the inner loop of modern collaborative robots with vision feedback.},
  archive      = {J_TROB},
  author       = {Riddhiman Laha and Marvin Becker and Jonathan Vorndamme and Juraj Vrabel and Luis F.C. Figueredo and Matthias A. Müller and Sami Haddadin},
  doi          = {10.1109/TRO.2023.3341689},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {864-885},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Predictive multi-agent-based planning and landing controller for reactive dual-arm manipulation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guaranteed encapsulation of targets with unknown motion by a
minimalist robotic swarm. <em>TROB</em>, <em>40</em>, 816–830. (<a
href="https://doi.org/10.1109/TRO.2023.3339536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a decentralized control algorithm for a robotic swarm given the task of encapsulating static and moving targets in a bounded unknown environment. We consider minimalist robots without memory, explicit communication, or localization information. The state-of-the-art approaches generally assume that the robots in the swarm are able to detect the relative position of neighboring robots and targets in order to provide convergence guarantees. In this work, we propose a novel control law for the guaranteed encapsulation of static and moving targets while avoiding all collisions, when the robots do not know the exact relative location of any robot or target in the environment. We make use of the Lyapunov stability theory to prove the convergence of our control algorithm and provide bounds on the ratio between the target and robot speeds. Furthermore, our proposed approach is able to provide stochastic guarantees under the bounds that we determine on task parameters for scenarios where a target moves faster than a robot. Finally, we present an analysis of how the emergent behavior changes with different parameters of the task and noisy sensor readings.},
  archive      = {J_TROB},
  author       = {Himani Sinhmar and Hadas Kress-Gazit},
  doi          = {10.1109/TRO.2023.3339536},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {816-830},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Guaranteed encapsulation of targets with unknown motion by a minimalist robotic swarm},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multirobot adversarial resilience using control barrier
functions. <em>TROB</em>, <em>40</em>, 797–815. (<a
href="https://doi.org/10.1109/TRO.2023.3341570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop an algorithm for resilient path planning, where a team of robots must navigate in a resilient formation such that they achieve $F$ -resilience, meaning they can coordinate in the presence of up to $F$ adversaries. Resilient formations are those having high connectivity often achieved by driving robots close together. Unfortunately, the objective of maintaining resilience can often times conflict with achieving collision and obstacle avoidance. We seek to provide safe navigation while maintaining resilience by employing a local controller that uses control barrier functions (CBFs). CBF-based formulations are amenable to satisfying multiple objectives, but can be prone to deadlock if any of the objectives conflict with each other. Furthermore, it is difficult to know a priori where this may occur in a given environment. To this end, we 1) characterize when the environment will force a tradeoff between safe navigation and resilience, and 2) develop an algorithm that derives a new representation of the environment in which areas where resilience cannot be provably guaranteed are blocked off. This algorithm can be used to plan a path through an environment that always provably admits a resilient formation. If the algorithm cannot find such a path, an alternative CBF is proposed where resilience can be treated as a soft constraint . For this case, a nested form of the CBF is executed and a critical gain is derived that provably prioritizes navigation over resilience while resilience is not attainable. Finally, in addition to simulation results, we run hardware experiments with six GoPiGo differential-drive robots that achieve $F$ -resilient consensus while navigating through a cluttered environment, to showcase the applicability of our methods in the presence of adversaries.},
  archive      = {J_TROB},
  author       = {Matthew Cavorsi and Lorenzo Sabattini and Stephanie Gil},
  doi          = {10.1109/TRO.2023.3341570},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {797-815},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Multirobot adversarial resilience using control barrier functions},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Singularity analysis and solutions for the origami
transmission mechanism of fast-moving untethered insect-scale robot.
<em>TROB</em>, <em>40</em>, 777–796. (<a
href="https://doi.org/10.1109/TRO.2023.3338949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing insect-scale robots with high mobility is becoming an essential challenge in the field of robotics research. Among the methods for fabricating the transmission mechanism of the insect-scale robot, the smart composite microstructure (SCM) method is getting more and more attention. This method can construct compact and functional miniature origami mechanisms through planarized fabrication and folding assembly processes. Our previous work has proposed an untethered robot S $^{\text{2}}$ worm equipped with a novel 2-DoF origami transmission mechanism. The S $^{\text{2}}$ worm is fabricated through SCM and holds a top speed of 27.4 cm/s. In this work, we propose a novel strategy for designing the insect-scale robot with high mobility, that is, applying Grassmann–Cayley Algebra (GCA) to avoid the singularity of the transmission mechanism. The experimental results prove that the singularity of the previous work has been solved. The new robot prototype S $^{\text{2}}$ worm-G weighs 4.71 g, scales 4.0 cm, achieves a top speed of 75.0 cm/s and a relative speed of 18.8 bodylength/s. To the best of our knowledge, the 2-DoF origami transmission mechanism is the first parallel mechanism designed for the insect-scale robot and the singularity of the mechanism is found and solved here. The experimental results prove that the refined S $^{\text{2}}$ worm-G robot is one of the best insect-scale robots for its size, mass, and mobility.},
  archive      = {J_TROB},
  author       = {Yide Liu and Bo Feng and Tianlun Cheng and Yanhong Chen and Xiyan Liu and Jiahang Zhang and Shaoxing Qu and Wei Yang},
  doi          = {10.1109/TRO.2023.3338949},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {777-796},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Singularity analysis and solutions for the origami transmission mechanism of fast-moving untethered insect-scale robot},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A general kinematic model of fish locomotion enables robot
fish to master multiple swimming motions. <em>TROB</em>, <em>40</em>,
750–763. (<a href="https://doi.org/10.1109/TRO.2023.3339015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fish locomotion which adopts body and/or caudal fin swimming mode consists of different motions, such as Cruising-straight, Cruising-turn, and various fast turns, among others. Currently, there is no single mathematical model that could illustrate all these motions. Thus, for scientists and engineers, it is quite cumbersome and complicated to model and control different motions with multiple principles. In this article, we proposed a general kinematic model to illustrate the kinematics of all aforementioned swimming motions. The model is synthesized by a nonlinear oscillator and a traveling wave equation. By changing four parameters extracted from the model, the kinematic model can demonstrate all the aforementioned swimming motions with different amplitudes and frequencies. To verify the model, we built a multijoint robotic fish and developed its dynamic model and control method to perform all the maneuvers under the guidance of the general kinematic model. Through this systematic methodology, one can easily study the principles of different swimming motions and design the multimotions controller for a robotic fish through only one governing kinematic model.},
  archive      = {J_TROB},
  author       = {Yong Zhong and Zicun Hong and Yuhan Li and Junzhi Yu},
  doi          = {10.1109/TRO.2023.3339015},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {750-763},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A general kinematic model of fish locomotion enables robot fish to master multiple swimming motions},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel graph-based motion planner of multi-mobile robot
systems with formation and obstacle constraints. <em>TROB</em>,
<em>40</em>, 714–728. (<a
href="https://doi.org/10.1109/TRO.2023.3339989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-mobile robot systems (MMRSs) show great advantages over one single robot in many applications. However, the robots are required to form desired task-specified formations, making feasible motions decrease significantly. Thus, it is challenging to determine whether the robots can pass through an obstructed environment under formation constraints, especially in an obstacle-rich environment. Furthermore, is there an optimal path for the robots? To deal with the two problems, a novel graph-based motion planner is proposed in this article. Valid configurations of the system are defined to satisfy both formation and obstacle constraints. Then, the whole valid configuration space is identified and mapped to an undirected graph. The breadth-first search (BFS) method is employed on the graph to answer the question of whether there is a feasible path on the graph. Finally, an optimal path will be planned on the updated graph, considering the cost of path length and formation preference. Simulation results show that the planner can be applied to get optimal motions of robots under formation constraints in obstacle-rich environments. In addition, different types of constraints are considered to verify the generality.},
  archive      = {J_TROB},
  author       = {Wenhang Liu and Jiawei Hu and Heng Zhang and Michael Yu Wang and Zhenhua Xiong},
  doi          = {10.1109/TRO.2023.3339989},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {714-728},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A novel graph-based motion planner of multi-mobile robot systems with formation and obstacle constraints},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motion planning for multiple heterogeneous magnetic robots
under global input. <em>TROB</em>, <em>40</em>, 697–713. (<a
href="https://doi.org/10.1109/TRO.2023.3339529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetism provides an untethered actuation mechanism and an alternative way to actuate robots. Using a magnetic field we can control the motion of robots embedded with magnets. This scales down the size of the robots dramatically such that they can be used in applications like drug delivery, sample collection, micromanipulation, and noninvasive procedures. Despite all advantages and potentials, magnetic actuation has one major drawback. Due to the similar interaction between the magnetic field and the embedded magnets in multirobot systems, controlling the robots independently is challenging. Using heterogeneous magnetic robots is one way to overcome the independent control challenge. Here, motion planning for multiple magnetic robots that move in parallel directions at different speeds in response to a global input is addressed in the absence of obstacles in a polygonal workspace. Through controllability analysis, it will be shown that having $n$ linearly independent heterogeneous responses to the global input, called Modes of Motion here, enables independent position control of $n$ robots in the system. Further, a procedure to have a potentially feasible sequence of motion is presented and intrarobot collision free directions of movement are formulated mathematically. These procedures are then used in the proposed optimization-based motion planning algorithm. Also, an innovative millimeter scale multimode magnetic pivot walker design is introduced and used for benchmarking in the experiments. Finally, the motion planning algorithm is used in multiple experiments, using our innovative pivot walkers, and its efficacy is illustrated.},
  archive      = {J_TROB},
  author       = {Farshid Asadi and Yildirim Hurmuzlu},
  doi          = {10.1109/TRO.2023.3339529},
  journal      = {IEEE Transactions on Robotics},
  month        = {12},
  pages        = {697-713},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Motion planning for multiple heterogeneous magnetic robots under global input},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A geometric framework for stiffness mappings of compliant
robotic systems on the special euclidean group. <em>TROB</em>,
<em>40</em>, 2181–2200. (<a
href="https://doi.org/10.1109/TRO.2023.3323824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the stiffness mapping of compliant robotic systems is generalized to the special Euclidean group SE(3). A geometric framework is proposed to unify the existing stiffness models. We analyze the symmetry and exactness relationship between joint and Cartesian stiffness matrices in this framework. To verify the theoretical results, motions of different types of manipulators, including serial and parallel ones, are tested in simulations. Based on the conservative property of the stiffness matrix, an impedance control strategy to achieve variable stiffness is proposed. In addition, a feasible stiffness identification method is developed using the skew-symmetric structure of the stiffness matrix.},
  archive      = {J_TROB},
  author       = {Tengyu Hou and Ye Ding and Xiangyang Zhu},
  doi          = {10.1109/TRO.2023.3323824},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {2181-2200},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A geometric framework for stiffness mappings of compliant robotic systems on the special euclidean group},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A variable stiffness spherical joint motor by magnetic
energy shaping. <em>TROB</em>, <em>40</em>, 1410–1420. (<a
href="https://doi.org/10.1109/TRO.2023.3336319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a robotic joint motor capable of providing bio-joint-like motion and controllable stiffness in omnidirection. Unlike existing compliant actuators relying on elastic elements or force/impedance control, the output shaft of the proposed actuator can be stabilized at any equilibrium in antagonistic sense by purely manipulating the motor currents in the electromagnets distributed on the spherical surface of the joint socket. The multi-DOF orientation and the joint stiffness can be simultaneously adjusted by dynamically shaping the magnetic energy of the motor in the vicinity of any specified equilibrium. The relationship between the motor currents and the motor torque as well as the torque gradients is established in closed-form for the spherical joint motor (SJM), which allows for real-time shaping of the magnetic energy and manipulation of the equilibrium and the stiffness. The concept of the proposed variable stiffness motor with the energy shaping method have been validated as a robotic wrist equipped on a robotic manipulator. The results demonstrate that the SJM is capable of providing dexterous motion and intrinsic joint compliance in omnidirection while also allowing simple joint design and efficient compliant manipulations for robots.},
  archive      = {J_TROB},
  author       = {Mengke Li and Qianhong Xiao and Zehui Wang and Chenjie Liu and Kun Bai},
  doi          = {10.1109/TRO.2023.3336319},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {1410-1420},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A variable stiffness spherical joint motor by magnetic energy shaping},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel back-support exoskeleton with a differential series
elastic actuator for lifting assistance. <em>TROB</em>, <em>40</em>,
1327–1338. (<a href="https://doi.org/10.1109/TRO.2023.3331680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to conventional back-support exoskeletons (BSEs) with two motors, BSEs driven by a single motor have the advantage of light weight. However, current single-motor BSEs have problems with accommodating asynchronous hip movements, achieving precise force control and efficient force transmission, and giving autonomy to users when walking. In this article, we propose a novel BSE with a differential series elastic actuator (D-SEA) for lifting assistance. The unique differential working principle can accommodate the angular difference between the hip joints and provide the same assistive torque at both hip joints. The D-SEA achieves precise force control with a custom controller based on accurate spring deflection feedback, and drives the hip joints via an efficient cable-roller mechanism. Taking advantage of the active backdrivability of the D-SEA, we proposed an intelligent assistive strategy that automatically provides adequate support for lifting tasks and grants autonomy to users during walking. In experiments, the BSE reduced the activation level of the back muscles by up to 40% during lifting, without increasing the activation of the back and leg muscles during walking.},
  archive      = {J_TROB},
  author       = {Shuo Ding and Francisco Anaya Reyes and Shounak Bhattacharya and Ashwin Narayan and Shuaishuai Han and Ofori Seyram and Haoyong Yu},
  doi          = {10.1109/TRO.2023.3331680},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {1327-1338},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A novel back-support exoskeleton with a differential series elastic actuator for lifting assistance},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed matching-by-clone hungarian-based algorithm for
task allocation of multiagent systems. <em>TROB</em>, <em>40</em>,
851–863. (<a href="https://doi.org/10.1109/TRO.2023.3335656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a novel approach, namely distributed matching-by-clone hungarian-based algorithm (DMCHBA), to multiagent task-allocation problems, in which the number of agents is smaller than the number of tasks. The proposed DMCHBA assumes that agents employ an implicit coordination mechanism and consists of two iterative phases, i.e., the communication phase and the assignment phase. In the communication phase, agents communicate with their connected neighbors and exchange their local knowledge base until they converge on the global knowledge base. In the assignment phase, each agent builds a squared cost matrix by cloning agents and adding pseudotasks when necessary, and applying the Hungarian method for task allocation. A local planning algorithm is then applied to identify the order of task execution for an agent. The proposed DMCHBA is proven to produce conflict-free assignments among agents in finite time. We compare the performance of DMCHBA with the consensus-based bundle algorithm, the distributed recursive Hungarian-based algorithms, and the cluster-based Hungarian algorithm (CBHA) in Monte-Carlo simulations with different numbers of agents and tasks. The numerical results reveal the superior convergence and optimality of DMCHBA over all other selected algorithms.},
  archive      = {J_TROB},
  author       = {Arezoo Samiei and Liang Sun},
  doi          = {10.1109/TRO.2023.3335656},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {851-863},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Distributed matching-by-clone hungarian-based algorithm for task allocation of multiagent systems},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RotorTM: A flexible simulator for aerial transportation and
manipulation. <em>TROB</em>, <em>40</em>, 831–850. (<a
href="https://doi.org/10.1109/TRO.2023.3336320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-cost autonomous micro aerial vehicles have great potential to help humans by simplifying and speeding up complex tasks, such as construction, package delivery, and search and rescue. These systems, which may consist of single or multiple vehicles, can be equipped with passive connection mechanisms, such as rigid links or cables for transportation and manipulation tasks. However, these systems are inherently complex. They are often underactuated and evolve in nonlinear manifold configuration spaces. In addition, the complexity escalates for systems with cable-suspended load due to the hybrid dynamics that vary with the cables&#39; tension conditions. This article presents the first aerial transportation and manipulation simulator incorporating different payloads and passive connection mechanisms with full system dynamics, planning, and control algorithms. Furthermore, it includes a novel general model accounting for the transient hybrid dynamics for aerial systems with cable-suspended load to closely mimic real-world systems. The availability of a flexible and intuitive interface further contributes to its usability and versatility. Comparisons between simulations and real-world experiments with different vehicles&#39; configurations show the fidelity of the simulator results with respect to real-world settings. The experiments also show the simulator&#39;s benefit for the rapid prototyping and transitioning of aerial transportation and manipulation systems to real-world deployment.},
  archive      = {J_TROB},
  author       = {Guanrui Li and Xinyang Liu and Giuseppe Loianno},
  doi          = {10.1109/TRO.2023.3336320},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {831-850},
  shortjournal = {IEEE Trans. Robot.},
  title        = {RotorTM: A flexible simulator for aerial transportation and manipulation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A miniature water jumping robot based on accurate
interaction force analysis. <em>TROB</em>, <em>40</em>, 764–776. (<a
href="https://doi.org/10.1109/TRO.2023.3332161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water jumping motion extends the robot&#39;s movement space and flexibility. However, the jumping performance is influenced by multiple factors such as driving force, rowing trajectory, and robot structure. The interaction force between the robot and water surface is complicated due to water deformation, and the difficulty of the water jumping increases with the robot&#39;s scale. This article designs a miniature water jumping robot with rowing driving legs. The hydrodynamic model between driving legs and water is established based on the modified Wagner theory with consideration of water surface deformation. Particularly, the dynamic model of the robot for the whole jumping process is also developed related to multiple factors. Then, the jumping performance is improved by optimizing the energy storage modality, rowing trajectory, and supporting leg shapes through the theoretical analysis and experiments. The fabricated robot weights 91 g, and its length, width, and height are 220, 410, and 95 mm, respectively. The maximum water jumping height and distance are 241 and 965 mm.},
  archive      = {J_TROB},
  author       = {Jihong Yan and Xin Zhang and Kai Yang and Jie Zhao},
  doi          = {10.1109/TRO.2023.3332161},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {764-776},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A miniature water jumping robot based on accurate interaction force analysis},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient constrained dynamics algorithms based on an
equivalent LQR formulation using gauss’ principle of least constraint.
<em>TROB</em>, <em>40</em>, 729–749. (<a
href="https://doi.org/10.1109/TRO.2023.3335652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive a family of efficient constrained dynamics algorithms by formulating an equivalent linear quadratic regulator (LQR) problem using Gauss&#39; principle of least constraint and solving it using dynamic programming. Our approach builds upon the pioneering (but largely unknown) $O(n + m^{2}\;d + m^{3})$ solver by Popov and Vereshchagin (PV), where $n$ , $m$ , and $d$ are the number of joints, number of constraints, and the kinematic tree depth, respectively. We provide an expository derivation for the original PV solver and extend it to floating-base kinematic trees with constraints allowed on any link. We make new connections between the LQR&#39;s dual Hessian and the inverse operational space inertia matrix (OSIM), permitting efficient OSIM computation, which we further accelerate using matrix inversion lemma. By generalizing the elimination ordering and accounting for MuJoCo -type soft constraints, we derive two original $O(n + m)$ complexity solvers. Our numerical results indicate that significant simulation speed-up can be achieved for high dimensional robots like quadrupeds and humanoids using our algorithms as they scale better than the widely used $O(nd^{2} + m^{2}\;d + d^{2}\;m)$ LTL algorithm of Featherstone. The derivation through the LQR-constrained dynamics connection can make our algorithm accessible to a wider audience and enable cross fertilization of software and research results between the fields.},
  archive      = {J_TROB},
  author       = {Ajay Suresha Sathya and Herman Bruyninckx and Wilm Decré and Goele Pipeleers},
  doi          = {10.1109/TRO.2023.3335652},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {729-749},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Efficient constrained dynamics algorithms based on an equivalent LQR formulation using gauss&#39; principle of least constraint},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Implicit time-integration simulation of robots with rigid
bodies and cosserat rods based on a newton–euler recursive algorithm.
<em>TROB</em>, <em>40</em>, 677–696. (<a
href="https://doi.org/10.1109/TRO.2023.3334647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a new algorithm for solving the forward dynamics of multibody systems consisting of rigid bodies connected in arbitrary topologies by localized joints and/or soft links, possibly actuated or not. The simulation is based on the implicit time integration of the Lagrangian model of these systems, where the soft links are modeled by Cosserat rods parameterized by assumed strain modes. This choice imposes a predictor–corrector structure on the approach, and requires computing both the residual vector and the Jacobian of the residual vector of the dynamics constrained by the time integrator. These additional calculations are handled here with a new Newton–Euler recursive inverse dynamics algorithm and its linearized tangent version. The approach is illustrated with numerical examples from the Cosserat rod literature and from recent robotic applications.},
  archive      = {J_TROB},
  author       = {Frédéric Boyer and Andrea Gotelli and Philipp Tempel and Vincent Lebastard and Federico Renda and Sébastien Briot},
  doi          = {10.1109/TRO.2023.3334647},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {677-696},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Implicit time-integration simulation of robots with rigid bodies and cosserat rods based on a Newton–Euler recursive algorithm},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural moving horizon estimation for robust flight control.
<em>TROB</em>, <em>40</em>, 639–659. (<a
href="https://doi.org/10.1109/TRO.2023.3331064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating and reacting to disturbances is crucial for robust flight control of quadrotors. Existing estimators typically require significant tuning for a specific flight scenario or training with extensive ground-truth disturbance data to achieve satisfactory performance. In this article, we propose a neural moving horizon estimator (NeuroMHE) that can automatically tune its key parameters modeled by a neural network and adapt to different flight scenarios. We achieve this by deriving the analytical gradients of the MHE estimates with respect to the MHE weighting matrices, which enables a seamless embedding of the MHE as a learnable layer into the neural network for highly effective learning. Interestingly, we show that the gradients can be computed efficiently using a Kalman filter in a recursive form. Moreover, we develop a model-based policy gradient algorithm to train NeuroMHE directly from the quadrotor trajectory tracking error without needing the ground-truth disturbance data. The effectiveness of NeuroMHE is verified extensively via both numerical and physical experiments on quadrotors in various challenging flights. Notably, NeuroMHE outperforms a state-of-the-art neural network-based estimator, reducing force estimation errors by up to 76.7%, while using a portable neural network that has only 7.7% of the learnable parameters of the latter. The proposed method is general and can be applied to robust adaptive control of other robotic systems.},
  archive      = {J_TROB},
  author       = {Bingheng Wang and Zhengtian Ma and Shupeng Lai and Lin Zhao},
  doi          = {10.1109/TRO.2023.3331064},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {639-659},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Neural moving horizon estimation for robust flight control},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Occlusion-robust autonomous robotic manipulation of human
soft tissues with 3-d surface feedback. <em>TROB</em>, <em>40</em>,
624–638. (<a href="https://doi.org/10.1109/TRO.2023.3335693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic manipulation of 3-D soft objects remains challenging in the industrial and medical fields. Various methods based on mechanical modeling, data-driven approaches or explicit feature tracking have been proposed. A unifying disadvantage of these methods is the high computational cost of simultaneous imaging processing, identification of mechanical properties, and motion planning, leading to a need for less computationally intensive methods. We propose a method for autonomous robotic manipulation with 3-D surface feedback to solve these issues. First, we produce a deformation model of the manipulated object, which estimates the robots&#39; movements by monitoring the displacement of surface points surrounding the manipulators. Then, we develop a 6-degree-of-freedom velocity controller to manipulate the grasped object to achieve a desired shape. We validate our approach through comparative simulations with existing methods and experiments using phantom and cadaveric soft tissues with the da Vinci research kit. The results demonstrate the robustness of the technique to occlusions and various materials. Compared to state-of-the-art linear and data-driven methods, our approach is more precise by 46.5% and 15.9% and saves 55.2% and 25.7% manipulation time, respectively.},
  archive      = {J_TROB},
  author       = {Junlei Hu and Dominic Jones and Mehmet R. Dogar and Pietro Valdastri},
  doi          = {10.1109/TRO.2023.3335693},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {624-638},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Occlusion-robust autonomous robotic manipulation of human soft tissues with 3-D surface feedback},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling and design of lattice-reinforced pneumatic soft
robots. <em>TROB</em>, <em>40</em>, 606–623. (<a
href="https://doi.org/10.1109/TRO.2023.3334629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lattice metamaterials exhibit diverse functions and complex spatial deformations by rational structural design. Here, lattice metamaterials are exploited to design pneumatic soft robots with programmable bending, twisting, and elongation deformations. The system comprises an elastomeric tube reinforced by lattice metamaterials. We develop an analytical framework to model the twisting, bending, and elongation finite deformation taking into account the geometric orthotropy and nonlinear elasticity. We experimentally validate our modeling approach and investigate the effects of geometric patterns and input loading on the soft actuators&#39; deformation. Theoretical guided design of lateral-climbing soft robots and exploration soft manipulators are demonstrated. The soft actuator could exhibit a combined twisting–bending–elongation deformation by lattice superimposition. The proposed structural design method paves the way for designing soft robots with complex and dexterous deformations.},
  archive      = {J_TROB},
  author       = {Dong Wang and Chengru Jiang and Guoying Gu},
  doi          = {10.1109/TRO.2023.3334629},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {606-623},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Modeling and design of lattice-reinforced pneumatic soft robots},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design, modeling, and control of AVOCADO: A multimodal
aerial-tethered robot for tree canopy exploration. <em>TROB</em>,
<em>40</em>, 592–605. (<a
href="https://doi.org/10.1109/TRO.2023.3334630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forests provide vital resources and services for humanity, but preserving and restoring them is challenging due to the difficulty of obtaining actionable data, especially in inaccessible areas, such as forest canopies. To address this, we follow the lead of arboreal animals that exploit multiple modes of locomotion. We combine aerial and tethered movements to enable AVOCADO to navigate within a tree canopy. Starting from the top of a tree, it can descend with the tether and maneuver around obstacles with thrusters. We extend our previous work with a new mechanical design with a protective shell, increased computational power and cameras for state estimation. We introduce a dynamic model and simulation, and perform a quasistatic and dynamic validation. For autonomy, we derive a control framework in simulation to regulate tether length, tilt, and heading, before transfer to the robot. We evaluate the controllers for trajectory tracking through experiments. AVOCADO can follow trajectories around obstacles and reject disturbances on the tether. Exploiting multimodal mobility will advance the exploration of tree canopies to actively monitor the true value of our forests.},
  archive      = {J_TROB},
  author       = {Steffen Kirchgeorg and Emanuele Aucone and Florian Wenk and Stefano Mintchev},
  doi          = {10.1109/TRO.2023.3334630},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {592-605},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design, modeling, and control of AVOCADO: A multimodal aerial-tethered robot for tree canopy exploration},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertainty-aware hand–eye calibration. <em>TROB</em>,
<em>40</em>, 573–591. (<a
href="https://doi.org/10.1109/TRO.2023.3330609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a generic framework for the hand–eye calibration of vision-guided industrial robots. In contrast to traditional methods, we explicitly model the uncertainty of the robot in a stochastically founded way. Albeit the repeatability of modern industrial robots is high, their absolute accuracy typically is much lower. This uncertainty—especially if not considered—deteriorates the result of the hand–eye calibration. Our proposed framework does not only result in a high accuracy of the computed hand–eye pose but also provides reliable information about the uncertainty of the robot. It further provides corrected robot poses for a convenient and inexpensive robot calibration. Our framework is computationally efficient and generic in several regards. It supports the use of a calibration target as well as self-calibration without the need for known 3-D points. It optionally enables the simultaneous calibration of the interior camera parameters. The framework is also generic with regard to the robot type and, hence, supports antropomorphic as well as selective compliance assembly robot arm (SCARA) robots, for example. Simulated and real experiments show the validity of the proposed methods. An extensive evaluation of our framework on a public dataset shows a considerably higher accuracy than 15 state-of-the-art methods.},
  archive      = {J_TROB},
  author       = {Markus Ulrich and Markus Hillemann},
  doi          = {10.1109/TRO.2023.3330609},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {573-591},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Uncertainty-aware Hand–Eye calibration},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enabling kubernetes orchestration of mixed-criticality
software for autonomous mobile robots. <em>TROB</em>, <em>40</em>,
540–553. (<a href="https://doi.org/10.1109/TRO.2023.3334642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Containerization and orchestration have become two key requirements in software development best practices. Containerization allows for better resource utilization, platform-independent development, and secure deployment of software. Orchestration automates the deployment, networking, scaling, and availability of containerized workloads and services. While containerization is increasingly being adopted in the robotic community, the use of task orchestration platforms (e.g., Kubernetes) is still an open challenge. The biggest limitation is due to the fact that state-of-the-art orchestrators do not support real-time (RT) containers, while advanced robotic software often consists of a mix of heterogeneous tasks (i.e., ROS nodes) with different levels of temporal constraints (i.e., mixed-criticality systems). This work addresses this challenge by presenting RT-Kube, a platform that extends the de-facto reference standard for container orchestration, Kubernetes, to schedule tasks with mixed-criticality requirements. It implements monitoring of tasks and detects missed deadlines for those with RT constraints. It selects low-priority tasks to be migrated at runtime to different units of the computing cluster to free resources and recover from temporal violations. We present quantitative experimental results on the software implementing the mission of a Robotnik RB-Kairos mobile robot to demonstrate the effectiveness of the proposed approach. The source code is publicly available on GitHub.},
  archive      = {J_TROB},
  author       = {Francesco Lumpp and Franco Fummi and Hiren D. Patel and Nicola Bombieri},
  doi          = {10.1109/TRO.2023.3334642},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {540-553},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Enabling kubernetes orchestration of mixed-criticality software for autonomous mobile robots},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive tracking and perching for quadrotor in dynamic
scenarios. <em>TROB</em>, <em>40</em>, 499–519. (<a
href="https://doi.org/10.1109/TRO.2023.3335670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perching on the moving platforms is a promising solution to enhance the endurance and operational range of quadrotors, which could benefit the efficiency of a variety of air ground cooperative tasks. To ensure robust perching, tracking with a steady relative state and reliable perception is a prerequisite. This paper presents an adaptive dynamic tracking and perching scheme for autonomous quadrotors to achieve tight integration with moving platforms. For reliable perception of dynamic targets, we introduce elastic visibility aware planning to actively avoid occlusion and target loss. Additionally, we propose a flexible terminal adjustment method that adapts the changes in flight duration and the couple d terminal states, ensuring full state synchronization with the time varying perching surface at various angles. A relaxation strategy is developed by optimizing the tangential relative speed to address the dynamics and safety violations brought by hard bo undary conditions. Moreover, we take SE(3) motion planning into account to ensure no collision until the contact moment. Furthermore, we propose an efficient spatiotemporal trajectory optimization framework considerin g full state dynamics The proposed method is extensively tested through benchmark comparisons and ablation studies. To facilitate the application of academic research to industry and to validate the efficiency under strictly limited computational resources, we deploy our system on a commercial drone (DJI MAVIC3) with a full size sport utility vehicle (SUV). We conduct extensive real world experiments, where the drone successfully tracks and perches at 30 km/h (8.3 m/ s) on the top of the SUV, and at 3.5∼m/s with 60° inclined into the trunk of the SUV.},
  archive      = {J_TROB},
  author       = {Yuman Gao and Jialin Ji and Qianhao Wang and Rui Jin and Yi Lin and Zhimeng Shang and Yanjun Cao and Shaojie Shen and Chao Xu and Fei Gao},
  doi          = {10.1109/TRO.2023.3335670},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {499-519},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Adaptive tracking and perching for quadrotor in dynamic scenarios},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Object spatial impedance achieved by a multifinger grasp
with hard-point contact. <em>TROB</em>, <em>40</em>, 483–498. (<a
href="https://doi.org/10.1109/TRO.2023.3335692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article identifies the space of spatial impedance behaviors that can be achieved by a grasp of a multifinger hand in which each fingertip makes hard-point contact with the held object. The dimension of the space of realizable impedances for a given number of fingers is determined analytically. A set of necessary and sufficient conditions on impedance matrices that can be realized by a given grasp is developed and the physical significance of these conditions is identified. The space of impedances that can be achieved by a hard point grasp is a hyperplane in the space of all possible impedance behaviors. A process to achieve an arbitrary full-rank impedance in the hyperplane with a grasp having the minimum number of fingers is developed. With this process, any spatial impedance behavior in the hyperplane can be attained with a three-finger grasp by properly selecting: first, the locations where fingertips contact the held object, and second, the translational impedance provided by a finger at each of these locations.},
  archive      = {J_TROB},
  author       = {Shuguang Huang and Joseph M. Schimmels},
  doi          = {10.1109/TRO.2023.3335692},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {483-498},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Object spatial impedance achieved by a multifinger grasp with hard-point contact},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Electroactive soft bistable actuator with adjustable energy
barrier and stiffness. <em>TROB</em>, <em>40</em>, 472–482. (<a
href="https://doi.org/10.1109/TRO.2023.3331065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A soft bistable actuator can generate high-speed motion between two prescribed stable positions, which is very useful for boosting the actuation of soft robots. Generally, the stroke of such an actuator is completely determined once the design is finalized, which prohibits its applications in robots that perform multiple tasks. In the current work, a bistable actuator with adjustable characteristics is proposed by exploring its strain energy landscape, in which the energy barrier is manipulatable via electroactive twisted and coiled polymer fibers. As such, the actuator can operate in either bistable or postbistable mode, both of which exhibit adjustable stiffness. A kinetostatic model that combines the chained beam constraint model and the mechanics of electroactive materials is established to characterize the actuator design. Experimental results validate the kinetostatic model and the behaviors of the actuator. As a robotic demonstration, a gripper that is formed by two actuators is prototyped, and it exhibits an adjustable load capacity (up to 6.5 times its weight under a 3 V voltage).},
  archive      = {J_TROB},
  author       = {Lei Jiang and Bo Li and Wentao Ma and Yehui Wu and Ruiyu Bai and Wenjie Sun and Yanjie Wang and Guimin Chen},
  doi          = {10.1109/TRO.2023.3331065},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {472-482},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Electroactive soft bistable actuator with adjustable energy barrier and stiffness},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). X-ICP: Localizability-aware LiDAR registration for robust
localization in extreme environments. <em>TROB</em>, <em>40</em>,
452–471. (<a href="https://doi.org/10.1109/TRO.2023.3335691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern robotic systems are required to operate in challenging environments, which demand reliable localization under challenging conditions. LiDAR-based localization methods, such as the iterative closest point (ICP) algorithm, can suffer in geometrically uninformative environments that are known to deteriorate point cloud registration performance and push optimization toward divergence along weakly constrained directions. To overcome this issue, this work proposes: 1) a robust fine-grained localizability detection module and 2) a localizability-aware constrained ICP optimization module, which couples with the localizability detection module in a unified manner. The proposed localizability detection is achieved by utilizing the correspondences between the scan and the map to analyze the alignment strength against the principal directions of the optimization as part of its fine-grained LiDAR localizability analysis. In the second part, this localizability analysis is then integrated into the scan-to-map point cloud registration to generate drift-free pose updates by enforcing controlled updates or leaving the degenerate directions of the optimization unchanged. The proposed method is thoroughly evaluated and compared to state-of-the-art methods in simulated and real-world experiments, demonstrating the performance and reliability improvement in LiDAR-challenging environments. In all the experiments, the proposed framework demonstrates accurate and generalizable localizability detection and robust pose estimation without environment-specific parameter tuning.},
  archive      = {J_TROB},
  author       = {Turcan Tuna and Julian Nubert and Yoshua Nava and Shehryar Khattak and Marco Hutter},
  doi          = {10.1109/TRO.2023.3335691},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {452-471},
  shortjournal = {IEEE Trans. Robot.},
  title        = {X-ICP: Localizability-aware LiDAR registration for robust localization in extreme environments},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The voraus-AD dataset for anomaly detection in robot
applications. <em>TROB</em>, <em>40</em>, 438–451. (<a
href="https://doi.org/10.1109/TRO.2023.3332224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the operation of industrial robots, unusual events may endanger the safety of humans and the quality of production. When collecting data to detect such cases, it is not ensured that data from all potentially occurring errors is included as unforeseeable events may happen over time. Therefore, anomaly detection (AD) delivers a practical solution, using only normal data to learn to detect unusual events. We introduce a dataset that allows training and benchmarking of anomaly detection methods for robotic applications based on machine data which will be made publicly available to the research community. As a typical robot task the dataset includes a pick-and-place application which involves movement, actions of the end effector, and interactions with the objects of the environment. Since several of the contained anomalies are not task-specific but general, evaluations on our dataset are transferable to other robotics applications as well. In addition, we present multivariate time-series flow (MVT-Flow) as a new baseline method for anomaly detection: It relies on deep-learning-based density estimation with normalizing flows, tailored to the data domain by taking its structure into account for the architecture. Our evaluation shows that MVT-Flow outperforms baselines from previous work by a large margin of 6.2% in area under receiving operator characteristic.},
  archive      = {J_TROB},
  author       = {Jan Thieß Brockmann and Marco Rudolph and Bodo Rosenhahn and Bastian Wandt},
  doi          = {10.1109/TRO.2023.3332224},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {438-451},
  shortjournal = {IEEE Trans. Robot.},
  title        = {The voraus-AD dataset for anomaly detection in robot applications},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comprehensive kinematic model of a tendon-driven wearable
tremor suppression device. <em>TROB</em>, <em>40</em>, 421–437. (<a
href="https://doi.org/10.1109/TRO.2023.3332160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable devices can suppress or reduce hand tremor motion associated with neurological disorders such as Parkinson&#39;s disease. Tendon-driven transmission systems have been proposed as a way to decrease the size and weight of these devices; however, they have complex control system requirements due to their substantially nonlinear behavior. To address this issue, this study focused on the development of a comprehensive kinematic model of a wearable tremor suppression glove that more accurately calculates the tendon displacement during hand motion. The novelty lies in the identification of the threshold bending angle for each joint at which the driven tendon touches the arc of the joint. The derived kinematic model of the glove was verified by both simulation and benchtop experiments, and the proposed model was validated during single-joint and multijoint hand movements. The kinematic model shows a mean 2-D correlation coefficient of 0.96 $\boldsymbol{\pm }$ 0.01 with the experimental data. Compared to the Euclidean norm model presented in the literature, it presents an average 83% improvement (a 4%–96% reduction in root mean square errors depending on the joint), which is most significant for increasing tendon displacements.},
  archive      = {J_TROB},
  author       = {Parisa Daemi and Yue Zhou and Michael D. Naish and Aaron D. Price and Ana Luisa Trejos},
  doi          = {10.1109/TRO.2023.3332160},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {421-437},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Comprehensive kinematic model of a tendon-driven wearable tremor suppression device},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lattice-based shape tracking and servoing of elastic
objects. <em>TROB</em>, <em>40</em>, 364–381. (<a
href="https://doi.org/10.1109/TRO.2023.3331596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a general unified tracking-servoing approach for controlling the shape of elastic deformable objects using robotic arms. Our approach works by forming a lattice around the object, binding the object to the lattice, and tracking and servoing the lattice instead of the object. This makes our approach have full control over the deformation of elastic deformable objects of any general form (linear, thin-shell, and volumetric) in 3-D space. Furthermore, it decouples the runtime complexity of the approach from the objects&#39; geometric complexity. Our approach is based on the as-rigid-as-possible deformation model. It requires no mechanical parameter of the object to be known and can drive the object toward desired shapes through large deformations. The inputs to our approach are the point cloud of the object&#39;s surface in its rest shape and the point cloud captured by a 3-D camera in each frame. Overall, our approach is more broadly applicable than existing approaches. We validate the efficiency of our approach through numerous experiments with elastic deformable objects of various shapes and materials (paper, rubber, plastic, and foam).},
  archive      = {J_TROB},
  author       = {Mohammadreza Shetab-Bushehri and Miguel Aranda and Youcef Mezouar and Erol Özgür},
  doi          = {10.1109/TRO.2023.3331596},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {364-381},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Lattice-based shape tracking and servoing of elastic objects},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trajectory planning and tracking of multiple objects on a
soft robotic table using a hierarchical search on time-varying potential
fields. <em>TROB</em>, <em>40</em>, 351–363. (<a
href="https://doi.org/10.1109/TRO.2023.3337291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a control strategy to carry out multiobject manipulation on a novel s oft r o botic ta ble (SoTa), which is a new form of the planar distributed manipulator. Manipulating multiple delicate objects simultaneously is an attractive feature of SoTa. The challenge here is to coordinate multiple objects in a confined planar space while avoiding interference with each other. The SoTa system adopts a manipulation strategy that includes a planning and a tracking stage for the purpose of sorting objects. The planning stage consists of two phases: 1) discrete path planning to find a path for each object on a grid map with respect to time; 2) trajectory generation to optimize and produce workable trajectories for SoTa. In the discrete path planning phase, a hierarchical searching method based on the time-varying potential field is proposed. Constraints of the SoTa system are modeled and incorporated into the path searching process. In the trajectory generation phase, a piecewise B-spline method is adopted to generate trajectories based on previously found discrete paths. Next, in the tracking stage, the objects are led to their goals along the trajectories ensuring safety and SoTa&#39;s capability. The performances of the proposed algorithm were simulated, analyzed, and compared with the conflict-based search method, which is optimal for multiagent path finding. A multiobject manipulation experiment of three objects on a $4\times 4$ grid was conducted on the SoTa. The results demonstrated the effectiveness of the proposed control strategy in executing multiobject manipulations for sorting tasks on the SoTa.},
  archive      = {J_TROB},
  author       = {Zixiao Chen and Zhicong Deng and Jaspreet Singh Dhupia and Martin Stommel and Weiliang Xu},
  doi          = {10.1109/TRO.2023.3337291},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {351-363},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Trajectory planning and tracking of multiple objects on a soft robotic table using a hierarchical search on time-varying potential fields},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shared autonomy of a robotic manipulator for grasping under
human intent uncertainty using POMDPs. <em>TROB</em>, <em>40</em>,
332–350. (<a href="https://doi.org/10.1109/TRO.2023.3334631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In shared autonomy (SA), accurate user intent prediction is crucial for good robot assistance and avoiding user–robot conflicts. Prior works have relied on passive observation of joystick inputs to predict user intent, which works when the goals are clearly separated or when a common policy exists for multiple goals. However, they may not work well when grasping objects to perform daily activities, as there are multiple ways to grasp the same object. We demonstrate the need for active information-gathering in such cases and show how this can be done in a principled manner by formulating SA as a discrete action partially observable Markov decision process (POMDP), reasoning over high-level actions. One of our insights is that apart from having explicit information-gathering actions and goal-oriented actions, it is important to have actions that move toward a distribution of goals and provide no assistance in the POMDP action space. Compared with a method with no active information-gathering, our method performs tasks faster, requires less user input, and decreases opposing actions, especially for more complex objects, getting higher ratings and preference in our user study.},
  archive      = {J_TROB},
  author       = {J-Anne Yow and Neha Priyadarshini Garg and Wei Tech Ang},
  doi          = {10.1109/TRO.2023.3334631},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {332-350},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Shared autonomy of a robotic manipulator for grasping under human intent uncertainty using POMDPs},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sim-suction: Learning a suction grasp policy for cluttered
environments using a synthetic benchmark. <em>TROB</em>, <em>40</em>,
316–331. (<a href="https://doi.org/10.1109/TRO.2023.3331679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents Sim-Suction , a robust object-aware suction grasp policy for mobile manipulation platforms with dynamic camera viewpoints, designed to pick up unknown objects from cluttered environments. Suction grasp policies typically employ data-driven approaches, necessitating large-scale, accurately-annotated suction grasp datasets. However, the generation of suction grasp datasets in cluttered environments remains underexplored, leaving uncertainties about the relationship between the object of interest and its surroundings. To address this, we propose a benchmark synthetic dataset, Sim-Suction-Dataset , comprising 500 cluttered environments with 3.2 million annotated suction grasp poses. The efficient Sim-Suction-Dataset generation process provides novel insights by combining analytical models with dynamic physical simulations to create fast and accurate suction grasp pose annotations. We introduce Sim-Suction-Pointnet to generate robust 6-D suction grasp poses by learning point-wise affordances from the Sim-Suction-Dataset , leveraging the synergy of zero-shot text-to-segmentation. Real-world experiments for picking up all objects demonstrate that Sim-Suction-Pointnet achieves success rates of 96.76%, 94.23%, and 92.39% on cluttered level 1 objects (prismatic shape), cluttered level 2 objects (more complex geometry), and cluttered mixed objects, respectively.},
  archive      = {J_TROB},
  author       = {Juncheng Li and David J. Cappelleri},
  doi          = {10.1109/TRO.2023.3331679},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {316-331},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Sim-suction: Learning a suction grasp policy for cluttered environments using a synthetic benchmark},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polymorphic control framework for automated and
individualized robot-assisted rehabilitation. <em>TROB</em>,
<em>40</em>, 298–315. (<a
href="https://doi.org/10.1109/TRO.2023.3335666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots were introduced in the field of upper limb neurorehabilitation to relieve the therapist from physical labor, and to provide high-intensity therapy to the patient. A variety of control methods were developed that incorporate patients&#39; physiological and biomechanical states to adapt the provided assistance automatically. Higher level states, such as selected type of assistance, chosen task characteristics, defined session goals, and given patient impairments, are often neglected or modeled into tight requirements, low-dimensional study designs, and narrow inclusion criteria so that presented solutions cannot be transferred to other tasks, robotic devices or target groups. In this work, we present the design of a modular high-level control framework based on invariant states covering all decision layers in therapy. We verified the functionality of our framework on the assistance and task layer by outlaying the invariant states based on the characteristics of 20 examined state-of-the-art controllers. Then, we integrated four controllers on each layer and designed two algorithms that automatically selected suitable controllers. The framework was deployed on an arm rehabilitation robot and tested on one participant acting as a patient. We observed plausible system reactions to external changes by a second operator representing a therapist. We believe that this work will boost the development of novel controllers and selection algorithms in cooperative decision-making on layers other than assistance, and eases transferability and integration of existing solutions on lower layers into arbitrary robotic systems.},
  archive      = {J_TROB},
  author       = {Michael Sommerhalder and Yves Zimmermann and Jaeyong Song and Robert Riener and Peter Wolf},
  doi          = {10.1109/TRO.2023.3335666},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {298-315},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Polymorphic control framework for automated and individualized robot-assisted rehabilitation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tight fusion of events and inertial measurements for direct
velocity estimation. <em>TROB</em>, <em>40</em>, 240–256. (<a
href="https://doi.org/10.1109/TRO.2023.3333108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional visual-inertial state estimation targets absolute camera poses and spatial landmark locations while first-order kinematics are typically resolved as an implicitly estimated substate. However, this poses a risk in velocity-based control scenarios, as the quality of the estimation of kinematics depends on the stability of absolute camera and landmark coordinates estimation. To address this issue, we propose a novel solution to tight visual–inertial fusion directly at the level of first-order kinematics by employing a dynamic vision sensor instead of a normal camera. More specifically, we leverage trifocal tensor geometry to establish an incidence relation that directly depends on events and camera velocity, and demonstrate how velocity estimates in highly dynamic situations can be obtained over short-time intervals. Noise and outliers are dealt with using a nested two-layer random sample consensus (RANSAC) scheme. In addition, smooth velocity signals are obtained from a tight fusion with preintegrated inertial signals using a sliding window optimizer. Experiments on both simulated and real data demonstrate that the proposed tight event-inertial fusion leads to continuous and reliable velocity estimation in highly dynamic scenarios independently of absolute coordinates. Furthermore, in extreme cases, it achieves more stable and more accurate estimation of kinematics than traditional, point-position-based visual-inertial odometry.},
  archive      = {J_TROB},
  author       = {Wanting Xu and Xin Peng and Laurent Kneip},
  doi          = {10.1109/TRO.2023.3333108},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {240-256},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Tight fusion of events and inertial measurements for direct velocity estimation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Haptic search with the smart suction cup on adversarial
objects. <em>TROB</em>, <em>40</em>, 226–239. (<a
href="https://doi.org/10.1109/TRO.2023.3331063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suction cups are an important gripper type in industrial robot applications, and the prior literature focuses on using vision-based planners to improve grasping success in these tasks. Vision-based planners can fail due to adversarial objects or lose generalizability for unseen scenarios, without retraining learned algorithms. In this article, we propose haptic exploration to improve suction cup grasping when visual grasp planners fail. We present the smart suction cup, an end effector that utilizes internal flow measurements for tactile sensing. We show that model-based haptic search methods, guided by these flow measurements, improve grasping success by up to 2.5× as compared with using only a vision planner during a bin-picking task. In characterizing the smart suction cup on both geometric edges and curves, we find that flow rate can accurately predict the ideal motion direction even with large postural errors. The smart suction cup includes no electronics on the cup itself, such that the design is easy to fabricate and haptic exploration does not damage the sensor. This work motivates the use of suction cups with autonomous haptic search capabilities in especially adversarial scenarios.},
  archive      = {J_TROB},
  author       = {Jungpyo Lee and Sebastian D. Lee and Tae Myung Huh and Hannah S. Stuart},
  doi          = {10.1109/TRO.2023.3331063},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {226-239},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Haptic search with the smart suction cup on adversarial objects},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Perching and grasping using a passive dynamic bioinspired
gripper. <em>TROB</em>, <em>40</em>, 213–225. (<a
href="https://doi.org/10.1109/TRO.2023.3336216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to grasp objects broadens the application range of unmanned aerial vehicles (UAVs) by allowing interactions with the environment. The difficulty in performing a midair grasp is the high probability of impact between the UAV&#39;s foot and the target. For a successful grasp, the foot must smoothly absorb the energy of impact and simultaneously engage with the target in a short period of time. We present a bioinspired passive dynamic foot in which the claws are actuated solely by the impact energy. Our gripper simultaneously resolves the issue of smooth absorption of the impact energy and fast closure of the claws by linking the motion of an ankle linkage and the claws through soft tendons. We study the dynamics of impact and use the stiffness of the tendon as our design/control parameter to adjust the mechanics of the gripper for smooth recycling of the impact energy. Our gripper closes within 45 ms after initial contact with the impacting object without requiring any controller or actuation energy. An electroadhesive locking mechanism attached to the tendon locks the claws within 20 ms after reaching closed configuration. We demonstrated the effectiveness of our gripper by integrating it in an UAV and performing a variety of passive dynamic perching and grasping tasks.},
  archive      = {J_TROB},
  author       = {Amir Firouzeh and Jongeun Lee and Hyunsoo Yang and Dongjun Lee and Kyu-Jin Cho},
  doi          = {10.1109/TRO.2023.3336216},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {213-225},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Perching and grasping using a passive dynamic bioinspired gripper},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Precision alignment in cell microinjection based on hybrid
triple-view micro-vision. <em>TROB</em>, <em>40</em>, 158–171. (<a
href="https://doi.org/10.1109/TRO.2023.3331879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alignment between the injection pipette and the holding pipette/biological entity is crucial for successful cell microinjection. Precision alignment can reduce cell damage and improve cell microinjection. However, in the traditional microscopic vision-based method, lack of depth perception is a drawback in monocular vision. On the other hand, stereo vision with a limited baseline distance and field of view (FOV) makes it challenging to observe biological samples. In this article, a novel hybrid triple-view micro-vision system, in which a binocular telecentric micro-vision unit and an inverted microscope are combined for scene depth and detail sense, is presented for cell microinjection. Based on this system, coarse-to-fine feature extraction methods for two discrepant pipettes are proposed, and a two-stage needle alignment strategy is established based on hybrid pose/image servo control. Some feature extraction and alignment experiments are implemented, and the results demonstrate that the proposed method achieves satisfactory alignment performance (mean position deviation: about 0.1 $\mu$ m; mean orientation deviation: about 0.4 $^\circ$ ) for zebra embryo microinjection, and the defined symmetry measure can reach 0.09.},
  archive      = {J_TROB},
  author       = {Zengsheng Liang and Zhong Chen and Qisen Wu and Xinyi Gao and Xianmin Zhang},
  doi          = {10.1109/TRO.2023.3331879},
  journal      = {IEEE Transactions on Robotics},
  month        = {11},
  pages        = {158-171},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Precision alignment in cell microinjection based on hybrid triple-view micro-vision},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A black-box physics-informed estimator based on gaussian
process regression for robot inverse dynamics identification.
<em>TROB</em>, <em>40</em>, 4842–4858. (<a
href="https://doi.org/10.1109/TRO.2024.3474851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning the inverse dynamics of robots directly from data, adopting a black-box approach, is interesting for several real-world scenarios where limited knowledge about the system is available. In this article, we propose a black-box model based on Gaussian process (GP) regression for the identification of the inverse dynamics of robotic manipulators. The proposed model relies on a novel multidimensional kernel, called Lagrangian Inspired Polynomial (LIP) kernel. The LIP kernel is based on two main ideas. First, instead of directly modeling the inverse dynamics components, we model as GPs the kinetic and potential energy of the system. The GP prior on the inverse dynamics components is derived from those on the energies by applying the properties of GPs under linear operators. Second, as regards the energy prior definition, we prove a polynomial structure of the kinetic and potential energy, and we derive a polynomial kernel that encodes this property. As a consequence, the proposed model allows also to estimate the kinetic and potential energy without requiring any label on these quantities. Results on simulation and on two real robotic manipulators, namely a 7 DOF Franka Emika Panda, and a 6 DOF MELFA RV4FL, show that the proposed model outperforms state-of-the-art black-box estimators based both on Gaussian processes and neural networks in terms of accuracy, generality, and data efficiency. The experiments on the MELFA robot also demonstrate that our approach achieves performance comparable to fine-tuned model-based estimators, despite requiring less prior information. The code of the proposed model is publicly available.},
  archive      = {J_TROB},
  author       = {Giulio Giacomuzzo and Ruggero Carli and Diego Romeres and Alberto Dalla Libera},
  doi          = {10.1109/TRO.2024.3474851},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {4842-4858},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A black-box physics-informed estimator based on gaussian process regression for robot inverse dynamics identification},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving the collision tolerance of high-speed industrial
robots via impact-aware path planning and series clutched actuation.
<em>TROB</em>, <em>40</em>, 4825–4841. (<a
href="https://doi.org/10.1109/TRO.2024.3475208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are more often deployed in unstructured or unpredictable environments. Particularly collisions at high speed can severely damage the drivetrains and joint bearings of robots. In order to avoid such collisions, path planners exist that adapt the robot&#39;s original trajectory online if a collision hazard is detected. These methods require additional sensors such as cameras, are computationally costly and never flawless due to occlusions. Another approach is to incorporate a cost function that promotes collision tolerance while planning the initial trajectory. The resulting impact-aware path plan minimizes the chance of robot hardware damage if a collision would occur. Two algorithms are presented to assess collision tolerance in high-speed robots, taking into account factors such as robot pose, impact direction, and maximum intermittent loading of the gearboxes and bearings. The first algorithm is more general while the second assumes the presence of joint overload clutches that decouple upon impact. These algorithms are applied to plan an impact-aware path for a custom 6-axis series clutched actuated robot that serves as use case. Both for the case with and without clutches, a generic impact-aware plan is presented as well as at least one derived, heuristic alternative. Without clutches, trajectories that are perpendicular to the end effector flange were found to be desirable, as they allow the robot to mitigate the highest collision force without overloading the gearboxes or bearings. On the other hand, with clutches, trajectories that are parallel to the end effector flange were found to be more collision tolerant. The effect of impact direction was also experimentally validated using the custom 6-axis robot. Collisions at velocities up to 1.2 m/s were mitigated through the combination of impact-aware path planning and series clutched actuation.},
  archive      = {J_TROB},
  author       = {Frederik Ostyn and Bram Vanderborght and Guillaume Crevecoeur},
  doi          = {10.1109/TRO.2024.3475208},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {4825-4841},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Improving the collision tolerance of high-speed industrial robots via impact-aware path planning and series clutched actuation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On semidefinite relaxations for matrix-weighted
state-estimation problems in robotics. <em>TROB</em>, <em>40</em>,
4805–4824. (<a href="https://doi.org/10.1109/TRO.2024.3475220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been remarkable progress in the development of so-called certifiable perception methods, which leverage semidefinite, convex relaxations to find global optima of perception problems in robotics. However, many of these relaxations rely on simplifying assumptions that facilitate the problem formulation, such as an isotropic measurement noise distribution. In this article, we explore the tightness of the semidefinite relaxations of matrix-weighted (anisotropic) state-estimation problems and reveal the limitations lurking therein: matrix-weighted factors can cause convex relaxations to lose tightness. In particular, we show that the semidefinite relaxations of localization problems with matrix weights may be tight only for low noise levels. To better understand this issue, we introduce a theoretical connection between the posterior uncertainty of the state estimate and the certificate matrix obtained via convex relaxation. With this connection in mind, we empirically explore the factors that contribute to this loss of tightness and demonstrate that redundant constraints can be used to regain it. As a second technical contribution of this article, we show that the state-of-the-art relaxation of scalar-weighted simultaneous localization and mapping cannot be used when matrix weights are considered. We provide an alternate formulation and show that its semidefinite program relaxation is not tight (even for very low noise levels) unless specific redundant constraints are used. We demonstrate the tightness of our formulations on both simulated and real-world data.},
  archive      = {J_TROB},
  author       = {Connor Holmes and Frederike Dümbgen and Timothy Barfoot},
  doi          = {10.1109/TRO.2024.3475220},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {4805-4824},
  shortjournal = {IEEE Trans. Robot.},
  title        = {On semidefinite relaxations for matrix-weighted state-estimation problems in robotics},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A distributed auction algorithm for task assignment with
robot coalitions. <em>TROB</em>, <em>40</em>, 4787–4804. (<a
href="https://doi.org/10.1109/TRO.2024.3475209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the task assignment problem with robot coalitions, as encountered in practical scenarios, such as multiplayer reach-avoid games. Unlike the classical assignment problem where a single robot performs each task, the problem considered here involves tasks that require execution by a robot coalition consisting of two robots. This task assignment problem is a special instance of 3-set packing problem, which is known to be nondeterministic polynomial time (NP)-hard. We introduce the concept of $\epsilon$ -coalition-competitive equilibrium ( $\epsilon$ -CCE) to characterize a kind of approximate solution that offers guaranteed performance. A distributed auction algorithm is developed to find an $\epsilon$ -CCE within a finite number of iterations. In addition, several enhancements have been implemented to adapt the auction algorithm for practical applications where the task assignment problem may vary over time. Numerical simulations demonstrate that the distributed algorithm achieves satisfactory approximation quality.},
  archive      = {J_TROB},
  author       = {Ruiliang Deng and Rui Yan and Peinan Huang and Zongying Shi and Yisheng Zhong},
  doi          = {10.1109/TRO.2024.3475209},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {4787-4804},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A distributed auction algorithm for task assignment with robot coalitions},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximate methods for visibility-based pursuit–evasion.
<em>TROB</em>, <em>40</em>, 4768–4786. (<a
href="https://doi.org/10.1109/TRO.2024.3474948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To the best of our knowledge, an exact solution to the visibility-based pursuit–evasion problem with point agents and polygonal obstacles addressed in this work is not known. Given the above, in this work, we present approximate algorithms, but feasible and with other desirable properties, for such a pursuit–evasion game. Our new method combines asymptotically optimal motion planning based on sampling (more specifically, optimal probabilistic roadmaps) and the value iteration of dynamic programming. In addition, our formulation finds solutions for the evader when there are singular surfaces, which previous work could not find. In this work, we obtain two main theoretical results. We first prove that the proposed discrete formulation is correct (that the method obtains the solution for the discretization of the given configuration space). Subsequently, combining random graph results, Bellman&#39;s optimality principle, and limits, it is proved that, as the number of samples tends to infinity, our approximate discrete formulation becomes the continuous formulation corresponding to the Hamilton–Jacobi–Isaacs equation. This results in a feasible method that improves its approximation as the number of samples increases. Simulation experiments in 2-D and 3-D environments with obstacles that are simply and multiplicattively connected exemplify the results of the new method and show the advantages over previous work.},
  archive      = {J_TROB},
  author       = {Emmanuel Antonio and Israel Becerra and Rafael Murrieta-Cid},
  doi          = {10.1109/TRO.2024.3474948},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {4768-4786},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Approximate methods for visibility-based Pursuit–Evasion},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impact of stress and workload on human performance in
robot teleoperation tasks. <em>TROB</em>, <em>40</em>, 4725–4744. (<a
href="https://doi.org/10.1109/TRO.2024.3484630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in robot teleoperation have enabled groundbreaking innovations in many fields, such as space exploration, healthcare, and disaster relief. The human operator&#39;s performance plays a key role in the success of any teleoperation task, with prior evidence suggesting that operator stress and workload can impact task performance. As robot teleoperation is currently deployed in safety-critical domains, it is essential to analyze how different stress and workload levels impact the operator. We are unaware of any prior work investigating how both stress and workload impact teleoperation performance. We conducted a novel study ( $n=24$ ) to jointly manipulate users&#39; stress and workload and analyze the user&#39;s performance through objective and subjective measures. Our results indicate that, as stress increased, over 70% of our participants performed better up to a moderate level of stress; yet, the majority of participants performed worse as the workload increased. Importantly, our experimental design elucidated that stress and workload have related yet distinct impacts on task performance, with workload mediating the effects of distress on performance ( $p&amp;lt; .05$ ).},
  archive      = {J_TROB},
  author       = {Yi Ting Sam and Erin Hedlund-Botti and Manisha Natarajan and Jamison Heard and Matthew Gombolay},
  doi          = {10.1109/TRO.2024.3484630},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {4725-4744},
  shortjournal = {IEEE Trans. Robot.},
  title        = {The impact of stress and workload on human performance in robot teleoperation tasks},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Augmented maximum correntropy criterion for robust geometric
perception. <em>TROB</em>, <em>40</em>, 4705–4724. (<a
href="https://doi.org/10.1109/TRO.2024.3484608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximum correntropy criterion (MCC) is a robust and powerful technique to handle heavy-tailed nonGaussian noise, which has many applications in the fields of vision, signal processing, machine learning, etc. In this article, we introduce several contributions to the MCC and propose an augmented MCC (AMCC), which raises the robustness of classic MCC variants for robust fitting to an unprecedented level. Our first contribution is to present an accurate bandwidth estimation algorithm based on the probability density function (PDF) matching, which solves the instability problem of the Silverman&#39;s rule. Our second contribution is to introduce the idea of graduated nonconvexity (GNC) and a worst-rejection strategy into MCC, which compensates for the sensitivity of MCC to high outlier ratios. Our third contribution is to provide a definition of local distribution measure to evaluate the quality of inliers, which makes the MCC no longer limited to random outliers but is generally suitable for both random and clustered outliers. Our fourth contribution is to show the generalizability of the proposed AMCC by providing eight application examples in geometry perception and performing comprehensive evaluations on five of them. Our experiments demonstrate that 1) AMCC is empirically robust to 80% $-$ 90% of random outliers across applications, which is much better than Cauchy M-estimation, MCC, and GNC-GM; 2) AMCC achieves excellent performance in clustered outliers, whose success rate is 60% $-$ 70% percentage points higher than the second-ranked method at 80% of outliers; 3) AMCC can run in real-time, which is 10 $-$ 100 times faster than RANSAC-type methods in low-dimensional estimation problems with high outlier ratios. This gap will increase exponentially with the model dimension.},
  archive      = {J_TROB},
  author       = {Jiayuan Li and Qingwu Hu and Xinyi Liu and Yongjun Zhang},
  doi          = {10.1109/TRO.2024.3484608},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {4705-4724},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Augmented maximum correntropy criterion for robust geometric perception},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic tissue traction using miniature force-sensing
forceps for minimally invasive surgery. <em>TROB</em>, <em>40</em>,
4690–4704. (<a href="https://doi.org/10.1109/TRO.2024.3486177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common limitation of autonomous tissue manipulation in robotic minimally invasive surgery (MIS) is the absence of force sensing and control at the tool level. Recently, our team has developed miniature force-sensing forceps that can simultaneously measure the grasping and pulling forces during tissue manipulation. Based on this design, here we further present a method to automate tissue traction that comprises grasping and pulling stages. During this process, the grasping and pulling forces can be controlled either separately or simultaneously through force decoupling. The force controller is built upon a static model of tissue manipulation, considering the interaction between the force-sensing forceps and soft tissue. The efficacy of this force control approach is validated through a series of experiments comparing targeted, estimated, and actual reference forces. To verify the feasibility of the proposed method in surgical applications, various tissue resections are conducted on ex vivo tissues employing a dual-arm robotic setup. Finally, we discuss the benefits of multiforce control in tissue traction, evidenced through comparative analyses of various ex vivo tissue resections with and without the proposed method, and the potential generalization with traction on different tissues. The results affirm the feasibility of implementing automatic tissue traction using miniature forceps with multiforce control, suggesting its potential to promote autonomous MIS.},
  archive      = {J_TROB},
  author       = {Tangyou Liu and Xiaoyi Wang and Jay Katupitiya and Jiaole Wang and Liao Wu},
  doi          = {10.1109/TRO.2024.3486177},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {4690-4704},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Automatic tissue traction using miniature force-sensing forceps for minimally invasive surgery},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trust and dependence on robotic decision support.
<em>TROB</em>, <em>40</em>, 4670–4689. (<a
href="https://doi.org/10.1109/TRO.2024.3484628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates people&#39;s trust and dependence on robotic decision support systems (DSSs), which provide cognitive assistance through suggestions. Robotic DSSs may not always offer optimal suggestions, requiring people to rely carefully to maximize performance. We analyze user reliance on suboptimal robots for solving instantaneous and sequential decision-making tasks with a math and card game, respectively. In instantaneous tasks, we find that the users&#39; perceived anthropomorphism $(p &amp;lt; . 001$ ) and the robot&#39;s behavior after a decision support failure ( $p &amp;lt; . 001$ ) significantly impact user trust. In a sequential task where the effectiveness of the human–robot team is not revealed until after several decisions, we find that introducing a user-initiated decision proposal before the robot reveals its recommendation can mitigate overreliance ( $p &amp;lt; . 05$ ) and users&#39; task expertise is critical in determining appropriate dependence on the robot&#39;s suggestions ( $p &amp;lt; . 01$ ). Combined, these studies are synergistic and the first to jointly examine the influence of various factors on user trust and dependence, offering guidance for designing robotic DSSs to maximize human–robot task performance.},
  archive      = {J_TROB},
  author       = {Manisha Natarajan and Matthew Gombolay},
  doi          = {10.1109/TRO.2024.3484628},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {4670-4689},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Trust and dependence on robotic decision support},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human–robot cooperative piano playing with learning-based
real-time music accompaniment. <em>TROB</em>, <em>40</em>, 4650–4669.
(<a href="https://doi.org/10.1109/TRO.2024.3484633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in machine learning have paved the way for the development of musical and entertainment robots. However, human–robot cooperative instrument playing remains a challenge, particularly due to the intricate motor coordination and temporal synchronization. In this article, we propose a theoretical framework for human–robot cooperative piano playing based on nonverbal cues. First, we present a music improvisation model that employs a recurrent neural network (RNN) to predict appropriate chord progressions based on the human&#39;s melodic input. Second, we propose a behavior-adaptive controller to facilitate seamless temporal synchronization, allowing the cobot to generate harmonious acoustics. The collaboration takes into account the bidirectional information flow between the human and robot. We have developed an entropy-based system to assess the quality of cooperation by analyzing the impact of different communication modalities during human–robot collaboration. Experiments demonstrate that our RNN-based improvisation can achieve a 93% accuracy rate. Meanwhile, with the MPC adaptive controller, the robot could respond to the human teammate in homophony performances with real-time accompaniment. Our designed framework has been validated to be effective in allowing humans and robots to work collaboratively in the artistic piano-playing task.},
  archive      = {J_TROB},
  author       = {Huijiang Wang and Xiaoping Zhang and Fumiya Iida},
  doi          = {10.1109/TRO.2024.3484633},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {4650-4669},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Human–Robot cooperative piano playing with learning-based real-time music accompaniment},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motion planning and inertia-based control for impact aware
manipulation. <em>TROB</em>, <em>40</em>, 2201–2216. (<a
href="https://doi.org/10.1109/TRO.2023.3319895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a metric called hitting flux, which is used in the motion generation and controls for a robot manipulator to interact with the environment through a hitting or a striking motion. Given the task of placing a known object outside of the workspace of the robot, the robot needs to come in contact with it at a nonzero relative speed. The configuration of the robot and the speed at contact matter because they affect the motion of the object. The physical quantity called hitting flux depends on the robot&#39;s configuration, the robot speed, and the properties of the environment. An approach to achieve the desired directional preimpact flux for the robot through a combination of a dynamical system for motion generation and a control system that regulates the directional inertia of the robot is presented. Furthermore, a quadratic program formulation for achieving a desired inertia matrix at a desired position while following a motion plan constrained to the robot limits is presented. The system is tested for different scenarios in simulation showing the repeatability of the procedure and in real scenarios with KUKA LBR iiwa 7 robot.},
  archive      = {J_TROB},
  author       = {Harshit Khurana and Aude Billard},
  doi          = {10.1109/TRO.2023.3319895},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {2201-2216},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Motion planning and inertia-based control for impact aware manipulation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Present and future of SLAM in extreme environments: The
DARPA SubT challenge. <em>TROB</em>, <em>40</em>, 936–959. (<a
href="https://doi.org/10.1109/TRO.2023.3323938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article surveys recent progress and discusses future opportunities for simultaneous localization and mapping (SLAM) in extreme underground environments. SLAM in subterranean environments, from tunnels, caves, and man-made underground structures on Earth, to lava tubes on Mars, is a key enabler for a range of applications, such as planetary exploration, search and rescue, disaster response, and automated mining, among others. SLAM in underground environments has recently received substantial attention, thanks to the DARPA Subterranean (SubT) Challenge , a global robotics competition aimed at assessing and pushing the state of the art in autonomous robotic exploration and mapping in complex underground environments. This article reports on the state of the art in underground SLAM by discussing different SLAM strategies and results across six teams that participated in the three-year-long SubT competition. In particular, the article has four main goals. First, we review the algorithms, architectures, and systems adopted by the teams; particular emphasis is put on light detection and ranging (LIDAR)-centric SLAM solutions (the go-to approach for virtually all teams in the competition), heterogeneous multirobot operation (including both aerial and ground robots), and real-world underground operation (from the presence of obscurants to the need to handle tight computational constraints). We do not shy away from discussing the “dirty details” behind the different SubT SLAM systems, which are often omitted from technical papers. Second, we discuss the maturity of the field by highlighting what is possible with the current SLAM systems and what we believe is within reach with some good systems engineering. Third, we outline what we believe are fundamental open problems, which are likely to require further research to break through. Finally, we provide a list of open-source SLAM implementations and datasets that have been produced during the SubT challenge and related efforts and constitute a useful resource for researchers and practitioners.},
  archive      = {J_TROB},
  author       = {Kamak Ebadi and Lukas Bernreiter and Harel Biggie and Gavin Catt and Yun Chang and Arghya Chatterjee and Christopher E. Denniston and Simon-Pierre Deschênes and Kyle Harlow and Shehryar Khattak and Lucas Nogueira and Matteo Palieri and Pavel Petráček and Matěj Petrlík and Andrzej Reinke and Vít Krátký and Shibo Zhao and Ali-akbar Agha-mohammadi and Kostas Alexis and Christoffer Heckman and Kasra Khosoussi and Navinda Kottege and Benjamin Morrell and Marco Hutter and Fred Pauling and François Pomerleau and Martin Saska and Sebastian Scherer and Roland Siegwart and Jason L. Williams and Luca Carlone},
  doi          = {10.1109/TRO.2023.3323938},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {936-959},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Present and future of SLAM in extreme environments: The DARPA SubT challenge},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design, control, and motion planning for a root-perching
rotor-distributed manipulator. <em>TROB</em>, <em>40</em>, 660–676. (<a
href="https://doi.org/10.1109/TRO.2023.3327634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manipulation performance improvement is crucial for aerial robots. For aerial manipulators, the baselink position and attitude errors directly affect the precision at the end effector. To address this stability problem, fixed-body approaches such as perching on the environment using the rotor suction force are useful. Additionally, conventional arm-equipped multirotors, called rotor-concentrated manipulators, find it difficult to generate a large wrench at the end effector due to joint torque limitations. Using distributed rotors to each link, the thrust can support each link weight, decreasing the arm joints&#39; torque. Based on this approach, rotor-distributed manipulators (RDMs) can increase feasible wrench and reachability of the end effector. This article introduces a minimal configuration of an RDM that can perch on surfaces, especially ceilings, using a part of their body. First, we design a minimal rotor-distributed arm considering the flight and end-effector performance. Second, a flight controller is proposed for this minimal RDM along with a perching controller adaptable for various types of aerial robots. Third, we propose a motion planning method based on inverse kinematics, considering specific constraints to the proposed RDMs, such as perching force. Finally, we evaluate flight and perching motions and confirm that the proposed manipulator can significantly improve the manipulation performance.},
  archive      = {J_TROB},
  author       = {Takuzumi Nishio and Moju Zhao and Kei Okada and Masayuki Inaba},
  doi          = {10.1109/TRO.2023.3327634},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {660-676},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design, control, and motion planning for a root-perching rotor-distributed manipulator},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A kinetostatic model for concentric push–pull robots.
<em>TROB</em>, <em>40</em>, 554–572. (<a
href="https://doi.org/10.1109/TRO.2023.3327811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concentric push–pull robots (CPPR) operate through the mechanical interactions of concentrically nested, laser-cut tubes with offset stiffness centers. The distal tips of the tubes are attached to each other, and relative displacement of the tube bases generates bending in the CPPR. Previous CPPR kinematic models assumed two tubes, planar shapes, no torsion, and no external loads. In this article, we develop a new, more general CPPR model accounting for any number of tubes, describing their variable-curvature 3-D shape when actuated, including the effects of torsion and external loads. To accomplish this, we employ a modified Kirchhoff rod model for each tube (with an offset stiffness center) and embed the constraints of concentricity. We use an energy method to determine robot shape as a function of actuation and external loading. We experimentally validate this kinetostatic model on prototype CPPRs with two tubes and three tubes and nonconstant laser-cut patterns that create variable curvature and stiffness. Experimental results agree with the model, paving the way for the use of this model in design optimization, planning, and control of CPPRs.},
  archive      = {J_TROB},
  author       = {Jake A. Childs and Caleb Rucker},
  doi          = {10.1109/TRO.2023.3327811},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {554-572},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A kinetostatic model for concentric Push–Pull robots},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bioinspired cable-driven actuation system for wearable
robotic devices: Design, control, and characterization. <em>TROB</em>,
<em>40</em>, 520–539. (<a
href="https://doi.org/10.1109/TRO.2023.3324200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable robotic devices interact with humans by applying the assistive force in parallel with muscle–tendon systems. Designing actuations in mimicking the natural activation patterns of human muscles is a promising way to optimize the performance of wearable robots. In this article, we propose a bioinspired cable-driven actuation system capable of providing anisometric contractions (including concentric and eccentric contraction) assistance or nearly acting as a transparent device in an efficient manner. A novel clutch–spring mechanism is employed to accomplish switches between assistive modes and the transparent mode. Corresponding control strategies coordinating with the mechanical design were presented and described in detail. Multiple evaluations were conducted on a test bench to characterize the system&#39;s performance. The closed-loop bandwidth of the system running concentric assistance control was 18.2 Hz. The R -squared values of linear fitting under eccentric assistance control were above 0.99. The engagement time of the proposed clutch was about 90 ms. Applying the actuation to an ankle exoskeleton, multiple walking experiments with electromyography measurements were performed on five subjects to show its application potential in existing wearable robots. Experimental results revealed that the proposed design could reduce soleus muscle activity by 27.32% compared with normal walking. This study highlights the importance of functional bionic design in human-assistance-related devices and introduces a general actuation system that could be directly applied to existing cable-driven wearable robots.},
  archive      = {J_TROB},
  author       = {Ming Xu and Zhihao Zhou and Zezheng Wang and Lecheng Ruan and Jingeng Mai and Qining Wang},
  doi          = {10.1109/TRO.2023.3324200},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {520-539},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Bioinspired cable-driven actuation system for wearable robotic devices: Design, control, and characterization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive asynchronous control using meta-learned neural
ordinary differential equations. <em>TROB</em>, <em>40</em>, 403–420.
(<a href="https://doi.org/10.1109/TRO.2023.3326350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based reinforcement learning and control have demonstrated great potential in various sequential decision making problem domains, including in robotics settings. However, real-world robotics systems often present challenges that limit the applicability of those methods. In particular, we note two problems that jointly happen in many industrial systems: first, irregular/asynchronous observations and actions and, second, dramatic changes in environment dynamics from an episode to another (e.g .$,$ varying payload inertial properties). We propose a general framework that overcomes those difficulties by meta-learning adaptive dynamics models for continuous-time prediction and control. The proposed approach is task-agnostic and can be adapted to new tasks in a straight-forward manner. We present evaluations in two different robot simulations and on a real industrial robot.},
  archive      = {J_TROB},
  author       = {Achkan Salehi and Steffen Rühl and Stephane Doncieux},
  doi          = {10.1109/TRO.2023.3326350},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {403-420},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Adaptive asynchronous control using meta-learned neural ordinary differential equations},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EVOLVER: Online learning and prediction of disturbances for
robot control. <em>TROB</em>, <em>40</em>, 382–402. (<a
href="https://doi.org/10.1109/TRO.2023.3326318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In nature, when encountering unexpected uncertainty, animals tend to react quickly to ensure safety as the top priority, and gradually adapt to it based on recent valuable experience. We present a framework, namely EVOLutionary model-based uncertainty obserVER (EVOLVER), to mimic the bio-behavior for robotics to achieve rapid transient reaction ability and high-precision steady-state performance simultaneously. In particular, the Koopman operator is leveraged to explore the latent structure of internal and external disturbances, which is subsequently utilized in an evolutionary model-based disturbance observer to estimate the eventual disturbance. The resulting observer can guarantee a provable convergence in optimal conditions. Several practical considerations, including construction of a training dataset, data noise handling, and lifting functions selection, are elaborated in pursuit of the theoretical optimality in real applications. The lightweight feature of our framework enables online computation, even on a microprocessor (STM32F7 with 100 Hz control frequency). The framework is thoroughly evaluated by one simulation and three experiments. The experimental scenarios include: 1) Trajectory prediction of an irregular free-flying object subject to aerodynamic drag, 2) indoor and outdoor agile flights of a quadrotor subject to wind gust, and 3) high-precision end-effector control of a manipulator subject to base moving disturbance. Comparison results show that the performance of our proposed EVOLVER is superior to several state-of-the-art model-based and learning-based schemes.},
  archive      = {J_TROB},
  author       = {Jindou Jia and Wenyu Zhang and Kexin Guo and Jianliang Wang and Xiang Yu and Yang Shi and Lei Guo},
  doi          = {10.1109/TRO.2023.3326318},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {382-402},
  shortjournal = {IEEE Trans. Robot.},
  title        = {EVOLVER: Online learning and prediction of disturbances for robot control},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast kinodynamic planning on the constraint manifold with
deep neural networks. <em>TROB</em>, <em>40</em>, 277–297. (<a
href="https://doi.org/10.1109/TRO.2023.3326922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion planning is a mature area of research in robotics with many well-established methods based on optimization or sampling the state space, suitable for solving kinematic motion planning. However, when dynamic motions under constraints are needed and computation time is limited, fast kinodynamic planning on the constraint manifold is indispensable. In recent years, learning-based solutions have become alternatives to classical approaches, but they still lack comprehensive handling of complex constraints, such as planning on a lower dimensional manifold of the task space while considering the robot&#39;s dynamics. This article introduces a novel learning-to-plan framework that exploits the concept of constraint manifold, including dynamics, and neural planning methods. Our approach generates plans satisfying an arbitrary set of constraints and computes them in a short constant time, namely the inference time of a neural network. This allows the robot to plan and replan reactively, making our approach suitable for dynamic environments. We validate our approach on two simulated tasks and in a demanding real-world scenario, where we use a Kuka LBR Iiwa 14 robotic arm to perform the hitting movement in robotic air hockey.},
  archive      = {J_TROB},
  author       = {Piotr Kicki and Puze Liu and Davide Tateo and Haitham Bou-Ammar and Krzysztof Walas and Piotr Skrzypczyński and Jan Peters},
  doi          = {10.1109/TRO.2023.3326922},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {277-297},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Fast kinodynamic planning on the constraint manifold with deep neural networks},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spectral sparsification for communication-efficient
collaborative rotation and translation estimation. <em>TROB</em>,
<em>40</em>, 257–276. (<a
href="https://doi.org/10.1109/TRO.2023.3327635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose fast and communication-efficient optimization algorithms for multirobot rotation averaging and translation estimation problems that arise from collaborative simultaneous localization and mapping (SLAM), structure-from-motion (SfM), and camera network localization applications. Our methods are based on theoretical relations between the Hessians of the underlying Riemannian optimization problems and the Laplacians of suitably weighted graphs. We leverage these results to design a collaborative solver in which robots coordinate with a central server to perform approximate second-order optimization, by solving a Laplacian system at each iteration. Crucially, our algorithms permit robots to employ spectral sparsification to sparsify intermediate dense matrices before communication, and hence provide a mechanism to tradeoff accuracy with communication efficiency with provable guarantees. We perform rigorous theoretical analysis of our methods and prove that they enjoy (local) linear rate of convergence. Furthermore, we show that our methods can be combined with graduated nonconvexity to achieve outlier-robust estimation. Extensive experiments on real-world SLAM and SfM scenarios demonstrate the superior convergence rate and communication efficiency of our methods.},
  archive      = {J_TROB},
  author       = {Yulun Tian and Jonathan P. How},
  doi          = {10.1109/TRO.2023.3327635},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {257-276},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Spectral sparsification for communication-efficient collaborative rotation and translation estimation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Invariant smoother for legged robot state estimation with
dynamic contact event information. <em>TROB</em>, <em>40</em>, 193–212.
(<a href="https://doi.org/10.1109/TRO.2023.3328202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes an invariant smoother for legged robot state estimation with the measurement of an inertial measurement unit and leg kinematics while assuming static foot contact. Because the proposed smoother is formulated with the residual functions with group-affine property, their Jacobians become independent from current state estimates. These state-independent Jacobians lead to better convergence properties in optimizing the cost in the smoother, especially under dynamic contact events. The proposed slip rejection method increases the uncertainty of static contact assumption when the robot has dynamic contact events. The estimated foot velocity, which is utilized to detect the dynamic contact events, is re-evaluated within the preserving time window. We also propose the contact loop method, a new measurement model asserting that foot position remains constant over multiple timesteps during stable contact. The proposed estimator is tested through online experiments, including indoor and 160 m-long outdoor experiments, and compared against state-of-the-art algorithms.},
  archive      = {J_TROB},
  author       = {Ziwon Yoon and Joon-Ha Kim and Hae-Won Park},
  doi          = {10.1109/TRO.2023.3328202},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {193-212},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Invariant smoother for legged robot state estimation with dynamic contact event information},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Occupancy grid mapping without ray-casting for
high-resolution LiDAR sensors. <em>TROB</em>, <em>40</em>, 172–192. (<a
href="https://doi.org/10.1109/TRO.2023.3323936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occupancy mapping is a fundamental component of robotic systems to reason about the unknown and known regions of the environment. This article presents an efficient occupancy mapping framework for high-resolution light detection and ranging (LiDAR) sensors, termed D-Map. The framework introduces three main novelties to address the computational efficiency challenges of occupancy mapping. First, we use a depth image to determine the occupancy state of regions instead of the traditional ray-casting method. Second, we introduce an efficient on-tree update strategy on a tree-based map structure. These two techniques avoid redundant visits to small cells, significantly reducing the number of cells to be updated. Third, we remove known cells from the map at each update by leveraging the low false alarm rate of LiDAR sensors. This approach not only enhances our framework&#39;s update efficiency by reducing map size but also endows it with an interesting decremental property, which we have named D-Map. To support our design, we provide theoretical analyzes of the accuracy of the depth image projection and time complexity of occupancy updates. Furthermore, we conduct extensive benchmark experiments on various LiDAR sensors in both public and private datasets. Our framework demonstrates superior efficiency in comparison with other state-of-the-art methods while maintaining comparable mapping accuracy and high memory efficiency. We demonstrate two real-world applications of D-Map for real-time occupancy mapping on a handheld device and an aerial platform carrying a high-resolution LiDAR.},
  archive      = {J_TROB},
  author       = {Yixi Cai and Fanze Kong and Yunfan Ren and Fangcheng Zhu and Jiarong Lin and Fu Zhang},
  doi          = {10.1109/TRO.2023.3323936},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {172-192},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Occupancy grid mapping without ray-casting for high-resolution LiDAR sensors},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Singularity analysis of rigid directed bearing graphs for
quadrotor formations. <em>TROB</em>, <em>40</em>, 139–157. (<a
href="https://doi.org/10.1109/TRO.2023.3324198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decentralization of formations using onboard sensing is important for multirobot systems, improving the robustness and independence of fleet operations. Bearing measurements (obtainable from embedded cameras) are an attractive choice for use in decentralized formation control, however, this requires that the formation framework be bearing rigid. Rigidity may be checked numerically for a given formation framework, however, it remains difficult to determine the geometric conditions under which otherwise rigid formations become flexible. This article models the sensor and robot constraints in bearing formations of quadrotors as a kinematic mechanism with analogous properties to find geometric conditions for the degeneration of bearing rigidity (singularities) and the resulting uncontrollable motions. A classification of singularities based on graph substructures is developed, and it is shown that arbitrarily large formations may be designed for which all singularities lie within a known set of geometric conditions. An application on how to use the knowledge of all singularity cases in a formation for singularity-free control maintenance is provided.},
  archive      = {J_TROB},
  author       = {Julian Erskine and Sébastien Briot and Isabelle Fantoni and Abdelhamid Chriette},
  doi          = {10.1109/TRO.2023.3324198},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {139-157},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Singularity analysis of rigid directed bearing graphs for quadrotor formations},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robot web for distributed many-device localization.
<em>TROB</em>, <em>40</em>, 121–138. (<a
href="https://doi.org/10.1109/TRO.2023.3324127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that a distributed network of robots or other devices which make measurements of each other can collaborate to globally localize via efficient ad hoc peer-to-peer communication. Our Robot Web solution is based on Gaussian belief propagation (GBP) on the fundamental nonlinear factor graph describing the probabilistic structure of all of the observations robots make internally or of each other, and is flexible for any type of robot, motion or sensor. We define a simple and efficient communication protocol which can be implemented by the publishing and reading of web pages or other asynchronous communication technologies. We show in simulations with up to 1000 robots interacting in arbitrary patterns that our solution convergently achieves global accuracy as accurate as a centralized nonlinear factor graph solver while operating with high distributed efficiency of computation and communication. Via the use of robust factors in GBP, our method is tolerant to a high percentage of faulty sensor measurements or dropped communication packets. Furthermore, we showcase that the system operates on real robots with limited onboard computational resources.},
  archive      = {J_TROB},
  author       = {Riku Murai and Joseph Ortiz and Sajad Saeedi and Paul H. J. Kelly and Andrew J. Davison},
  doi          = {10.1109/TRO.2023.3324127},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {121-138},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A robot web for distributed many-device localization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic synthesis of 1-DOF transformable wheel mechanisms.
<em>TROB</em>, <em>40</em>, 101–120. (<a
href="https://doi.org/10.1109/TRO.2023.3328970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transformable wheel mechanism of a trifooted mobile service robot determines its driving performance. Currently, two independent actuators adjust the wheel&#39;s three feet adaptively, but we aim to develop novel single-actuator-operable 1-DOF transformable wheel mechanisms. Due to the unexplored nature of 1-DOF mechanisms, the trial-and-error approach may fail to find such mechanisms. Herein, we propose a fully automated gradient-based design approach that simultaneously determines the mechanism&#39;s topology, dimension, and joint type without a baseline mechanism. We take both fundamental kinematic and functional (such as torque–force transmission ratio) requirements into account. Our formulation employing a unified ground synthesis model is newly established to consider the trajectory and orientation of the mechanism end effector, control the number of synthesized prismatic joints, and satisfy the torque–force transmission ratio. Under various design constraints, we successfully synthesized novel mechanisms and their functionalities were validated via simulations and the motions of their prototypes.},
  archive      = {J_TROB},
  author       = {Jungho Kim and Jeong Won Shim and Seok Won Kang and Youngsoo Kim and Yoon Young Kim},
  doi          = {10.1109/TRO.2023.3328970},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {101-120},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Automatic synthesis of 1-DOF transformable wheel mechanisms},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stability analysis of tendon driven continuum robots and
application to active softening. <em>TROB</em>, <em>40</em>, 85–100. (<a
href="https://doi.org/10.1109/TRO.2023.3324571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tendon driven continuum robots are often considered to navigate through and operate in cluttered environments. While their compliance allows them to conform safely to obstacles, it leads them also to buckle under tendon actuation. In this article, we perform for the first time an extensive elastic stability analysis of these robots for arbitrary planar designs. The buckling phenomena are investigated and analyzed using bifurcation diagrams, complementing the current state of the art and adding new knowledge about robots composed of $n$ spacer disks. We show the existence of multiple robot configurations with different shapes, achievable with the same actuation inputs. A global stability criterion is also established, which links the critical tendon force, until which the robot is stable to the design parameters. Finally, the buckling phenomena are used to actively soften the robot for a better compromise between compliance and payload. An open loop control strategy is proposed, which can theoretically decrease the stiffness to zero, while maintaining the same robot shape. Experimentally, the robot is made four times more compliant than it is nominally using tendon actuation only.},
  archive      = {J_TROB},
  author       = {Quentin Peyron and Jessica Burgner-Kahrs},
  doi          = {10.1109/TRO.2023.3324571},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {85-100},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Stability analysis of tendon driven continuum robots and application to active softening},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continuous occupancy mapping in dynamic environments using
particles. <em>TROB</em>, <em>40</em>, 64–84. (<a
href="https://doi.org/10.1109/TRO.2023.3323841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle-based dynamic occupancy maps were proposed in recent years to model the obstacles in dynamic environments. Current particle-based maps describe the occupancy status in discrete grid form and suffer from the grid size problem, wherein a large grid size is unfavorable for motion planning while a small grid size lowers efficiency and causes gaps and inconsistencies. To tackle this problem, this article generalizes the particle-based map into continuous space and builds an efficient 3-D egocentric local map. A dual-structure subspace division paradigm, composed of a voxel subspace division and a novel pyramid-like subspace division, is proposed to propagate particles and update the map efficiently with the consideration of occlusions. The occupancy status at an arbitrary point in the map space can then be estimated with the weights of the particles. To reduce the noise in modeling static and dynamic obstacles simultaneously, an initial velocity estimation approach and a mixture model are utilized. Experimental results show that our map can effectively and efficiently model both dynamic obstacles and static obstacles. Compared to the state-of-the-art grid-form particle-based map, our map enables continuous occupancy estimation and substantially improves the mapping performance at different resolutions.},
  archive      = {J_TROB},
  author       = {Gang Chen and Wei Dong and Peng Peng and Javier Alonso-Mora and Xiangyang Zhu},
  doi          = {10.1109/TRO.2023.3323841},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {64-84},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Continuous occupancy mapping in dynamic environments using particles},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization-based control for dynamic legged robots.
<em>TROB</em>, <em>40</em>, 43–63. (<a
href="https://doi.org/10.1109/TRO.2023.3324580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a world designed for legs, quadrupeds, bipeds, and humanoids have the opportunity to impact emerging robotics applications from logistics, to agriculture, to home assistance. The goal of this survey is to cover the recent progress toward these applications that have been driven by model-based optimization for the real-time generation and control of movement. The majority of the research community has converged on the idea of generating locomotion control laws by solving an optimal control problem (OCP) in either a model-based or data-driven manner. However, solving the most general of these problems online remains intractable due to complexities from intermittent unidirectional contacts with the environment, and from the many degrees of freedom of legged robots. This survey covers methods that have been pursued to make these OCPs computationally tractable, with a specific focus on how environmental contacts are treated, how the model can be simplified, and how these choices affect the numerical solution methods employed. The survey focuses on model-based optimization while paving its way for broader combination with learning-based formulations to accelerate progress in this growing field.},
  archive      = {J_TROB},
  author       = {Patrick M. Wensing and Michael Posa and Yue Hu and Adrien Escande and Nicolas Mansard and Andrea Del Prete},
  doi          = {10.1109/TRO.2023.3324580},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {43-63},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Optimization-based control for dynamic legged robots},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Majorization minimization methods for distributed pose graph
optimization. <em>TROB</em>, <em>40</em>, 22–42. (<a
href="https://doi.org/10.1109/TRO.2023.3324818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of distributed pose graph optimization (PGO) that has important applications in multirobot simultaneous localization and mapping (SLAM). We propose the majorization minimization (MM) method for distributed PGO ( $\mathsf {MM\text{--}PGO}$ ) that applies to a broad class of robust loss kernels. The $\mathsf {MM\text{--}PGO}$ method is guaranteed to converge to first-order critical points under mild conditions. Furthermore, noting that the $\mathsf {MM\text{--}PGO}$ method is reminiscent of proximal methods, we leverage Nesterov&#39;s method and adopt adaptive restarts to accelerate convergence. The resulting accelerated MM methods for distributed PGO—both with a master node in the network ( $\mathsf {AMM\text{--}PGO}^*$ ) and without ( $\mathsf {AMM\text{--}PGO}^{\#}$ )—have faster convergence in contrast to the $\mathsf {MM\text{--}PGO}$ method without sacrificing theoretical guarantees. In particular, the $\mathsf {AMM\text{--}PGO}^{\#}$ method, which needs no master node and is fully decentralized, features a novel adaptive restart scheme and has a rate of convergence comparable to that of the $\mathsf {AMM\text{--}PGO}^*$ method using a master node to aggregate information from all the nodes. The efficacy of this work is validated through extensive applications to 2-D and 3-D SLAM benchmark datasets and comprehensive comparisons against existing state-of-the-art methods, indicating that our MM methods converge faster and result in better solutions to distributed PGO.},
  archive      = {J_TROB},
  author       = {Taosha Fan and Todd D. Murphey},
  doi          = {10.1109/TRO.2023.3324818},
  journal      = {IEEE Transactions on Robotics},
  month        = {10},
  pages        = {22-42},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Majorization minimization methods for distributed pose graph optimization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asynchronous blob tracker for event cameras. <em>TROB</em>,
<em>40</em>, 4750–4767. (<a
href="https://doi.org/10.1109/TRO.2024.3454410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-based cameras are popular for tracking fast-moving objects due to their high temporal resolution, low latency, and high dynamic range. In this article, we propose a novel algorithm for tracking event blobs using raw events asynchronously in real time. We introduce the concept of an event blob as a spatio-temporal likelihood of event occurrence where the conditional spatial likelihood is blob-like. Many real-world objects, such as car headlights or any quickly moving foreground objects, generate event blob data. The proposed algorithm uses a nearest neighbor classifier with a dynamic threshold criteria for data association coupled with an extended Kalman filter to track the event blob state. Our algorithm achieves highly accurate blob tracking, velocity estimation, and shape estimation even under challenging lighting conditions and high-speed motions ( $&amp;gt;$ 11 000 pixels/s). The microsecond time resolution achieved means that the filter output can be used to derive secondary information, such as time-to-contact or range estimation, that will enable applications to real-world problems, such as collision avoidance, in autonomous driving.},
  archive      = {J_TROB},
  author       = {Ziwei Wang and Timothy Molloy and Pieter van Goor and Robert Mahony},
  doi          = {10.1109/TRO.2024.3454410},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4750-4767},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Asynchronous blob tracker for event cameras},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using implicit behavior cloning and dynamic movement
primitive to facilitate reinforcement learning for robot motion
planning. <em>TROB</em>, <em>40</em>, 4733–4749. (<a
href="https://doi.org/10.1109/TRO.2024.3468770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) for motion planning of multi-degree-of-freedom robots still suffers from low efficiency in terms of slow training speed and poor generalizability. In this article, we propose a novel RL-based robot motion planning framework that uses implicit behavior cloning (IBC) and dynamic movement primitive (DMP) to improve the training speed and generalizability of an off-policy RL agent. IBC utilizes human demonstration data to leverage the training speed of RL, and DMP serves as a heuristic model that transfers motion planning into a simpler planning space. To support this, we also create a human demonstration dataset using a pick-and-place experiment that can be used for similar studies. Comparison studies reveal the advantage of the proposed method over the conventional RL agents with faster training speed and higher scores. A real-robot experiment indicates the applicability of the proposed method to a simple assembly task. Our work provides a novel perspective on using motion primitives and human demonstration to leverage the performance of RL for robot applications.},
  archive      = {J_TROB},
  author       = {Zengjie Zhang and Jayden Hong and Amir M. Soufi Enayati and Homayoun Najjaran},
  doi          = {10.1109/TRO.2024.3468770},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4733-4749},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Using implicit behavior cloning and dynamic movement primitive to facilitate reinforcement learning for robot motion planning},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial bacteria flagella with microstructured
soft-magnetic teeth. <em>TROB</em>, <em>40</em>, 4719–4732. (<a
href="https://doi.org/10.1109/TRO.2024.3463482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating functional subunits into a microrobot offers a promising pathway to enhance its operational capabilities. The functional integration of microrobots lies in organizing subunit distribution into a 3-D morphology while balancing the geometry formation affected by subunits and locomotion performance. Here, in this article, discrete microstructured soft-magnetic teeth (MTs) are circularly embedded into an artificial bacterial flagellum (ABF) to function as equivalent subunits, representing a good start to demonstrate the integration of subelements in microrobots through local stress regulation. Based on various substructure patterns, the controllable geometry modulation of ABF-MTs has unveiled the tunable angle-dependent deformation behavior, offering numerous possibilities for geometric morphology and propulsion extension. The outstanding kinematic performance demonstrates the seamless fusion of functionality and propulsion by maintaining locomotion speed, trajectory planning, pursuit, and step-motion-like behavior. Such a physical-forming strategy offers an avenue for incorporating subdevices in microrobot functionalization.},
  archive      = {J_TROB},
  author       = {Chaojian Hou and Kun Wang and Shuideng Wang and Zejie Yu and Xiaokai Wang and Zhi Qu and Mingxing Cheng and Lu Fan and Lixin Dong},
  doi          = {10.1109/TRO.2024.3463482},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4719-4732},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Artificial bacteria flagella with microstructured soft-magnetic teeth},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning to assist different wearers in multitasks:
Efficient and individualized human-in-the-loop adaptation framework for
lower-limb exoskeleton. <em>TROB</em>, <em>40</em>, 4699–4718. (<a
href="https://doi.org/10.1109/TRO.2024.3468768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the typical purposes of using lower-limb exoskeleton robots is to provide assistance to the wearer by supporting their weight and augmenting their physical capabilities according to a given task and human motion intentions. The generalizability of robots across different wearers in multiple tasks is important to ensure that the robot can provide correct and effective assistance in actual implementation. However, most lower-limb exoskeleton robots exhibit only limited generalizability. Therefore, this article proposes a human-in-the-loop learning and adaptation framework for exoskeleton robots to improve their performance in various tasks and for different wearers. To suit different wearers, an individualized walking trajectory is generated online using dynamic movement primitives and Bayes optimization. To accommodate various tasks, a task translator is constructed using a neural network to generalize a trajectory to more complex scenarios. These generalization techniques are integrated into a unified variable impedance model, which regulates the exoskeleton to provide assistance while ensuring safety. In addition, an anomaly detection network is developed to quantitatively evaluate the wearer&#39;s comfort, which is considered in the trajectory learning procedure and contributes to the relaxation of conflicts in impedance control. The proposed framework is easy to implement, because it requires proprioceptive sensors only to perform and deploy data-efficient learning schemes. This makes the exoskeleton practical for deployment in complex scenarios, accommodating different walking patterns, habits, tasks, and conflicts. Experiments and comparative studies on a lower-limb exoskeleton robot are performed to demonstrate the effectiveness of the proposed framework.},
  archive      = {J_TROB},
  author       = {Yu Chen and Shu Miao and Gong Chen and Jing Ye and Chenglong Fu and Bin Liang and Shiji Song and Xiang Li},
  doi          = {10.1109/TRO.2024.3468768},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4699-4718},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning to assist different wearers in multitasks: Efficient and individualized human-in-the-loop adaptation framework for lower-limb exoskeleton},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proprioceptive state estimation for amphibious tactile
sensing. <em>TROB</em>, <em>40</em>, 4684–4698. (<a
href="https://doi.org/10.1109/TRO.2024.3463509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel vision-based proprioception approach for a soft robotic finger that can estimate and reconstruct tactile interactions in terrestrial and aquatic environments. The key to this system lies in the finger&#39;s unique metamaterial structure, which facilitates omnidirectional passive adaptation during grasping, protecting delicate objects across diverse scenarios. A compact in-finger camera captures high-framerate images of the finger&#39;s deformation during contact, extracting crucial tactile data in real time. We present a volumetric discretized model of the soft finger and use the geometry constraints captured by the camera to find the optimal estimation of the deformed shape. The approach is benchmarked using a motion capture system with sparse markers and a haptic device with dense measurements. Both results show state-of-the-art accuracy, with a median error of 1.96 mm for overall body deformation, corresponding to 2.1 $\%$ of the finger&#39;s length. More importantly, the state estimation is robust in both on-land and underwater environments as we demonstrate its usage for underwater object shape sensing. This combination of passive adaptation and real-time tactile sensing paves the way for amphibious robotic grasping applications.},
  archive      = {J_TROB},
  author       = {Ning Guo and Xudong Han and Shuqiao Zhong and Zhiyuan Zhou and Jian Lin and Jian S. Dai and Fang Wan and Chaoyang Song},
  doi          = {10.1109/TRO.2024.3463509},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4684-4698},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Proprioceptive state estimation for amphibious tactile sensing},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ConvBKI: Real-time probabilistic semantic mapping network
with quantifiable uncertainty. <em>TROB</em>, <em>40</em>, 4648–4667.
(<a href="https://doi.org/10.1109/TRO.2024.3453771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop a modular neural network for real-time (&gt;10 Hz) semantic mapping in uncertain environments, which explicitly updates per-voxel probabilistic distributions within a neural network layer. Our approach combines the reliability of classical probabilistic algorithms with the performance and efficiency of modern neural networks. Although robotic perception is often divided between modern differentiable methods and classical explicit methods, a union of both is necessary for real-time and trustworthy performance. We introduce a novel convolutional Bayesian kernel inference (ConvBKI) layer which incorporates semantic segmentation predictions online into a 3-D map through a depthwise convolution layer by leveraging conjugate priors. We compare ConvBKI against state-of-the-art deep learning approaches and probabilistic algorithms for mapping to evaluate reliability and performance. We also create a robot operating system package of ConvBKI and test it on real-world perceptually challenging off-road driving data.},
  archive      = {J_TROB},
  author       = {Joey Wilson and Yuewei Fu and Joshua Friesen and Parker Ewen and Andrew Capodieci and Paramsothy Jayakumar and Kira Barton and Maani Ghaffari},
  doi          = {10.1109/TRO.2024.3453771},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4648-4667},
  shortjournal = {IEEE Trans. Robot.},
  title        = {ConvBKI: Real-time probabilistic semantic mapping network with quantifiable uncertainty},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Position regulation of a conductive nonmagnetic object with
two stationary rotating-magnetic-dipole field sources. <em>TROB</em>,
<em>40</em>, 4635–4647. (<a
href="https://doi.org/10.1109/TRO.2024.3454568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eddy currents induced by rotating magnetic dipole fields can produce forces and torques that enable dexterous manipulation of conductive nonmagnetic objects. This paradigm shows promise for application in the remediation of space debris. The induced force from each rotating-magnetic-dipole field source always includes a repulsive component, suggesting that the object should be surrounded by field sources to some degree to ensure the object does not leave the dexterous workspace during manipulation. In this article, we show that it is possible to fully control the position of an object in a workspace near the midpoint between just two stationary field sources. A given position controller requires a low-level force controller. We propose two new force controllers, and compare them with the state-of-the-art method from the literature. One of the new force controllers is particularly good at not inducing parasitic torques, which is hypothesized to be beneficial for future tasks manipulating and detumbling rotating resident space objects. We perform experimental verification using numerical and physical simulators of microgravity.},
  archive      = {J_TROB},
  author       = {Devin K. Dalton and Griffin F. Tabor and Tucker Hermans and Jake J. Abbott},
  doi          = {10.1109/TRO.2024.3454568},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4635-4647},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Position regulation of a conductive nonmagnetic object with two stationary rotating-magnetic-dipole field sources},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A networked multiagent system for mobile wireless
infrastructure on demand. <em>TROB</em>, <em>40</em>, 4598–4614. (<a
href="https://doi.org/10.1109/TRO.2024.3463493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the prevalence of wireless connectivity in urban areas around the globe, there remain numerous and diverse situations where connectivity is insufficient or unavailable. To address this, we introduce mobile wireless infrastructure on demand , a system of unmanned aerial vehicles (UAVs) that can be rapidly deployed to establish an ad hoc wireless network. This network has the capability of reconfiguring itself dynamically to satisfy and maintain the required quality of communication. The system optimizes the positions of the UAVs and the routing of data flows throughout the network to achieve this Quality of Service (QoS). By these means, task agents using the network simply request a desired QoS, and the system adapts accordingly while allowing them to move freely. We have validated this system both in simulation and in real-world experiments. The results demonstrate that our system effectively offers mobile wireless infrastructure on demand, extending the operational range of task agents and supporting complex mobility patterns, all while ensuring connectivity and being resilient to agent failures.},
  archive      = {J_TROB},
  author       = {Miguel Calvo-Fullana and Mikhail Gerasimenko and Daniel Mox and Leopoldo Agorio and Mariana del Castillo and Vijay Kumar and Alejandro Ribeiro and Juan Andrés Bazerque},
  doi          = {10.1109/TRO.2024.3463493},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4598-4614},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A networked multiagent system for mobile wireless infrastructure on demand},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A compact 2-DOF cross-scale piezoelectric robotic
manipulator with adjustable force for biological delicate puncture.
<em>TROB</em>, <em>40</em>, 4561–4577. (<a
href="https://doi.org/10.1109/TRO.2024.3462932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic micromanipulation technology plays a fundamental supporting role in biomedical engineering field. However, it is still a challenge for robotic manipulators to meet the puncture performance requirements for complex cells and curved vessels with different sizes, because they are difficult to achieve a comprehensive characteristic of multi-DOF, long stroke, high displacement resolution, large puncture force, and high force resolution for limitations of structures, driving elements, and actuation methods. To addresses this challenge, this article proposes the conceptual design of a piezoelectric robotic manipulator (PERM) driven by a single piezoelectric actuator. A configuration design idea and a new actuation method are elaborated to achieve 2-DOF cross-scale manipulation and adjustable puncture force. Theoretical analyses and simulations are carried out to investigate the influence of key structural parameters on displacement response and puncture force, as well as to determine the parameters. A prototype is fabricated, a dedicated handheld controller is developed, and a robotic micropuncture system is constructed to conduct characteristic testing and application research. Experimental results reveal that the manipulator achieves linear and rotary strokes of 38.5 mm and 360°, displacement resolutions of 48 nm and 0.38 μ rad, a puncture force range from 1.70 to 301.34 mN, and a force resolution of 0.13 mN. Additionally, the manipulator successfully performs delicate puncture of silicone capillaries with different sizes and a curved silicone capillary under collaborative manipulation of the piezoelectric platform. This article exhibits a high-performance PERM and verifies its feasibility in micropuncture of tiny and complex-shaped organisms.},
  archive      = {J_TROB},
  author       = {Xiang Gao and Jie Deng and Weiyi Wang and Qingbing Chang and Jianhua Sun and Junkao Liu and Shijing Zhang and Yingxiang Liu},
  doi          = {10.1109/TRO.2024.3462932},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4561-4577},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A compact 2-DOF cross-scale piezoelectric robotic manipulator with adjustable force for biological delicate puncture},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new wave in robotics: Survey on recent MmWave radar
applications in robotics. <em>TROB</em>, <em>40</em>, 4544–4560. (<a
href="https://doi.org/10.1109/TRO.2024.3463504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We survey the current state of millimeter-wave (mmWave) radar applications in robotics with a focus on unique capabilities, and discuss future opportunities based on the state of the art. Frequency modulated continuous wave mmWave radars operating in the 76–81 GHz range are an appealing alternative to lidars, cameras, and other sensors operating in the near-visual spectrum. Radar has been made more widely available in new packaging classes, more convenient for robotics and its longer wavelengths have the ability to bypass visual clutter, such as fog, dust, and smoke. We begin by covering radar principles as they relate to robotics. We then review the relevant new research across a broad spectrum of robotics applications beginning with motion estimation, localization, and mapping. We then cover object detection and classification, and then close with an analysis of current datasets and calibration techniques that provide entry points into radar research.},
  archive      = {J_TROB},
  author       = {Kyle Harlow and Hyesu Jang and Timothy D. Barfoot and Ayoung Kim and Christoffer Heckman},
  doi          = {10.1109/TRO.2024.3463504},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4544-4560},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A new wave in robotics: Survey on recent MmWave radar applications in robotics},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robotic cutting of fruits and vegetables: Modeling the
effects of deformation, fracture toughness, knife edge geometry, and
motion. <em>TROB</em>, <em>40</em>, 4526–4543. (<a
href="https://doi.org/10.1109/TRO.2024.3462943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a huge potential for automation of cutting fruits and vegetables in the kitchen and food industry as this can not only save time and labor on meal preparation and food packaging but also improve workspace safety. Foods may undergo large deformations, and the knife can experience different forces, which together make it difficult to carry out cutting as intended. With an accurate model, the contact force between the knife and the cutting board can be extracted from the sensor data for control to realize a smooth knife movement. In this article, we apply the finite element method (FEM) to estimate deformation and the cutting force, and linear elastic fracture mechanics to predict fracture. 3-D FEM is computationally prohibitive, since numerous tiny elements must be repeatedly regenerated around the knife edge as it moves further into a food item. To address this issue, we perform 2-D FEM modeling of parallel slices of the object and use interpolation to iteratively update forces and fracture, the latter of which is predicted when the energy release rate exceeds the material&#39;s fracture toughness. A strain-based analysis quantifies the reduction in the cutting force when the knife is in a slicing motion. Modeling is completed over the effects of the knife&#39;s edge geometry and cutting path (with translation and rotation). The scheme is then incorporated into an existing control strategy Mu et al. 2023 to perform the knife skill of rock chop on soft objects. Experiments conducted over various types of natural food have demonstrated the accuracy of our model and its potential for real-time cutting.},
  archive      = {J_TROB},
  author       = {Prajjwal Jamdagni and Yan-Bin Jia},
  doi          = {10.1109/TRO.2024.3462943},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4526-4543},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robotic cutting of fruits and vegetables: Modeling the effects of deformation, fracture toughness, knife edge geometry, and motion},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). M<span class="math inline"><sup>3</sup></span>tac: A
multispectral multimodal visuotactile sensor with beyond-human sensory
capabilities. <em>TROB</em>, <em>40</em>, 4506–4525. (<a
href="https://doi.org/10.1109/TRO.2024.3462931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To realize the exquisite interaction and precise manipulation for the robot, in this article, we propose a multispectral multimodal visuotactile sensor named M $^{3}$ Tac, which combines visible, near-infrared, and mid-infrared imaging technologies for the first time and can exceed the sensing ability of human skin in terms of resolution (719 pixels/cm $^{2}$ ), temperature sensing range (−20–130 $^\text{o}$ C), etc. The M $^{3}$ Tac cannot only realize high-quality sensing of deformation, texture, force, stickiness, and temperature comparable to human skin but also can realize proximity sensing that is lacking for human skin. To achieve this, we not only design a multispectral imaging system with an elastic film whose light penetrability can be regulated by the brightness of the light, but also develop corresponding algorithms, including the pixel-level force sensing with finite element method (accuracy: $\pm$ 0.023N), the proximity perception (accuracy: $\pm$ 3.8 mm), the 3-D reconstruction (accuracy: 0.33 mm), the super-resolution temperature sensing (accuracy: $\pm 0.3^\text{o}$ C), the multimodal fusion classification (accuracy: 98%), and the stickiness recognition (accuracy: 98%). Finally, we conduct experiments to verify the effectiveness and application potential of our research.},
  archive      = {J_TROB},
  author       = {Shoujie Li and Haixin Yu and Guoping Pan and Huaze Tang and Jiawei Zhang and Linqi Ye and Xiao-Ping Zhang and Wenbo Ding},
  doi          = {10.1109/TRO.2024.3462931},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4506-4525},
  shortjournal = {IEEE Trans. Robot.},
  title        = {M$^{3}$Tac: A multispectral multimodal visuotactile sensor with beyond-human sensory capabilities},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From sim to real: A pipeline for training and deploying
traffic smoothing cruise controllers. <em>TROB</em>, <em>40</em>,
4490–4505. (<a href="https://doi.org/10.1109/TRO.2024.3463407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing and validating controllers for connected and automated vehicles to enhance traffic flow presents significant challenges, from the complexity of replicating real-world stop-and-go traffic dynamics in simulation, to the intricacies involved in transitioning from simulation to actual deployment. In this work, we present a full pipeline from data collection to controller deployment. Specifically, we collect 772 km of driving data from the I-24 in Tennessee, and use it to build a one-lane simulator, placing simulated vehicles behind real-world trajectories. Using policy-gradient methods with an asymmetric critic, we improve fuel efficiency by over 10% when simulating congested scenarios. Our comprehensive approach includes reinforcement learning for controller training, software verification, hardware validation and setup, and navigating various sim-to-real challenges. Furthermore, we analyze the controller&#39;s behavior and wave-smoothing properties, and deploy it on four Toyota Rav4’s in a real-world validation experiment on the I-24. Finally, we release the driving dataset (Nice et al., 2021), the simulator and the trained controller (Lichtlé et al., 2022), to enable future benchmarking and controller design.},
  archive      = {J_TROB},
  author       = {Nathan Lichtlé and Eugene Vinitsky and Matthew Nice and Rahul Bhadani and Matthew Bunting and Fangyu Wu and Benedetto Piccoli and Benjamin Seibold and Daniel B. Work and Jonathan W. Lee and Jonathan Sprinkle and Alexandre M. Bayen},
  doi          = {10.1109/TRO.2024.3463407},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4490-4505},
  shortjournal = {IEEE Trans. Robot.},
  title        = {From sim to real: A pipeline for training and deploying traffic smoothing cruise controllers},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the evaluation of collision probability along a path.
<em>TROB</em>, <em>40</em>, 4449–4468. (<a
href="https://doi.org/10.1109/TRO.2024.3463479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Characterizing the risk of operations is a fundamental requirement in robotics, and a crucial ingredient of safe planning. The problem is multifaceted, with multiple definitions arising in the vast recent literature fitting different application scenarios and leading to different computational approaches. A basic element shared by most frameworks is the definition and evaluation of the probability of collision for a mobile object in an environment with obstacles. We observe that, even in basic cases, different interpretations are possible. This article proposes an index we call “Risk Density,” which offers a theoretical link between conceptually distant assumptions about the interplay of single collision events along a continuous path. We show how this index can be used to approximate the collision probability in the case where the robot evolves along a nominal continuous curve from random initial conditions. Indeed, under this hypothesis the proposed approximation outperforms some well-established methods either in accuracy or computational cost.},
  archive      = {J_TROB},
  author       = {Lorenzo Paiola and Giorgio Grioli and Antonio Bicchi},
  doi          = {10.1109/TRO.2024.3463479},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4449-4468},
  shortjournal = {IEEE Trans. Robot.},
  title        = {On the evaluation of collision probability along a path},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single-grasp deformable object discrimination: The effect of
gripper morphology, sensing modalities, and action parameters.
<em>TROB</em>, <em>40</em>, 4414–4426. (<a
href="https://doi.org/10.1109/TRO.2024.3463402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In haptic object discrimination, the effect of gripper embodiment, action parameters, and sensory channels has not been systematically studied. We used two anthropomorphic hands and two two-finger grippers to grasp two sets of deformable objects. On the object classification task, we found: 1) among classifiers, SVM on sensory features and LSTM on raw time series performed best across all grippers; 2) faster compression speeds degraded performance; 3) generalization to different grasping configurations was limited; transfer to different compression speeds worked well for the Barrett Hand only. Visualization of the feature spaces using PCA showed that gripper morphology and action parameters were the main source of variance, making generalization across embodiment or grip configurations very difficult. On the highly challenging dataset consisting of polyurethane foams alone, only the Barrett Hand achieved excellent performance. Tactile sensors can thus provide a key advantage even if recognition is based on stiffness rather than shape. The dataset with 24 000 measurements is publicly available.},
  archive      = {J_TROB},
  author       = {Michal Pliska and Shubhan Patni and Michal Mareš and Pavel Stoudek and Zdenek Straka and Karla Stepanova and Matej Hoffmann},
  doi          = {10.1109/TRO.2024.3463402},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4414-4426},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Single-grasp deformable object discrimination: The effect of gripper morphology, sensing modalities, and action parameters},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Confidence-aware object capture for a manipulator subject to
floating-base disturbances. <em>TROB</em>, <em>40</em>, 4396–4413. (<a
href="https://doi.org/10.1109/TRO.2024.3463476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing stationary aerial objects on unmanned surface vehicles (USVs) is challenging due to quasiperiodic and fast floating-base motions caused by wave-induced disturbances. It is hard to maintain high motion prediction accuracy due to the stochastic nature of these disturbances, and perform object capture through real-time tracking due to the limited active torque. We introduce confidence analysis in predictive capture. To address the inaccuracy predictions, we calculate a real-time confidence tube to evaluate the prediction quality. To overcome tracking difficulties, we plan a trajectory to capture the object at a future moment while maximizing the confidence of the capture position on the predicted trajectory. All calculations are completed within 0.2 s to ensure a timely response. We validate our approach through experiments, where we simulate disturbances by executing real USV motions using a servo platform. The results demonstrate that our method achieves an 80% success rate.},
  archive      = {J_TROB},
  author       = {Ruoyu Xu and Zixing Jiang and Beibei Liu and Yuquan Wang and Huihuan Qian},
  doi          = {10.1109/TRO.2024.3463476},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4396-4413},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Confidence-aware object capture for a manipulator subject to floating-base disturbances},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LeTac-MPC: Learning model predictive control for
tactile-reactive grasping. <em>TROB</em>, <em>40</em>, 4376–4395. (<a
href="https://doi.org/10.1109/TRO.2024.3463470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grasping is a crucial task in robotics, necessitating tactile feedback and reactive grasping adjustments for robust grasping of objects under various conditions and with differing physical properties. In this article, we introduce LeTac-MPC, a learning-based model predictive control (MPC) for tactile-reactive grasping. Our approach enables the gripper to grasp objects with different physical properties on dynamic and force-interactive tasks. We utilize a vision-based tactile sensor, GelSight (Yuan et al. 2017), which is capable of perceiving high-resolution tactile feedback that contains information on the physical properties and states of the grasped object. LeTac-MPC incorporates a differentiable MPC layer designed to model the embeddings extracted by a neural network from tactile feedback. This design facilitates convergent and robust grasping control at a frequency of 25 Hz. We propose a fully automated data collection pipeline and collect a dataset only using standardized blocks with different physical properties. However, our trained controller can generalize to daily objects with different sizes, shapes, materials, and textures. The experimental results demonstrate the effectiveness and robustness of the proposed approach. We compare LeTac-MPC with two purely model-based tactile-reactive controllers (MPC and PD) and open-loop grasping. Our results show that LeTac-MPC has optimal performance in dynamic and force-interactive tasks and optimal generalizability.},
  archive      = {J_TROB},
  author       = {Zhengtong Xu and Yu She},
  doi          = {10.1109/TRO.2024.3463470},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4376-4395},
  shortjournal = {IEEE Trans. Robot.},
  title        = {LeTac-MPC: Learning model predictive control for tactile-reactive grasping},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gatekeeper: Online safety verification and control for
nonlinear systems in dynamic environments. <em>TROB</em>, <em>40</em>,
4358–4375. (<a href="https://doi.org/10.1109/TRO.2024.3454415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents the gatekeeper algorithm, a real-time and computationally lightweight method that ensures that trajectories of a nonlinear system satisfy safety constraints despite sensing limitations. gatekeeper integrates with existing path planners and feedback controllers by introducing an additional verification step to ensure that proposed trajectories can be executed safely, despite nonlinear dynamics subject to bounded disturbances, input constraints, and partial knowledge of the environment. Our key contribution is that 1) we propose an algorithm to recursively construct safe trajectories by numerically forward propagating the system over a (short) finite horizon, and 2) we prove that tracking such a trajectory ensures the system remains safe for all future time, i.e., beyond the finite horizon. We demonstrate the method in a simulation of a dynamic firefighting mission, and in physical experiments of a quadrotor navigating in an obstacle environment that is sensed online. We also provide comparisons against the state-of-the-art techniques for similar problems.},
  archive      = {J_TROB},
  author       = {Devansh Ramgopal Agrawal and Ruichang Chen and Dimitra Panagou},
  doi          = {10.1109/TRO.2024.3454415},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4358-4375},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Gatekeeper: Online safety verification and control for nonlinear systems in dynamic environments},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward globally optimal state estimation using automatically
tightened semidefinite relaxations. <em>TROB</em>, <em>40</em>,
4338–4358. (<a href="https://doi.org/10.1109/TRO.2024.3454570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, semidefinite relaxations of common optimization problems in robotics have attracted growing attention due to their ability to provide globally optimal solutions. In many cases, it was shown that specific handcrafted redundant constraints are required to obtain tight relaxations, and thus global optimality. These constraints are formulation-dependent and typically identified through a lengthy manual process. Instead, the present article suggests an automatic method to find a set of sufficient redundant constraints to obtain tightness, if they exist. We first propose an efficient feasibility check to determine if a given set of variables can lead to a tight formulation. Second, we show how to scale the method to problems of bigger size. At no point of the process do we have to find redundant constraints manually. We showcase the effectiveness of the approach, in simulation and on real datasets, for range-based localization and stereo-based pose estimation. We also reproduce semidefinite relaxations presented in recent literature and show that our automatic method always finds a smaller set of constraints sufficient for tightness than previously considered.},
  archive      = {J_TROB},
  author       = {Frederike Dümbgen and Connor Holmes and Ben Agro and Timothy Barfoot},
  doi          = {10.1109/TRO.2024.3454570},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4338-4358},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Toward globally optimal state estimation using automatically tightened semidefinite relaxations},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multitentacle gripper for dynamic capture. <em>TROB</em>,
<em>40</em>, 4284–4300. (<a
href="https://doi.org/10.1109/TRO.2024.3454437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic capture is one of the most challenging issues to be solved in the field of robotics. Although robotic hands/grippers have emerged for decades, there are still few of them that can dynamically capture moving targets because the process is strongly accompanied by impact force and uncertainties in relative gripper/target locations and velocities. In this article, we present the novel design of a multitentacle gripper inspired by the motions of sea anemones. It is found that each tentacle of the sea anemone is not individually able to capture a fish but the collaboration of a larger number of tentacles can greatly enhance the overall capture ability. Based on this concept, 12 continuum arms including active and passive types are proposed and evaluated for their deformation to external forces. In addition, a deployable base, inspired by origami and Sarrus mechanisms, is utilized to change the posture of the continuum arms and drive the active arms. An inertial measurement unit is equipped to sense the impact of the dynamic targets. Finally, a series of experiments proved that the proposed multitentacle gripper could capture dynamic targets with different shapes, velocities, and collision angles, showing satisfactory capture robustness.},
  archive      = {J_TROB},
  author       = {Chenghao Yang and Ian D. Walker and David T. Branson and Jian S. Dai and Tao Sun and Rongjie Kang},
  doi          = {10.1109/TRO.2024.3454437},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4284-4300},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A multitentacle gripper for dynamic capture},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Certifiably correct range-aided SLAM. <em>TROB</em>,
<em>40</em>, 4265–4283. (<a
href="https://doi.org/10.1109/TRO.2024.3454430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the first algorithm to efficiently compute certifiably optimal solutions to range-aided simultaneous localization and mapping (RA-SLAM) problems. Robotic navigation systems increasingly incorporate point-to-point ranging sensors, leading to state estimation problems in the form of RA-SLAM. However, the RA-SLAM problem is significantly more difficult to solve than traditional pose-graph SLAM: Ranging sensor models introduce nonconvexity and single range measurements do not uniquely determine the transform between the involved sensors. As a result, RA-SLAM inference is sensitive to initial estimates yet lacks reliable initialization techniques. Our approach, certifiably correct RA-SLAM (CORA), leverages a novel quadratically constrained quadratic programming formulation of RA-SLAM to relax the RA-SLAM problem to a semidefinite program (SDP). CORA solves the SDP efficiently using the Riemannian Staircase methodology; the SDP solution provides both: 1) a lower bound on the RA-SLAM problem&#39;s optimal value and 2) an approximate solution of the RA-SLAM problem, which can be subsequently refined using local optimization. CORA applies to problems with arbitrary pose-pose, pose-landmark, and ranging measurements and, due to using convex relaxation, is insensitive to initialization. We evaluate CORA on several real-world problems. In contrast to state-of-the-art approaches, CORA is able to obtain high-quality solutions on all problems despite being initialized with random values. In addition, we study the tightness of the SDP relaxation with respect to important problem parameters: The number of: 1) robots; 2) landmarks; and 3) range measurements. These experiments demonstrate that the SDP relaxation is often tight and reveal relationships between graph connectivity and the tightness of the SDP relaxation.},
  archive      = {J_TROB},
  author       = {Alan Papalia and Andrew Fishberg and Brendan W. O&#39;Neill and Jonathan P. How and David M. Rosen and John J. Leonard},
  doi          = {10.1109/TRO.2024.3454430},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4265-4283},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Certifiably correct range-aided SLAM},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On safety and liveness filtering using hamilton–jacobi
reachability analysis. <em>TROB</em>, <em>40</em>, 4235–4251. (<a
href="https://doi.org/10.1109/TRO.2024.3454470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hamilton–Jacobi (HJ) reachability-based filtering provides a powerful framework to co-optimize performance and safety (or liveness) for autonomous systems. Under this filtering scheme, a nominal controller is minimally modified to ensure system safety or liveness. However, the resulting controllers can exhibit abrupt switching and bang-bang behavior, which is not suitable for applications of autonomous systems in the real world. This work presents a novel, unifying framework to design safety and liveness filters through reachability analysis. We explicitly characterize the maximal set of control inputs that ensures safety (or liveness) at a given state. Different safety filters can then be constructed using different subsets of this maximal set along with a projection operator to modify the nominal controller. We use the proposed framework to design three safety filters, each balancing performance, computation time, and smoothness differently. We highlight their relative strengths and limitations by applying these filters to autonomous navigation and rocket landing scenarios and on a physical robot testbed. We also discuss practical aspects associated with implementing these filters on real-world autonomous systems. Our research advances the understanding and potential application of reachability-based controllers on real-world autonomous systems.},
  archive      = {J_TROB},
  author       = {Javier Borquez and Kaustav Chakraborty and Hao Wang and Somil Bansal},
  doi          = {10.1109/TRO.2024.3454470},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4235-4251},
  shortjournal = {IEEE Trans. Robot.},
  title        = {On safety and liveness filtering using Hamilton–Jacobi reachability analysis},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design and control of roller grasper v3 for in-hand
manipulation. <em>TROB</em>, <em>40</em>, 4222–4234. (<a
href="https://doi.org/10.1109/TRO.2024.3454388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot in-hand manipulation is an important skill for robots to carry out sophisticated tasks that require moving the grasped object within hand. In this work, we present the Roller Grasper V3, a nonanthropomorphic robot grasper with a steerable roller on each of its four fingertips, and a manipulation architecture that enables the Roller Grasper V3 to achieve full 6-DoF manipulation of the grasped object in $SE(3)$ . The manipulation architecture consists of a high-level planner that searches for a feasible path with waypoints for the object to be manipulated, and a low-level control policy that is used to navigate the object in between the adjacent waypoints. The method was experimentally validated on the Roller Grasper V3 to manipulate multiple objects with different geometries and topologies.},
  archive      = {J_TROB},
  author       = {Shenli Yuan and Lin Shao and Yunhai Feng and Jiatong Sun and Teng Xue and Connor L. Yako and Jeannette Bohg and J. Kenneth Salisbury},
  doi          = {10.1109/TRO.2024.3454388},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4222-4234},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design and control of roller grasper v3 for in-hand manipulation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anytime replanning of robot coverage paths for partially
unknown environments. <em>TROB</em>, <em>40</em>, 4190–4206. (<a
href="https://doi.org/10.1109/TRO.2024.3454417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a method to replan coverage paths for a robot operating in an environment with initially unknown static obstacles. Existing coverage approaches reduce coverage time by covering along the minimum number of coverage lines (straight-line paths). However, recomputing such paths online can be computationally expensive resulting in robot stoppages that increase coverage time. A naive alternative is greedy detour replanning, i.e., replanning with minimum deviation from the initial path, which is efficient to compute but may result in unnecessary detours. In this work, we propose an anytime coverage replanning approach named OARP-Replan that performs near-optimal replans to an interrupted coverage path within a given time budget. We do this by solving linear relaxations of integer linear programs to identify sections of the interrupted path that can be optimally replanned within the time budget. We validate OARP-Replan in simulation and perform comparisons against a greedy detour replanner and other state-of-the-art coverage planners. We also demonstrate OARP-Replan in experiments using an industrial-level autonomous robot.},
  archive      = {J_TROB},
  author       = {Megnath Ramesh and Frank Imeson and Baris Fidan and Stephen L. Smith},
  doi          = {10.1109/TRO.2024.3454417},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4190-4206},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Anytime replanning of robot coverage paths for partially unknown environments},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An exploration-enhanced search algorithm for robot indoor
source searching. <em>TROB</em>, <em>40</em>, 4160–4178. (<a
href="https://doi.org/10.1109/TRO.2024.3454572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chemical, biological, or radioactive substances may be released in accidents, posing a threat to human life and property. Due to the dense obstacles and specific structures of indoor environments, indoor source searching still faces challenges, such as the initial position of the robot cannot be placed freely, the source may not be in the airflow, and most areas indoors lack concentration and airflow clues. This study proposes an exploration-enhanced search algorithm, enabling the robot to search for a source located downstream of the robot or outside the airflow in an indoor environment with a narrow plume without losing the classic upstream search ability. The algorithm equips the robot with the capability to search for a source in complex indoor environments where measurements frequently change. The algorithm is evaluated in the simulated environment to assess the contributions of its components and its performance under different airflow speeds. The algorithm is also compared with the state-of-the-art algorithms and shows superior performance. The effectiveness of the algorithm is further demonstrated in real-world environments.},
  archive      = {J_TROB},
  author       = {Miao Wang and Bin Xin and Mengjie Jing and Yun Qu},
  doi          = {10.1109/TRO.2024.3454572},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4160-4178},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An exploration-enhanced search algorithm for robot indoor source searching},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Performance-guided rotating magnetic field control in large
workspaces with reconfigurable electromagnetic actuation system.
<em>TROB</em>, <em>40</em>, 4117–4131. (<a
href="https://doi.org/10.1109/TRO.2024.3453768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote-actuated magnetic robots, relying solely on the magnetic torque stemming from rotating magnetic fields, hold immense promise in biomedical applications. However, to precisely actuate magnetic robots in large workspaces, the efficient generation of isotropic rotating fields using electromagnetic actuation (EMA) systems presents an enduring challenge. This is because the choice of configuration of the EMA system is a major concern, particularly when considering collision avoidance between coils and the human body while ensuring isotropic actuation. In this study, we presented an analysis of the characteristics of various three-coil configurations by quantitatively evaluating field isotropy. Furthermore, we introduced a performance-guided optimization method to adjust coil configurations by optimizing designed evaluation metrics, aiming to generate rotating fields with isotropic characteristics in a target local region. Finally, we implemented a reconfigurable EMA and conducted extensive experiments to demonstrate the capability of our method and platform. The experimental results showcase the potential of our approach for advanced clinical applications.},
  archive      = {J_TROB},
  author       = {Mingxue Cai and Zhaoyang Qi and Yanfei Cao and Xurui Liu and Xinyu Wu and Tiantian Xu and Li Zhang},
  doi          = {10.1109/TRO.2024.3453768},
  journal      = {IEEE Transactions on Robotics},
  month        = {9},
  pages        = {4117-4131},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Performance-guided rotating magnetic field control in large workspaces with reconfigurable electromagnetic actuation system},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A compliant robotic leg based on fibre jamming.
<em>TROB</em>, <em>40</em>, 4578–4597. (<a
href="https://doi.org/10.1109/TRO.2024.3443714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans possess a remarkable ability to react to unpredictable perturbations through immediate mechanical responses, which harness the visco-elastic properties of muscles to maintain balance. Inspired by this behavior, we propose a novel design of a robotic leg utilizing fibre jammed structures as passive compliant mechanisms to achieve variable joint stiffness and damping. We developed multimaterial fibre jammed tendons with tunable mechanical properties, which can be 3-D printed in one-go without need for assembly. Through extensive numerical simulations and experimentation, we demonstrate the usefulness of these tendons for shock absorbance and maintaining joint stability. We investigate how they could be used effectively in a multijoint robotic leg by evaluating the relative contribution of each tendon to the overall stiffness of the leg. Further, we showcase the potential of these jammed structures for legged locomotion, highlighting how morphological properties of the tendons can be used to enhance stability in robotic legs.},
  archive      = {J_TROB},
  author       = {Lois Liow and James Brett and Josh Pinskier and Lauren Hanson and Louis Tidswell and Navinda Kottege and David Howard},
  doi          = {10.1109/TRO.2024.3443714},
  journal      = {IEEE Transactions on Robotics},
  month        = {8},
  pages        = {4578-4597},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A compliant robotic leg based on fibre jamming},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid system stability analysis of multilane mixed-autonomy
traffic. <em>TROB</em>, <em>40</em>, 4469–4489. (<a
href="https://doi.org/10.1109/TRO.2024.3443504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles (AVs) hold vast potential to enhance transportation systems by reducing congestion, improving safety, and lowering emissions. AV controls lead to emergent traffic phenomena; one such intriguing phenomenon is traffic breaks (rolling roadblocks), where a single AV efficiently stabilizes multiple lanes through frequent lane switching, similar to the highway patrolling officers weaving across multiple lanes during difficult traffic conditions. While previous theoretical studies focus on single-lane mixed-autonomy systems, this work proposes a stability analysis framework for multilane systems under AV controls. Casting this problem into the hybrid system paradigm, the proposed analysis integrates continuous vehicle dynamics and discrete jumps from AV lane-switches. Through examining the influence of the lane-switch frequency on the system&#39;s stability, the analysis offers a principled explanation of the traffic break phenomenon, and further discovers opportunities for less-intrusive traffic smoothing by employing less frequent lane-switching. The analysis further facilitates the design of traffic-aware AV lane-switch strategies to enhance system stability. Numerical analysis reveals a strong alignment between the theory and simulation, validating the effectiveness of the proposed stability framework in analyzing multilane mixed-autonomy traffic systems.},
  archive      = {J_TROB},
  author       = {Sirui Li and Roy Dong and Cathy Wu},
  doi          = {10.1109/TRO.2024.3443504},
  journal      = {IEEE Transactions on Robotics},
  month        = {8},
  pages        = {4469-4489},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Hybrid system stability analysis of multilane mixed-autonomy traffic},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time ultrasound imaging of a human muscle to optimize
shared control in a hybrid exoskeleton. <em>TROB</em>, <em>40</em>,
4322–4336. (<a href="https://doi.org/10.1109/TRO.2024.3443668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid exoskeleton is a class of wearable robotic technology that simultaneously uses a powered exoskeleton and functional electrical stimulation (FES) to generate assistive joint torques for people with impaired mobility due to neurological disorders such as spinal cord injury (SCI). The hybrid assistive technology benefits from FES that actively elicits force from paralyzed muscles via their neural excitation, leading to muscle strengthening. The main technical barrier to realizing the hybrid technology is to attain stable coordination between FES and the exoskeleton despite the quick onset of FES-induced muscle fatigue, which causes a rapid decline in the muscle force. Current methods to measure the induced fatigue lack direct muscle state measurements and may be ineffective at capturing the muscle force decay due to FES. Instead, ultrasound (US) imaging accurately quantifies FES-related muscle contractility and fatigue due to the direct visualization of muscle fibers. In this article, we use real-time US imaging-derived muscle strain changes as biomarkers of FES-induced fatigue in an optimal controller that modulates exoskeleton assistance and FES dosage. To demonstrate that real-time US imaging is a promising muscle–machine interface technology that can optimize shared control in a hybrid exoskeleton, we perform experiments involving continuous seated knee extension and over-ground walking tasks on two participants with SCI and four participants without disabilities. Furthermore, this work helps design a novel and unprecedented robotic gait technology with the capability to impart FES-associated therapeutic benefits while assisting the gait of neurologically impaired individuals, including those with SCI, stroke, multiple sclerosis, etc.},
  archive      = {J_TROB},
  author       = {Ashwin Iyer and Ziyue Sun and Krysten Lambeth and Mayank Singh and Christine Cleveland and Nitin Sharma},
  doi          = {10.1109/TRO.2024.3443668},
  journal      = {IEEE Transactions on Robotics},
  month        = {8},
  pages        = {4322-4336},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Real-time ultrasound imaging of a human muscle to optimize shared control in a hybrid exoskeleton},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sensor observability analysis for maximizing task-space
observability of articulated robots. <em>TROB</em>, <em>40</em>,
4102–4116. (<a href="https://doi.org/10.1109/TRO.2024.3443696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel performance metric for articulated robots with distributed directional sensors called the sensor observability analysis (SOA). These robot-mounted distributed directional sensors (e.g., joint torque sensors) change their individual sensing directions as the joints move. SOA transforms individual sensor axes in joint space to provide the cumulative sensing quality of these sensors to observe each task-space axis, akin to forward kinematics for sensors. For example, certain joint configurations may align joint torque sensors in such a way that they are unable to observe interaction forces in one or more task-space (e.g., Cartesian) axes. The resultant sensor observability performance metrics can then be used in optimization and in null-space control to avoid sensor observability in singular configurations or to maximize sensor observability in particular directions. We use the specific case of force sensing in serial robot manipulators to showcase the analysis. Parallels are drawn between sensor observability and traditional kinematic manipulability; SOA is shown to be more generalizable in terms of analyzing non-joint-mounted sensors and can potentially be applied to sensor types other than for force sensing. Simulations and experiments using a custom 3-degree of freedom robot and the Baxter robot demonstrate the utility and importance of sensor observability in physical interactions.},
  archive      = {J_TROB},
  author       = {Christopher Yee Wong and Wael Suleiman},
  doi          = {10.1109/TRO.2024.3443696},
  journal      = {IEEE Transactions on Robotics},
  month        = {8},
  pages        = {4102-4116},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Sensor observability analysis for maximizing task-space observability of articulated robots},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GNSS/multisensor fusion using continuous-time factor graph
optimization for robust localization. <em>TROB</em>, <em>40</em>,
4003–4023. (<a href="https://doi.org/10.1109/TRO.2024.3443699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and robust vehicle localization in highly urbanized areas is challenging. Sensors are often corrupted in those complicated and large-scale environments. This article introduces gnssFGO , a global and online trajectory estimator that fuses global navigation satellite systems (GNSS) observations alongside multiple sensor measurements for robust vehicle localization. In gnssFGO , we fuse asynchronous sensor measurements into the graph with a continuous-time trajectory representation using Gaussian process (GP) regression. This enables querying states at arbitrary timestamps without strict state and measurement synchronization. Thus, the proposed method presents a generalized factor graph for multisensor fusion. To evaluate and study different GNSS fusion strategies, we fuse GNSS measurements in loose and tight coupling with a speed sensor, inertial measurement unit, and LiDAR-odometry. We employed datasets from measurement campaigns in Aachen, Düsseldorf, and Cologne and presented comprehensive discussions on sensor observations, smoother types, and hyperparameter tuning. Our results show that the proposed approach enables robust trajectory estimation in dense urban areas where a classic multisensor fusion method fails due to sensor degradation. In a test sequence containing a 17-km route through Aachen, the proposed method results in a mean 2-D positioning error 0.48 m while fusing raw GNSS observations with LiDAR odometry in a tight coupling},
  archive      = {J_TROB},
  author       = {Haoming Zhang and Chih-Chun Chen and Heike Vallery and Timothy D. Barfoot},
  doi          = {10.1109/TRO.2024.3443699},
  journal      = {IEEE Transactions on Robotics},
  month        = {8},
  pages        = {4003-4023},
  shortjournal = {IEEE Trans. Robot.},
  title        = {GNSS/Multisensor fusion using continuous-time factor graph optimization for robust localization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guarantees on robot system performance using stochastic
simulation rollouts. <em>TROB</em>, <em>40</em>, 3984–4002. (<a
href="https://doi.org/10.1109/TRO.2024.3444070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we provide finite-sample performance guarantees for control policies executed on stochastic robotic systems. Given an open- or closed-loop policy and a finite set of trajectory rollouts under the policy, we bound the expected value, value at risk, and conditional value at risk of the trajectory cost, and the probability of failure in a sparse cost setting. The bounds hold, with user-specified probability, for any policy synthesis technique and can be seen as a postdesign safety certification. Generating the bounds only requires sampling simulation rollouts, without assumptions on the distribution or complexity of the underlying stochastic system. We adapt these bounds to also give a constraint satisfaction test to verify the safety of the robot system. We provide a thorough analysis of the bound sensitivity to sim-to-real distribution shifts and provide results for constructing robust bounds that can tolerate some specified amount of distribution shift. Furthermore, we extend our method to apply when selecting the best policy from a set of candidates, requiring a multihypothesis correction. We show the statistical validity of our bounds in the Ant, Half-cheetah, and Swimmer MuJoCo environments and demonstrate our constraint satisfaction test with the Ant. Finally, using the 20-degree-of-freedom MuJoCo Shadow Hand, we show the necessity of the multihypothesis correction.},
  archive      = {J_TROB},
  author       = {Joseph A. Vincent and Aaron O. Feldman and Mac Schwager},
  doi          = {10.1109/TRO.2024.3444070},
  journal      = {IEEE Transactions on Robotics},
  month        = {8},
  pages        = {3984-4002},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Guarantees on robot system performance using stochastic simulation rollouts},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven batch localization and SLAM using koopman
linearization. <em>TROB</em>, <em>40</em>, 3964–3983. (<a
href="https://doi.org/10.1109/TRO.2024.3443674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a framework for model-free batch localization and simultaneous localization and mapping (SLAM). We use lifting functions to map a control-affine system into a high-dimensional space, where both the process model and the measurement model are rendered bilinear. During training, we solve a least-squares problem using groundtruth data to compute the high-dimensional model matrices associated with the lifted system purely from data. At inference time, we solve for the unknown robot trajectory and landmarks through an optimization problem, where constraints are introduced to keep the solution on the manifold of the lifting functions. The problem is efficiently solved using a sequential quadratic program (SQP), where the complexity of an SQP iteration scales linearly with the number of timesteps. Our algorithms, called reduced constrained Koopman linearization localization (RCKL-Loc) and reduced constrained Koopman linearization SLAM (RCKL-SLAM), are validated experimentally in simulation and on two datasets: one with an indoor mobile robot equipped with a laser rangefinder that measures range to cylindrical landmarks, and one on a golf cart equipped with radio-frequency identification (RFID) range sensors. We compare RCKL-Loc and RCKL-SLAM with classic model-based nonlinear batch estimation. While RCKL-Loc and RCKL-SLAM have a similar performance compared to their model-based counterparts, they outperform the model-based approaches when the prior model is imperfect, showing the potential benefit of the proposed data-driven technique.},
  archive      = {J_TROB},
  author       = {Zi Cong Guo and Frederike Dümbgen and James Richard Forbes and Timothy D. Barfoot},
  doi          = {10.1109/TRO.2024.3443674},
  journal      = {IEEE Transactions on Robotics},
  month        = {8},
  pages        = {3964-3983},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Data-driven batch localization and SLAM using koopman linearization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MMP++: Motion manifold primitives with parametric curve
models. <em>TROB</em>, <em>40</em>, 3950–3963. (<a
href="https://doi.org/10.1109/TRO.2024.3444068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion manifold primitives (MMP), a manifold-based approach for encoding basic motion skills, can produce diverse trajectories, enabling the system to adapt to unseen constraints. Nonetheless, we argue that current MMP models lack crucial functionalities of movement primitives, such as temporal and via-points modulation, found in traditional approaches. This shortfall primarily stems from MMP&#39;s reliance on discrete-time trajectories. To overcome these limitations, we introduce motion manifold primitives++ (MMP++), a new model that integrates the strengths of both MMP and traditional methods by incorporating parametric curve representations into the MMP framework. Furthermore, we identify a significant challenge with MMP++: performance degradation due to geometric distortions in the latent space, meaning that similar motions are not closely positioned. To address this, isometric motion manifold primitives++ (IMMP++) is proposed to ensure the latent space accurately preserves the manifold&#39;s geometry. Our experimental results across various applications, including two-DoF planar motions, seven-DoF robot arm motions, and SE(3) trajectory planning, show that MMP++ and IMMP++ outperform existing methods in trajectory generation tasks, achieving substantial improvements in some cases. Moreover, they enable the modulation of latent coordinates and via-points, thereby allowing efficient online adaptation to dynamic environments.},
  archive      = {J_TROB},
  author       = {Yonghyeon Lee},
  doi          = {10.1109/TRO.2024.3444068},
  journal      = {IEEE Transactions on Robotics},
  month        = {8},
  pages        = {3950-3963},
  shortjournal = {IEEE Trans. Robot.},
  title        = {MMP++: Motion manifold primitives with parametric curve models},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft robot employing a series of pneumatic actuators and
distributed balloons: Modeling, evaluation, and applications.
<em>TROB</em>, <em>40</em>, 3933–3949. (<a
href="https://doi.org/10.1109/TRO.2024.3444069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tasks involving exploration and inspection of narrow environments demand a robot to have a flexible body. Such a robot is especially preferred if the integrity of its surrounding is crucial, as in endoscopy procedures. We propose the design of a small, self-propelled soft robot that can operate in a constrained environment. By periodic activation of a series of pneumatic actuators fabricated using a casting technique, sinusoidal locomotion is achieved. The wave-like locomotive strategy with an additional support mechanism enabled movement in multiple scenarios, including traveling horizontally and vertically in environments of different characteristics. Two analytical models are presented to highlight the design characteristics. The first predicts the velocity of the robot in relation to the working conditions, while the second calculates the force that the robot body exerts on its surroundings. Its mobility was tested in simple and complex routes under rigid and elastic environments. The resulting percent errors for the predictions of velocity and lateral force are 7.89% and 16.86%, respectively. In terms of performance, the robot can move horizontally in rigid tubes even if the walls are lubricated, and can achieve a peak speed of 40.11 mm/s, or 0.171 Body-Length/s (BL/s). With the addition of a tail balloon, the robot also successfully ascended a vertical tube with a maximum speed of 9.22 mm/s (or 0.039 BL/s). The presented work is expected to pave the way toward feasible robotic applications, such as pipe inspection.},
  archive      = {J_TROB},
  author       = {Tuan Tai Nguyen and Dinh Quang Nguyen and Van Anh Ho},
  doi          = {10.1109/TRO.2024.3444069},
  journal      = {IEEE Transactions on Robotics},
  month        = {8},
  pages        = {3933-3949},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Soft robot employing a series of pneumatic actuators and distributed balloons: Modeling, evaluation, and applications},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bidirectional energy flow modulation for passive admittance
control. <em>TROB</em>, <em>40</em>, 3917–3932. (<a
href="https://doi.org/10.1109/TRO.2024.3443690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Admittance control is a control scheme to enable physical interactions of a robot, but it easily induces instability when the robot contacts a rigid surface. In this study, a passivity analysis was conducted on a robotic system with admittance control. The results showed that coupled stability with the environment can be ensured when the velocity error between the proxy and the real robot is eliminated. Thus, an adaptive structure modification method is proposed to suppress the possible source of instability. In addition, the energy tank method is combined with the proposed method to ensure system passivity. As a proof of concept, three robot experiments were performed, and the results of the proposed method were compared with those of conventional admittance control and impedance control (with friction compensation). The comparison showed that the proposed method could make the system passive while realizing the desired dynamics during the interaction.},
  archive      = {J_TROB},
  author       = {Donghyeon Lee and Dongwoo Ko and Min Jun Kim and Wan Kyun Chung},
  doi          = {10.1109/TRO.2024.3443690},
  journal      = {IEEE Transactions on Robotics},
  month        = {8},
  pages        = {3917-3932},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Bidirectional energy flow modulation for passive admittance control},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient deep learning of robust policies from MPC using
imitation and tube-guided data augmentation. <em>TROB</em>, <em>40</em>,
4301–4321. (<a href="https://doi.org/10.1109/TRO.2024.3431988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imitation learning (IL) can generate computationally efficient policies from demonstrations provided by model predictive control (MPC). However, IL methods often require extensive data-collection and training-efforts, limiting changes to the policy if the task changes, and they produce policies with limited robustness to new disturbances. In this work, we propose an IL strategy to efficiently compress a computationally expensive MPC into a deep neural network policy that is robust to previously unseen disturbances. By using a robust variant of the MPC, called robust tube MPC, and leveraging properties from the controller, we introduce computationally efficient data augmentation methods that enable a significant reduction of the number of MPC demonstrations and training efforts required to generate a robust policy. Our approach opens the possibility of zero-shot transfer of a policy trained from a single MPC demonstration collected in a nominal domain, such as a simulation or a robot in a lab/controlled environment, to a new domain with previously unseen bounded model errors/perturbations. Numerical evaluations performed using linear and nonlinear MPC for agile flight on a multirotor show that our method outperforms strategies commonly employed in IL (such as dataset-aggregation and domain randomization) in terms of demonstration-efficiency, training time, and robustness to perturbations unseen during training. Experimental evaluations validate the efficiency and real-world robustness.},
  archive      = {J_TROB},
  author       = {Andrea Tagliabue and Jonathan P. How},
  doi          = {10.1109/TRO.2024.3431988},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {4301-4321},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Efficient deep learning of robust policies from MPC using imitation and tube-guided data augmentation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NR-SLAM: Nonrigid monocular SLAM. <em>TROB</em>,
<em>40</em>, 4252–4264. (<a
href="https://doi.org/10.1109/TRO.2024.3422004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents NR-SLAM, a novel nonrigid monocular simultaneous localization and mapping (SLAM) system founded on the combination of a dynamic deformation graph with a visco-elastic deformation model. The former enables our system to represent the dynamics of the deforming environment as the camera explores, while the later allows us to model general deformations in a simple way. The presented system is able to automatically initialize and extend a map modeled by a sparse point cloud in deforming environments, that is refined with a sliding-window deformable bundle adjustment. This map serves as base for the estimation of the camera motion and deformation and enables us to represent arbitrary surface topologies, overcoming the limitations of previous methods. To assess the performance of our system in challenging deforming scenarios, we evaluate it in several representative medical datasets. In our experiments, NR-SLAM outperforms previous deformable SLAM systems, achieving millimeter reconstruction accuracy and bringing automated medical intervention closer. For the benefit of the community, we make the source code public.},
  archive      = {J_TROB},
  author       = {Juan J. Gómez Rodríguez and José M.M. Montiel and Juan D. Tardós},
  doi          = {10.1109/TRO.2024.3422004},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {4252-4264},
  shortjournal = {IEEE Trans. Robot.},
  title        = {NR-SLAM: Nonrigid monocular SLAM},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive graduated nonconvexity loss function for robust
nonlinear least-squares solutions. <em>TROB</em>, <em>40</em>,
4207–4221. (<a href="https://doi.org/10.1109/TRO.2024.3434169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many problems in robotics, such asestimating the state from noisy sensor data or aligning two point clouds, can be posed and solved as least-squares problems. Unfortunately, vanilla nonminimal solvers for least-squares problems are notoriously sensitive to outliers and initialization errors. The conventional approach to outlier rejection is to use a robust loss function, which is typically selected and tuned a priori. A newly developed approach to handle large initialization errors is graduated nonconvexity (GNC), which is defined for a particular choice of a robust loss function. The main contribution of this article is to combine these two approaches by using an adaptive kernel within a GNC optimization scheme. This brings a solution to least-squares problems that is robust to both outliers and initialization errors, without the need for model selection and tuning. Simulations and experiments demonstrate that the proposed method is more robust compared to non-GNC counterparts and performs on par with other GNC-tailored loss functions.},
  archive      = {J_TROB},
  author       = {Kyungmin Jung and Thomas Hitchcox and James Richard Forbes},
  doi          = {10.1109/TRO.2024.3434169},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {4207-4221},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An adaptive graduated nonconvexity loss function for robust nonlinear least-squares solutions},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new expression for the passivity bound for a class of
sampled-data systems. <em>TROB</em>, <em>40</em>, 4179–4189. (<a
href="https://doi.org/10.1109/TRO.2024.3433869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we characterize the passivity of a class of haptic systems modeled as a simple sampled-data system. We guarantee passivity by ensuring that there is sufficient damping in the haptic interface. Previous work established a necessary and sufficient bound on damping, but the corresponding mathematical expressions were complicated, and the derivation was not completely rigorous. After providing a rigorous proof, we derive a more tractable expression. Using this improved expression, we establish passivity conditions for several classes of transfer functions representing virtual environments, including some special cases with time delay. The original results assumed that the operator can be modeled by a passive but otherwise arbitrary transfer function. This assumption is weakened to allow the operator model to have a shortage of passivity. This requires only a slight modification of the passivity bound.},
  archive      = {J_TROB},
  author       = {Rodney G. Roberts and Carl A. Moore and J. Edward Colgate},
  doi          = {10.1109/TRO.2024.3433869},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {4179-4189},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A new expression for the passivity bound for a class of sampled-data systems},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A shared autonomy system for precise and efficient remote
underwater manipulation. <em>TROB</em>, <em>40</em>, 4147–4159. (<a
href="https://doi.org/10.1109/TRO.2024.3431830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional underwater intervention operations using robotic vehicles require expert teleoperators and limit interaction with remote scientists. In this article, we present the shared autonomy for remote collaboration (SHARC) framework that enables novice operators to cooperatively conduct underwater sampling and manipulation tasks. With SHARC, operators can plan and complete manipulation tasks using natural language or hand gestures through a virtual reality (SHARC-VR) interface. The interface provides remote operators with a contextual 3-D scene understanding that is updated according to bandwidth availability. Evaluation of the SHARC framework through controlled lab experiments demonstrates that SHARC-VR enables novice operators to complete manipulation tasks in framerate-limited conditions (i.e., 0.1–0.5 frames per second) faster than expert pilots using a conventional topside controller. For both novice and expert users, the SHARC-VR interface also increases the task completion rate and improves sampling precision. The SHARC framework is readily extensible to other hardware architectures, including terrestrial and space systems.},
  archive      = {J_TROB},
  author       = {Amy Phung and Gideon Billings and Andrea F. Daniele and Matthew R. Walter and Richard Camilli},
  doi          = {10.1109/TRO.2024.3431830},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {4147-4159},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A shared autonomy system for precise and efficient remote underwater manipulation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DiffTune: Autotuning through autodifferentiation.
<em>TROB</em>, <em>40</em>, 4085–4101. (<a
href="https://doi.org/10.1109/TRO.2024.3429191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of robots in high-level tasks depends on the quality of their lower level controller, which requires fine-tuning. However, the intrinsically nonlinear dynamics and controllers make tuning a challenging task when it is done by hand. In this article, we present DiffTune, a novel, gradient-based automatic tuning framework. We formulate the controller tuning as a parameter optimization problem. Our method unrolls the dynamical system and controller as a computational graph and updates the controller parameters through gradient-based optimization. The gradient is obtained using sensitivity propagation, which is the only method for gradient computation when tuning for a physical system instead of its simulated counterpart. Furthermore, we use $\mathcal {L}_{1}$ adaptive control to compensate for the uncertainties (that unavoidably exist in a physical system) such that the gradient is not biased by the unmodeled uncertainties. We validate the DiffTune on a Dubin&#39;s car and a quadrotor in challenging simulation environments. In comparison with state-of-the-art autotuning methods, DiffTune achieves the best performance in a more efficient manner owing to its effective usage of the first-order information of the system. Experiments on tuning a nonlinear controller for quadrotor show promising results, where DiffTune achieves 3.5× tracking error reduction on an aggressive trajectory in only ten trials over a 12-D controller parameter space.},
  archive      = {J_TROB},
  author       = {Sheng Cheng and Minkyung Kim and Lin Song and Chengyu Yang and Yiquan Jin and Shenlong Wang and Naira Hovakimyan},
  doi          = {10.1109/TRO.2024.3429191},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {4085-4101},
  shortjournal = {IEEE Trans. Robot.},
  title        = {DiffTune: Autotuning through autodifferentiation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Challenges for monocular 6-d object pose estimation in
robotics. <em>TROB</em>, <em>40</em>, 4065–4084. (<a
href="https://doi.org/10.1109/TRO.2024.3433870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object pose estimation is a core perception task that enables, for example, object manipulation and scene understanding. The widely available, inexpensive, and high-resolution RGB sensors and CNNs that allow for fast inference make monocular approaches especially well-suited for robotics applications. We observe that previous surveys establish the state of the art for varying modalities, single- and multiview settings, and datasets and metrics that consider a multitude of applications. We argue, however, that those works&#39; broad scope hinders the identification of open challenges that are specific to monocular approaches and the derivation of promising future challenges for their application in robotics. By providing a unified view on recent publications from both robotics and computer vision, we find that occlusion handling, pose representations, and formalizing and improving category-level pose estimation are still fundamental challenges that are highly relevant for robotics. Moreover, to further improve robotic performance, large object sets, novel objects, refractive materials, and uncertainty estimates are central and largely unsolved open challenges. In order to address them, ontological reasoning, deformability handling, scene-level reasoning, realistic datasets, and the ecological footprint of algorithms need to be improved.},
  archive      = {J_TROB},
  author       = {Stefan Thalhammer and Dominik Bauer and Peter Hönig and Jean-Baptiste Weibel and José García-Rodríguez and Markus Vincze},
  doi          = {10.1109/TRO.2024.3433870},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {4065-4084},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Challenges for monocular 6-D object pose estimation in robotics},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PIN-SLAM: LiDAR SLAM using a point-based implicit neural
representation for achieving global map consistency. <em>TROB</em>,
<em>40</em>, 4045–4064. (<a
href="https://doi.org/10.1109/TRO.2024.3422055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and robust localization and mapping are essential components for most autonomous robots. In this paper, we propose a simultaneous localization and mapping (SLAM) system for building globally consistent maps, called point-based implicit neural (PIN)-SLAM, that is based on an elastic and compact PIN map representation. Taking range measurements as input, our approach alternates between incremental learning of the local implicit signed distance field and the pose estimation using a correspondence-free, point-to-implicit model registration to the current local map. Our implicit map is based on sparse optimizable neural points, which are inherently elastic and deformable with the global pose adjustment when closing a loop. Loops are also detected using the neural point features. Extensive experiments validate that PIN-SLAM is robust to various environments and versatile to different range sensors, such as light detection and ranging (LiDAR) and RGB color and depth (RGB-D) cameras. PIN-SLAM achieves pose estimation accuracy better or on par with the state-of-the-art LiDAR odometry or SLAM systems and outperforms the recent neural implicit SLAM approaches while maintaining a more consistent, and highly compact implicit map that can be reconstructed as accurate and complete meshes. Finally, thanks to the voxel hashing for efficient neural points indexing and the fast implicit map-based registration without closest point association, PIN-SLAM can run at the sensor frame rate on a moderate graphics processing unit (GPU).},
  archive      = {J_TROB},
  author       = {Yue Pan and Xingguang Zhong and Louis Wiesmann and Thorbjörn Posewsky and Jens Behley and Cyrill Stachniss},
  doi          = {10.1109/TRO.2024.3422055},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {4045-4064},
  shortjournal = {IEEE Trans. Robot.},
  title        = {PIN-SLAM: LiDAR SLAM using a point-based implicit neural representation for achieving global map consistency},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consensus complementarity control for multicontact MPC.
<em>TROB</em>, <em>40</em>, 3879–3896. (<a
href="https://doi.org/10.1109/TRO.2024.3435423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a hybrid model predictive control algorithm, consensus complementarity control, for systems that make and break contact with their environment. Many state-of-the-art controllers for tasks, which require initiating contact with the environment, such as locomotion and manipulation, require a priori mode schedules or are too computationally complex to run at real-time rates. We present a method based on the alternating direction method of multipliers that is capable of high-speed reasoning over potential contact events. Via a consensus formulation, our approach enables parallelization of the contact scheduling problem. We validate our results on five numerical examples, including four high-dimensional frictional contact problems, and a physical experimentation on an underactuated multicontact system. We further demonstrate the effectiveness of our method on a physical experiment accomplishing a high-dimensional, multicontact manipulation task with a robot arm.},
  archive      = {J_TROB},
  author       = {Alp Aydinoglu and Adam Wei and Wei-Cheng Huang and Michael Posa},
  doi          = {10.1109/TRO.2024.3435423},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3879-3896},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Consensus complementarity control for multicontact MPC},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DALI: Domain adaptive LiDAR object detection via
distribution-level and instance-level pseudolabel denoising.
<em>TROB</em>, <em>40</em>, 3866–3878. (<a
href="https://doi.org/10.1109/TRO.2024.3435387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection using LiDAR point clouds relies on a large amount of human-annotated samples when training the underlying detectors&#39; deep neural networks. However, generating 3-D bounding box annotation for a large-scale dataset could be costly and time-consuming. Alternatively, unsupervised domain adaptation (UDA) enables a given object detector to operate on novel new data, with an unlabeled training dataset, by transferring the knowledge learned from training labeled source domain data to the new unlabeled target domain . Pseudolabel strategies, which involve training the 3-D object detector using target-domain predicted bounding boxes from a pretrained model, are commonly used in UDA. However, these pseudolabels often introduce noise, impacting performance. In this article, we introduce the domain adaptive LiDAR (DALI) object detection framework to address noise at both distribution and instance levels. First, a posttraining size normalization (PTSN) strategy is developed to mitigate bias in pseudolabel size distribution by identifying an unbiased scale after network training. To address instance-level noise between pseudolabels and corresponding point clouds, two pseudopoint clouds generation (PPCG) strategies, ray-constrained and constraint-free, are developed to generate pseudopoint clouds for each instance, ensuring the consistency between pseudolabels and pseudopoints during training. We demonstrate the effectiveness of our method on the publicly available and popular datasets KITTI, Waymo, and nuScenes. We show that the proposed DALI framework achieves state-of-the-art results and outperforms leading approaches on most of the domain adaptation tasks.},
  archive      = {J_TROB},
  author       = {Xiaohu Lu and Hayder Radha},
  doi          = {10.1109/TRO.2024.3435387},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3866-3878},
  shortjournal = {IEEE Trans. Robot.},
  title        = {DALI: Domain adaptive LiDAR object detection via distribution-level and instance-level pseudolabel denoising},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unlocking human-like facial expressions in humanoid robots:
A novel approach for action unit driven facial expression disentangled
synthesis. <em>TROB</em>, <em>40</em>, 3850–3865. (<a
href="https://doi.org/10.1109/TRO.2024.3422051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanoid robots often struggle to express the intricate and authentic facial expressions characteristic of humans, potentially hampering user engagement. To address this challenge, we introduce a comprehensive two-stage methodology to empower our autonomous affective robot with the capacity to exhibit rich and natural facial expressions. In the initial stage, we present an innovative action unit (AU) driven facial expression disentangled synthesis method, enabling the generation of nuanced robot facial expression images guided by AUs. By harnessing facial AUs within a framework of weakly supervised learning, we effectively surmount the scarcity of paired training data (comprising source and target facial expression images). To preserve the integrity of AUs while mitigating identity interference, we leverage a latent facial attribute space to disentangle expression-related and expression-unrelated cues, employing solely the former for expression synthesis. In the subsequent phase, we actualize an affective robot endowed with multifaceted degrees of freedom for facial movements, facilitating the embodiment of the synthesized fine-grained facial expressions. We devise a specialized motor command mapping network that serves as a conduit between the generated expression images and the robot&#39;s realistic facial responses. By utilizing the physical motor positions as constraints, we refine the prediction of precise motor commands from the robot&#39;s generated facial expressions. This refinement process ensures that the robot&#39;s facial movements authentically express accurate and natural expressions. Finally, qualitative and quantitative evaluations on the benchmarking Emotionet dataset verify the effectiveness of the proposed generation method. Results on the self-developed affective robot indicate that our method achieves a promising generation of specific facial expressions with given AUs, significantly enhancing the affective human–robot interaction.},
  archive      = {J_TROB},
  author       = {Xiaofeng Liu and Rongrong Ni and Biao Yang and Siyang Song and Angelo Cangelosi},
  doi          = {10.1109/TRO.2024.3422051},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3850-3865},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Unlocking human-like facial expressions in humanoid robots: A novel approach for action unit driven facial expression disentangled synthesis},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous policy networks for composite robot team
communication and coordination. <em>TROB</em>, <em>40</em>, 3833–3849.
(<a href="https://doi.org/10.1109/TRO.2024.3431829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-performing human–human teams learn intelligent and efficient communication and coordination strategies to maximize their joint utility. These teams implicitly understand the different roles of heterogeneous team members and adapt their communication protocols accordingly. Multiagent reinforcement learning (MARL) has attempted to develop computational methods for synthesizing such joint coordination–communication strategies, but emulating heterogeneous communication patterns across agents with different state, action, and observation spaces has remained a challenge. Without properly modeling agent heterogeneity, as in prior MARL work that leverages homogeneous graph networks, communication becomes less helpful and can even deteriorate the team&#39;s performance. In the past, we proposed heterogeneous policy networks (HetNet) to learn efficient and diverse communication models for coordinating cooperative heterogeneous teams. In this extended work, we extend HetNet to support scaling heterogeneous robot teams. Building on heterogeneous graph-attention networks, we show that HetNet not only facilitates learning heterogeneous collaborative policies, but also enables end-to-end training for learning highly efficient binarized messaging. Our empirical evaluation shows that HetNet sets a new state-of-the-art in learning coordination and communication strategies for heterogeneous multiagent teams by achieving an 5.84% to 707.65% performance improvement over the next-best baseline across multiple domains while simultaneously achieving a 200× reduction in the required communication bandwidth.},
  archive      = {J_TROB},
  author       = {Esmaeil Seraj and Rohan Paleja and Luis Pimentel and Kin Man Lee and Zheyuan Wang and Daniel Martin and Matthew Sklar and John Zhang and Zahi Kakish and Matthew Gombolay},
  doi          = {10.1109/TRO.2024.3431829},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3833-3849},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Heterogeneous policy networks for composite robot team communication and coordination},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evetac: An event-based optical tactile sensor for robotic
manipulation. <em>TROB</em>, <em>40</em>, 3812–3832. (<a
href="https://doi.org/10.1109/TRO.2024.3428430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical tactile sensors have recently become popular. They provide high spatial resolution, but struggle to offer fine temporal resolutions. To overcome this shortcoming, we study the idea of replacing the RGB camera with an event-based camera and introduce a new event-based optical tactile sensor called Evetac. Along with hardware design, we develop touch processing algorithms to process its measurements online at 1000 Hz. We devise an efficient algorithm to track the elastomer&#39;s deformation through the imprinted markers despite the sensor&#39;s sparse output. Benchmarking experiments demonstrate Evetac&#39;s capabilities of sensing vibrations up to 498 Hz, reconstructing shear forces, and significantly reducing data rates compared to RGB optical tactile sensors. Moreover, Evetac&#39;s output and the marker tracking provide meaningful features for learning data-driven slip detection and prediction models. The learned models form the basis for a robust and adaptive closed-loop grasp controller capable of handling a wide range of objects. We believe that fast and efficient event-based tactile sensors like Evetac will be essential for bringing human-like manipulation capabilities to robotics.},
  archive      = {J_TROB},
  author       = {Niklas Funk and Erik Helmut and Georgia Chalvatzaki and Roberto Calandra and Jan Peters},
  doi          = {10.1109/TRO.2024.3428430},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3812-3832},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Evetac: An event-based optical tactile sensor for robotic manipulation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast path planning through large collections of safe boxes.
<em>TROB</em>, <em>40</em>, 3795–3811. (<a
href="https://doi.org/10.1109/TRO.2024.3434168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a fast algorithm for the design of smooth paths (or trajectories) that are constrained to lie in a collection of axis-aligned boxes. We consider the case where the number of these safe boxes is large, and basic preprocessing of them (such as finding their intersections) can be done offline. At runtime, we quickly generate a smooth path between given initial and terminal positions. Our algorithm designs trajectories that are guaranteed to be safe at all times, and detects infeasibility whenever such a trajectory does not exist. Our algorithm is based on two subproblems that we can solve very efficiently: finding a shortest path in a weighted graph, and solving (multiple) convex optimal-control problems. We demonstrate the proposed path planner on large-scale numerical examples, and we provide an efficient open-source software implementation, fastpathplanning .},
  archive      = {J_TROB},
  author       = {Tobia Marcucci and Parth Nobel and Russ Tedrake and Stephen Boyd},
  doi          = {10.1109/TRO.2024.3434168},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3795-3811},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Fast path planning through large collections of safe boxes},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regret-based sampling of pareto fronts for multiobjective
robot planning problems. <em>TROB</em>, <em>40</em>, 3778–3794. (<a
href="https://doi.org/10.1109/TRO.2024.3428990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many problems in robotics seek to simultaneously optimize several competing objectives. A conventional approach is to create a single cost function comprised of the weighted sum of the individual objectives. Solutions to this scalarized optimization problem are Pareto optimal solutions to the original multiobjective problem. However, finding an accurate representation of a Pareto front remains an important challenge. Uniformly spaced weights are often inefficient and do not provide error bounds. We address the problem of computing a finite set of weights whose optimal solutions closely approximate the solution of any other weight vector. To this end, we prove fundamental properties of the optimal cost as a function of the weight vector. We propose an algorithm that greedily adds the weight vector least-represented by the current set, and provide bounds on the regret. We extend our method to include suboptimal solvers for the scalarized optimization, and handle stochastic inputs to the planning problem. Finally, we illustrate that the proposed approach significantly outperforms baseline approaches for different robot planning problems with varying numbers of objective functions.},
  archive      = {J_TROB},
  author       = {Alexander Botros and Nils Wilde and Armin Sadeghi and Javier Alonso-Mora and Stephen L. Smith},
  doi          = {10.1109/TRO.2024.3428990},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3778-3794},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Regret-based sampling of pareto fronts for multiobjective robot planning problems},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EVORA: Deep evidential traversability learning for
risk-aware off-road autonomy. <em>TROB</em>, <em>40</em>, 3756–3777. (<a
href="https://doi.org/10.1109/TRO.2024.3431828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traversing terrain with good traction is crucial for achieving fast off-road navigation. Instead of manually designing costs based on terrain features, existing methods learn terrain properties directly from data via self-supervision to automatically penalize trajectories moving through undesirable terrain, but challenges remain in properly quantifying and mitigating the risk due to uncertainty in the learned models. To this end, we present evidential off-road autonomy (EVORA), a unified framework to learn uncertainty-aware traction model and plan risk-aware trajectories. For uncertainty quantification, we efficiently model both aleatoric and epistemic uncertainty by learning discrete traction distributions and probability densities of the traction predictor&#39;s latent features. Leveraging evidential deep learning, we parameterize Dirichlet distributions with the network outputs and propose a novel uncertainty-aware squared Earth Mover&#39;s Distance loss with a closed-form expression that improves learning accuracy and navigation performance. For risk-aware navigation, the proposed planner simulates state trajectories with the worst-case expected traction to handle aleatoric uncertainty and penalizes trajectories moving through terrain with high epistemic uncertainty. Our approach is extensively validated in simulation and on wheeled and quadruped robots, showing improved navigation performance compared to methods that assume no slip, assume the expected traction, or optimize for the worst-case expected cost.},
  archive      = {J_TROB},
  author       = {Xiaoyi Cai and Siddharth Ancha and Lakshay Sharma and Philip R. Osteen and Bernadette Bucher and Stephen Phillips and Jiuguang Wang and Michael Everett and Nicholas Roy and Jonathan P. How},
  doi          = {10.1109/TRO.2024.3431828},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3756-3777},
  shortjournal = {IEEE Trans. Robot.},
  title        = {EVORA: Deep evidential traversability learning for risk-aware off-road autonomy},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A consistent parallel estimation framework for
visual-inertial SLAM. <em>TROB</em>, <em>40</em>, 3734–3755. (<a
href="https://doi.org/10.1109/TRO.2024.3433868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we revisit the optimal fusion of visual and inertial information from a monocular camera and an inertial measurement unit and propose a novel parallel visual-inertial simultaneous localization and mapping (SLAM) estimation framework in favor of the multithread computation on a single CPU. We start modeling the SLAM problem with a Bayesian batch estimator, and then split it into two submodules, localization and mapping, of different scales and processing rates, however, can thus run concurrently. The estimation consistency is taken into account in decoupling the two submodules so that when loop closure occurs the localization accuracy can seamlessly benefit from the mapping result via online global optimization, which distinguishes our solution from the others. To this end, we design the corresponding front-end and back-end to consistently solve localization and mapping in parallel, especially the hybrid robocentric and world-centric formulations are used for modeling the respective problems. We also demonstrate the effectiveness of the proposed method using both the synthetic data generated for Monte-Carlo simulations and diverse real datasets acquired in highly-dynamic, long-term, and large-scale SLAM scenarios. Simulation results validate the significantly improved consistency and accuracy by applying our method. Experimental results show the better (competitive at least) performance against a state-of-the-art method, while being capable of processing a huge amount of measurements in building large-scale maps without blocking the high-accuracy real-time localization outputs.},
  archive      = {J_TROB},
  author       = {Zheng Huai and Guoquan Huang},
  doi          = {10.1109/TRO.2024.3433868},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3734-3755},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A consistent parallel estimation framework for visual-inertial SLAM},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contact models in robotics: A comparative analysis.
<em>TROB</em>, <em>40</em>, 3716–3733. (<a
href="https://doi.org/10.1109/TRO.2024.3434208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics simulation is ubiquitous in robotics. Whether in model-based approaches (e.g., trajectory optimization), or model-free algorithms (e.g., reinforcement learning), physics simulators are a central component of modern control pipelines in robotics. Over the past decades, several robotic simulators have been developed, each with dedicated contact modeling assumptions and algorithmic solutions. In this article, we survey the main contact models and the associated numerical methods commonly used in robotics for simulating advanced robot motions involving contact interactions. In particular, we recall the physical laws underlying contacts and friction (i.e., Signorini condition, Coulomb&#39;s law, and the maximum dissipation principle), and how they are transcribed in current simulators. For each physics engine, we expose their inherent physical relaxations along with their limitations due to the numerical techniques employed. Based on our study, we propose theoretically grounded quantitative criteria on which we build benchmarks assessing both the physical and computational aspects of simulation. We support our work with an open-source and efficient C++ implementation of the existing algorithmic variations. Our results demonstrate that some approximations or algorithms commonly used in robotics can severely widen the reality gap and impact target applications. We hope this work will help motivate the development of new contact models, contact solvers, and robotic simulators in general, at the root of recent progress in motion generation in robotics.},
  archive      = {J_TROB},
  author       = {Quentin Le Lidec and Wilson Jallet and Louis Montaut and Ivan Laptev and Cordelia Schmid and Justin Carpentier},
  doi          = {10.1109/TRO.2024.3434208},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3716-3733},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Contact models in robotics: A comparative analysis},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Port-hamiltonian neural ODE networks on lie groups for robot
dynamics learning and control. <em>TROB</em>, <em>40</em>, 3695–3715.
(<a href="https://doi.org/10.1109/TRO.2024.3428433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate models of robot dynamics are critical for safe and stable control and generalization to novel operational conditions. Hand-designed models, however, may be insufficiently accurate, even after careful parameter tuning. This motivates the use of machine learning techniques to approximate the robot dynamics over a training set of state-control trajectories. The dynamics of many robots are described in terms of their generalized coordinates on a matrix Lie group, e.g., on $\text{SE}(3)$ for ground, aerial, and underwater vehicles, and generalized velocity, and satisfy conservation of energy principles. This article proposes a port-Hamiltonian formulation over a Lie group of the structure of a neural ordinary differential equation (ODE) network to approximate the robot dynamics. In contrast to a black-box ODE network, our formulation embeds energy conservation principle and Lie group&#39;s constraints in the dynamics model and explicitly accounts for energy-dissipation effect such as friction and drag forces in the dynamics model. We develop energy shaping and damping injection control for the learned, potentially under-actuated Hamiltonian dynamics to enable a unified approach for stabilization and trajectory tracking with various robot platforms.},
  archive      = {J_TROB},
  author       = {Thai Duong and Abdullah Altawaitan and Jason Stanley and Nikolay Atanasov},
  doi          = {10.1109/TRO.2024.3428433},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3695-3715},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Port-hamiltonian neural ODE networks on lie groups for robot dynamics learning and control},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated microrobotic manipulation using reconfigurable
magnetic microswarms. <em>TROB</em>, <em>40</em>, 3676–3694. (<a
href="https://doi.org/10.1109/TRO.2024.3428429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Untethered microrobots possess a promising perspective for micromanipulation applications. With specifically designed morphologies and structures, microrobots are able to perform controllable delivery of target objects. However, the manipulation process still lacks autonomy, to achieve which the mechanism of picking, transporting, and releasing behaviors needs further investigation. In this article, we propose to achieve automated microrobotic manipulation using magnetic microswarms with multimodal morphology. The microswarm is composed of around 11–21 million $\text{Fe}_{3}\mathrm{O}_{4}$ nanoparticles (1.0 $\text{--}1.8\,\mu$ L particle suspension). When exposed to different dynamic magnetic fields, the swarm could exhibit corresponding forms. We realize precise and controllable cargo picking and releasing by exploiting the fluid fields of different swarm forms. In order to quantitatively describe these behaviors, we design a finite-state machine. A super-twisting sliding-mode controller has been formulated for the motion control of swarms. The disturbances are compensated via a disturbance observer. To enable automated micromanipulation in obstructed scenarios, a path planner inspired by rapidly exploring random tree algorithm is designed for path planning when obstacles exist. We also propose an enhanced-genetic algorithm to optimally transport multiple objects to the target position. Experiments demonstrate that our method could effectively transport micro-objects with different sizes and shapes. The precise selectivity of the method is validated when multiple objects exist in the working environment. Finally, the long-distance delivery ability and adaptivity to various friction situations of our strategy are demonstrated. This work explores a concise, untethered, and automated micromanipulation strategy, provides a new automatic tool for micromanipulation tasks, and extends the application potential of swarm microrobotics.},
  archive      = {J_TROB},
  author       = {Jialin Jiang and Lidong Yang and Bo Hao and Tiantian Xu and Xinyu Wu and Li Zhang},
  doi          = {10.1109/TRO.2024.3428429},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3676-3694},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Automated microrobotic manipulation using reconfigurable magnetic microswarms},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Impact robustness versus torque bandwidth: A design guide
for differential elastic actuators. <em>TROB</em>, <em>40</em>,
3657–3675. (<a href="https://doi.org/10.1109/TRO.2024.3422049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential elastic actuators connect a motor and a spring via differential gears to a shared output shaft, offering a more compact solution for creating mechanically robust systems than series elastic actuators, with superior torque transmission at high frequencies. The key to maximizing DEA performance lies in the careful selection of stiffness, inertia, and damping values to meet specific requirements for performance and durability. We introduce a DEA design guide that utilizes open-loop torque-bandwidth for performance evaluation and the magnitude of impact-induced gear torque for robustness evaluation. This approach enables determining DEA parameters using closed-form equations, eliminating the need for simulations or extensive expert knowledge. The effectiveness of our method is confirmed through experiments with a reconfigurable DEA prototype.},
  archive      = {J_TROB},
  author       = {Anton Shu and Clara Raschel and Manuel Keppler and Armin Wedler and Martin Görner},
  doi          = {10.1109/TRO.2024.3422049},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3657-3675},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Impact robustness versus torque bandwidth: A design guide for differential elastic actuators},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). High-speed motion planning for aerial swarms in unknown and
cluttered environments. <em>TROB</em>, <em>40</em>, 3642–3656. (<a
href="https://doi.org/10.1109/TRO.2024.3429193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coordinated flight of multiple drones allows to achieve tasks faster such as search and rescue and infrastructure inspection. Thus, pushing the State-of-the-Art of aerial swarms in navigation speed and robustness is of tremendous benefit. In particular, being able to account for unexplored/unknown environments when planning trajectories allows for safer flight. In this work, we propose the first high-speed, decentralized, and synchronous motion planning framework (HDSM) for an aerial swarm that explicitly takes into account the unknown/undiscovered parts of the environment. The proposed approach generates an optimized trajectory for each planning agent that avoids obstacles and other planning agents while moving and exploring the environment. The only global information that each agent has is the target location. The generated trajectory is high-speed, safe from unexplored spaces, and brings the agent closer to its goal. The proposed method outperforms four recent state-of-the-art methods in success rate (100% success in reaching the target location), flight speed (97% faster), and flight time (50% lower). Finally, the method is validated on a set of Crazyflie nano-drones as a proof of concept.},
  archive      = {J_TROB},
  author       = {Charbel Toumieh and Dario Floreano},
  doi          = {10.1109/TRO.2024.3429193},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3642-3656},
  shortjournal = {IEEE Trans. Robot.},
  title        = {High-speed motion planning for aerial swarms in unknown and cluttered environments},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reconciling RaiSim with the maximum dissipation principle.
<em>TROB</em>, <em>40</em>, 3638–3641. (<a
href="https://doi.org/10.1109/TRO.2024.3430711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in reinforcement learning (RL) in robotics has been obtained by training control policy directly in simulation. Particularly in the context of quadrupedal locomotion, astonishing locomotion policies depicting high robustness against environmental perturbations have been trained by leveraging RaiSim simulator. While it avoids introducing forces at distance, it has been shown recently that RaiSim does not obey the maximum dissipation principle, a fundamental principle when simulating rigid contact interactions. In this note, we detail these relaxations and propose an algorithmic correction of the RaiSim contact algorithm to handle the maximum dissipation principle adequately. Our experiments empirically demonstrate our approach leads to simulation following this fundamental principle.},
  archive      = {J_TROB},
  author       = {Quentin Le Lidec and Justin Carpentier},
  doi          = {10.1109/TRO.2024.3430711},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3638-3641},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Reconciling RaiSim with the maximum dissipation principle},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Directional critical load index: A distance-to-instability
metric for continuum robots. <em>TROB</em>, <em>40</em>, 3620–3637. (<a
href="https://doi.org/10.1109/TRO.2024.3428432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equilibrium stability assessment is a primary issue in continuum robots (CRs). The possible stable-to-unstable transitions that CRs may admit complicate the use of CRs in tasks where safety and human–robot interactions are mandatory. In this context, metrics measuring the distance from instability are essential but rarely developed. Existing metrics are frequently based on the evaluation of matrices involving mixed units, thus resulting in unit-dependent metrics. Moreover, the physical meaning of existing metric is hard to interpretate. This article proposes to use the magnitude of a force that brings instability to the CR equilibrium as a measure of the distance to instability. The major advantages of this metric are the intrinsic physical meaning, the practical interpretation of the results, and the well-defined unit of the measurements. The proposed metric (named directional critical load index) is based on the linearization of the eigenvalues of the reduced Hessian matrix of the total potential energy, which can be achieved regardless of the employed discretization technique. Three different case studies illustrate and demonstrate the main results of this article.},
  archive      = {J_TROB},
  author       = {Federico Zaccaria and Edoardo Idà and Sébastien Briot},
  doi          = {10.1109/TRO.2024.3428432},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3620-3637},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Directional critical load index: A distance-to-instability metric for continuum robots},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Constrained stein variational trajectory optimization.
<em>TROB</em>, <em>40</em>, 3602–3619. (<a
href="https://doi.org/10.1109/TRO.2024.3428428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present constrained Stein variational trajectory optimization (CSVTO), an algorithm for performing trajectory optimization with constraints on a set of trajectories in parallel. We frame constrained trajectory optimization as a novel form of constrained functional minimization over trajectory distributions, which avoids treating the constraints as a penalty in the objective and allows us to generate diverse sets of constraint-satisfying trajectories. Our method uses Stein variational gradient descent to find a set of particles that approximates a distribution over low-cost trajectories while obeying constraints. CSVTO is applicable to problems with differentiable equality and inequality constraints and includes a novel particle resampling step to escape local minima. By explicitly generating diverse sets of trajectories, CSVTO is better able to avoid poor local minima and is more robust to initialization. We demonstrate that CSVTO outperforms baselines in challenging highly constrained tasks, such as a 7-DoF wrench manipulation task, where CSVTO outperforms all baselines both in success and constraint satisfaction.},
  archive      = {J_TROB},
  author       = {Thomas Power and Dmitry Berenson},
  doi          = {10.1109/TRO.2024.3428428},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3602-3619},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Constrained stein variational trajectory optimization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Precise control of soft robots amidst uncertain
environmental contacts and forces. <em>TROB</em>, <em>40</em>,
3565–3580. (<a href="https://doi.org/10.1109/TRO.2024.3427339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have reported on the remarkable ability of bioinspired soft robots to exhibit dexterous and contact-friendly motions. However, for these robots with deformable bodies, it is extremely challenging to achieve precise and robust control when undergoing uncertain forces and contact in the environment. In this work, we take a first step to address this issue for slender pneumatic soft robots by proposing a comprehensive modeling and control framework. Our framework employs a fully parametrized model that accurately describes both robot configurations and distributed forces using Hermite interpolation. Leveraging this model, we further establish an estimation algorithm that can infer complete robot configurations and distributed external forces from limited motion data, enabling perception of contact locations and forces. Integrating this model and estimator, our control framework achieves precise robot motion control under diverse forces, with the average trajectory tracking error within 0.3 mm. It also detects and adapts to uncertain contact, demonstrated in tests of automatic obstacle avoidance and precise grasping. This framework holds promise for various applications such as environmental exploration and safe manipulation, where compliant interaction with the environment is required.},
  archive      = {J_TROB},
  author       = {Xinjia Huang and Zihao Yuan and Xinyu Yang and Guoying Gu},
  doi          = {10.1109/TRO.2024.3427339},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3565-3580},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Precise control of soft robots amidst uncertain environmental contacts and forces},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robotic gas source localization with probabilistic mapping
and online dispersion simulation. <em>TROB</em>, <em>40</em>, 3551–3564.
(<a href="https://doi.org/10.1109/TRO.2024.3426368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas source localization ( GSL ) with an autonomous robot is a problem with many prospective applications, from finding pipe leaks to emergency-response scenarios. In this work, we present a new method to perform GSL in realistic indoor environments, featuring obstacles, and turbulent flow. Given the highly complex relationship between the source position and the measurements available to the robot (the single-point gas concentration, and the wind vector) we propose an observation model that derives from contrasting the online, real-time simulation of the gas dispersion from any candidate source localization against a gas concentration map built from sensor readings. To account for a convenient and grounded integration of both into a probabilistic estimation framework, we introduce the concept of probabilistic gas-hit maps, which provide a higher level of abstraction to model the time-dependent nature of gas dispersion. Results from both simulated and real experiments show the capabilities of our current proposal to deal with source localization in complex indoor environments.},
  archive      = {J_TROB},
  author       = {Pepe Ojeda and Javier Monroy and Javier Gonzalez-Jimenez},
  doi          = {10.1109/TRO.2024.3426368},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3551-3564},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robotic gas source localization with probabilistic mapping and online dispersion simulation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Measurement simplification in <span
class="math inline"><em>ρ</em></span>-POMDP with performance guarantees.
<em>TROB</em>, <em>40</em>, 3537–3550. (<a
href="https://doi.org/10.1109/TRO.2024.3424018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision making under uncertainty is at the heart of any autonomous system acting with imperfect information. The cost of solving the decision-making problem is exponential in the action and observation spaces, thus rendering it unfeasible for many online systems. This article introduces a novel approach to efficient decision making, by partitioning the high-dimensional observation space. Using the partitioned observation space, we formulate analytical bounds on the expected information-theoretic reward, for general belief distributions. These bounds are then used to plan efficiently while maintaining performance guarantees. We show that the bounds are adaptive and computationally efficient, and that they converge to the original solution. We extend the partitioning paradigm and present a hierarchy of partitioned spaces that allows greater efficiency in planning. We then propose a specific variant of these bounds for Gaussian beliefs and show a theoretical performance improvement of at least a factor of 4. Finally, we compare our novel method to other state-of-the-art algorithms in active simultaneous localization and mapping scenarios, in simulation and in real experiments. In both cases, we show a significant speedup in planning with performance guarantees.},
  archive      = {J_TROB},
  author       = {Tom Yotam and Vadim Indelman},
  doi          = {10.1109/TRO.2024.3424018},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3537-3550},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Measurement simplification in $\rho$-POMDP with performance guarantees},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A tree-based next-best-trajectory method for 3-d UAV
exploration. <em>TROB</em>, <em>40</em>, 3496–3513. (<a
href="https://doi.org/10.1109/TRO.2024.3422052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a fully integrated tree-based combined exploration-planning algorithm: exploration-rapidly-exploring random trees (RRT) (ERRT). The algorithm is focused on providing real-time solutions for local exploration in a fully unknown and unstructured environment while directly incorporating exploratory behavior, robot-safe path planning, and robot actuation into the central problem. ERRT provides a complete sampling and tree-based solution for evaluating “where to go next” by considering a tradeoff between maximizing information gain and minimizing the distances traveled and the robot actuation along the path. The complete scheme is evaluated in extensive simulations, comparisons, and real-world field experiments in constrained and narrow subterranean and GPS-denied environments. The framework is fully robot operating system (ROS) integrated and straightforward to use.},
  archive      = {J_TROB},
  author       = {Björn Lindqvist and Akash Patel and Kalle Löfgren and George Nikolakopoulos},
  doi          = {10.1109/TRO.2024.3422052},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3496-3513},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A tree-based next-best-trajectory method for 3-D UAV exploration},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). <span class="math inline"><em>D</em><sup>2</sup></span>SLAM:
Decentralized and distributed collaborative visual-inertial SLAM system
for aerial swarm. <em>TROB</em>, <em>40</em>, 3445–3464. (<a
href="https://doi.org/10.1109/TRO.2024.3422003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative simultaneous localization and mapping (CSLAM) is essential for autonomous aerial swarms, laying the foundation for downstream algorithms, such as planning and control. To address existing CSLAM systems&#39; limitations in relative localization accuracy, crucial for close-range UAV collaboration, this article introduces $D^{2}$ SLAM—a novel decentralized and distributed CSLAM system. $D^{2}$ SLAM innovatively manages near-field estimation for precise relative state estimation in proximity and far-field estimation for consistent global trajectories. Its adaptable front-end supports both stereo and omnidirectional cameras, catering to various operational needs and overcoming field-of-view challenges in aerial swarms. Experiments demonstrate $D^{2}$ SLAM&#39;s effectiveness in accurate ego-motion estimation, relative localization, and global consistency. Enhanced by distributed optimization algorithms, $D^{2}$ SLAM exhibits remarkable scalability and resilience to network delays, making it well suited for a wide range of real-world aerial swarm applications. We believe the adaptability and proven performance of $D^{2}$ SLAM signify a notable advancement in autonomous aerial swarm technology.},
  archive      = {J_TROB},
  author       = {Hao Xu and Peize Liu and Xinyi Chen and Shaojie Shen},
  doi          = {10.1109/TRO.2024.3422003},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3445-3464},
  shortjournal = {IEEE Trans. Robot.},
  title        = {$D^{2}$SLAM: Decentralized and distributed collaborative visual-inertial SLAM system for aerial swarm},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust pivoting manipulation using contact implicit bilevel
optimization. <em>TROB</em>, <em>40</em>, 3425–3444. (<a
href="https://doi.org/10.1109/TRO.2024.3422053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalizable manipulation requires that robots be able to interact with novel objects and environment. This requirement makes manipulation extremely challenging as a robot has to reason about complex frictional interactions with uncertainty in physical properties of the object and the environment. In this article, we study robust optimization for planning of pivoting manipulation in the presence of uncertainties. We present insights about how friction can be exploited to compensate for inaccuracies in the estimates of the physical properties during manipulation. Under certain assumptions, we derive analytical expressions for stability margin provided by friction during pivoting manipulation. This margin is then used in a contact implicit bilevel optimization framework to optimize a trajectory that maximizes this stability margin to provide robustness against uncertainty in several physical parameters of the object. We present analysis of the stability margin with respect to several parameters involved in the underlying bilevel optimization problem. We demonstrate our proposed method using a 6 DoF manipulator for manipulating several different objects. We also design and validate an MPC controller using the proposed algorithm which can track and regulate the position of the object during manipulation.},
  archive      = {J_TROB},
  author       = {Yuki Shirai and Devesh K. Jha and Arvind U. Raghunathan},
  doi          = {10.1109/TRO.2024.3422053},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3425-3444},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust pivoting manipulation using contact implicit bilevel optimization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Determination of all stable and unstable equilibria for
image-point-based visual servoing. <em>TROB</em>, <em>40</em>,
3406–3424. (<a href="https://doi.org/10.1109/TRO.2024.3422050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local minima are a well-known drawback of image-based visual servoing systems. Up to now, there were no formal guarantees on their number, or even their existence, according to the considered configuration. In this work, a formal approach is presented for the exhaustive computation of all minima and unstable equilibria for a class of six well-known image-based visual servoing controllers. This approach relies on a new polynomial formulation of the equilibrium condition that avoids using the camera pose. By using modern computational algebraic geometry methods and an ad hoc symmetry breaking strategy, the formal resolution of this new equilibrium condition is rendered computationally feasible. The proposed methodology is applied to compute the equilibria of several classical visual servoing tasks, with planar and nonplanar configurations of four and five points. The effects of local minima and saddle points on the dynamics of the system are finally illustrated through intensive simulation results, as well as the effects of image noise and uncertainties on depths.},
  archive      = {J_TROB},
  author       = {Alessandro Colotti and Jorge García Fontán and Alexandre Goldsztejn and Sébastien Briot and François Chaumette and Olivier Kermorgant and Mohab Safey El Din},
  doi          = {10.1109/TRO.2024.3422050},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3406-3424},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Determination of all stable and unstable equilibria for image-point-based visual servoing},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transferring grasping across grippers: Learning–optimization
hybrid framework for generalized planar grasp generation. <em>TROB</em>,
<em>40</em>, 3388–3405. (<a
href="https://doi.org/10.1109/TRO.2024.3422054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As diverse robotic hands keep emerging for industrial and household use, designing general grasp synthesis algorithms applicable to multiple grippers remains challenging. To improve the generality and effectiveness of multigripper planar grasping algorithms, we propose a grasping framework featuring gripper-agnostic scene inference and gripper-changeable optimization. In our approach, we introduce an interaction probability map that bridges the scene inference and grasp optimization modules. It efficiently decouples the learning of grasping knowledge and modeling of gripper&#39;s kinematics. The inference module adopts a modified directional ensemble method with a generated fingertip dataset to refine scene information. In grasp optimization, we formulate gripper-kinematic constraints for different grippers according to joint types. Extensive evaluations on the Cornell Grasping Dataset (with a success rate of 95.51%) and on multifingered grippers (ten grippers in the real world) demonstrate that our hybrid approach generalizes learnable knowledge across various grippers. This work enables the direct transfer of learned grasping knowledge to new grippers in real-world applications.},
  archive      = {J_TROB},
  author       = {Xianli Wang and Qingsong Xu},
  doi          = {10.1109/TRO.2024.3422054},
  journal      = {IEEE Transactions on Robotics},
  month        = {7},
  pages        = {3388-3405},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Transferring grasping across grippers: Learning–Optimization hybrid framework for generalized planar grasp generation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Value approximation for two-player general-sum differential
games with state constraints. <em>TROB</em>, <em>40</em>, 4837–4855. (<a
href="https://doi.org/10.1109/TRO.2024.3411850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving Hamilton–Jacobi–Isaacs (HJI) PDEs numerically enables equilibrial feedback control in two-player differential games, yet faces the curse of dimensionality (CoD). While physics-informed neural networks (PINNs) have shown promise in alleviating CoD in solving PDEs, vanilla PINNs fall short in learning discontinuous solutions due to their sampling nature, leading to poor safety performance of the resulting policies when values are discontinuous due to state or temporal logic constraints. In this study, we explore three potential solutions to this challenge: 1) a hybrid learning method that is guided by both supervisory equilibria and the HJI PDE, 2) a value-hardening method where a sequence of HJIs are solved with increasing Lipschitz constant on the constraint violation penalty, and 3) the epigraphical technique that lifts the value to a higher dimensional state space where it becomes continuous. Evaluations through 5-D and 9-D vehicle and 13-D drone simulations reveal that the hybrid method outperforms others in terms of generalization and safety performance by taking advantage of both the supervisory equilibrium values and co-states, and the low cost of PINN loss gradients.},
  archive      = {J_TROB},
  author       = {Lei Zhang and Mukesh Ghimire and Wenlong Zhang and Zhe Xu and Yi Ren},
  doi          = {10.1109/TRO.2024.3411850},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {4837-4855},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Value approximation for two-player general-sum differential games with state constraints},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HIPer: A human-inspired scene perception model for
multifunctional mobile robots. <em>TROB</em>, <em>40</em>, 4668–4683.
(<a href="https://doi.org/10.1109/TRO.2024.3420799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking over arbitrary tasks like humans do with a mobile service robot in open-world settings requires a holistic scene perception for decision-making and high-level control. This article presents a human-inspired scene perception model to minimize the gap between human and robotic capabilities. The approach takes over fundamental neuroscience concepts, such as a triplet perception split into recognition, knowledge representation, and knowledge interpretation. A recognition system splits the background and foreground to integrate exchangeable image-based object detectors and simultaneous localization and mapping, a multilayer knowledge base represents scene information in a hierarchical structure and offers interfaces for high-level control, and knowledge interpretation methods deploy spatio-temporal scene analysis and perceptual learning for self-adjustment. A single-setting ablation study is used to evaluate the impact of each component on the overall performance for a fetch-and-carry scenario in two simulated and one real-world environment.},
  archive      = {J_TROB},
  author       = {Florenz Graf and Jochen Lindermayr and Birgit Graf and Werner Kraus and Marco F. Huber},
  doi          = {10.1109/TRO.2024.3420799},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {4668-4683},
  shortjournal = {IEEE Trans. Robot.},
  title        = {HIPer: A human-inspired scene perception model for multifunctional mobile robots},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive complexity model predictive control. <em>TROB</em>,
<em>40</em>, 4615–4634. (<a
href="https://doi.org/10.1109/TRO.2024.3410408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces a formulation of model predictive control (MPC), which adaptively reasons about the complexity of the model while maintaining feasibility and stability guarantees. Existing approaches often handle computational complexity by shortening prediction horizons or simplifying models, both of which can result in instability. Inspired by related approaches in behavioral economics, motion planning, and biomechanics, our method solves MPC problems with a simple model for dynamics and constraints over regions of the horizon where such a model is feasible and a complex model where it is not. The approach leverages an interleaving of planning and execution to iteratively identify these regions, which can be safely simplified if they satisfy an exact template/anchor relationship. We show that this method does not compromise the stability and feasibility properties of the system, and measures performance in simulation experiments on a quadrupedal robot executing agile behaviors over terrains of interest. We find that this adaptive method enables more agile motion (55% increase in top speed) and expands the range of executable tasks compared with fixed-complexity implementations.},
  archive      = {J_TROB},
  author       = {Joseph Norby and Ardalan Tajbakhsh and Yanhao Yang and Aaron M. Johnson},
  doi          = {10.1109/TRO.2024.3410408},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {4615-4634},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Adaptive complexity model predictive control},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified motion modeling approach for snake robot’s gaits
generated with backbone curve method. <em>TROB</em>, <em>40</em>,
4132–4146. (<a href="https://doi.org/10.1109/TRO.2024.3420803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a unified motion modeling approach for the 3-D snake robot is proposed, which enables motion prediction of all kinds of gaits generated by the backbone curve method on the ground. More specifically, the motion of the snake robot is novelly decomposed into two components, namely, the curve component and the shift component, which are explicitly related to the backbone curve&#39;s parameters and control&#39;s input. Considering the actual behavior of snake robots, a nonslip assumption is made to facilitate the modeling approach. Based on that, the ground-contacting points of the robot&#39;s links during shift control are conveniently analyzed, which helps to determine the moving direction of the curve components. Finally, with ground contacting points and backbone curve parameters determined, the characteristics of the two components, as well as the motion model, are successfully obtained. Utilizing this modeling approach, the widely used gaits, such as sidewinding, crawler, and S-pedal, are successfully modeled and then carefully analyzed to predict the movement of the snake robot with arbitrary given control input. Three groups of experiments are conducted, with the collected results showing the satisfactory accuracy of the obtained models. Compared with existing methods, the proposed modeling approach achieves a much more precise prediction, both in the direction and magnitude of snake robot motions.},
  archive      = {J_TROB},
  author       = {Wei Huang and Yongchun Fang and Xian Guo and Huawang Liu and Lixing Liu},
  doi          = {10.1109/TRO.2024.3420803},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {4132-4146},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A unified motion modeling approach for snake robot&#39;s gaits generated with backbone curve method},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SLAM-based joint calibration of multiple asynchronous
microphone arrays and sound source localization. <em>TROB</em>,
<em>40</em>, 4024–4044. (<a
href="https://doi.org/10.1109/TRO.2024.3410456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot audition systems with multiple microphone arrays have many applications in practice. However, the accurate calibration of multiple microphone arrays remains challenging because there are many unknown parameters to be identified, including the relative transforms (i.e., orientation and translation) and asynchronous factors (i.e., initial time offset and sampling clock difference) between microphone arrays. To tackle these challenges, in this article, we adopt batch simultaneous localization and mapping (SLAM) for joint calibration of multiple asynchronous microphone arrays and sound source localization. Using the Fisher information matrix (FIM) approach, we first conduct the observability analysis (i.e., parameter identifiability) of the abovementioned calibration problem and establish necessary/sufficient conditions under which the FIM and the Jacobian matrix have full column rank, which implies the identifiability of the unknown parameters. We also discover several scenarios where the unknown parameters are not uniquely identifiable. Subsequently, we propose an effective framework to initialize the unknown parameters, which is used as the initial guess in batch SLAM for multiple microphone array calibration, aiming to further enhance optimization accuracy and convergence. Extensive numerical simulations and real experiments have been conducted to verify the performance of the proposed method. The experimental results show that the proposed pipeline achieves higher accuracy with fast convergence in comparison to methods that use the noise-corrupted ground truth of the unknown parameters as the initial guess in the optimization and other existing frameworks.},
  archive      = {J_TROB},
  author       = {Jiang Wang and Yuanzheng He and Daobilige Su and Katsutoshi Itoyama and Kazuhiro Nakadai and Junfeng Wu and Shoudong Huang and Youfu Li and He Kong},
  doi          = {10.1109/TRO.2024.3410456},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {4024-4044},
  shortjournal = {IEEE Trans. Robot.},
  title        = {SLAM-based joint calibration of multiple asynchronous microphone arrays and sound source localization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning human-like functional grasping for multifinger
hands from few demonstrations. <em>TROB</em>, <em>40</em>, 3897–3916.
(<a href="https://doi.org/10.1109/TRO.2024.3420722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the challenge of enabling multifinger hands to perform human-like functional grasping for various intentions. However, accomplishing functional grasping in real robot hands present many challenges, including handling generalization ability for kinematically diverse robot hands, generating intention-conditioned grasps for a large variety of objects, and incomplete perception from a single-view camera. In this work, we first propose a six-step functional grasp synthesis algorithm based on fine-grained contact modeling. With the fine-grained contact-based optimization and learned dense shape correspondence, the algorithm is adaptable to various objects of the same category and a wide range of multifinger hands using few demonstrations. Second, over 10 k functional grasps are synthesized to train our neural network, named DexFG-Net, which generates intention-conditioned grasps based on reconstructed object. Extensive experiments in the simulation and physical grasps indicate that the grasp synthesis algorithm can produce human-like functional grasp with robust stability and functionality, and the DexFG-Net can generate plausible and human-like intention-conditioned grasping postures for anthropomorphic hands.},
  archive      = {J_TROB},
  author       = {Wei Wei and Peng Wang and Sizhe Wang and Yongkang Luo and Wanyi Li and Daheng Li and Yayu Huang and Haonan Duan},
  doi          = {10.1109/TRO.2024.3420722},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3897-3916},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning human-like functional grasping for multifinger hands from few demonstrations},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Disturbance-adaptive tapered soft manipulator with precise
motion controller for enhanced task performance. <em>TROB</em>,
<em>40</em>, 3581–3601. (<a
href="https://doi.org/10.1109/TRO.2024.3420802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of soft manipulators requires a more promising solution, including efficient structures and controllers. This article presents a novel cable–pneumatic hybrid-driven tapered soft manipulator (TSM) design and control scheme to enhance the performance in actual tasks. This article is the first to present the design with a Bowden tube as a driving tendon and propose a composite tendon with Bowden tubes and cable tendons (BTCTs). Leveraging the principles of hybrid-driven antagonism, the compact TSM integrates the composite tendon with BTCTs and pneumatically actuated tapered bellows. This new hybrid-driven form provides the TSM with excellent resistance to axial extension, tangential bending, and torsion, enhancing the stiffness of the TSM. The variable-stiffness range of the TSM was quantified in tests, including axial stiffness (0.57–10.77 N/mm), tangential bending stiffness (0.01–0.45 N/mm), and torsion stiffness (0.02–0.044 N $\cdot$ m/ $^\circ$ ) tests. A deep learning-based neural network approach was utilized to model the inverse kinematics of the TSM. For more precise motion control, using position and orientation feedback from the sensor at the tip, we have designed a closed-loop iterative feedback controller incorporating three algorithms. Experiments on spatial point positioning, trajectory tracking with different constraints, orientation control, and disturbance experiments were conducted on the TSM. Experimental results [spatial point positioning error (mean error of stable region: 0.17 mm), circular trajectory tracking error (mean and standard deviation (SD) of 100 trials: 0.87 $\pm$ 0.57 mm), orientation control error (less than 1 $^{\circ }$ ), and the performance in disturbance experiment] demonstrated that our approach has high control accuracy and strong robustness against external disturbances. We conducted experiments involving teleoperation control, collision-free precise operations in cluttered and constrained environments, and disturbance-adaptive board cleaning testing, ensuring both stability and safety during contact with humans. These experiments intuitively demonstrate the potential of this TSM for executing complex tasks in real-world environments, promising to become a safe collaborative assistant for humans in the future.},
  archive      = {J_TROB},
  author       = {Xianglong Li and Quan Xiong and Dongbao Sui and Qinghua Zhang and Hongwu Li and Ziqi Wang and Tianjiao Zheng and Hesheng Wang and Jie Zhao and Yanhe Zhu},
  doi          = {10.1109/TRO.2024.3420802},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3581-3601},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Disturbance-adaptive tapered soft manipulator with precise motion controller for enhanced task performance},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting trust for resilient hypothesis testing with
malicious robots. <em>TROB</em>, <em>40</em>, 3514–3536. (<a
href="https://doi.org/10.1109/TRO.2024.3415235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we develop a resilient binary hypothesis testing framework for decision making in adversarial multirobot crowdsensing tasks. This framework exploits stochastic trust observations between robots to arrive at tractable, resilient decision making at a centralized fusion center (FC) even when, first, there exist malicious robots in the network and their number may be larger than the number of legitimate robots, and second, the FC uses one-shot noisy measurements from all robots. We derive two algorithms to achieve this. The first is the two-stage approach (2SA) that estimates the legitimacy of robots based on received trust observations, and provably minimizes the probability of detection error in the worst-case malicious attack. For the 2SA, we assume that the proportion of malicious robots is known but arbitrary. For the case of an unknown proportion of malicious robots, we develop the adversarial generalized likelihood ratio test (A-GLRT) that uses both the reported robot measurements and trust observations to simultaneously estimate the trustworthiness of robots, their reporting strategy, and the correct hypothesis. We exploit particular structures in the problem to show that this approach remains computationally tractable even with unknown problem parameters. We deploy both algorithms in a hardware experiment where a group of robots conducts crowdsensing of traffic conditions subject to a Sybil attack on a mock-up road network. We extract the trust observations for each robot from communication signals, which provide statistical information on the uniqueness of the sender. We show that even when the malicious robots are in the majority, the FC can reduce the probability of detection error to 30.5% and 29% for the 2SA and the A-GLRT algorithms, respectively.},
  archive      = {J_TROB},
  author       = {Matthew Cavorsi and Orhan Eren Akgün and Michal Yemini and Andrea J. Goldsmith and Stephanie Gil},
  doi          = {10.1109/TRO.2024.3415235},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3514-3536},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Exploiting trust for resilient hypothesis testing with malicious robots},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Obstacle-aided trajectory control of a quadrupedal robot
through sequential gait composition. <em>TROB</em>, <em>40</em>,
3481–3495. (<a href="https://doi.org/10.1109/TRO.2024.3410531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling and controlling legged robot locomotion on terrains with densely distributed large rocks and boulders are fundamentally challenging. Unlike traditional methods, which often consider these rocks and boulders as obstacles and attempt to find a clear path to circumvent them, in this study, we aim to develop methods for robots to actively utilize interaction forces with these “obstacles” for locomotion and navigation. To do so, we studied the locomotion of a quadrupedal robot as it traversed a simplified obstacle field with 12 different gaits and discovered that with each gait, the robot could passively converge to a distinct orientation. A compositional return map explained this observed passive convergence and enabled prediction of the steady-state orientation angles for each quadrupedal gait. We experimentally demonstrated that with these predictions, a legged robot could effectively generate the desired shape of trajectories among large, slippery obstacles, simply by switching between different gaits. Our study offered a novel method for robots to exploit traditionally-considered “obstacles” to achieve agile movements on challenging terrains.},
  archive      = {J_TROB},
  author       = {Haodi Hu and Feifei Qian},
  doi          = {10.1109/TRO.2024.3410531},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3481-3495},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Obstacle-aided trajectory control of a quadrupedal robot through sequential gait composition},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deformable open-frame cable-driven parallel robots:
Modeling, analysis, and control. <em>TROB</em>, <em>40</em>, 3465–3480.
(<a href="https://doi.org/10.1109/TRO.2024.3420714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a generalized type of cable-driven parallel robot with deformable frames (D-CDPRs). The class of D-CDPRs allows: first, inevitable deformation of traditional rigid frame CDPRs to be considered; and second, new possibilities to develop CDPRs with lightweight frames that would deform. Comparatively, such lightweight CDPRs are easier to set up and largely reduce the cost of material and construction. However, the analysis and control of D-CDPRs are challenging as existing works usually assume the CDPR frame is rigid, such that the cable exit points on the frame are known and fixed. If the modeling errors induced by the deformable frame are not addressed appropriately, the control performance of D-CDPRs will be inaccurate and even unstable. To tackle this problem, novel modeling, analysis, and control approaches are proposed accordingly for D-CDPRs. Using the Euler–Bernoulli beam equations to develop a D-CDPR model, the workspace analysis is proposed and explored. Furthermore, the model-based feedforward length (MBFL) controller is proposed, where it is shown that cable length can be used to execute the tension control for D-CDPRs. Finally, the proposed work is validated in both simulation and hardware experiments.},
  archive      = {J_TROB},
  author       = {Arthur Ngo Foon Chan and Wuichung Cheng and Darwin Lau},
  doi          = {10.1109/TRO.2024.3420714},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3465-3480},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Deformable open-frame cable-driven parallel robots: Modeling, analysis, and control},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How safe is particle filtering-based localization for mobile
robots? An integrity monitoring approach. <em>TROB</em>, <em>40</em>,
3372–3387. (<a href="https://doi.org/10.1109/TRO.2024.3420798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deriving safe bounds on particle filter estimate is a research problem that, if solved, could greatly benefit robots in life-critical applications, a field that is facing increasing interest as more robots are being deployed near humans. In response, this article introduces a new fault detector and derives a performance measure for particle filter: integrity risk. Integrity risk is defined as the probability of having large estimate errors without triggering an alarm, all while considering measurement faults, unknown deterministic errors that cannot be modeled via normal white noise. In this work, the faults come in the form of incorrectly associated features when using the local nearest neighbors. Simulations and experiments assess the efficiency of the introduced safety metric. The results show that safety improves as map density increases as long as the number of particles is sufficient to shape the error distribution and the landmarks are well separated. Also, the results indicate that, when landmarks are poorly separated, particle filter is safer than Kalman filter, whereas, when landmarks are well separated, particle filter is often, but not always, safer than Kalman filter.},
  archive      = {J_TROB},
  author       = {Osama Abdul Hafez and Mathieu Joerger and Matthew Spenko},
  doi          = {10.1109/TRO.2024.3420798},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3372-3387},
  shortjournal = {IEEE Trans. Robot.},
  title        = {How safe is particle filtering-based localization for mobile robots? an integrity monitoring approach},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Task and motion planning for execution in the real.
<em>TROB</em>, <em>40</em>, 3356–3371. (<a
href="https://doi.org/10.1109/TRO.2024.3418550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task and motion planning represents a powerful set of hybrid planning methods that combine reasoning over discrete task domains and continuous motion generation. Traditional reasoning necessitates task domain models and enough information to ground actions to motion planning queries. Gaps in this knowledge often arise from sources such as occlusion or imprecise modeling. This work generates task and motion plans that include actions cannot be fully grounded at planning time. During execution, such an action is handled by a provided human-designed or learned closed-loop behavior. Execution combines offline planned motions and online behaviors till reaching the task goal. Failures of behaviors are fed back as constraints to find new plans. Forty real-robot trials and motivating demonstrations are performed to evaluate the proposed framework and compare it against state-of-the-art. Results show faster execution time, less number of actions, and more success in problems where diverse gaps arise. The experiment data are shared for researchers to simulate these settings. The work shows promise in expanding the applicable class of realistic partially grounded problems that robots can address.},
  archive      = {J_TROB},
  author       = {Tianyang Pan and Rahul Shome and Lydia E. Kavraki},
  doi          = {10.1109/TRO.2024.3418550},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3356-3371},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Task and motion planning for execution in the real},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quadratic programming-based reference spreading control for
dual-arm robotic manipulation with planned simultaneous impacts.
<em>TROB</em>, <em>40</em>, 3341–3355. (<a
href="https://doi.org/10.1109/TRO.2024.3420800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the aim of further enabling the exploitation of intentional impacts in robotic manipulation, a control framework is presented that directly tackles the challenges posed by tracking control of robotic manipulators that are tasked to perform nominally simultaneous impacts. This framework is an extension of the reference spreading (RS) control framework, in which overlapping ante- and post-impact references that are consistent with impact dynamics are defined. In this work, such a reference is constructed starting from a teleoperation-based approach. By using the corresponding ante- and post-impact control modes in the scope of a quadratic programming control approach, peaking of the velocity error and control inputs due to impacts is avoided while maintaining high tracking performance. With the inclusion of a novel interim mode, we aim to also avoid input peaks and steps when uncertainty in the environment causes a series of unplanned single impacts to occur rather than the planned simultaneous impact. This work in particular presents for the first time an experimental evaluation of RS control on a robotic setup, showcasing its robustness against uncertainty in the environment compared to three baseline control approaches.},
  archive      = {J_TROB},
  author       = {Jari van Steen and Gijs van den Brandt and Nathan van de Wouw and Jens Kober and Alessandro Saccon},
  doi          = {10.1109/TRO.2024.3420800},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3341-3355},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Quadratic programming-based reference spreading control for dual-arm robotic manipulation with planned simultaneous impacts},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An underactuated active transfemoral prosthesis with series
elastic actuators enables multiple locomotion tasks. <em>TROB</em>,
<em>40</em>, 3306–3321. (<a
href="https://doi.org/10.1109/TRO.2024.3415228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic lower limb prostheses have the power to revolutionize mobility by enhancing gait efficiency and facilitating movement. While several design approaches have been explored to create lightweight and energy-efficient devices, the potential of underactuation remains largely untapped in lower limb prosthetics. Taking inspiration from the natural harmony of walking, in this article, we have developed an innovative active transfemoral prosthesis. By incorporating underactuation, our design uses a single power actuator placed near the knee joint and connected to a differential mechanism to drive both the knee and ankle joints. We conduct comprehensive benchtop tests and evaluate the prosthesis with three individuals who have above-knee amputations, assessing its performance in walking, stair climbing, and transitions between sitting and standing. Our evaluation focuses on gathering position and torque data recorded from sensors integrated into the prosthesis and comparing these measurements to biomechanical data of able-bodied locomotion. Our findings highlight the promise of underactuation in advancing lower limb prosthetics and demonstrate the feasibility of our knee–ankle underactuated design in various tasks, showcasing its ability to replicate natural movement.},
  archive      = {J_TROB},
  author       = {Ilaria Fagioli and Francesco Lanotte and Tommaso Fiumalbi and Andrea Baldoni and Alessandro Mazzarini and Filippo Dell&#39;Agnello and Huseyin Eken and Vito Papapicco and Tommaso Ciapetti and Alessandro Maselli and Claudio Macchi and Sofia Dalmiani and Angelo Davalli and Emanuele Gruppioni and Emilio Trigili and Simona Crea and Nicola Vitiello},
  doi          = {10.1109/TRO.2024.3415228},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3306-3321},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An underactuated active transfemoral prosthesis with series elastic actuators enables multiple locomotion tasks},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analytical model and experimental testing of the SoftFoot:
An adaptive robot foot for walking over obstacles and irregular
terrains. <em>TROB</em>, <em>40</em>, 3290–3305. (<a
href="https://doi.org/10.1109/TRO.2024.3415237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot feet are crucial for maintaining dynamic stability and propelling the body during walking, especially on uneven terrains. Traditionally, robot feet were mostly designed as flat and stiff pieces of metal, which meets its limitations when the robot is required to step on irregular grounds, e.g., stones. While one could think that adding compliance under such feet would solve the problem, this is not the case. To address this problem, we introduced the SoftFoot, an adaptive foot design that can enhance walking performance over irregular grounds. The proposed design is completely passive and varies its shape and stiffness based on the exerted forces, through a system of pulley, tendons, and springs opportunely placed in the structure. This article outlines the motivation behind the SoftFoot and describes the theoretical model which led to its final design. The proposed system has been experimentally tested and compared with two analogous conventional feet, a rigid one and a compliant one, with similar footprints and soles. The experimental validation focuses on the analysis of the standing performance, measured in terms of the equivalent support surface extension and the compensatory ankle angle, and the rejection of impulsive forces, which is important in events such as stepping on unforeseen obstacles. Results show that the SoftFoot has the largest equivalent support surface when standing on obstacles, and absorbs impulsive loads in a way almost as good as a compliant foot.},
  archive      = {J_TROB},
  author       = {Cristina Piazza and Cosimo Della Santina and Giorgio Grioli and Antonio Bicchi and Manuel G. Catalano},
  doi          = {10.1109/TRO.2024.3415237},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3290-3305},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Analytical model and experimental testing of the SoftFoot: An adaptive robot foot for walking over obstacles and irregular terrains},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parallel-continuum robots: A survey. <em>TROB</em>,
<em>40</em>, 3252–3270. (<a
href="https://doi.org/10.1109/TRO.2024.3415230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel-continuum robots combine the advantages of both parallel and continuum robotics. They offer a compromise between the inherent compliance and slenderness of continuum robots and the high precision and strength of rigid-link parallel robots. Throughout recent years there has been an increasing research interest in these novel architectures, which form closed kinematic chains that feature flexible, continuous links undergoing elastic deformations. As the number of publications in this emerging research field is steadily increasing, this survey article summarizes and reviews the state of the art in parallel-continuum robots, discussing their design and modeling. A definition and notation for parallel-continuum robots is introduced, allowing for a clear classification. In conclusion, current open research questions and possible applications for such robots are discussed.},
  archive      = {J_TROB},
  author       = {Sven Lilge and Kathrin Nuelle and Jake A. Childs and Kefei Wen and D. Caleb Rucker and Jessica Burgner-Kahrs},
  doi          = {10.1109/TRO.2024.3415230},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3252-3270},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Parallel-continuum robots: A survey},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TossNet: Learning to accurately measure and predict robot
throwing of arbitrary objects in real time with proprioceptive sensing.
<em>TROB</em>, <em>40</em>, 3232–3251. (<a
href="https://doi.org/10.1109/TRO.2024.3416009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate measuring and modeling of dynamic robot manipulation (e.g., tossing and catching) is particularly challenging, due to the inherent nonlinearity, complexity, and uncertainty in high-speed robot motions and highly dynamic robot–object interactions happening in very short distances and times. Most studies leverage extrinsic sensors such as visual and tactile feedback toward task or object-centric modeling of manipulation dynamics, which, however, may hit bottleneck due to the significant cost and complexity, e.g., the environmental restrictions. In this work, we investigate whether using solely the on-board proprioceptive sensory modalities can effectively capture and characterize dynamic manipulation processes. In particular, we present an object-agnostic strategy to learn the robot toss dynamics of arbitrary unknown objects from the spatio-temporal variations of robot toss movements and wrist-force/torque (F/T) observations. We then propose TossNet, an end-to-end formulation that jointly measures the robot toss dynamics and predicts the resulting flying trajectories of the tossed objects. Experimental results in both simulation and real-world scenarios demonstrate that our methods can accurately model the robot toss dynamics of both seen and unseen objects, and predict their flying trajectories with superior prediction accuracy in nearly real-time. Ablative results are also presented to demonstrate the effectiveness of each proprioceptive modality and their correlations in modeling the toss dynamics. Case studies show that TossNet can be applied on various real robot platforms for challenging tossing-centric robot applications, such as blind juggling and high-precise robot pitching.},
  archive      = {J_TROB},
  author       = {Lipeng Chen and Weifeng Lu and Kun Zhang and Yizheng Zhang and Longfei Zhao and Yu Zheng},
  doi          = {10.1109/TRO.2024.3416009},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3232-3251},
  shortjournal = {IEEE Trans. Robot.},
  title        = {TossNet: Learning to accurately measure and predict robot throwing of arbitrary objects in real time with proprioceptive sensing},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust quadrupedal jumping with impact-aware landing:
Exploiting parallel elasticity. <em>TROB</em>, <em>40</em>, 3212–3231.
(<a href="https://doi.org/10.1109/TRO.2024.3411988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introducing parallel elasticity in the hardware design endows quadrupedal robots with the ability to perform explosive and efficient motions. However, for this kind of articulated soft quadruped, realizing dynamic jumping with robustness against system uncertainties remains a challenging problem. To achieve this, we propose an impact-aware jumping planning and control approach. Specifically, an offline kino-dynamic-type trajectory optimizer is first formulated to achieve compliant 3-D jumping motions, using a novel actuated spring-loaded inverted pendulum (SLIP) model. Then, an optimization-based online landing strategy, including preimpact leg motion modulation and postimpact landing recovery, is designed. The actuated SLIP model, with the capability of explicitly characterizing parallel elasticity, captures the jumping and landing dynamics, making the problem of motion generation/regulation more tractable. Finally, a hybrid torque control consisting of a feedback tracking loop and a feedforward compensation loop is employed for motion control. Experiments demonstrate the ability to accomplish robust 3-D jumping motions with stable landing and recovery. Besides, our approach can be applied to quadrupedal robots with or without additional parallel compliance.},
  archive      = {J_TROB},
  author       = {Jiatao Ding and Vassil Atanassov and Edoardo Panichi and Jens Kober and Cosimo Della Santina},
  doi          = {10.1109/TRO.2024.3411988},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3212-3231},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust quadrupedal jumping with impact-aware landing: Exploiting parallel elasticity},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cable-driven upper limb rehabilitation robot with
muscle-synergy-based myoelectric controller. <em>TROB</em>, <em>40</em>,
3199–3211. (<a href="https://doi.org/10.1109/TRO.2024.3411849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface electromyography (sEMG) signal has been used in upper limb rehabilitation robots (ULRR). However, existing ULRR based on myoelectric controllers suffers from limited generalization ability in estimating three-dimensional (3-D) motion intention. This article proposes a muscle-synergy-inspired approach to enhance the generalization ability of the myoelectric controller of a cable-driven ULRR. Low-dimensional commands are extracted from sEMG signals based on an EMG-to-muscle activation model and non-negative matrix factorization. The extracted commands are used to estimate the 3-D human force. Two different trajectory tracking tasks are selected to test the generalization ability. The system is trained based on training sets where participants perform one task. Then the system is tested using testing sets where participants perform the other task. Finally, the system is verified on real-time robotic control experiment. Results show that the proposed controller achieves better force estimating accuracy, better trajectory tracking accuracy, and lower interaction force than the myoelectric controller without considering muscle synergies, which means the proposed controller yields better generalization performance.},
  archive      = {J_TROB},
  author       = {Chenglin Xie and Yueling Lyu and Guoxin Li and Raymond Kai-Yu Tong and Haisheng Xia and Rong Song and Zhijun Li},
  doi          = {10.1109/TRO.2024.3411849},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3199-3211},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A cable-driven upper limb rehabilitation robot with muscle-synergy-based myoelectric controller},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A minimally designed audio-animatronic robot. <em>TROB</em>,
<em>40</em>, 3181–3198. (<a
href="https://doi.org/10.1109/TRO.2024.3410467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animatronic robots that simulate the lively and realistic motions of creatures can be excellent robotic platforms for social interaction with people. In particular, the robot head is a very important part of expressing various emotions and generating human-friendly and aesthetic impressions. This article presents Ray, a new type of audio-animatronic robot head. All the mechanical structure of the robot is built in one step by 3-D printing and has multiple layers expressing the overall shape of a human head and important features such as eyes, nose, mouth, and chin. This simple, lightweight structure and the separatetendon-based actuation system underneath allow for smooth, fast motions of the robot. We also develop an audio-driven motion generation module that automatically synthesizes natural and rhythmic motions of the head and mouth based on the given audio. The developed robot platform is used for various applications, for example, as a talking robot, robot singer, and robot MC. We expect this research opens up a new paradigm and application possibilities for minimally designed audio-animatronic robots.},
  archive      = {J_TROB},
  author       = {Kyu Min Park and Jeongah Cheon and Sehyuk Yim},
  doi          = {10.1109/TRO.2024.3410467},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3181-3198},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A minimally designed audio-animatronic robot},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Planar friction modeling with LuGre dynamics and limit
surfaces. <em>TROB</em>, <em>40</em>, 3166–3180. (<a
href="https://doi.org/10.1109/TRO.2024.3410455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During planar motion, contact surfaces exhibit a coupling between tangential and rotational friction forces. This article proposes planar friction models grounded in the LuGre model and limit surface theory. First, distributed planar extended state models are proposed, and the elastoplastic model is extended for multidimensional friction. Subsequently, we derive a reduced planar friction model coupled with a precalculated limit surface, which offers the reduced computational cost. The limit surface approximation through an ellipsoid is discussed. The properties of the planar friction models are assessed in various simulations, demonstrating that the reduced planar friction model achieves comparable performance to the distributed model while exhibiting $\sim\! 80$ times the lower computational cost.},
  archive      = {J_TROB},
  author       = {Gabriel Arslan Waltersson and Yiannis Karayiannidis},
  doi          = {10.1109/TRO.2024.3410455},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3166-3180},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Planar friction modeling with LuGre dynamics and limit surfaces},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MINRob: A large force-outputting miniature robot based on a
triple-magnet system. <em>TROB</em>, <em>40</em>, 3127–3145. (<a
href="https://doi.org/10.1109/TRO.2024.3410096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetically actuated miniature robots are limited in their mechanical outputting capability, because the magnetic forces decrease significantly with decreasing robot size and increasing actuating distance. Hence, the output force of these robots can hardly meet the demand for specific biomedical applications (e.g., tissue penetration). This article proposes a tetherless magnetic impact needle robot (MINRob) based on a triple-magnet system with reversible and repeatable magnetic collisions to overcome this constraint on output force. The working procedure of the proposed system is divided into several states, and a mathematical model is developed to predict and optimize the force output. These force values in magnetic impact and penetration are obtained from a customized setup, indicating a ten-fold increase compared with existing miniature robots that only utilize magnetic attractive force. Eventually, the proposed MINRob is integrated with a teleoperation system, enabling remote and precise control of the robot&#39;s position and orientation. The triple-magnet system offers promising locomotion patterns and penetration capacity via the notably increased force output, showing great potential in robot-assisted tissue penetration in minimally invasive healthcare.},
  archive      = {J_TROB},
  author       = {Yuxuan Xiang and Ruomao Liu and Zihan Wei and Xinliang Wang and Weida Kang and Min Wang and Jun Liu and Xudong Liang and Jiachen Zhang},
  doi          = {10.1109/TRO.2024.3410096},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3127-3145},
  shortjournal = {IEEE Trans. Robot.},
  title        = {MINRob: A large force-outputting miniature robot based on a triple-magnet system},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust visual feedback control for precise in-hand
manipulation using parallel soft actuators. <em>TROB</em>, <em>40</em>,
3097–3108. (<a href="https://doi.org/10.1109/TRO.2024.3410130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robotic hands are reliable for grasping objects of various shapes. However, they perform poorly in the high-precision manipulation of grasped objects because the modeling and sensing of soft actuator deformation are complex. To overcome this problem, in a previous study, we proposed a robust visual feedback control method for precise in-hand manipulation using parallel soft actuators. This method enables precise in-hand manipulation without measuring the soft actuator deformations. Generally, in the feedback control of a parallel drive system, the actuator force is converted into the force/torque applied to the grasped object. The conversion matrix constantly changes depending on the position/orientation of the object and the contact points of the soft actuators with the object. Consequently, accurately measuring the conversion matrix is difficult. Therefore, we estimated it as a constant matrix in our previous studies, and its robustness was confirmed experimentally. However, its theoretical robustness was not analyzed sufficiently. Therefore, in this article, we discuss the robustness of the estimated constant matrix through a mathematical stability proof. Furthermore, we investigate the characteristics of the estimated drive matrix. Then, we perform a numerical robustness analysis. Finally, the robustness of the proposed method is studied via the above investigation and verification experiments.},
  archive      = {J_TROB},
  author       = {Yoshiki Mori and Mingzhu Zhu and Sadao Kawamura},
  doi          = {10.1109/TRO.2024.3410130},
  journal      = {IEEE Transactions on Robotics},
  month        = {6},
  pages        = {3097-3108},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robust visual feedback control for precise in-hand manipulation using parallel soft actuators},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward robust robot 3-d perception in urban environments:
The UT campus object dataset. <em>TROB</em>, <em>40</em>, 3322–3340. (<a
href="https://doi.org/10.1109/TRO.2024.3400831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the UT Campus Object Dataset (CODa), a mobile robot egocentric perception dataset collected on the University of Texas Austin Campus. Our dataset contains 8.5 h of multimodal sensor data from 3-D light detection and ranging (LiDAR), stereo RGB and rgb and depth (RGBD) cameras, and a 9-DoF inertial measurement unit (IMU). CODa contains 58 min of ground truth annotations containing 1.3 million 3-D bounding boxes with instance identifiers (ID) for 53 semantic classes, 5000 frames of 3-D semantic annotations for urban terrain, and pseudoground truth localization. We repeatedly traverse identical geographic regions for diverse indoor and outdoor areas, weather conditions, and times of the day. Using CODa, we empirically demonstrate that: 1) 3-D object detection performance improves in urban settings when trained using CODa compared with existing datasets, 2) sensor-specific fine-tuning increases 3-D object detection accuracy, and 3) pretraining on CODa improves cross-dataset 3-D object detection performance in urban settings compared with pretraining on AV datasets. We release benchmarks for 3-D object detection and 3-D semantic segmentation, with future plans for additional tasks. We publicly release CODa on the Texas Data Repository (Zhang et al., 2023), pretrained models, dataset development package, and interactive dataset viewer. We expect CODa to be a valuable dataset for egocentric perception and planning for navigation in urban environments.},
  archive      = {J_TROB},
  author       = {Arthur Zhang and Chaitanya Eranki and Christina Zhang and Ji-Hwan Park and Raymond Hong and Pranav Kalyani and Lochana Kalyanaraman and Arsh Gamare and Arnav Bagad and Maria Esteva and Joydeep Biswas},
  doi          = {10.1109/TRO.2024.3400831},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {3322-3340},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Toward robust robot 3-D perception in urban environments: The UT campus object dataset},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variable wheelbase control of wheeled mobile robots with
worm-inspired creeping gait strategy. <em>TROB</em>, <em>40</em>,
3271–3289. (<a href="https://doi.org/10.1109/TRO.2024.3400947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wheeled mobile robots (WMRs) with variable wheelbases are capable of traveling on deformable terrains and handling complex detection tasks. While the variable wheelbase length of WMR allows it to interact with the terrains adaptively, enhancing its mobility, it brings a control challenge. Inspired by the worm&#39;s movement of stretching body at different lengths under different environmental resistance, a creeping gait (CG) strategy is proposed in this work to enable the WMR to be controlled in dual modes: wheeled following mode (WFM) and specified length mode (SLM). WFM adjusts the wheelbase&#39;s length by the wheels&#39; movements freely to minimize the internal force and torque between wheels. SLM adjusts the wheelbase&#39;s length using a proposed fuzzy logic based algorithm to stabilize the body&#39;s posture on rough terrain and overcome specific motion challenges, such as escaping wheel sinking. A state-adaptive mode-switching controller is then developed using the dwell time approach to smooth the output velocities during the switching phase, and a Lyapunov analysis is performed to verify its stability. According to the results of physical experiments, three-wheeled mobile robot movements with CG enable more precise path following by 37% and faster response by 11% compared to fixed wheelbase movements, and the dwell time approach achieves smoother speed transitions between the modes than the direct switching method, especially when moving from flat to slope terrain.},
  archive      = {J_TROB},
  author       = {Huanan Qi and Liang Ding and Miao Zheng and Lan Huang and Haibo Gao and Guangjun Liu and Zongquan Deng},
  doi          = {10.1109/TRO.2024.3400947},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {3271-3289},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Variable wheelbase control of wheeled mobile robots with worm-inspired creeping gait strategy},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mitigating distributional shift in semantic segmentation via
uncertainty estimation from unlabeled data. <em>TROB</em>, <em>40</em>,
3146–3165. (<a href="https://doi.org/10.1109/TRO.2024.3401020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowing when a trained segmentation model is encountering data that is different to its training data is important. Understanding and mitigating the effects of this play an important part in their application from a performance and assurance perspective—this being a safety concern in applications such as autonomous vehicles. This article presents a segmentation network that can detect errors caused by challenging test domains without any additional annotation in a single forward pass. As annotation costs limit the diversity of labeled datasets, we use easy-to-obtain, uncurated and unlabeled data to learn to perform uncertainty estimation by selectively enforcing consistency over data augmentation. To this end, a novel segmentation benchmark based on the sense-assess-eXplain (SAX) is used, which includes labeled test data spanning three autonomous-driving domains, ranging in appearance from dense urban to off-road. The proposed method, named $\mathrm{\gamma }\text{-}\text{SSL}$ , consistently outperforms uncertainty estimation and out-of-distribution techniques on this difficult benchmark—by up to 10.7% in area under the receiver operating characteristic curve and 19.2% in area under the precision-recall curve in the most challenging of the three scenarios.},
  archive      = {J_TROB},
  author       = {David S. W. Williams and Daniele De Martini and Matthew Gadd and Paul Newman},
  doi          = {10.1109/TRO.2024.3401020},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {3146-3165},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Mitigating distributional shift in semantic segmentation via uncertainty estimation from unlabeled data},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A meniscus-like structure in anthropomorphic joints to
attenuate impacts. <em>TROB</em>, <em>40</em>, 3109–3126. (<a
href="https://doi.org/10.1109/TRO.2024.3408005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During robotic locomotion, shock forces from ground impact propagate through the leg and may cause fatigue or damage to joints and sensitive hardware. To attenuate impacts in diverse aspects and directions, multiple approaches, including active control strategies and passive compliant joints, are essential for providing a comprehensive solution. Here, inspired by human knees, a meniscus-like structure was developed for a compliant anthropomorphic joint to provide a complementary way of shock absorption, especially along the axial direction. The proposed meniscus-like structure comprises a pair of curved arms wrapped with preloaded elastic bands whose elongations produce restoring forces against the axial load. This structure simultaneously realized impact attenuation in three aspects: Decreasing contact stress by designing consistently conformal contact interfaces under axial movement; reducing peak impact forces by tuning load-displacement curves to obtain a high-static-low-dynamic nonlinear stiffness; and dissipating energy by hysteresis due to sliding frictions. The effectiveness in attenuating impacts on robotic legs was further verified by both analytical analyses and impact experiments that it outperforms regular elastic buffers at multiple leg configurations. Inserting meniscus-like structures into anthropomorphic joints efficiently utilized the joint space to attenuate axial impacts, complementing the system of interaction safety for the robot community.},
  archive      = {J_TROB},
  author       = {Lianxin Yang and Zhihua Zhao},
  doi          = {10.1109/TRO.2024.3408005},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {3109-3126},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A meniscus-like structure in anthropomorphic joints to attenuate impacts},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Safe set-based trajectory planning for robotic manipulators.
<em>TROB</em>, <em>40</em>, 3082–3096. (<a
href="https://doi.org/10.1109/TRO.2024.3400975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the line of seminal works on projected path dynamics and time-optimal control of robots, which originated in the 1980s, and recent advances on the computation of safe sets for complex systems in control, we present a new trajectory planning framework for $N$ -link robotic manipulators. Given a path, defined typically in the workspace, we recover the admissible velocity profiles and the realizable corresponding torque profiles that achieve a path traversal. To make this possible, we introduce a new torque feedback parameterization. This enables us to construct the set where the trajectory of the projected path can be confined while reaching a target set with a feasible control action, namely, the reach–avoid set. As a product of this procedure, we develop feedback controllers that guarantee state and input constraint satisfaction, can track reference trajectories, and can handle temporal specifications related, for example, to rendezvous and avoidance setups. Encouraging proof-of-concept experimental evaluation of the theory on a UR10 robotic manipulator suggests the framework can complement and further expand the existing classical approaches.},
  archive      = {J_TROB},
  author       = {Ryan McGovern and Nikolaos Athanasopoulos and Seán McLoone},
  doi          = {10.1109/TRO.2024.3400975},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {3082-3096},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Safe set-based trajectory planning for robotic manipulators},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic adaptive dynamic window approach. <em>TROB</em>,
<em>40</em>, 3068–3081. (<a
href="https://doi.org/10.1109/TRO.2024.3400932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust local navigation is a critical capability for any mobile robot operating in a real-world unstructured environment, especially when there are humans or other moving obstacles in the workspace. One of the most commonly used methods for local navigation is the dynamic window approach (DWA), which does not address the problem of dynamic obstacles and depends heavily on the settings of the parameters in its cost function. Thus, it is a static approach that does not adapt to the characteristics of the environment, which can change significantly. On the other hand, data-driven deep learning approaches attempt to adapt to the characteristics of the environment by predicting the appropriate robot motion based on the current observation. However, they cannot guarantee collision-free trajectories for unseen inputs. In this work, we combine the best of both worlds. We propose a neural network to predict the weights of the DWA, which is then used for safe local navigation. To address the problem of dynamic obstacles, the proposed method considers a short sequence of observations to allow the network to model the motion of the obstacles and adjust the DWA weights accordingly. The network is trained using proximal policy optimization in a reinforcement learning setting in a simulated dynamic environment. We perform a comprehensive evaluation of the proposed approach in realistic scenarios using range scans of real 3-D spaces and show that it outperforms both DWA and purely deep learning approaches.},
  archive      = {J_TROB},
  author       = {Matej Dobrevski and Danijel Skočaj},
  doi          = {10.1109/TRO.2024.3400932},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {3068-3081},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Dynamic adaptive dynamic window approach},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autonomous drone racing: A survey. <em>TROB</em>,
<em>40</em>, 3044–3067. (<a
href="https://doi.org/10.1109/TRO.2024.3400838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decade, the use of autonomous drone systems for surveying, search and rescue, or last-mile delivery has increased exponentially. With the rise of these applications comes the need for highly robust, safety-critical algorithms that can operate drones in complex and uncertain environments. In addition, flying fast enables drones to cover more ground, increasing productivity and further strengthening their use case. One proxy for developing algorithms used in high-speed navigation is the task of autonomous drone racing (ADR), where researchers program drones to fly through a sequence of gates and avoid obstacles as quickly as possible using onboard sensors and limited computational power. Speeds and accelerations exceed over 80 $\text{km}/\text{h}$ and 4 g, respectively, raising significant challenges across perception, planning, control, and state estimation. To achieve maximum performance, systems require real-time algorithms that are robust to motion blur, high dynamic range, model uncertainties, aerodynamic disturbances, and often unpredictable opponents. This survey covers the progression of ADR across model-based and learning-based approaches. In this article, we provide an overview of the field, its evolution over the years, and conclude with the biggest challenges and open questions to be faced in the future.},
  archive      = {J_TROB},
  author       = {Drew Hanover and Antonio Loquercio and Leonard Bauersfeld and Angel Romero and Robert Penicka and Yunlong Song and Giovanni Cioffi and Elia Kaufmann and Davide Scaramuzza},
  doi          = {10.1109/TRO.2024.3400838},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {3044-3067},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Autonomous drone racing: A survey},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel contact-aided continuum robotic system: Design,
modeling, and validation. <em>TROB</em>, <em>40</em>, 3024–3043. (<a
href="https://doi.org/10.1109/TRO.2024.3400944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tendon-driven continuum robots are of great promise in dexterous manipulation in long-narrow spaces, such as in-situ maintenance of aeroengines, due to their slender body and compliant hyper-redundant architecture. However, major challenges in implementing this come from mechanical design and morphology estimation: torsion and buckling issues induced by the intrinsic compliant architecture and the coupling of system gravity and distal loads; and low-accuracy morphology model influenced by complex load conditions. In this article, inspired by the contact-aided compliant mechanisms (CACMs), a novel continuum robotic system using the bearing-based CACM is developed to overcome the two intrinsic issues (i.e., torsion and buckling) while eliminating the implied wear due to friction at joint/socket interfaces without affecting its stiffness adversely. Subsequently, based on the chained beam constraint model, a comprehensive kinetostatic modeling framework is systematically derived, focusing on mechanism-oriented strategies (i.e., tendon routing friction, physical joint constraint, and section buckling estimation). Finally, various experiments are performed to verify the effectiveness of both our designed hardware and algorithm. It is demonstrated that the robotic system with such hardware and algorithm achieving the torsional stiffness outperforms the twin-pivot design at least 24 times, stiffness enhancement &gt; 100 times, morphology error &lt; 2.5% of the manipulator length, and avoiding the first-order instability. Additionally, we demonstrate the navigation experiment by using two developed control strategies to show the performances of the robotic system.},
  archive      = {J_TROB},
  author       = {Zheshuai Yang and Laihao Yang and Yu Sun and Xuefeng Chen},
  doi          = {10.1109/TRO.2024.3400944},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {3024-3043},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A novel contact-aided continuum robotic system: Design, modeling, and validation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MS-VRO: A multistage visual-millimeter wave radar fusion
odometry. <em>TROB</em>, <em>40</em>, 3004–3023. (<a
href="https://doi.org/10.1109/TRO.2024.3400941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular visual odometry (VO) has extensive applications in mobile robots and computer vision. However, current applications of monocular VO systems in complex environments still have limitations. Accurate, robust, and easy-to-use VO is still an unsolved problem to some extent. In recent years, the single-chip millimeter-wave (mmWave) radar has been increasingly used in various types of mobile robots due to its advantages of small size, low cost, and robustness in harsh weather conditions. In this article, we apply the mmWave radar to a VO system and propose a multistage visual-radar fusion odometry framework, MS-VRO. The framework is based on a typical monocular VO system. By merging mmWave radar data in different stages, the proposed odometry improves the accuracy, robustness, and generalization ability of VO. The framework contains a new visual-radar initialization method, a visual-radar joint optimization method, and a radar-aided visual feature selection and processing method that can remove dynamic object features and bad map points. Through these, the proposed method solves the problems of monocular VO, including scale ambiguity, scale drift, and performance degradation in dynamic environments. We build a dataset that can be used for research on visual-radar fusion odometry and test the proposed method on the new dataset and other public datasets. The result shows that the proposed odometry achieves significantly better performance than VO methods and is more accurate and robust compared to some typical visual-inertial odometry methods.},
  archive      = {J_TROB},
  author       = {Yuwei Cheng and Mengxin Jiang and Yimin Liu},
  doi          = {10.1109/TRO.2024.3400941},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {3004-3023},
  shortjournal = {IEEE Trans. Robot.},
  title        = {MS-VRO: A multistage visual-millimeter wave radar fusion odometry},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Not only rewards but also constraints: Applications on
legged robot locomotion. <em>TROB</em>, <em>40</em>, 2984–3003. (<a
href="https://doi.org/10.1109/TRO.2024.3400935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several earlier studies have shown impressive control performance in complex robotic systems by designing the controller using a neural network and training it with model-free reinforcement learning. However, these outstanding controllers with natural motion style and high task performance are developed through extensive reward engineering, which is a highly laborious and time-consuming process of designing numerous reward terms and determining suitable reward coefficients. In this article, we propose a novel reinforcement learning framework for training neural network controllers for complex robotic systems consisting of both rewards and constraints . To let the engineers appropriately reflect their intent to constraints and handle them with minimal computation overhead, two constraint types and an efficient policy optimization algorithm are suggested. The learning framework is applied to train locomotion controllers for several legged robots with different morphology and physical attributes to traverse challenging terrains. Extensive simulation and real-world experiments demonstrate that performant controllers can be trained with significantly less reward engineering, by tuning only a single reward coefficient. Furthermore, a more straightforward and intuitive engineering process can be utilized, thanks to the interpretability and generalizability of constraints.},
  archive      = {J_TROB},
  author       = {Yunho Kim and Hyunsik Oh and Jeonghyun Lee and Jinhyeok Choi and Gwanghyeon Ji and Moonkyu Jung and Donghoon Youm and Jemin Hwangbo},
  doi          = {10.1109/TRO.2024.3400935},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {2984-3003},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Not only rewards but also constraints: Applications on legged robot locomotion},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Keypoint-guided efficient pose estimation and domain
adaptation for micro aerial vehicles. <em>TROB</em>, <em>40</em>,
2967–2983. (<a href="https://doi.org/10.1109/TRO.2024.3400938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual detection of micro aerial vehicles (MAVs) is an important problem in many tasks such as vision-based swarming of MAVs. This article studies vision-based 6-D pose estimation to detect a 3-D bounding box of a target MAV, and then, estimate its 3-D position and 3-D attitude. The 3-D attitude information is critical to better estimate the target&#39;s velocity since the attitude and motion are dynamically coupled. In this article, we propose a novel 6-D pose estimation method, whose novelties are threefold. First, we propose a novel centroid point-guided keypoint localization network that outperforms the state-of-the-art methods in terms of both accuracy and efficiency. Second, while there are no publicly available real-world datasets for 6-D pose estimation for MAVs up to now, we propose a high-quality dataset based on an automatic dataset collection method. Third, since the dataset is collected in an indoor environment but detection tasks are usually in outdoor environments, we propose a self-training-based unsupervised domain adaption method to transfer the method from indoor to outdoor. Finally, we show that the estimated 6-D pose especially the 3-D attitude can significantly help improve the target&#39;s velocity estimation.},
  archive      = {J_TROB},
  author       = {Ye Zheng and Canlun Zheng and Jiahao Shen and Peidong Liu and Shiyu Zhao},
  doi          = {10.1109/TRO.2024.3400938},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {2967-2983},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Keypoint-guided efficient pose estimation and domain adaptation for micro aerial vehicles},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Smooth distances for second-order kinematic robot control.
<em>TROB</em>, <em>40</em>, 2950–2966. (<a
href="https://doi.org/10.1109/TRO.2024.3400924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose an algorithm for computing a smoothed version of the distance between two objects. As opposed to the traditional Euclidean distance between two objects, which may not be differentiable, this smoothed distance is guaranteed to be differentiable. Differentiability is an important property in many applications, in particular in robotics, in which obstacle-avoidance schemes often rely on the derivative/Jacobian of the distance between two objects. We prove mathematical properties of this smoothed distance and of the algorithm for computing it, and show its applicability in robotics by applying it to a second-order kinematic control framework, also proposed in this article. The control framework using smooth distances was successfully implemented on a 7 DOF manipulator.},
  archive      = {J_TROB},
  author       = {Vinicius Mariano Gonçalves and Anthony Tzes and Farshad Khorrami and Philippe Fraisse},
  doi          = {10.1109/TRO.2024.3400924},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {2950-2966},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Smooth distances for second-order kinematic robot control},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interactive autonomous navigation with internal state
inference and interactivity estimation. <em>TROB</em>, <em>40</em>,
2932–2949. (<a href="https://doi.org/10.1109/TRO.2024.3400937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) provides a promising way for intelligent agents (e.g., autonomous vehicles) to learn to navigate complex scenarios. However, DRL with neural networks as function approximators is typically considered a black box with little explainability and often suffers from suboptimal performance, especially for autonomous navigation in highly interactive multiagent environments. To address these issues, we propose three auxiliary tasks with spatio-temporal relational reasoning and integrate them into the standard DRL framework, which improves the decision making performance and provides explainable intermediate indicators. We propose to explicitly infer the internal states (i.e., traits and intentions) of surrounding agents (e.g., human drivers) as well as to predict their future trajectories in the situations with and without the ego agent through counterfactual reasoning. These auxiliary tasks provide additional supervision signals to infer the behavior patterns of other interactive agents. Multiple variants of framework integration strategies are compared. We also employ a spatio-temporal graph neural network to encode relations between dynamic entities, which enhances both internal state inference and decision making of the ego agent. Moreover, we propose an interactivity estimation mechanism based on the difference between predicted trajectories in these two situations, which indicates the degree of influence of the ego agent on other agents. To validate the proposed method, we design an intersection driving simulator based on the Intelligent Intersection Driver Model that simulates vehicles and pedestrians. Our approach achieves robust and state-of-the-art performance in terms of standard evaluation metrics and provides explainable intermediate indicators (i.e., internal states, and interactivity scores) for decision making.},
  archive      = {J_TROB},
  author       = {Jiachen Li and David Isele and Kanghoon Lee and Jinkyoo Park and Kikuo Fujimura and Mykel J. Kochenderfer},
  doi          = {10.1109/TRO.2024.3400937},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {2932-2949},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Interactive autonomous navigation with internal state inference and interactivity estimation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantifying the risk of unmapped associations for mobile
robot localization safety. <em>TROB</em>, <em>40</em>, 2920–2931. (<a
href="https://doi.org/10.1109/TRO.2024.3401093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrity risk is a measure of localization safety that accounts for the presence of undetected sensor faults. The metric has been used for decades in aviation and has recently been applied to terrestrial robots operating on life-critical missions. For ground vehicles, integrity risk can be quantified for systems using lidar measurements, where two specific fault types have been identified: miss-association and unmapped association. While miss-association faults, which occur when a correctly extracted feature is associated with the wrong landmark, have been well studied, the probability of an unmapped association fault, where an incorrectly extracted feature is associated with a landmark, is not well understood. Namely, previous research has never quantified this value and instead relies on an assumed value, one whose value has not been properly justified. This work is the first to provide a methodology that estimates the risk of unmapped association for each mapped landmark; the article demonstrates the effect of this probability for both the chi-squared and fixed-lag smoothing methods for integrity monitoring. Data collected in downtown Chicago, IL, USA, were used to test the impact of unmapped association faults on localization safety. The results indicate that using the previously assumed value is reasonable in many situations, but that applications with strict safety requirements should incorporate the method described here to properly account for unmapped association faults.},
  archive      = {J_TROB},
  author       = {Yihe Chen and Boris Pervan and Matthew Spenko},
  doi          = {10.1109/TRO.2024.3401093},
  journal      = {IEEE Transactions on Robotics},
  month        = {5},
  pages        = {2920-2931},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Quantifying the risk of unmapped associations for mobile robot localization safety},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft printable robots with flexible metal endoskeleton.
<em>TROB</em>, <em>40</em>, 2907–2919. (<a
href="https://doi.org/10.1109/TRO.2024.3392162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in soft robotics have seen the rapid development of soft grippers for industrial pick-and-place applications. They are, however, ill-suited to bear heavy loads due to their compliant nature. Paradoxically, researchers have sought to increase the stiffness of soft grippers to improve load-bearing capabilities. Unfortunately, contemporary soft actuators with variable stiffness are fabricated using manual processes and their performance is subject to an individual&#39;s mastery. They are therefore not reliable for long-term industrial use. In this article, we present our work on a 3-D-printed metal-endoskeleton-reinforced actuator (MERA) for industrial pick-and-place applications. We also highlight the fabrication processes needed to recreate it repetitively. Using stainless steel splints (SSS), we demonstrate that MERA is able to modulate its stiffness at selective junctures for stable and effective grasping. We also describe our design rationale with a qualitative mathematical model and validate its performance quantitatively using a finite element model, which is further investigated in the following fatigue test. In our experiments, the MERA equipped with SSS is able to output a peak tip force of 8 N, which is a 291% increase compared to the one without metallic reinforcement. In addition, an increase of 76.5% in gripping load and a maximum holding force per actuator of 13.8 N are realized through the stiffness tuning of a MERA-Gripper. Despite significantly improving load-bearing capabilities, the actuator manages to retain an overall low profile with a weight of 82 g. Finally, we adapted the MERA into a reconfigurable gripper and tested its grasping capabilities on objects of various shapes, sizes, and weights.},
  archive      = {J_TROB},
  author       = {Chao-Yu Chen and Benjamin Wee Keong Ang and Yangfan Li and Jun Liu and Zhuangjian Liu and Chen-Hua Yeow},
  doi          = {10.1109/TRO.2024.3392162},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2907-2919},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Soft printable robots with flexible metal endoskeleton},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autonomous vehicle localization without prior
high-definition map. <em>TROB</em>, <em>40</em>, 2888–2906. (<a
href="https://doi.org/10.1109/TRO.2024.3392149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate localization by which vehicles can arrive at their destination while accurately following a given route is one of the most important factors for autonomous driving. In recent years, numerous studies have been conducted to achieve accurate localization using high-definition (HD) maps. Based on the HD map information (e.g., spatial data, lane, and traffic sign), autonomous vehicles can localize themselves by matching the surrounding spatial information obtained from onboard sensors to the HD maps. However, generating HD maps is a time-consuming and costly task. This study introduces a time-saving, effective, and accurate localization method inspired by humans, using only onboard sensors and publicly available 2-D map information. Similar to the multilevel localization process performed by humans, the proposed method interprets and matches the surrounding spatial data to the publicly available 2-D maps using deep-learning-based place recognition and simultaneous localization and mapping, thereby enabling autonomous vehicles to localize even without prior HD maps. Through the proposed method, our framework enables autonomous vehicles to perform maximally decimeter-level accurate localization without using HD maps. Evaluation of the proposed method using various datasets and publicly available map sources demonstrates that accurate global localization can be achieved without prior HD maps.},
  archive      = {J_TROB},
  author       = {Sangmin Lee and Jee-Hwan Ryu},
  doi          = {10.1109/TRO.2024.3392149},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2888-2906},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Autonomous vehicle localization without prior high-definition map},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PRIMP: PRobabilistically-informed motion primitives for
efficient affordance learning from demonstration. <em>TROB</em>,
<em>40</em>, 2868–2887. (<a
href="https://doi.org/10.1109/TRO.2024.3390052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a Learning-from-Demonstration (LfD) method using probability densities on the workspaces of robot manipulators. The method, named PRobabilistically-Informed Motion Primitives (PRIMP), learns the probability distribution of the end effector trajectories in the 6-D workspace that includes both positions and orientations. It is able to adapt to new situations such as novel via points with uncertainty and a change of viewing frame. The method itself is robot-agnostic, in that the learned distribution can be transferred to another robot with the adaptation to its workspace density. Workspace-STOMP, a new version of the existing STOMP motion planner, is also introduced, which can be used as a postprocess to improve the performance of PRIMP and any other reachability-based LfD method. The combination of PRIMP and Workspace-STOMP can further help the robot avoid novel obstacles that are not present during the demonstration process. The proposed methods are evaluated with several sets of benchmark experiments. PRIMP runs more than five times faster than existing state-of-the-art methods while generalizing trajectories more than twice as close to both the demonstrations and novel desired poses. They are then combined with our lab&#39;s robot imagination method that learns object affordances, illustrating the applicability to learn tool use through physical experiments.},
  archive      = {J_TROB},
  author       = {Sipu Ruan and Weixiao Liu and Xiaoli Wang and Xin Meng and Gregory S. Chirikjian},
  doi          = {10.1109/TRO.2024.3390052},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2868-2887},
  shortjournal = {IEEE Trans. Robot.},
  title        = {PRIMP: PRobabilistically-informed motion primitives for efficient affordance learning from demonstration},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complete and near-optimal robotic crack coverage and filling
in civil infrastructure. <em>TROB</em>, <em>40</em>, 2850–2867. (<a
href="https://doi.org/10.1109/TRO.2024.3392077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a simultaneous sensor-based inspection and footprint coverage (SIFC) planning and control design with applications to autonomous robotic crack mapping and filling. The main challenge of the SIFC problem lies in the coupling of complete sensing (for mapping) and robotic footprint (for filling) coverage tasks. Initially, we assume known target information (e.g., cracks) and employ classic cell decomposition methods to achieve complete sensing coverage of the workspace and complete robotic footprint coverage using the least-cost route. Subsequently, we generalize the algorithm to handle unknown target information, allowing the robot to scan and incrementally construct the target map online while conducting robotic footprint coverage. The online polynomial-time SIFC planning algorithm minimizes the total robot traveling distance, guarantees complete sensing coverage of the entire workspace, and achieves near-optimal robotic footprint coverage, as demonstrated through experiments. For the demonstrated application, we design coordinated nozzle motion control with the planned robot trajectory to efficiently fill all cracks within the robot&#39;s footprint. Experimental results illustrate the algorithm&#39;s design, performance, and comparisons. The SIFC algorithm offers a high-efficiency motion planning solution for various robotic applications requiring simultaneous sensing and actuation coverage.},
  archive      = {J_TROB},
  author       = {Vishnu Veeraraghavan and Kyle Hunte and Jingang Yi and Kaiyan Yu},
  doi          = {10.1109/TRO.2024.3392077},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2850-2867},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Complete and near-optimal robotic crack coverage and filling in civil infrastructure},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tube acceleration: Robust dexterous throwing against release
uncertainty. <em>TROB</em>, <em>40</em>, 2831–2849. (<a
href="https://doi.org/10.1109/TRO.2024.3386391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotic throwing, the release phase involves complex dynamic interactions due to object deformation and limited gripper opening speed, often resulting in inaccurate and nonrepeatable throws. While data-driven methods can be employed to compensate for the release uncertainty, the generalizability of learned models to unseen objects is not guaranteed, and object-specific fine-tuning with new data may be required. This fine-tuning process raises concerns about the scalability of such methods for dexterous throwing, where the robot needs to execute diverse motions for throwing various objects. Instead of case-by-case fine-tuning, we aim at designing throwing motion robust against release uncertainty. We encapsulate all uncertainties resulting from complex contact dynamics in a surrogate model of their resulting effect on gripper opening delay . We introduce the notion of tube acceleration to model the class of constant-acceleration motion in joint space that guarantees a release within the set of valid throwing configurations. We propose a convex relaxation of the primal optimization problem with a tight error bound and evaluate its performance in terms of reliability and efficiency. Results show that the approach offers run-time performance to allow online computation of throws on a 7-DoF robot arm. It achieves a high accuracy and success rate (97% for planar throws) at throwing a variety of complex objects, even when using a simple ballistic model for the object&#39;s flying dynamics.},
  archive      = {J_TROB},
  author       = {Yang Liu and Aude Billard},
  doi          = {10.1109/TRO.2024.3386391},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2831-2849},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Tube acceleration: Robust dexterous throwing against release uncertainty},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cosserat-rod-based dynamic modeling of soft slender robot
interacting with environment. <em>TROB</em>, <em>40</em>, 2811–2830. (<a
href="https://doi.org/10.1109/TRO.2024.3386393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft slender robots have attracted more and more research attentions in these years due to their continuity and compliance natures. However, mechanics modeling for soft robots interacting with environment is still an academic challenge because of the nonlinearity of deformation and the nonsmooth property of the contacts. In this work, starting from a piece-wise local strain field assumption, we propose a nonlinear dynamic model for soft robot via Cosserat rod theory using Newtonian mechanics, which handles the frictional contact with environment and transfer them into the nonlinear complementary constraint (NCP) formulation. Moreover, we smooth both the contact and friction constraints in order to convert the inequality equations of NCP to the smooth equality equations. The proposed model allows us to compute the dynamic deformation and frictional contact force under common optimization framework in real time when the soft slender robot interacts with other rigid or soft bodies. In the end, the corresponding experiments are carried out which valid our proposed dynamic model.},
  archive      = {J_TROB},
  author       = {Lingxiao Xun and Gang Zheng and Alexandre Kruszewski},
  doi          = {10.1109/TRO.2024.3386393},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2811-2830},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Cosserat-rod-based dynamic modeling of soft slender robot interacting with environment},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online multicontact receding horizon planning via value
function approximation. <em>TROB</em>, <em>40</em>, 2791–2810. (<a
href="https://doi.org/10.1109/TRO.2024.3392154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning multicontact motions in a receding horizon fashion requires a value function to guide the planning with respect to the future, e.g., building momentum to traverse large obstacles. Traditionally, the value function is approximated by computing trajectories in a prediction horizon (never executed) that foresees the future beyond the execution horizon. However, given the nonconvex dynamics of multicontact motions, this approach is computationally expensive. To enable online receding horizon planning (RHP) of multicontact motions, we find efficient approximations of the value function. Specifically, we propose a trajectory-based and a learning-based approach. In the former, namely RHP with multiple levels of model fidelity, we approximate the value function by computing the prediction horizon with a convex relaxed model. In the latter, namely locally guided RHP, we learn an oracle to predict local objectives for locomotion tasks, and we use these local objectives to construct local value functions for guiding a short-horizon RHP. We evaluate both approaches in simulation by planning centroidal trajectories of a humanoid robot walking on moderate slopes, and on large slopes where the robot cannot maintain static balance. Our results show that locally guided RHP achieves the best computation efficiency (95%–98.6% cycles converge online). This computation advantage enables us to demonstrate online RHP of our real-world humanoid robot Talos walking in dynamic environments that change on-the-fly.},
  archive      = {J_TROB},
  author       = {Jiayi Wang and Sanghyun Kim and Teguh Santoso Lembono and Wenqian Du and Jaehyun Shim and Saeid Samadi and Ke Wang and Vladimir Ivan and Sylvain Calinon and Sethu Vijayakumar and Steve Tonneau},
  doi          = {10.1109/TRO.2024.3392154},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2791-2810},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Online multicontact receding horizon planning via value function approximation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neurosymbolic motion and task planning for linear temporal
logic tasks. <em>TROB</em>, <em>40</em>, 2749–2768. (<a
href="https://doi.org/10.1109/TRO.2024.3392079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a neurosymbolic framework to solve motion planning problems for mobile robots involving temporal goals. The temporal goals are described using temporal logic formulas, such as bounded linear temporal logic (LTL) and co-safe LTL to capture complex tasks. The proposed framework trains neural network (NN)-based planners that enjoy strong correctness guarantees when applying to unseen tasks, i.e., the exact task (including workspace, temporal logic formula, and errors in the dynamical models of the robot) is not available during the training of NNs. Our approach to achieving theoretical guarantees and computational efficiency is based on two insights. First, we incorporate a symbolic model into the training of NNs such that the resulting NN-based planner inherits the interpretability and correctness guarantees of the symbolic model. Moreover, the symbolic model serves as a discrete “memory,” which is necessary for satisfying temporal logic formulas. Second, we train a library of NNs offline and combine a subset of the trained NNs into a single NN-based planner at runtime when a task is revealed. In particular, we develop a novel constrained NN training procedure, named formal NN training, to enforce that each NN in the library represents a “symbol” in the symbolic model. As a result, our neurosymbolic framework enjoys the scalability and flexibility benefits of machine learning and inherits the provable guarantees from control-theoretic and formal-methods techniques. We demonstrate the effectiveness of our framework in both simulations and on an actual robotic vehicle and show that our framework can generalize to unseen tasks where state-of-the-art meta-reinforcement learning techniques fail.},
  archive      = {J_TROB},
  author       = {Xiaowu Sun and Yasser Shoukry},
  doi          = {10.1109/TRO.2024.3392079},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2749-2768},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Neurosymbolic motion and task planning for linear temporal logic tasks},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous targets trapping with swarm robots by using
adaptive density-based interaction. <em>TROB</em>, <em>40</em>,
2729–2748. (<a href="https://doi.org/10.1109/TRO.2024.3392078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Homogeneous swarm robots are of significant research interest due to their robustness, flexibility, and scalability in completing complex tasks across various applications. This article focuses on trapping heterogeneous targets using swarm robots, with emphasis on their different strengths. These targets consist of weak, strong, and group-moving individuals, where stronger targets exhibit larger body size, higher physical strength, and stronger resistance ability. Our goal is to develop an adaptive controller that enables swarm robots to self-organize and distribute themselves to trap targets, while adjusting encirclement thickness and robot group size based on target strength. We leverage local implicit information generated from density-based interaction to improve interrobot and robot–target interactions through adaptive allocation and transformation mechanisms. The feasibility of our approach is validated through numerical simulations and experiments involving up to 50 physical robots and one human-controlled transformer.},
  archive      = {J_TROB},
  author       = {Shuai Zhang and Xiaokang Lei and Xingguang Peng and Jia Pan},
  doi          = {10.1109/TRO.2024.3392078},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2729-2748},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Heterogeneous targets trapping with swarm robots by using adaptive density-based interaction},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CATNIPS: Collision avoidance through neural implicit
probabilistic scenes. <em>TROB</em>, <em>40</em>, 2712–2728. (<a
href="https://doi.org/10.1109/TRO.2024.3386394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a transformation of a neural radiance field (NeRF) to an equivalent Poisson point process (PPP). This PPP transformation allows for rigorous quantification of uncertainty in NeRFs, in particular, for computing collision probabilities for a robot navigating through a NeRF environment. The PPP is a generalization of a probabilistic occupancy grid to the continuous volume and is fundamental to the volumetric ray-tracing model underlying radiance fields. Building upon this PPP representation, we present a chance-constrained trajectory optimization method for safe robot navigation in NeRFs. Our method relies on a voxel representation called the probabilistic unsafe robot region that spatially fuses the chance constraint with the NeRF model to facilitate fast trajectory optimization. We then combine a graph-based search with a spline-based trajectory optimization to yield robot trajectories through the NeRF that are guaranteed to satisfy a user-specific collision probability. We validate our chance constrained planning method through simulations and hardware experiments, showing superior performance compared to prior works on trajectory planning in NeRF environments.},
  archive      = {J_TROB},
  author       = {Timothy Chen and Preston Culbertson and Mac Schwager},
  doi          = {10.1109/TRO.2024.3386394},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2712-2728},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CATNIPS: Collision avoidance through neural implicit probabilistic scenes},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Enhancing the performance of a biomimetic robotic
elbow-and-forearm system through bionics-inspired optimization.
<em>TROB</em>, <em>40</em>, 2692–2711. (<a
href="https://doi.org/10.1109/TRO.2024.3386615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article delineates the formulation and verification of an innovative robotic elbow-and-forearm system design, mirroring the intricate biomechanics of human musculoskeletal systems. Conventional robotic models often undervalue the substantial function of soft tissues, which provides a compromise between compactness, safety, stability, and range of motion. In contrast, this study proposes a holistic replication of biological joints, encompassing bones, cartilage, ligaments, and tendons, culminating in a biomimetic robot. The research underscores a compact and stable structure of the human elbow and forearm, attributable to a tri-bone framework and diverse soft tissues. The methodology involves exhaustive examinations of human anatomy, succeeded by a theoretical exploration of the contribution of soft tissues to the stability of a prototype robotic elbow-and-forearm system. Evaluation results unveil remarkable parallels in the range of motion between the robotic joints and their human counterparts. The robotic elbow emulates 98.8% of the biological elbow&#39;s range of motion, with high torque capacities of 11.25 N $\cdot$ m (extension) and 24 N $\cdot$ m (flexion). Similarly, the robotic forearm achieves 58.6% of the human forearm&#39;s rotational range, generating substantial output torques of 14 N $\cdot$ m (pronation) and 7.8 N $\cdot$ m (supination). Moreover, the prototype exhibits significant load-bearing abilities, resisting a 5 kg dumbbell load without substantial displacement. It demonstrates a payload capacity exceeding 4 kg and rapid action capabilities, such as lifting a 2 kg dumbbell at a speed of 0.74 Hz and striking a ping-pong ball at an end-effector speed of 3.2 m/s. This research underscores that a detailed biomechanics study can address existing robotic design obstacles, optimize performance and anthropomorphic resemblance, and reaffirm traditional anatomical principles.},
  archive      = {J_TROB},
  author       = {Haosen Yang and Guowu Wei and Lei Ren},
  doi          = {10.1109/TRO.2024.3386615},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2692-2711},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Enhancing the performance of a biomimetic robotic elbow-and-forearm system through bionics-inspired optimization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Development and characteristics of a highly biomimetic
robotic shoulder inspired by musculoskeletal mechanical intelligence.
<em>TROB</em>, <em>40</em>, 2672–2691. (<a
href="https://doi.org/10.1109/TRO.2024.3390057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides a comprehensive analysis of the existing landscape of conventional and highly biomimetic robotic arms, highlighting a prevalent tradeoff between size, range of motion, and load capacity in current highly biomimetic designs. To overcome the limitations, this article undertakes an in-depth exploration of the human shoulder, focusing on the identification of mechanical intelligence within the biological glenohumeral joint, such as the incomplete ball-and-socket structure, coupling stability of humeroradial and glenohumeral joints, and the self-locking mechanism of the glenohumeral joint. These intelligent features can potentially enhance both the stability and mobility of robotic joints, all the while preserving their compactness. To validate these potential benefits, this article introduces a novel, highly biomimetic robotic glenohumeral joint that meticulously replicates human musculoskeletal structures, from bones and ligaments to cartilage, muscles, and tendons. This novel design incorporates the mechanical intelligence found in the biological joint. Through rigorous simulations and empirical studies, this article demonstrates that the aforementioned mechanical intelligences significantly enhance the flexibility and load capacity of the robot&#39;s glenohumeral joint. Furthermore, extensive manipulation experiments confirm the robustness and viability of the proposed highly biomimetic robotic arm. Remarkably, the presented robotic arm executed 46.25% glenohumeral flexion/extension, 105.43% adduction/abduction, and 99.23% rotation, and can sustain a payload of 4 kg, and open the door which requires a torque of over 1.5 Nm to twist the handle. Hence, this article not only validates the intrinsic mechanical intelligence identified in the deconstruction of the human shoulder joint, but also contributes a pioneering design of a new, highly biomimetic robotic arm, significantly pushing boundaries of current robotic technology.},
  archive      = {J_TROB},
  author       = {Haosen Yang and Guowu Wei and Lei Ren},
  doi          = {10.1109/TRO.2024.3390057},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2672-2691},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Development and characteristics of a highly biomimetic robotic shoulder inspired by musculoskeletal mechanical intelligence},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the generality and application of mason’s voting theorem
to center of mass estimation for pure translational motion.
<em>TROB</em>, <em>40</em>, 2656–2671. (<a
href="https://doi.org/10.1109/TRO.2024.3392080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object rearrangement is widely demanded in many of the manipulation tasks performed by industrial and service robots. Rearranging an object through planar pushing is deemed energy efficient and safer compared with the pick-and-place operation. However, due to the unknown physical properties of the object, rearranging an object toward the target position is difficult to accomplish. Even though robots can benefit from multimodal sensory data for estimating novel object dynamics, the exact estimation error bound is still unknown. In this work, first, we demonstrate a way to obtain an error bound on the center of mass (CoM) estimation for the novel object only using a position-controlled robot arm and a vision sensor. Specifically, we extend Mason&#39;s Voting Theorem to object CoM estimation in the absence of accurate information on friction and object shape. The probable CoM locations are monotonously narrowed down to a convex region, and the extended voting theorems&#39; guarantee that the convex region contains the CoM ground truth in the presence of contact normal estimation error and pushing execution error. For the object translation task, existing methods generally assume that the pusher-object system&#39;s physical properties and full-state feedback are available, or utilize iterative pushing executions, which limits the application of planar pushing to real-world settings. In this work, assuming a nominal friction coefficient between the pusher and object through contact normal error bound analysis, we leverage the estimated convex region and the Zero Moment Two Edge Pushing method (Gao et al., 2023) to select the contact configurations for object pure translation. It is ensured that the selected contact configurations are capable of tolerating the CoM estimation error. The experimental results show that the object can be accurately translated to the target position with only two controlled pushes at most.},
  archive      = {J_TROB},
  author       = {Ziyan Gao and Armagan Elibol and Nak Young Chong},
  doi          = {10.1109/TRO.2024.3392080},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2656-2671},
  shortjournal = {IEEE Trans. Robot.},
  title        = {On the generality and application of mason&#39;s voting theorem to center of mass estimation for pure translational motion},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PH-gauss-lobatto reduced-order-model for shape control of
soft-continuum manipulators. <em>TROB</em>, <em>40</em>, 2641–2655. (<a
href="https://doi.org/10.1109/TRO.2024.3391650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft and hyperelastic materials possess properties of resilience and flexibility, characterizing a class of soft-continuum manipulators (SCMs). The latter describes a robot structure with an infinite number of degrees of freedom (DoF), useful for mobility and manipulation. However, these geometric characteristics are a source of modeling and control problems. In this article, a Pythagorean hodograph (PH) curve-based reduced order model (ROM) relying on the Gauss-Lobatto quadrature is investigated for the modeling and the control of SCM. This allows, first, reducing the dimension of the SCM kinematics based on the PH parametric curves with a predefined length, and second, developing the shape kinematics control from its control polygon. The use of the Gauss-Lobatto quadrature allows to move independently the PH curve control points, while preserving PH features of length and minimum curve energy. These features are important to control in real-time the shape of the SCM. The proposed approach has been validated numerically and experimentally, carried out on a bioinspired soft continuum elephant trunk robot.},
  archive      = {J_TROB},
  author       = {Steeve Mbakop and Gilles Tagne and Tanguy Chevillon and Sergey V. Drakunov and Rochdi Merzouki},
  doi          = {10.1109/TRO.2024.3391650},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2641-2655},
  shortjournal = {IEEE Trans. Robot.},
  title        = {PH-gauss-lobatto reduced-order-model for shape control of soft-continuum manipulators},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast and accurate deep loop closing and relocalization for
reliable LiDAR SLAM. <em>TROB</em>, <em>40</em>, 2620–2640. (<a
href="https://doi.org/10.1109/TRO.2024.3386363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loop closing and relocalization are crucial techniques to establish reliable and robust long-term SLAM by addressing pose estimation drift and degeneration. This article begins by formulating loop closing and relocalization within a unified framework. Then, we propose a novel multihead network, LCR-Net, to tackle both tasks effectively. It exploits novel feature extraction and a pose-aware attention mechanism to precisely estimate similarities and 6-DoF poses between pairs of LiDAR scans. In the end, we integrate our LCR-Net into a SLAM system and achieve robust and accurate online LiDAR SLAM in outdoor driving environments. We thoroughly evaluate our LCR-Net through three setups derived from loop closing and relocalization, including candidate retrieval, closed-loop point cloud registration, and continuous relocalization using multiple datasets. The results demonstrate that LCR-Net excels in all three tasks, surpassing the state-of-the-art methods and exhibiting a remarkable generalization ability. Notably, our LCR-Net outperforms baseline methods without using a time-consuming robust pose estimator, rendering it suitable for online SLAM applications. To the best of the authors&#39; knowledge, the integration of LCR-Net yields the first LiDAR SLAM with the capability of deep loop closing and relocalization.},
  archive      = {J_TROB},
  author       = {Chenghao Shi and Xieyuanli Chen and Junhao Xiao and Bin Dai and Huimin Lu},
  doi          = {10.1109/TRO.2024.3386363},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2620-2640},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Fast and accurate deep loop closing and relocalization for reliable LiDAR SLAM},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Provably feasible semi-infinite program under collision
constraints via subdivision. <em>TROB</em>, <em>40</em>, 2602–2619. (<a
href="https://doi.org/10.1109/TRO.2024.3391649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a semi-infinite program (SIP) solver for trajectory optimizations of general articulated robots. These problems are more challenging than standard nonlinear program by involving an infinite number of nonconvex, collision constraints. Prior SIP solvers based on constraint sampling cannot guarantee the satisfaction of all constraints. Instead, our method uses a conservative bound on articulated body motions to ensure the solution feasibility throughout the optimization procedure. We further use subdivision to adaptively reduce the error in conservative motion estimation. Combined, we prove that our SIP solver guarantees feasibility while approaching the optimal solution of SIP problems up to arbitrary user-provided precision. We demonstrate our method toward several trajectory optimization problems in simulation, including industrial robot arms and UAVs. The results demonstrate that our approach generates collision-free locally optimal trajectories within a couple of minutes.},
  archive      = {J_TROB},
  author       = {Duo Zhang and Chen Liang and Xifeng Gao and Kui Wu and Zherong Pan},
  doi          = {10.1109/TRO.2024.3391649},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2602-2619},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Provably feasible semi-infinite program under collision constraints via subdivision},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond inverted pendulums: Task-optimal simple models of
legged locomotion. <em>TROB</em>, <em>40</em>, 2582–2601. (<a
href="https://doi.org/10.1109/TRO.2024.3386390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reduced-order models (ROMs) are popular in online motion planning due to their simplicity. A good ROM for control captures critical task-relevant aspects of the full dynamics while remaining low dimensional. However, planning within the reduced-order space unavoidably constrains the full model, and hence we sacrifice the full potential of the robot. In the community of legged locomotion, this has lead to a search for better model extensions, but many of these extensions require human intuition, and there has not existed a principled way of evaluating the model performance and discovering new models. In this work, we propose a model optimization algorithm that automatically synthesizes ROMs, optimal with respect to a user-specified distribution of tasks and corresponding cost functions. To demonstrate our work, we optimized models for a bipedal robot Cassie. We show in simulation that the optimal ROM reduces the cost of Cassie&#39;s joint torques by up to 23% and increases its walking speed by up to 54%. We also show hardware result that the real robot walks on flat ground with 10% lower torque cost.},
  archive      = {J_TROB},
  author       = {Yu-Ming Chen and Jianshu Hu and Michael Posa},
  doi          = {10.1109/TRO.2024.3386390},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2582-2601},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Beyond inverted pendulums: Task-optimal simple models of legged locomotion},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GJK++: Leveraging acceleration methods for faster collision
detection. <em>TROB</em>, <em>40</em>, 2564–2581. (<a
href="https://doi.org/10.1109/TRO.2024.3386370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collision detection is a fundamental problem in various domains, such as robotics, computational physics, and computer graphics. In general, collision detection is tackled as a computational geometry problem, with the so-called Gilbert, Johnson, and Keerthi (GJK) algorithm being the most adopted solution nowadays. While introduced in 1988, GJK remains the most effective solution to compute the distance or the collision between two 3-D convex geometries. Over the years, it was shown to be efficient, scalable, and generic, operating on a broad class of convex shapes, ranging from simple primitives (sphere, ellipsoid, box, cone, capsule, etc.) to complex meshes involving thousands of vertices. In this article, we introduce several contributions to accelerate collision detection and distance computation between convex geometries by leveraging the fact that these two problems are fundamentally optimization problems. Notably, we establish that the GJK algorithm is a specific subcase of the well-established Frank–Wolfe (FW) algorithm in convex optimization. By adapting recent works linking Polyak and Nesterov accelerations to FW methods, we also propose two accelerated extensions of the classic GJK algorithm. Through an extensive benchmark over millions of collision pairs involving objects of daily life, we show that these two accelerated GJK extensions significantly reduce the overall computational burden of collision detection, leading to computation times that are up to two times faster. Finally, we hope this work will significantly reduce the computational cost of modern robotic simulators, allowing the speedup of modern robotic applications that heavily rely on simulation, such as reinforcement learning or trajectory optimization.},
  archive      = {J_TROB},
  author       = {Louis Montaut and Quentin Le Lidec and Vladimir Petrik and Josef Sivic and Justin Carpentier},
  doi          = {10.1109/TRO.2024.3386370},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2564-2581},
  shortjournal = {IEEE Trans. Robot.},
  title        = {GJK++: Leveraging acceleration methods for faster collision detection},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Safe multiagent motion planning under uncertainty for drones
using filtered reinforcement learning. <em>TROB</em>, <em>40</em>,
2529–2542. (<a href="https://doi.org/10.1109/TRO.2024.3387010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider the problem of safe multiagent motion planning for drones in uncertain, cluttered workspaces. For this problem, we present a tractable motion planner that builds upon the strengths of reinforcement learning (RL) and constrained-control-based trajectory planning. First, we use single-agent RL to learn motion plans from data that reach the target but may not be collision free. Next, we use a convex optimization, chance constraints, and set-based methods for constrained control to ensure safety, despite the uncertainty in the workspace, agent motion, and sensing. The proposed approach can handle state and control constraints on the agents, and enforce collision avoidance among themselves and with static obstacles in the workspace with high probability. The proposed approach yields a safe, real-time implementable, multiagent motion planner that is simpler to train than methods based solely on learning. Numerical simulations and experiments show the efficacy of the approach.},
  archive      = {J_TROB},
  author       = {Sleiman Safaoui and Abraham P. Vinod and Ankush Chakrabarty and Rien Quirynen and Nobuyuki Yoshikawa and Stefano Di Cairano},
  doi          = {10.1109/TRO.2024.3387010},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2529-2542},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Safe multiagent motion planning under uncertainty for drones using filtered reinforcement learning},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Biomimetic morphing quadrotor inspired by eagle claw for
dynamic grasping. <em>TROB</em>, <em>40</em>, 2513–2528. (<a
href="https://doi.org/10.1109/TRO.2024.3386616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel biomimetic morphing quadrotor design inspired by the morphology of an eagle claw during prey capture. The arms of the quadrotor are capable of vertical folding to enable dynamic grasping, mimicking the transition of the eagle claw from an open to a closed state. This transition is achieved through the rotation of a central servomotor and the associated movement of 20 links. Thanks to the closed-loop multilink structure of the frame, the propellers of the quadrotor remain in a fixed orientation when the arms are folded, allowing for system stabilization at any arm rotation angle. The geometric property of the whole frame is analyzed to determine the relationships and constraints of the links, which is important in experimental vehicle fabrication. To handle possible physical property changes and external disturbances during grasping, the adaptive sliding mode controllers are applied. To deal with objects of unknown size in grasping tasks, an admittance filter is proposed for adaptive morphology. While in flight, our proposed morphing quadrotor is able to rapidly or continuously transition to any configuration within its range smoothly. Experimental results show the ability of the quadrotor to dynamically grasp various unknown objects at 0.4 m/s without additional tools, as well as its versatility in traversal of narrow spaces and perching.},
  archive      = {J_TROB},
  author       = {Mengxin Xu and Qixin De and Dafang Yu and An Hu and Zhe Liu and Hesheng Wang},
  doi          = {10.1109/TRO.2024.3386616},
  journal      = {IEEE Transactions on Robotics},
  month        = {4},
  pages        = {2513-2528},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Biomimetic morphing quadrotor inspired by eagle claw for dynamic grasping},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design, control, and validation of a novel cable-driven
series elastic actuation system for a flexible and portable back-support
exoskeleton. <em>TROB</em>, <em>40</em>, 2769–2790. (<a
href="https://doi.org/10.1109/TRO.2024.3381556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various active back-support exoskeletons have been developed to assist manual materials handling work for low back injury prevention. Existing back-support exoskeleton actuation either suffers from rigid transmission structure, or fails to efficiently generate assistance via portable actuation system with flexible transmissions. In this article, a novel cable-driven series elastic actuation (CSEA) system is proposed to realize a flexible and portable back-support exoskeleton design with safe, efficient, and sufficient assistive torque output capability. The CSEA system realizes a flexible actuation based on cable transmission for an ergonomic human–exoskeleton interaction. Based on a torsion spring–support beam mechanism, it achieves an efficient assistance output capability to prevent high cable force demand and resultant lumbar compression, assuring a safe and synergistic operation for flexible exoskeleton actuation. Meanwhile, this mechanism enables the CSEA system to integrate series elastic actuator (SEA) with cable transmission and operates with multiple statuses to leverage SEA advantages and to overcome its torque output limitation. Dynamic model is established for the CSEA system, and a unified torque controller is designed for stable, continuous, and accurate torque control of the CSEA system despite its discontinuous dynamics during operation status transition. The efficacy of the closed-loop CSEA system to enable an ergonomic and efficient back-support exoskeleton actuation with the capability of accurately delivering desired level of assistance is verified via bench tests and human tests. Results verified that the CSEA system actuated exoskeleton can effectively reduce activity of relevant muscles during trunk flexion and extension motions compared to no exoskeleton case, validating successful application of the CSEA system on the exoskeleton for an effective back support effect.},
  archive      = {J_TROB},
  author       = {Hongpeng Liao and Hugo Hung-tin Chan and Gaoyu Liu and Xuan Zhao and Fei Gao and Masayoshi Tomizuka and Wei-Hsin Liao},
  doi          = {10.1109/TRO.2024.3381556},
  journal      = {IEEE Transactions on Robotics},
  month        = {3},
  pages        = {2769-2790},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design, control, and validation of a novel cable-driven series elastic actuation system for a flexible and portable back-support exoskeleton},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Impact-aware bimanual catching of large-momentum objects.
<em>TROB</em>, <em>40</em>, 2543–2563. (<a
href="https://doi.org/10.1109/TRO.2024.3381551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates one of the most challenging tasks in dynamic manipulation—catching large-momentum moving objects. Beyond the realm of quasi-static manipulation, dealing with highly dynamic objects can significantly improve the robot&#39;s capability of interacting with its surrounding environment. Yet, the inevitable motion mismatch between the fast moving object and the approaching robot will result in large impulsive forces, which lead to the unstable contacts and irreversible damage to both the object and the robot. To address the above problems, we propose an online optimization framework to: 1) estimate and predict the linear and angular motion of the object, 2) search and select the optimal contact locations across every surface of the object to mitigate impact through sequential quadratic programming, 3) simultaneously optimize the end-effector motion, stiffness, and contact force for both robots using multimode trajectory optimization (MMTO), and 4) realise the impact-aware catching motion on the compliant robotic system based on indirect force controller. We validate the impulse distribution, contact selection, and impact-aware MMTO algorithms in simulation and demonstrate the benefits of the proposed framework in real-world experiments including catching large-momentum moving objects with well-defined motion, constrained motion, and free-flying motion.},
  archive      = {J_TROB},
  author       = {Lei Yan and Theodoros Stouraitis and João Moura and Wenfu Xu and Michael Gienger and Sethu Vijayakumar},
  doi          = {10.1109/TRO.2024.3381551},
  journal      = {IEEE Transactions on Robotics},
  month        = {3},
  pages        = {2543-2563},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Impact-aware bimanual catching of large-momentum objects},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RL-based adaptive controller for high precision reaching in
a soft robot arm. <em>TROB</em>, <em>40</em>, 2498–2512. (<a
href="https://doi.org/10.1109/TRO.2024.3381558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High precision control of soft robots is challenging due to their stohcastic behavior and material-dependent nature. While RL has been applied in soft robotics, achieving precision in task execution is still a long way off. Traditionally, RL requires substantial data for convergence, often obtained from a training environment. Yet, despite exhibiting high accuracy in the training environment, RL-policies often fall short in reality due to the training-to-reality gap, and the performance is exacerbated by the stochastic nature of soft robots. This study paves the way for the implementation of RL for soft robot control to achieve high precision in task execution. Two sample-efficient adaptive control strategies are proposed that leverage the RL-policy. The schemes can overcome stochasticity, bridge the training-to-reality gap, and attain desired accuracy even in challenging tasks, such as obstacle avoidance. In addition, deliberate and reversible damage is induced to the pneumatic actuation chamber, altering the soft robot&#39;s behavior to test the adaptability of our solutions. Despite the damage, desired accuracy was achieved in most scenarios without needing to retrain the RL-policy.},
  archive      = {J_TROB},
  author       = {Muhammad Sunny Nazeer and Cecilia Laschi and Egidio Falotico},
  doi          = {10.1109/TRO.2024.3381558},
  journal      = {IEEE Transactions on Robotics},
  month        = {3},
  pages        = {2498-2512},
  shortjournal = {IEEE Trans. Robot.},
  title        = {RL-based adaptive controller for high precision reaching in a soft robot arm},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Impact-aware planning and control for aerial robots with
suspended payloads. <em>TROB</em>, <em>40</em>, 2478–2497. (<a
href="https://doi.org/10.1109/TRO.2024.3381555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A quadrotor with a cable-suspended payload imposes great challenges in impact-aware planning and control. This joint system has dual motion modes, depending on whether the cable is slack or not, and presents complicated dynamics. Therefore, generating feasible agile flight while preserving the retractable nature of the cable is still a challenging task. In this article, we propose a novel impact-aware planning and control framework that resolves potential impacts caused by motion mode switching. Our method leverages the augmented Lagrangian method to solve an optimization problem with nonlinear complementarity constraints, which ensures trajectory feasibility with high accuracy while maintaining efficiency. We further propose a hybrid nonlinear model predictive control method to address the model mismatch issue in agile flight. Our methods have been comprehensively validated in both simulation and experiments, demonstrating superior performance compared to existing approaches. To the best of our knowledge, we are the first to successfully perform automatic multiple motion mode switching for aerial payload systems in real-world experiments.},
  archive      = {J_TROB},
  author       = {Haokun Wang and Haojia Li and Boyu Zhou and Fei Gao and Shaojie Shen},
  doi          = {10.1109/TRO.2024.3381555},
  journal      = {IEEE Transactions on Robotics},
  month        = {3},
  pages        = {2478-2497},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Impact-aware planning and control for aerial robots with suspended payloads},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive-force-based control of dynamic legged locomotion
over uneven terrain. <em>TROB</em>, <em>40</em>, 2462–2477. (<a
href="https://doi.org/10.1109/TRO.2024.3381554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agile-legged robots have proven to be highly effective in navigating and performing tasks in complex and challenging environments, including disaster zones and industrial settings. However, these applications commonly require the capability of carrying heavy loads while maintaining dynamic motion. Therefore, this article presents a novel methodology for incorporating adaptive control into a force-based control system. Recent advancements in the control of quadruped robots show that force control can effectively realize dynamic locomotion over rough terrain. By integrating adaptive control into the force-based controller, our proposed approach can maintain the advantages of the baseline framework while adapting to significant model uncertainties and unknown terrain impact models. Experimental validation was successfully conducted on the Unitree A1 robot. With our approach, the robot can carry heavy loads (up to 50% of its weight) while performing dynamic gaits such as fast trotting and bounding across uneven terrains.},
  archive      = {J_TROB},
  author       = {Mohsen Sombolestan and Quan Nguyen},
  doi          = {10.1109/TRO.2024.3381554},
  journal      = {IEEE Transactions on Robotics},
  month        = {3},
  pages        = {2462-2477},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Adaptive-force-based control of dynamic legged locomotion over uneven terrain},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CMax-SLAM: Event-based rotational-motion bundle adjustment
and SLAM system using contrast maximization. <em>TROB</em>, <em>40</em>,
2442–2461. (<a href="https://doi.org/10.1109/TRO.2024.3378443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event cameras are bioinspired visual sensors that capture pixelwise intensity changes and output asynchronous event streams. They show great potential over conventional cameras to handle challenging scenarios in robotics and computer vision, such as high speed and high dynamic range. This article considers the problem of rotational motion estimation using event cameras. Several event-based rotation estimation methods have been developed in the past decade, but their performance has not been evaluated and compared under unified criteria yet. In addition, these prior works do not consider a global refinement step. To this end, we conduct a systematic study of this problem with two objectives in mind: Summarizing previous works and presenting our own solution. First, we compare prior works both theoretically and experimentally. Second, we propose the first event-based rotation-only bundle adjustment (BA) approach. We formulate it leveraging the state-of-the-art contrast maximization (CMax) framework, which is principled and avoids the need to convert events into frames. Third, we use the proposed BA to build CMax-simultaneous localization and mapping (SLAM), the first event-based rotation-only SLAM system comprising a front-end and a back-end. Our BA is able to run both offline (trajectory smoothing) and online (CMax-SLAM back-end). To demonstrate the performance and versatility of our method, we present comprehensive experiments on synthetic and real-world datasets, including indoor, outdoor, and space scenarios. We discuss the pitfalls of real-world evaluation and propose a proxy for the reprojection error as the figure of merit to evaluate event-based rotation BA methods. We release the source code and novel data sequences to benefit the community. We hope this work leads to a better understanding and fosters further research on event-based egomotion estimation.},
  archive      = {J_TROB},
  author       = {Shuang Guo and Guillermo Gallego},
  doi          = {10.1109/TRO.2024.3378443},
  journal      = {IEEE Transactions on Robotics},
  month        = {3},
  pages        = {2442-2461},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CMax-SLAM: Event-based rotational-motion bundle adjustment and SLAM system using contrast maximization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On-manifold strategies for reactive dynamical system
modulation with nonconvex obstacles. <em>TROB</em>, <em>40</em>,
2390–2409. (<a href="https://doi.org/10.1109/TRO.2024.3378179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a novel, reactive, modulated control strategy based on dynamical systems (DS) for planning in the context of multiple nonconvex obstacles. Our DS modulation strategy leverages an on-manifold planning methodology and provides several methods for real-time on-manifold navigation around nonconvex obstacles. We introduce a sample-based obstacle representation for complex, nonconvex obstacles, as well as a projection-based method for representing surfaces, such as tables, cylinders, and ellipsoids. These representations can be combined to represent multiple obstacles and obstacle types (sample- or projection-based) with a single, continuously differentiable function. We validate our approach in several real-world scenarios, including navigation within (simulated) constrained environments, as well as reactive control of a real 7-DoF manipulator with dynamic obstacles (including humans) while utilizing a 1 kHz control loop rate. Using our sample-based representation, we can calculate the obstacle representation function in less than 1 ms with up to 35 k points using a CPU implementation, and up to 600 k points with a GPU implementation.},
  archive      = {J_TROB},
  author       = {Christopher K. Fourie and Nadia Figueroa and Julie A. Shah},
  doi          = {10.1109/TRO.2024.3378179},
  journal      = {IEEE Transactions on Robotics},
  month        = {3},
  pages        = {2390-2409},
  shortjournal = {IEEE Trans. Robot.},
  title        = {On-manifold strategies for reactive dynamical system modulation with nonconvex obstacles},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fiber-optic force sensing of modular robotic skin for remote
and autonomous robot control. <em>TROB</em>, <em>40</em>, 2373–2389. (<a
href="https://doi.org/10.1109/TRO.2024.3378178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots have taken the place of human operators in hazardous and challenging jobs requiring high dexterity in manipulation, and robots with skin for force and tactile sensing that mimics the function of mechanoreception in animals will be highly dexterous in performing complex tasks. In this study, we propose the design of modular robotic skin, capable of detecting the magnitude and the location of a contact force simultaneously. Each skin module needs three degrees of freedom in sensing in order to estimate the horizontal and the vertical locations of the contact force as well as its magnitude. Force sensing in the proposed skin is enabled by a custom-designed triangular beam structure underneath the skin cover. A force applied to the skin cover causes the bending of the beam, which is detected by fiber optic strain sensors. The result shows the resolutions of 1.45 N for force estimation and 1.85 and 1.91 mm for contact localization in horizontal and vertical directions, respectively. We also demonstrate how the proposed skin can be used for remote and autonomous control of commercial robotic arms equipped with an array of the skin modules.},
  archive      = {J_TROB},
  author       = {Sudong Lee and Jae In Kim and Youngjoon Baek and Dongjune Chang and Jeongseob Lee and Young Soo Park and Dongjun Lee and Yong-Lae Park},
  doi          = {10.1109/TRO.2024.3378178},
  journal      = {IEEE Transactions on Robotics},
  month        = {3},
  pages        = {2373-2389},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Fiber-optic force sensing of modular robotic skin for remote and autonomous robot control},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Low-cost and easy-to-build soft robotic skin for safe and
contact-rich human–robot collaboration. <em>TROB</em>, <em>40</em>,
2327–2338. (<a href="https://doi.org/10.1109/TRO.2024.3378174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although many soft robotic skins have been introduced, their use has been hindered due to practical limitations, such as difficulties in manufacturing, poor accessibility, and cost inefficiency. To solve this, we present a low-cost, easy-to-build soft robotic skin utilizing air-pressure sensors and 3D-printed pads. In our approach, we utilized digital fabrication and robot operating system (ROS) to facilitate the creation and use of the robotic skin. The skin pad was fabricated by printing thermoplastic urethane (TPU) and postprocessed with an organic solvent to secure air-tightness. Each pad consists of a TPU shell and infill, so the internal air-pressure changes in response to tactile stimuli, such as force and vibration. The internal pressure is measured and processed by a microcontroller and transmitted to the host computer via a serial bus. We conducted experiments to investigate the characteristics of the skin pads, and the results showed that the developed robotic skins are capable of perceiving interaction force and dynamic stimuli. Finally, we developed the dedicated soft robotic skins for our custom robot designed in-house, and demonstrated safe and intuitive physical human–robot interaction.},
  archive      = {J_TROB},
  author       = {Kyungseo Park and Kazuki Shin and Sankalp Yamsani and Kevin Gim and Joohyung Kim},
  doi          = {10.1109/TRO.2024.3378174},
  journal      = {IEEE Transactions on Robotics},
  month        = {3},
  pages        = {2327-2338},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Low-cost and easy-to-build soft robotic skin for safe and contact-rich Human–Robot collaboration},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design and hierarchical control of a homocentric
variable-stiffness magnetic catheter for multiarm robotic
ultrasound-assisted coronary intervention. <em>TROB</em>, <em>40</em>,
2306–2326. (<a href="https://doi.org/10.1109/TRO.2024.3378442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous magnetic catheterization has become a promising technology for next-generation minimally invasive cardiovascular surgery. In this article, a novel homocentric variable-stiffness magnetic robotic catheter (HVS-MRC) is presented. This device is controlled by a multiarm robot-assisted catheterization system for use in radiation-free coronary ultrasound intervention. The uniqueness of the HVS-MRC is the generation of variable stiffness through the telescopic motion of three homocentric components with embedded internal magnets. These components can be used to achieve multiple curvatures and large deflections ( $&amp;gt;$ 120 $^\circ$ ) under a magnetic wrench provided by an external mobile magnetic module to adapt to the complex coronary environment. The variable-stiffness kinematics modeling, multivessel selection strategy, and preoperative surgical planning of the proposed magnetic robotic catheter are established. Meanwhile, an extracorporeal mobile ultrasound module is adopted to intraoperatively localize the catheter&#39;s in-plane motion with a dominant visual/force feedback controller. A hierarchical relative control scheme is proposed based on the relative Jacobian method to synchronize the motions of the multiarm robot-assisted catheterization system. The overall performance is evaluated with an in vitro human-sized coronary arterial phantom with challenging anatomical variabilities. The results reveal that the HVS-MRC exhibits a high-accuracy intervention performance (average error of 1.52 $ \pm$ 0.35 mm) with smoother steering compared with conventional catheters. High synchronization with a low ultrasound target loss rate (15.8%) and constant-force tracing (2.50 $\pm$ 1.02 N) of the multiarm robot-assisted catheterization system demonstrate promising application potential in radiation-free autonomous ultrasonographic coronary intervention operations.},
  archive      = {J_TROB},
  author       = {Zhengyang Li and Junan Li and Zehao Wu and Yuanhe Chen and Magejiang Yeerbulati and Qingsong Xu},
  doi          = {10.1109/TRO.2024.3378442},
  journal      = {IEEE Transactions on Robotics},
  month        = {3},
  pages        = {2306-2326},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design and hierarchical control of a homocentric variable-stiffness magnetic catheter for multiarm robotic ultrasound-assisted coronary intervention},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Goal-conditioned dual-action imitation learning for
dexterous dual-arm robot manipulation. <em>TROB</em>, <em>40</em>,
2287–2305. (<a href="https://doi.org/10.1109/TRO.2024.3372778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-horizon dexterous robot manipulation of deformable objects, such as banana peeling, is a problematic task because of the difficulties in object modeling and a lack of knowledge about stable and dexterous manipulation skills. This article presents a goal-conditioned dual-action deep imitation learning (DIL) approach that can learn dexterous manipulation skills using human demonstration data. Previous DIL methods map the current sensory input and reactive action, which often fails because of compounding errors in imitation learning caused by the recurrent computation of actions. The method predicts reactive action only when the precise manipulation of the target object is required (local action) and generates the entire trajectory when precise manipulation is not required (global action). This dual-action formulation effectively prevents compounding error in the imitation learning using the trajectory-based global action while responding to unexpected changes in the target object during the reactive local action. The proposed method was tested in a real dual-arm robot and successfully accomplished the banana-peeling task.},
  archive      = {J_TROB},
  author       = {Heecheol Kim and Yoshiyuki Ohmura and Yasuo Kuniyoshi},
  doi          = {10.1109/TRO.2024.3372778},
  journal      = {IEEE Transactions on Robotics},
  month        = {3},
  pages        = {2287-2305},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Goal-conditioned dual-action imitation learning for dexterous dual-arm robot manipulation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft-tipped sensor with compliance control for elasticity
sensing and palpation. <em>TROB</em>, <em>40</em>, 2430–2441. (<a
href="https://doi.org/10.1109/TRO.2024.3371691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stiffness sensing and palpation are essential for understanding object properties, including tissue health and fruit ripeness. Currently, there is limited research on using soft-tipped sensors for stiffness sensing and dynamic palpation. To address these challenges, we investigate how the pressure-modulated optical tracking (PMOT) sensor can use compliance control to quantify tissue stiffness and detect margins in samples through dynamic palpation. Results show that the PMOT sensor modulus of elasticity sensing range is from 4.20 to 177.62 kPa. Across all the untrained samples, elasticity was measured with a root-mean-square error of 7.72%. Furthermore, it is shown that the sensor can locate margins between 13.4-kPa and embedded 29.3-kPa materials during palpation. When mounted on a linear rail, averaged for the direction of travel, the sensor&#39;s signal-to-noise ratio was up to 39.5:1. Participants used the sensor to locate embedded margins in a teleoperation environment with visual feedback. This was achieved with an accuracy of 96.5%.},
  archive      = {J_TROB},
  author       = {Duncan G. Raitt and Mahmud Huseynov and Shervanthi Homer-Vanniasinkam and Helge A. Wurdemann and Sara-Adela Abad},
  doi          = {10.1109/TRO.2024.3371691},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2430-2441},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Soft-tipped sensor with compliance control for elasticity sensing and palpation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-robot relative pose estimation and IMU preintegration
using passive UWB transceivers. <em>TROB</em>, <em>40</em>, 2410–2429.
(<a href="https://doi.org/10.1109/TRO.2024.3370027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultra-wideband (UWB) systems are becoming increasingly popular as a means of inter-robot ranging and communication. A major constraint associated with UWB is that only one pair of UWB transceivers can range at a time to avoid interference, hence hindering the scalability of UWB-based localization. In this article, a ranging protocol is proposed that allows all robots to passively listen on neighboring communicating robots without any hierarchical restrictions on the role of the robots. This is utilized to allow each robot to obtain more range measurements and to broadcast preintegrated inertial measurement unit (IMU) measurements for relative extended pose state estimation directly on $SE_{2}(3)$ . Consequently, a simultaneous clock-synchronization and relative-pose estimator is formulated using an on-manifold extended Kalman filter (EKF) and is evaluated in simulation using Monte Carlo runs for up to seven robots. The ranging protocol is implemented in C on custom-made UWB boards fitted to three quadcopters, and the proposed filter is evaluated over multiple experimental trials, yielding up to 48% improvement in localization accuracy.},
  archive      = {J_TROB},
  author       = {Mohammed Ayman Shalaby and Charles Champagne Cossette and Jerome Le Ny and James Richard Forbes},
  doi          = {10.1109/TRO.2024.3370027},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2410-2429},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Multi-robot relative pose estimation and IMU preintegration using passive UWB transceivers},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design of an adaptive lightweight LiDAR to decouple
robot–camera geometry. <em>TROB</em>, <em>40</em>, 2254–2271. (<a
href="https://doi.org/10.1109/TRO.2024.3371885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental challenge in robot perception is the coupling of the sensor pose and robot pose. This has led to research in active vision where the robot pose is changed to reorient the sensor to areas of interest for perception. Furthermore, egomotion, such as jitter, and external effects, such as wind and others, affect perception requiring additional efforts in software such as image stabilization. This effect is particularly pronounced in microair vehicles and microrobots that typically are lighter and subject to larger jitter but do not have the computational capability to perform stabilization in real time. We present a novel microelectromechanical mirror light detection and ranging (LiDAR) system to change the field of view of the LiDAR independent of the robot motion. Our design has the potential for use on small, low-power systems where the expensive components of the LiDAR can be placed external to the small robot. We show the utility of our approach in simulation and on prototype hardware mounted on a unmanned aerial vehicle (UAV). We believe that this LiDAR and its compact movable scanning design provide mechanisms to decouple robot and sensor geometry allowing us to simplify robot perception. We also demonstrate examples of motion compensation using inertial measurement unit (IMU) and external odometry feedback in hardware.},
  archive      = {J_TROB},
  author       = {Yuyang Chen and Dingkang Wang and Lenworth Thomas and Karthik Dantu and Sanjeev J. Koppal},
  doi          = {10.1109/TRO.2024.3371885},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2254-2271},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design of an adaptive lightweight LiDAR to decouple Robot–Camera geometry},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On second-order derivatives of rigid-body dynamics: Theory
and implementation. <em>TROB</em>, <em>40</em>, 2233–2253. (<a
href="https://doi.org/10.1109/TRO.2024.3370002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based control for robots has increasingly depended on optimization-based methods, such as differential dynamic programming (DDP) and iterative LQR (iLQR). These methods can form the basis of model-predictive control, which is commonly used for controlling legged robots. Computing the partial derivatives of the robot dynamics is often the most expensive part of these algorithms, regardless of whether analytical methods, finite difference, automatic differentiation (AD), or chain-rule accumulation is used. Since the second-order derivatives of the robot dynamics result in tensor computations, they are often ignored, leading to the use of iLQR, instead of the full second-order DDP method. In this article, we present analytical methods to compute the second-order derivatives of inverse and forward dynamics for open-chain rigid-body systems with multi-DoF joints and fixed/floating bases. An extensive comparison of accuracy and run-time performance with AD and other methods is provided, including the consideration of code-generation techniques in C/C++ to speed up the computations. For the 36 DoF ATLAS humanoid, the second-order inverse and forward dynamics derivatives take $\approx 200 \,\mu \text{s}$ , and $\approx \text{2.1}\,\text{ms}$ , respectively, on a 12th Gen Intel i5-12400 processor with 2.5 GHz clock-speed, resulting in a $\approx 3.2 \times$ and $\approx 3.8 \times$ speedup, respectively, over the AD approach.},
  archive      = {J_TROB},
  author       = {Shubham Singh and Ryan P. Russell and Patrick M. Wensing},
  doi          = {10.1109/TRO.2024.3370002},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2233-2253},
  shortjournal = {IEEE Trans. Robot.},
  title        = {On second-order derivatives of rigid-body dynamics: Theory and implementation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Material scrunching enables working channels in miniaturized
vine-inspired robots. <em>TROB</em>, <em>40</em>, 2166–2180. (<a
href="https://doi.org/10.1109/TRO.2024.3370088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new subclass of soft robot, known as tip-extending or “vine” robots, consists of long inflatable devices that move through the environment by extending from the tip. A key requirement for many applications of these robots is a working channel—a hollow tube through the core of the robot for passing tools, sensors, fluids, etc. While working channels have been proposed in a few vine robots, it remains an open challenge to create miniaturized vine robots (diameter $&amp;lt;\! 1$ cm) with working channels that enable continuous access through the core. In this article, we analyze the growth models of current vine robot designs and show that the working channel greatly increases required pressure to grow at small scales due to internal friction. Based on this insight, we propose the concept of storing scrunched material at the tip of the vine robot to circumvent this frictional force. We validate our models and demonstrate this concept via prototypes down to diameter of 2.3 mm. Overall, this work enables the creation of miniaturized vine robots with working channels, which significantly enhances their practicality and potential for impact in applications such as minimally invasive surgery.},
  archive      = {J_TROB},
  author       = {Cédric Girerd and Anna Alvarez and Elliot W. Hawkes and Tania K. Morimoto},
  doi          = {10.1109/TRO.2024.3370088},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2166-2180},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Material scrunching enables working channels in miniaturized vine-inspired robots},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bioinspired single actuator-driven soft robot capable of
multistrategy locomotion. <em>TROB</em>, <em>40</em>, 2149–2165. (<a
href="https://doi.org/10.1109/TRO.2024.3370050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidirectional jumping is commonly found in living creatures and desirable to be integrated into mobile robots for enhanced agility. Existing jumping robots mostly employ complex or cumbersome structures and modular designs to achieve multidirectional jumping. There is a lack of a simple, lightweight, and compact actuator design for multidirectional jumping robots. Here, we present a multidirectional jumping soft robot (MDJSR) driven by a biaxial electrohydraulic actuator (BEHA). The BEHA has a simple structure, i.e., a thin plastic frame-guided film pouch with four pairs of distributed electrodes and enclosed with a dielectric liquid. Inspired by gall midge larvae, the MDJSR exhibits two switchable locomotion strategies, including continuous nonenergy-storing jumping to move fast and energy-storing jumping to cross obstacles. Its multidirectional jumping capability was demonstrated in the navigation through a labyrinth with two ways of obstacle-crossing and obstacle-circumventing in different terrain environments. In addition, the robot can be deployed to detect unknown space and collect environmental factors. This work provides an enabling solution to miniature and lightweight multimodal jumping soft robots for various robotic tasks.},
  archive      = {J_TROB},
  author       = {Rui Chen and Xinyu Zhu and Zean Yuan and Huayan Pu and Jun Luo and Yu Sun},
  doi          = {10.1109/TRO.2024.3370050},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2149-2165},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A bioinspired single actuator-driven soft robot capable of multistrategy locomotion},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical incremental MPC for redundant robots: A robust
and singularity-free approach. <em>TROB</em>, <em>40</em>, 2128–2148.
(<a href="https://doi.org/10.1109/TRO.2024.3370049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a model predictive control (MPC) method for redundant robots controlling multiple hierarchical tasks formulated as multilayer constrained optimal control problems (OCPs). The proposed method, named hierarchical incremental MPC (HIMPC), is robust to dynamic uncertainties, untethered from kinematic/algorithmic singularities, and capable of handling input and state constraints such as joint torque and position limits. To this end, we first derive robust incremental systems that approximate uncertain system dynamics without computing complex nonlinear functions or identifying model parameters. Then, the constrained OCPs are cast as quadratic programming problems which result in linear MPC, where dynamically-consistent task priority is achieved by deploying equality constraints and optimal control is attained under input and state constraints. Moreover, hierarchical feasibility and recursive feasibility are theoretically proven. Since the computational complexity of HIMPC drastically decreases compared with nonlinear MPC-based methods, it is implemented under the sampling frequency of 1 kHz for physical experiments with redundant manipulator setups, where robustness (high tracking accuracy and enhanced dynamic consistency), admissibility of multiple constraints, and singularity-avoidance nature are demonstrated and compared with state-of-the-art task-prioritized controllers.},
  archive      = {J_TROB},
  author       = {Yongchao Wang and Yang Liu and Marion Leibold and Martin Buss and Jinoh Lee},
  doi          = {10.1109/TRO.2024.3370049},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2128-2148},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Hierarchical incremental MPC for redundant robots: A robust and singularity-free approach},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Learning a generalizable trajectory sampling distribution
for model predictive control. <em>TROB</em>, <em>40</em>, 2111–2127. (<a
href="https://doi.org/10.1109/TRO.2024.3370026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a sample-based model predictive control (MPC) method for collision-free navigation that uses a normalizing flow as a sampling distribution, conditioned on the start, goal, environment, and cost parameters. This representation allows us to learn a distribution that accounts for both the dynamics of the robot and complex obstacle geometries. We propose a way to incorporate this sampling distribution into two sampling-based MPC methods, MPPI, and iCEM. However, when deploying these methods, the robot may encounter an out-of-distribution (OOD) environment. To generalize our method to OOD environments, we also present an approach that performs projection on the representation of the environment. This projection changes the environment representation to be more in-distribution while also optimizing trajectory quality in the true environment. Our simulation results on a 2-D double-integrator, a 12-DoF quadrotor and a seven-DoF kinematic manipulator suggest that using a learned sampling distribution with projection outperforms MPC baselines on both in-distribution and OOD environments over different cost functions, including OOD environments generated from real-world data.},
  archive      = {J_TROB},
  author       = {Thomas Power and Dmitry Berenson},
  doi          = {10.1109/TRO.2024.3370026},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2111-2127},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning a generalizable trajectory sampling distribution for model predictive control},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Input decoupling of lagrangian systems via coordinate
transformation: General characterization and its application to soft
robotics. <em>TROB</em>, <em>40</em>, 2098–2110. (<a
href="https://doi.org/10.1109/TRO.2024.3370089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suitable representations of dynamical systems can simplify their analysis and control. On this line of thought, this article aims to answer the following question: Can a transformation of the generalized coordinates under which the actuators directly perform work on a subset of the configuration variables be found? We not only show that the answer to this question is yes but also provide necessary and sufficient conditions. More specifically, we look for a representation of the configuration space such that the right-hand side of the dynamics in Euler–Lagrange form becomes $[\boldsymbol{I}\; \boldsymbol{O}]^{T}\boldsymbol{u}$ , being $\boldsymbol{u}$ the system input. We identify a class of systems, called collocated , for which this problem is solvable. Under mild conditions on the input matrix, a simple test is presented to verify whether a system is collocated or not. By exploiting power invariance, we provide necessary and sufficient conditions that a change of coordinates decouples the input channels if and only if the dynamics is collocated. In addition, we use the collocated form to derive novel controllers for damped underactuated mechanical systems. To demonstrate the theoretical findings, we consider several Lagrangian systems with a focus on continuum soft robots.},
  archive      = {J_TROB},
  author       = {Pietro Pustina and Cosimo Della Santina and Frédéric Boyer and Alessandro De Luca and Federico Renda},
  doi          = {10.1109/TRO.2024.3370089},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2098-2110},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Input decoupling of lagrangian systems via coordinate transformation: General characterization and its application to soft robotics},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A human–robot collaboration controller utilizing confidence
for disagreement adjustment. <em>TROB</em>, <em>40</em>, 2081–2097. (<a
href="https://doi.org/10.1109/TRO.2024.3370025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of collaborative robots, the demand for efficient and safe physical human–robot interaction (pHRI) is significantly increasing. In this article, a two-loop pHRI controller is proposed to reduce the disagreement in human–robot cooperation and to enhance the level of robot assistance. In the outer loop, a human motion intention estimator is designed, combining the strength of model-free and model-based approaches. It estimates the human&#39;s desired movement position and provides the confidence level for the estimated value. Subsequently, the estimated value is tracked by the inner loop controller, and the confidence level is used to adjust the robot&#39;s behavior in order to reduce the disagreement. In the inner loop, a neuro-adaptive controller with a variable reference model is designed to achieve the efficient pHRI. A neural network is applied to compensate for the nonlinearity of the robot dynamics, gradually aligning the input–output characteristic of the robot dynamic model with the one of the reference model. To minimize the human–robot disagreement during the collaboration process and to enhance the robot&#39;s assistance level, a reinforcement learning method is proposed to adjust parameters of the reference model. The proposed control scheme is implemented on a Franka Panda robot and validated through the point-to-point movement simulation and a real-world human–robot lifting experiment. Results suggest that compared to other methods, the proposed approach can indeed reduce the human–robot disagreement and improve the robot assistance level.},
  archive      = {J_TROB},
  author       = {Muyuan Ma and Long Cheng},
  doi          = {10.1109/TRO.2024.3370025},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2081-2097},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A Human–Robot collaboration controller utilizing confidence for disagreement adjustment},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). REFINE: Reachability-based trajectory design using robust
feedback linearization and zonotopes. <em>TROB</em>, <em>40</em>,
2060–2080. (<a href="https://doi.org/10.1109/TRO.2024.3366819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performing real-time receding horizon motion planning for autonomous vehicles while providing safety guarantees remains difficult. This is because existing methods to accurately predict ego vehicle behavior under a chosen controller use online numerical integration that requires a fine time discretization and thereby adversely affects real-time performance. To address this limitation, several recent papers have proposed to apply offline reachability analysis to conservatively predict the behavior of the ego vehicle. Reachable sets can be constructed by utilizing a simplified model whose behavior is assumed a priori to conservatively bound the dynamics of a full-order model. However, it can be challenging to meticulously construct this conservative bound. This article proposes a framework named REFINE to overcome the limitations of these existing approaches. REFINE utilizes a parameterized robust controller that partially linearizes the vehicle dynamics even in the presence of modeling error. Zonotope-based reachability analysis is then performed on the closed-loop, full-order vehicle dynamics to offline compute the corresponding control-parameterized, overapproximate forward reachable sets (FRS). Because reachability analysis is applied to the full-order model, the potential conservativeness introduced by using a simplified model is avoided. The precomputed, control-parameterized FRS is then used online in an optimization framework to ensure safety. The proposed method is compared to several state-of-the-art methods during a simulation-based evaluation on a full-size vehicle model and is demonstrated on a $\frac{1}{10}$ th race car robot in real hardware testing. In contrast to existing methods, REFINE is shown to enable the vehicle to safely navigate itself through complex environments.},
  archive      = {J_TROB},
  author       = {Jinsun Liu and Yifei Simon Shao and Lucas Lymburner and Hansen Qin and Vishrut Kaushik and Lena Trang and Ruiyang Wang and Vladimir Ivanovic and H. Eric Tseng and Ram Vasudevan},
  doi          = {10.1109/TRO.2024.3366819},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2060-2080},
  shortjournal = {IEEE Trans. Robot.},
  title        = {REFINE: Reachability-based trajectory design using robust feedback linearization and zonotopes},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PIPO-SLAM: Lightweight visual-inertial SLAM with
preintegration merging theory and pose-only descriptions of multiple
view geometry. <em>TROB</em>, <em>40</em>, 2046–2059. (<a
href="https://doi.org/10.1109/TRO.2024.3366815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization-based visual-inertial simultaneous localization and mapping system (VI-SLAM) focuses on the establishment of the loss function using both inertial and visual constraints. Preintegration theory is commonly used to express inertial constraints, but it lacks the merging equation between keyframes, challenging VI-SLAM from culling and merging redundant keyframes. To address this, we establish an on-manifold preintegration merging theory, including the merging of preintegrated terms, noise covariance, and Jacobians for bias updating, which significantly improves the preintegration theory and provides theoretical support for the keyframe management function of VI-SLAM. Visual constraints are typically expressed using multiple view geometry with 3-D points optimized as scene structure parameters. However, the excessive dimensionality of the optimization parameters generated by 3-D points can lead to computational bottlenecks. Through the recent pose-only imaging geometry representation, we construct a lightweight optimization algorithm for SLAM that avoids the dimensional explosion in bundle adjustment. Based on the above, we propose a 3-D points-free SLAM optimizer. The proposed algorithms are validated on simulation, public datasets, and real-world experiments, and compared against advanced open-source systems, such as ORB-SLAM3 and VINS.},
  archive      = {J_TROB},
  author       = {Yangbing Ge and Lilian Zhang and Yuanxin Wu and Dewen Hu},
  doi          = {10.1109/TRO.2024.3366815},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2046-2059},
  shortjournal = {IEEE Trans. Robot.},
  title        = {PIPO-SLAM: Lightweight visual-inertial SLAM with preintegration merging theory and pose-only descriptions of multiple view geometry},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enabling versatility and dexterity of the dual-arm
manipulators: A general framework toward universal cooperative
manipulation. <em>TROB</em>, <em>40</em>, 2024–2045. (<a
href="https://doi.org/10.1109/TRO.2024.3370048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grasping and manipulating various kinds of objects cooperatively is the core skill of a dual-arm robot when deployed as an autonomous agent in a human-centered environment. This requires fully exploiting the robot&#39;s versatility and dexterity. In this work, we propose a general framework for dual-arm manipulators that contains two correlative modules. The learning-based dexterity-reachability-aware perception module deals with vision-based bimanual grasping. It employs an end-to-end evaluation network and probabilistic modeling of the robot&#39;s reachability to deliver feasible and dexterity-optimum grasp pairs for unseen objects. The optimization-based versatility-oriented control module addresses the online cooperative manipulation control by using a hierarchical quadratic programming formulation. Self-collision avoidance and dual-arm manipulability ellipsoid tracking with high reliability and fidelity are simultaneously achieved based on a learned lightweight distance proxy function and a speed-level tracking technique on Riemannian manifold. Intrinsic system safety is guaranteed, and a novel interface for skill transfer is enabled. A long-horizon rearrangement experiment, a bimanual turnover manipulation, and multiple comparative performance evaluation verify the effectiveness of the proposed framework.},
  archive      = {J_TROB},
  author       = {Yi Ren and Zhehua Zhou and Ziwei Xu and Yang Yang and Guangyao Zhai and Marion Leibold and Fenglei Ni and Zhengyou Zhang and Martin Buss and Yu Zheng},
  doi          = {10.1109/TRO.2024.3370048},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {2024-2045},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Enabling versatility and dexterity of the dual-arm manipulators: A general framework toward universal cooperative manipulation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An optimal control formulation of tool affordance applied to
impact tasks. <em>TROB</em>, <em>40</em>, 1966–1982. (<a
href="https://doi.org/10.1109/TRO.2024.3365993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans use tools to complete impact-aware tasks, such as hammering a nail or playing tennis. The postures adopted to use these tools can significantly influence the performance of these tasks, where the force or velocity of the hand holding a tool plays a crucial role. The underlying motion planning challenge consists of grabbing the tool in preparation for the use of this tool with an optimal body posture. Directional manipulability describes the dexterity of force and velocity in a joint configuration along a specific direction. In order to take directional manipulability and tool affordances into account, we apply an optimal control method combining iterative linear quadratic regulator with the alternating direction method of multipliers. Our approach considers the notion of tool affordances to solve motion planning problems, by introducing a cost based on directional velocity manipulability. The proposed approach is applied to impact tasks in simulation and on a real 7-axis robot, specifically in a nail-hammering task with the assistance of a pilot hole. Our comparison study demonstrates the importance of maximizing directional manipulability in impact-aware tasks.},
  archive      = {J_TROB},
  author       = {Boyang Ti and Yongsheng Gao and Jie Zhao and Sylvain Calinon},
  doi          = {10.1109/TRO.2024.3365993},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1966-1982},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An optimal control formulation of tool affordance applied to impact tasks},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven momentum observers with physically consistent
gaussian processes. <em>TROB</em>, <em>40</em>, 1938–1951. (<a
href="https://doi.org/10.1109/TRO.2024.3366818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a data-driven modeling framework with physically consistent Gaussian processes (GPs), enabling learning-based disturbance estimation for uncertain mechanical systems with covariance-adaptive momentum observers (MOs). We present novel error bound results in closed form, holding with high, exactly computable probabilities, and exploit the multidimensional, physically constrained function distribution induced by the differential equation structure of Lagrangian systems. The inherent uncertainty quantification provided by GPs and the derived model error bounds are then leveraged to probabilistically guarantee exponential stability of a class of data-driven, adaptive MOs with user-definable convergence parameters. We demonstrate the performance of our proposed methods in simulations and physical experiments, showing significant improvements compared to the state-of-the-art from industry and research.},
  archive      = {J_TROB},
  author       = {Giulio Evangelisti and Sandra Hirche},
  doi          = {10.1109/TRO.2024.3366818},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1938-1951},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Data-driven momentum observers with physically consistent gaussian processes},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A sliding window filter with GNSS-state constraint for
RTK-visual-inertial navigation. <em>TROB</em>, <em>40</em>, 1920–1937.
(<a href="https://doi.org/10.1109/TRO.2024.3365008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a novel method by using a sliding window filter (SWF) for real-time kinematic (RTK) visual-inertial navigation. Unlike other recent works that retain only the states of visual keyframes to reduce computational complexity, we additionally retain the GNSS states (i.e., position, orientation, and velocity of the body and inertial biases at the time of capturing GNSS measurements) in the SWF to construct more appropriate constraints between measurements and states. In order to make the method run as a real-time system, especially when the SWF contains numerous GNSS states, we propose a parallel elimination strategy in a predefined elimination ordering, which can solve the Gauss–Newton problem and simultaneously obtain the covariance for ambiguity resolution (AR). We reveal when and how the system improves the AR performance. Moreover, we analyze the observability of the system under different conditions. We also conduct experiments in the real world and compare the results with the state-of-the-art. Experimental results show that the proposed method is able to achieve a higher and stabler fixed rate in GNSS challenging environments, and has better positioning performance with or without measurements of a base station. We have decided to publish the code of our work for the community.},
  archive      = {J_TROB},
  author       = {Xiaohong Huang and Cui Yang and Miaowen Wen},
  doi          = {10.1109/TRO.2024.3365008},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1920-1937},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A sliding window filter with GNSS-state constraint for RTK-visual-inertial navigation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Do you need a hand? – a bimanual robotic dressing assistance
scheme. <em>TROB</em>, <em>40</em>, 1906–1919. (<a
href="https://doi.org/10.1109/TRO.2024.3366008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing physically assistive robots capable of dressing assistance has the potential to significantly improve the lives of the elderly and disabled population. However, most robotics dressing strategies considered a single robot only, which greatly limited the performance of the dressing assistance. In fact, healthcare professionals perform the task bimanually. Inspired by them, we propose a bimanual cooperative scheme for robotic dressing assistance. In the scheme, an interactive robot joins hands with the human thus supporting/guiding the human in the dressing process while the dressing robot performs the dressing task. We identify a key feature: the elbow angle that affects the dressing action and propose an optimal strategy for the interactive robot using the feature. A dressing coordinate based on the posture of the arm is defined to better encode the dressing policy. We validate the interactive dressing scheme with extensive experiments and also an ablation study.},
  archive      = {J_TROB},
  author       = {Jihong Zhu and Michael Gienger and Giovanni Franzese and Jens Kober},
  doi          = {10.1109/TRO.2024.3366008},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1906-1919},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Do you need a hand? – a bimanual robotic dressing assistance scheme},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ringbot: Monocycle robot with legs. <em>TROB</em>,
<em>40</em>, 1890–1905. (<a
href="https://doi.org/10.1109/TRO.2024.3362326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents the development and evaluation of Ringbot, a novel leg-wheel transformer robot incorporating a monocycle mechanism with legs. Ringbot aims to provide versatile mobility by replacing the driver and driving components of a conventional monocycle vehicle with legs mounted on compact driving modules inside the wheel. The article covers the hardware and software implementation of a prototype robot. The Ringbot prototype features a wheel and two driving modules located inside, each equipped with a 3-DoF leg for balancing, steering, and legged motions to assist monocycle driving. The driving control is achieved through decoupled speed controller and steering controller. In addition, active-legged motions are implemented and managed through a finite-state machine. The controllers for wheeled driving and legged motions were tested in a simulation environment, as well as on the hardware prototype, to verify the concept of a monocycle with legs and evaluate the prototype&#39;s capabilities.},
  archive      = {J_TROB},
  author       = {Kevin Genehyub Gim and Joohyung Kim},
  doi          = {10.1109/TRO.2024.3362326},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1890-1905},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Ringbot: Monocycle robot with legs},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal soft amphibious robots using simple
plastic-sheet-reinforced thin pneumatic actuators. <em>TROB</em>,
<em>40</em>, 1874–1889. (<a
href="https://doi.org/10.1109/TRO.2024.3360961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large challenge in the field of soft amphibious robotics is achieving high maneuverability and multiterrain adaptability through multimodal locomotion in hybrid terrestrial–aquatic environments. To address this issue, drawing inspiration from fruit-fly larvae and Spanish dancer sea slugs, a novel tethered soft amphibious robot with multimodal locomotion is proposed in this article, performing forward, backward, turning, and self-overturn motions both on land and in water. It leverages plastic-sheet-reinforced thin pneumatic actuators, which are constructed from thermoplastic membranes and embedded with a nonstretchable plastic sheet, enabling bidirectional bending with large angles. The robot achieves a forward jumping velocity of 1.77 BL/s and a forward swimming velocity of 0.69 BL/s, both faster than previously reported soft amphibious robots; connecting two actuator units in parallel, it achieves agile turning with a velocity of 111.8 $^\circ$ /s. Our proposed robot demonstrates exceptional multiterrain adaptability, facile terrestrial–aquatic transition capabilities, and underwater buoyancy adjustment ability. Especially when accidentally overturned, it can recover itself without external assistance, a capability rarely achieved by other soft robots.},
  archive      = {J_TROB},
  author       = {Jiaxi Wu and Mingxin Wu and Wenhui Chen and Chen Wang and Guangming Xie},
  doi          = {10.1109/TRO.2024.3360961},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1874-1889},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Multimodal soft amphibious robots using simple plastic-sheet-reinforced thin pneumatic actuators},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Selection of secure gravity-based caging grasps of planar
objects: Robustness and experimental validation. <em>TROB</em>,
<em>40</em>, 1860–1873. (<a
href="https://doi.org/10.1109/TRO.2024.3365010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gravity-based caging grasps are robotic grasps where the robot hand passively supports an object against gravity. When a robot hand supports an object at a local minimum of the object gravitational energy, the robot hand forms a basket like grasp of the object. Any object movement in a basket grasp requires an increase of the object gravitational energy, thus allowing secure object pickup and transport with robot hands that use a small number fingers. The basket grasp depth measures the minimal additional energy the object must acquire to escape the basket grasp. This article extends previous work detailing a computation scheme that determines the depth of entire sets of candidate basket grasps associated with alternative finger placements on the object boundary before pickup. The computation relies on categorization of escape stances that mark the basket grasp depth: double-support escapes are first analyzed and computed, then single-support escapes are analyzed and computed. The minimum energy combination of both types of escape stances defines the depth of entire sets of candidate basket grasps, which is then used to identify the deepest and, hence, most secure basket grasp. This article additionally presents experimental validation of the computation scheme as well as numerical analysis of basket grasp robustness to object estimation errors.},
  archive      = {J_TROB},
  author       = {Alon Shirizly and Elon D. Rimon},
  doi          = {10.1109/TRO.2024.3365010},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1860-1873},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Selection of secure gravity-based caging grasps of planar objects: Robustness and experimental validation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified shape and external load state estimation for
continuum robots. <em>TROB</em>, <em>40</em>, 1813–1827. (<a
href="https://doi.org/10.1109/TRO.2024.3360950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuum robots navigate narrow, winding passageways while safely and compliantly interacting with their environments. Sensing the robot&#39;s shape under these conditions is often done indirectly, using a few coarsely distributed (e.g., strain or position) sensors combined with the robot&#39;s mechanics-based model. More recently, given high-fidelity shape data, external interaction loads along the robot have been estimated by solving an inverse problem on the mechanics model of the robot. In this article, we argue that since shape and force are fundamentally coupled, they should be estimated simultaneously using a statistically principled approach. We accomplish this by applying continuous-time batch estimation directly to the arclength domain. A general continuum robot model serves as a statistical prior that is fused with discrete, noisy measurements taken along the robot&#39;s backbone. The result is a continuous posterior containing both shape and load functions of arclength, as well as their uncertainties. We first test the approach with a Cosserat rod, i.e., the underlying modeling framework that is the basis for a variety of continuum robots. We verify our approach numerically using distributed loads with various sensor combinations. Next, we experimentally validate shape and external load errors for highly concentrated force distributions (point loads). Finally, we apply the approach to a tendon-actuated continuum robot demonstrating applicability to more complex actuated robots.},
  archive      = {J_TROB},
  author       = {James M. Ferguson and D. Caleb Rucker and Robert J. Webster},
  doi          = {10.1109/TRO.2024.3360950},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1813-1827},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Unified shape and external load state estimation for continuum robots},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Direct visual servoing based on discrete orthogonal moments.
<em>TROB</em>, <em>40</em>, 1795–1812. (<a
href="https://doi.org/10.1109/TRO.2024.3360954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new approach to achieve direct visual servoing (DVS) based on discrete orthogonal moments (DOMs). DVS is performed in such a way that the extraction of geometric primitives, matching, and tracking steps in the conventional feature-based visual servoing pipeline can be bypassed. Although DVS enables highly precise positioning, it suffers from a limited convergence domain and poor robustness due to the extreme nonlinearity of the cost function to be minimized and the presence of redundant data between visual features. To tackle these issues, we propose a generic and augmented framework that considers DOMs as visual features. By using the Tchebichef, Krawtchouk, and Hahn moments as examples, we not only present the strategies for adaptively tuning the parameters and order of the visual features but also exhibit an analytical formulation of the associated interaction matrix. Simulations demonstrate the robustness and accuracy of our approach, as well as its advantages over the state-of-the-art. Real-world experiments have also been performed to validate the effectiveness of our approach.},
  archive      = {J_TROB},
  author       = {Yuhan Chen and Max Qing-Hu Meng and Li Liu},
  doi          = {10.1109/TRO.2024.3360954},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1795-1812},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Direct visual servoing based on discrete orthogonal moments},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Latent space planning for multiobject manipulation with
environment-aware relational classifiers. <em>TROB</em>, <em>40</em>,
1724–1739. (<a href="https://doi.org/10.1109/TRO.2024.3360956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objects rarely sit in isolation in everyday human environments. If we want robots to operate and perform tasks in our human environments, they must understand how the objects they manipulate will interact with structural elements of the environment for all but the simplest of tasks. As such, we would like our robots to reason about how multiple objects and environmental elements relate to one another and how those relations may change as the robot interacts with the world. We examine the problem of predicting interobject and object–environment relations between previously unseen objects and novel environments purely from partial-view point clouds. Our approach enables robots to plan and execute sequences to complete multiobject manipulation tasks defined from logical relations. This removes the burden of providing explicit, continuous object states as goals to the robot. We explore several different neural network architectures for this task. We find the best performing model to be a novel transformer-based neural network that both predicts object–environment relations and learns a latent-space dynamics function. We achieve reliable sim-to-real transfer without any fine-tuning. Our experiments show that our model understands how changes in observed environmental geometry relate to semantic relations between objects.},
  archive      = {J_TROB},
  author       = {Yixuan Huang and Nichols Crawford Taylor and Adam Conkey and Weiyu Liu and Tucker Hermans},
  doi          = {10.1109/TRO.2024.3360956},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1724-1739},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Latent space planning for multiobject manipulation with environment-aware relational classifiers},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Piezoelectric soft robot inchworm motion by tuning ground
friction through robot shape: Quasi-static modeling and experimental
validation. <em>TROB</em>, <em>40</em>, 2339–2356. (<a
href="https://doi.org/10.1109/TRO.2024.3353035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrically-driven soft robots based on piezoelectric actuators may enable compact form factors and maneuverability in complex environments. In most prior work, piezoelectric actuators are used to control a single degree of freedom. In this work, the coordinated activation of five independent piezoelectric actuators, attached to a common metal foil, is used to implement inchworm-inspired crawling motion in a robot that is less than 0.5 mm thick. The motion is based on the control of its friction to the ground through the robot&#39;s shape, in which one end of the robot (depending on its shape) is anchored to the ground by static friction, while the rest of its body expands or contracts. A complete analytical model of the robot shape, which includes gravity, and contact is developed to quantify the robot shape, friction, and displacement. After validation of the model by experiments, the robot&#39;s five actuators are collectively sequenced for inchworm-like forward and backward motion.},
  archive      = {J_TROB},
  author       = {Zhiwu Zheng and Prakhar Kumar and Yenan Chen and Hsin Cheng and Sigurd Wagner and Minjie Chen and Naveen Verma and James C. Sturm},
  doi          = {10.1109/TRO.2024.3353035},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {2339-2356},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Piezoelectric soft robot inchworm motion by tuning ground friction through robot shape: Quasi-static modeling and experimental validation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continuous-time control synthesis under nested signal
temporal logic specifications. <em>TROB</em>, <em>40</em>, 2272–2286.
(<a href="https://doi.org/10.1109/TRO.2024.3353081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a novel approach for the continuous-time control synthesis of nonlinear systems under nested signal temporal logic (STL) specifications. While the majority of existing literature focuses on control synthesis for STL specifications without nested temporal operators, addressing nested temporal operators poses a notably more challenging scenario and requires new theoretical advancements. Our approach hinges on the concepts of STL tree (sTLT) and control barrier function (CBF). Specifically, we detail the construction of an sTLT from a given STL formula and a continuous-time dynamical system, the sTLT semantics (i.e., satisfaction condition), and the equivalence or underapproximation relation between sTLT and STL. Leveraging the fact that the satisfaction condition of an sTLT is essentially keeping the state within certain sets during certain time intervals, it provides explicit guidelines for the CBF design. The resulting controller is obtained through the utilization of an online CBF-based program coupled with an event-triggered scheme for online updating the activation time interval of each CBF, with which the correctness of the system behavior can be established by construction. We demonstrate the efficacy of the proposed method for single-integrator and unicycle models under nested STL formulas.},
  archive      = {J_TROB},
  author       = {Pian Yu and Xiao Tan and Dimos V. Dimarogonas},
  doi          = {10.1109/TRO.2024.3353081},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {2272-2286},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Continuous-time control synthesis under nested signal temporal logic specifications},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Statistically distinct plans for multiobjective task
assignment. <em>TROB</em>, <em>40</em>, 2217–2232. (<a
href="https://doi.org/10.1109/TRO.2024.3359530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of finding statistically distinct plans for stochastic task assignment problems such as online multirobot pickup and delivery (MRPD) when facing multiple competing objectives. In many real-world settings, robot fleets do not only need to fulfill delivery requests but also have to consider auxiliary objectives such as energy efficiency or avoiding human-centered work spaces. We pose MRPD as a multiobjective optimization problem where the goal is to find MRPD policies that yield different tradeoffs between given objectives. There are two main challenges: 1) MRPD is computationally hard, which limits the number of tradeoffs that can reasonably be computed and 2) due to the random task arrivals, one needs to consider the statistical variance of the objective values in addition to the average. We present an adaptive sampling algorithm that finds a set of policies that 1) are approximately optimal, 2) approximate the set of all optimal solutions, and 3) are statistically distinguishable. We prove completeness and adapt a state-of-the-art MRPD solver to the multiobjective setting for three example objectives. In a series of simulation experiments, we demonstrate the advantages of the proposed method compared to baseline approaches and show its robustness in a sensitivity analysis. The approach is general and could be adapted to other multiobjective task assignments and planning problems under uncertainty.},
  archive      = {J_TROB},
  author       = {Nils Wilde and Javier Alonso-Mora},
  doi          = {10.1109/TRO.2024.3359530},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {2217-2232},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Statistically distinct plans for multiobjective task assignment},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MAVERIC: A data-driven approach to personalized autonomous
driving. <em>TROB</em>, <em>40</em>, 1952–1965. (<a
href="https://doi.org/10.1109/TRO.2024.3359543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalization of autonomous vehicles (AVs) may significantly increase acceptance. In particular, we hypothesize that the similarity of an AV&#39;s driving style compared to a user&#39;s driving style, the level of aggressiveness of the driving style, and other subjective factors (e.g., personality) will have a major impact on user&#39;s willingness to use the AV. In this work, we 1) develop a data-driven approach to personalize driving style and calibrate the level of aggressiveness and 2) investigate the subjective factors that impact user preference. Across two human subject studies (n = 54), we demonstrate that our approach can mimic the driving styles and tune the level of aggressiveness. Second, we leverage our framework to investigate the factors that impact homophily. We demonstrate that our approach generates driving styles objectively ( $p &amp;lt; . 001$ ) and subjectively ( $p =. 002$ ) consistent with end-user styles ( $p &amp;lt; . 001$ ) and can effectively isolate and modulate a dimension of style (i.e., aggressiveness) ( $p &amp;lt; . 001$ ). Furthermore, we find that personality ( $p &amp;lt; . 001$ ), perceived similarity ( $p &amp;lt; . 001$ ), and high-velocity driving style ( $p =. 0031$ ) significantly modulate the effect of homophily.},
  archive      = {J_TROB},
  author       = {Mariah L. Schrum and Emily Sumner and Matthew C. Gombolay and Andrew Best},
  doi          = {10.1109/TRO.2024.3359543},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1952-1965},
  shortjournal = {IEEE Trans. Robot.},
  title        = {MAVERIC: A data-driven approach to personalized autonomous driving},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Haptic transparency and interaction force control for a
lower limb exoskeleton. <em>TROB</em>, <em>40</em>, 1842–1859. (<a
href="https://doi.org/10.1109/TRO.2024.3359541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling the interaction forces between a human and an exoskeleton is crucial for providing transparency or adjusting assistance or resistance levels. However, it is an open problem to control the interaction forces of lower limb exoskeletons designed for unrestricted overground walking. For these types of exoskeletons, it is challenging to implement force/torque sensors at every contact between the user and the exoskeleton for direct force measurement. Moreover, it is important to compensate for the exoskeleton&#39;s whole-body gravitational and dynamical forces, especially for heavy lower limb exoskeletons. Previous works either simplified the dynamic model by treating the legs as independent double pendulums, or they did not close the loop with interaction force feedback. The proposed whole-exoskeleton closed-loop compensation (WECC) method calculates the interaction torques during the complete gait cycle by using whole-body dynamics and joint torque measurements on a hip-knee exoskeleton. Furthermore, it uses a constrained optimization scheme to track desired interaction torques in a closed loop while considering physical and safety constraints. We evaluated the haptic transparency and dynamic interaction torque tracking of WECC control on three subjects. We also compared the performance of WECC with a controller based on a simplified dynamic model and a passive version of the exoskeleton. The WECC controller results in a consistently low absolute interaction torque error during the whole gait cycle for both zero and nonzero desired interaction torques. In contrast, the simplified controller yields poor performance in tracking desired interaction torques during the stance phase.},
  archive      = {J_TROB},
  author       = {Emek Barış Küçüktabak and Yue Wen and Sangjoon J. Kim and Matthew R. Short and Daniel Ludvig and Levi Hargrove and Eric J. Perreault and Kevin M. Lynch and José L. Pons},
  doi          = {10.1109/TRO.2024.3359541},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1842-1859},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Haptic transparency and interaction force control for a lower limb exoskeleton},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Safe reinforcement learning in uncertain contexts.
<em>TROB</em>, <em>40</em>, 1828–1841. (<a
href="https://doi.org/10.1109/TRO.2024.3354176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When deploying machine learning algorithms in the real world, guaranteeing safety is an essential asset. Existing safe learning approaches typically consider continuous variables, i.e., regression tasks. However, in practice, robotic systems are also subject to discrete, external environmental changes, e.g., having to carry objects of certain weights or operating on frozen, wet, or dry surfaces. Such influences can be modeled as discrete context variables. In the existing literature, such contexts are, if considered, mostly assumed to be known. In this work, we drop this assumption and show how we can perform safe learning when we cannot directly measure the context variables. To achieve this, we derive frequentist guarantees for multiclass classification, allowing us to estimate the current context from measurements. Furthermore, we propose an approach for identifying contexts through experiments. We discuss under which conditions we can retain theoretical guarantees and demonstrate the applicability of our algorithm on a Furuta pendulum with camera measurements of different weights that serve as contexts.},
  archive      = {J_TROB},
  author       = {Dominik Baumann and Thomas B. Schön},
  doi          = {10.1109/TRO.2024.3354176},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1828-1841},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Safe reinforcement learning in uncertain contexts},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Task-driven hybrid model reduction for dexterous
manipulation. <em>TROB</em>, <em>40</em>, 1774–1794. (<a
href="https://doi.org/10.1109/TRO.2024.3359531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In contact-rich tasks, like dexterous manipulation, the hybrid nature of making and breaking contact creates challenges for model representation and control. For example, choosing and sequencing contact locations for in-hand manipulation, where there are thousands of potential hybrid modes, is not generally tractable. In this article, we are inspired by the observation that far fewer modes are actually necessary to accomplish many tasks. Building on our prior work learning hybrid models, represented as linear complementarity systems, we find a reduced-order hybrid model requiring only a limited number of task-relevant modes. This simplified representation, in combination with model predictive control, enables real-time control yet is sufficient for achieving high performance. We demonstrate the proposed method first on synthetic hybrid systems, reducing the mode count by multiple orders of magnitude while achieving task performance loss of less than 5%. We also apply the proposed method to a three-fingered robotic hand manipulating a previously unknown object. With no prior knowledge, we achieve state-of-the-art closed-loop performance within a few minutes of online learning, by collecting only a few thousand environment samples.},
  archive      = {J_TROB},
  author       = {Wanxin Jin and Michael Posa},
  doi          = {10.1109/TRO.2024.3359531},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1774-1794},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Task-driven hybrid model reduction for dexterous manipulation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameter estimation of nonsmooth frictionless impacts
through a hybrid observer. <em>TROB</em>, <em>40</em>, 1758–1773. (<a
href="https://doi.org/10.1109/TRO.2024.3359537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the velocity of a mass involved in nonsmooth impacts is a challenging problem because of their hybrid nature, especially when the restitution coefficient and the orientation of the tangent line at the point of impact are unknown. In this article, various hybrid observers are proposed for some families of mechanical systems to estimate the velocities, the restitution coefficient, and the orientation of the constraint, under the assumption that only the positions are measured. The stability properties of the corresponding error dynamics are proved, showing semiglobal exponential convergence to zero. First, the performance of the proposed observer is tested in some simulation runs. Second, the analysis is carried out in experimental tests, by measuring the position of the impacting body through slow and fast camcorders, with a post-processing of the recorded video. A final experimental evaluation is done in real-time with a hardware architecture based on a Raspberry Pi.},
  archive      = {J_TROB},
  author       = {Sergio Galeani and Laura Menini and Corrado Possieri and Antonio Tornambe},
  doi          = {10.1109/TRO.2024.3359537},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1758-1773},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Parameter estimation of nonsmooth frictionless impacts through a hybrid observer},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CineMPC: A fully autonomous drone cinematography system
incorporating zoom, focus, pose, and scene composition. <em>TROB</em>,
<em>40</em>, 1740–1757. (<a
href="https://doi.org/10.1109/TRO.2024.3353550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present CineMPC, a complete cinematographic system that autonomously controls a drone to film multiple targets recording user-specified aesthetic objectives. Existing solutions in autonomous cinematography control only the camera extrinsics, namely, its position and orientation. In contrast, CineMPC is the first solution that includes the camera intrinsic parameters in the control loop, which are essential tools for controlling cinematographic effects such as focus, depth of field, and zoom. The system estimates the relative poses between the targets and the camera from an RGB-D image and optimizes a trajectory for the extrinsic and intrinsic camera parameters to film the artistic and technical requirements specified by the user. The drone and the camera are controlled in a nonlinear model predicted control (MPC) loop by reoptimizing the trajectory at each time step in response to current conditions in the scene. The perception system of CineMPC can track the targets&#39; position and orientation despite the camera effects. Experiments in a photo-realistic simulation and with a real platform demonstrate the capabilities of the system to achieve a full array of cinematographic effects that are not possible without the control of the intrinsics of the camera. Code for CineMPC is implemented following a modular architecture in ROS and released to the community.},
  archive      = {J_TROB},
  author       = {Pablo Pueyo and Juan Dendarieta and Eduardo Montijano and Ana Cristina Murillo and Mac Schwager},
  doi          = {10.1109/TRO.2024.3353550},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1740-1757},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CineMPC: A fully autonomous drone cinematography system incorporating zoom, focus, pose, and scene composition},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A distributed outmost push approach for multirobot herding.
<em>TROB</em>, <em>40</em>, 1706–1723. (<a
href="https://doi.org/10.1109/TRO.2024.3359528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a distributed control strategy for herding groups of evaders toward a predefined goal region using a team of robotic herders. In herding problems, evaders tend to move away from each other to increase their coverage regions. This makes it challenging to develop control solutions since the wandering evaders need to be collected while driving the herd. To address this, we propose the distributed outmost push strategy, where each robotic herder pushes the evader that is farthest from the goal region. The intuition behind this strategy is that robotic herders should focus on evaders that are further from the goal region as they are more likely to be missed during the herding process. The outmost evaders are selected from the local field of view, and the robotic herders make decisions in a decentralized manner. We also analyze the convergence of the designed dynamics and the minimum sensing range required for herders. The proposal&#39;s effectiveness and generality are validated through numerical simulations and real robotic experiments.},
  archive      = {J_TROB},
  author       = {Shuai Zhang and Xiaokang Lei and Mengyuan Duan and Xingguang Peng and Jia Pan},
  doi          = {10.1109/TRO.2024.3359528},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1706-1723},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A distributed outmost push approach for multirobot herding},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Line coverage with multiple robots: Algorithms and
experiments. <em>TROB</em>, <em>40</em>, 1664–1683. (<a
href="https://doi.org/10.1109/TRO.2024.3355802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The line coverage problem involves finding efficient routes for the coverage of linear features by one or more resource-constrained robots. Linear features model environments such as road networks, power lines, and oil and gas pipelines. Two modes of travel are defined for robots: servicing and deadheading. A robot services a feature if it performs task-specific actions, such as taking images, as it traverses the feature; otherwise, it is deadheading. Traversing the environment incurs costs (e.g., travel time) and resource demands (e.g., battery life). Servicing and deadheading can have different cost and demand functions, which can be direction dependent. The environment is modeled as a graph, and an integer linear program is presented. As the problem is NP-hard, we design a fast and efficient heuristic algorithm, Merge-Embed-Merge (MEM). Exploiting the constructive property of the MEM algorithm, algorithms for line coverage of large graphs with multiple depots are developed. Furthermore, turning costs and nonholonomic constraints are efficiently incorporated into the algorithm. The algorithms are benchmarked on 100 road networks and demonstrated in experiments with aerial robots.},
  archive      = {J_TROB},
  author       = {Saurav Agarwal and Srinivas Akella},
  doi          = {10.1109/TRO.2024.3355802},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1664-1683},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Line coverage with multiple robots: Algorithms and experiments},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design, modeling, and control of a coaxial drone.
<em>TROB</em>, <em>40</em>, 1650–1663. (<a
href="https://doi.org/10.1109/TRO.2024.3354161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various quadrotor drones have been developed in recent years, mainly focusing on either improving maximum thrust per platform area or flight maneuverability. Evidently, achieving both advantages simultaneously is a challenging task, since they call for opposing rotor requirements. Specifically, improving the drone&#39;s maximum thrust per platform area mainly requires reducing the number of rotors to make way for larger and more powerful rotors. While this can be an effective method to increase overall thrust, improving flight maneuverability requires a greater number of rotors to generate larger rotating torques or to increase the thrust vectoring capability. To address this challenge, we design a novel coaxial drone with two contra-rotating rotors for high thrust efficiency while enabling independent dual-axis rotor rotation to maintain maneuverability along the roll and pitch axes. The thrust vectoring capability is provided by two dedicated servomotors connected vertically in series with the coaxial propellers to produce a compact and elongated fuselage frame. A nonlinear flight model in six degrees of freedom is developed for the underactuated system, incorporating four control inputs from the two propellers and servos, respectively. Consequently, a nonlinear control allocation approach is proposed such that the drone can produce a desired control force and yaw torque to stabilize the drone&#39;s position and yaw angle. For the uncontrolled roll and pitch dynamics, a damping component is added such that the roll and pitch angular velocities can also be stabilized. Both numerical simulations and real experiments are conducted to validate the design of the drone and the effectiveness of the proposed control strategy.},
  archive      = {J_TROB},
  author       = {Liangming Chen and Jiaping Xiao and Yumin Zheng and N Arun Alagappan and Mir Feroskhan},
  doi          = {10.1109/TRO.2024.3354161},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1650-1663},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Design, modeling, and control of a coaxial drone},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CS-BRM: A probabilistic RoadMap for consistent belief space
planning with reachability guarantees. <em>TROB</em>, <em>40</em>,
1630–1649. (<a href="https://doi.org/10.1109/TRO.2024.3355375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new belief space planning algorithm, called covariance steering belief roadmap (CS-BRM), is introduced, analyzed, and numerically and experimentally tested. CS-BRM is a multiquery algorithm for motion planning for dynamical systems under simultaneous motion and observation uncertainties. CS-BRM extends the probabilistic roadmap approach to belief spaces based on the recently developed theory of covariance steering (CS) that enables guaranteed satisfaction of terminal belief constraints in finite time. The nodes in the CS-BRM are sampled in the belief space and represent distributions of the system states. A covariance steering controller steers the system from one BRM node to another, thus acting as an edge controller of the corresponding belief graph that ensures belief constraint satisfaction. After the edge controller is computed, a specific edge cost is assigned to that edge. The CS-BRM algorithm allows the sampling of nonstationary belief nodes, and thus, is able to explore the velocity space and find much more efficient trajectories than previous BRM methods. The performance of CS-BRM is evaluated and compared to previous belief space planning approaches using several numerical examples and experimental demonstrations, illustrating the benefits of the proposed approach.},
  archive      = {J_TROB},
  author       = {Dongliang Zheng and Jack Ridderhof and Zhiyuan Zhang and Panagiotis Tsiotras and Ali-Akbar Agha-Mohammadi},
  doi          = {10.1109/TRO.2024.3355375},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1630-1649},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CS-BRM: A probabilistic RoadMap for consistent belief space planning with reachability guarantees},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast contact-implicit model predictive control.
<em>TROB</em>, <em>40</em>, 1617–1629. (<a
href="https://doi.org/10.1109/TRO.2024.3351554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a general approach for controlling robotic systems that make and break contact with their environments. Contact-implicit model predictive control (CI-MPC) generalizes linear MPC to contact-rich settings by utilizing a bilevel planning formulation with lower level contact dynamics formulated as time-varying linear complementarity problems (LCPs) computed using strategic Taylor approximations about a reference trajectory. These dynamics enable the upper level planning problem to reason about contact timing and forces, and generate entirely new contact-mode sequences online. To achieve reliable and fast numerical convergence, we devise a structure-exploiting interior-point solver for these LCP contact dynamics and a custom trajectory optimizer for the tracking problem. We demonstrate real-time solution rates for CI-MPC and the ability to generate and track nonperiodic behaviors in hardware experiments on a quadrupedal robot. We also show that the controller is robust to model mismatch and can respond to disturbances by discovering and exploiting new contact modes across a variety of robotic systems in simulation, including a pushbot, planar hopper, planar quadruped, and planar biped.},
  archive      = {J_TROB},
  author       = {Simon Le Cleac&#39;h and Taylor A. Howell and Shuo Yang and Chi-Yen Lee and John Zhang and Arun Bishop and Mac Schwager and Zachary Manchester},
  doi          = {10.1109/TRO.2024.3351554},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1617-1629},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Fast contact-implicit model predictive control},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-modal semidense 6-DOF tracking of an event camera in
challenging conditions. <em>TROB</em>, <em>40</em>, 1600–1616. (<a
href="https://doi.org/10.1109/TRO.2024.3355370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based localization is a cost-effective and, thus, attractive solution for many intelligent mobile platforms. However, its accuracy and especially robustness still suffer from low illumination conditions, illumination changes, and aggressive motion. Event-based cameras are bio-inspired visual sensors that perform well in high dynamic range conditions and have high-temporal resolution, and thus, provide an interesting alternative in such challenging scenarios. While purely event-based solutions currently do not yet produce satisfying mapping results, the present work demonstrates the feasibility of purely event-based tracking if an alternative sensor is permitted for mapping. The method relies on geometric 3-D–2-D registration of semidense maps and events, and achieves highly reliable and accurate cross-modal tracking results. Practically relevant scenarios are given by depth camera-supported tracking or map-based localization with a semidense map prior created by a regular image-based visual SLAM or structure-from-motion system. Conventional edge-based 3-D–2-D alignment is extended by a novel polarity-aware registration that makes use of signed time-surface maps obtained from event streams. We, furthermore, introduce a novel culling strategy for occluded points. Both modifications increase the speed of the tracker and its robustness against occlusions or large view-point variations. The approach is validated on many real datasets covering the abovementioned challenging conditions, and compared against similar solutions realized with regular cameras.},
  archive      = {J_TROB},
  author       = {Yi-Fan Zuo and Wanting Xu and Xia Wang and Yifu Wang and Laurent Kneip},
  doi          = {10.1109/TRO.2024.3355370},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1600-1616},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Cross-modal semidense 6-DOF tracking of an event camera in challenging conditions},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BTC: A binary and triangle combined descriptor for 3-d place
recognition. <em>TROB</em>, <em>40</em>, 1580–1599. (<a
href="https://doi.org/10.1109/TRO.2024.3353076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and robust place recognition is essential for robot navigation, yet achieving full pose invariance and high performance across diverse scenes remains challenging. In this work, we propose a novel global and local combined descriptor named binary triangle combined (BTC) descriptor. We first extract the keypoints of a point cloud by projecting the points to planes extracted therein. Any three keypoints form a unique triangle, with the lengths of its sides constituting a triangle descriptor that captures the global appearance of the point cloud. Thanks to the distinct shape of a triangle given three side lengths, the similarity between two triangles and their vertices (i.e., keypoints) correspondence can be naturally determined from the side lengths of the triangle descriptors. The matched triangle pairs evaluate the appearance similarity between two point clouds, while the vertices’ correspondence enables accurate estimation of their relative pose; both are crucial for the place recognition task. To enhance the accuracy of triangle matching, BTC introduces a binary descriptor, which describes the point distribution neighboring each keypoint. The local geometry information encoded by the binary descriptor augments descriptiveness and discriminativeness to the triangle descriptor. Collectively, the two descriptors achieve both global and local descriptions of the environment with high accuracy, efficiency, and robustness. We extensively compare the proposed BTC descriptor against state-of-the-art methods (e.g., Scan Context, LCD-Net) on a wide range of datasets collected using different types of LiDAR sensors (spinning LiDARs and nonrepetitive scanning LiDARs) in various environments (urban, campus, forest, park, and mountain). The quantitative results demonstrate that BTC exhibits greater adaptability and significant improvement in precision compared to its counterparts, especially in challenging cases with large viewpoint variations (e.g., reverse direction, large translation, and/or rotation).},
  archive      = {J_TROB},
  author       = {Chongjian Yuan and Jiarong Lin and Zheng Liu and Hairuo Wei and Xiaoping Hong and Fu Zhang},
  doi          = {10.1109/TRO.2024.3353076},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1580-1599},
  shortjournal = {IEEE Trans. Robot.},
  title        = {BTC: A binary and triangle combined descriptor for 3-D place recognition},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attribute-based robotic grasping with data-efficient
adaptation. <em>TROB</em>, <em>40</em>, 1566–1579. (<a
href="https://doi.org/10.1109/TRO.2024.3353484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic grasping is one of the most fundamental robotic manipulation tasks and has been the subject of extensive research. However, swiftly teaching a robot to grasp a novel target object in clutter remains challenging. This article attempts to address the challenge by leveraging object attributes that facilitate recognition, grasping, and rapid adaptation to new domains. In this work, we present an end-to-end encoder–decoder network to learn attribute-based robotic grasping with data-efficient adaptation capability. We first pretrain the end-to-end model with a variety of basic objects to learn generic attribute representation for recognition and grasping. Our approach fuses the embeddings of a workspace image and a query text using a gated-attention mechanism and learns to predict instance grasping affordances. To train the joint embedding space of visual and textual attributes, the robot utilizes object persistence before and after grasping. Our model is self-supervised in a simulation that only uses basic objects of various colors and shapes but generalizes to novel objects in new environments. To further facilitate generalization, we propose two adaptation methods, adversarial adaption and one-grasp adaptation. Adversarial adaptation regulates the image encoder using augmented data of unlabeled images, whereas one-grasp adaptation updates the overall end-to-end model using augmented data from one grasp trial. Both adaptation methods are data-efficient and considerably improve instance grasping performance. Experimental results in both simulation and the real world demonstrate that our approach achieves over 81% instance grasping success rate on unknown objects, which outperforms several baselines by large margins.},
  archive      = {J_TROB},
  author       = {Yang Yang and Houjian Yu and Xibai Lou and Yuanhao Liu and Changhyun Choi},
  doi          = {10.1109/TRO.2024.3353484},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1566-1579},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Attribute-based robotic grasping with data-efficient adaptation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). General-purpose Sim2Real protocol for learning contact-rich
manipulation with marker-based visuotactile sensors. <em>TROB</em>,
<em>40</em>, 1509–1526. (<a
href="https://doi.org/10.1109/TRO.2024.3352969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visuotactile sensors can provide rich contact information, having great potential in contact-rich manipulation tasks with reinforcement learning (RL) policies. Sim2Real technique tackles the challenge of RL&#39;s reliance on a large amount of interaction data. However, most Sim2Real methods for manipulation tasks with visuotactile sensors rely on rigid-body physics simulation, which fails to simulate the real elastic deformation precisely. Moreover, these methods do not exploit the characteristic of tactile signals for designing the network architecture. In this article, we build a general-purpose Sim2Real protocol for manipulation policy learning with marker-based visuotactile sensors. To improve the simulation fidelity, we employ an FEM-based physics simulator that can simulate the sensor deformation accurately and stably for arbitrary geometries. We further propose a novel tactile feature extraction network that directly processes the set of pixel coordinates of tactile sensor markers and a self-supervised pretraining strategy to improve the efficiency and generalizability of RL policies. We conduct extensive Sim2Real experiments on the peg-in-hole task to validate the effectiveness of our method. And we further show its generalizability on additional tasks including plug adjustment and lock opening. The protocol, including the simulator and the policy learning framework, will be open-sourced for community usage.},
  archive      = {J_TROB},
  author       = {Weihang Chen and Jing Xu and Fanbo Xiang and Xiaodi Yuan and Hao Su and Rui Chen},
  doi          = {10.1109/TRO.2024.3352969},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1509-1526},
  shortjournal = {IEEE Trans. Robot.},
  title        = {General-purpose Sim2Real protocol for learning contact-rich manipulation with marker-based visuotactile sensors},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Body contact estimation of continuum robots with
tension-profile sensing of actuation fibers. <em>TROB</em>, <em>40</em>,
1492–1508. (<a href="https://doi.org/10.1109/TRO.2024.3354171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cable-driven continuum robots are widely used for endoluminal intervention because of their dexterity and shape conforming steerability. However, body contact between the continuum robot and its surrounding anatomy is unavoidable, which imposes a potential safety risk, including vessel wall damage or even perforation. This article presents an approach for body contact estimation of continuum robots with tension-profile sensing of actuation fibers. First, tension-sensing optical fibers with multiple inscribed fiber Bragg grating sensors are used for both actuation and in-situ sensing of the continuum robot. Second, a beam theory-based mechanical model considering segmental differences, multiple fiber interactions, and external force interactions is established, followed by robust estimation of contact positions and forces. Finally, detailed simulations are conducted to validate the accuracy and effectiveness of the proposed method. Experiments on a notched continuum robot are carried out, and the results show that the proposed approach can effectively recover in-situ segmental actuation forces without the need of explicit modeling of the friction between the fibers and guiding channels. The method enables the estimation of the number of contact points, as well as contact positions and contact forces along the body of the continuum robot.},
  archive      = {J_TROB},
  author       = {Anzhu Gao and Zecai Lin and Cheng Zhou and Xiaojie Ai and Bidan Huang and Weidong Chen and Guang-Zhong Yang},
  doi          = {10.1109/TRO.2024.3354171},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1492-1508},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Body contact estimation of continuum robots with tension-profile sensing of actuation fibers},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multistage cable routing through hierarchical imitation
learning. <em>TROB</em>, <em>40</em>, 1476–1491. (<a
href="https://doi.org/10.1109/TRO.2024.3353075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of learning to perform multistage robotic manipulation tasks, with applications to cable routing, where the robot must route a cable through a series of clips. This setting presents challenges representative of complex multistage robotic manipulation scenarios: handling deformable objects, closing the loop on visual perception, and handling extended behaviors consisting of multiple steps that must be executed successfully to complete the entire task. In such settings, learning individual primitives for each stage that succeed with a high enough rate to perform a complete temporally extended task is impractical: if each stage must be completed successfully and has a nonnegligible probability of failure, the likelihood of successful completion of the entire task becomes negligible. Therefore, successful controllers for such multistage tasks must be able to recover from failure and compensate for imperfections in low-level controllers by smartly choosing which controllers to trigger at any given time, retrying, or taking corrective action as needed. To this end, we describe an imitation learning system that uses vision-based policies trained from demonstrations at both the lower (motor control) and the upper (sequencing) level, present a system for instantiating this method to learn the cable routing task, and perform evaluations showing great performance in generalizing to very challenging clip placement variations.},
  archive      = {J_TROB},
  author       = {Jianlan Luo and Charles Xu and Xinyang Geng and Gilbert Feng and Kuan Fang and Liam Tan and Stefan Schaal and Sergey Levine},
  doi          = {10.1109/TRO.2024.3353075},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1476-1491},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Multistage cable routing through hierarchical imitation learning},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TerrainMesh: Metric-semantic terrain reconstruction from
aerial images using joint 2-d-3-d learning. <em>TROB</em>, <em>40</em>,
1457–1475. (<a href="https://doi.org/10.1109/TRO.2024.3353073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers outdoor terrain mapping using RGB images obtained from an aerial vehicle. While feature-based localization and mapping techniques deliver real-time vehicle odometry and sparse keypoint depth reconstruction, a dense model of the environment geometry and semantics (vegetation, buildings, etc.) is usually recovered offline with significant computation and storage. This article develops a joint 2-D-3-D learning approach to reconstruct a local metric-semantic mesh at each camera keyframe maintained by a visual odometry algorithm. Given the estimated camera trajectory, the local meshes can be assembled into a global environment model to capture the terrain topology and semantics during online operation. A local mesh is reconstructed using an initialization and refinement stage. In the initialization stage, we estimate the mesh vertex elevation by solving a least squares problem relating the vertex barycentric coordinates to the sparse keypoint depth measurements. In the refinement stage, we associate 2-D image and semantic features with the 3-D mesh vertices using camera projection and apply graph convolution to refine the mesh vertex spatial coordinates and semantic features based on joint 2-D and 3-D supervision. Quantitative and qualitative evaluation using real aerial images show the potential of our method to support environmental monitoring and surveillance applications.},
  archive      = {J_TROB},
  author       = {Qiaojun Feng and Nikolay Atanasov},
  doi          = {10.1109/TRO.2024.3353073},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1457-1475},
  shortjournal = {IEEE Trans. Robot.},
  title        = {TerrainMesh: Metric-semantic terrain reconstruction from aerial images using joint 2-D-3-D learning},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multivehicle perimeter defense in conical environments.
<em>TROB</em>, <em>40</em>, 1439–1456. (<a
href="https://doi.org/10.1109/TRO.2024.3351556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider a perimeter defense problem in a planar conical environment in which $M$ identical vehicles, each having a finite capture radius, seek to defend a concentric perimeter from mobile intruders. The intruders are released at the circumference of the environment at arbitrary times and in any number. Upon release, each intruder moves radially toward the perimeter with fixed speed. We provide a worst-case analysis of this problem. Specifically, we present a competitive analysis approach to this problem by measuring the performance of decentralized and cooperative online algorithms for the vehicles against arbitrary inputs, relative to an optimal offline algorithm that has information about entire intruder release sequence in advance. We first establish a necessary condition on the problem parameters that guarantees finite competitiveness of any algorithm. We then design and analyze three decentralized and two cooperative online algorithms and characterize parameter regimes in which they have finite competitive ratios. Specifically, our first two decentralized algorithms are provably 1 and 2-competitive, respectively, whereas our third decentralized algorithm exhibits different competitive ratios in different regimes of problem parameters. Our first cooperative algorithm is 1.5-competitive and our second cooperative algorithm exhibits different competitive ratios in different regimes of problem parameters. Finally, we provide multiple numerical plots in the parameter space to reveal additional insights into the relative performance of our algorithms and discuss an extension to the case of heterogeneous vehicles.},
  archive      = {J_TROB},
  author       = {Shivam Bajaj and Shaunak D. Bopardikar and Eric Torng and Alexander Von Moll and David W. Casbeer},
  doi          = {10.1109/TRO.2024.3351556},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1439-1456},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Multivehicle perimeter defense in conical environments},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of bioinspired multimodal underwater robot
“HERO-BLUE” for walking, swimming, and crawling. <em>TROB</em>,
<em>40</em>, 1421–1438. (<a
href="https://doi.org/10.1109/TRO.2024.3353040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel hybrid underwater robot platform, Hazardous and Extreme environment RObot for Biomimetic multilocomotion-based Underwater Expedition (HERO-BLUE) that integrates swimming and legged motions. HERO-BLUE is equipped with a multimodal fin comprising numerous passive joints that can act as both a swimming fin and a walking limb. This multimodal fin is integrated with a salamander-like spine and soft undulating fin in a single robot system to enable three representative locomotion modes: swimming, walking, and crawling. This article provides details of the hardware configuration of HERO-BLUE, mathematical models for each locomotion mode, motion planning methodology, and control strategies for enabling hybrid motions. For legged motions, a dynamic simulation study was conducted to analyze the ground reaction force. The results verified the effectiveness of the proposed multimodal fin. In water tank experiments, the swimming capability was validated through thrust tests and swimming trials, and the legged motion capability was quantitatively validated in three environments, including gravel, water flow, and slopes. Furthermore, field trials were conducted in real-life scenarios in open seas, lakes, and stream beds. The experimental results show that HERO-BLUE can successively combine swimming and legged motion capability and increase underwater mobility in various challenging underwater environments.},
  archive      = {J_TROB},
  author       = {Taesik Kim and Juhwan Kim and Son-Cheol Yu},
  doi          = {10.1109/TRO.2024.3353040},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1421-1438},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Development of bioinspired multimodal underwater robot “HERO-BLUE” for walking, swimming, and crawling},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uni-fusion: Universal continuous mapping. <em>TROB</em>,
<em>40</em>, 1373–1392. (<a
href="https://doi.org/10.1109/TRO.2024.3351548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Uni-Fusion, a universal continuous mapping framework for surfaces, surface properties (color, infrared, etc.) and more (latent features in contrastive language-image pretraining (CLIP) embedding space, etc.). We propose the first universal implicit encoding model that supports encoding of both geometry and different types of properties (RGB, infrared, features, etc.) without requiring any training. Based on this, our framework divides the point cloud into regular grid voxels and generates a latent feature in each voxel to form a latent implicit map (LIM) for geometries and arbitrary properties. Then, by fusing a local LIM frame-wisely into a global LIM, an incremental reconstruction is achieved. Encoded with corresponding types of data, our LIM is capable of generating continuous surfaces, surface property fields, surface feature fields, and all other possible options. To demonstrate the capabilities of our model, we implement three applications: incremental reconstruction for surfaces and color, 2-D-to-3-D transfer of fabricated properties, and open-vocabulary scene understanding by creating a text CLIP feature field on surfaces. We evaluate Uni-Fusion by comparing it in corresponding applications, from which Uni-Fusion shows high-flexibility in various applications while performing best or being competitive.},
  archive      = {J_TROB},
  author       = {Yijun Yuan and Andreas Nüchter},
  doi          = {10.1109/TRO.2024.3351548},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1373-1392},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Uni-fusion: Universal continuous mapping},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GMMap: Memory-efficient continuous occupancy map using
gaussian mixture model. <em>TROB</em>, <em>40</em>, 1339–1355. (<a
href="https://doi.org/10.1109/TRO.2023.3348305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy consumption of memory accesses dominates the compute energy in energy-constrained robots, which require a compact 3-D map of the environment to achieve autonomy. Recent mapping frameworks only focused on reducing the map size while incurring significant memory usage during map construction due to the multipass processing of each depth image. In this work, we present a memory-efficient continuous occupancy map, named GMMap, that accurately models the 3-D environment using a Gaussian mixture model (GMM). Memory-efficient GMMap construction is enabled by the single-pass compression of depth images into local GMMs, which are directly fused together into a globally-consistent map. By extending Gaussian Mixture Regression (GMR) to model unexplored regions, occupancy probability is directly computed from Gaussians. Using a low-power ARM Cortex A57 CPU, GMMap can be constructed in real time at up to 60 images/s. Compared with prior works, GMMap maintains high accuracy while reducing the map size by at least 56%, memory overhead by at least 88%, dynamic random-access memory (DRAM) access by at least 78%, and energy consumption by at least 69%. Thus, GMMap enables real-time 3-D mapping on energy-constrained robots.},
  archive      = {J_TROB},
  author       = {Peter Zhi Xuan Li and Sertac Karaman and Vivienne Sze},
  doi          = {10.1109/TRO.2023.3348305},
  journal      = {IEEE Transactions on Robotics},
  month        = {1},
  pages        = {1339-1355},
  shortjournal = {IEEE Trans. Robot.},
  title        = {GMMap: Memory-efficient continuous occupancy map using gaussian mixture model},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
