<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TCSS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tcss---654">TCSS - 654</h2>
<ul>
<li><details>
<summary>
(2024). Unveiling the evolution of enterprise digital innovation
strategies: Insights from u.s.-listed companies’ annual reports.
<em>TCSS</em>, <em>11</em>(6), 8243–8256. (<a
href="https://doi.org/10.1109/TCSS.2024.3360040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a new metric for evaluating digital innovation in enterprise transformation using textual analysis of annual reports from U.S.-listed companies. Through network analysis and topic modeling, we identified 12 topics categorized into three main areas: digital technology innovation, customer-oriented digital strategy, and digital transformation in traditional business operations. Our research indicates that digital innovation strategies are critical for maintaining competitiveness and have shifted to a more innovation management-oriented approach. We also found differences in digital innovation strategies between companies and industries. Our study contributes to the theoretical significance of enterprise management and sustainable development.},
  archive      = {J_TCSS},
  author       = {Shizhen Bai and Yongbo Tan and Chunjia Han and Mu Yang and Brij B. Gupta and Varsha Arya and Neeraj Kumar},
  doi          = {10.1109/TCSS.2024.3360040},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8243-8256},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Unveiling the evolution of enterprise digital innovation strategies: Insights from U.S.-listed companies&#39; annual reports},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Socially governed energy hub trading enabled by
blockchain-based transactions. <em>TCSS</em>, <em>11</em>(6), 8227–8242.
(<a href="https://doi.org/10.1109/TCSS.2023.3308608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized trading schemes involving energy prosumers have prevailed in recent years. Such schemes provide a pathway for increased energy efficiency and can be enhanced by the use of blockchain technology to address security concerns in decentralized trading. To improve transaction security and privacy protection while ensuring desirable social governance, this article proposes a novel two-stage blockchain-based operation and trading mechanism to enhance energy hubs connected with integrated energy systems (IESs). This mechanism includes multienergy aggregators (MAGs) that use a consortium blockchain and its enabled proof-of-work (PoW) to transfer and audit transaction records, with social governance principles for guiding prosumers’ decision-making in the peer-to-peer (P2P) transaction management process. The uncertain nature of renewable generation and load demand are adequately modeled in the two-stage Wasserstein-based distributionally robust optimization (DRO). The practicality of the proposed mechanism is illustrated by several case studies that jointly show its ability to handle an increased renewable generation capacity, achieve a 16.7% saving in the audit cost, and facilitate 2.4% more P2P interactions. Overall, the proposed two-stage blockchain-based trading mechanism provides a practical trading scheme and can reduce redundant trading amounts by 6.5%, leading to a further reduction of the overall operation cost. Compared to the state-of-the-art benchmark methods, our mechanism exhibits significant operation cost reduction and ensures social governance and transaction security for IES and energy hubs.},
  archive      = {J_TCSS},
  author       = {Pengfei Zhao and Shuangqi Li and Zhidong Cao and Paul Jen-Hwa Hu and Chenghong Gu and Xiaohe Yan and Da Huo and Tianyi Luo and Zikang Wang},
  doi          = {10.1109/TCSS.2023.3308608},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8227-8242},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Socially governed energy hub trading enabled by blockchain-based transactions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ICT governance practices and industry 4.0 technologies in
support of decision-making in brazilian smart cities in the face of the
COVID-19 pandemic. <em>TCSS</em>, <em>11</em>(6), 8213–8226. (<a
href="https://doi.org/10.1109/TCSS.2023.3306707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facing uncertainty catalyzed by the COVID-19 pandemic, the decision-making of information and communication technology (ICT) managers in smart cities has become essential for technological development. This exploratory study describes the effects of ICT governance practices and the use of Industry 4.0 technologies on the decision-making of technology managers in Brazilian cities considered smart in the face of the COVID-19 pandemic. To this end, 39 municipalities were selected based on classifications of Brazilian smart cities, and data were collected through the electronic citizen service system and a survey application. It identified the use of the Information Technology Infrastructure Library (ITIL) and the ICT Master Plan (PDTIC) as the cities’ ICT governance practices. Regarding Industry 4.0 technologies, the use of business intelligence (BI), cloud computing (CC), and open data was verified. Furthermore, the need to develop a planning culture and the need for internal training of professionals in the face of new technological resources emerged. The results showed that ICT governance practices and Industry 4.0 technologies have positive effects if used holistically according to the alignment with the municipality’s strategic objectives. The senior management of municipalities must see the importance of making constant investments in infrastructure and the technical capacity of professionals to achieve greater effectiveness in the use of technological resources.},
  archive      = {J_TCSS},
  author       = {Jalisson Tavares Costa and Rogério Patrício Chagas do Nascimento},
  doi          = {10.1109/TCSS.2023.3306707},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8213-8226},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {ICT governance practices and industry 4.0 technologies in support of decision-making in brazilian smart cities in the face of the COVID-19 pandemic},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A dark side of trust: Examining the influence of
environmental risk perception on citizens’ plastic-avoiding behavior.
<em>TCSS</em>, <em>11</em>(6), 8204–8212. (<a
href="https://doi.org/10.1109/TCSS.2023.3297747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the influencing dynamics of environmental risk perception on plastic-avoiding behavior by incorporating government trust and environmental locus of control within the influencing structure. Via an online survey, this study received 1126 valid responses and used partial least square-based structural equation modeling (PLS-SEM) techniques for data analysis. Three major findings are obtained. First, environmental risk perception positively impacts people’s plastic-avoiding behavior. Second, this relationship is partially mediated by environmental locus of control. Finally, government trust moderates the impact of environmental risk perception on both the environmental locus of control and plastic-avoiding behavior. When government trust is higher (lower), environmental risk perception has less (more) influence on the environmental locus of control and plastic-avoiding behavior. Therefore, absolute high government trust is far from ideal in environmental management because it induces high government dependence, which stimulates people’s “inertia” and makes them shirk their responsibilities for environmental protection. To reduce the dark side of government trust, it is suggested that the government shows some “weakness” and emphasizes its need for the public’s support for plastic crisis management.},
  archive      = {J_TCSS},
  author       = {Bairong Wang and Bin Liu and Yong Li},
  doi          = {10.1109/TCSS.2023.3297747},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8204-8212},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A dark side of trust: Examining the influence of environmental risk perception on citizens’ plastic-avoiding behavior},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Auditable federated learning with byzantine robustness.
<em>TCSS</em>, <em>11</em>(6), 8191–8203. (<a
href="https://doi.org/10.1109/TCSS.2023.3266019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) has led to disruptive innovations in many fields, such as medical diagnoses. A key enabler for ML is large training data, but existing data, such as medical data, are not fully exploited by ML because of data silos and privacy concerns. Federated learning (FL) is a promising distributed learning paradigm to address this problem. On the other hand, existing FL approaches are vulnerable to poisoning attacks or privacy leakage from a malicious aggregator or client. This article proposes an auditable FL scheme with Byzantine robustness against the aggregator and client: The aggregator is malicious but available, and the client could perform poisoning attacks. First, the Pedersen commitment scheme (PCS) for homomorphic encryption was applied to preserve privacy and for commitments to the FL process to achieve auditability. The auditability enables clients to verify the correctness and consistency of the entire FL process and to identify parties that misbehave. Second, an efficient technique of divide and conquer was designed based on PCS to allow parties to cooperate and securely aggregate gradients to defend against poisoning attacks. This technique enables clients to share no common secret key and cooperate to decrypt ciphertext, guaranteeing a client’s privacy even if some other clients are corrupted by adversaries. This technique was optimized to tolerate the dropout of clients. This article reports a formal analysis concerning privacy, efficiency, and auditability against malicious participants. Extensive experiments on various benchmark datasets show that the scheme is robust with high model accuracy against poisoning attacks.},
  archive      = {J_TCSS},
  author       = {Yihuai Liang and Yan Li and Byeong-Seok Shin},
  doi          = {10.1109/TCSS.2023.3266019},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8191-8203},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Auditable federated learning with byzantine robustness},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic evolutionary game model of hot topics propagation
for network public opinion. <em>TCSS</em>, <em>11</em>(6), 8178–8190.
(<a href="https://doi.org/10.1109/TCSS.2023.3265020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid propagation and significant impact, the network public opinion of hot topics has become a concern of the social public and governments. The existing models based on the evolutionary game cannot reflect the real-world propagation of hot topics under uncertain environmental interference. And few researchers analyze the early intervention timing of the government on hot topics based on stochastic evolutionary game theory. To solve these problems, the government intervention parameters of punishment intensity, intervention delay, and intervention probability are introduced to build a three-party stochastic evolutionary game model of “media-netizen-government” in the multi-agent system under the scene of hot topics propagation. Then, the stochastic differential equation is expanded and simulated by the explicit forward Euler numerical method. Finally, simulation experiments are conducted to quantitatively analyze the random evolutionary process and the government intervention timing by adjusting key parameters, which can provide the optimal timing and suggestions for governments to intervene in hot topics propagation.},
  archive      = {J_TCSS},
  author       = {Hongsong Chen and Xiufeng Zhao},
  doi          = {10.1109/TCSS.2023.3265020},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8178-8190},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Stochastic evolutionary game model of hot topics propagation for network public opinion},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual attributes of thumbnails in predicting YouTube brand
channel views in the marketing digitalization era. <em>TCSS</em>,
<em>11</em>(6), 8169–8177. (<a
href="https://doi.org/10.1109/TCSS.2023.3289410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digitalization has shaped the relationships among companies, consumers, and social participants with the advancements of digital technology. As a result, companies are increasingly adopting and integrating the YouTube system for content dissemination and engagement with their customers and stakeholders. This study proposes a prediction model that analyzes 16 278 image datasets collected from 137 brand channels’ videos with over 100 000 views, generated before September 26, 2022. Using the dataset, we analyze the factors affecting the number of content views of brand channels and construct a view prediction model. This study finds that the characteristics of the thumbnail image, offline top brand characteristics, and channel size (number of subscribers and number of channel videos) significantly influence YouTube’s online channel views. The results of this study provide a strategy for brands to communicate more actively with stakeholders through the YouTube system.},
  archive      = {J_TCSS},
  author       = {Ha Eun Jang and Seung Ho Kim and Jong Seok Jeon and Joo Hee Oh},
  doi          = {10.1109/TCSS.2023.3289410},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8169-8177},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Visual attributes of thumbnails in predicting YouTube brand channel views in the marketing digitalization era},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An NLP-deep learning approach for product rating prediction
based on online reviews and product features. <em>TCSS</em>,
<em>11</em>(6), 8156–8168. (<a
href="https://doi.org/10.1109/TCSS.2023.3290558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on predicting the popularity of a product based on its overall rating score. Unlike previous studies that focus on predicting the review rating based on sentiment analysis and the polarity of the reviews, in this research, the effect of product features in determining its popularity is directly measured and analyzed. To this end, a methodology consisting of three phases is considered. Phase 1 predicts the overall rating by feeding the general product features, extracted from the online product information available on Amazon webpages to three different deep learning (DL) models: deep feedforward neural network (DFFNN), probabilistic neural network (PNN), and radial basis function neural network (RBFNN). Phase 2 identifies other features that customers care about the most by applying the named entity recognition (NER) algorithm to the customer online reviews. Finally, Phase 3 feeds the combination of the general and custom features to the same DL models to predict the overall rating score of the product. The experimental results on a dataset of laptop products indicate an impressive performance of the proposed approach, which is mainly attributed to including custom product features in the inputs of the DL algorithm. More precisely, the proposed model could achieve the highest accuracy score of 84.01%, 84.68% for recall, 87.63% for precision, and 84.06% for F1 score. Applying this procedure could help businesses identify the specific areas of strengths and weaknesses of their products or services from the perspective of their customers, allowing them to thrive in today’s competitive markets.},
  archive      = {J_TCSS},
  author       = {Tolou Amirifar and Salim Lahmiri and Masoumeh Kazemi Zanjani},
  doi          = {10.1109/TCSS.2023.3290558},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8156-8168},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An NLP-deep learning approach for product rating prediction based on online reviews and product features},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A categorization of decentralized autonomous organizations:
The case of the aragon platform. <em>TCSS</em>, <em>11</em>(6),
8143–8155. (<a href="https://doi.org/10.1109/TCSS.2023.3299254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of blockchain technology has paved the way for numerous innovations in online governance, with decentralized autonomous organizations (DAOs) emerging as a prominent development, often referred to as “digital jurisdictions.” Despite experiencing remarkable growth, currently boasting nearly 7M users and ${\$}$ 18 billion in assets, DAOs remain relatively underexplored in the existing literature, particularly from an empirical perspective. This study presents a comprehensive framework comprising 15 dimensions to categorize DAOs based on their operational domain, purpose, scope, voting process, and utilization of crypto-tokens. By applying this categorization schema to 40 DAO communities hosted on the Aragon platform, encompassing over 423 000 participants and managing treasuries worth ${\$}$ 960M, we shed light on the prevailing characteristics of these DAOs. Contrary to assertions made by blockchain enthusiasts, our analysis reveals that DAOs predominantly operate in financial and technological domains, primarily offering blockchain-based services. Additionally, our investigation into their governance structure exposes limitations in terms of democratic participation, as decision-making power typically correlates with the number of tokens owned by the voter, resembling plutocracies rather than true democracies. We believe these findings will facilitate researchers’ comprehension of this innovative form of governance and aid practitioners in designing future DAOs with greater effectiveness. Furthermore, our analysis can be replicated on other platforms or at different time periods to validate and contrast our conclusions.},
  archive      = {J_TCSS},
  author       = {Andrea Peña-Calvin and Jorge Saldivar and Javier Arroyo and Samer Hassan},
  doi          = {10.1109/TCSS.2023.3299254},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8143-8155},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A categorization of decentralized autonomous organizations: The case of the aragon platform},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving the transferability of adversarial attacks on face
recognition with beneficial perturbation feature augmentation.
<em>TCSS</em>, <em>11</em>(6), 8130–8142. (<a
href="https://doi.org/10.1109/TCSS.2023.3291565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition (FR) models can be easily fooled by adversarial examples, which are crafted by adding imperceptible perturbations on benign face images. The existence of adversarial face examples poses a great threat to the security of society. To build a more sustainable digital nation, in this article, we improve the transferability of adversarial face examples to expose more blind spots of the existing FR models. Though generating hard samples has shown its effectiveness in improving the generalization of models in training tasks, the effectiveness of using this idea to improve the transferability of adversarial face examples remains unexplored. To this end, based on the property of hard samples and the symmetry between training tasks and adversarial attack tasks, we propose the concept of hard models, which have similar effects as hard samples for adversarial attack tasks. Using the concept of hard models, we propose a novel attack method called beneficial perturbation feature augmentation attack (BPFA), which reduces the overfitting of adversarial examples to surrogate FR models by constantly generating new hard models to craft the adversarial examples. Specifically, in the backpropagation, BPFA records the gradients on preselected feature maps and uses the gradient on the input image to craft the adversarial example. In the next forward propagation, BPFA leverages the recorded gradients to add beneficial perturbations on their corresponding feature maps to increase the loss. Extensive experiments demonstrate that BPFA can significantly boost the transferability of adversarial attacks on FR.},
  archive      = {J_TCSS},
  author       = {Fengfan Zhou and Hefei Ling and Yuxuan Shi and Jiazhong Chen and Zongyi Li and Ping Li},
  doi          = {10.1109/TCSS.2023.3291565},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8130-8142},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Improving the transferability of adversarial attacks on face recognition with beneficial perturbation feature augmentation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A comparative analysis of centralized and decentralized
developer autonomous organizations managing conflicts in discussing
external crises. <em>TCSS</em>, <em>11</em>(6), 8118–8129. (<a
href="https://doi.org/10.1109/TCSS.2023.3247464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding whether and how online developer communities resolve conflicts that occur in discussions is critical. Few studies focused on the conflicts caused by external crises, such as geopolitical events (e.g., the 2022 Russo-Ukrainian Crisis). We comparatively studied how a decentralized autonomous organization (DAO), Aave project community, and a centralized autonomous organization (CAO), GitHub project community, managed external crises caused by conflicts. Our mixed-method analysis showed that a DAO could be better than a CAO for mitigating conflicts. And blockchain technologies (i.e., voting and cryptocurrency) played vital roles. To address the low voter turnout, we proposed adding a monetary incentive to engage more DAO members in forming common goals.},
  archive      = {J_TCSS},
  author       = {Hongzhou Chen and Wei Cai},
  doi          = {10.1109/TCSS.2023.3247464},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8118-8129},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A comparative analysis of centralized and decentralized developer autonomous organizations managing conflicts in discussing external crises},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multicommodity prices prediction using multivariate
data-driven modeling: Indonesia case. <em>TCSS</em>, <em>11</em>(6),
8106–8117. (<a href="https://doi.org/10.1109/TCSS.2022.3229772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the problems experienced by micro, small, and medium enterprises (MSMEs) during this pandemic is that most MSME actors do not understand plan-making during a crisis. This situation was exacerbated by erratic commodity prices, which resulted in several MSME players choosing to temporarily close because their turnover got a drastic decline. To help MSME actors maintain their business by knowing commodity price predictions, we propose a deep learning model using the long short-term memory (LSTM) method to predict commodity prices in Indonesia. LSTM is a type of recurrent neural network (RNN) with a memory cell to store information and solve the vanishing gradient problem in RNN. Furthermore, multivariate LSTM leverages the model to predict datasets with more than one feature. This study used a dataset collected from the Pusat Informasi Harga Pangan Strategis Nasional (PIHPS Nasional) managed by the Indonesian Ministry of Finance and Bank Indonesia consisting of significantly contributed food commodities to the formation of (strategic) inflation rates in Indonesia. The time range of commodity prices is from August 1, 2017, to July 30, 2021. There are 11 commodity price features in the dataset, namely, rice, chicken meat, eggs, onions, garlic, large red chilies, curly red chilies, red chilies, green chilies, cooking oil, and sugar. The lowest mean absolute error (MAE) on prediction is up to 255.998 obtained by the attention multivariate LSTM model with the Adam optimizer, adding batch normalization (Batchnorm) layer, reducing LSTM layer, hidden size, and grouped features. It makes the prediction more accurate and avoids overfitting and underfitting in this case.},
  archive      = {J_TCSS},
  author       = {Marsellino Prawiro Halim and Novanto Yudistira and Candra Dewi},
  doi          = {10.1109/TCSS.2022.3229772},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8106-8117},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Multicommodity prices prediction using multivariate data-driven modeling: Indonesia case},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Bitcoin address clustering based on change address
improvement. <em>TCSS</em>, <em>11</em>(6), 8094–8105. (<a
href="https://doi.org/10.1109/TCSS.2023.3239031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change address identification is one of the difficulties in bitcoin address clustering as an emerging social computing problem. Most of the current-related research only applies to certain specific types of transactions and faces the problems of low recognition rate and high false positive rate. We innovatively propose a clustering method based on multiconditional recognition of one-time change addresses and conduct experiments with on- chain bitcoin transaction data. The results show that the proposed method identifies at least 12.3% more one-time change addresses than other heuristics. On top of the multi-input heuristic clustering method, the proposed method also improves the address clustering performance by 5.7%, achieves optimal recognition results compared with similar methods, and significantly reduces the false positive rate of recognition results. This work provides the technical basis for antimoney laundering efforts based on entity identification. Code and data could be accessed from https://github.com/ECNU-Cross-Innovation-Lab/BitcoinAddressClustering .},
  archive      = {J_TCSS},
  author       = {Feng Liu and Zhihan Li and Kun Jia and Panwei Xiang and Aimin Zhou and Jiayin Qi and Zhibin Li},
  doi          = {10.1109/TCSS.2023.3239031},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8094-8105},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Bitcoin address clustering based on change address improvement},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The best and sustainable COVID-19 policy in the world.
<em>TCSS</em>, <em>11</em>(6), 8089–8093. (<a
href="https://doi.org/10.1109/TCSS.2022.3227926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article will scientifically evaluate individual COVID-19 policies of countries around the world, U.S. states, and Japanese prefectures, respectively. The efficacy of the vaccines has been reported in many of the world’s top medical journals, but even after more than a year of vaccination, the claims have yet to be met. Human emotions, behaviors, and individual policies can significantly influence the outcome against the pandemic. The evaluation in this article is based on a single determinant of the policy outcome. Scoring policies is based on dividing the number of deaths due to COVID-19 by the population in millions. The lower the score, the better the policy. Unfortunately, scores monotonically increase, so that policymakers can only suppress them but cannot improve or decrease them. Therefore, mistakes by policymakers cannot be corrected in the future and they are fatal forever. The result using three tools will reveal the best COVID-19 policy in the world. The revealed policy should have been or be adopted in individual countries for mitigating and ending the COVID-19 pandemic. This article also suggests what is needed in our society for reducing the unnecessary deaths due to COVID-19.},
  archive      = {J_TCSS},
  author       = {Yoshiyasu Takefuji},
  doi          = {10.1109/TCSS.2022.3227926},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8089-8093},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {The best and sustainable COVID-19 policy in the world},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual neural network for defect detection with highly
imbalanced data in 3-d printing. <em>TCSS</em>, <em>11</em>(6),
8078–8088. (<a href="https://doi.org/10.1109/TCSS.2024.3441524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital light processing (DLP) is a popular additive manufacturing technology that uses light irradiation to fabricate 3-D devices via a projector to achieve laser-sensitive resin curing. However, the performance and reliability of DLP can be affected by internal defects such as printing errors and the accumulation of residual stress. Existing defect detection methods rely on monitoring the printed parts, which leads to resource wastage and struggles to effectively handle imbalanced defect data. In this article, we propose a defect detection method called dual neural network, which involves detecting defects in materials before the printing process to prevent resource wastage and serious consequences. Specifically, to handle the highly imbalanced class distribution problem in online DLP defect detection, dual neural network utilizes a domain learner and balance learner to effectively balance the information of the minority class and learn the generalization knowledge from the imbalanced defect dataset. Experimental results demonstrate the effectiveness of our proposed method, which has also been applied to real-world production equipment successfully.},
  archive      = {J_TCSS},
  author       = {Fang Wang and Gang Xiong and Qihang Fang and Zhen Shen and Di Wang and Xisong Dong and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3441524},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8078-8088},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A dual neural network for defect detection with highly imbalanced data in 3-D printing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Community awareness personalized federated learning for
defect detection. <em>TCSS</em>, <em>11</em>(6), 8064–8077. (<a
href="https://doi.org/10.1109/TCSS.2024.3405556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple organizations in social manufacturing can collaborate on high-quality product defect detection with social networks. Federated learning (FL) is an emerging paradigm where multiple clients can collaboratively train a defect detection model in a privacy-preserving manner. A prevalent issue in FL, concept drift, is discussed in this article. Feature representations of the same label may vary at different clients which affects the performance of FL. To address this issue, a novel community aware personalized federated learning (CA-PFL) is proposed in this article. A graph structured federation social network is constructed with local model updates. Communities in federation network are discovered with community detection to ensure that the same label at different clients have similar representations in each community. Shared layers of local models are aggregated in each community and each local client keeps their personalized layers. Furthermore, a federation community contrastive loss (FedCCL) is proposed to accelerate training convergence by constraining the direction of local model updating. Experimental results on nine datasets demonstrate that CA-PFL achieves higher accuracy and faster convergence than state-of-the-art personalized federated learning methods in concept drifts scenarios.},
  archive      = {J_TCSS},
  author       = {Hongwei Zhao and Qiyuan Liu and Haoyun Sun and Liang Xu and Weishan Zhang and Yikang Zhao and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3405556},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8064-8077},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Community awareness personalized federated learning for defect detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conversational crowdsensing in the age of industry 5.0: A
parallel intelligence and large models powered novel sensing approach.
<em>TCSS</em>, <em>11</em>(6), 8046–8063. (<a
href="https://doi.org/10.1109/TCSS.2024.3451649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transition from cyber-physical-system-based (CPS-based) Industry 4.0 to cyber-physical-social-system-based (CPSS-based) Industry 5.0 brings new requirements and opportunities to current sensing approaches, especially in light of recent progress in large language models (LLMs) and retrieval augmented generation (RAG). Therefore, the advancement of parallel intelligence powered crowdsensing intelligence (CSI) is witnessed, which is currently advancing toward linguistic intelligence. In this article, we propose a novel sensing paradigm, namely conversational crowdsensing, for Industry 5.0 (especially for social manufacturing). It can alleviate workload and professional requirements of individuals and promote the organization and operation of diverse workforce, thereby facilitating faster response and wider popularization of crowdsensing systems. Specifically, we design the architecture of conversational crowdsensing to effectively organize three types of participants (biological, robotic, and digital) from diverse communities. Through three levels of effective conversation (i.e., interhuman, human–AI, and inter-AI), complex interactions and service functionalities of different workers can be achieved to accomplish various tasks across three sensing phases (i.e., requesting, scheduling, and executing). Moreover, we explore the foundational technologies for realizing conversational crowdsensing, encompassing LLM-based multiagent systems, scenarios engineering and conversational human–AI cooperation. Finally, we present potential applications of conversational crowdsensing and discuss its implications. We envision that conversations in natural language will become the primary communication channel during crowdsensing process, enabling richer information exchange and cooperative problem-solving among humans, robots, and AI.},
  archive      = {J_TCSS},
  author       = {Zhengqiu Zhu and Yong Zhao and Sihang Qiu and Kai Xu and Quanjun Yin and Jincai Huang and Zhong Liu and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3451649},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8046-8063},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Conversational crowdsensing in the age of industry 5.0: A parallel intelligence and large models powered novel sensing approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A service-oriented autonomous crane system. <em>TCSS</em>,
<em>11</em>(6), 8030–8045. (<a
href="https://doi.org/10.1109/TCSS.2024.3404395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The servicing of crane systems has been a major problem in the crane business value chain. The crane industry has been exploring well-defined solutions to solve problems on the customer&#39;s site. The service-oriented concept, empowered by artificial intelligence (AI) technology, has shown advantages in addressing issues in manufacturing. In this study, the authors propose a novel crane business model for the crane industry: a service-oriented autonomous crane system, which integrates advanced management concepts and AI-powered technology into the traditional industry-crane system. With the help of the novel business model, the crane industry and customers/users can benefit from an improvement in crane performance, and the model also offers further potential to promote problem-solving in the crane industry on the customer&#39;s site. From the perspective of knowledge development, this study gives a clear description of an intelligent service-oriented crane system. Crane stakeholders can develop their own customized autonomous crane systems based on the novel model with its technical structure. From the perspective of strengthening the crane business, the proposed model provides the foundation for developing smart solutions for the crane industry according to the specific requirements. From the perspective of scenarios applied to large construction machinery, the case study in this article provides a valuable reference for augmenting the servicing of large scale construction machinery.},
  archive      = {J_TCSS},
  author       = {Guangyu Xiong and Petri Helo and Steve Ekström and Zhen Shen},
  doi          = {10.1109/TCSS.2024.3404395},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8030-8045},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A service-oriented autonomous crane system},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Socialized incubator for startup companies: A new paradigm
to construct multilayer industrial ecosystem under the context of social
manufacturing. <em>TCSS</em>, <em>11</em>(6), 8015–8029. (<a
href="https://doi.org/10.1109/TCSS.2024.3439367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An incubator is a kind of public or private organization that can provide multidimensional support to startup companies in exchange for profit or stake sharing. To date, huge numbers of incubators have been established all over the world, and many successful companies have been incubated by them. However, most of the existing incubators are more focused on incubating the target startup companies and pay relatively less attention to promoting the establishment of the supply chain networks and the ecosystems for the startup companies. In this regard, a new kind of socialized incubator model is established. Based on a kind of “Service-Product-Ecosystem” oriented configuration/operation mechanism, the socialized incubator can provide multidimension production services and value-added services during the entire incubation life-cycle of startup companies, transfer startup companies into ready-for-sold products, and construct multilayer vertical industrial ecosystems for the startup companies using socialized manufacturing resources. The socialized incubator model is verified through a case study on incubating a real startup company.},
  archive      = {J_TCSS},
  author       = {Maolin Yang and Pingyu Jiang and Haoliang Shi and Tianshuo Zang and Huanrong Ren and Laiyi Li and Shuwei Zhang},
  doi          = {10.1109/TCSS.2024.3439367},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8015-8029},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Socialized incubator for startup companies: A new paradigm to construct multilayer industrial ecosystem under the context of social manufacturing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ICyberGuard: A FlipIt game for enhanced cybersecurity in
IIoT. <em>TCSS</em>, <em>11</em>(6), 8005–8014. (<a
href="https://doi.org/10.1109/TCSS.2024.3443174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social manufacturing has significantly advanced the industrial Internet of Things (IIoT), integrating information technology and operation technology to enhance production efficiency and quality, and to foster new business models. This integration, however, introduces novel risks, including advanced persistent threats, which demand robust security measures to safeguard IIoT systems. This article proposes an iCyberGuard game model, tailored for IIoT environments, designed to imitate the cyber and physical attacks for information and operation technologies. Then, we used a reinforcement learning algorithm to compute the optimal strategy. We conducted comprehensive simulation experiments, which demonstrate that our model the strategic interactions between attackers and defenders. Participants are enabled to learn adaptively, discerning optimal strategies based on the intelligence of their adversaries. Finally, we explain the practical significance of the best strategy of defenders or attackers, and how users can rely on these best strategies to strengthen the security performance of the network.},
  archive      = {J_TCSS},
  author       = {Xiaoguang Chen and Wenyuan Cao and Lili Chen and Jinpeng Han and Manzhi Yang and Zhen Wang and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3443174},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {8005-8014},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {ICyberGuard: A FlipIt game for enhanced cybersecurity in IIoT},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchain-of-things-based edge learning contracts for
federated predictive maintenance toward resilient manufacturing.
<em>TCSS</em>, <em>11</em>(6), 7990–8004. (<a
href="https://doi.org/10.1109/TCSS.2024.3395467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social manufacturing leverages the power of social networks and collaborative processes to enhance manufacturing capabilities and supports the sharing of ideas, resources, and information. However, traditional remote maintenance under a social manufacturing context lacks resilience against disruptions and cyber attacks. These issues often lead to interruptions in production. This article proposed blockchain-of-things-based edge learning contracts for federated predictive maintenance (FPM). First, given the diversity and heterogeneity of equipment, an open platform communication unified architecture (OPCUA)-based equipment meta-model is proposed to facilitate the interconnection and data sharing. Second, a Blockchain-of-Things-based secure access control approach is proposed, to directly collect data from controllers. This approach prevents tampering, unlike traditional local database collection methods. Third, to address the security and efficiency needs, an edge learning contract method is proposed for FPM. An integrated learning algorithm based on smart contracts is designed to achieve prediction performance that is comparable to local centralized training while reducing data transmission load and enhancing data security. Finally, a federated predictive maintenance platform is designed and implemented to enhance the system&#39;s resilience, and its effectiveness is verified through case studies.},
  archive      = {J_TCSS},
  author       = {Jiewu Leng and Jiwei Guo and Dewen Wang and Yuanwei Zhong and Kailin Xu and Sihan Huang and Jiajun Liu and Chunyang Yu and Zhipeng Ye and Qiang Liu},
  doi          = {10.1109/TCSS.2024.3395467},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7990-8004},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Blockchain-of-things-based edge learning contracts for federated predictive maintenance toward resilient manufacturing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy-social manufacturing for social computing.
<em>TCSS</em>, <em>11</em>(6), 7976–7989. (<a
href="https://doi.org/10.1109/TCSS.2024.3379254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article explores social manufacturing (SM) within cyber–physical–social systems (CPSSs), leveraging artificial intelligence (AI) to revolutionize energy prosumer networks. We introduce a blockchain-enabled operation and management mechanism for energy systems, incorporating energy aggregators for efficient transaction audits and employing consortium blockchain and proof-of-work for enhanced security. Guided by social governance principles and utilizing the soft actor–critic (SAC) approach for handling renewable generation and load demand uncertainties, our method offers a resilient and cost-effective solution. Simulated case studies reveal a 16.7% reduction in audit costs and a 2.4% increase in peer-to-peer transactions, highlighting improved network synergy. Our approach also reduces redundant trading by 6.5% and cuts operational costs by up to 6%, demonstrating the effectiveness of blockchain in improving cost-efficiency and enhancing social governance and security in energy manufacturing systems. The findings of this study contribute a novel vista to the ongoing discourse in SM, illustrating the formidable potential of advanced information and AI technologies in amplifying the operational acumen of contemporary manufacturing ecosystems.},
  archive      = {J_TCSS},
  author       = {Alexis Pengfei Zhao and Shuangqi Li and Yanjia Wang and Paul Jen-Hwa Hu and Chenye Wu and Zhidong Cao and Faith Xue Fei},
  doi          = {10.1109/TCSS.2024.3379254},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7976-7989},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Energy-social manufacturing for social computing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling and solving the allocation problem of
spatiotemporal crowdsourced logistics tasks in social manufacturing.
<em>TCSS</em>, <em>11</em>(6), 7967–7975. (<a
href="https://doi.org/10.1109/TCSS.2024.3410273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the allocation problem of crowdsourced logistics tasks in social manufacturing, a bipartite graph is constructed from the location of crowdsourced workers, and the temporal and spatial attributes of the tasks to represent the crowdsourced task allocation model according to its characteristics of spatiotemporal discretization and subject to full allocation. Considering workers&#39; acceptable distance, transportation cost, and tasks balance, a crowdsourced task allocation model with the overall maximum benefit to workers as the optimization objective is established. First, the dynamic allocation problem is converted to a stationary one using a dynamic programming algorithm to determine the acceptable distance of the workers under the optimal allocation quality, and then the improved beluga whale optimization (IBWO) algorithm is utilized to solve the problem. The Sobol sequence initialization method is used to improve the population diversity and initial solution quality, and the cyclone foraging strategy is used in the development phase to enhance the global search capability and convergence performance of the algorithm. Experiments were conducted on the dataset downloaded from the website ( http://dataju.cn ). The results show that the overall benefits of the workers improved by 150.12, 181.96, and 260.64, which validates the rationality of the model and the feasibility and practicality of the method.},
  archive      = {J_TCSS},
  author       = {Dianting Liu and Lei Shang and Xuanjun Dai and Zuqiong Zhang},
  doi          = {10.1109/TCSS.2024.3410273},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7967-7975},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Modeling and solving the allocation problem of spatiotemporal crowdsourced logistics tasks in social manufacturing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A granular-computing-based data-sharing decision-making
method for enabling blockchain-based order tracking in social
manufacturing. <em>TCSS</em>, <em>11</em>(6), 7952–7966. (<a
href="https://doi.org/10.1109/TCSS.2024.3404425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the social manufacturing context, geographically distributed and decentralized micro-and-small-scale manufacturing enterprises (MSMEs) self-organize into manufacturing communities (MCs), a type of decentralized autonomous organization (DAO). In MCs, MSMEs share their manufacturing resources for order-driven cross-enterprise production cooperation, which is supported through blockchain-based order tracking. However, the application of blockchain also brings concerns about data security and privacy protection to MSMEs, which leads to disputes between MSMEs about which data should be stored in the blockchain. For this problem, a granular-computing-based data-sharing decision-making (GrC-DSDM) method is proposed. In the GrC-DSDM method, a fuzzy proximity relationship is used to describe the familiarity between MSMEs in the same MC, and MC familiarity is obtained based on the granular space derived from the fuzzy proximity relation. A fuzzy preference relation is used to represent MSMEs’ preferences for all metadata related to the order, and a group decision-making method is applied to calculate the preference values for all metadata. Through constructing the mapping relationship between MC familiarity and preference values of all metadata, we can determine which metadata should be shared with the MC for blockchain-based order tracking. The GrC-DSDM method can support group decision-making on data sharing among MSMEs in the same MC. The implementation of the GrC-DSDM method is demonstrated through the example of a sheet metal parts processing MC. It is expected that the GrC-DSDM method will provide a basis for enabling blockchain-based order tracking in MCs.},
  archive      = {J_TCSS},
  author       = {Jiajun Liu and Pingyu Jiang and Jie Zhang},
  doi          = {10.1109/TCSS.2024.3404425},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7952-7966},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A granular-computing-based data-sharing decision-making method for enabling blockchain-based order tracking in social manufacturing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SLoB: Suboptimal load balancing scheduling in local
heterogeneous GPU clusters for large language model inference.
<em>TCSS</em>, <em>11</em>(6), 7941–7951. (<a
href="https://doi.org/10.1109/TCSS.2024.3423749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) are becoming powerful engines for social productivity in the manufacturing lifecycle. Existing application-level LLMs inference services focus on large datacenter and small edge intelligence (EI) scenarios, adopting iteration-level batch schedulers to solve resource utilization and inference speed problems. However, these services are incompatible with the scene of medium-sized local heterogeneous graphics processing unit (GPU) clusters with specific patterns, whose scale is between the two aforementioned scenarios. This type of scene proposes tradeoff problems for inference resource and speed, as well as user satisfaction problems for the semisparse frequency of queries with streaming responses. We propose suboptimal load balancing (SLoB), a distributed LLMs inference service scheduler in medium-sized local heterogeneous GPU clusters. SLoB leverages a multilevel adapter to accommodate LLMs usage patterns of scenes and balance resource utilization with inference efficiency. For semisparse problems, it adopts a mixed-priority pipeline scheduler with the least-padding principle to improve users’ satisfaction, a metric considering the weights of different tokens in streaming responses. Based on the system prototype, our experiments under simulated workloads demonstrate that SLoB gains a maximum improvement of 29.4 $\times$ under the satisfaction metric compared with the traditional run-to-completion scheduling solution while improving by up to 3.0 $\times$ compared with the state-of-the-art (SOTA) solution Orca.},
  archive      = {J_TCSS},
  author       = {Peiwen Jiang and Haoxin Wang and Zinuo Cai and Lintao Gao and Weishan Zhang and Ruhui Ma and Xiaokang Zhou},
  doi          = {10.1109/TCSS.2024.3423749},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7941-7951},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {SLoB: Suboptimal load balancing scheduling in local heterogeneous GPU clusters for large language model inference},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enlarge the error prediction dataset in 3-d printing: An
unsupervised dental crown mesh generator. <em>TCSS</em>, <em>11</em>(6),
7929–7940. (<a href="https://doi.org/10.1109/TCSS.2024.3417388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of the dataset is critical to the performance of neural networks for error prediction in 3-D printing. In order to enlarge the dataset, we propose a customized two-stage framework, cascaded cross-modality generative adversarial networks (CCMGANs), for generating dental crown meshes in an unsupervised manner. At the first stage, a displacement map-guided generative adversarial network (GAN) is used to generate coarse meshes with diverse shapes. At the second stage, fine-grained details are added to the coarse meshes using an image-based GAN. Unlike previous work that integrates a differentiable renderer into the mesh deformation process directly, we adopt a two-step strategy. First, we use a depth image refinement module to achieve the domain transformation from the rendered depth images of the generated meshes to those of the real ones. Then, we propose a mesh refinement module to optimize the coarse meshes in an image-supervised manner. To alleviate the self-intersection problem, we propose a loss to penalize the distances of point pairs in self-intersection regions. Experimental results show that our method is able to generate highly realistic meshes and outperforms the state-of-the-art point cloud generation method TreeGCN in terms of the metrics FDD, MMD-CD, MMD-EMD, and COV-EMD. Furthermore, we utilize the generated data to augment the original dataset, and demonstrate that the generated data can effectively improve the accuracy of the error prediction task in 3-D printing.},
  archive      = {J_TCSS},
  author       = {Meihua Zhao and Gang Xiong and Qihang Fang and Xisong Dong and Fang Wang and Yunjun Han and Zhen Shen and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3417388},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7929-7940},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Enlarge the error prediction dataset in 3-D printing: An unsupervised dental crown mesh generator},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physics-driven data collection in 3-d printing: Traversing
the realm of social manufacturing. <em>TCSS</em>, <em>11</em>(6),
7909–7928. (<a href="https://doi.org/10.1109/TCSS.2024.3407823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive manufacturing (AM), also called 3-D printing, is a supporting technology in social manufacturing that has gained significant attention recently. As the AM industry grows, collecting and analyzing data are essential to ensure product quality, process efficiency, and cost-effectiveness. However, obtaining experimental data is challenging owing to cost and time constraints. Therefore, cost-effective and time-efficient strategies for collecting AM data are urgently required. This study proposes a novel data-collection approach that integrates the concept of finite element analysis (FEA) and physics-informed machine learning (PIML). We begin by discussing the importance of data collection in AM and the associated challenges. We then present various types of data that can be collected in AM, including the 3-D models and end-to-end data. End-to-end data comprise experimental data (i.e., sensors and images) and simulation data. Moreover, we present a case study that demonstrates the generation of simulation data and provides a detailed analysis of warpage. The STereoLithography (STL) file format of the BeltClip object from the Thingiverse possesses slicing through the Ultimaker© Cura software. The resulting G-code file is input to the Digimat-AM platform for virtual simulation of the BeltClip printing process. Digimat-AM, as a FEA simulation tool, then generates observational sample data. These data function as a roadmap for understanding the application of physical information for learning, which constitutes the observational bias aspect of PIML. The observational data obtained from the Digimat-AM is suggested for building a machine-learning model. Finally, we conclude with a discussion of inductive and learning biases in the prediction, control, and optimization aspects of AM.},
  archive      = {J_TCSS},
  author       = {Tariku Sinshaw Tamir and Gang Xiong and Zhen Shen and Jiewu Leng},
  doi          = {10.1109/TCSS.2024.3407823},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7909-7928},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Physics-driven data collection in 3-D printing: Traversing the realm of social manufacturing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Geometry-guided neural implicit surface reconstruction.
<em>TCSS</em>, <em>11</em>(6), 7898–7908. (<a
href="https://doi.org/10.1109/TCSS.2024.3416313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiview 3-D reconstruction holds considerable promise across a wide applications in social manufacturing. Conducting in-depth research on precise and robust multiview 3-D reconstruction holds the potential to significantly empower the domain of social manufacturing. Recently, there has been a burgeoning interest in the domain of neural implicit surfaces learning through volume rendering for the purpose of multiview reconstruction without 3-D supervision. Conventional approaches often overlook explicit multiview geometry constraints, resulting in shortcomings in generating consistent surface reconstructions and recovering fine details. To solve this, we propose geometry-guided neural implicit surface ( GG-NeuS ), a geometry-guided neural implicit surfaces learning method for multiview surface reconstruction. Our model places a stronger emphasis on maintaining geometry consistency, significantly enhancing the quality of reconstruction. First, we enforce multiview geometry constraints on the surface points by locating the zero-level set of signed distance function (SDF). Second, we incorporate normal cues, predicted by general-purpose monocular estimators, to substantially recover fine geometric details. Additionally, we introduce a voxel-based surface reconstruction methodology that strikes an optimal balance between training time and reconstruction quality. Through comprehensive qualitative and quantitative experiments and analyses, we demonstrate that GG-NeuS successfully reconstructs fine-grained surface details and achieves superior surface reconstruction quality than state-of-the-art approaches.},
  archive      = {J_TCSS},
  author       = {Keqiang Li and Huaiyu Wu and Mingyang Zhao and Qihang Fang and Jian Yang and Ao Zhang and Zhen Shen and Gang Xiong and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3416313},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7898-7908},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Geometry-guided neural implicit surface reconstruction},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guest editorial: Special issue on social manufacturing after
ChatGPT. <em>TCSS</em>, <em>11</em>(6), 7892–7897. (<a
href="https://doi.org/10.1109/TCSS.2024.3496032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCSS},
  author       = {Fei-Yue Wang and Pingyu Jiang and Gang Xiong and MengChu Zhou and Bernd Kuhlenkötter and Petri Helo and Zhen Shen},
  doi          = {10.1109/TCSS.2024.3496032},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7892-7897},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Guest editorial: Special issue on social manufacturing after ChatGPT},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generating-based attacks to online social networks.
<em>TCSS</em>, <em>11</em>(6), 7881–7891. (<a
href="https://doi.org/10.1109/TCSS.2024.3461710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social network (OSN) privacy leakage problem addresses more and more users’ concerns. Studying the problem from attackers’ view could tell us how to prevent further data leakage. Currently, attackers mainly focus on mapping identities between their background knowledge and the published data to collect useful information. However, it becomes difficult to find the global optimal mapping strategy because of the complexity of the OSN data. This article proposes a novel generating-based attack on OSN data, no longer restricted to mapping-based information collection. Generally, the proposed scheme learns OSN properties from the attackers’ background knowledge and employs the knowledge to fill the unknown area in the published data. The proposed scheme employs a generative adversarial network to ensure the similarity between the generated graph and the published data. The conditional information is also added in the generation process such that the generated graph is restricted to the conditions under attackers’ background knowledge. Experimental results show that the proposed scheme successfully infer private information with real-world OSN datasets.},
  archive      = {J_TCSS},
  author       = {Tianchong Gao and Yucheng Bian and Feng Li and Agnideven Palanisamy Sundar},
  doi          = {10.1109/TCSS.2024.3461710},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7881-7891},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Generating-based attacks to online social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An extensible bounded rationality-based task recommendation
scheme for from-scratch mobile crowdsensing. <em>TCSS</em>,
<em>11</em>(6), 7871–7880. (<a
href="https://doi.org/10.1109/TCSS.2024.3452099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing (MCS) has recently shown good performance in solving large-scale sensing tasks. As an essential topic in MCS, recommending tasks to participants has received extensive attention from researchers. Most studies assume that participants are absolutely rational, which is unrealistic because it is difficult for participants to know all the information about the transaction. Furthermore, most of them do not consider how to learn the preferences of new participants. In addition, their works are difficult to extend to different MCS scenarios. Considering the above problems, we propose an extensible bounded rationality-based task recommendation scheme (EBRTR), which contains a task recommendation framework and a bounded rationality decision-making model. First, a task recommendation framework that can be easily extended to various MCS scenarios is designed. Second, in our bounded rationality decision-making model, for participants with historical task information, according to the implicit information in their historical tasks, the human thinking mode with bounded rationality is simulated, and the improved classification and regression tree (ICART) algorithm is designed to construct the decision tree. For participants who newly join the platform, social information is introduced to construct an initial decision tree. Finally, extensive experimental evaluations demonstrate the effectiveness of the proposed scheme.},
  archive      = {J_TCSS},
  author       = {Qiqi Shen and Miao Ma and Mengge Li},
  doi          = {10.1109/TCSS.2024.3452099},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7871-7880},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An extensible bounded rationality-based task recommendation scheme for from-scratch mobile crowdsensing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incentivizing socio-ethical integrity in decentralized
machine learning ecosystems for collaborative knowledge sharing.
<em>TCSS</em>, <em>11</em>(6), 7857–7870. (<a
href="https://doi.org/10.1109/TCSS.2024.3450494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To broaden domain knowledge and enable advanced analytics, machine learning (ML) algorithms increasingly utilize comprehensive datasets across diverse sectors. However, these disparate datasets held by various stakeholders raise concerns over data heterogeneity, privacy, and security. Decentralized ML research aims to protect data privacy and integrate knowledge bases, especially knowledge graphs, to address data heterogeneity challenges. Yet, the question of how to foster trustworthy collaborations in decentralized ML ecosystems remains underexplored. This study pioneers two innovative socio-economic mechanisms designed to ensure dependable collaborations with socio-ethical integrity within a decentralized knowledge inference framework, enabling participants to share knowledge while maintaining data privacy and ethical standards. We employ an evolutionary game theory model to analyze the dynamic interactions between requestors and workers, focusing on achieving a stable equilibrium through theoretical and numerical evaluations. Furthermore, we explore how various critical factors, such as incentive schemes and the accuracy of identifying malicious workers, influence the system&#39;s equilibrium, providing insights into optimizing collaborative efforts in decentralized ML ecosystems.},
  archive      = {J_TCSS},
  author       = {Yuanfang Chi and Qiyue Zhang and Jiaxiang Sun and Wei Cai and Z. Jane Wang and Victor C. M. Leung},
  doi          = {10.1109/TCSS.2024.3450494},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7857-7870},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Incentivizing socio-ethical integrity in decentralized machine learning ecosystems for collaborative knowledge sharing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extracting the full story: A multimodal approach and dataset
to crisis summarization in tweets. <em>TCSS</em>, <em>11</em>(6),
7846–7856. (<a href="https://doi.org/10.1109/TCSS.2024.3436690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our digitally connected world, the influx of microblog data poses a formidable challenge in extracting relevant information amid a continuous stream of updates. This challenge intensifies during crises, where the demand for timely and relevant information is crucial. Current summarization techniques often struggle with the intricacies of microblog data in such situations. To address this, our research explores crisis-related microblogs, recognizing the crucial role of multimedia content, such as images, in offering a comprehensive perspective. In response to these challenges, we introduce a multimodal extractive-abstractive summarization model. Leveraging a fusion of TF-IDF scoring and bigram filtering, coupled with the effectiveness of three distinct models—BIGBIRD, CLIP, and bootstrapping language-image pre-training (BLIP)—we aim to overcome the limitations of traditional extractive and text-only approaches. Our model is designed and evaluated on a newly curated Twitter dataset featuring 12 494 tweets and 3090 images across eight crisis events, each accompanied by gold-standard summaries. The experimental findings showcase the remarkable efficacy of our model, surpassing current benchmarks by a notable margin of 16% and 17%. This confirms our model&#39;s strength and its relevance in crisis scenarios with the crucial interplay of text and multimedia. Notably, our research contributes to multimodal, abstractive microblog summarization, addressing a key gap in the literature. It is also a valuable tool for swift information extraction in time-sensitive situations.},
  archive      = {J_TCSS},
  author       = {Raghvendra Kumar and Ritika Sinha and Sriparna Saha and Adam Jatowt},
  doi          = {10.1109/TCSS.2024.3436690},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7846-7856},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Extracting the full story: A multimodal approach and dataset to crisis summarization in tweets},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ReOP: Generating transferable fake users for recommendation
systems via reverse optimization. <em>TCSS</em>, <em>11</em>(6),
7830–7845. (<a href="https://doi.org/10.1109/TCSS.2024.3451452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has demonstrated that recommendation systems exhibit vulnerability under data poisoning attacks. The primary process of data poisoning attacks involves generating malicious data (i.e., fake users) through surrogate models and injecting the malicious data into the target models’ datasets, thereby manipulating the output results of the target models. However, current methods generating fake users based on gradient descent may cause them to fall into undesired local minimum in the loss landscape and overfitting to the surrogate model, thus limiting the performance of attacking other recommendation models. To address this problem, we propose the reverse optimization algorithm (ReOP), which utilizes the reverse direction of optimization to update fake users, enabling them to steer clear of sharp local minimum in loss landscape and navigate towards the flat local minimum. ReOP makes fake users less sensitive to model changes, alleviates their overfitting to the surrogate model, and thus significantly improves the transferability of fake users. Experimental results demonstrate that ReOP surpasses the state-of-the-art baseline methods, effectively generating fake users with significant attack effects on various target models.},
  archive      = {J_TCSS},
  author       = {Fulan Qian and Yan Cui and Hai Chen and Wenbin Chen and Yuanting Yan and Shu Zhao},
  doi          = {10.1109/TCSS.2024.3451452},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7830-7845},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {ReOP: Generating transferable fake users for recommendation systems via reverse optimization},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Platform-driven collaboration patterns: Structural evolution
over time and scale. <em>TCSS</em>, <em>11</em>(6), 7814–7829. (<a
href="https://doi.org/10.1109/TCSS.2024.3452028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within an increasingly digitalized organizational landscape, this research explores the dynamics of decentralized collaboration, contrasting it with traditional collaboration models. An effective capturing of high-level collaborations (beyond direct messages) is introduced as the network construction methodology including both temporal and content dimensions of user collaborations—an alternating timed interaction (ATI) metric as the first aspect, and a quantitative strategy of thematic similarity as the second aspect. This study validates three hypotheses that collectively underscore the complexities of digital team dynamics within sociotechnical systems. First, it establishes the significant influence of problem context on team structures in work environments. Second, the study reveals specific evolving patterns of team structures on digital platforms concerning team size and problem maturity. Last, it identifies substantial differences in team structure patterns between digital platforms and traditional organizational settings, underscoring the unexplored nature of digital collaboration dynamics. Focusing on Wikipedia&#39;s co-creation teams as a representative online platform, this study is instrumental for organizations navigating the digital era by identifying opportunities and challenges for managing information flow. The findings reveal significant collaborative potential and innovation in large online teams: the high speed of knowledge-sharing, numerous subcommunities, and highly decentralized leadership. This study paves the way for platform governors to design strategic interventions, tailored for different problem types, to optimize digital team dynamics and align them to broader organizational goals.},
  archive      = {J_TCSS},
  author       = {Negin Maddah and Babak Heydari},
  doi          = {10.1109/TCSS.2024.3452028},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7814-7829},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Platform-driven collaboration patterns: Structural evolution over time and scale},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Empathetic response generation with self and other-imagine
graph. <em>TCSS</em>, <em>11</em>(6), 7801–7813. (<a
href="https://doi.org/10.1109/TCSS.2024.3424424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empathy, an essential quality in daily human conversations, plays a crucial role in dialogue systems. In recent years, there has been a surge of interest among researchers in developing empathetic response generation. However, existing methods often ignore the high-level process of generating empathy-imagination, which involves consciously putting oneself in the other person&#39;s shoes during a conversation. To solve this critical problem, we propose a novel approach called EmpSOI that adopts self and other-imagine to generate empathetic responses. Specifically, we design two heterogeneous graphs to incorporate the two different imaginative perspectives: the self-imagine perspective and the other-imagine perspective, which enables the model to empathize with the user from different perspectives. Besides, we incorporate a gating mechanism to regulate the contribution of imagination information from these two perspectives during the response generation stage. The mechanism enables the model to differentiate between two imaginative perspectives. The results of extensive automatic and manual experiments illustrate the advantages of our model compared to other comparative models in perceiving the user&#39;s emotional state and generating empathetic responses.},
  archive      = {J_TCSS},
  author       = {Xun Wang and Zhen Liu and Tingting Liu and Zheng Fang},
  doi          = {10.1109/TCSS.2024.3424424},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7801-7813},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Empathetic response generation with self and other-imagine graph},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MinLoQ: An effective and efficient framework to jointly
minimize epidemic spread and economic loss. <em>TCSS</em>,
<em>11</em>(6), 7789–7800. (<a
href="https://doi.org/10.1109/TCSS.2024.3429400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In major public health events such as the outbreak of COVID-19, it is crucial to design effective and efficient quarantine policies to minimize both the epidemic spread as well as the economic loss. Most prior works in the literature either only consider the epidemic control while ignoring the economic loss or just tell the percentage of users to quarantine without explicitly pointing out whom to quarantine. In addition, many assume that we have perfect knowledge of each user&#39;s health states at all times, and they are not equipped to handle super-large networks with more than 100 000 users. In this work, we consider those pandemics with incubation periods and assume that we are unable to know the exact health states of all users. We propose a method to estimate each user&#39;s probability of being infectious and then propose the basic minimum-loss quarantine (basic-MinLoQ) algorithm to jointly minimize the epidemic spread, the economic loss as well as the number of people in quarantine. For super-large networks with more than 100 000 nodes, we propose the subgraph minimum-loss quarantine (subgraph-MinLoQ) algorithm to reduce the computation complexity. Simulation results show that our basic-MinLoQ algorithm outperforms several prior works, including Netshield, Acquaintance, and GreedyDrop, in terms of epidemic control and reducing economic loss. While our proposed subgraph-MinLoQ algorithm can efficiently identify people to quarantine and control the epidemic spread in super-large networks with more than100 000 users.},
  archive      = {J_TCSS},
  author       = {Wenxiang Dong and H. Vicky Zhao},
  doi          = {10.1109/TCSS.2024.3429400},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7789-7800},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {MinLoQ: An effective and efficient framework to jointly minimize epidemic spread and economic loss},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mutual information measure for glass ceiling effect in
preferential attachment models. <em>TCSS</em>, <em>11</em>(6),
7778–7788. (<a href="https://doi.org/10.1109/TCSS.2024.3432600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a novel mutual information-based measure to assess the glass ceiling effect in preferential attachment networks, which advances the analysis of inequalities in attributed networks. Using Shannon entropy and generalizing to Rényi entropy, our measure evaluates the conditional probability distributions of node attributes given the node degrees of adjacent nodes, which offers a more nuanced understanding of inequality compared to traditional methods that emphasize node degree distributions and degree assortativity alone. To evaluate the efficacy of the proposed measure, we evaluate it using an analytical structural inequality model as well as historical publication data. Results show that our mutual information measure aligns well with both the theoretical model and empirical data, underscoring its reliability as a robust approach for capturing inequalities in attributed networks. Moreover, we introduce a novel stochastic optimization algorithm that utilizes a parameterized conditional logit model for edge addition. Our algorithm is shown to outperform the baseline uniform distribution based approach in mitigating the glass ceiling effect. By strategically recommending links based on this algorithm, we can effectively hinder the glass ceiling effect within networks.},
  archive      = {J_TCSS},
  author       = {Rui Luo and Buddhika Nettasinghe and Vikram Krishnamurthy},
  doi          = {10.1109/TCSS.2024.3432600},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7778-7788},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Mutual information measure for glass ceiling effect in preferential attachment models},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Priority over quantity: A self-incentive credit assignment
scheme for cooperative multiagent reinforcement learning. <em>TCSS</em>,
<em>11</em>(6), 7766–7777. (<a
href="https://doi.org/10.1109/TCSS.2024.3428334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Centralized training and decentralized execution (CTDE) paradigm is widely employed to address the nonstationary and partial observability in multiagent reinforcement learning (MARL). One of the main challenges that restricts the performance of the CTDE paradigm is credit assignment. Existing methods cannot sufficiently energize each agent for exploring a broader solution space without compromising performance or factorization complexity. In this article, we propose a self-incentive credit assignment scheme to prioritize individual agent actions based on a novel factorization method called multihead residual value factorization (MRVF) rather than being constrained by the quantity of collective policies. It learns an extra representation of value gradients from the cooperative behaviors and factorizes the residual global joint action value as a monotonic function, which can effectively improve the representability of the value function. Theoretical analysis indicates that our method has stronger representational ability and satisfies the individual-global-max (IGM) condition. Extensive experiments validate that our method achieves significant performance improvement in terms of both the learning speed and stability; particularly, it gains the best performance on two super hard maps of the widely used benchmark StarCraft multiagent challenge (SMAC) while the performances on other scenarios of SMAC are better or as well as the state-of-the-art baseline.},
  archive      = {J_TCSS},
  author       = {Hao Tang and Cheng Wang and Shengbo Chang and Junqi Zhang},
  doi          = {10.1109/TCSS.2024.3428334},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7766-7777},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Priority over quantity: A self-incentive credit assignment scheme for cooperative multiagent reinforcement learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hierarchical information compression approach for
knowledge discovery from social multimedia. <em>TCSS</em>,
<em>11</em>(6), 7754–7765. (<a
href="https://doi.org/10.1109/TCSS.2024.3440997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge discovery is an ongoing research endeavor aimed at uncovering valuable insights and patterns from large volumes of data in massive social systems (MSSs). Although recent advances in deep learning have made significant progress in knowledge discovery, the “data dimensionality reduction” problem still poses practical challenges. To address this, we have introduced a hierarchical information compression (IC) approach, which emphasizes the elimination of redundant and irrelevant features and the generation of high-quality knowledge representation, aiming to enhance the information density of the knowledge discovery process. Our approach consists of coarse-grained and fine-grained stages for data compression. In the coarse-grained stage, our method employs the key feature distiller based on the Siamese network to effectively identify a substantial number of irrelevant features and latent redundancies within coarse-grained data blocks. Moving on to the fine-grained stage, our model further compresses the internal features of the data, extracting the most crucial knowledge and facilitating data compression by cross-block learning. By implementing these two stages, the approach achieves both inter and innerblock IC while preserving essential knowledge. To validate the performance of our proposed model, we conducted several experiments using WikiSum, a large knowledge corpus based on English Wikipedia in MSSs. The experimental results demonstrate that our model achieved a 2.38% increase on recall-oriented understudy for gisting evaluation (ROUGE)-2 and an improvement of over 7% on the informativeness and conciseness metrics, as evidenced by the improved scores obtained from both automatic and human evaluations. The experimental results prove that our model can effectively select the most pertinent and meaningful content and reduce the redundancy to generate better knowledge representation.},
  archive      = {J_TCSS},
  author       = {Zheng Liu and Yu Weng and Ruiyang Xu and Chaomurilige and Honghao Gao},
  doi          = {10.1109/TCSS.2024.3440997},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7754-7765},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A hierarchical information compression approach for knowledge discovery from social multimedia},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). One person one vote: Achieving temporal dynamic and
byzantine-resilient digital community. <em>TCSS</em>, <em>11</em>(6),
7742–7753. (<a href="https://doi.org/10.1109/TCSS.2024.3440990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital communities are dynamically developed with users admitted in as digital identities, and process their affairs via egalitarian decision processes, namely one person one vote. However, the digital democracy in these digital communities is threatened by Byzantines therein. Most existing works focused on Byzantine detection, but we are interested in growing Byzantine-resilient community rather than whitelisting. Several works concerning developing a Byzantine-resilient digital community are vulnerable to the collapse of these selected digital identities or impractical binarized trust relations among digital identities. To this end, we propose two practical schemes based on edge links and attributes that can achieve temporal dynamic and Byzantine-resilient digital communities, providing digital democracy. Specifically, we first propose the mixed sampling of links and attributes in digital community to output node-edge sequences. Then, we further design the skip gram-based quantification of trust relationships using the node-edge sequences. Thereafter, based on the quantified trust relationships, we propose vertex-based and edge-based strategies that prove the constraints when dynamically developing a Byzantine-resilient digital community. The key advantage is that our work can be applied to any graph containing both digital identity nodes and attribute nodes, rather than the graphs with one kind node and the fully connected graphs. Last, we conduct experiments on four real-world datasets, and the extensive results indicate the superior performance of our work, compared to four existing works. This work can be applied to social networks, online shopping platforms, etc., and keep digital democracy therein.},
  archive      = {J_TCSS},
  author       = {Ping Zhao and Yaqiong Mu and Guanglin Zhang},
  doi          = {10.1109/TCSS.2024.3440990},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7742-7753},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {One person one vote: Achieving temporal dynamic and byzantine-resilient digital community},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sociolinguistic radar of phonological variation and social
meaning: Variables, quantitative methods, and prospects. <em>TCSS</em>,
<em>11</em>(6), 7734–7741. (<a
href="https://doi.org/10.1109/TCSS.2024.3432117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the term “social radar,” which collects and processes information about social behaviors, this article proposed “sociolinguistic radar,” which represents an emerging branch in social investigation and evaluation system aiming to explore the dynamic correlation between sociophonetic variants and macrosociological categories, such as age, gender, ethnicity, and socioeconomic status. The classic quantitative methods in this field include sociolinguistic surveys and interview, quantitative sociophonetics, and social network analysis. These methods have been proved to be effective in tracking the cognitive correlates of phonological variables. Under the emerging framework of sociolinguistic radar, speakers are no longer passive carriers, but active agents in transforming linguistic styles in the process of forming social differentiations, thus contributing to the construction of new social meaning. With the advancement in neuroscience and artificial intelligence (AI), the neurosociolinguistic and AI-based sociolinguistic radar research will thrive and empower the scope and strength of detecting linguistic variation. The working mechanism of this emerging model leverages neural and AI tool packages to radar and analyze linguistic variation, communication patterns, and diverse sociolinguistic phenomena. This interdisciplinary approach combines the principles of sociolinguistics, which will thoroughly examine the relationship between language and society.},
  archive      = {J_TCSS},
  author       = {Wei Wang and Lili Fan and Yutong Wang and Qinghua Ni and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3432117},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7734-7741},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Sociolinguistic radar of phonological variation and social meaning: Variables, quantitative methods, and prospects},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AMIR: An automated misinformation rebuttal system—a COVID-19
vaccination datasets-based exposition. <em>TCSS</em>, <em>11</em>(6),
7723–7733. (<a href="https://doi.org/10.1109/TCSS.2024.3429526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Misinformation has emerged as a major societal threat in the recent years in general; specifically in the context of the COVID-19 pandemic, it has wrecked havoc, for instance, by fueling vaccine hesitancy. Cost-effective, scalable solutions for combating misinformation are the need of the hour. This work explored how existing information obtained from social media and augmented with more curated fact checked data repositories can be harnessed to facilitate automated rebuttal of misinformation at scale. While the ideas herein can be generalized and reapplied in the broader context of misinformation mitigation using a multitude of information sources and catering to the spectrum of social media platforms, this work serves as a proof of concept, and as such, it is confined in its scope to only rebuttal of tweets, and in the specific context of misinformation regarding COVID-19. It leverages two publicly available datasets, viz. FaCov (fact-checked articles) Sharma et al., 2022 and misleading (social media Twitter) Sharma et al., 2024 data on COVID-19 vaccination.},
  archive      = {J_TCSS},
  author       = {Shakshi Sharma and Anwitaman Datta and Rajesh Sharma},
  doi          = {10.1109/TCSS.2024.3429526},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7723-7733},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {AMIR: An automated misinformation rebuttal System—A COVID-19 vaccination datasets-based exposition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time driver and traffic data integration for enhanced
road safety. <em>TCSS</em>, <em>11</em>(6), 7711–7722. (<a
href="https://doi.org/10.1109/TCSS.2024.3448400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional roadway safety assessment heavily relies on historical crash data, overlooking real-time factors such as driver behaviors and current traffic conditions and lacking forward-looking analysis for predicting future trends. This study introduces an enhanced innovative data fusion method based on the safe route mapping (SRM) methodology with combined use of historical crash data and real-time data, leveraging a custom-built Android app to amalgamate road and vehicle data effectively, showcasing notable advancements in real-time risk assessment. The enhanced safe route mapping (ESRM) framework monitors driver actions and road conditions meticulously. Data collected from drivers is analyzed on a central server using facial recognition algorithm to detect signs of fatigue and distractions, assessing overall driving competence. Simultaneously, roadside cameras capture live traffic data, analyzed using a specialized video analytics method to track vehicle speed and paths. The fusion of these data streams enables the introduction of a predictive model, Light gradient boosting machine (GBM), forecasting potential immediate issues for drivers. Predicted risk scores are integrated with historical crash data using a Fuzzy logic model, delineating risk levels for different road sections. The performance of ESRM model is tested using real-world data and a driving simulation, demonstrating remarkable accuracy, especially in accounting for real-time fusion of driver behavior and traffic conditions. The resultant visual risk heatmap aids authorities in identifying safer routes, proactive law enforcement deployment, and informed trip planning based on real-time risk levels. This study not only underscores the importance of real-time data in roadway safety but also paves the way for data-driven, dynamic risk assessment models, potentially reducing road accidents and fostering a safer driving environment.},
  archive      = {J_TCSS},
  author       = {Yufei Huang and Shan Jiang and Mohsen Jafari and Peter J. Jin},
  doi          = {10.1109/TCSS.2024.3448400},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7711-7722},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Real-time driver and traffic data integration for enhanced road safety},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A social network model for analysis of public opinion
formation process. <em>TCSS</em>, <em>11</em>(6), 7698–7710. (<a
href="https://doi.org/10.1109/TCSS.2024.3435908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing popularity of social networks has amplified their capacity to form public opinions. The opinion formation process is affected by social factors and social phenomena such as spiral of silence and echo chambers. In this article, we present a directed homophilic preferential attachment (DHPA) model to capture the dynamics of social network generation and rewiring (network dynamics) and to take the variation of attitudes and characteristics of users when expressing their opinions and their desire to establish relationships with others into account (opinion dynamics). The proposed model not only integrates network dynamics and opinion dynamics but also accounts for homophily and the formation of social phenomena that create consensus or polarity. This results in more realistic outcomes compared to similar models. In addition, the model can contrast factors that drive consensus with those that drive polarization. DHPA provides necessary facilities for examining the impact of different factors on the opinion formation process. It enables us to analyze the circumstances to reach consensus and polarity. It is shown that the network generated by the proposed DHPA model appropriately conforms to real social networks. We have examined the impact of some important social factors by conducting a number of sensitivity analysis scenarios on the model, which led to interesting results.},
  archive      = {J_TCSS},
  author       = {Hani Rabiee and Behrouz Tork Ladani and Ebrahim Sahafizadeh},
  doi          = {10.1109/TCSS.2024.3435908},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7698-7710},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A social network model for analysis of public opinion formation process},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge graph-based personalized multitask enhanced
recommendation. <em>TCSS</em>, <em>11</em>(6), 7685–7697. (<a
href="https://doi.org/10.1109/TCSS.2024.3446289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problem of data sparsity in recommendation systems, various studies have used knowledge graphs as auxiliary information. These studies have employed multitask learning (MTL) to enhance recommendation performance. However, the shared information between tasks is not fully explored when using an MTL strategy for training both recommendation and knowledge graph-related tasks. Moreover, most studies cannot effectively model the knowledge sharing, consequently affecting recommendation performance. In response to these problems, we proposed a novel knowledge graph-based personalized multitask enhanced recommendation model. To explore the shared information between tasks, a relation attention mechanism was proposed to distinguish the relative importance of neighborhood information to the central entity. Additionally, we utilized a lightweight graph convolutional network to more effectively aggregate high-order neighborhood information from the knowledge graph. This approach improves the accuracy of neighborhood feature and ensures that more suitable shared information is obtained. Furthermore, we developed a linear interaction component to model knowledge sharing between recommendation and knowledge graph embedding tasks. This component allows for detailed feature interaction learning between items and entities, enhancing the shared feature representation, generalization capabilities, and overall performance of the recommendation system. The experimental results on three public datasets indicate that our model outperforms other benchmark models in CTR prediction and top- $\boldsymbol{K}$ recommendation.},
  archive      = {J_TCSS},
  author       = {Liangmin Guo and Tingting Liu and Shiming Zhou and Haiyue Tang and Xiaoyao Zheng and Yonglong Luo},
  doi          = {10.1109/TCSS.2024.3446289},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7685-7697},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Knowledge graph-based personalized multitask enhanced recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An advanced pricing mechanism for nonfungible tokens (NFTs)
based on rarity and market dynamics. <em>TCSS</em>, <em>11</em>(6),
7671–7684. (<a href="https://doi.org/10.1109/TCSS.2024.3430846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonfungible tokens (NFTs) are unique cryptocurrencies that exist on a blockchain and cannot be replicated. However, today&#39;s NFT market lacks a sensible pricing framework, which causes NFT price fluctuations to interfere with the investment market. The purpose of this research is to build a dynamic pricing mechanism for NFT based on NFT features, validate the improvement of factor analysis on the pricing model, and integrate the rarity-based model with market factors in an online market. We presented and implemented a prototype pricing algorithm through a designed NFT market. This implementation shows that this advanced pricing mechanism could be used in a real-world pricing scenario and could provide a reasonable price change when market factors change. Furthermore, the experimental results demonstrated that the rarity scores of the features and market factors can potentially induce price fluctuations within the range of negative 0.4 to positive 0.4.},
  archive      = {J_TCSS},
  author       = {Wenze Xiong and Yetong Wang and Wanxin Li and Yutong Zhang and Jie Zhang and Hao Guo},
  doi          = {10.1109/TCSS.2024.3430846},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7671-7684},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An advanced pricing mechanism for nonfungible tokens (NFTs) based on rarity and market dynamics},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DGCN-TES: Dynamic GCN-based multitask model with temporal
event sharing for rumor detection. <em>TCSS</em>, <em>11</em>(6),
7658–7670. (<a href="https://doi.org/10.1109/TCSS.2024.3443275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rumor detection task aims to identify unofficial and unconfirmed information that is spreading on social media. At any given moment, different users express their opinions, focusing on some propagation events, and the posts they make gradually form a social network that expands as it grows. Over time, nodes and edges form a dynamic graph that presents different states at different moments. However, most existing research focuses more on the text content, social context, propagation mode, etc., and they ignore the factors from many aspects and do not consider the dynamic relationships implied in the propagation development of social media. To analyze these dynamic properties, this article proposes a dynamic network-based multitask rumor detection method called dynamic GCN-based multitask model with temporal event sharing for rumor detection (DGCN-TES). This method can effectively capture the dynamic patterns of relationships in propagation events and change them over time to detect rumors. It is mainly divided into three modules: 1) dynamic-graph convolutional network (GCN) module, which uses dynamic graph neural network to construct the propagation graph of rumor events at different times, which can better capture the dynamic spatial features that change over time; 2) content-long short-term memory (LSTM), which uses the LSTM network as a benchmark model and has been improved to better capture time-series text features over time and for multitask shared interactions; and 3) temporal event sharing layer is the sharing layer, which uses time step as the basic unit of sharing, and realizes the sharing interaction between dynamic structural features and temporal text features between the first two modules. We tested the method on two real-world rumor detection datasets PHEME and WEIBO, and the final results show that the method improved F1-score by more than 2.63% and 3.91% compared to the other best baselines baseline.},
  archive      = {J_TCSS},
  author       = {Shuzhen Wan and Guanghao Yang and Fangmin Dong and Mengyuan Wang},
  doi          = {10.1109/TCSS.2024.3443275},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7658-7670},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {DGCN-TES: Dynamic GCN-based multitask model with temporal event sharing for rumor detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous hypernetwork representation learning with
hyperedge fusion. <em>TCSS</em>, <em>11</em>(6), 7646–7657. (<a
href="https://doi.org/10.1109/TCSS.2024.3434737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing hypernetwork representation learning methods fail to fully consider the hyperedges, leading to the untapped potential of information contained within the hyperedges. To address this issue, this article proposes a heterogeneous hypernetwork representation learning method with hyperedge fusion abbreviated as HRHF. First, this method incorporates the hyperedges into random walk node sequences by means of incidence graph to enhance tuple relationships, i.e., the hyperedges among the nodes. Second, under the condition of the above random walk node sequences, the cognitive structure model, cognitive set model, and cognitive hyperedge model are jointly optimized to comprehensively consider pairwise relationships and tuple relationships among the nodes to learn high-quality node representation vectors. The experimental results demonstrate that, for the link prediction task, this method outperforms other optimal baseline methods, i.e., hyper-path-based random walks + hyper-gram (HPHG) by 0.99% points on the drug dataset, is comparable to the other optimal method, i.e., Event2vec on the global positioning system (GPS) dataset, is close to the performance of other optimal methods, i.e., hyper-path-based random walks + skip-gram (HPSG) on the MovieLens, and is close to the performance of other optimal methods, i.e., Hyper2vec on the WordNet dataset. For the hypernetwork reconstruction task, this method achieves superior average performance on the drug and GPS datasets compared with other baseline methods.},
  archive      = {J_TCSS},
  author       = {Keke Wang and Yu Zhu and Xiaoying Wang and Jianqiang Huang and Tengfei Cao},
  doi          = {10.1109/TCSS.2024.3434737},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7646-7657},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Heterogeneous hypernetwork representation learning with hyperedge fusion},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on label propagation algorithm of community
structure analysis in complex networks. <em>TCSS</em>, <em>11</em>(6),
7634–7645. (<a href="https://doi.org/10.1109/TCSS.2024.3426659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of nodes interaction is crucial to evaluate the dynamics of complex networks, as well as the community structure of social networks. Particularly, the corresponding results can be used to reveal the nature of information propagation in the field of film industry. In this article, an analytical framework of nodes relationship is proposed to go deeply into the network topology. Specifically, the proposed framework can be used to effectively characterize the nodes interaction and thus simplify the network. Moreover, an object interaction similarity label propagation algorithm (OISLPA) based on label propagation theory is then formulated, which is essential to analyze the topology of community structure. It is possible to use OISLPA as an analytical tool for optimal seed nodes selection depending on the community structure. The result is significant as it can help us to predict the information propagation effects through different types of networks.},
  archive      = {J_TCSS},
  author       = {Shan Liu and Fengxuan Shao and Ruixing Tao and Hao Wen},
  doi          = {10.1109/TCSS.2024.3426659},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7634-7645},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Research on label propagation algorithm of community structure analysis in complex networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quality-improved and delay-aware incentive mechanism for
mobile crowdsensing with social concerns: A stackelberg game approach.
<em>TCSS</em>, <em>11</em>(6), 7618–7633. (<a
href="https://doi.org/10.1109/TCSS.2024.3430396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive popularity of mobile devices, mobile crowdsensing (MCS) has emerged as a promising large-scale data collection paradigm. Suitable incentive mechanisms are essential for encouraging user participation. Current MCS work more or less ignores three factors. First, mobile users are assumed to be independent of each other, ignoring social effects. Second, due to the heterogeneity of users, if you just blindly attract users without distinguishing them, the data quality can decrease. Finally, the limited communication resource allocation problem during uploading sensing results is ignored. Therefore, we model the quality-improved and delay-aware incentive mechanism with social concerns as a two-stage Stackelberg game, in which the rational use of social effects not only motivates user participation but also avoids a serious decline in information value due to repetition, and reasonable allocation of communication resources ensures the timeliness of delay-sensitive tasks. Furthermore, data screening, similarity analysis, voting, and reputation are used simultaneously to improve data quality. The Hessian matrix in a multiuser, multitask hyperspace setting is utilized to verify the existence and uniqueness of the game equilibrium. The closed-form expressions of the optimal requester pricing and the optimal user data load strategies are derived, respectively. The proposed mechanism is compared with gather–scatter, incentive-G, Blockchain-based secure, interactive, and fair MCS (BSIF), and Socially-aware incentive mechanism (SAIM) algorithms. Extensive simulation results on a real trajectory dataset show that compared with these state-of-the-art algorithms, the proposed incentive mechanism can motivate users to provide more data loads with few rewards, greatly improve the requester utility, and suppress the data upload of malicious users.},
  archive      = {J_TCSS},
  author       = {Mengge Li and Miao Ma and Liang Wang and Bo Yang},
  doi          = {10.1109/TCSS.2024.3430396},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7618-7633},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Quality-improved and delay-aware incentive mechanism for mobile crowdsensing with social concerns: A stackelberg game approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Region-farm crop planning through double deep q-learning
toward sustainable agriculture. <em>TCSS</em>, <em>11</em>(6),
7608–7617. (<a href="https://doi.org/10.1109/TCSS.2024.3441543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global food market faces escalating risks and uncertainties, bringing great challenges in balancing a country&#39;s food supply and demand. Therefore, it is of great significance to carry out crop planning and reasonably divide the planting area of each crop to ensure the national food security. However, the existing planting planning methods have the problems of inaccurate crop price prediction and poor flexibility, and challenges remain on how to motivate farmers. With the rapid development of science and technology, agricultural crop planning techniques have made great progress. This study focuses on agricultural planting planning, exploring both planting area planning based on predicted crop prices and a crop allocation model within a multifarmer context. The regional planting goals are decomposed into specific allocations for individual farmers and plots, addressing objectives including maximizing farmer profits and expanding soybean cultivation for national self-sufficiency. The work employs the long short-term memory (LSTM) model to predict the prices of soybean, wheat, and maize. First, linear programming model is applied to plan planting areas of crops, incorporating constraints to encourage sustainable agricultural practices. Second, a multifarmer crop allocation model, utilizing the double deep Q network (DDQN) algorithm, is developed to enhance the fairness among farmers and assure rotational benefits. Experimental validation confirms the effectiveness of the proposed algorithms, providing valuable decision support for agricultural planning with economic and ecological sustainability.},
  archive      = {J_TCSS},
  author       = {Xiujuan Wang and Yulin Xu and Haoyu Wang and Mengzhen Kang and Jing Hua and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3441543},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7608-7617},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Region-farm crop planning through double deep Q-learning toward sustainable agriculture},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on opinion diffusion and evolution model in complex
network. <em>TCSS</em>, <em>11</em>(6), 7595–7607. (<a
href="https://doi.org/10.1109/TCSS.2024.3438212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The openness and freedom of the Internet have made more and more users choose to spread information on the Internet, which has also led to a sharp increase in the speed and breadth of event information diffusion, and the changes in public opinion have also become more diverse. Motivated by this observation, in this article, we propose an opinion information diffusion model based on opinion dynamics. Through the analysis of the model, the influence of the activation probability and the diffusion willingness in the model on the diffusion result is studied. In addition, we improved the opinion evolution rules in the bounded trust model and analyzed the evolution of group opinions from the perspectives of group size, trust threshold, and acceptance of individual opinions. Finally, based on the idea of reverse influence sampling, positive information propagation maximization (PIPM), a positive information propagation maximization algorithm is proposed, and it is shown by the experimental results that it can effectively solve the problem of maximizing the spread of positive public opinion information. These findings shed new light on the practical application value for controlling the development of public opinion and maximizing the transmission of positive information.},
  archive      = {J_TCSS},
  author       = {Shan Liu and Yue Tian and Xiaoqing Wu},
  doi          = {10.1109/TCSS.2024.3438212},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7595-7607},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Research on opinion diffusion and evolution model in complex network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding sentiment polarities and emotion categories of
people on public incidents with the relation to government policies.
<em>TCSS</em>, <em>11</em>(6), 7584–7594. (<a
href="https://doi.org/10.1109/TCSS.2024.3403872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public incidents necessitate prompt proactive measures by the government and pertinent departments, posing substantial challenges to emergency management capabilities. With the advancement of internet technologies, social media platforms have played a pivotal role in shaping the landscape of public incidents, progressively emerging as primary conduits for authentic expression and sentiment sharing among individuals. The sentiment polarities and emotion categories manifested on social media platforms serve as the correspondence to real-world societal behaviors and performance. This article presents a novel framework leveraging the Transformer-based pretrained language model for conducting large-scale analysis of publicly available short text data sourced from social media platforms. The research aims to comprehensively understand the dynamic fluctuations across fourteen dimensions of sentiment polarities and emotion categories extracted from short text data expressed by people on public incidents over temporal periods. The study seeks to elucidate the relation between the enactment of relevant policies and the observed sentiment polarities as well as emotion categories. One sentiment polarity and two emotion categories related to policies on public incidents are outlined. This research contributes to the government and pertinent departments by providing insights into the text content on social media platforms concerning public incidents, thereby facilitating the understanding of the evolving sentiment polarities and emotion categories.},
  archive      = {J_TCSS},
  author       = {Haochen Zou and Yongli Wang},
  doi          = {10.1109/TCSS.2024.3403872},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7584-7594},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Understanding sentiment polarities and emotion categories of people on public incidents with the relation to government policies},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MSSA: Multispectral semantic alignment for cross-modality
infrared-RGB person reidentification. <em>TCSS</em>, <em>11</em>(6),
7568–7583. (<a href="https://doi.org/10.1109/TCSS.2024.3403691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread deployment of dual-camera systems has laid a solid foundation for practical applications of infrared (IR)-RGB cross-modality person reidentification (ReID). However, the inherent modality differences between RGB and IR images cause significant intra-class variances in the feature space for individuals of the same identity. Current methods typically employ various network architectures for the image style transfer or extracting modality-invariant features, yet they overlook the information extraction from the most fundamental spectral semantic features. Based on the existing approaches, we propose a multi-spectral semantic alignment (MSSA) architecture aimed at aligning fine-grained spectral semantic features across both intra-modality and inter-modality perspectives. Through modality center semantic alignment (MCSA) learning, we comprehensively mitigate differences in identity features of different modalities. Moreover, to attenuate the discriminative information unique to a single modality, we introduce the modality reliability intensification (MRI) loss to enhance the reliability of identity information. Finally, to tackle the challenge that inter-modality intra-class disparities surpass inter-modality inter-class differences, we leverage the dynamic discriminative center (DDC) loss to further bolster the discriminability of reliable information. Through an extensive experiments conducted on SYSU-MM01, RegDB, and LLCM datasets, we demonstrate the substantial advantages of the proposed MSSA over other state-of-the-art methods.},
  archive      = {J_TCSS},
  author       = {Qingshan Chen and Moyan Zhang and Zhenzhen Quan and Yumeng Zhang and Mikhail G. Mozerov and Chao Zhai and Hongjuan Li and Yujun Li},
  doi          = {10.1109/TCSS.2024.3403691},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7568-7583},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {MSSA: Multispectral semantic alignment for cross-modality infrared-RGB person reidentification},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counterfactual data augmentation with denoising diffusion
for graph anomaly detection. <em>TCSS</em>, <em>11</em>(6), 7555–7567.
(<a href="https://doi.org/10.1109/TCSS.2024.3403503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A critical aspect of graph neural networks (GNNs) is to enhance the node representations by aggregating node neighborhood information. However, when detecting anomalies, the representations of abnormal nodes are prone to be averaged by normal neighbors, making the learned anomaly representations less distinguishable. To tackle this issue, we propose an unsupervised counterfactual data augmentation method for graph anomaly detection (CAGAD) that introduces a graph pointer neural network as the heterophilic node detector to identify potential anomalies whose neighborhoods are normal-node-dominant. For each identified potential anomaly, we design a graph-specific diffusion model to translate a part of its neighbors, which are probably normal, into anomalous ones. At last, we involve these translated neighbors in GNN neighborhood aggregation to produce counterfactual representations of anomalies. Through aggregating the translated anomalous neighbors, counterfactual representations become more distinguishable and further advocate detection performance. The experimental results on four datasets demonstrate that CAGAD significantly outperforms strong baselines, with an average improvement of 2.35% on F1, 2.53% on AUC-ROC, and 2.79% on AUC-PR.},
  archive      = {J_TCSS},
  author       = {Chunjing Xiao and Shikang Pang and Xovee Xu and Xuan Li and Goce Trajcevski and Fan Zhou},
  doi          = {10.1109/TCSS.2024.3403503},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7555-7567},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Counterfactual data augmentation with denoising diffusion for graph anomaly detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel confined attention-enabled hierarchical bi-LSTM and
bi-GRU fusion: A multiscale traffic flow prediction application.
<em>TCSS</em>, <em>11</em>(6), 7541–7554. (<a
href="https://doi.org/10.1109/TCSS.2024.3402735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is essential for alleviating congestion and enhancing traffic management. While previous efforts have mainly concentrated on road-level predictions, the advancement of technology and the growing presence of automated vehicles have encouraged lane-level forecasting for more efficient driving and routing decisions. Therefore, this work presents a hierarchical model using recurrent neural networks (RNNs) that takes the lane-level information as the input and makes multiscale (lane level and road level) traffic flow predictions. Initially, the lane-level predictions are made using confined attention enabled RNN (CAERNN), built using bidirection long short-term memory (Bi-LSTM) and bidirection gated recurrent unit (Bi-GRU), and separately learning the periodic and temporal characteristics. Further, the features extracted by each lane are used to predict the traffic flow on the entire road. A novel confined attention mechanism is integrated into the Bi-LSTM module to improve the model&#39;s performance by focusing on recent, more relevant information in the traffic flow sequence. It is observed that the confined attention mechanism performs better than the conventional attention mechanism. Furthermore, the external features are integrated to improve the model&#39;s performance. The proposed model is evaluated on publicly available real-world data sets (in normal and COVID-19 scenarios), and the compared results with several state-of-the-art methods are evidence for the CAERNN&#39;s effectiveness.},
  archive      = {J_TCSS},
  author       = {Nisha Singh Chauhan and Neetesh Kumar},
  doi          = {10.1109/TCSS.2024.3402735},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7541-7554},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Novel confined attention-enabled hierarchical bi-LSTM and bi-GRU fusion: A multiscale traffic flow prediction application},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incentive mechanism design toward a win–win situation for
generative art trainers and artists. <em>TCSS</em>, <em>11</em>(6),
7528–7540. (<a href="https://doi.org/10.1109/TCSS.2024.3415631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent development of generative art, a typical category of artificial intelligence-generated content (AIGC), is essentially beneficial for social good, which can help amateurs to create artwork and improve experts’ efficiency. However, some artists are opposed to generative art technologies due to the copyright infringement and influence of the artists’ way of earning a living, which makes the artists protest against generative art technologies, causing a lose–lose situation. Adversarial attacks against generative model training are potential solutions to address this issue, while the lose–lose situation cannot be improved. To build a win–win situation, a feasible method is to incentivize the artists to actively contribute their artworks to generative model training without influencing their living or infringing copyright, such as data crowdsourcing, but traditional data crowdsourcing methods cannot well fit the generative art area. Therefore, this article builds a blockchain-based trading system for generative model training data collection and generated artwork circulation. Specifically, this article formulates a social welfare maximization problem based on the reverse auction and designs a corresponding incentive mechanism. The conducted theoretical analysis and numerical evaluation demonstrate the effectiveness of the proposed incentive mechanism toward a win–win situation for generative art model trainers and artists.},
  archive      = {J_TCSS},
  author       = {Haihan Duan and Abdulmotaleb El Saddik and Wei Cai},
  doi          = {10.1109/TCSS.2024.3415631},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7528-7540},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Incentive mechanism design toward a Win–Win situation for generative art trainers and artists},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Feature graph augmented network representation for
community detection. <em>TCSS</em>, <em>11</em>(6), 7516–7527. (<a
href="https://doi.org/10.1109/TCSS.2024.3399210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection plays an important role in understanding complex networks. Many traditional embedding-based community detection methods only focus on the relations between nodes in the topology space (i.e., topology graph). Besides, there are also some works that consider the feature embedding of nodes to further improve the detection performance. However, most of them ignore the relationships between nodes in the feature space (i.e., feature graph). To address this issue, in this article, we construct the feature graph from the features of nodes to capture the relations between nodes in the feature space, and incorporate it with the topology graph and the feature embedding, leading to the novel feature graph augmented network representation for community detection (FGCD) method. Specifically, FGCD extracts the embeddings of topology graph, node features, and feature graph, respectively, and ensembles them by a layerwise fusion method with an attention mechanism. Extensive experiments on 11 real-world datasets show that FGCD outperforms most existing state-of-the-art algorithms, which well demonstrates its superiority.},
  archive      = {J_TCSS},
  author       = {Lei Zhang and Zeqi Wu and Haipeng Yang and Wuji Zhang and Peng Zhou},
  doi          = {10.1109/TCSS.2024.3399210},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7516-7527},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Feature graph augmented network representation for community detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quad-faceted feature-based graph network for domain-agnostic
text classification to enhance learning effectiveness. <em>TCSS</em>,
<em>11</em>(6), 7500–7515. (<a
href="https://doi.org/10.1109/TCSS.2024.3421632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing learning effectiveness requires one to define suitable learning outcomes and align assessment constructs with these outcomes. We present a quad-faceted feature-based graph network to classify assessment texts into domain-agnostic class labels more accurately. The proposed model incorporates four complementary graphs (syntactic, semantic, sequential, and topical) with observable and latent node types and unique edge weight computations that are dependent on node properties to extract unique features from a given text. The purpose of incorporating syntactic information is to consider the dependency parsing between word nodes, while the semantic information is to provide the algorithm with contextual similarity between phrase nodes that are more effective than words in encapsulating the meaning of a text. The sequential graph is applied to regular expression nodes that contribute to a domain-agnostic class label, while the topical graph identifies topics that are convergent to each other based on their distributions. As opposed to existing techniques that construct graphs solely based on word nodes, the proposed model exploits the benefits of term weighting, nested phrases, regular expressions, and topic modeling to develop a diverse heterogeneous architecture for text classification. We evaluate the classification performance on questions with different class labels such as cognitive complexities, reasoning capabilities, and question types, as well as longer documents. Experiment results show that the proposed model outperforms in terms of macroaverage F1 score when compared with existing deep learning techniques. We also demonstrate the application of the classification model to understand learners’ attitudes via an empirical study in a workplace-learning environment.},
  archive      = {J_TCSS},
  author       = {S. Supraja and Andy W. H. Khong},
  doi          = {10.1109/TCSS.2024.3421632},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7500-7515},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Quad-faceted feature-based graph network for domain-agnostic text classification to enhance learning effectiveness},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterative role negotiation via the bilevel GRA++ with
decision tolerance. <em>TCSS</em>, <em>11</em>(6), 7484–7499. (<a
href="https://doi.org/10.1109/TCSS.2024.3409893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Role negotiation (RN) is situated at the initial stage of the role-based collaboration (RBC) methodology and is independent of the subsequent agent evaluation and role assignment (RA) processes. RN is to determine the roles and the resource requirements for each role. In existing RBC-related research, RN is assumed to be static. This means that the roles and the resource requirements for each role are predetermined by decision-makers. However, the resources allocated to each role can vary. At this time, iterative RN outcomes will have different RA results. There may not be a direct dominant relationship between different RA outcomes, especially when solving group role assignment (GRA) with multiple objectives (GRA++) problems, which makes it even more complex. To address these concerns, we introduce the original bilevel GRA++ (BGRA++) model. Specifically, at the lower level of BGRA++, a strategy is designed for quantifying iterative RNs. For the upper level, we introduce the novel GRA-NSGA-II algorithm for the RA process. Finally, we introduce the concept of decision tolerance to assist decision-makers in selecting the optimal solution from the multiple RNs. Last, simulation experiments are conducted to verify the robustness and practicability of the proposed method. Comparisons and discussions show that the proposed solution is highly competitive for solving the GRA++ problem with iterative RN.},
  archive      = {J_TCSS},
  author       = {Qian Jiang and Dongning Liu and Haibin Zhu and Shijue Wu and Naiqi Wu and Xin Luo and Yan Qiao},
  doi          = {10.1109/TCSS.2024.3409893},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7484-7499},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Iterative role negotiation via the bilevel GRA++ with decision tolerance},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyperbolic translation-based sequential recommendation.
<em>TCSS</em>, <em>11</em>(6), 7467–7483. (<a
href="https://doi.org/10.1109/TCSS.2024.3409711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of sequential recommendation algorithms is to predict personalized sequential behaviors of users (i.e., next-item recommendation). Learning representations of entities (i.e., users and items) from sparse interaction behaviors and capturing the relationships between entities are the main challenges for sequential recommendation. However, most sequential recommendation algorithms model relationships among entities in Euclidean space, where it is difficult to capture hierarchical relationships among entities. Moreover, most of them utilize independent components to model the user preferences and the sequential behaviors, ignoring the correlation between them. To simultaneously capture the hierarchical structure relationships and model the user preferences and the sequential behaviors in a unified framework, we propose a general hyperbolic translation-based sequential recommendation framework, namely HTSR. Specifically, we first measure the distance between entities in hyperbolic space. Then, we utilize personalized hyperbolic translation operations to model the third-order relationships among a user, his/her latest visited item, and the next item to consume. In addition, we instantiate two hyperbolic translation-based sequential recommendation models, namely Poincaré translation-based sequential recommendation (PoTSR) and Lorentzian translation-based sequential recommendation (LoTSR). PoTSR and LoTSR utilize the Poincaré distance and Lorentzian distance to measure similarities between entities, respectively. Moreover, we utilize the tangent space optimization method to determine optimal model parameters. Experimental results on five real-world datasets show that our proposed hyperbolic translation-based sequential recommendation methods outperform the state-of-the-art sequential recommendation algorithms.},
  archive      = {J_TCSS},
  author       = {Yonghong Yu and Aoran Zhang and Li Zhang and Rong Gao and Shang Gao and Hongzhi Yin},
  doi          = {10.1109/TCSS.2024.3409711},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7467-7483},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Hyperbolic translation-based sequential recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybridized approach for enhanced fake review detection.
<em>TCSS</em>, <em>11</em>(6), 7448–7466. (<a
href="https://doi.org/10.1109/TCSS.2024.3411635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User reviews on online consumption platforms are crucial for both consumers and merchants, serving as a reference for purchase decisions and product improvement. However, fake reviews can mislead consumers and harm merchant profits and reputation. Developing effective methods for detecting deceptive reviews is crucial to protecting the interests of both parties. In recent years, research on fake review detection has focused on improving machine learning and neural network methods to enhance the accuracy of fake review detection, neglecting the fundamental and necessary work of text feature representation for reviews. High-quality review text feature representation affects or even determines the quality and performance of fake review detection methods. The increasing prevalence of fake reviews results in a more complex distribution within the feature space of review texts, thus necessitating review embedding methods that exhibit comprehensive semantic comprehension and contextual awareness of review texts. To improve the quality of textual feature representation, we propose a review-embedding attention-based long short-term memory (A-LSTM) method that can encode the global semantics of reviews and detect the deception of the review content. A-LSTM uses attention gates to discover the importance of words, and by analyzing the importance of words, it can help distinguish the characteristics of real and fake reviews, and we propose an attention loss function to solve the problem of class imbalance. On the Yelp dataset, the accuracy of deceptive review detection has increased to 90.9%.},
  archive      = {J_TCSS},
  author       = {Shu Xu and Haoqi Cuan and Zhichao Yin and Chunyong Yin},
  doi          = {10.1109/TCSS.2024.3411635},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7448-7466},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A hybridized approach for enhanced fake review detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The powerball method with biased stochastic gradient
estimation for large-scale learning systems. <em>TCSS</em>,
<em>11</em>(6), 7435–7447. (<a
href="https://doi.org/10.1109/TCSS.2024.3411630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Powerball method, via incorporating a power coefficient into conventional optimization algorithms, has been considered in accelerating stochastic optimization (SO) algorithms in recent years, giving rise to a series of powered stochastic optimization (PSO) algorithms. Although the Powerball technique is orthogonal to the existing accelerated techniques (e.g., the learning rate adjustment strategy) for SO algorithms, the current PSO algorithms take a nearly similar algorithm framework to SO algorithms, where the direct negative result for PSO algorithms is making them inherit low-convergence rate and unstable performance from SO for practical problems. Inspired by this gap, this work develops a novel class of PSO algorithms from the perspective of biased stochastic gradient estimation (BSGE). Specifically, we first explore the theoretical property and the empirical characteristic of vanilla-powered stochastic gradient descent (P-SGD) with BSGE. Second, to further demonstrate the positive impact of BSGE in enhancing the P-SGD type algorithm, we investigate the feature of theory and experiment of P-SGD with momentum under BSGE, where we particularly focus on the effect of negative momentum in P-SGD that is less studied in PSO. Particularly, we prove that the overall complexity of the resulting algorithms matches that of advanced SO algorithms. Finally, large numbers of numerical experiments on benchmark datasets confirm the successful reformation of BSGE in perfecting PSO. This work provides comprehension of the role of BSGE in PSO algorithms, extending the family of PSO algorithms.},
  archive      = {J_TCSS},
  author       = {Zhuang Yang},
  doi          = {10.1109/TCSS.2024.3411630},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7435-7447},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {The powerball method with biased stochastic gradient estimation for large-scale learning systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MMPF: Multimodal purification fusion for automatic
depression detection. <em>TCSS</em>, <em>11</em>(6), 7421–7434. (<a
href="https://doi.org/10.1109/TCSS.2024.3411616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is a common mental disorder that requires objective and valid assessment tools. However, purely data-driven methods cannot satisfy the clinical diagnostic criteria for automatic depression detection (ADD), and the instability and heterogeneity of multimodal data have not been fully resolved. Therefore, we propose a novel auxiliary tool for ADD based on multimodal purification fusion (MMPF). Initially, a prior constraint gating (PCG) strategy is used to inject doctors’ constraints into depression data to guide and constrain the learning process. Then, we introduce text and audio encoders to extract unpurified features from preprocessed depression data. Afterward, multimodal purification refinement is proposed to extract unintersected common and specific features from unpurified features, generating purified features. Meanwhile, we leverage a multiperspective contrastive learning (MCL) strategy to enhance unpurified and purified features. Finally, modality interaction (MI) based on the transformer is proposed to conduct multimodal fusion. A dynamic corrective learning (DCL) strategy is introduced to tackle modality imbalances and inconsistent sentiment. MMPF is evaluated on the Distress Analysis Interview Corpus Wizard of Oz and performs promisingly in unimodal and multimodal depression detection, indicating its significant role in ADD.},
  archive      = {J_TCSS},
  author       = {Biao Yang and Miaomiao Cao and Xianlin Zhu and Suhong Wang and Changchun Yang and Rongrong Ni and Xiaofeng Liu},
  doi          = {10.1109/TCSS.2024.3411616},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7421-7434},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {MMPF: Multimodal purification fusion for automatic depression detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LIHAN: A lattice-guided incomplete heterogeneous information
network embedding model for node classification. <em>TCSS</em>,
<em>11</em>(6), 7411–7420. (<a
href="https://doi.org/10.1109/TCSS.2024.3405569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world heterogeneous information networks (HINs) are modeled as heterogeneous graphs, in which features and structures are often incomplete. Existing models employ manual imputation or dynamic adjustment to populate the incomplete data. However, there are some limitations in incomplete heterogeneous graph representation learning: 1) using populated data may lose content and high-level interaction information of HINs, even lead to negative impacts on the performance of downstream tasks; and 2) existing models fail to utilize the high-order heterogeneous structures in original incomplete network data. To resolve the above issues, in this article, we proposed a lattice-based incomplete heterogeneous structural attention network (LIHAN) for learning incomplete heterogeneous node embeddings. LIHAN first constructs characteristic lattice and structure lattice by mining characteristic sets and structure sets according to the partial order relations in between. Then, an improved lattice-based heterogeneous dual-attention mechanism is used to learn the heterogeneous node representations. Extensive node classification experiments are conducted on five open datasets to verify the superior performance of the proposed LIHAN model over the state-of-the-art models. Experimental results illustrate that LIHAN outperforms other methods on the micro-F1 and macro-F1 in node classification tasks. Moreover, experiments on different levels of lattices and the parameter sensitivity analysis shows the great stability during the process of experiments.},
  archive      = {J_TCSS},
  author       = {Guangxu Mei and Ziyu Guo and Li Pan and Qian Li and Feng Li and Shijun Liu},
  doi          = {10.1109/TCSS.2024.3405569},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7411-7420},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {LIHAN: A lattice-guided incomplete heterogeneous information network embedding model for node classification},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Adaptive weight and wasserstein distance constrained
low-rank sparse representation method for functional connectivity
network estimation. <em>TCSS</em>, <em>11</em>(6), 7400–7410. (<a
href="https://doi.org/10.1109/TCSS.2024.3400029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional connectivity (FC) network derived from resting-state functional magnetic resonance imaging (rs-fMRI) has been extensively employed in the automated identification of brain disorders. Conventional FC network modeling methods typically assign equal importance to different sampling points of rs-fMRI and brain regions of interest (ROIs). Nevertheless, considering temporal and regional heterogeneity, this assumption may not always be applicable. Moreover, sparse regression algorithms with regularization terms are commonly adopted to eliminate spurious FC. However, these conventional regularization terms impose a uniform sparse penalty on all FC without considering the prior knowledge that the brain tends to transmit information in an energetically efficient manner. To address the above problems, we propose an adaptive weight and Wasserstein distance constrained low-rank sparse representation (AW-WD-LSR) method to construct FC networks. Specifically, we employ adaptive weights to the reconstruction errors of rs-fMRI time series across various ROIs and sampling points, thereby amplifying the significance of crucial features in the joint representation, leading to a more robust FC network. Meanwhile, we incorporate a local constraint by introducing the optimal transport distance (i.e., Wasserstein distance) between ROIs to adjust the sparse penalty on the corresponding FC. The larger Wasserstein distance, the higher information transmission cost between two ROIs, resulting in a greater penalty imposed on the corresponding FC. The efficacy of the innovation modules is demonstrated in classification tasks involving major depressive disorder (MDD) with mixed features (MMF), MDD without mixed features (MDD noMF ), and healthy controls (HCs).},
  archive      = {J_TCSS},
  author       = {Jingyu Liu and Zhigang Li and Yuhang Sheng and Jingjing Zhou and Lei Feng and Hongxin Cai and Weijia Liu and Fuze Tian and Qunxi Dong and Rui Liu},
  doi          = {10.1109/TCSS.2024.3400029},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7400-7410},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Adaptive weight and wasserstein distance constrained low-rank sparse representation method for functional connectivity network estimation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robust maximum fairness consensus model with limited cost
under the uncertain trust relationships and individual weights.
<em>TCSS</em>, <em>11</em>(6), 7386–7399. (<a
href="https://doi.org/10.1109/TCSS.2024.3417263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertainty of the trust relationships between decision makers (DMs) or the uncertainty of individual weights will lead to the uncertainty of fairness and consensus management in group. To provide a solid solution, we propose a robust maximum fairness consensus model with limited cost under the uncertain trust relationships and individual weights (RTRMFCM). Specifically, this article constructs an uncertainty set to more precisely describe the uncertainty of the trust relationship between DMs. Based on individual fair preference considerations from the trust network, we adopt a robust optimization method to reduce the risk of DMs feeling unfair. Furthermore, a robust approach based on the combination of uncertain individual weights has been developed to reduce the risk of consensus being destroyed. Then, some theoretical analyzes are presented. We also provide a numerical analysis to validate the applicability of the RTRMFCM. Finally, the simulation analyses have revealed the characteristics of the RTRMFCM, and show that the RTRMFCM is more effective than the maximum fairness consensus model with limited cost under trust relationship (TRMFCM).},
  archive      = {J_TCSS},
  author       = {Xu Zhou and Gaocan Gong and Quanbo Zha and Min Zhan},
  doi          = {10.1109/TCSS.2024.3417263},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7386-7399},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A robust maximum fairness consensus model with limited cost under the uncertain trust relationships and individual weights},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fairness-aware maximal cliques identification in attributed
social networks with concept-cognitive learning. <em>TCSS</em>,
<em>11</em>(6), 7373–7385. (<a
href="https://doi.org/10.1109/TCSS.2024.3445721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed social networks are pervasive in real life and play a crucial role in shaping various aspects of society. These networks not only capture the connections between individuals but also encompass the associated attributes and characteristics. Analyzing and understanding these attributes provide insights into social behaviors, information diffusion patterns, and the formation of influential communities. Consequently, we propose a novel algorithm for detecting fairness-aware maximal cliques in the attributed social networks. We extract the concept lattice of attributed social networks and quantify these concepts using the concept stability and fairness measures defined in this article. By utilizing the proposed fairness-aware distance, we identify fairness-aware maximal cliques within attributed social networks. The effectiveness of the algorithm is then validated using five real-world network datasets. Experimental results fully demonstrate the effectiveness and scalability of our approach in identifying key structures, analyzing attribute networks, and promoting the development of responsible computational systems.},
  archive      = {J_TCSS},
  author       = {Min Tao and Fei Hao and Ling Wei and Huilai Zhi and Sergei O. Kuznetsov and Geyong Min},
  doi          = {10.1109/TCSS.2024.3445721},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7373-7385},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Fairness-aware maximal cliques identification in attributed social networks with concept-cognitive learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient planning method to recommend COA based on new
command and control organizational structure model. <em>TCSS</em>,
<em>11</em>(6), 7359–7372. (<a
href="https://doi.org/10.1109/TCSS.2024.3408653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a command and control (C2) organizational structure model, which can analyze military C2 organization structure from three perspectives: organizational elements, organizational relationships, and organizational processes. In the organizational processes, a decision-making problem of recommending course of action (COA) is described. Then, a planning method is proposed to solve this decision-making problem, which includes six evaluation metrics of COA effectiveness and a tabu search algorithm implemented within the C2 organization structure model. On this basis, we provide two application examples to demonstrate the usability of the proposed C2 organizational structure model and its COA planning method for operational decision-making.},
  archive      = {J_TCSS},
  author       = {Lijian Sun and Yun Zhou and Hanlin You and Cheng Zhu and Weiming Zhang},
  doi          = {10.1109/TCSS.2024.3408653},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7359-7372},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An efficient planning method to recommend COA based on new command and control organizational structure model},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Smart management of sand-breaking systems for taklimakan
SandSea highway: A parallel intelligence and fuzzy control approach.
<em>TCSS</em>, <em>11</em>(6), 7348–7358. (<a
href="https://doi.org/10.1109/TCSS.2024.3413795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The planning, construction, and maintenance of sand-breaking systems around highway in Taklimakan SandSea mainly depend on expert&#39;s empirical knowledge, and face the problems of time-consuming management, unpredictable system performance, and few available data. This work proposes a management and control method of sand-breaking systems that follows artificial system, computational experiments, and parallel execution (ACP) theory. Expert knowledge was extracted to develop artificial sand-breaking system. conditional tabular generative adversarial network (CTGAN) was developed to achieve data augmentation. Computational experiments were implemented to evaluate artificial system performance by predicting whether the system can reach the set age limit. Using fuzzy control, the real sand-breaking system and the artificial one can learn from each other in parallel execution to provide decision support for sand-breaking system management. This approach provides a human–machine hybrid parallel intelligence system for complex sand-breaking systems management.},
  archive      = {J_TCSS},
  author       = {Fangle Chang and Xiujuan Wang and Mengzhen Kang and Yu Tao and Jiahong Yang and Jiaqiang Lei and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3413795},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7348-7358},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Smart management of sand-breaking systems for taklimakan SandSea highway: A parallel intelligence and fuzzy control approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nuclear pollution or safe discharge: Topic evolution and
cognitive analysis on fukushima’s treated radioactive water.
<em>TCSS</em>, <em>11</em>(6), 7338–7347. (<a
href="https://doi.org/10.1109/TCSS.2024.3406700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the Societies 5.0, a series of discussions on the emerging Fukushima treated radioactive water (FTRW) event was carried out, which has an impact on sustainable development in multiple fields including the economy, culture, and society. In order to comprehensively understand emerging topics and their evolution, explore the impact of people&#39;s cognition on their participation, and focus on people&#39;s attitudes and public participation in the FTRW event, we propose an evolution analysis framework (EAF) to analyze the massive multilingual comments and news collected from social media platforms in several countries. We design a multilingual topic extraction model (XLM-topic) to detect the patterns of topics and analyze their evolution. Potential relations between the FTRW event&#39;s elements are explored by relational reasoning based on a knowledge graph, which is established by entities and relations extracted from comments and news. Moreover, we predict the public attitudes and participation toward the FTRW event by utilizing our custom-designed public opinion cellular automata (POCA). The proposed POCA simulates the information dissemination, cognitive changes, and topic evolution among social groups in virtual spaces. It collaborates with XLM-topic to analyze trends in both physical and virtual spaces. Analysis results indicate that participants in different regions and countries have different attitudes and reactions toward the FTRW event, and the public&#39;s cognition on this event will interact with itself. Our study is conducive to promoting the integration and interaction of virtual space and physical space in the context of Societies 5.0, providing decision-making support for building a more harmonious and stable social environment.},
  archive      = {J_TCSS},
  author       = {Xin Liu and Ziliang Chen and Fei-Yue Wang and Dawei Yang and Rui Qin and Mingjiang Pang and Qinghua Ni and Huiquan Gao},
  doi          = {10.1109/TCSS.2024.3406700},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7338-7347},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Nuclear pollution or safe discharge: Topic evolution and cognitive analysis on fukushima&#39;s treated radioactive water},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancements in affective disorder detection: Using
multimodal physiological signals and neuromorphic computing based on
SNNs. <em>TCSS</em>, <em>11</em>(6), 7309–7337. (<a
href="https://doi.org/10.1109/TCSS.2024.3420445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the integration of artificial intelligence (AI) techniques with multimodal physiological signals represents a pivotal approach to detect affective disorders (ADs). With the increasing complexity and diversity of physiological signal modalities, researchers have introduced various AI methods using multimodal physiological signals to improve model classification performance and explainability to increase trust and facilitate clinical adoption. Among these methods, spiking neural networks (SNNs) stand out as a promising avenue due to their alignment with the operating principles of the human brain, robust biological explainability, and adeptness in processing spatial–temporal information in an efficient event-driven manner with low power consumption. Furthermore, the emergence of neuromorphic computing (NC) chips based on SNNs has greatly bolstered the field of NC, enabling effective support for objective, pervasive, and wearable AI-assisted medical diagnostic devices for ADs and other diseases. This article presents a review of recent achievements in multimodal AD detection and points out the associated challenges in utilizing multimodal physiological signals and NC based on SNNs for AD detection. Building upon this foundation, we give perspectives on future work. The intended readership for this review consists of researchers in the fields of cognitive computing, computational psychophysiology, affective computing, NC, and brain-inspired computing. We hope that this survey not only garners increased attention from the scientific community but also serves as a valuable guide for future studies in this field.},
  archive      = {J_TCSS},
  author       = {Fuze Tian and Lixin Zhang and Lixian Zhu and Mingqi Zhao and Jingyu Liu and Qunxi Dong and Qinglin Zhao},
  doi          = {10.1109/TCSS.2024.3420445},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7309-7337},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Advancements in affective disorder detection: Using multimodal physiological signals and neuromorphic computing based on SNNs},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tensor correlation fusion for multimodal physiological
signal emotion recognition. <em>TCSS</em>, <em>11</em>(6), 7299–7308.
(<a href="https://doi.org/10.1109/TCSS.2024.3406988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an essential challenge within the realm of affective computing, emotion recognition assumes a vital role in bestowing computers with a higher level and comprehensive intelligence. Furthermore, it has emerged as a crucial research topic in both human–computer interaction (HCI) and medical rehabilitation related to mental illnesses. However, the related fusion studies for modeling physiological signals in emotion recognition are less based on multimodal coordinated representation and lack the exploration of multimodal physiological signal correlation. In this article, we propose a tensor correlation fusion framework for emotion recognition based on multimodal physiological signals. After extracting effective features from various physiological signals, the coordinated representation module of the framework first simultaneously learns the linear correlation of all input physiological signals based on the covariance tensor. An optimized solution strategy is constructed to obtain the coordinated representation corresponding to each physiological signal. Finally, an emotion recognition module fuses the correlation information of the coordinated representation of different physiological signals as input to the emotion recognition classifier. This framework constructs coordinated representation by introducing a strategy to simultaneously capture the correlation among multiple physiological signals, providing a fresh perspective with a well-defined mathematical foundation for the fusion of multimodal physiological signals in the realm of emotion recognition. The experiments conducted on the DEAP dataset demonstrate that compared with related methods, the framework achieves relatively higher emotion recognition performance while obtaining a coordinated representation of multimodal physiological signal correlations of emotions, all while achieving superior processing speed.},
  archive      = {J_TCSS},
  author       = {Jian Shen and Kexin Zhu and Huakang Liu and Jinwen Wu and Kang Wang and Qunxi Dong},
  doi          = {10.1109/TCSS.2024.3406988},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7299-7308},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Tensor correlation fusion for multimodal physiological signal emotion recognition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal enhanced multimodal graph neural networks for fake
news detection. <em>TCSS</em>, <em>11</em>(6), 7286–7298. (<a
href="https://doi.org/10.1109/TCSS.2024.3404921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news detection is of crucial importance and has received great attention. However, the existing fake news detection methods rarely consider the news release time, which limits the achievable detection performance, especially for detecting the instant fake news clusters that have sudden and aggregated characteristics. To tackle this issue, a temporal enhanced multimodal graph neural networks (TEMGNNs) method is proposed. The multimodal graph with semantic complementary enhancement is developed by feature aggregation of textual information, image information, and external knowledge. Moreover, the associations among different modalities are obtained by using the graph attention networks and the weights of each modality are adaptively learned. Furthermore, the aggregation of news with adjacent time and the same topic to form a temporal news cluster and learning temporal features for fake new detection by using our proposed graph neural networks. Extensive experiments results obtained on two public datasets demonstrate that our proposed method has the best performance compared with the benchmark methods. It is also shown that the exploitation of the temporal information and multimodal information benefits for fake news detection.},
  archive      = {J_TCSS},
  author       = {Zhibo Qu and Fuhui Zhou and Xi Song and Rui Ding and Lu Yuan and Qihui Wu},
  doi          = {10.1109/TCSS.2024.3404921},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7286-7298},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Temporal enhanced multimodal graph neural networks for fake news detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Throughput-scalable shard reorganization tailored to node
relations in sharding blockchain networks. <em>TCSS</em>,
<em>11</em>(6), 7271–7285. (<a
href="https://doi.org/10.1109/TCSS.2024.3406769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sharding is a promising strategy to enhance blockchain scalability. However, the surge in transactions has led to heightened relations between nodes in the system, reflecting the volume of transactions between them. The increase in related nodes engaging in identical transactions across diverse shards leads to substantial cross-shard transactions, contributing to communication delays and impeding enhancements in throughput. Current methods typically employ greedy or heuristic approaches to organize nodes into shards, resulting in marginal reductions in the total relation between related nodes in different shards (i.e., the number of cross-shard transactions), while causing shard imbalance. Hence, there is a crucial need for periodic shard reorganization based on node relations to minimize the total relation between related nodes across different shards while ensuring shard balance. In this article, we investigate the reorganization of nodes into shards based on node relations in sharding blockchains, aiming to minimize the total relation between related nodes in different shards. We formulate the shard reorganization problem and introduce the shard reorganization algorithm based on the relation between nodes (SRRN) to address this issue. Theoretical analysis proves that SRRN is a $2\lambda M$ -approximation algorithm, where $\lambda=({r_{\max}}/{r_{\min}})$ , with $M$ representing the number of shards, and $r_{\max}$ and $r_{\min}$ denoting the maximum and minimum nonzero relations between nodes, respectively. Simulation results demonstrate that SRRN outperforms baseline algorithms in terms of total relation, degree of relation reduction, differences in computing power between shards, cross-shard ratio, and throughput.},
  archive      = {J_TCSS},
  author       = {Liping Tao and Yang Lu and Yuqi Fan and Lei Shi and Chee Wei Tan and Zhen Wei},
  doi          = {10.1109/TCSS.2024.3406769},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7271-7285},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Throughput-scalable shard reorganization tailored to node relations in sharding blockchain networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep masked graph node clustering. <em>TCSS</em>,
<em>11</em>(6), 7257–7270. (<a
href="https://doi.org/10.1109/TCSS.2024.3401218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, reconstructing features and learning node representations by graph autoencoders (GAE) have attracted much attention in deep graph node clustering. However, existing works often overemphasize structural information and overlook the impact of real-world prevalent noise on feature learning and clustering with graph data, which may be detrimental to robust training. To address these issues, the utilization of a masking strategy that specifically focuses on feature reconstruction may mitigate these limitations. In this article, we propose a graph node clustering generative method named deep masked graph node clustering (DMGNC), which leverages a masked autoencoder to effectively reconstruct node features, enabling the discovery of latent information crucial for accurate node clustering. Additionally, a clustering self-optimization module is designed to guide the iterative update of our end-to-end clustering framework. Further, we extend the masked graph autoencoder (MGA) and develop a contrastive method called deep masked graph node contrastive clustering (DMGNCC), which applies the MGA to graph node contrastive learning at both the node level and the class level in a united model. Extensive experimental results on real-world graph benchmark datasets demonstrate the effectiveness and superiority of the proposed method.},
  archive      = {J_TCSS},
  author       = {Jinbin Yang and Jinyu Cai and Luying Zhong and Yueyang Pi and Shiping Wang},
  doi          = {10.1109/TCSS.2024.3401218},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7257-7270},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Deep masked graph node clustering},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CeKT: Knowledge tracing for predicting collective
performance on exercise sequence. <em>TCSS</em>, <em>11</em>(6),
7244–7256. (<a href="https://doi.org/10.1109/TCSS.2024.3406048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of artificial intelligence has become a hot topic in the field of education. However, current studies primarily focus on personalization for learners, with the aim of accurately modeling learners’ knowledge level based on their learning history and providing better personalized services, while overlooking the needs of educators. In contrast to the focus on personalization of learners, educators place greater emphasis on accurately assessing collective performance and relative differences within a group, which serves as a qualitative measure of the teaching quality. In this study, we investigate collective knowledge tracing (CeKT), a method designed to estimate the average knowledge level of all students in a course based on a sequence of exercises. To achieve this objective, we propose a graph-based solution capable of estimating the average knowledge level solely from the exercise sequence as well as capturing the intrinsic structure of the exercise sequence (i.e., the sequential order of exercises and the repetition of exercises). Through experimental validation, we affirm that our approach enables a precise estimation of the average knowledge mastery of all students given an exercise sequence and also holds distinct value in three applications within the education domain.},
  archive      = {J_TCSS},
  author       = {Zetao Zheng and Zhengyang Wu and Zahir Tari and Jia Zhu and Ke Deng},
  doi          = {10.1109/TCSS.2024.3406048},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7244-7256},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {CeKT: Knowledge tracing for predicting collective performance on exercise sequence},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BERT-based deceptive review detection in social media:
Introducing DeceptiveBERT. <em>TCSS</em>, <em>11</em>(6), 7234–7243. (<a
href="https://doi.org/10.1109/TCSS.2024.3403937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the Internet has facilitated the emergence of social media platforms as significant channels for individuals to express their thoughts and engage in instantaneous interactions. However, the reliance on online reviews has also given rise to deceptive practices, where anonymous spammers generate fake reviews to manipulate the perception of a product. Ensuring the integrity of the online review system requires identifying and mitigating fake reviews. While existing machine learning (ML)- and neural network (NN)-based sentiment analysis methods can detect deceptive reviews, they often suffer from long training times, high computational resource requirements, and memory constraints. This study aims to overcome these limitations by introducing a transformer-based “deceptive bidirectional encoder representations from transformers (DeceptiveBERT) model.” This model utilizes contextual representations to enhance the precision of deceptive review identification. Transfer learning is employed to leverage knowledge from a pre-existing BERT base-uncased word embedding model, enabling efficient feature extraction. The proposed model incorporates a combination of classification layers to categorize reviews into two distinct categories: deceptive and truthful. Additionally, the study addresses the challenge of imbalanced datasets by utilizing three separate datasets and implementing appropriate methodologies for dataset curation. The effectiveness of the DeceptiveBERT model was evaluated through experimentation. The results demonstrate its efficacy, with the model achieving accuracy rates of 75%, 84.79%, and 81.08% on the Ott, YelpNYC, and YelpZip datasets, respectively.},
  archive      = {J_TCSS},
  author       = {Syeda Basmah Hyder and Noshina Tariq and Syed Atif Moqurrab and Muhammad Ashraf and Joon Yoo and Gautam Srivastava},
  doi          = {10.1109/TCSS.2024.3403937},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7234-7243},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {BERT-based deceptive review detection in social media: Introducing DeceptiveBERT},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). End-to-end visual grounding framework for multimodal NER in
social media posts. <em>TCSS</em>, <em>11</em>(6), 7223–7233. (<a
href="https://doi.org/10.1109/TCSS.2024.3402738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal named entity recognition (MNER) for social media aims to detect named entities in user-generated posts with the aid of visual information from attached images. Existing methods use pretrained visual models or visual grounding (VG) toolkits to learn visual information. However, they still suffer from the mismatch issue, where the visual features extracted from visual encoder are inconsistent with actual requirements for cross-modal interaction. In an ideal scenario, the visual encoder should actively extract visual information guided by the text, which inherently provides the blueprint of desired visual features. In this article, we present an end-to-end VG framework for MNER task (VG-MNER), which adaptively learns the text-related visual features. Specifically, we introduce a backbone network with a feature fusion module to learn and aggregate multisize visual representations. We then develop a text-related visual attention to refine the visual features. Notably, entity-image contrast loss is designed to guide the training of visual encoder. The proposed model outperforms several state-of-the-art methods, achieving F1 scores of 75.62% and 88.11% on two benchmark datasets. Experimental results reveal the effectiveness of leveraging text-related visual information in the MNER task.},
  archive      = {J_TCSS},
  author       = {Yifan Lyu and Jiapei Hu and Yun Xue and Qianhua Cai},
  doi          = {10.1109/TCSS.2024.3402738},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7223-7233},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {End-to-end visual grounding framework for multimodal NER in social media posts},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CDME-GAT: Context-aware depression detection using
multiembedding and graph attention networks in social media text.
<em>TCSS</em>, <em>11</em>(6), 7212–7222. (<a
href="https://doi.org/10.1109/TCSS.2024.3402689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression, a prevalent mental health concern, requires timely identification and intervention. Automating the early stage identification of depression cues within social media text has become critically important. Existing methods for depression identification through text obtained from social media have shown promising results; however, these methods do not address the graphlike nature of social media data. To date, there has been little work addressing this problem by appropriately modeling social media data. This article aims to effectively harness the power of multiembedding techniques and graph attention networks (GATs) for depression identification. To overcome these limitations, the current study presents a novel methodology that combines multiple token-level embeddings, including BERT, RoBERTa, and DeBERTa, with GATs to leverage the graphlike nature of social media data and detect depression cues from such text. A dataset comprising 100 000 tweets has been curated using data from publicly available annotated tweet datasets. This dataset maintains a balanced distribution between depressive and nondepressive text samples. This was followed by a rigorous cleaning and preprocessing pipeline. Next, these data were transformed into a numeric feature matrix using multiple-word embeddings, which enabled the treatment of tweets as nodes in a graphlike structure. This graph was used for training a GAT model with multiple self-attentional layers, culminating in a linear layer for mapping traits to binary classes. The model presented in the current study achieves a precision of 97.2%, a recall of 96.4%, and an F1 score of 96.7% on a benchmark dataset.},
  archive      = {J_TCSS},
  author       = {Minni Jain and Siddh Jain and Amita Jain and Bhavuk Garg},
  doi          = {10.1109/TCSS.2024.3402689},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7212-7222},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {CDME-GAT: Context-aware depression detection using multiembedding and graph attention networks in social media text},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Disentangled representation learning for structural role
discovery. <em>TCSS</em>, <em>11</em>(6), 7200–7211. (<a
href="https://doi.org/10.1109/TCSS.2024.3404975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roles are defined as the equivalent classes of isomorphic nodes in the network. They focus on the local connective patterns and describe the structural similarities between nodes, and learning role-based network embeddings can help to recognize identities or functions of entities in real-world networks. This field has been studied over the past decades, however, the existing role-based network embedding methods all concentrate too much on distinguishing node structures and ignore that nodes can belong to different roles even if they have the same local structures. Not only the classical network structure can influence the role of node, but also the emergence of different type of relationship between nodes has impact to it. We believe that roles are influenced by multiple independent factors, and nodes in the same roles should possess both similar local structures and entangled patterns with neighbors hidden in each factor, but most of the existing methods did not clearly point out this challenge. Therefore, we propose a disentangled framework based on graph neural networks to simultaneously model the local structures and interactive relationships in multiple factors to generate role-oriented network embeddings. We design a novel role-aware neighbor choosing mechanism to assign each neighbor a different interactive weight for each latent factor, which can measure its influence on roles. We conduct experiments on synthetic and real-world networks, and the results demonstrate the superiority and effectiveness of our model.},
  archive      = {J_TCSS},
  author       = {Wang Zhang and Lin Pan and Xuan Guo and Pengfei Jiao},
  doi          = {10.1109/TCSS.2024.3404975},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7200-7211},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Disentangled representation learning for structural role discovery},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TriKF: Triple-perspective knowledge fusion network for
empathetic question generation. <em>TCSS</em>, <em>11</em>(6),
7186–7199. (<a href="https://doi.org/10.1109/TCSS.2024.3418820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Questioning is one of the essential tactics for demonstrating empathy in social dialogues. Effective questioning can guide individuals to express their experiences, feelings, and thoughts, aiming to establish emotional connections and deepen interpersonal understanding. However, how to generate empathetic questions in emotional support conversations remains an unresolved issue. To fill this research gap to some extent, we propose an empathetic question generation (QG) framework called triple-perspective knowledge fusion (TriKF), which incorporates external knowledge from the perspectives of events, cognition, and affection to comprehensively understand the dialogue context. Specifically, this framework acquires commonsense knowledge from these three perspectives and integrates them into the dialogue context to enrich the contextual information. To the best of our knowledge, this is the first method proposed for empathetic QG. Additionally, we construct an empathetic question dataset, namely EQ-EMAC. This dataset comprises 4213 dialogues with single user inputs and multiple empathetic question responses, which can be utilized to assess the effectiveness and generalization capability of empathetic QG models. Experimental results have demonstrated the effectiveness of TriKF on the task of empathetic QG compared with seven baseline models.},
  archive      = {J_TCSS},
  author       = {Tiantian Chen and Ying Shen and Xuri Chen and Lin Zhang and Shengjie Zhao},
  doi          = {10.1109/TCSS.2024.3418820},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7186-7199},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {TriKF: Triple-perspective knowledge fusion network for empathetic question generation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unveiling cognitive constraints in language production:
Extracting and validating the active ego network of words.
<em>TCSS</em>, <em>11</em>(6), 7173–7185. (<a
href="https://doi.org/10.1109/TCSS.2024.3419565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The “ego network of words” model captures structural properties in language production associated with cognitive constraints. While previous research focused on the layer-based structure and its semantic properties, this article argues that an essential element, the concept of an active network , is missing. The active part of the ego network of words only includes words that are regularly used by individuals, akin to the ego networks in the social domain, where the active part includes relationships regularly nurtured by individuals, and hence demanding cognitive effort. In this work, we define a methodology for extracting the active part of the ego network of words and validate it using interview transcripts and tweets. The robustness of our method to varying input data sizes and temporal stability is demonstrated. We also demonstrate that without the active network concept (and a tool for properly extracting the active network from data), the “ego network of words” model is not able to properly estimate the cognitive effort involved and it becomes vulnerable to the amount of data considered (leading to the disappearance of the layered structure in large datasets). Our results are well-aligned with prior analyses of the ego network of words, where the limitation of the data collected led automatically (and implicitly) to approximately consider the active part of the network only. Moreover, the validation on the transcripts dataset (MediaSum) highlights the generalizability of the model across diverse domains and the ingrained cognitive constraints in language usage.},
  archive      = {J_TCSS},
  author       = {Kilian Ollivier and Chiara Boldrini and Andrea Passarella and Marco Conti},
  doi          = {10.1109/TCSS.2024.3419565},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7173-7185},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Unveiling cognitive constraints in language production: Extracting and validating the active ego network of words},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Seeing through the mask: Recognition of genuine emotion
through masked facial expression. <em>TCSS</em>, <em>11</em>(6),
7159–7172. (<a href="https://doi.org/10.1109/TCSS.2024.3404611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of facial expression recognition is to recognize the corresponding emotions. However, people tend to hide their emotions by displaying facial expressions that differ from those evoked by emotions. These inconsistent facial expressions are referred to as masked facial expressions (MFEs). The automatic recognition of hidden emotions within an MFE using image data is challenging. In this study, we find distinctive movement patterns in the facial action units (AUs) of MFE sequences through a detailed analysis. Considering our findings, we propose handcrafted features called dynamic AU intensity features (DAIFs) to represent AU movement. Furthermore, we develop a decoupled AU transformer (DAUT) model for recognition, where the decoupled convolution operators ensure that the temporal information in the DAIF is not damaged. To further improve the recognition performance, we design self-supervised clip prediction for pretraining of DAUT. Experimental results demonstrate that our proposed method performs exceptionally well across all tasks in the MFE dataset, particularly improving accuracy by nearly double on the most challenging 36-class task. This suggests that leveraging temporal information from facial AU movements is a reliable and effective technique for recognizing MFEs.},
  archive      = {J_TCSS},
  author       = {Ju Zhou and Xinyu Liu and Hanpu Wang and Zheyuan Zhang and Tong Chen and Xiaolan Fu and Guangyuan Liu},
  doi          = {10.1109/TCSS.2024.3404611},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7159-7172},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Seeing through the mask: Recognition of genuine emotion through masked facial expression},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Modeling the contributions of participator, content, and
network to topic duration in online social group. <em>TCSS</em>,
<em>11</em>(6), 7146–7158. (<a
href="https://doi.org/10.1109/TCSS.2024.3414586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a common phenomenon that often appears on social platforms, news sites, and community forums, topics have played an irreplaceable role in public opinion and social governance. Meanwhile, people&#39;s daily lives are increasingly dependent on the breeding, transformation, and attenuation of hot topics. This article aims to discuss the problem about topic duration, that is, what are the principle factors that affect topic duration? Why do some topics survive longer and even generate subtopics, while other topics disappear rapidly? To answer these questions, we innovatively use 104 121 alliance chat content in Nova Empire II from July 2023 to December 2023 as a case study. Dynamic topics trajectories are first obtained from a novel multilevel association model. Then, a potential factors system based on the dimensions of topic properties, topic users, and social network is established to quantitatively evaluate the influence for different factors. Experimental results from a robust statistical analysis framework demonstrate that higher topic discussion intensity, more content from opinion leader, faster information diffusion, and closer intertopic correlations will significantly improve the topic duration. Finally, a series of strategies are proposed to promote the design of social system applications from the perspectives of online social group.},
  archive      = {J_TCSS},
  author       = {Guoshuai Zhang and Jiaji Wu and Gwanggil Jeon and Penghui Wang and Yuan Chen and Yuhui Wang and Mingzhou Tan},
  doi          = {10.1109/TCSS.2024.3414586},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7146-7158},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Modeling the contributions of participator, content, and network to topic duration in online social group},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). User experience of different groups in social VR
applications: An empirical study based on user reviews. <em>TCSS</em>,
<em>11</em>(6), 7133–7145. (<a
href="https://doi.org/10.1109/TCSS.2024.3416208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social virtual reality (VR) applications provide a diverse and evolving ecosystem for different groups to socialize in VR. Understanding how people explore social VR applications is crucial for VR developers, such as designing social VR content. Previous work has focused on interviewing participants to study the user experience (UX) of social VR. However, the potential value of user reviews of social VR platforms is largely unexplored. In this article, we collect 105 757 user reviews of nine social VR applications from two digital distribution platforms (Steam and Oculus) to study the impact of social VR on people by in-depth analysis of reviews related to avatars, harassment, and physical reactions of different groups. We observe that players prefer avatar customization, and social VR applications are suitable places for some groups, such as lesbian, gay, bisexual, transgender, queer (LGBTQ). However, there are also many complaints from players about harassment and bullying in these social VR applications. Our findings highlight potential design implications of social VR applications for creating more friendly and fulfilling social VR experiences for users.},
  archive      = {J_TCSS},
  author       = {Jiong Dong and Kaoru Ota and Mianxiong Dong},
  doi          = {10.1109/TCSS.2024.3416208},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7133-7145},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {User experience of different groups in social VR applications: An empirical study based on user reviews},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review on machine theory of mind. <em>TCSS</em>,
<em>11</em>(6), 7114–7132. (<a
href="https://doi.org/10.1109/TCSS.2024.3416707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theory of Mind (ToM) is the ability to attribute mental states to others, an important component of human cognition. At present, there has been growing interest in the artificial intelligence (AI) with cognitive abilities, for example in healthcare and the motoring industry. Research indicates that infants exhibit early signs in cognitive and social understanding, including some basic abilities related to beliefs, desires, and intentions (BDIs). Thus, the ability to attribute BDIs to others is also crucial for the development of machine ToM. In this article, we review recent progress in machine ToM on BDIs. And we shall introduce the experiments, datasets, and methods of machine ToM on these three aspects, summarize the development of different tasks and datasets in recent years, and compare well-behaved models in aspects of advantages, limitations, and applicable conditions, hoping that this study can guide researchers to quickly keep up with latest trend in this field. Unlike other domains with a specific task and resolution framework, machine ToM lacks a unified instruction and a series of standard evaluation tasks, which make it difficult to formally compare the proposed models. And the existing models still cannot exhibit the same ToM reasoning ability as real humans, lack of transferability, interpretability, few-shot learning, etc. We argue that, one method to address this difficulty is now to present a standard assessment criteria and dataset, better a large-scale dataset covered multiple aspects of ToM. Besides, for developing an AI of ToM, it requires the cooperation of experts from various domains.},
  archive      = {J_TCSS},
  author       = {Yuanyuan Mao and Shuang Liu and Qin Ni and Xin Lin and Liang He},
  doi          = {10.1109/TCSS.2024.3416707},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7114-7132},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A review on machine theory of mind},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Large-scale traffic prediction with hierarchical hypergraph
message passing networks. <em>TCSS</em>, <em>11</em>(6), 7103–7113. (<a
href="https://doi.org/10.1109/TCSS.2024.3419008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) are widely used in social computation such as urban traffic prediction. However, when faced with city-level forecasting challenges, the graph-based deep learning methods struggle to process large-scale multivariate data effectively. To address the challenges of limited scalability, a traffic prediction framework based on a hypergraph message passing network (HMSG) is proposed in this article. The model represents the urban transportation network with hypergraph, where nodes denote transportation hubs and hyperedges represent their relationship at geographical and feature level. Compared with pairwise edges, hyperedges are more scalable and flexible, providing a more descriptive representation of traffic information. The HMSG algorithm updates node and hyperedge features in two steps, facilitating effective and efficient integration of hidden spatial features across layers. The proposed framework is evaluated on large-scale historical datasets and demonstrates its completion of city-scale traffic prediction tasks. The results also show that it matches the accuracy of existing traffic prediction methods on small-scale datasets. This validates the potential of the traffic prediction model based on the HMSG algorithm for intelligent transportation applications.},
  archive      = {J_TCSS},
  author       = {Jingcheng Wang and Yong Zhang and Yongli Hu and Baocai Yin},
  doi          = {10.1109/TCSS.2024.3419008},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7103-7113},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Large-scale traffic prediction with hierarchical hypergraph message passing networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sustainable COVID-19 policy responses with urban mobility
network epidemic models. <em>TCSS</em>, <em>11</em>(6), 7086–7102. (<a
href="https://doi.org/10.1109/TCSS.2024.3418622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has challenged countries worldwide to strike a balance between implementing epidemic control measures and maintaining economic activity. In response, many countries have adopted sustainable, precise, region-specific, and multilevel prevention and control measures. To apply these measures more effectively and purposefully, it is imperative to quantify their impact on the transmission of COVID-19 within urban areas. Here, we propose a dynamic metapopulation susceptible-exposed-infectious-removed (SEIR) model that incorporates the urban mobility network to simulate the spread of COVID-19 in Beijing and investigate the effects of precise intervention measures. Our proposed model accurately fits the real epidemic trajectory, even with the significant changes in human mobility patterns before and after the epidemic. Additionally, it can also serve as a useful policy evaluation tool by simulating the impact of perturbations in mobility networks on epidemic transmission dynamics. Based on this tool, our results demonstrate that point-of-interest capacity limitation measures can significantly reduce the number of infections with only a minor loss of urban mobility. Furthermore, we show that community dynamic management measures can effectively control and mitigate COVID-19 spread while enabling the normal operation of most economic and social activities. By quantifying the impact of precise intervention measures on new infections and mobility losses, our model enables a cost-benefit analysis of these measures, thus informing targeted and sustainable policy responses to COVID-19.},
  archive      = {J_TCSS},
  author       = {Yanggang Cheng and Shibo He and Cunqi Shao and Chao Li and Jiming Chen},
  doi          = {10.1109/TCSS.2024.3418622},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7086-7102},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Sustainable COVID-19 policy responses with urban mobility network epidemic models},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Metacracy: A new governance paradigm beyond bounded
intelligence. <em>TCSS</em>, <em>11</em>(6), 7072–7085. (<a
href="https://doi.org/10.1109/TCSS.2024.3493372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCSS},
  author       = {Fei-Yue Wang and Rui Qin and Juanjuan Li and Levente Kováacs and Bin Hu},
  doi          = {10.1109/TCSS.2024.3493372},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {12},
  number       = {6},
  pages        = {7072-7085},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Metacracy: A new governance paradigm beyond bounded intelligence},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cryptoeconomic user behavior in the acute stages of
geopolitical conflict. <em>TCSS</em>, <em>11</em>(5), 7055–7068. (<a
href="https://doi.org/10.1109/TCSS.2024.3404590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geopolitical conflicts significantly impact financial networks and systems, e.g., Russia and Ukraine. Cryptoeconomic blockchains such as Bitcoin and Ethereum were introduced as substitutes for traditional financial systems and might behave differently under significant stress. The Russia–Ukraine conflict allowed us to analyze the impact of such complex geopolitical conflicts on the user behaviors of cryptoeconomic blockchains. This article investigates the early stage of such geopolitical conflict using time-varying graphs. We collected and analyzed all the transactions for Bitcoin and Ethereum that took place 2 weeks before and after the conflict started, i.e., we focused on what can be defined as the acute impact of such an event. Our results suggest that the early stage of such geopolitical conflicts may significantly affect cryptoeconomic blockchains’ user behaviors. For instance, we detected that some users behaved more cautiously during the preconflict phase and resumed normalcy during the postconflict phase but exhibited a shift in their behavior. This article analyzes the relationship between the early stages of geopolitical conflicts and cryptoeconomic systems.},
  archive      = {J_TCSS},
  author       = {Jorão Gomes and Heder Bernardino and Alex Borges Vieira and Verena Dorner and Davor Svetinovic},
  doi          = {10.1109/TCSS.2024.3404590},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {7055-7068},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Cryptoeconomic user behavior in the acute stages of geopolitical conflict},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Virtual-coupling-based timetable rescheduling for heavy-haul
railways under disruptions. <em>TCSS</em>, <em>11</em>(5), 7045–7054.
(<a href="https://doi.org/10.1109/TCSS.2024.3404550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the demand for coal and other ore resources increases, the hauling capacity of heavy-haul railways is severely challenged. Virtual coupling technology has gained attention for its ability to improve operational efficiency in bottleneck sections and reduce the time it takes for trains operating on the line to resume normal operation during emergencies. In this article, virtual coupling-based timetable rescheduling method is proposed to reduce the delays under disruptions and improve the line capacity. A mixed-integer linear program (MILP) model that allows trains to be coupled either at departure or by sharing the same arrival and departure line is formulated to reduce the delay time and its propagation range. The strategies of retiming, rearranging tracks, and virtual coupling are adopted to collaboratively optimize the deviation in train schedules and track utilization under disruptions, aiming to enhance the occupancy capacity of arrival and departure lines while simultaneously reducing train delays. A heuristic algorithm utilizing simulated annealing (SA)-particle swarm optimization (PSO) algorithm is developed to generate optimal train coupling and stopping schemes. Numerical experiments are conducted to verify the effectiveness of the proposed model and heuristic algorithm on a real heavy-haul railway configuration. The results demonstrate that our method effectively reduces train delays and minimizes the impact of track utilization on adjacent stations, as well as the repercussions of train delays on subsequent stations.},
  archive      = {J_TCSS},
  author       = {Xiaolan Ma and Min Zhou and Hongwei Wang and Weichen Song and Hairong Dong},
  doi          = {10.1109/TCSS.2024.3404550},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {7045-7054},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Virtual-coupling-based timetable rescheduling for heavy-haul railways under disruptions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VLOG: Vehicle identity verification based on local and
global behavior analysis. <em>TCSS</em>, <em>11</em>(5), 7032–7044. (<a
href="https://doi.org/10.1109/TCSS.2024.3414587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Vehicles (IoV) improves traffic safety and efficiency by wireless communications among vehicles and infrastructures. To ensure secure communications in IoV, the problem of vehicle identity security must be solved before deployment. In this article, we propose a quick-response behavior-based vehicle identity verification method, called VLOG, for solving identity theft in IoV. This method is based on the idea of a vehicle usually having relatively stable traveling habit/behaivor. If we detect unusual behavior, the vehicle&#39;s identity may be stolen. VLOG captures vehicles’ latent behavior models from local and global two aspects, and further merges local and global models into a comprehensive behavior-based identity verification model. In the local part, we give a 2-D Gaussian model to fit the behavior data. In the global part, we learn vehicles’ traveling preferences under secure multiparty computation framework with considering the behavior volatility. The results of experiments based on a real-world vehicular trace dataset show the best performance of VLOG in terms of accuracy, F1 score, and cost. Meanwhile, VLOG also performs well in the area under the curve and precision-recall curve. Besides, since our model is preprepared, when a vehicle is required to be detected, the verification response time is short.},
  archive      = {J_TCSS},
  author       = {Zhong Li and Yubo Kong and Jie Luo and Yifei Meng and Changjun Jiang},
  doi          = {10.1109/TCSS.2024.3414587},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {7032-7044},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {VLOG: Vehicle identity verification based on local and global behavior analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Dual graph neural networks for dynamic users’ behavior
prediction on social networking services. <em>TCSS</em>, <em>11</em>(5),
7020–7031. (<a href="https://doi.org/10.1109/TCSS.2024.3409383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social network services (SNSs) provide platforms where users engage in social link behavior (e.g., predicting social relationships) and consumption behavior. Recent advancements in deep learning for recommendation and link prediction explore the symbiotic relationships between these behaviors, leveraging social influence theory and user homogeneity, i.e., users tend to accept recommendations from social friends and connect with like-minded users. These studies yield positive feedback for users and platforms, fostering practical applications and economic development. While previous works jointly model these behaviors, most studies often overlook the evolution of social relationships and users’ preferences in dynamic scenes and the correlations inside, as well as the higher order information within the social network and preference network (consumption history). To address this, we propose the dynamic graph neural joint behavior prediction model (DGN-JBP). Specifically, we actively disentangle and initialize user embeddings from multiple perspectives to refine information for modeling. Additionally, we design an attentive graph neural network and combine it with gate recurrent units (GRUs) to extract high-order dynamic information. Finally, we design a dual framework and purposefully fuse embeddings to mutually enhance the effectiveness of predictions on two prediction tasks. Extensive experimental results on two real-world datasets clearly demonstrate the effectiveness of our proposed model.},
  archive      = {J_TCSS},
  author       = {Junwei Li and Le Wu and Yulu Du and Richang Hong and Weisheng Li},
  doi          = {10.1109/TCSS.2024.3409383},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {7020-7031},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Dual graph neural networks for dynamic users’ behavior prediction on social networking services},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quasi group role assignment with agent satisfaction in
self-service spatiotemporal crowdsourcing. <em>TCSS</em>,
<em>11</em>(5), 7002–7019. (<a
href="https://doi.org/10.1109/TCSS.2024.3417959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quasi group role assignment (QGRA) presents a novel social computing model designed to address the burgeoning domain of self-service spatiotemporal crowdsourcing (SSC), specifically for tackling the photographing to make money problem (PMMP). Nevertheless, the application of QGRA in practical scenarios encounters a significant bottleneck. QGRA provides optimal assignment strategies under conditions where both the number of crowdsourced tasks and workers remain stable. However, real-world crowdsourcing applications may necessitate the phased integration of new tasks. With the rapid increase in the number of tasks, a set of residual tasks inevitably exists that are difficult to complete. To maximize the completion of crowdsourced tasks, workers may be assigned low-yield or even unprofitable tasks. Given the reluctance of crowdsourcing workers to be overstretched for these tasks, along with the inherent characteristics of self-service crowdsourcing tasks, this can lead to the failure of the assignment scheme. To tackle the identified challenges, this article proposes the QGRA with agent satisfaction (QGRAAS) method. Initially, it sheds light on a creative satisfaction filtering algorithm (SFA), which is engineered to perform optimal task assignments while actively optimizing the profitability of crowdsourcing workers. This approach ensures the satisfaction of workers, thereby fostering their loyalty to the platform. Concurrently, in response to the phased changes in the crowdsourcing environment, this article incorporates the concept of bonus incentives. This aids decision-makers in achieving a tradeoff between the operational costs and task completion rates. The robustness and practicality of the proposed solutions are confirmed through simulation experiments.},
  archive      = {J_TCSS},
  author       = {Qian Jiang and Dongning Liu and Haibin Zhu and Baoying Huang and Naiqi Wu and Yan Qiao},
  doi          = {10.1109/TCSS.2024.3417959},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {7002-7019},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Quasi group role assignment with agent satisfaction in self-service spatiotemporal crowdsourcing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anticipating technical expertise and capability evolution in
research communities using dynamic graph transformers. <em>TCSS</em>,
<em>11</em>(5), 6982–7001. (<a
href="https://doi.org/10.1109/TCSS.2024.3416837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to anticipate global technical expertise and capability evolution trends is essential for national and global security, especially in safety-critical domains such as nuclear nonproliferation (NN) and rapidly emerging fields like artificial intelligence (AI). In this work, we extend traditional statistical relational learning approaches (e.g., link prediction in collaboration networks) and formulate a problem of anticipating technical expertise and capability evolution using dynamic heterogeneous graph representations. We develop novel capabilities to forecast collaboration patterns, authorship behavior, and technical capability evolution at different granularities (e.g., scientist and institution levels) in two distinct research fields. We implement a dynamic graph transformer (DGT) neural architecture, which pushes the state-of-the-art graph neural network models by: 1) forecasting heterogeneous (rather than homogeneous) nodes and edges; and 2) relying on both discrete- and continuous-time inputs. We demonstrate that our DGT models predict collaboration, partnership, and expertise patterns with 0.26, 0.73, and 0.53 mean reciprocal rank values for AI and 0.48, 0.93, and 0.22 for NN domains. DGT model performance exceeds the best-performing static graph baseline models by 30%–80% across AI and NN domains. Our findings demonstrate that DGT models boost inductive task performance when previously unseen nodes appear in the test data for the domains with emerging collaboration patterns (e.g., AI). Specifically, models accurately predict which established scientists will collaborate with early career scientists and vice versa in the AI domain.},
  archive      = {J_TCSS},
  author       = {Sameera Horawalavithana and Ellyn Ayton and Anastasiya Usenko and Robin Cosbey and Svitlana Volkova},
  doi          = {10.1109/TCSS.2024.3416837},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6982-7001},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Anticipating technical expertise and capability evolution in research communities using dynamic graph transformers},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Community detection for heterogeneous multiple social
networks. <em>TCSS</em>, <em>11</em>(5), 6966–6981. (<a
href="https://doi.org/10.1109/TCSS.2024.3399784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The community plays a crucial role in understanding user behavior and network characteristics in social networks. Some users can use multiple social networks at once for a variety of objectives. These users are called overlapping users who bridge different social networks. Detecting communities across multiple social networks is vital for interaction mining, information diffusion, and behavior migration analysis among networks. This article presents a community detection method based on nonnegative matrix trifactorization for multiple heterogeneous social networks, which formulates a common consensus matrix to represent the global fused community. Specifically, the proposed method involves creating adjacency matrices based on network structure and content similarity, followed by alignment matrices that distinguish overlapping users in different social networks. With the generated alignment matrices, the method could enhance the fusion degree of the global community by detecting overlapping user communities across networks. The effectiveness of the proposed method is evaluated with new metrics on Twitter, Instagram, and Tumblr datasets. The results of the experiments demonstrate its superior performance in terms of community quality and community fusion.},
  archive      = {J_TCSS},
  author       = {Ziqing Zhu and Guan Yuan and Tao Zhou and Jiuxin Cao},
  doi          = {10.1109/TCSS.2024.3399784},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6966-6981},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Community detection for heterogeneous multiple social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incentive mechanism for redactable blockchain governance: An
evolutionary game approach. <em>TCSS</em>, <em>11</em>(5), 6953–6965.
(<a href="https://doi.org/10.1109/TCSS.2024.3398044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has garnered significant attention in recent years due to its capacity to offer secure and transparent transactional systems. However, the technology&#39;s inherent immutability can present challenges in specific scenarios. While earlier research has concentrated on the development of redactable blockchain, existing solutions have primarily focused on the modification mechanism, often overlooking the critical element of an incentive mechanism for governance, which is paramount for ensuring the security of redactable blockchain. Some previous researches have explored the design of incentive mechanisms, but these studies exhibit certain shortcomings. To promote active participation, we have designed an incentive mechanism rooted in evolutionary game theory for stakeholders in redactable blockchain, aiming to facilitate the governance of redactable blockchain. Furthermore, we have conducted a comprehensive simulation founded on game-theoretic analysis. The results substantiate the effectiveness of our redactable blockchain incentive mechanism in achieving its intended objectives.},
  archive      = {J_TCSS},
  author       = {Jiaxiang Sun and Rong Zhao and Haoran Yin and Wei Cai},
  doi          = {10.1109/TCSS.2024.3398044},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6953-6965},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Incentive mechanism for redactable blockchain governance: An evolutionary game approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A counterfactual inference-based social network
user-alignment algorithm. <em>TCSS</em>, <em>11</em>(5), 6939–6952. (<a
href="https://doi.org/10.1109/TCSS.2024.3405999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User alignment refers to linking a user&#39;s accounts across multiple social networks, which is important for studying community discovery, recommendation systems, and other related fields. However, existing methods primarily perform user alignment by correlating user features, neglecting the causal relationship between network topology and user alignment, which makes it challenging to achieve superior user alignment accuracy and generalization capabilities. Therefore, we propose a counterfactual inference-based social network user-alignment algorithm (CINUA). This improves user connection retention due to the non-Euclidean geometric characterization of hyperbolic spaces. The similarity of aligned users is augmented using a hyperbolic graph attention network. User-feature embedding and fusion facilitate user relevance mining. Furthermore, there are causal relationships between network topology structure and user linkages. In various communities, there are some highly similar user pairs, and based on counterfactual inference, the network topology is adjusted to enhance sample diversity. Multilevel factual and counterfactual networks are constructed through iterative diffusion based on user alignment and their linkages. By integrating the users’ causal features in multiple networks, the accuracy and generalization capabilities of the user alignment model are effectively improved. In this article, the experimental results indicate that CINUA achieves a user alignment accuracy improvement of 5.98% and 3.03%, on two datasets respectively compared to the baseline methods on average. CINUA can achieve favorable alignment results even when the training dataset is small. This demonstrates that our algorithm can ensure both user alignment accuracy and generalization capability.},
  archive      = {J_TCSS},
  author       = {Ling Xing and Yuanhao Huang and Qi Zhang and Honghai Wu and Huahong Ma and Xiaohui Zhang},
  doi          = {10.1109/TCSS.2024.3405999},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6939-6952},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A counterfactual inference-based social network user-alignment algorithm},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modality bias calibration network via information
disentanglement for visible–infrared person reidentification.
<em>TCSS</em>, <em>11</em>(5), 6925–6938. (<a
href="https://doi.org/10.1109/TCSS.2024.3398696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible–infrared person reidentification (VI-ReID) in social surveillance systems involves analyzing social behavior using nonoverlapping cross-modality camera sets. It often has poor retrieval performance under modality gap. One way to alleviate such the modality discrepancy is to learn shared person features that are generalizable across different modalities. However, because of significant differences in color between the visible and infrared images, the learned share features are always inclined to specific information of corresponding modality. To this end, we propose a modality bias calibration network (MBCNet) that filters out identity-irrelevant interference and recalibrates the learned modality-shared features. Specifically, to emphasize the modality-shared cues, we employ a feature decomposition module in the feature-level to filter out style variations and extract identity-relevant discriminative cues from the residual feature. In order to achieve a better disentanglement, a dual ranking entropy constraint is further proposed to ensure that the learned features contain only identity-relevant information and discard style-relevant information. Simultaneously, we design a decorrelated orthogonality Loss to ensure the disentangled features are not correlated with each other. Through comprehensive experiments, we demonstrate that MBCNet significantly improves the cross-modality retrieval performance in social surveillance systems and effectively addresses the modality bias training issue.},
  archive      = {J_TCSS},
  author       = {Haojie Liu and Hao Luo and Xiantao Peng and Wei Jiang},
  doi          = {10.1109/TCSS.2024.3398696},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6925-6938},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Modality bias calibration network via information disentanglement for Visible–Infrared person reidentification},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Divide-and-conquer policy in the naming game. <em>TCSS</em>,
<em>11</em>(5), 6911–6924. (<a
href="https://doi.org/10.1109/TCSS.2024.3417184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The naming game (NG) is a classic model for studying the emergence and evolution of language within a population. In this article, we extend the traditional NG model to encompass multiple committed opinions and investigate the system dynamics on the complete graph with an arbitrarily large population and random networks of finite size. For the fully connected complete graph, the homogeneous mixing condition enables us to use mean-field theory to analyze the opinion evolution of the system. However, when the number of opinions increases, the number of variables describing the system grows exponentially. To mitigate this, we focus on a special scenario where the largest group of committed agents competes with a motley of committed groups, each of which is smaller than the largest one, while initially, most of uncommitted agents hold one unique opinion. This scenario is chosen for its recurrence in diverse societies and its potential for complexity reduction by unifying agents from smaller committed groups into one category. Our investigation reveals that when the size of the largest committed group reaches the critical threshold, most of uncommitted agents change their beliefs to this opinion, triggering a phase transition. Further, we derive the general formula for the multiopinion evolution using a recursive approach, enabling investigation into any scenario. Finally, we employ agent-based simulations to reveal the opinion evolution and dominance transition in random graphs. Our results provide insights into the conditions under which the dominant opinion emerges in a population and the factors that influence these conditions.},
  archive      = {J_TCSS},
  author       = {Cheng Ma and Brendan Cross and Gyorgy Korniss and Boleslaw K. Szymanski},
  doi          = {10.1109/TCSS.2024.3417184},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6911-6924},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Divide-and-conquer policy in the naming game},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on the association network and combined-type
prediction of films and users based on complex networks. <em>TCSS</em>,
<em>11</em>(5), 6897–6910. (<a
href="https://doi.org/10.1109/TCSS.2024.3417275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The arrival of the era of media convergence has promoted the expansion of the film industry and the user market. At present, the data of movies and users show complex attribute characteristics, and the reasonable division of massive data is still an urgent problem to be solved in this field. Motivated by this observation, based on the classical complex network model, this article proposes the definition of object distance and the evolution rules of association network, which can be used to analyze the feature attributes of movies and users. Second, a new clustering model, in which clustering units have different interactive behavior patterns, is designed to realize dynamic clustering in association networks. Finally, we measure the market influence of different types of movies and design a prediction model of potential market user popularity of combined-types according to the related network architecture. Compared with the actual data on Douban, the rationality and accuracy of the model for market prediction of different types of combinations are verified. These findings shed new light on the practical application value of providing guidance for better film marketing production.},
  archive      = {J_TCSS},
  author       = {Shan Liu and Kun Huang and Hao Wen},
  doi          = {10.1109/TCSS.2024.3417275},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6897-6910},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Research on the association network and combined-type prediction of films and users based on complex networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Composite nonconvex low-rank tensor completion with joint
structural regression for traffic sensor networks data recovery.
<em>TCSS</em>, <em>11</em>(5), 6882–6896. (<a
href="https://doi.org/10.1109/TCSS.2024.3406629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic sensor networks allow convenient collection of travel data that are of great significance for intelligent transportation systems (ITSs). However, the universality of missing data impedes the application of ITS and thus accurate missing data recovery is indispensable in practice. Typically, the global low-rankness and local spatiotemporal smoothness exist in underlying traffic tensor data. In light of this, this article proposes an improved low-rank tensor completion (LRTC) model by exploiting abundant structural information from incomplete tensors. Specifically, a logarithm power composite (LPC)-norm is first proposed as a nonconvex substitute of the rank function, leading to a flexible characterization of tensor multidimensional correlation. Then, a joint structural regression (JSR) model is presented to simultaneously leverage the intrinsic temporal continuity and profile similarity of traffic data. By doing so, we construct a novel nonconvex LRTC model by integrating the global low-rankness and fine-grained spatiotemporal structure that are complementary to each other. To solve the proposed model, following the optimization framework of the alternating direction method of multipliers (ADMMs), we develop an efficient iterative algorithm where each step can be solved in a closed form. Extensive experiments on four real-world traffic data are conducted to evaluate the effectiveness of the proposed approach. The results demonstrate that compared with other tensor completion methods, our model significantly improves the recovery performance.},
  archive      = {J_TCSS},
  author       = {Xiaobo Chen and Kaiyuan Wang and Feng Zhao and Fuwen Deng and Qiaolin Ye},
  doi          = {10.1109/TCSS.2024.3406629},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6882-6896},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Composite nonconvex low-rank tensor completion with joint structural regression for traffic sensor networks data recovery},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). In-database feature extraction to improve early detection of
problematic online gambling behavior. <em>TCSS</em>, <em>11</em>(5),
6868–6881. (<a href="https://doi.org/10.1109/TCSS.2024.3406501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study involves a comprehensive analysis of an anonymized dataset provided by a Swiss online casino that adds to the identification of reliable early indicators for problematic online gambling. Targeting gambling addiction prevention, our objective was to model and evaluate behavioral characteristics that signal early stages of problem gambling. We scrutinized player behaviors against a list of gamblers previously excluded for problematic gambling, using this as our target variable. Our approach combined traditional gambling risk indicators, as outlined in the existing literature, with innovative exploratory feature engineering and feature selection. This involved computing moving aggregates over specific periods to capture nuanced gambling patterns. All features were evaluated by assessing mutual information with the target variable as well as the collinearity of each pairwise combination of features. Based on our data analysis, we found that the total losses in the previous seven days, total deposits in the previous 15 days, total duration played in the previous seven days, stakes (amount bet per game) over the previous seven days, and making a deposit 12 h after a loss (chasing) were the most informative and independent risk indicators. To assess the accuracy of these indicators for early detection of problematic gambling and accordingly for responsible gambling interventions, we combined them in a linear regression model and compared its performance with the casino&#39;s currently used model. We found that a binary decision model based on a linear combination of these indicators provided better recall, greater precision, and more timely decisions than the benchmark.},
  archive      = {J_TCSS},
  author       = {Gabriel Stechschulte and Malte Wintner and Matthias Hemmje and Jürg Schwarz and Suzanne Lischer and Michael Kaufmann},
  doi          = {10.1109/TCSS.2024.3406501},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6868-6881},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {In-database feature extraction to improve early detection of problematic online gambling behavior},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeFedHDP: Fully decentralized online federated learning for
heart disease prediction in computational health systems. <em>TCSS</em>,
<em>11</em>(5), 6854–6867. (<a
href="https://doi.org/10.1109/TCSS.2024.3406528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart disease is a leading global cause of death, while federated learning (FL) is an effective way to predict it. Due to patient privacy concerns and the centralized nature of current FL approaches, collaborative research in heart disease prediction (HDP) faces significant hurdles in computational health systems. This article introduces a distributed online aggregation method within fully decentralized federated learning (DFL), named DeFedHDP, to address these privacy challenges and improve the model of HDP. Moreover, the differential privacy (DP) mechanism is applied to the aggregation strategy of DeFedHDP to protect the privacy of the patients. The data holder communicates directly with neighbors in a series of time-varying directed graphs without the involvement of a central server. Furthermore, each participant is both a trainer of the local model and a collaborator of the other participants’ models. The data does not leave the local device, only the model parameters are exchanged and integrated, and this decentralized approach can further improve the level of privacy protection. In addition, to cope with model gradient disappearance and gradient explosion, the one-point bandit feedback (OPBF) strategy is utilized to estimate the true gradient values. Experiments on a public medical dataset show that the effectiveness of DeFedHDP is close to the centralized FedAVG algorithm for client-server architectures in terms of accuracy and speed.},
  archive      = {J_TCSS},
  author       = {Mengli Wei and Ju Yang and Zhongyuan Zhao and Xiaogang Zhang and Jinsong Li and Zhiliang Deng},
  doi          = {10.1109/TCSS.2024.3406528},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6854-6867},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {DeFedHDP: Fully decentralized online federated learning for heart disease prediction in computational health systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Co-move: COVID-19 and inter-region human mobility analysis
and prediction. <em>TCSS</em>, <em>11</em>(5), 6843–6853. (<a
href="https://doi.org/10.1109/TCSS.2024.3406512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans relocate for a variety of reasons, including employment, study, tourism, family, and health. However, in COVID-19, the government imposed restrictions such as lockdowns, travel bans, and quarantine regulations, preventing many people from traveling for work, study, or leisure; thus, human mobility exhibits distinct patterns than ordinary movements. In this article, we analyze the effect of COVID-19 on interregion human mobility using curated Twitter data and propose a framework named Co-Move for human mobility prediction. There were three challenges in predicting mobility: 1) heterogenous data; 2) short and long-term periodic patterns; and 3) complex intercorrelation. To address these challenges, the framework comprises parallel multiscale convolution and long short-term memory components. Extensive experiments on real-life mobility datasets show the mean square error (MSE) of 0.0179, RMSE of 0.129, mean absolute error (MAE) of 0.1075, and outperform baseline models.},
  archive      = {J_TCSS},
  author       = {Sandip Kumar Burnwal and Pragati Sinha and Bhumika and Jayant Vyas and Debasis Das},
  doi          = {10.1109/TCSS.2024.3406512},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6843-6853},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Co-move: COVID-19 and inter-region human mobility analysis and prediction},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parallel multiscale bridge fusion network for audio–visual
automatic depression assessment. <em>TCSS</em>, <em>11</em>(5),
6830–6842. (<a href="https://doi.org/10.1109/TCSS.2024.3416029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is a prevalent and severe mental illness that significantly impacts patients’ physical health and daily life. Recent studies have focused on multimodal depression assessment, aiming to objectively and conveniently evaluate depression using multimodal data. However, existing methods based on audio–visual modalities struggle to capture the dynamic variations in depression clues and cannot fully explore multimodal data over a long time. In addition, they rely heavily on insufficient single-stage multimodal fusion, which limits the accuracy of depression assessment. To address these limitations, we propose a novel parallel multiscale bridge fusion network (PMBFN) for audio–visual depression assessment. PMBFN comprehensively captures subtle multilevel dynamic changes in depression expression through parallel multiscale dynamic convolutions and long short-term memories (LSTMs) and effectively solves the problem of long-term audio–visual sequence information loss by using spatiotemporal attention pooling modules. Furthermore, the multimodal bridge fusion module is proposed in PMBFN to achieve multistage interactive recursive multimodal fusion, enhancing the expressive capacity of multimodal depression-related features to improve the accuracy of assessment. Extensive experiments on the DAIC-WOZ and E-DAIC datasets demonstrate that our method outperforms current state-of-the-art methods and clearly shows our method&#39;s effectiveness eventually.},
  archive      = {J_TCSS},
  author       = {Min Hu and Lei Liu and Xiaohua Wang and Yiming Tang and Jiaoyun Yang and Ning An},
  doi          = {10.1109/TCSS.2024.3416029},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6830-6842},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Parallel multiscale bridge fusion network for Audio–Visual automatic depression assessment},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sentiment classification of anxiety-related texts in social
media via fuzing linguistic and semantic features. <em>TCSS</em>,
<em>11</em>(5), 6819–6829. (<a
href="https://doi.org/10.1109/TCSS.2024.3410391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anxiety disorder is a common mental disorder that has received increasing attention due to its high incidence, comorbidity, and recurrence. In recent years, with the rapid development of information technology, social media platforms have become a crucial source of data for studying anxiety disorders. Existing studies on anxiety disorders have focused on utilizing user-generated contents to study correlations with disorders or identify disorders. However, these studies overlook the emotional information in social media posts, restraining the effective capture of users’ emotions or mental states when posting. This article focuses on the sentiment polarity of anxiety-related posts on a Chinese social media and designs sentiment classification models via fuzing linguistic and semantic features of the posts. First, we extract the linguistic features from posts based on the simplified Chinese–Linguistic inquiry and word count (SC-LIWC) dictionary, and propose a novel recursive feature selection algorithm to reserve important linguistic features. Second, we propose a TextCNN-based model to study the deep semantic features of posts and fuze their linguistic features to obtain a better representation. Finally, to conduct anxiety analysis on Chinese social media, we construct a postlevel sentiment analysis dataset based on anxiety-related posts on Sina Weibo. The experimental results indicate that our proposed fusion models exhibit better performance in the task of identifying the sentiment polarity of anxiety-related posts on Chinese social media.},
  archive      = {J_TCSS},
  author       = {Jianghong Zhu and Zhenwen Zhang and Zhihua Guo and Zepeng Li},
  doi          = {10.1109/TCSS.2024.3410391},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6819-6829},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Sentiment classification of anxiety-related texts in social media via fuzing linguistic and semantic features},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integral-reinforcement-learning-based hierarchical optimal
evolutionary strategy for continuous action social dilemma games.
<em>TCSS</em>, <em>11</em>(5), 6807–6818. (<a
href="https://doi.org/10.1109/TCSS.2024.3409833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a framework for exploring optimal evolutionary strategies in continuous-action social dilemma games with a hierarchical structure comprising a leader and multifollowers. Previous studies in game theory have frequently overlooked the hierarchical structure among individuals, assuming that decisions are made simultaneously. Here, we propose a hierarchical structure for continuous action games that involves a leader and followers to enhance cooperation. The optimal evolutionary strategy for the leader is to guide the followers’ actions to maximize overall benefits by exerting minimal control, while the followers aim to maximize their payoff by making minimal changes to their strategies. We establish the coupled Hamilton–Jacobi–Bellman (HJB) equations to find the optimal evolutionary strategy. To address the complexity of asymmetric roles arising from the leader-follower structure, we introduce an integral reinforcement learning (RL) algorithm known as two-level heuristic dynamic programming (HDP)-based value iteration (VI). The implementation of the algorithm utilizes neural networks (NNs) to approximate the value functions. Moreover, the convergence of the proposed algorithm is demonstrated. Additionally, three social dilemma models are presented to validate the efficacy of the proposed algorithm.},
  archive      = {J_TCSS},
  author       = {Litong Fan and Dengxiu Yu and Zhen Wang},
  doi          = {10.1109/TCSS.2024.3409833},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6807-6818},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Integral-reinforcement-learning-based hierarchical optimal evolutionary strategy for continuous action social dilemma games},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantum-social network analysis for community detection: A
comprehensive review. <em>TCSS</em>, <em>11</em>(5), 6795–6806. (<a
href="https://doi.org/10.1109/TCSS.2024.3397967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamics and underlying structure of complex social networks (SNs) can be discovered using community detection. Considering how quantum computing might improve community detection techniques is becoming more and more popular in light of recent developments in computing technology. In this article, the rapidly developing topic of quantum-SN analysis for community discovery is thoroughly reviewed. Community detection is studied in the context of several quantum-inspired techniques, including quantum annealing and quantum-inspired optimization. To make use of the strengths of both conventional SN research methods and quantum computing techniques, hybrid quantum-classical approaches are being investigated. Case studies and applications that have made use of quantum-SN analysis methodologies are reviewed to highlight the practical consequences and potential advantages over conventional methods. The article also highlights the challenges and limitations of using quantum computing for SN analysis, including technical constraints and ethical issues. Finally, prospects and future research objectives in the area of quantum-SN analysis are highlighted. This covers possible developments in quantum algorithms for community detection, the incorporation of quantum computing with other SN research tasks, and the significance of multidisciplinary collaborations.},
  archive      = {J_TCSS},
  author       = {Samya Muhuri and Shashank Sheshar Singh},
  doi          = {10.1109/TCSS.2024.3397967},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6795-6806},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Quantum-social network analysis for community detection: A comprehensive review},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SIA-net: Sparse interactive attention network for multimodal
emotion recognition. <em>TCSS</em>, <em>11</em>(5), 6782–6794. (<a
href="https://doi.org/10.1109/TCSS.2024.3409715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal emotion recognition (MER) integrates multiple modalities to identify the user&#39;s emotional state, which is the core technology of natural and friendly human–computer interaction systems. Currently, many researchers have explored comprehensive multimodal information for MER, but few consider that comprehensive multimodal features may contain noisy, useless, or redundant information, which interferes with emotional feature representation. To tackle this challenge, this article proposes a sparse interactive attention network (SIA-Net) for MER. In SIA-Net, the sparse interactive attention (SIA) module mainly consists of intramodal sparsity and intermodal sparsity. The intramodal sparsity provides sparse but effective unimodal features for multimodal fusion. The intermodal sparsity adaptively sparses intramodal and intermodal interactive relations and encodes them into sparse interactive attention. The sparse interactive attention with a small number of nonzero weights then act on multimodal features to highlight a few but important features and suppress numerous redundant features. Furthermore, the intramodal sparsity and intermodal sparsity are deep sparse representations that make unimodal features and multimodal interactions sparse without complicated optimization. The extensive experimental results show that SIA-Net achieves superior performance on three widely used datasets.},
  archive      = {J_TCSS},
  author       = {Shuzhen Li and Tong Zhang and C. L. Philip Chen},
  doi          = {10.1109/TCSS.2024.3409715},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6782-6794},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {SIA-net: Sparse interactive attention network for multimodal emotion recognition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Geometric constraints and rough-fine registration-based
localization method for social intelligent transportation systems.
<em>TCSS</em>, <em>11</em>(5), 6771–6781. (<a
href="https://doi.org/10.1109/TCSS.2024.3412911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization and pose estimation algorithms play an important role in intelligent transportation systems (ITSs), as ITS need to accurately sense and understand the traffic environment to support autonomous navigation, traffic flow management, and autonomous material handling. This article proposes a pose estimation method in the front end of lidar odometry with geometric constraints. The proposed method can accurately capture the geometric information in the environment and ensure the effectiveness of the point cloud participating in the registration to improve the accuracy of registration. In the back end, an enhanced pose estimation strategy combining rough registration and fine registration is adopted to further improve localization accuracy. Comprehensive experimental results show that the proposed method achieves higher localization accuracy against other baselines, which also demonstrates that the proposed method can cope with challenging scenes such as complex road conditions and dynamic objects.},
  archive      = {J_TCSS},
  author       = {Xing Li and Zhiyu Zhou and Chengjun Zhang and Yilin Wu and Yu Liu},
  doi          = {10.1109/TCSS.2024.3412911},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6771-6781},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Geometric constraints and rough-fine registration-based localization method for social intelligent transportation systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RAH! RecSys–assistant–human: A human-centered recommendation
framework with LLM agents. <em>TCSS</em>, <em>11</em>(5), 6759–6770. (<a
href="https://doi.org/10.1109/TCSS.2024.3404039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of the web has led to an exponential growth in content. Recommender systems play a crucial role in human–computer interaction (HCI) by tailoring content based on individual preferences. Despite their importance, challenges persist in balancing recommendation accuracy with user satisfaction, addressing biases while preserving user privacy, and solving cold-start problems in cross-domain situations. This research argues that addressing these issues is not solely the recommender systems’ responsibility, and a human-centered approach is vital. We introduce the recommender system, assistant, and human (RAH) framework, an innovative solution with large language model (LLM)-based agents such as perceive, learn, act, critic, and reflect, emphasizing the alignment with user personalities. The framework utilizes the learn-act-critic loop and a reflection mechanism for improving user alignment. Using the real-world data, our experiments demonstrate the RAH framework&#39;s efficacy in various recommendation domains, from reducing human burden to mitigating biases and enhancing user control. Notably, our contributions provide a human-centered recommendation framework that partners effectively with various recommendation models.},
  archive      = {J_TCSS},
  author       = {Yubo Shu and Haonan Zhang and Hansu Gu and Peng Zhang and Tun Lu and Dongsheng Li and Ning Gu},
  doi          = {10.1109/TCSS.2024.3404039},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6759-6770},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {RAH! RecSys–Assistant–Human: A human-centered recommendation framework with LLM agents},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FMDNet: Feature-attention-embedding-based multimodal-fusion
driving-behavior-classification network. <em>TCSS</em>, <em>11</em>(5),
6745–6758. (<a href="https://doi.org/10.1109/TCSS.2024.3411486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving behavior classification is a critical component of social transportation systems and advanced driver assistance systems, and it has gained increasing attention in recent years. Accurate classification algorithms for driving behavior play a significant role in enhancing traffic safety, energy conservation, and related fields. In this article, we propose a novel driving behavior classification network named feature-attention-embedding-based multimodal-fusion driving-behavior-classification network (FMDNet). FMDNet incorporates eight types of data, including acceleration along the x-axis, y-axis, z-axis, roll angle, pitch angle, yaw angle, roadside image, and vehicle speed, to classify driving behavior. To effectively fuse features extracted from different modalities, taking into account their varying importance, we introduce the feature attention embedding-based fusion module (FAEF) as our fusion strategy. This fusion strategy enhances the network&#39;s capability to capture meaningful features by incorporating two feature attention embedding units that delve deeper into the interplay between different modes. Furthermore, we provide further validation of the effectiveness of our approach through extensive ablation experiments to investigate and analyze the impact of various modal data on the classification of driving behavior. Our proposed FMDNet achieves state-of-the-art performance on the public UAH-DriveSet dataset, demonstrating its effectiveness with an impressive F1-score of 99.0%. Additionally, the robustness of our model is confirmed on distracted dataset, achieving a remarkable F1-score of 99.7%. The model&#39;s outstanding performance on both the UAH-DriveSet dataset and the distracted-dataset highlights its capabilities and potential for real-world applications. https://github.com/Wenzhuo-Liu/FMDNet},
  archive      = {J_TCSS},
  author       = {Wenzhuo Liu and Jianli Lu and Junbin Liao and Yicheng Qiao and Guoying Zhang and Jiayin Zhu and Bozhang Xu and Zhiwei Li},
  doi          = {10.1109/TCSS.2024.3411486},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6745-6758},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {FMDNet: Feature-attention-embedding-based multimodal-fusion driving-behavior-classification network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coupled epidemic-information propagation with stranding
mechanism on multiplex metapopulation networks. <em>TCSS</em>,
<em>11</em>(5), 6727–6744. (<a
href="https://doi.org/10.1109/TCSS.2024.3404239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acknowledging the significance of information propagation and individual adaptive behavior has been regarded as an indispensable prerequisite for a complete understanding of epidemic spreading. Recent studies have widely considered the metapopulation model, where epidemics spread over a single layer of physical networks via individual mobility. However, these advances neglected the interventions of accompanied information and individual behavior response related to epidemics. In this article, we develop a coupled epidemic-information propagation model on multiplex metapopulation networks leveraging the microscopic Markov chain (MMC) approach, aiming to explore the spatiotemporal characteristics of epidemic spreading process. Taking the individual adaptive behavior into account, the stranding mechanism based on infection level and medical resources is introduced to capture the population size dynamics during individual mobility among different patches. Theoretical epidemic threshold is analytically derived under the improved framework. Extensive numerical simulations are performed to validate our theoretical analysis and further examine the impacts of information propagation and spreading parameters on epidemic threshold and steady-state prevalence. Our results indicate that both the scale of information diffusion and the specific configuration of spreading parameters can significantly suppress the epidemic prevalence. These findings shed a novel light on theoretical research and decision-making of coupled epidemic-information process in the spatiotemporal perspective.},
  archive      = {J_TCSS},
  author       = {Xuming An and Chen Zhang and Lin Hou and Kaibo Wang},
  doi          = {10.1109/TCSS.2024.3404239},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6727-6744},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Coupled epidemic-information propagation with stranding mechanism on multiplex metapopulation networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating social explanations into explainable artificial
intelligence (XAI) for combating misinformation: Vision and challenges.
<em>TCSS</em>, <em>11</em>(5), 6705–6726. (<a
href="https://doi.org/10.1109/TCSS.2024.3404236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article overviews the state of the art, research challenges, and future directions in our vision: integrating social explanation into explainable artificial intelligence (XAI) to combat misinformation. In our context, “social explanation” is an explanatory approach that reveals the social aspect of misinformation by analyzing sociocontextual cues, such as user attributes, user engagement metrics, diffusion patterns, and user comments. Our vision is motivated by the research gap in the existing XAI that tends to overlook the broader social context in which misinformation spreads. In this article, we first define social explanation, demonstrating it through examples, enabling technologies, and real-world applications. We then outline the unique benefits social explanation brings to the fight against misinformation and discuss the challenges that make our vision complex. The significance of this article lies in introducing the “social explanation” concept in XAI, which has been underexplored in the previous literature. Also, we demonstrate how social explanations can be effectively employed to tackle misinformation and promote collaboration across diverse fields by drawing upon interdisciplinary techniques spanning from computer science, social computing, human–computer interaction, to psychology. We hope that this article will advance progress in the field of XAI and contribute to the ongoing efforts to counter misinformation.},
  archive      = {J_TCSS},
  author       = {Yeaeun Gong and Lanyu Shang and Dong Wang},
  doi          = {10.1109/TCSS.2024.3404236},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6705-6726},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Integrating social explanations into explainable artificial intelligence (XAI) for combating misinformation: Vision and challenges},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Refashioning emotion recognition modeling: The advent of
generalized large models. <em>TCSS</em>, <em>11</em>(5), 6690–6704. (<a
href="https://doi.org/10.1109/TCSS.2024.3396345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After its inception, emotion recognition or affective computing has increasingly become an active research topic due to its broad applications. The corresponding computational models have gradually migrated from statistically shallow models to neural-network-based deep models, which can significantly boost the performance of emotion recognition and consistently achieve the best results on different benchmarks, and thus has been considered the first option for emotion recognition. However, the debut of large language models (LLMs), such as ChatGPT and GPT4, has remarkably astonished the world due to their emerged capabilities of zero/few-shot learning, in-context learning (ICL), chain-of-thought, and others that are never shown in previous deep models. In the present article, we comprehensively investigate how the LLMs perform in emotion recognition in terms of diverse aspects, including ICL, few-shot prompting, accuracy, generalization, and explanation. Moreover, we offer some insights and pose other potential challenges, hoping to ignite broader discussions about enhancing emotion recognition in the new era of advanced and more generalized models.},
  archive      = {J_TCSS},
  author       = {Zixing Zhang and Liyizhe Peng and Tao Pang and Jing Han and Huan Zhao and Björn W. Schuller},
  doi          = {10.1109/TCSS.2024.3396345},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6690-6704},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Refashioning emotion recognition modeling: The advent of generalized large models},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Declined tactile angle discrimination in young patients with
migraine without aura or tension-type headache. <em>TCSS</em>,
<em>11</em>(5), 6684–6689. (<a
href="https://doi.org/10.1109/TCSS.2024.3397680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many headache patients often report cognitive disturbances, but tactile cognitive data are limited. Applying computing-aided strategies to reveal the association between migraine without aura (MOA) or tension-type headache (TTH) and tactile cognition is one of the research highlights. The aim of this study was to investigate whether MOA or TTH patients had a decline in tactile discrimination by utilizing a tactile angle discrimination tester. A cross-sectional study was performed between 1 January 2021, and 1 January 2022. A total of 301 participants were enrolled, with 107 in control, 90 in MOA, and 104 in TTH groups. A tactile cognition tester was used to objectively examine tactile discrimination in all participants. Tactile angle discrimination thresholds were measured to compare tactile cognitive functions among three groups. There were no statistically significant differences in their demographic characteristics. Compared to the normal control group, the MOA and TTH groups exhibited significantly higher tactile angle discrimination thresholds (showing decline in tactile discrimination), whereas no significant differences were found between the MOA and TTH groups. Differences in tactile angle discrimination thresholds were observed between young (≤ 44 years old) and middle-aged/elderly (≥ 45 years old) participants in the normal control group but not in the MOA and TTH groups. Moreover, the tactile deficits shown in the MOA or TTH groups were evident only in young participants. This study first demonstrated that patients with MOA or TTH, especially those patients younger than 44 years old, had decreased tactile angle discrimination ability, suggesting decline of tactile cognition.},
  archive      = {J_TCSS},
  author       = {Ge Jiao and Jian Zhang and Zhilin Zhang and Jinglong Wu and Junru Zhu and Qunxi Dong and Aihua Wang and Shengyuan Yu},
  doi          = {10.1109/TCSS.2024.3397680},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6684-6689},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Declined tactile angle discrimination in young patients with migraine without aura or tension-type headache},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dense graph convolutional with joint cross-attention network
for multimodal emotion recognition. <em>TCSS</em>, <em>11</em>(5),
6672–6683. (<a href="https://doi.org/10.1109/TCSS.2024.3412074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal emotion recognition (MER) has attracted much attention since it can leverage consistency and complementary relationships across multiple modalities. However, previous studies mostly focused on the complementary information of multimodal signals, neglecting the consistency information of multimodal signals and the topological structure of each modality. To this end, we propose a dense graph convolution network (DGC) equipped with a joint cross attention (JCA), named DG-JCA, for MER. The main advantage of the DG-JCA model is that it simultaneously integrates the spatial topology, consistency, and complementarity of multimodal data into a unified network framework. Meanwhile, DG-JCA extends the graph convolution network (GCN) via a dense connection strategy and introduces cross attention to joint model well-learned features from multiple modalities. Specifically, we first build a topology graph for each modality and then extract neighborhood features of different modalities using DGC driven by dense connections with multiple layers. Next, JCA performs cross-attention fusion in intra- and intermodality based on each modality&#39;s characteristics while balancing the contributions of various modalities’ features. Finally, subject-dependent and subject-independent experiments on the DEAP and SEED-IV datasets are conducted to evaluate the proposed method. Abundant experimental results show that the proposed model can effectively extract and fuse multimodal features and achieve outstanding performance in comparison with some state-of-the-art approaches.},
  archive      = {J_TCSS},
  author       = {Cheng Cheng and Wenzhe Liu and Lin Feng and Ziyu Jia},
  doi          = {10.1109/TCSS.2024.3412074},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6672-6683},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Dense graph convolutional with joint cross-attention network for multimodal emotion recognition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). XeroPol: Emotion-aware contrastive learning for zero-shot
cross-lingual politeness identification in dialogues. <em>TCSS</em>,
<em>11</em>(5), 6662–6671. (<a
href="https://doi.org/10.1109/TCSS.2024.3421672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Politeness is key to successful conversations. It depicts the behavior that is socially valued and is often accompanied by emotions. Previously, researchers have focused on detecting politeness in goal-oriented conversations in high-resource English language. The existing studies do not focus on identifying politeness in a resource-scared Indian languages such as Hindi, primarily due to the lack of labeled data. To overcome this limitation, in this article, we propose a novel emotion-aware contrastive learning (CL) method for zero-shot cross-lingual politeness identification ( XeroPol ) task in dialogues. We introduce ContrastiveAligner , a CL-based alignment method for zero-shot cross-lingual transfer. ContrastiveAligner employs translated data and pushes the model to generate similar utterance embeddings for different languages. As politeness and emotion are interrelated, hence, as the conversation progresses, the variation in emotions tends to pose challenges in identifying politeness in dialogues. Thus, in this work, we also design an auxiliary emotion-aware CL objective using sentiment information, namely the EmoSenti objective , which is expected to implicitly model the emotion change across utterances and help in the primary task of politeness identification. Experiments on MultiDoGo and EmoWOZ datasets demonstrate that the proposed approach significantly outperforms the baselines. Further analysis such as human evaluation on the EmoInHindi dataset validates the efficacy of the entire approach.},
  archive      = {J_TCSS},
  author       = {Priyanshu Priya and Mauajama Firdaus and Asif Ekbal},
  doi          = {10.1109/TCSS.2024.3421672},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6662-6671},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {XeroPol: Emotion-aware contrastive learning for zero-shot cross-lingual politeness identification in dialogues},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Early detection and prevention of malicious user behavior on
twitter using deep learning techniques. <em>TCSS</em>, <em>11</em>(5),
6649–6661. (<a href="https://doi.org/10.1109/TCSS.2024.3419171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organized misinformation campaigns on Twitter continue to proliferate, even as the platform acknowledges such activities through its transparency center. These deceptive initiatives significantly impact vital societal issues, including climate change, thus spurring research aimed at pinpointing and intercepting these malicious actors. Present-day algorithms for detecting bots harness an array of data drawn from user profiles, tweets, and network configurations, delivering commendable outcomes. Yet, these strategies mainly concentrate on postincident identification of malevolent users, hinging on static training datasets that categorize individuals based on historical activities. Diverging from this approach, we advocate for a forward-thinking methodology, which utilizes user data to foresee and mitigate potential threats before their realization, thereby cultivating more secure, equitable, and unbiased online communities. To this end, our proposed technique forecasts malevolent activities by tracing the projected trajectories of user embeddings before any malevolent action materializes. For validation, we employed a dynamic directed multigraph paradigm to chronicle the evolving engagements between Twitter users. When juxtaposed against the identical dataset, our technique eclipses contemporary methodologies by an impressive 40.66% in F score (F1 score) in the anticipatory identification of harmful users. Furthermore, we undertook a model evaluation exercise to gauge the efficiency of distinct system elements.},
  archive      = {J_TCSS},
  author       = {Rubén Sánchez-Corcuera and Arkaitz Zubiaga and Aitor Almeida},
  doi          = {10.1109/TCSS.2024.3419171},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6649-6661},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Early detection and prevention of malicious user behavior on twitter using deep learning techniques},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KGNext: Knowledge-graph-enhanced transformer for next POI
recommendation with uncertain check-ins. <em>TCSS</em>, <em>11</em>(5),
6637–6648. (<a href="https://doi.org/10.1109/TCSS.2024.3396506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The next point-of-interest (POI) recommendation aims to predict users’ future movements based on their historical trajectories. However, in reality, users may provide uncertain check-in records, resulting in uploaded data that lack precise location information and is instead ambiguous. Despite this challenge, only a limited number of studies have addressed this issue, often overlooking the intricate interactions among users, POIs, and POI categories. To that end, we propose a novel model called knowledge-graph-enhanced transformer (KGNext). KGNext leverages transition and interaction graphs derived from our constructed transitional-interactive knowledge graph (TIKG) to uncover both general movement patterns and varied user preferences regarding POIs and POI categories. Furthermore, KGNext integrates comprehensive contextual information from historical trajectories with TIKG to generate user trajectory embeddings. These encoded features are then utilized by a transformer model to provide fine-grained predictions of the next POI. Experimental results on three real-world datasets demonstrate the superiority of KGNext.},
  archive      = {J_TCSS},
  author       = {Xiangjie Kong and Zhiyu Chen and Jianxin Li and Junhui Bi and Guojiang Shen},
  doi          = {10.1109/TCSS.2024.3396506},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6637-6648},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {KGNext: Knowledge-graph-enhanced transformer for next POI recommendation with uncertain check-ins},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simplex pattern prediction based on dynamic higher order
path convolutional networks. <em>TCSS</em>, <em>11</em>(5), 6623–6636.
(<a href="https://doi.org/10.1109/TCSS.2024.3408214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, higher order patterns have played an important role in network structure analysis. The simplices in higher order patterns enrich dynamic network modeling and provide strong structural feature information for feature learning. However, the disorder dynamic network with simplex patterns has not been organized and divided according to time windows. Besides, existing methods do not make full use of the feature information to predict the simplex patterns with higher orders. To address these issues, we propose a simplex pattern prediction method based on dynamic higher order path convolutional networks. First, we divide the dynamic higher order datasets into different network structures under continuous-time windows, which possess complete time information. Second, feature extraction is performed on the network structure of continuous-time windows through higher order path convolutional networks. Subsequently, we embed time nodes into feature encoding and obtain feature representations of simplex patterns through feature fusion. The obtained feature representations of simplices are recognized by a simplex pattern discriminator to predict the simplex patterns at different moments. Finally, compared to other dynamic graph representation learning algorithms, our proposed algorithm has significantly improved its performance in predicting simplex patterns on five real dynamic higher order datasets.},
  archive      = {J_TCSS},
  author       = {Jianrui Chen and Meixia He and Peican Zhu and Zhihui Wang},
  doi          = {10.1109/TCSS.2024.3408214},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6623-6636},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Simplex pattern prediction based on dynamic higher order path convolutional networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Progressive income tax and its emerging growth effects: A
complex system approach. <em>TCSS</em>, <em>11</em>(5), 6605–6622. (<a
href="https://doi.org/10.1109/TCSS.2024.3418625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we apply an agent-based stock-flow consistent model (AB-SFC) to analyze economic growth differences when establishing different types of taxes on personal income: proportional and progressive. We use an income tax design that distinguishes between two sections of income. We contribute to the prominent literature on macro agent-based models by providing an unexplored feature in the income tax scheme. Our main findings are that this tax design seems to offset the inequality through tax exemption for low-income households but seems to have a limited impact on inequality generated between middle and high-income households. Notably, we did not find evidence of a deterioration in economic growth in the presence of a progressive income tax instead of a proportional one. Therefore, this article proposes a scenario where changing the tax scheme reduces inequality without hampering growth. This result has important implications for policy.},
  archive      = {J_TCSS},
  author       = {Emiliano Alvarez and Marcelo Álvez and Juan Gabriel Brida},
  doi          = {10.1109/TCSS.2024.3418625},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6605-6622},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Progressive income tax and its emerging growth effects: A complex system approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Response generation in social network with topic and emotion
constraints. <em>TCSS</em>, <em>11</em>(5), 6592–6604. (<a
href="https://doi.org/10.1109/TCSS.2024.3397802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Response generation is the task of automatically generating human-like content based on the provided context. One of its prominent applications is to simulate realistic response content for social network posts. In the digital age, social network platforms play a vital role in information exchange and social interaction. This study focuses on response generation techniques for the platform of public opinion evolution simulation that simulate realistic response content, enabling a deeper understanding of the emotional expressions of network users. Recent advancements in deep learning techniques, particularly the sequence-to-sequence (Seq2Seq) model, have shown promise in the response generation field. However, we still face two challenges: content variety, topic and emotion relevancy. To this end, we propose the EmoTG-ETRS model which comprises three parts. The first is a response generation module based on Transformer architecture. Then, an auxiliary emotion improvement module is incorporated to enhance the emotional expressiveness of the response candidates. Finally, a reverse selection module, which combines maximum mutual information (MMI) evaluation, emotional expression evaluation, and topic consistency evaluation, is devised to select the highest-scoring response. Extensive experiments have been conducted to evaluate the effectiveness of the proposed model and the results demonstrate that the EmoTG-ETRS model improves the quality of produced replies in terms of topic consistency and emotional accuracy rate when compared with the SOTA research works.},
  archive      = {J_TCSS},
  author       = {Biwei Cao and Jiuxin Cao and Bo Liu and Jie Gui and Jun Zhou and Yuan Yan Tang and James Tin-Yau Kwok},
  doi          = {10.1109/TCSS.2024.3397802},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6592-6604},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Response generation in social network with topic and emotion constraints},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Task partitioning and scheduling based on stochastic policy
gradient in mobile crowdsensing. <em>TCSS</em>, <em>11</em>(5),
6580–6591. (<a href="https://doi.org/10.1109/TCSS.2024.3398430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has become prevalent for decision-making task assignments in mobile crowdsensing (MCS). However, when facing sensing scenarios with varying numbers of workers or task attributes, existing DRL-based task assignment schemes fail to generate matching policies continuously and are susceptible to environmental fluctuations. To overcome these issues, a twin-delayed deep stochastic policy gradient (TDDS) approach is presented for balanced and low-latency MCS task decomposition and parallel subtask allocation. A masked attention mechanism is incorporated into the policy network to enable TDDS to adapt to task-attribute and subtask variations. To enhance environmental adaptability, an off-policy DRL algorithm incorporating experience replay is developed to eliminate sample correlation during training. Gumbel-Softmax sampling is integrated into the twin-delayed deep deterministic policy gradient (TD3) to support discrete action space decisions and a customized reward strategy to reduce task completion delay and balance workloads. Extensive simulation results confirm that the proposed scheme outperforms mainstream DRL baselines in terms of environmental adaptability, task completion delay, and workload balancing.},
  archive      = {J_TCSS},
  author       = {Tianjing Wang and Yu Zhang and Hang Shen and Guangwei Bai},
  doi          = {10.1109/TCSS.2024.3398430},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6580-6591},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Task partitioning and scheduling based on stochastic policy gradient in mobile crowdsensing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning frequency-aware cross-modal interaction for
multimodal fake news detection. <em>TCSS</em>, <em>11</em>(5),
6568–6579. (<a href="https://doi.org/10.1109/TCSS.2024.3415160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, fake news detection (FND) is an essential task in the field of social network analysis, and multimodal detection methods that combine text and image have been significantly explored in the last five years. However, the physical features of images that can be clearly shown in the frequency level are often ignored, and thus cross-modal feature extraction and interaction still remain a great challenge when the frequency domain is introduced for multimodal FND. To address this issue, we propose a frequency-aware cross-modal interaction network (FCINet) for multimodal FND in this article. First, a triple-branch encoder with robust feature extraction capacity is proposed to explore the representation of frequency, spatial, and text domains, separately. Then, we design a parallel cross-modal interaction strategy to fully exploit the interdependencies among them to facilitate multimodal FND. Finally, a combined loss function including deep auxiliary supervision and event classification is introduced to improve the generalization ability for multitask training. Extensive experiments and visual analysis on two public real-world multimodal fake news datasets show that the presented FCINet obtains excellent performance and exceeds numerous state-of-the-art methods.},
  archive      = {J_TCSS},
  author       = {Yan Bai and Yanfeng Liu and Yongjun Li},
  doi          = {10.1109/TCSS.2024.3415160},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6568-6579},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Learning frequency-aware cross-modal interaction for multimodal fake news detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decomposing neuroanatomical heterogeneity of autism spectrum
disorder across different developmental stages using morphological
multiplex network model. <em>TCSS</em>, <em>11</em>(5), 6557–6567. (<a
href="https://doi.org/10.1109/TCSS.2024.3411113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is accompanied by impaired social cognition and behavior. The expense of supporting patients with ASD turns into a significant problem for society. Parsing neurobiological subtypes is a crucial way for delineating the heterogeneity in autistic brains, with significant implications for improving ASD diagnosis and promoting the development of personalized intervention models. Nevertheless, a comprehensive understanding of the heterogeneity in cortical morphology of ASD is still lacking, and the question of whether neuroanatomical subtypes remain stable during cortical development remains unclear. Here, we used T1-weighted images of 515 male patients with ASD, including 216 autistic children (6–11 years), 187 adolescents (12–17 years), and 112 young adults (18–29 years), along with 595 age and gender-matched typically developing (TD) individuals. Cortical thickness (CT), surface area (SA), and volumes of cortical (CV) and subcortical (SV) regions were extracted. A single network layer was established by calculating the covariance of each feature across brain regions between participants, thereby constructing a multilayer intersubject covariance network. Applying a community detection algorithm to multilayer networks derived from different feature combinations, we observed that the network comprising CT and CV layers exhibited the most prominent modular organization, resulting in three subtypes of ASD for each of the three age groups. Subtypes within the corresponding age group significantly differed in terms of brain morphology and clinical scales. Furthermore, the subtypes of children with ASD underwent reorganization with development, transitioning from childhood to adolescence and adulthood, rather than consistently persist. Additionally, subtype categorization largely improved the diagnostic accuracy of ASD compared to diagnosing the entire ASD cohort. These findings demonstrated distinct neuroanatomical manifestations of ASD subtypes across various developmental periods, highlighting the significance of age-related subtyping in facilitating the etiology and diagnosis of ASD.},
  archive      = {J_TCSS},
  author       = {Xiang Fu and Ying Wang and Jialong Li and Hongmin Cai and Xinyan Zhang and Zhijun Yao and Minqiang Yang and Weihao Zheng},
  doi          = {10.1109/TCSS.2024.3411113},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6557-6567},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Decomposing neuroanatomical heterogeneity of autism spectrum disorder across different developmental stages using morphological multiplex network model},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MetaGA: Metalearning with graph-attention for improved
long-tail item recommendation. <em>TCSS</em>, <em>11</em>(5), 6544–6556.
(<a href="https://doi.org/10.1109/TCSS.2024.3411043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recommendation of long-tail items has been a persistent issue in recommender system research. The primary reason for this problem is that the model cannot learn better item features due to the lack of interactive record data of tail items, which leads to a decline in the model&#39;s recommendation performance. Existing methods transfer the features of the head items to the tail items, thereby ignoring their differences and failing to produce a satisfactory recommendation effect. To address the issue, we propose a novel recommendation model called MetaGA based on metalearning. The MetaGA model obtains initial parameters from head items through metalearning and fine-tunes model parameters during the learning process of tail item features. Additionally, it employs a graph convolutional network and attention mechanism to enhance tail data and reduce the difference between head and tail data. Through the above two steps, the model utilizes the abundant data of the head items to address the problem of sparse data of the tail items, resulting in improved recommendation performance. We conducted extensive experiments on three real-world datasets, and the results demonstrate that our proposed MetaGA model significantly outperforms other state-of-the-art baselines for tail item recommendation.},
  archive      = {J_TCSS},
  author       = {Bingjun Qin and Zhenhua Huang and Zhengyang Wu and Cheng Wang and Yunwen Chen},
  doi          = {10.1109/TCSS.2024.3411043},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6544-6556},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {MetaGA: Metalearning with graph-attention for improved long-tail item recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CGNN: A compatibility-aware graph neural network for social
media bot detection. <em>TCSS</em>, <em>11</em>(5), 6528–6543. (<a
href="https://doi.org/10.1109/TCSS.2024.3396413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise and prevalence of social bots, their negative impacts on society are gradually recognized, prompting research attention to effective detection and countermeasures. Recently, graph neural networks (GNNs) have flourished and have been applied to social bot detection research, improving the performance of detection methods effectively. However, existing GNN-based social bot detection methods often fail to account for the heterogeneous associations among users within social media contexts, especially the heterogeneous integration of social bots into human communities within the network. To address this challenge, we propose a heterogeneous compatibility perspective for social bot detection, in which we preserve more detailed information about the varying associations between neighbors in social media contexts. Subsequently, we develop a compatibility-aware graph neural network (CGNN) for social bot detection. CGNN consists of an efficient feature processing module, and a lightweight compatibility-aware GNN encoder, which enhances the model’s capacity to depict heterogeneous neighbor relations by emulating the heterogeneous compatibility function. Through extensive experiments, we showed that our CGNN outperforms the existing state-of-the-art (SOTA) method on three commonly used social bot detection benchmarks while utilizing only about 2% of the parameter size and 10% of the training time compared with the SOTA method. Finally, further experimental analysis indicates that CGNN can identify different edge categories to a significant extent. These findings, along with the ablation study, provide strong evidence supporting the enhancement of GNN’s capacity to depict heterogeneous neighbor associations on social media bot detection tasks.},
  archive      = {J_TCSS},
  author       = {Haitao Huang and Hu Tian and Xiaolong Zheng and Xingwei Zhang and Daniel Dajun Zeng and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3396413},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6528-6543},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {CGNN: A compatibility-aware graph neural network for social media bot detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). The generation and regulation of public opinion on
multiplex social networks. <em>TCSS</em>, <em>11</em>(5), 6513–6527. (<a
href="https://doi.org/10.1109/TCSS.2024.3396229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dissemination of information and the development of public opinion are essential elements of most social networks and are often described as distinct, man-made occurrences. However, what is often disregarded is the interdependence between these two phenomena. Information dissemination serves as the foundation for the formation of public opinion, while public opinion, in turn, drives the spread of information. In our study, we model the coevolutionary relationship between information and public opinion on heterogeneous multiplex networks. This model takes into account a minority of individuals with steadfast opinions and a majority of individuals with fluctuating views. Our findings reveal the equilibrium state of public opinion in this model and examine the consistency between opinions and the network structure. Additionally, by identifying a linear relationship between mainstream public opinion and extreme individuals, we propose a strategy for regulating public opinion by adjusting the positions of extreme groups.},
  archive      = {J_TCSS},
  author       = {Zhong Zhang and Jian-liang Wu and Cun-quan Qu and Fei Jing},
  doi          = {10.1109/TCSS.2024.3396229},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6513-6527},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {The generation and regulation of public opinion on multiplex social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Profit maximization in online influencer marketing from the
perspective of modified agent-based modeling. <em>TCSS</em>,
<em>11</em>(5), 6501–6512. (<a
href="https://doi.org/10.1109/TCSS.2024.3395627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To provide a new perspective for understanding the dynamics of advertising campaigns in online influencer marketing (OIM), this article proposes the modified agent-based (MAB) model. As an extension of the existing agent-based model, it takes into account some important factors such as influencer avoidance and product competition and modifies some existing parameters to provide a more realistic approach for simulating marketing campaigns. Based on it, we define a novel set function named as dual-profit function. It is proven to be nonsubmodular and nonsupermodular. The dual-profit maximization (DPM) problem which regards dual-profit function as its objective function and the DPM algorithm used to address DPM problem is proposed. The influence of several parameters is evaluated through experiments conducted on real-world datasets.},
  archive      = {J_TCSS},
  author       = {Liman Du and Wenguo Yang and Suixiang Gao},
  doi          = {10.1109/TCSS.2024.3395627},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6501-6512},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Profit maximization in online influencer marketing from the perspective of modified agent-based modeling},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). COVID-19 vaccine side effect analysis by leveraging social
media: Focusing on connectivity and cluster characteristics of vaccine
side effects. <em>TCSS</em>, <em>11</em>(5), 6487–6500. (<a
href="https://doi.org/10.1109/TCSS.2024.3392341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19, a highly contagious global epidemic, has prompted governments to actively recommend vaccination as a crucial measure to overcome its impact. However, vaccine hesitancy remains a significant challenge, stemming from concerns related to rapid vaccine development, streamlined clinical trials, misinformation, and potential side effects. To address these concerns, an in-depth understanding of COVID-19 vaccine side effects is paramount. This article aims to analyze COVID-19 vaccine side effects using machine learning applied to Twitter, a representative social media platform. Thorough experiments show that we can not only detect officially known COVID-19 vaccine side effects, such as pain and headache but also identify previously unknown COVID-19 vaccine side effects like myocarditis and thrombosis. More importantly, we show that connectivity analysis and cluster analysis can provide a more detailed understanding of vaccine side effects, including differences from conventional text-mining analysis results. This article has the potential to alleviate public anxiety by discovering and analyzing vaccine side effects through social media data analysis. In addition, the proposed method is more important because it can be applied not only to COVID-19 vaccines but also to other side effects related to other medications.},
  archive      = {J_TCSS},
  author       = {Sunguk Yun and Jaekyun Jeong and Jungeun Kim},
  doi          = {10.1109/TCSS.2024.3392341},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6487-6500},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {COVID-19 vaccine side effect analysis by leveraging social media: Focusing on connectivity and cluster characteristics of vaccine side effects},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SISSRM: Sequentially induced signed subnetwork
reconstruction model for generating realistic synthetic signed networks.
<em>TCSS</em>, <em>11</em>(5), 6476–6486. (<a
href="https://doi.org/10.1109/TCSS.2024.3392613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy is one of the major concerns in the availability of large-scale real-world network datasets for various applications. Therefore, we require network models that can generate realistic synthetic networks of a very large scale that are capable of preserving patterns of given structural property in its evolution period. In this article, we proffer a novel network reconstruction model for signed networks, i.e., sequentially induced signed subnetwork reconstruction model (SISSRM), that is able to preserve the distribution of degrees, obsolescence, unbalanced, and balanced triangles, correlation among diverse triad types, spectral radius, degree correlation, and network balancedness during its growth process. SISSRM reproduces different structural properties of a given real-world signed network more accurately as compared to the considered state-of-the-art network models. The extensive experimentation on nine real-world empirical networks validates the significance of our proposed model in the generation of realistic synthetic signed networks.},
  archive      = {J_TCSS},
  author       = {Aikta Arya and Pradumn Kumar Pandey},
  doi          = {10.1109/TCSS.2024.3392613},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6476-6486},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {SISSRM: Sequentially induced signed subnetwork reconstruction model for generating realistic synthetic signed networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time granularity setting principle for short-term passenger
flow prediction in urban rail transit. <em>TCSS</em>, <em>11</em>(5),
6466–6475. (<a href="https://doi.org/10.1109/TCSS.2024.3385850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time granularity is a key parameter necessary for short-time passenger flow prediction of urban rail transit (URT); however, no universal method is available for its setting. This study investigates the time granularity setting principle for short-term passenger flow prediction in URT. First, a method to measure the autocorrelation of passenger flow time series is constructed, focusing on the comparison of time granularities. Second, based on the functional relationship between the first-order autocorrelation coefficients of the passenger flow time series under different time granularities, the time granularity setup principle is obtained for different passenger flow characteristics. Finally, the reasonableness and universality of the time granularity setting principle are verified by analyzing the passenger flow characteristics and autocorrelation magnitude of the actual inbound and origin-destination (OD) passenger flow data under different stations and dates at different time granularities.},
  archive      = {J_TCSS},
  author       = {Guangyu Zhu and Yansu Gong and Jiacun Ding and Edmond Q. Wu and Rob Law},
  doi          = {10.1109/TCSS.2024.3385850},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6466-6475},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Time granularity setting principle for short-term passenger flow prediction in urban rail transit},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-enabled deep depression detection and evaluation informed
by DSM-5-TR. <em>TCSS</em>, <em>11</em>(5), 6453–6465. (<a
href="https://doi.org/10.1109/TCSS.2024.3382139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression, a prevalent and debilitating mental health disorder, affects millions of individuals worldwide, profoundly impacting their quality of life. Early identification and diagnosis of depression and its intensity are crucial for effective treatment and management. However, many people with depression do not seek professional help, especially in the early stages. In recent years, social media platforms like Twitter have gained popularity as spaces for sharing personal thoughts and emotions, including sensitive signals indicative of serious issues such as self-harm, suicidal thoughts, or illegal activities. These signals may help us to identify depression-related tweets and determine whether an individual is suffering from depression. This research focuses on utilizing artificial intelligence and deep learning (DL) models to categorize tweets related to depression and measure its intensity. The proposed approach combines emotional features, topical events, and behavioral-biometric signals to train the long short-term memory (LSTM)-based DL models. To create a comprehensive dataset, we collaborated with an expert psychologist who followed the clinical assessment procedure outlined in the Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (DSM-5-TR) to label 95 322 tweets as “non-depressed” or “depressed,” further categorized into “mild,” “moderate,” and “severe” intensity levels. Through a series of experiments, our proposed method achieved superior performance compared to baseline models, yielding a mean squared error of 0.002336 and the highest $R$ 2 value of 0.61. These results highlight the accuracy and potential applications of our approach in automatic depression screening and monitoring on social media platforms.},
  archive      = {J_TCSS},
  author       = {Tabia Tanzin Prama and Md. Saiful Islam and Md Musfique Anwar and Ifrat Jahan},
  doi          = {10.1109/TCSS.2024.3382139},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6453-6465},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {AI-enabled deep depression detection and evaluation informed by DSM-5-TR},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic generation of critical audit matters (CAMs) using
LSTM–MacBert-based dual-stream transfer learning. <em>TCSS</em>,
<em>11</em>(5), 6435–6452. (<a
href="https://doi.org/10.1109/TCSS.2024.3385493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The disclosure of critical audit matters (CAMs) plays an important part in audit report reform and financial risk warnings. Current CAMs include matters that need to be focused on from the audit after a comprehensive evaluation of the internal control and other enterprise information, combined with the experience of the project manager, which is closely related to subjective factors, such as auditor professionalism and independence. An increase in subjective judgment becomes a breeding ground for audit failure. First, since long short-term memory (LSTM) is often used to process temporal data, MacBERT is often used as a text encoding, so LSTM is used to encode financial information to overcome the influence of subjective factors, and MacBert is used to encode nonfinancial information. The two modes are then separately encoded to form a dual-stream structure that simulates the process of auditors reviewing documents. Second, a transformer is used to perform multimodal interactions on the dual-stream encoding results to simulate the process of auditors integrating important information. Finally, the multimodal interaction results are fed into the fully connected layers and the SoftMax function to achieve cross-modal fusion, which simulates the process of auditors obtaining CAMs. Simulating single-modal coding, multimodal interaction, and cross-modal fusion helps to realize the automatic generation of CAMs. This ensemble model is called the CAMs automatic generation model and is based on LSTM–MacBert dual-stream transfer learning. The experimental results show that the features of financial statements and public disclosure text extracted by the model can effectively screen CAMs and realize the automatic generation of high-level CAMs.},
  archive      = {J_TCSS},
  author       = {Xiaojia Wang and Ziqing Luo and Ying Chen},
  doi          = {10.1109/TCSS.2024.3385493},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6435-6452},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Automatic generation of critical audit matters (CAMs) using LSTM–MacBert-based dual-stream transfer learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unlocking bias detection: Leveraging transformer-based
models for content analysis. <em>TCSS</em>, <em>11</em>(5), 6422–6434.
(<a href="https://doi.org/10.1109/TCSS.2024.3392469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bias detection in text is crucial for combating the spread of negative stereotypes, misinformation, and biased decision-making. Traditional language models frequently face challenges in generalizing beyond their training data and are typically designed for a single task, often focusing on bias detection at the sentence level. To address this, we present the contextualized bi-directional dual transformer (CBDT) classifier. This model combines two complementary transformer networks: the context transformer and the entity transformer, with a focus on improving bias detection capabilities. We have prepared a dataset specifically for training these models to identify and locate biases in texts. Our evaluations across various datasets demonstrate CBDT effectiveness in distinguishing biased narratives from neutral ones and identifying specific biased terms. This work paves the way for applying the CBDT model in various linguistic and cultural contexts, enhancing its utility in bias detection efforts. We also make the annotated dataset available for research purposes.},
  archive      = {J_TCSS},
  author       = {Shaina Raza and Oluwanifemi Bamgbose and Veronica Chatrath and Shardule Ghuge and Yan Sidyakin and Abdullah Yahya Mohammed Muaad},
  doi          = {10.1109/TCSS.2024.3392469},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6422-6434},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Unlocking bias detection: Leveraging transformer-based models for content analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A spatiotemporal graphical attention navigation algorithm
based on limited state information. <em>TCSS</em>, <em>11</em>(5),
6407–6421. (<a href="https://doi.org/10.1109/TCSS.2024.3384451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safe and efficient navigation of a robot in a high-density and dynamic crowd is a challenging task. Most of existing navigation algorithms need to acquire the full dynamics of neighboring humans at all times, making them heavily dependent on a complex upper level information state estimation process. Moreover, the scene perception modules of existing algorithms do not comprehensively model human–robot interaction in the spatiotemporal dimension, leading to frequent freezing and collision problems in reinforcement learning-based navigation algorithms. To address the above problems, we propose a fine-grained spatiotemporal graphical attention navigation algorithm (FST-RL), which enriches the scene perception module of reinforcement learning algorithms by jointly encoding human–robot motion patterns, interhuman relations, and long-term dependent information of human–robot interactions. With the proposed algorithm, socially compatible navigation routes can be generated by the built-in spatiotemporal reasoning module with the premise of obtaining only the position information of agents in the robot&#39;s perception domain. The experimental results show a significant improvement of FST-RL in terms of success rate (22.3% improvement), navigation time (13.6% reduction), and average return (20.8% improvement) in a high-density human environment compared with the current optimal navigation algorithm (DS-RNN). Ablation and qualitative experiments show that the scene perception module of FST-RL can effectively reduce the robot&#39;s collision and conservative behaviors in challenging scenarios.},
  archive      = {J_TCSS},
  author       = {Tao Ma and Zhen Liu and Tingting Liu and Yumeng Zhao and Yanjie Chai},
  doi          = {10.1109/TCSS.2024.3384451},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6407-6421},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A spatiotemporal graphical attention navigation algorithm based on limited state information},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A secure medical information storage and sharing method
based on multiblockchain architecture. <em>TCSS</em>, <em>11</em>(5),
6392–6406. (<a href="https://doi.org/10.1109/TCSS.2024.3381983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing application of technology in the healthcare industry, it has become imperative to establish a robust medical information ecosystem for effective management of medical information secure storage and sharing. This article proposes a healthier ecosystem in collaboration with the main consortium chain and data side chain, using multiblockchain architecture. In the implementation methods for this ecosystem, we store medical information in JavaScript Object Notation (JSON) format within different side chain structures. Additionally, we introduce an improved Practical Byzantine Fault Tolerant (PBFT) consensus mechanism based on a point nomination system and a dynamic RBAC access mechanism. By simulating a blockchain environment with multiple nodes, we analyze the efficiency of this method in terms of record retrieval, consensus mechanism, and storage execution time. The results demonstrate that compared to a single chain structure, the proposed method in this article achieves a substantial 30% improvement in query time efficiency. Moreover, the improved PBFT outperforms the traditional PBFT algorithm without dishonest nodes. Medical records stored in JSON format require shorter storage and execution time compared to text format records. This research contributes toward enhancing the security and efficiency of medical information storage and sharing among different medical subject information systems, thereby fostering a healthier healthcare alliance ecosystem.},
  archive      = {J_TCSS},
  author       = {Jian Hu and Peng Zhu and Juanjuan Li and Yong Qi and Youbing Xia and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3381983},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6392-6406},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A secure medical information storage and sharing method based on multiblockchain architecture},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visualizing routes with AI-discovered street-view patterns.
<em>TCSS</em>, <em>11</em>(5), 6380–6391. (<a
href="https://doi.org/10.1109/TCSS.2024.3382944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Street-level visual appearances play an important role in studying social systems, such as understanding the built environment, driving routes, and associated social and economic factors. It has not been integrated into a typical geographical visualization interface (e.g., map services) for planning driving routes. In this article, we study this new visualization task with several new contributions. First, we experiment with a set of AI techniques and propose a solution of using semantic latent vectors for quantifying visual appearance features. Second, we calculate image similarities among a large set of street-view images and then discover spatial imagery patterns. Third, we integrate these discovered patterns into driving route planners with new visualization techniques. Finally, we present VivaRoutes, an interactive visualization prototype, to show how visualizations leveraged with these discovered patterns can help users effectively and interactively explore multiple routes. Furthermore, we conducted a user study to assess the usefulness and utility of VivaRoutes.},
  archive      = {J_TCSS},
  author       = {Tsung Heng Wu and Md Amiruzzaman and Ye Zhao and Deepshikha Bhati and Jing Yang},
  doi          = {10.1109/TCSS.2024.3382944},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6380-6391},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Visualizing routes with AI-discovered street-view patterns},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Entity-relation guided random walk for link prediction in
knowledge graphs. <em>TCSS</em>, <em>11</em>(5), 6366–6379. (<a
href="https://doi.org/10.1109/TCSS.2024.3382263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are structured knowledge bases that represent information as a collection of interconnected entities and relations. Link prediction in KGs aims to infer missing or potential links between entities based on triple facts. Among different link prediction methods, knowledge graph embedding (KGE) has gained widespread popularity, with the goal of learning low-dimensional representations for KGs. However, most present KGE methods struggle to capture both local and global neighborhood information efficiently. Additionally, many hybrid methods have limitations in modeling and capturing interactions between triples. In this article, we propose an entity-relation-guided random walk (ERGRW) method for link prediction in KGs. Unlike conventional approaches that solely focus on entity-based walks, ERGRW creatively introduces relations as objects to walk as well. Inspired by distance-based methods, we design novel random walk rules based on the translation principle within triples. Thus, the ERGRW not only captures local and global neighborhood information but also discovers potential semantic relationships and interactions in the KGs. Furthermore, the encoder–decoder framework of ERGRW is able to learn comprehensive representation and improve link prediction performance. Extensive experiments conducted on four standard datasets demonstrate the superiority of ERGRW for link prediction.},
  archive      = {J_TCSS},
  author       = {Weisheng Li and Hao Zhong and Ronghua Lin and Chao Chang and Zhihong Pan and Yong Tang},
  doi          = {10.1109/TCSS.2024.3382263},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6366-6379},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Entity-relation guided random walk for link prediction in knowledge graphs},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative route planning of road trips in regional
central cities of china: An approach based on e-CARGO model.
<em>TCSS</em>, <em>11</em>(5), 6347–6365. (<a
href="https://doi.org/10.1109/TCSS.2024.3389773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the road trip in regional central cities has become one of the mainstream travel styles for Chinese tourists. However, existing research fails to plan the road trip route in Chinese regional central cities due to its flexibility, complexity, and long-term characteristic. A collaborative route planning approach for road trips, namely CoRPoRT, is proposed. This approach decomposes the route planning of a road trip into two role-based collaboration subproblems to alleviate the complexity issue. Then, the environments–classes, agents, roles, groups, and objects (E-CARGO) model is innovatively employed to formalize the problems and guide the optimization process for dealing with the long-term characteristic of road trips. Moreover, we identify the complex constraints affecting point of interest selections and propose an efficient solution via the IBM CPLEX solver to handle the flexibility of road trips. Finally, a case study and simulation experiments verify the effectiveness of CoRPoRT. CoRPoRT presents a general problem modeling method and a novel research paradigm for the route planning of road trips.},
  archive      = {J_TCSS},
  author       = {Hongyu Zhang and Zhuoxuan Huang and Zixu Jiang and Hua Ma and Haibin Zhu},
  doi          = {10.1109/TCSS.2024.3389773},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6347-6365},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Collaborative route planning of road trips in regional central cities of china: An approach based on E-CARGO model},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contextual semantics interaction graph embedding learning
for recommender systems. <em>TCSS</em>, <em>11</em>(5), 6333–6346. (<a
href="https://doi.org/10.1109/TCSS.2024.3394701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have become an indispensable tool in today&#39;s digital age, significantly enhancing user engagement on various online platforms by curating personalized item recommendations tailored to individual preferences. While the field has long been dominated by the collaborative filtering technique, which primarily leverages user–item interaction data, it often falls short in encapsulating the rich contextual intricacies and evolving dynamics inherent to these interactions. Recognizing this limitation, our research introduces the contextual semantic interaction graph embedding (CSI-GE) method. This advanced model incorporates a dynamic hop window within a multilayer graph convolutional network, ensuring a comprehensive extraction of both immediate and evolving contextual features. By amalgamating self-supervised contrastive learning, we achieve a refinement of user and item embeddings. Furthermore, our innovative variance–invariance–covariance (VIC) regularization-based loss function fortifies the robustness of these embeddings. Through rigorous testing, CSI-GE consistently outperformed contemporary methods, underscoring its superior accuracy and stability.},
  archive      = {J_TCSS},
  author       = {Shiyu Zhao and Yong Zhang and Mengran Li and Xinglin Piao and Baocai Yin},
  doi          = {10.1109/TCSS.2024.3394701},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6333-6346},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Contextual semantics interaction graph embedding learning for recommender systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causal intervention for fairness in multibehavior
recommendation. <em>TCSS</em>, <em>11</em>(5), 6320–6332. (<a
href="https://doi.org/10.1109/TCSS.2024.3379903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems usually learn user interests from various user behaviors, including clicks and postclick behaviors (e.g. , like and favorite, which reflects the true interests of users). However, these behaviors inevitably exhibit popularity bias, leading to some unfairness issues: 1) for items with similar quality, more popular ones get more exposure; and 2) even worse the popular items with lower popularity might receive more exposure. Existing work on mitigating popularity bias blindly eliminates the bias and usually ignores the effect of item quality. We argue that the relationships between different user behaviors (e.g. , conversion rate) actually reflect the item quality. Therefore, to handle the unfairness issues, we propose to mitigate the popularity bias by considering multiple user behaviors. In this work, we examine causal relationships behind the interaction generation procedure in multibehavior recommendation. Specifically, we find that: 1) item popularity is a confounder between the exposed items and users’ postclick interactions, leading to the exposure unfairness; and 2) some hidden confounders (e.g. , the reputation of item producers) affect both item popularity and quality, resulting in the quality unfairness. To alleviate these confounding issues, we propose a causal framework to estimate the causal effect, which leverages backdoor adjustment to block the backdoor paths caused by the confounders. In the inference stage, we remove the negative effect of popularity and utilize the good effect of quality for recommendation. Experiments on two real-world datasets validate the effectiveness of our proposed framework, which enhances fairness without sacrificing recommendation accuracy on postclick behavior.},
  archive      = {J_TCSS},
  author       = {Xi Wang and Wenjie Wang and Fuli Feng and Wenge Rong and Chuantao Yin and Zhang Xiong},
  doi          = {10.1109/TCSS.2024.3379903},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6320-6332},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Causal intervention for fairness in multibehavior recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FairAGG: Toward fair graph neural networks via fair
aggregation. <em>TCSS</em>, <em>11</em>(5), 6308–6319. (<a
href="https://doi.org/10.1109/TCSS.2024.3385539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have shown intrinsic topology bias inherited from graph-structured data, where a majority of nodes are associated with specific sensitive attributes (e.g., age, and race). In this regard, GNNs make discriminatory decisions toward certain groups defined by the sensitive attribute. Over the past few years, efforts have been made to mitigate the fairness issue of GNNs caused by topology bias. While achieving impressive results, these works likely only scratch the surface of what is possible with well-tuned GNN models or heuristic graph preprocessing techniques. Despite modern GNNs being built upon the message-passing framework, few works dig into the hidden reasoning behind the fairness issue of GNNs from such a fundamental perspective. In this work, we empirically demonstrate that message aggregation with higher edge weight for intergroup edges improves model fairness but sacrifices utility. The above observations motivate us to propose and derive a simple yet effective message-passing scheme, FairAGG , leading to more fair GNNs with less comprised downstream performance. Specifically, FairAGG measures the contribution of graph topology on fairness using Shapley value , which facilitates fair aggregation through reweighting. Experiments on several real-world datasets demonstrate that FairAGG enhances the fairness of the GNNs model while maintaining competitive utility performance.},
  archive      = {J_TCSS},
  author       = {Yuchang Zhu and Jintang Li and Liang Chen and Zibin Zheng},
  doi          = {10.1109/TCSS.2024.3385539},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6308-6319},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {FairAGG: Toward fair graph neural networks via fair aggregation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Piezoelectric touch sensing and random-forest-based
technique for emotion recognition. <em>TCSS</em>, <em>11</em>(5),
6296–6307. (<a href="https://doi.org/10.1109/TCSS.2024.3392569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition, a process of automatic cognition of human emotions, has great potential to improve the degree of social intelligence. Among various recognition methods, emotion recognition based on touch event&#39;s temporal and force information receives global interests. Although previous studies have shown promise in the field of keystroke-based emotion recognition, they are limited by the need for long-term text input and the lack of high-precision force sensing technology, hindering their real-time performance and wider applicability. To address this issue, in this article, a piezoelectric-based keystroke dynamic technique is presented for quick emotion detection. The nature of piezoelectric materials enables high-resolution force detection. Meanwhile, the data collecting procedure is highly simplified because only the password entry is needed. International Affective Digitized Sounds (IADS) are applied to elicit users’ emotions, and a pleasure-arousal-dominance (PAD) emotion scale is used to evaluate and label the degree of emotion induction. A random forest (RF)-based algorithm is used in order to reduce the training dataset and improve algorithm portability. Finally, an average recognition accuracy of 79.33% of four emotions (happiness, sadness, fear, and disgust) is experimentally achieved. The proposed technique improves the reliability and practicability of emotion recognition in realistic social systems.},
  archive      = {J_TCSS},
  author       = {Yuqing Qi and Weichen Jia and Lulei Feng and Yanning Dai and Chenyu Tang and Fuqiang Zhou and Shuo Gao},
  doi          = {10.1109/TCSS.2024.3392569},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6296-6307},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Piezoelectric touch sensing and random-forest-based technique for emotion recognition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An integrated healthcare service system based on blockchain
technologies. <em>TCSS</em>, <em>11</em>(5), 6278–6295. (<a
href="https://doi.org/10.1109/TCSS.2024.3392591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare, as a fundamental public service, has undergone extensive efforts spanning decades to elevate both quality and patient satisfaction. Recent strides in information and communication technologies have catalyzed research into medical data sharing, acknowledged as pivotal for delivering high-quality treatment. Nevertheless, the existence of discrete platforms for different services has cultivated data silos among healthcare service providers, posing an impediment to service quality. Concurrently, security issues loom as potential threats to the efficacy of medical data sharing. To tackle these challenges, this article introduces an integrated healthcare service system grounded in blockchain technology, which aims to establish a seamless and trustworthy environment for data sharing among diverse participants within the healthcare community. The proposed system accommodates an array of ancillary services, contributing to an enriched experience for both patients and healthcare providers. The intrinsic attributes of blockchain, such as data immutability and traceability, serve to mitigate the risk of data tampering and leakage, thereby ensuring data security and safeguarding patient privacy. This study substantiates the efficacy of the proposition through extensive experiments, underscoring the potential of blockchain to augment the quality of healthcare services.},
  archive      = {J_TCSS},
  author       = {Qian Geng and Ziang Chuai and Jian Jin},
  doi          = {10.1109/TCSS.2024.3392591},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6278-6295},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An integrated healthcare service system based on blockchain technologies},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tibetan-BERT-wwm: A tibetan pretrained model with whole word
masking for text classification. <em>TCSS</em>, <em>11</em>(5),
6268–6277. (<a href="https://doi.org/10.1109/TCSS.2024.3374633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks contributed massive text data generated by users in it, which were crucial in information explosion. These unstructured and ambiguous expressed data may result in difficulty in obtaining available contextual information from it, which can help us gain more accurate insights into user-generated content, user preferences, and topic dynamics within social networks. By training on a large-scale unsupervised corpus and fine-tuning parameters using a limited amount of supervised data, the pretrained language model can effectively capture rich contextual information and achieve excellent performance in numerous downstream tasks of natural language processing (NLP). For the low-resource language such as Tibetan, the distributed representation results of dynamic changes obtained from pretrained language models can effectively alleviate the problem of insufficient labeled data. In order to achieve more effective contextual information and word-level semantic information in Tibetan social media, we collected a large amount of Tibetan language corpus and trained a Tibetan pretrained language model, named as Tibetan-BERT-wwm, by using the whole word masking strategy. Additionally, we apply the model to analyze textual data from social networks to assess its efficacy in capturing user sentiments and news topic in Tibetan social media. In this study, accuracy, precision, recall, and F1 score were used to evaluate its performance. The results showed that the macro-F1 of Tibetan-BERT-wwm in the public dataset TNCC document and title are 75.55% and 64.17%, the self-built sentiment analysis dataset is 70.98%. Compared with other pretrained language models, the Tibetan-BERT-wwm model can capture the semantic information of Tibetan well and improve the Tibetan classification effect.},
  archive      = {J_TCSS},
  author       = {Yatao Liang and Hui Lv and Yan Li and La Duo and Chuanyi Liu and Qingguo Zhou},
  doi          = {10.1109/TCSS.2024.3374633},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6268-6277},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Tibetan-BERT-wwm: A tibetan pretrained model with whole word masking for text classification},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient rumor suppression approach with knowledge graph
convolutional network in social network. <em>TCSS</em>, <em>11</em>(5),
6254–6267. (<a href="https://doi.org/10.1109/TCSS.2024.3383493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks currently serve as one of the primary sources from which people obtain news, with the spread of rumors emerging as a major concern. The goal of rumor suppression is to minimize the number of individuals affected by rumors through various methods, such as blocking and disseminating the truth. Although this problem has evolved into a popular research topic, existing solutions often overlook the temporal impact of rumor-refuting information and the influence of user opinions on rumor spreading. In the study, we first investigate the two-stage rumor minimization problem. The problem primarily considers two situations about only the propagation of rumors and the simultaneous propagation of rumor and rumor-refuting information, aiming to minimize the impact of rumors. We propose the two-stage user opinion rumor propagation model (TSUORP), which fully incorporates the timing of official releases of rumor-refuting information and their influence on the generation of rumors propagation. Based on this, we propose an approach using the knowledge graph convolutional network (KGCN) algorithm to rapidly and effectively select rumor-refuting information seed nodes based on user opinions. To assess the validity of our proposed approach, we perform experiments on three authentic datasets, showcasing its notable advantages.},
  archive      = {J_TCSS},
  author       = {Fei Gao and Qiang He and Xingwei Wang and Lin Qiu and Min Huang},
  doi          = {10.1109/TCSS.2024.3383493},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6254-6267},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An efficient rumor suppression approach with knowledge graph convolutional network in social network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tracking of disinformation sources: Examining pages and
URLs. <em>TCSS</em>, <em>11</em>(5), 6242–6253. (<a
href="https://doi.org/10.1109/TCSS.2024.3391626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social media (OSM) platforms have become hotbeds for various cybercrimes. Attackers often employ “shotgun” approaches, slightly altering their malicious content to evade detection and distributing it across multiple OSM channels to target more victims. This tactic is used to launch fake news, political propaganda, and social engineering attacks. To address these issues, we propose a novel framework that uses artificial intelligence (AI) to effectively trace the source of disinformation and detect content with abnormal similarities. Our approach not only analyzes the content itself but also focuses on the external uniform resource locators (URLs) associated with the content and the specific pages where the malicious content appears. The framework is designed to filter out suspicious content, external URLs, and channels based on a few verified instances of disinformation, using an adaptive approach that can quickly respond to evolving disinformation tactics. The framework was evaluated using a real dataset and revealed that certain channels on OSM platforms function as critical bridges between normal and disinformation clusters. Our study offers valuable insights for OSM platforms and administrators to proactively detect clusters of disinformation messages, external URLs, and channels with only a small number of manually verified samples. Additionally, it illuminates the role and dynamics of how disinformation evolves and spreads, which can aid in developing more effective strategies to combat disinformation on OSM platforms.},
  archive      = {J_TCSS},
  author       = {Chun-Ming Lai and Yi-Hua Guo},
  doi          = {10.1109/TCSS.2024.3391626},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6242-6253},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Tracking of disinformation sources: Examining pages and URLs},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A trustworthy approach to classify and analyze
epidemic-related information from microblogs. <em>TCSS</em>,
<em>11</em>(5), 6229–6241. (<a
href="https://doi.org/10.1109/TCSS.2024.3391395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media platforms, such as Twitter, are crucial resources to obtain situational information during disease outbreaks. Due to the sheer volume of user-generated content, providing tools that can automatically classify input texts into various types, such as symptoms, transmission, prevention measures, etc., and generate concise situational updates is necessary. Apart from high classification accuracy, interpretability is an important requirement when designing machine learning models for tasks in medical domain. In this article, we provide annotated epidemic-related datasets with labels of information types and rationales, which are short phrases from the original tweets, to support the assigned labels. Next, we introduce a trustworthy approach for the automatic classification of tweets posted during epidemics. Our classification model is able to extract short explanations/rationales for output decisions on unseen data. Moreover, we propose a simple graph-based ranking method to generate short summaries of tweets. Experiments on two epidemic-related datasets show the following: 1) our classification model obtains an average of 82% Macro-F1 and better interpretability scores in terms of Token-F1 (20% improvement) than baselines; 2) the extracted rationales capture essential disease-related information in the tweets; 3) our graph-based method with rationales is simple, yet efficient for generating concise situational updates.},
  archive      = {J_TCSS},
  author       = {Thi Huyen Nguyen and Marco Fisichella and Koustav Rudra},
  doi          = {10.1109/TCSS.2024.3391395},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6229-6241},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A trustworthy approach to classify and analyze epidemic-related information from microblogs},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FROST: Controlled label propagation for multisource
detection. <em>TCSS</em>, <em>11</em>(5), 6217–6228. (<a
href="https://doi.org/10.1109/TCSS.2024.3390931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We often see rumors rapidly spreading in online social networks. These are harmful for our society in many ways. Infection source detection is the task of identifying the sources of rumors or any other such infections in social networks, so that appropriate intervention could be performed to control the harm. Researchers have studied this problem under various scenarios, where multisource detection has been of special importance. In this article, we propose a novel infection rate controlled label propagation method for multisource detection called FROST . It leverages the connection strengths between a pair of nodes in the form of infection rate to capture the implicit information latent within an infection. Initially, labels are assigned to nodes indicating whether the nodes are infected or not. Afterward, the labels are propagated across the network in a controlled manner based on the infection rate. Once the propagation converges, the locally prominent nodes are considered as sources. We compare FROST against six state-of-the-art methods and two heuristic baselines in terms of ten evaluation measures over four social networks datasets. Our results show that FROST generally outperforms the competing methods across various evaluation measures and datasets. It also estimates the number of sources closer to the actual than the competing methods. FROST scales effectively for large infections, including when there are infection overlaps, where the competing methods generally lag.},
  archive      = {J_TCSS},
  author       = {Syed Shafat Ali and Ajay Rastogi and Tarique Anwar},
  doi          = {10.1109/TCSS.2024.3390931},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6217-6228},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {FROST: Controlled label propagation for multisource detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Study of brainwave entrainment induced by 1-h-long 40-hz
flickering stimulation. <em>TCSS</em>, <em>11</em>(5), 6210–6216. (<a
href="https://doi.org/10.1109/TCSS.2024.3374455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steady-state visual evoked potentials (SSVEPs) have been widely applied in brain–computer interfaces, cognitive and clinical neuroscience study. Recently, 40-Hz flickering induced brainwave entrainment (BWE) was used to intervene cognition and aging-related diseases, such as Alzheimer’s disease (AD), vascular cognitive impairment, and phobic anxiety, through 1-h-long visual stimulations. The mechanism of action was believed to induce gamma oscillation in related brain regions. According to our knowledge, the amplitude of BWE at 40 Hz through a prolonged visual stimulation has not been reported. Therefore, we recorded electroencephalogram (EEG) signal induced by a high refreshing rate monitor in 50 healthy subjects. We observed that the response of BWE varied among subjects and fluctuated over time. The relationship between 40-Hz BWE and mental state was analyzed by the brainwave band ratio and signal entropies. We found that the amplitude of BWE was inverse proportionally to brainwave band α/β ratio and correlated with the sample entropy of the recorded EEG, which further connected the BWE response to the fatigue level of the subjects. We also demonstrated that a 1-min stimulation test before the 1-h-long visual stimulation was able to predict the amplitude of BWE. Finally, we showed that the measured α/β and θ/β ratios of EEG were not changed significantly before and after the 1-h-long stimulation. Our experimental results provided database for prolonged BWE, which is beneficial for the design of BWE treatment.},
  archive      = {J_TCSS},
  author       = {Tan Yizhou and Li Zhe and Zhou Yong and Cai Hanshu and Qiu Haixia and Zhao Yue and Gu Ying},
  doi          = {10.1109/TCSS.2024.3374455},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6210-6216},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Study of brainwave entrainment induced by 1-h-long 40-hz flickering stimulation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FairCMS: Cloud media sharing with fair copyright protection.
<em>TCSS</em>, <em>11</em>(5), 6192–6209. (<a
href="https://doi.org/10.1109/TCSS.2024.3374452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The onerous media sharing task prompts resource-constrained media owners to seek help from a cloud platform, i.e., storing media contents in the cloud and letting the cloud do the sharing. There are three key security/privacy problems that need to be solved in the cloud media sharing scenario, including data privacy leakage and access control in the cloud, infringement on the owner&#39;s copyright, and infringement on the user&#39;s rights. In view of the fact that no single technique can solve the above three problems simultaneously, two cloud media sharing schemes are proposed in this article, named FairCMS-I and FairCMS-II. By cleverly utilizing the proxy re-encryption technique and the asymmetric fingerprinting (AFP) technique, FairCMS-I and FairCMS-II solve the above three problems with different privacy/efficiency tradeoffs. Among them, FairCMS-I focuses more on cloud-side efficiency while FairCMS-II focuses more on the security of the media content, which provides owners with flexibility of choice. In addition, FairCMS-I and FairCMS-II also have advantages over existing cloud media sharing efforts in terms of optional indistinguishability under chosen-plaintext attack (IND-CPA) security and high cloud-side efficiency, as well as exemption from needing a trusted third party. Furthermore, FairCMS-I and FairCMS-II allow owners to reap significant local resource savings and thus can be seen as the privacy-preserving outsourcing of AFP. Finally, the feasibility and efficiency of FairCMS-I and FairCMS-II are demonstrated by experiments.},
  archive      = {J_TCSS},
  author       = {Xiangli Xiao and Yushu Zhang and Leo Yu Zhang and Zhongyun Hua and Zhe Liu and Jiwu Huang},
  doi          = {10.1109/TCSS.2024.3374452},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6192-6209},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {FairCMS: Cloud media sharing with fair copyright protection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extracting high-fidelity smaller scale subgraphs of complex
networks by edge-reinforced random walk. <em>TCSS</em>, <em>11</em>(5),
6181–6191. (<a href="https://doi.org/10.1109/TCSS.2024.3381777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world networks have properties such as complex interactions and large-scale structures, which pose significant computational challenges when analyzing their structural and dynamical behavior. Network reduction algorithms, such as renormalization group and subgraph extraction, have emerged as potential solutions to address these challenges. These algorithms aim to reveal critical properties hidden within the original network, such as self-similarity and scale invariance. However, existing reduction procedures often rely on specific assumptions or have high computational complexity, which severely limits their practicality. To overcome these limitations, this article proposes a subgraph extraction strategy based on edge-reinforced random walks to achieve network reduction. In comparison with traditional renormalization procedures, our method offers lower computational complexity while effectively preserving most of the crucial structural properties of real networks. Specifically, the proposed method selects nodes with higher degree values in the network as candidate starting nodes for the random walk and then obtains smaller scale subgraphs of the original network through a random walk method that depends on the edge weights. Extensive experiments on synthetic and real networks show that the critical properties of most networks exhibit strong self-similarity behavior under the presented subgraph extraction method.},
  archive      = {J_TCSS},
  author       = {Dan Chen and Housheng Su},
  doi          = {10.1109/TCSS.2024.3381777},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6181-6191},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Extracting high-fidelity smaller scale subgraphs of complex networks by edge-reinforced random walk},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Digitizing history: Transitioning historical paper documents
to digital content for information retrieval and mining—a comprehensive
survey. <em>TCSS</em>, <em>11</em>(5), 6151–6180. (<a
href="https://doi.org/10.1109/TCSS.2024.3378419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Historical document processing (HDP) corresponds to the task of converting the physical-bind form of historical archives into a web-based centrally digitized form for their conservation , preservation , and ubiquitous access . Besides the conservation of these invaluable historical collections, the key agenda is to make these geographically distributed historical repositories available for information mining and retrieval in a web-centralized touchless mode . Being a matter of interest for interdisciplinary scholars, the endeavor has garnered the attention of many researchers resulting in an immense body of the literature dedicated to digitization strategies. The present study first assembles the prevalent tasks essential for HDP into a pipeline and frames an outline for a generic workflow for historical document digitization. Then, it reports the latest task-specific state of the art which gives a brief discourse on the methods and open challenges in handling historical printed and handwritten script images. Next, grounded on various layout attributes, it further talks about the evaluation metrics and datasets available for observational and analytical purposes. The current study is an attempt to trail the contours of undergoing research and its bottlenecks thus, providing readers with a comprehensive view and understanding of existing studies and unfolding the open avenues for the future outlook.},
  archive      = {J_TCSS},
  author       = {Nancy Girdhar and Mickaël Coustaty and Antoine Doucet},
  doi          = {10.1109/TCSS.2024.3378419},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6151-6180},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Digitizing history: Transitioning historical paper documents to digital content for information retrieval and Mining—A comprehensive survey},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single-node injection label specificity attack on graph
neural networks via reinforcement learning. <em>TCSS</em>,
<em>11</em>(5), 6135–6150. (<a
href="https://doi.org/10.1109/TCSS.2024.3377554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have achieved remarkable success in various real-world applications. However, recent studies highlight the vulnerability of GNNs to malicious perturbations. Previous adversaries primarily focus on graph modifications or node injections to existing graphs, yielding promising results but with notable limitations. Graph modification attack (GMA) requires manipulation of the original graph, which is often impractical, while graph injection attack (GIA) necessitates training a surrogate model in the black-box setting, leading to significant performance degradation due to divergence between the surrogate architecture and the actual victim model. Furthermore, most methods concentrate on a single attack goal and lack a generalizable adversary to develop distinct attack strategies for diverse goals, thus limiting precise control over victim model behavior in real-world scenarios. To address these issues, we present a gradient-free generalizable adversary that injects a single malicious node to manipulate the classification result of a target node in the black-box evasion setting. Specifically, we model the single-node injection label specificity attack as a Markov decision process (MDP) and propose gradient-free generalizable single node injection attack, namely G ${}^{2}$ -SNIA, a reinforcement learning framework employing proximal policy optimization (PPO). By directly querying the victim model, G ${}^{2}$ -SNIA learns patterns from exploration to achieve diverse attack goals with extremely limited attack budgets. Through comprehensive experiments over three acknowledged benchmark datasets and four prominent GNNs in the most challenging and realistic scenario, we demonstrate the superior performance of our proposed G ${}^{2}$ -SNIA over the existing state-of-the-art baselines. Moreover, by comparing G ${}^{2}$ -SNIA with multiple white-box evasion baselines, we confirm its capacity to generate solutions comparable to those of the best adversaries.},
  archive      = {J_TCSS},
  author       = {Dayuan Chen and Jian Zhang and Yuqian Lv and Jinhuan Wang and Hongjie Ni and Shanqing Yu and Zhen Wang and Qi Xuan},
  doi          = {10.1109/TCSS.2024.3377554},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6135-6150},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Single-node injection label specificity attack on graph neural networks via reinforcement learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recognizing core knowledge from domain knowledge network for
platform-based business development. <em>TCSS</em>, <em>11</em>(5),
6125–6134. (<a href="https://doi.org/10.1109/TCSS.2024.3385671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging topic in industrial digital transformation, digital business development in the context of platformization has received widespread attention. A large number of industrial companies have established new platform-based systems for digital business development by integrating their original information systems. The unified platform development mode promotes the integration of previously decentralized knowledge. However, the massive expansion of the knowledge system under platformization causes it to be no easier for developers to master or understand the core knowledge (context, concepts, and elements) of the business to be developed. According to the above dilemmas we have observed in the industry, in this article, a domain knowledge network modeling method for the knowledge system under platformization and a GP-based rule generation method for recognizing core business knowledge in the domain knowledge network are proposed for the first time. Our experiment and practical case study verify that our method can recognize a set of core business knowledge from a large knowledge network efficiently, which could help developers understand the business to be developed with a lower cognitive load. We hope the idea of platform-based business development and core business knowledge recognition can provide a reference for those companies that need efficient digital business development.},
  archive      = {J_TCSS},
  author       = {Poly Z.H. Sun and Hongwei Jiang and Chengjun Wang and Xinfeng Ru and Xinguo Ming},
  doi          = {10.1109/TCSS.2024.3385671},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6125-6134},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Recognizing core knowledge from domain knowledge network for platform-based business development},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Group multirole assignment with cooperation, conflict, and
public interest factors. <em>TCSS</em>, <em>11</em>(5), 6112–6124. (<a
href="https://doi.org/10.1109/TCSS.2024.3374206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In collaborative endeavors, there are always various types of cooperation, conflict, and public interest relationships. Taking home appliance production as a typical example, this article extends the group role assignment with the cooperation and conflict factors (GRACCF) model by newly adding public interest relationships to formalize the problem dealing with the above three collaboration relationships. By adding three different threshold parameters to represent cooperation, conflict as well as public interest relationships, we can make complex decisions based on the benefit values from different relationships. Through the discussion and analysis of large-scale experiments, different change trends are presented to help make certain adjustments and provide suggestions on the boundaries of these values in production and formulate appropriate production plans after determining these boundaries.},
  archive      = {J_TCSS},
  author       = {Xintong Ke and Haibin Zhu and Dongning Liu},
  doi          = {10.1109/TCSS.2024.3374206},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6112-6124},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Group multirole assignment with cooperation, conflict, and public interest factors},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward web3 applications: Easing the access and transition.
<em>TCSS</em>, <em>11</em>(5), 6098–6111. (<a
href="https://doi.org/10.1109/TCSS.2024.3382582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web3 is leading a wave of the next generation of web services that even many Web2 applications are keen to ride. However, the lack of Web3 background for Web2 developers hinders easy and effective access and transition. On the other hand, Web3 applications desire encouragement and advertisement from conventional Web2 companies and projects due to their low market shares. In this article, we propose a seamless transition framework that transits Web2 to Web3, named WebttCom [ WebttCom stands for Web2 (two)–Web3 (three) Communicator], after exploring the connotation of Web3 and the key differences between Web2 and Web3 applications. We also provide a full-stack implementation as a use case to support the proposed framework, followed by performance evaluation and surveys with $\sim$ 1000 participants that show $\sim$ 80% positive and $\sim$ 20% neutral responses. We confirm that the proposed framework WebttCom addresses the defined research question, and the implementation well satisfies the framework WebttCom in terms of strong necessity , usability , and completeness based on the survey results.},
  archive      = {J_TCSS},
  author       = {Guangsheng Yu and Xu Wang and Qin Wang and Tingting Bi and YiFei Dong and Ren Ping Liu and Nektarios Georgalas and Andrew Reeves},
  doi          = {10.1109/TCSS.2024.3382582},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6098-6111},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Toward web3 applications: Easing the access and transition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial and temporal user interest representations for
sequential recommendation. <em>TCSS</em>, <em>11</em>(5), 6087–6097. (<a
href="https://doi.org/10.1109/TCSS.2024.3378454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, recommendation systems have become increasingly prevalent in various fields, facilitating quick access to the information users need. As a result, many models have been proposed to model user interests, leading to more accurate recommendation lists, superior user experience, and business value. However, characterizing the dynamically changing interests of users is a challenging task. User interests shift over time while maintaining some long-term interests, and at each time, users’ interests are diverse. To investigate the benefits of multidimensional interests for users, this article proposes to characterize user preferences based on their spatiotemporal interests. Utilizing temporal and spatial information is critical for improving recommendation accuracy. To achieve this, we present a novel approach called multilong short-term interest (MLSI) user representation for recommendation. This method extracts long-term and short-term interests of users from their behavioral sequences using decoupled self-supervised learning with different optimizers. Self-attention is then employed to capture the diverse interests of users through their behavioral sequences. Final, long-term and short-term interests, as well as diversified interests, are aggregated to represent user interests. Extensive experiments on real-world datasets show that MLSI not only outperforms state-of-the-art methods but also more effectively characterizes user interests, reflecting an improvement ranging from 5% to 20% across various metrics on multiple datasets.},
  archive      = {J_TCSS},
  author       = {Haibing Hu and Kai Han and Zhizhuo Yin and Defu Lian},
  doi          = {10.1109/TCSS.2024.3378454},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6087-6097},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Spatial and temporal user interest representations for sequential recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchain platform selection for supply chain finance: A
bilateral-negotiation-based group multiattribute decision making method.
<em>TCSS</em>, <em>11</em>(5), 6072–6086. (<a
href="https://doi.org/10.1109/TCSS.2024.3385736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply chain finance (SCF) can provide innovative financing approaches for cash-constrained supply chain partners, which has been utilized for industries to optimize capital, reduce costs and alleviate financing pressure. Despite there are promising results in SCF, there are still many challenges in the development of SCF practice, such as the information asymmetry problem and credit data transmission barriers. Blockchain has been widely adopted in the finance industry, it can provide solutions to these challenges. However, the capabilities and performance of different blockchain platforms (BPs) vary greatly, thus, it is necessary to select an appropriate BP according to the specific circumstances of SCF. The main purpose of this article is to develop a decision-making framework to select a suitable BP for the blockchain implementation of SCF. Since SCF business involves multiple entities such as core enterprises, suppliers, and financial institutions, each entity has different requirements for BP, so conflicts of opinion are prone to occur in the decision making process. To this end, we develop a bilateral negotiation group multiattribute decision making (BN-GMADM) method with personalized individual semantics (PIS) to coordinate opinions and promote consensus. In addition, the distributed linguistic scoring rule (DLSR) is proposed for BP alternatives scoring and ranking. A case study and several analyses are provided to illustrate and validate the proposed approach.},
  archive      = {J_TCSS},
  author       = {Tiantian Gai and Jian Wu and Mingshuo Cao and Yujia Liu and Changyong Liang},
  doi          = {10.1109/TCSS.2024.3385736},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6072-6086},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Blockchain platform selection for supply chain finance: A bilateral-negotiation-based group multiattribute decision making method},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stress prediction based on chaos theory and an
event–behavior–stress triangle model. <em>TCSS</em>, <em>11</em>(5),
6056–6071. (<a href="https://doi.org/10.1109/TCSS.2024.3386752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting stress can help people take timely action to manage stress before potential physical and psychological problems arise. In this study, we analyze and verify chaotic features of human&#39;s stress response to stressor and uplift events, and present an event–behavior–stress triangle model for stress prediction. We reconstruct the phase space based on chaos theory, and integrate stress-correlated pre and postfactors (events and behaviors) through an event–behavior–stress correlation memory and a behavior-stress correlation memory for stress prediction. User&#39;s personal features (including self-cognition, opinion about school, personality traits, and future event&#39;s impact) are also involved in stress prediction. We conduct the experiments on the publicly available StudentLife dataset collected from a mobile phone app, including users’ daily activities inferred through the automatic and continuous sensing application and users’ self-reported ecological momentary assessments (EMA) data. The experimental results show that the proposed method outperforms four baseline methods, achieving (88.13% accuracy, 79.38% precision, 77.10% recall, 78.19% F1-score) for 2-labeled (nonstressed/stressed) stress prediction, and (70.42% accuracy, 69.21% precision, 67.90% recall, 68.53% F1-score) for 3-label (nonstressed/little-stressed/huge-stressed) stress prediction. Further possible improvements and implications related to chaos-based stress prediction are also discussed at the end of the article. https://github.com/lny0806/chaos-stress-predict},
  archive      = {J_TCSS},
  author       = {Ningyun Li and Ling Feng and Huijun Zhang and Lei Cao and Xin Wang},
  doi          = {10.1109/TCSS.2024.3386752},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6056-6071},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Stress prediction based on chaos theory and an Event–Behavior–Stress triangle model},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RumorGraphXplainer: Do structures really matter in rumor
detection. <em>TCSS</em>, <em>11</em>(5), 6038–6055. (<a
href="https://doi.org/10.1109/TCSS.2024.3378065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of social media has enabled individuals to rapidly share information, including rumors, which can have significant impacts on various domains. Traditional approaches to rumor control are impractical for social media platforms due to the volume and speed of information. Automated detection methods are needed that not only identify rumors early but also provide explanations for their decisions to protect free speech. Recent advancements in deep learning have shown promise in automating rumor detection. Graph-based models, such as bidirectional graph convolution network (Bi-GCN), capture propagation, and dispersion patterns to differentiate rumors from the truth. However, the interpretability of these deep learning models is a challenge. This article focuses on graph convolution networks (GCNs), which lack attention maps for easy model attribution but excel at capturing global structural features. We investigate the importance of graph structure in rumor detection using two GCN models on a real-world dataset, analyzing the learned latent propagation and dispersion features. To the best of our knowledge, this is the first study to explore GCNs in rumor detection and investigate the significance of graph structure in this task. Our research addresses three primary questions: 1) the primary contributors to GCN-based rumor detection models and their differences across models; 2) the importance of graph structure for accurate predictions in GCN-based models; and 3) the latent propagation and dispersion features learned by GCN-based detection models during the rumor detection process.},
  archive      = {J_TCSS},
  author       = {Daniel Wai Kit Chin and Kwan Hui Lim and Roy Ka-Wei Lee},
  doi          = {10.1109/TCSS.2024.3378065},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6038-6055},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {RumorGraphXplainer: Do structures really matter in rumor detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). XLoCoFC: A fast fuzzy community detection approach based on
expandable local communities through max-membership degree propagation.
<em>TCSS</em>, <em>11</em>(5), 6022–6037. (<a
href="https://doi.org/10.1109/TCSS.2024.3392069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy community detection (FCD) aims to reveal the community structure by allocating quantitative values to nodes across different communities. This article proposes a fast FCD approach called the Expandable Local Community based Fuzzy Community (XLoCoFC) detection method based on max-membership degree propagation (max-MDP) and normalized peripheral similarity index ( $ \boldsymbol{n}\mathbf{P}\mathbf{S}\mathbf{I}$ ). Initially, nodes having comparatively higher $ \boldsymbol{n}\mathbf{P}\mathbf{S}\mathbf{I}$ values are considered as topologically dominating nodes and selected as seeds. For an initial community, called local community, seed’s $ \boldsymbol{n}\mathbf{P}\mathbf{S}\mathbf{I}$ values from the respective neighbors’ peripheries are utilized as the neighbors’ membership degrees. Then an iterative process propagates max-membership degrees from nodes to nodes, and $ \boldsymbol{n}\mathbf{P}\mathbf{S}\mathbf{I}$ values are used as factors in the propagation. In this propagation, local communities having more dominating nodes expand and others contract. The propagation process converges very quickly. Such simplicity in its design makes our proposed XLoCoFC approach to be very fast in finding community structures on large networks. Time complexity of the proposed approach is $ \boldsymbol{O}\left(\boldsymbol{n}\boldsymbol{d}^{2}\times \mathbf{lo}\mathbf{g}_{2} \boldsymbol{d}+\mathbf{k}\mathbf{l}\mathbf{q}\right)$ which is significantly less than the majority of the FCD algorithms, for whom it is either $ \boldsymbol{O}\left(\boldsymbol{n}^{2}\right)$ or more. Moreover, XLoCoFC has no dependence on any network feature. It does not require tuning of any parameter which may impact its output. To demonstrate the working of the proposed XLoCoFC approach, we conduct extensive performance analysis comparatively by executing a set of existing approaches on several popular real-life and synthetic networks with number of nodes ranging from 24 to 1134 890. Evaluation of the results considering the accuracy and quality metrics as well as a group MCDM technique clearly establishes the superiority of our approach over others.},
  archive      = {J_TCSS},
  author       = {Uttam K. Roy and Pranab K. Muhuri and Sajib K. Biswas},
  doi          = {10.1109/TCSS.2024.3392069},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6022-6037},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {XLoCoFC: A fast fuzzy community detection approach based on expandable local communities through max-membership degree propagation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised video summarization based on the diffusion
model of feature fusion. <em>TCSS</em>, <em>11</em>(5), 6010–6021. (<a
href="https://doi.org/10.1109/TCSS.2024.3384627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video summarization (VS) technologies can automatically extract key frames with effective information and thus can help to quickly identify the events or speed up the decision-making process, especially for accidents. With the fast development of deep learning technologies, many generative adversarial network (GAN)- and reinforcement learning (RL)-based unsupervised VS methods have been developed in recent years. However, these methods could suffer from the problems of unstable training and difficulty of reward function formulation, respectively. To this end, we present an unsupervised VS method called diffusion model of feature fusion (DMFF) in this article, which consists of a diffusion module (DM), a feature extraction and compression module (FECM), and a coarse-fine frame selector (CFFS). DM is designed to avoid the training instability problem caused by GAN&#39;s alternate training generator and discriminator. FECM is used to extract and compress video features. CFFS is designed to capture both low-level and high-level features between frames to handle complex and diverse accident videos. Then, high-level local and global features are fused to generate a multigrained final frame score. Experiments on two widely used benchmark datasets, SumMe and TVSum, demonstrate the effectiveness and superiority of the proposed network to the state-of-the-art methods, and the training is more stable.},
  archive      = {J_TCSS},
  author       = {Qinghao Yu and Hui Yu and Ying Sun and Derui Ding and Muwei Jian},
  doi          = {10.1109/TCSS.2024.3384627},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {6010-6021},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Unsupervised video summarization based on the diffusion model of feature fusion},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ER-C3D: Enhancing r-c3-d network with adaptive shrinkage and
symmetrical multiscale for behavior detection. <em>TCSS</em>,
<em>11</em>(5), 5997–6009. (<a
href="https://doi.org/10.1109/TCSS.2024.3383270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavior detection receives considerable attention in real-life human–computer interaction, where the complexity of background information and the variable durations of movements are two major factors affecting the accuracy of behavior detection. To overcome the inadequacy of these factors, this article proposes an enhancing region convolutional 3-D (ER-C3D) network with adaptive shrinkage and symmetrical multiscale for behavior detection. The improved ER-C3D network includes a feature subnet, a proposal subnet, and a classification subnet. First, a 3D-RSST unit is constructed by embedding an adaptive shrinkage structure and a soft thresholding operation. Meanwhile, a residual adaptive shrinkage mechanism, composed of multiple cascaded 3D-RSST units with different parameters, is designed to reduce redundant information of video streams in the feature subnet. Second, a spatiotemporal symmetrical multiscale structure is substituted for the single-layer convolution and embedded into the proposal subnet. Specially, contextual symmetrical multiscale motion characteristics with different levels and granularities are acquired by expanding the spatiotemporal receptive field of candidate temporal proposals. Finally, a soft-nonmaximal suppression strategy is introduced to filter high-quality temporal proposals in the classification subnet. The experimental results on the THUMOS’14 and ActivityNet1.2 datasets indicate that the mAP@0.5 of the improved ER-C3D network reaches 39.4% and 42.2%, respectively, which is 10.5% and 15.4% higher than R-C3D. Compared with related methods, the proposed method shows improvement in both the positional precision of behavioral boundary and the accuracy of behavioral classification.},
  archive      = {J_TCSS},
  author       = {Zhong Huang and Mengyuan Tao and Ning An and Min Hu and Fuji Ren},
  doi          = {10.1109/TCSS.2024.3383270},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5997-6009},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {ER-C3D: Enhancing R-c3-D network with adaptive shrinkage and symmetrical multiscale for behavior detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Team composition for competitive information spread:
Dual-diversity maximization based on information and team.
<em>TCSS</em>, <em>11</em>(5), 5984–5996. (<a
href="https://doi.org/10.1109/TCSS.2024.3383241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social-media platforms provide citizens a new way to stay informed and offer marketers a shot at promoting their brand. In social advertising, information diversity can create a level playing field for competitive information dissemination. Team diversity is important because teams with a diverse composition tend to perform better over time. The former demands that all the social networks’ users should receive diverse information. The later requires teams to be diverse with respect to team members’ attributes. However, to our knowledge, not only the diversity of the information spreading in the social network but also the influential users’ attributes are never simultaneously considered in research. Therefore, we propose a novel information- and team-based dual-diversity maximization (ITDM) problem in this article. The dual-diversity focused by the ITDM problem can be cast as a combination of information diversity and team diversity. The goal of ITDM problem is to obtain a good strategy for building marketing teams composed of influential social networks’ users. To some extent, this problem is an extension of classical IM problem that aims at selecting some influential users to trigger large information spread in social networks. The main difference between them is that team composition is taken into consideration by ITDM problem. Given that the ITDM problem is challenging, an algorithm on the foundation of Shapley value and negative-cycle-detection is designed to address it. We experimentally demonstrate the effectiveness of our algorithm on several real-world datasets.},
  archive      = {J_TCSS},
  author       = {Liman Du and Wenguo Yang and Suixiang Gao},
  doi          = {10.1109/TCSS.2024.3383241},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5984-5996},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Team composition for competitive information spread: Dual-diversity maximization based on information and team},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PAMT: A novel propagation-based approach via adaptive
similarity mask for node classification. <em>TCSS</em>, <em>11</em>(5),
5973–5983. (<a href="https://doi.org/10.1109/TCSS.2024.3387487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semisupervised node classification on attributed networks is a crucial task for network analysis. By decoupling two critical operations in graph convolutional networks (GCNs), namely feature transformation and neighborhood aggregation, recent works of decoupled GCNs could support the information to propagate deeper and achieve advanced performance on node classification. However, they follow the structure-aware propagation strategy of GCNs, making it hard to capture the attribute correlation of nodes and be sensitive to the structure noise described by edges whose two endpoints belong to different categories. To address these issues, we propose a new method called the propagation with adaptive mask then training (PAMT). The key idea is to integrate the attribute similarity mask into the structure-aware propagation process. In this way, PAMT could preserve the attribute correlation of adjacent nodes during the propagation and effectively reduce the influence of structure noise. Moreover, we develop an iterative refinement mechanism to update the similarity mask during the training process to improve the training performance. Extensive experiments on six real-world datasets demonstrate the superior performance and robustness of PAMT over the state-of-the-art baselines.},
  archive      = {J_TCSS},
  author       = {Jinsong Chen and Boyu Li and Qiuting He and Kun He},
  doi          = {10.1109/TCSS.2024.3387487},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5973-5983},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {PAMT: A novel propagation-based approach via adaptive similarity mask for node classification},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Honest or dishonest? Promoting integrity in loot box games
through evolutionary game theory. <em>TCSS</em>, <em>11</em>(5),
5961–5972. (<a href="https://doi.org/10.1109/TCSS.2024.3376718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of free-to-play games featuring in-game payments, the loot box sales model challenges traditional fixed-price purchases by stimulating players’ psychological desires. However, concerns have arisen among players regarding the transparency of loot box drop rates as claimed by game companies. Considering players’ “partial information” and “bounded rationality” in-game, this study explores strategic interactions and evolutionary outcomes under various decision-making scenarios through a bipartite evolutionary game model, employing the replication dynamics approach. In contrast to conventional studies that examine market manipulation post hoc, evolutionary game theory enables a proactive examination of strategies to foster fairness within the loot box game market. The findings indicate that the dynamic between companies and players may ultimately converge to either a lose–lose or win–win scenario. Through simulation analysis, the impact of stakeholders’ initial strategic ratios and critical parameters on the evolutionary trajectory is examined. It is observed that companies hold a dominant position in enhancing cooperation, whereas regulatory bodies can foster industry development through heightened regulation. This assertion is substantiated with real-world examples. The goal of this research is to advocate for integrity and transparency within the gaming industry, ensuring a fair environment for players.},
  archive      = {J_TCSS},
  author       = {Haoran Yin and Jiaxiang Sun and Wei Cai},
  doi          = {10.1109/TCSS.2024.3376718},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5961-5972},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Honest or dishonest? promoting integrity in loot box games through evolutionary game theory},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence can recognize whether a job
applicant is selling and/or lying according to facial expressions and
head movements much more correctly than human interviewers.
<em>TCSS</em>, <em>11</em>(5), 5949–5960. (<a
href="https://doi.org/10.1109/TCSS.2024.3376732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whether an interviewee’s honest and deceptive responses can be detected by the signals of facial expressions in videos has been debated and called to be researched. We developed deep learning models enabled by computer vision to extract the temporal patterns of job applicants’ facial expressions and head movements to identify self-reported honest and deceptive impression management (IM) tactics from video frames in real asynchronous video interviews. A 12- to 15-min video was recorded for each of the N = 121 job applicants as they answered five structured behavioral interview questions. Each applicant completed a survey to self-evaluate their trustworthiness on four IM measures. Additionally, a field experiment was conducted to compare the concurrent validity associated with self-reported IMs between our modeling and human interviewers. Human interviewers’ performance in predicting these IM measures from another subset of 30 videos was obtained by having N = 30 human interviewers evaluate three recordings. Our models explained 91% and 84% of the variance in honest and deceptive IMs, respectively, and showed a stronger correlation with self-reported IM scores compared to human interviewers.},
  archive      = {J_TCSS},
  author       = {Hung-Yue Suen and Kuo-En Hung and Che-Wei Liu and Yu-Sheng Su and Han-Chih Fan},
  doi          = {10.1109/TCSS.2024.3376732},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5949-5960},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Artificial intelligence can recognize whether a job applicant is selling and/or lying according to facial expressions and head movements much more correctly than human interviewers},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Word- and sentence-level representations for implicit aspect
extraction. <em>TCSS</em>, <em>11</em>(5), 5935–5948. (<a
href="https://doi.org/10.1109/TCSS.2024.3391833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect terms extraction (ATE), a key subtask for aspect-based sentiment analysis, opinion summarization, and topic modeling aims at extracting grammatical elements (nouns, phrases, and adjectives) from user reviews that reveal the discussed features of the entity under review. These aspect terms are usually the targets of the opinions expressed. Identifying them requires tackling substantial linguistic challenges but, due to the multiple commercial and social applications, significant research effort has been invested in efficiently mining aspects. Recent advances in ATE address methods that exploit a sentence or a word-level encoding of a user review as a solution. This article proposes a novel and effective word- and sentence-level encoding framework, which utilizes a neural network architecture that learns to extract aspect terms. The main advantage of our approach is that it can extract explicit and implicit aspects (i.e., aspects that are not directly mentioned in the user-generated text). We evaluate our method on four widely used datasets where we prove its efficiency against state-of-the-art alternative approaches.},
  archive      = {J_TCSS},
  author       = {Pantelis Agathangelou and Ioannis Katakis and Panagiotis Kasnesis},
  doi          = {10.1109/TCSS.2024.3391833},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5935-5948},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Word- and sentence-level representations for implicit aspect extraction},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review-level sentiment information enhanced multitask
learning approach for explainable recommendation. <em>TCSS</em>,
<em>11</em>(5), 5925–5934. (<a
href="https://doi.org/10.1109/TCSS.2024.3376728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation system plays a remarkable role in solving the problem of information overload on the Internet. Existing research demonstrates that a recommended list enclosed with appropriate explanations can enhance the transparency of the system and encourage users to make decisions. Although existing works have achieved effective results, they still suffer from at least one of the following limitations: the work either does not use sentiment information or review information, does not explicitly incorporate review-level sentiment information into the model, is based on review retrieval, and generates explanations in the form of templates or phrases. To tackle the above limitations, this article proposes a REview-level Sentiment information enhanced multiTask learning approach for Explainable Recommendation (RESTER). Specifically, it first considers the user&#39;s review information and analyzes the sentiment polarity contained in the review. Then, the user/item&#39;s identity feature, review feature, and sentiment information are fused into a multitask learning framework by leveraging the implicit correlation between the rating prediction and explanation generation tasks. Comprehensive experiments on datasets in three different domains have shown that the proposed model is superior to all other baselines in both rating prediction and explanation generation tasks.},
  archive      = {J_TCSS},
  author       = {Fenfang Xie and Yuansheng Wang and Kun Xu and Liang Chen and Zibin Zheng and Mingdong Tang},
  doi          = {10.1109/TCSS.2024.3376728},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5925-5934},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A review-level sentiment information enhanced multitask learning approach for explainable recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A headline-centric graph-based dual context matching
approach for incongruent news detection. <em>TCSS</em>, <em>11</em>(5),
5913–5924. (<a href="https://doi.org/10.1109/TCSS.2024.3384698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of incongruent news has demonstrated its significant role in propagating fake news, which catalyzes the dissemination of both misinformation and disinformation. Consequently, detecting incongruent news articles is an important research problem to counter early spreading of misinformation. In the literature, researchers have explored various bag-of-word-based features, news body-centric and news headline-centric encoding methods for incongruent news article detection. However, headline-centric and body-centric approaches in the literature fail to detect partially incongruent articles efficiently. Motivated by the above limitations, this study proposes graph-based dual context matching (GDCM), which first represents headlines and news bodies as a bigram network to capture contextual relations between words and document structure. For every word in the headline, GDCM extracts dual contexts (positive and negative) from the bigram network representing news body and estimates similarity between dual contexts and the headline for incongruent news detection. We conduct extensive experiments on three publicly available benchmark datasets and compare its performance with 16 baseline models. Our experimental results suggest that the proposed model outperforms existing state-of-the-art models and efficiently detects partially incongruent news. We further validate the performance of the proposed model through several ablation studies. The following key observations can be made from the ablation studies: 1) extracting dual bigram context of words in the headline from different segments of news body and then estimating the similarity between dual bigram contexts from news body and the headline helps in incongruent news detection and also helps in detecting partial incongruent news efficiently; and 2) representing news headlines and bodies in the form of a network based on bigram context helps to capture better nonlinear and contextual relationships between headline and body.},
  archive      = {J_TCSS},
  author       = {Sujit Kumar and Saurabh Kumar and Sanasam Ranbir Singh},
  doi          = {10.1109/TCSS.2024.3384698},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5913-5924},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A headline-centric graph-based dual context matching approach for incongruent news detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward multimodal complaint severity detection from social
media. <em>TCSS</em>, <em>11</em>(5), 5903–5912. (<a
href="https://doi.org/10.1109/TCSS.2024.3393729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of complaints submitted online and the sheer volume of information made available by social media platforms highlight the need for automated complaint analysis tools. In linguistic studies, complaints have been classified according to how much of personal risk the complainant is willing to take. This is crucial information for understanding the motivations of complainants and how people come up with reasonable means of reparation. Few attempts have been made to use the existing multimodal complaint model, which focuses on improving the textual mode with the help of images, to find specific visual features that help identify complaints. Our aim is to find a solution to this problem. In order to detect complaints and the severity level associated with them in a multitask setting, we propose Multimodal framEwork for Complaint and Severity-level detectIon (MECSI), a novel multimodal framework that uses local and global attributes (in both modalities) and relates them to the textual context. To do this, we add severity-level annotation to the newly released CESAMARD dataset, which is a compilation of reviews and images of products listed on the Amazon website. The experimental findings confirmed the superiority of our proposed model over the state-of-the-art model and other strong rival baselines, proving the efficacy of our proposed framework.},
  archive      = {J_TCSS},
  author       = {Apoorva Singh and Prince Jha and Souryadip Das and Raghav Jain and Sriparna Saha},
  doi          = {10.1109/TCSS.2024.3393729},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5903-5912},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Toward multimodal complaint severity detection from social media},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Atmosphere kamaal ka tha (was wonderful): A multilingual
joint learning framework for aspect category detection and sentiment
classification. <em>TCSS</em>, <em>11</em>(5), 5892–5902. (<a
href="https://doi.org/10.1109/TCSS.2024.3374450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code-mixing refers to switching between two or more languages within the same utterance, which is very prevalent in multilingual societies. The amount of code-mixed content has increased due to the spike in multilingual users on review platforms. Analyzing these reviews can be beneficial for both consumers and service providers. Aspect category (AC) sentiment analysis (ACSA) provides a fine-grained analysis of reviews. ACSA identifies the AC and measures the sentiment expressed toward a given AC. The research in this direction has mostly focused on monolingual languages, which are insufficient for analyzing code-mixed reviews. To expedite research in this direction, we propose new tasks in the code-mixed language (ACSA-Mix). We develop a benchmark setup to create a code-mixed Hinglish (i.e., mixing of Hindi and English) dataset for ACSA-Mix, annotated with AC and sentiment values. To demonstrate the practical usage of the dataset, we solve ACSA-Mix tasks in the Seq2Seq framework, where natural language sentences are generated to represent the outputs that allow pretrained language models to be used effectively. Further, a multilingual multitask joint learning framework is proposed that transfers knowledge between Hinglish (ACSA-Mix) and English (ACSA) tasks. We consider ACSA-Mix tasks the primary tasks and enhance their performance by ACSA tasks (auxiliary) by sharing knowledge between them. We observe improvement over the single task ACSA-Mix models. 1 1The dataset has been made available on https://www.iitp.ac.in/ ai-nlp-ml/resources.html and at Github repository: https://github.com/20118/ACSA-Mix},
  archive      = {J_TCSS},
  author       = {Mamta and Asif Ekbal},
  doi          = {10.1109/TCSS.2024.3374450},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5892-5902},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Atmosphere kamaal ka tha (Was wonderful): A multilingual joint learning framework for aspect category detection and sentiment classification},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revocable certificateless cross-domain authentication scheme
based on primary–secondary blockchain. <em>TCSS</em>, <em>11</em>(5),
5880–5891. (<a href="https://doi.org/10.1109/TCSS.2024.3378719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain interaction in social networks and mobile applications is rapidly expanding. The demand for accessing data across multiple domains from different applications is growing. Establishing robust authorization and access control mechanisms within trusted domains has become a critical foundation for data security. Despite advancements in the field of identity authentication and cross-domain access, challenges persist in various application domain transition scenarios, including cumbersome and inefficient processes, and the potential for authority misuse by malicious actors in decentralized environments. To mitigate these limitations, we propose a blockchain-based scheme that leverages consensus mechanisms to enable “one-time authentication, multidomain authorization.” This scheme enhances security attributes and performance in several key aspects. First, we developed a primary–secondary chain model compatible with multiple trusted domains, where the primary chain records user authentication and authorization information, and the secondary chain logs domain-specific user identity registration information. Nodes within the primary and secondary chains reach a rapid consensus on authentication outcomes through an improved consensus algorithm. Building on this model, we devised a certificateless cross-domain identity authentication method, rendering the authentication and authorization processes more secure and efficient. Additionally, to address the issue of centralized user authority, an optimized chameleon hash function was designed to facilitate identity revocation within a multicentric environment. Furthermore, security analyses and simulation validations were conducted to assess the performance of the proposed scheme. Compared to existing approaches, our scheme demonstrates reduced computational and communication overhead, substantiating its efficacy in streamlining cross-domain interactions.},
  archive      = {J_TCSS},
  author       = {Ze Wang and Zhenglin Zong and Fang Li and Shimin Sun and Ping Zhao},
  doi          = {10.1109/TCSS.2024.3378719},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5880-5891},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Revocable certificateless cross-domain authentication scheme based on Primary–Secondary blockchain},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Users volatility on reddit and voat. <em>TCSS</em>,
<em>11</em>(5), 5871–5879. (<a
href="https://doi.org/10.1109/TCSS.2024.3379318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media platforms behave like giant arenas where users can rely on different content and express their opinions through likes, comments, and shares. However, do users welcome different perspectives or only listen to their preferred narratives? This article examines how users explore the digital space and allocate their attention among communities on two social networks, Voat and Reddit. By analyzing a massive dataset of about 215 million comments posted by about 16 million users on Voat and Reddit in 2019, we find that most users tend to explore new communities at a decreasing rate, meaning they have a limited set of preferred groups they visit regularly. Moreover, we provide evidence that preferred communities of users tend to cover similar topics throughout the year. We also find that communities have a high turnover of users, meaning that users come and go frequently showing a high volatility that strongly departs from a null model simulating users’ behavior.},
  archive      = {J_TCSS},
  author       = {Niccolò Di Marco and Matteo Cinelli and Shayan Alipour and Walter Quattrociocchi},
  doi          = {10.1109/TCSS.2024.3379318},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5871-5879},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Users volatility on reddit and voat},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Node injection attack based on label propagation against
graph neural network. <em>TCSS</em>, <em>11</em>(5), 5858–5870. (<a
href="https://doi.org/10.1109/TCSS.2024.3395794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network (GNN) has achieved remarkable success in various graph learning tasks, such as node classification, link prediction, and graph classification. The key to the success of GNN lies in its effective structure information representation through neighboring aggregation. However, the attacker can easily perturb the aggregation process through injecting fake nodes, which reveals that GNN is vulnerable to the graph injection attack (GIA). Existing GIA methods primarily focus on damaging the classical feature aggregation process while overlooking the neighborhood aggregation process via label propagation. To bridge this gap, we propose the label-propagation-based global injection attack (LPGIA) which conducts the GIA on the node classification task. Specifically, we analyze the aggregation process from the perspective of label propagation and transform the GIA problem into a global injection label specificity attack problem. To solve this problem, LPGIA utilizes a label-propagation-based strategy to optimize the combinations of the nodes connected to the injected node. Then, LPGIA leverages the feature mapping to generate malicious features for injected nodes. In extensive experiments against representative GNNs, LPGIA outperforms the previous best-performing injection attack method in various datasets, demonstrating its superiority and transferability.},
  archive      = {J_TCSS},
  author       = {Peican Zhu and Zechen Pan and Keke Tang and Xiaodong Cui and Jinhuan Wang and Qi Xuan},
  doi          = {10.1109/TCSS.2024.3395794},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5858-5870},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Node injection attack based on label propagation against graph neural network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cryptocurrency in the aftermath: Unveiling the impact of the
SVB collapse. <em>TCSS</em>, <em>11</em>(5), 5839–5857. (<a
href="https://doi.org/10.1109/TCSS.2024.3388495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we explore the aftermath of the Silicon Valley Bank (SVB) collapse, with a particular focus on its impact on crypto markets. We conduct a multidimensional investigation, which includes a factual summary, analysis of user sentiment, and examination of market performance. We uncover a somewhat counterintuitive finding: the SVB collapse did not lead to the destruction of cryptocurrencies; instead, they displayed resilience.},
  archive      = {J_TCSS},
  author       = {Qin Wang and Guangsheng Yu and Shiping Chen},
  doi          = {10.1109/TCSS.2024.3388495},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5839-5857},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Cryptocurrency in the aftermath: Unveiling the impact of the SVB collapse},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Coordinated rescheduling of train timetable and crew scheme
for passenger-freight collinear railway. <em>TCSS</em>, <em>11</em>(5),
5828–5838. (<a href="https://doi.org/10.1109/TCSS.2024.3379214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On a passenger-freight collinear railway, the freight train operation level is comparatively low, frequently resulting in significant deviations from the original timetable and crew plan in the presence of various interferences. This article focuses on the problem of coordinated rescheduling of train timetable and crew scheme in the presence of disruptions on a double-track passenger-freight collinear railway. We develop a mixed-integer linear program (MILP) model considering the distinct priorities of passenger and freight trains, as well as crew operations, thereby surpassing the current practice of independently adjusting train timetable and crew plan to achieve a collaborative solution. The objective is to minimize delays for passenger trains and deviations in crew schedule, while maximizing the delivery rate of freight trains at railway Bureau boundary stations prior to the settlement time. Furthermore, for large-scale delays, we design a solution algorithm based on the rolling horizon approach to enhance computational efficiency. To validate the effectiveness of the proposed model, simulation experiments are conducted using actual running data from the Beijing–Shanghai railway. The experimental results illustrate that our coordinated model enhances the feasibility of adjustment outcomes during emergencies, in contrast to the model that neglects crew connections. Additionally, our proposed algorithm guarantees a solving error of under 5% and reduces solving time by over 60% compared with the results obtained by CPLEX. Moreover, three additional comparison experiments are conducted to further demonstrate the impact of crew activities on train operation adjustments, which also indicate that our approach can provide dispatchers with more feasible train operation adjustment schemes in terms of crew utilization.},
  archive      = {J_TCSS},
  author       = {Rui Wang and Min Zhou and Hongwei Wang and Bo Yang and Hairong Dong and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3379214},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5828-5838},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Coordinated rescheduling of train timetable and crew scheme for passenger-freight collinear railway},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A malicious information traceability model based on
neighborhood similarity and multiple types of interaction.
<em>TCSS</em>, <em>11</em>(5), 5815–5827. (<a
href="https://doi.org/10.1109/TCSS.2024.3385025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The open and free nature of online platforms presents challenges for tracing malicious information. To address this, we propose a traceability model based on neighborhood similarity and multitype interaction. First, we propose neighborhood similarity algorithms (D-NTC) to address the universality of malicious information dissemination. This algorithm evaluates the impact of user node importance on malicious information propagation by combining node degrees and the topological overlap of neighboring nodes. Second, we consider the interactive nature of multiple types of elements in the network and construct an interactive module based on user-path-malicious information. This module effectively captures the mutual influence relationships among diverse elements. Additionally, we employ representation learning to optimize the transition probability matrix between elements, leveraging hidden relationships to further characterize their interactive impact. Finally, we propose the NSMTI-Rank algorithm, which tackles the complexity of quantifying the influence of multiple types of elements. Drawing inspiration from mutual reinforcement effects, NSMTI-Rank comprehensively quantifies element influence through an iterative framework. Experimental results demonstrate the effectiveness of our approach in mining user node importance and capturing the interaction information among diverse elements in the network. Moreover, it enables the timely and effective identification of sources of malicious information dissemination.},
  archive      = {J_TCSS},
  author       = {Tun Li and Zhou Li and Kexin Ma and Qian Li and Rong Wang and Chaolong Jia and Yunpeng Xiao},
  doi          = {10.1109/TCSS.2024.3385025},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5815-5827},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A malicious information traceability model based on neighborhood similarity and multiple types of interaction},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding successful startups by using information flows among
investors in higher order network of investments. <em>TCSS</em>,
<em>11</em>(5), 5803–5814. (<a
href="https://doi.org/10.1109/TCSS.2024.3394439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding potential successful startups is always a key issue for industrial innovation and economic development, yet it poses a significant challenge due to the complexity of investments and low success rates. Compared with existing models on knowledge correlations among pairwise startups in a first-order perspective, potential dependencies among sequential investment behaviors reveal knowledge correlations among multiple startups, which requires modeling from a higher order perspective. In this article, a novel higher order network (HON) framework, generated by dependencies among investment behaviors with timestamps, is proposed to identify the pattern of knowledge flows among startups, which has been approved higher accuracy in predicting investment behaviors. Moreover, we introduce a HON-based centrality indicator to measure the importance of startups. Experiments compared with baseline models have shown that the startups identified by proposed indicator are more influential in knowledge propagation and are closer to success. An empirical study conducted by Crunchbase database further reveals that internet-based startups occupy a significant position in investment landscapes, with those associated with finance and commerce not only attracting considerable investments but also facilitating greater success for related startups.},
  archive      = {J_TCSS},
  author       = {Wei Guan and Qing Guan and Yueran Duan and Changhong Xiang},
  doi          = {10.1109/TCSS.2024.3394439},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5803-5814},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Finding successful startups by using information flows among investors in higher order network of investments},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Community enhanced knowledge graph for recommendation.
<em>TCSS</em>, <em>11</em>(5), 5789–5802. (<a
href="https://doi.org/10.1109/TCSS.2024.3383603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the capability of encoding auxiliary information for alleviating the data sparsity issue, knowledge graph (KG) has gained an increasing amount of attention in recent years. With auxiliary knowledge about items, the KG-based recommender systems have achieved better performance compared with the existing methods. However, the effectiveness of the KG-based methods highly depends on the quality of the KG. Unfortunately, KGs are usually with the problem of incompleteness and sparseness. Besides, the existing KG-based methods could not discriminate the importance of different factors that users consider when making decisions, which may degrade the interpretability of the methods. In this article, we propose a recommendation model named community enhanced knowledge graph for recommendation (CEKGR). By adding entities and relations, the KG is enriched with more semantic information, which would help mine users’ preference for better recommendation. With weights of each path, the interpretability of the recommendation can be improved. To validate the effectiveness of the proposed method, we conduct experiments on three public datasets. Experiment results have shown the improvement compared with other state-of-the-art methods. Besides, case study has illustrated the interpretability of the proposed recommendation model.},
  archive      = {J_TCSS},
  author       = {Zhen-Yu He and Chang-Dong Wang and Jinfeng Wang and Jian-Huang Lai and Yong Tang},
  doi          = {10.1109/TCSS.2024.3383603},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5789-5802},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Community enhanced knowledge graph for recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient core-selecting incentive mechanism for data
sharing in federated learning. <em>TCSS</em>, <em>11</em>(5), 5775–5788.
(<a href="https://doi.org/10.1109/TCSS.2024.3381041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a distributed machine learning system that uses participants’ data to train an improved global model. In federated learning, participants collaboratively train a global model, and after the training is completed, each participant receives that global model along with an incentive. Rational participants try to maximize their individual utility, and they will not input their high-quality data truthfully unless they are provided with satisfactory payments based on their contributions. Furthermore, federated learning benefits from the cooperation of participants. Accordingly, how to establish an incentive mechanism that both incentivizes inputting data truthfully and promotes cooperative contributions has become an important issue to consider. In this article, we introduce a data sharing game model for federated learning and employ game-theoretic approaches to design a core-selecting incentive mechanism by utilizing a popular concept in cooperative games, the core. In federated learning, the core can be empty, resulting in the core-selecting mechanism becoming infeasible. To address this issue, our core-selecting mechanism employs a relaxation method and simultaneously minimizes the benefits of inputting false data for all participants. Meanwhile, to reduce the computational complexity of the core-selecting mechanism, we propose an efficient core-selecting mechanism based on sampling approximation that only aggregates models on sampled coalitions to approximate the exact result. Extensive experiments demonstrate that the efficient core-selecting mechanism can incentivize truthful input of high-quality data and promote cooperation effectively, while it reduces computational overhead compared to the core-selecting mechanism.},
  archive      = {J_TCSS},
  author       = {Mengda Ji and Genjiu Xu and Jianjun Ge and Mingqiang Li},
  doi          = {10.1109/TCSS.2024.3381041},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5775-5788},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Efficient core-selecting incentive mechanism for data sharing in federated learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive dual-space network with multigraph fusion for
EEG-based emotion recognition. <em>TCSS</em>, <em>11</em>(5), 5763–5774.
(<a href="https://doi.org/10.1109/TCSS.2024.3386621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the work on electroencephalogram (EEG)-based emotion recognition aims to extract the distinguishing features from high-dimensional EEG signals, ignoring the complementarity of information between EEG latent space and graph space. Furthermore, the influence of brain connectivity on emotions encompasses both physical structure and functional connectivity, which may have varying degrees of importance for different individuals. To address these issues, this article introduces an adaptive dual-space network (ADS-Net) with multigraph fusion aimed at capturing more comprehensive information by integrating dual-space representations. Specifically, ADS-Net models the spatial correlation of EEG channels in graph topological space, while exploring long-range dependencies and frequency relationships from EEG data in latent space. Subsequently, these representations are adaptively combined through an innovative gated fusion approach to extract complementary corepresentations. Moreover, drawing on the principles of brain connectivity theory, the proposed method constructs a multigraph to indicate the associativity of EEG channels. To further capture individual differences, an adaptive multigraph fusion mechanism is developed for the dynamic integration of physical and functional connectivity graphs. When compared to state-of-the-art methods, the superior experimental results underscore the effectiveness and broad applicability of the proposed method.},
  archive      = {J_TCSS},
  author       = {Mengqing Ye and C. L. Philip Chen and Wenming Zheng and Tong Zhang},
  doi          = {10.1109/TCSS.2024.3386621},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5763-5774},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Adaptive dual-space network with multigraph fusion for EEG-based emotion recognition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary dynamics of preguidance strategies in
population games. <em>TCSS</em>, <em>11</em>(5), 5751–5762. (<a
href="https://doi.org/10.1109/TCSS.2024.3386501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Promoting cooperation among conflicting entities in human society and intelligent systems is a formidable task. One potential solution could involve the formulation of incentives designed to decrease the benefits of noncooperators and/or increase the rewards for cooperators. We put forth a novel incentive approach, specifically, a guidance strategy where certain cooperators willingly bear a cost to alter the actions of agents who intend to defect prior to the actual commencement of a game. We introduce an innovative game-theoretical framework that sheds light on the dynamics of guidance strategies, encompassing both peer guidance and pool guidance. Under the peer guidance scheme, each guider independently incurs the cost to influence agents intending to defect, whereas in the pool guidance scheme, guiders organically establish an institution to influence agents prone to free riding. Regardless of whether a peer or pool guidance scheme is utilized, the implementation of a guidance strategy has proven to be remarkably effective in reducing the instances of pure cooperation, also known as second-order free riding. Intriguingly, our result suggests that the pool guidance strategy demonstrates a more potent deterrent effect on second-order free-riding behavior than the peer guidance strategy, particularly when the cost of guidance is exceptionally high. These findings underscore the significance of preguidance in fostering cooperation in human and multiagent AI systems and could offer valuable insights for the development of a regulatory mechanism for preemptive guidance and subsequent punishment.},
  archive      = {J_TCSS},
  author       = {Linjie Liu and Xiaojie Chen},
  doi          = {10.1109/TCSS.2024.3386501},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5751-5762},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Evolutionary dynamics of preguidance strategies in population games},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid quantum-classical neural network for multimodal
multitask sarcasm, emotion, and sentiment analysis. <em>TCSS</em>,
<em>11</em>(5), 5740–5750. (<a
href="https://doi.org/10.1109/TCSS.2024.3388016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm detection in unimodal or multimodal setting is a very complex task. Sarcasm, emotion, and sentiment are related to each other, and hence any multitask model could be an effective way to leverage the interdependence among these tasks. In order to better represent these clandestine associations, we avoid solely relying on traditional machine learning methods to encode the relationships between the modalities. In this article, we propose a hybrid quantum model that banks upon the low computational complexity and robust representational power of a variational quantum circuit (VQC) and the tried and tested dense neural network to tackle sentiment, emotion, and sarcasm classification simultaneously. We empirically establish that the quantum properties like superposition, entanglement, and interference will better capture and replicate not only the cross-modal interactions between text, acoustics, and visuals but also the correlations between the three responses. We consider the extended MUStARD dataset to evaluate our proposed hybrid model. The results show that our proposed hybrid quantum framework yields more promising results for the primary task of sarcasm detection with the help of the two secondary classification tasks, viz. sentiment and emotion.},
  archive      = {J_TCSS},
  author       = {Arpan Phukan and Santanu Pal and Asif Ekbal},
  doi          = {10.1109/TCSS.2024.3388016},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5740-5750},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Hybrid quantum-classical neural network for multimodal multitask sarcasm, emotion, and sentiment analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Automatic diagnosis of depression based on facial
expression information and deep convolutional neural network.
<em>TCSS</em>, <em>11</em>(5), 5728–5739. (<a
href="https://doi.org/10.1109/TCSS.2024.3393247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is a complex mental disease, which involves many factors such as psychology, physiology, and society, and which causes harm to society. Up to now, there are no valuable biomarkers for clinical diagnosis. This research constructed a dataset, which includes calm, sad, and happy facial expressions from both patients with depression and normal people, and classification and visualization of depression. The network includes a dual-scale convolution module, adaptive channel attentional mechanism, and gradient class activation mapping technique. In which, dual-scale convolution captures features of the facial region at different scales and the adaptive channel attention captures the facial region with the most significant features. The results show that we improve the performance of depression classification based on facial information, and recruit gradient class activation mapping technique obtaining a specific visual face pattern of depression that is different from that of normal people, which provides a potential interpretable and discriminant evidence for the clinical diagnosis. Thereby, promoting the development and application of artificial intelligence in the field of psychiatry.},
  archive      = {J_TCSS},
  author       = {Mi Li and Yuqi Wang and Chuang Yang and Zeying Lu and Jianhui Chen},
  doi          = {10.1109/TCSS.2024.3393247},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5728-5739},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Automatic diagnosis of depression based on facial expression information and deep convolutional neural network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HateThaiSent: Sentiment-aided hate speech detection in thai
language. <em>TCSS</em>, <em>11</em>(5), 5714–5727. (<a
href="https://doi.org/10.1109/TCSS.2024.3376958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media platforms are a double-edged sword: on the one hand, they enable the dissemination of information; but on the other hand, they also provide an avenue for spreading online abuse and harassment, such as hate speech. While significant research efforts are being devoted to detecting online hate speech in the English language, little attention has been paid to the Thai language. In this study, we created a benchmark dataset, called HateThaiSent , which labels each post with both hate speech and sentiment information. To detect hate speech, we created a multitask model that uses a dual-channel deep learning approach based on FastText and BERT embeddings, with an added capsule network. One channel utilizes pretrained FastText embeddings while the other uses embeddings from the BERT language model. We aimed to answer two research questions: (Q1) Does incorporating sentiment information improves the performance of hate speech detection (HD) in the Thai language? (Q2) What is the comparative effectiveness of two different approaches for sentiment-aware HD in the Thai language: feature engineering versus multitasking? Our proposed approach outperformed other baselines and state-of-the-art models on the HateThaiSent dataset, with overall accuracy/macro- $F_{1}$ values of 89.67%/89.79%, and 80.92%/80.97% for hate speech and sentiment detection tasks, respectively. We concluded that multitasking is more effective than feature engineering in enhancing the performance of the main task (HD).},
  archive      = {J_TCSS},
  author       = {Krishanu Maity and A. S. Poornash and Shaubhik Bhattacharya and Salisa Phosit and Sawarod Kongsamlit and Sriparna Saha and Kitsuchart Pasupa},
  doi          = {10.1109/TCSS.2024.3376958},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5714-5727},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {HateThaiSent: Sentiment-aided hate speech detection in thai language},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Simulating news recommendation ecosystems for insights and
implications. <em>TCSS</em>, <em>11</em>(5), 5699–5713. (<a
href="https://doi.org/10.1109/TCSS.2024.3381329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studying the evolution of online news communities is essential for improving the effectiveness of news recommender systems. Traditionally, this has been done through empirical research based on static data analysis. While this approach has yielded valuable insights for optimizing recommender system designs, it is limited by the lack of appropriate datasets and open platforms for controlled social experiments. This gap in the existing literature hinders a comprehensive understanding of the impact of recommender systems on the evolutionary process and its underlying mechanisms. As a result, suboptimal system designs may be developed that could negatively affect long-term utilities. In this work, we propose SimuLine, a simulation platform to dissect the evolution of news recommendation ecosystems and present a detailed analysis of the evolutionary process and underlying mechanisms. SimuLine first constructs a latent space well reflecting the human behaviors and then simulates the news recommendation ecosystem via agent-based modeling. Based on extensive simulation experiments and the comprehensive analysis framework consisting of quantitative metrics, visualization, and textual explanations, we analyze the characteristics of each evolutionary phase from the perspective of life-cycle theory and propose a relationship graph illustrating the key factors and affecting mechanisms. Furthermore, we explore the impacts of recommender system designing strategies, including the utilization of cold-start news, breaking news, and promotion, on the evolutionary process, which sheds new light on the design of recommender systems.},
  archive      = {J_TCSS},
  author       = {Guangping Zhang and Dongsheng Li and Hansu Gu and Tun Lu and Li Shang and Ning Gu},
  doi          = {10.1109/TCSS.2024.3381329},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5699-5713},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Simulating news recommendation ecosystems for insights and implications},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Impact of indoor mobility behavior on the respiratory
infectious diseases transmission trends. <em>TCSS</em>, <em>11</em>(5),
5685–5698. (<a href="https://doi.org/10.1109/TCSS.2024.3379147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor human mobility plays a crucial role in the transmission of respiratory infectious diseases. Previous studies have predominantly addressed a single type or a series of behaviors in specific scenarios, neglecting the abstraction of mobility behavior in various scenes and how these abstracted behaviors impact disease propagation. To address these problems, this study abstracts mobility behaviors in a general scenario into two main categories: crowding behavior from the spatial aspect (i.e., a group of people gathering closely), and stopping behavior from the temporal aspect (i.e., someone remaining in one position without any change over time). Then, their impacts on disease spreading and the impact of individual spatiotemporal distribution resulting from these behaviors on epidemic transmission are investigated. First, behavioral factors and transmission trend indicators are defined, and the exposure risk with virion-laden particles (ERP) model is used as the fundamental for simulation. Second, 200 indoor scenarios are constructed and simulated to help determine variable values. Concurrently, the influences of target factors on disease transmission are determined using structural equation modeling and causal inference modeling. Final, guidelines are formulated to mitigate epidemic spread in indoor scenarios: prioritizing “increasing the number of point of interests (POIs) for a fixed number of people” compared to “making the distribution of POIs more dispersed” and “limiting the number of stoppings,” and ultimately using “shortening the duration of stopping” strategy; “directing the distribution of individuals more uniform” by implementing the aforementioned strategies or be conducted independently.},
  archive      = {J_TCSS},
  author       = {Ziwei Cui and Ming Cai and Zheng Zhu and Gongbo Chen and Yao Xiao},
  doi          = {10.1109/TCSS.2024.3379147},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5685-5698},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Impact of indoor mobility behavior on the respiratory infectious diseases transmission trends},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved fruit fly optimization algorithm for disassembly
lines requiring multiskilled workers. <em>TCSS</em>, <em>11</em>(5),
5671–5684. (<a href="https://doi.org/10.1109/TCSS.2024.3382593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Waste recycling is an important part of resource reuse and environmental protection. The study of disassembly lines deals with the process of recycling and remanufacturing end-of-life products. The performance of a disassembly line is affected by many factors, especially the operation cost of workstations, the precedence relationships among disassembly tasks, the skill level of workers, and their learning speed. This study considers the learning effect of disassembly workers, establish a mixed integer programming model of the disassembly balancing problem, and explores the search for optimal solution. It allocates tasks and multiskilled workers on workstations to maximize disassembly profits in the disassembly process. To solve it, an improved fruit fly optimization algorithm is proposed, and three methods are designed for the smell search. At the same time, the visual search is also designed to avoid the problem of falling into local optimum. The validity and effectiveness of the proposed algorithm are verified with experiments that compare the results with CPLEX, a well-known IBM optimizer, and some popular peer algorithms.},
  archive      = {J_TCSS},
  author       = {Shujin Qin and JianPing Wang and Jiacun Wang and Shixin Liu and XiWang Guo and Liang Qi and Ziyan Zhao},
  doi          = {10.1109/TCSS.2024.3382593},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5671-5684},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An improved fruit fly optimization algorithm for disassembly lines requiring multiskilled workers},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel temporal privacy-preserving model for social
recommendation. <em>TCSS</em>, <em>11</em>(5), 5658–5670. (<a
href="https://doi.org/10.1109/TCSS.2024.3378349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommendation improved the quality and efficiency of recommendation but increased the risk of privacy leakage, especially with the introduction of social networks. Consequently, the social recommendation considering user privacy has drawn tremendous attention from academia to industry. Nevertheless, most of the existing work regards the recommender systems as static, ignoring the diffusion of social influence over time. In this article, we propose a secure and efficient framework, temporal privacy-preserving social recommendation model (PrivTSR), to capture the changes of user preference for items and item types with time. PrivTSR first utilizes differential privacy to encrypt the data owned by the data owner. Then, inspired by the long short-term memory (LSTM), at each time step the initial user embedding and the initial item embedding are generated via DeepWalk as new ratings of users for items emerges in the user–item-type graph. The initial user-preference embedding is generated randomly at the first time step, and it is equivalent to the updated embedding of the previous time step for the later time steps. Most importantly, on the social graph, PrivTSR updates the user embedding and the user-preference embedding with graph attention convolutional network and graph attention diffused network, which aggregates (diffuses) social influence from (to) neighbors in depth and breadth. On the user–item-type graph, the user embedding and the item embedding are updated by aggregating the embedding of users and items in the six paths. Final, taking into account the users’ preference for items and item types, PrivTSR predicts the ratings of users to the items for the next time step. The extensive experiments are conducted on two real-world datasets, which demonstrated the superiority of our model over several competitive baselines.},
  archive      = {J_TCSS},
  author       = {Lina Gao and Jiguo Yu and Jianli Zhao and Chunqiang Hu},
  doi          = {10.1109/TCSS.2024.3378349},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5658-5670},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A novel temporal privacy-preserving model for social recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complications associated with implantable spinal cord
stimulator: A study of FDA databases from regulatory perspective.
<em>TCSS</em>, <em>11</em>(5), 5647–5657. (<a
href="https://doi.org/10.1109/TCSS.2024.3374642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adverse event (AE) is any unexpected outcome associated with the use of a medical product in a patient. The tracking and recording of AE are important for reevaluation of safety and effectiveness of medical devices. The response to AE may include recall, which attempts to address the reported problem by repairing, re-labeling, etc. Spinal cord stimulator system (SCS) is an implantable device that sends low levels of electricity directly into the spinal cord to relieve pain, its indications include back pain, postsurgical pain, injuries to spinal cord, etc. As a type of active implantable device, SCS represent relatively high rate of AE. In this article, we analyzed 15 694 AE reports of SCS extracted from the Manufacturer and User Facility Device Experience (MAUDE) database of the United States Food and Drug Administration (FDA) between 1 January 2023 and 30 June 2023. In addition, we analyzed 65 recall reports of SCS extracted from the Recalls of Medical Devices database of FDA from 2005 to 2023 as supplement. The text data in AE dataset has been preprocessed using the natural language toolkit (NLTK), a natural language tool kit in Python. To predict the severity of AE, four classifiers as well as four vectorization methods were applied. The experiment achieved the highest accuracy of 90.6% with eXtreme Gradient Boosting Classifier (XGBC) and unigram. This study proposed an automatic approach of labeling the severity of AE data and conclude that SCS AE often occur when recharging the battery of SCS and when transmitting data via wireless communication route.},
  archive      = {J_TCSS},
  author       = {Xinyan Zhang and Yaohua Li},
  doi          = {10.1109/TCSS.2024.3374642},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5647-5657},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Complications associated with implantable spinal cord stimulator: A study of FDA databases from regulatory perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced implicit sentiment understanding with prototype
learning and demonstration for aspect-based sentiment analysis.
<em>TCSS</em>, <em>11</em>(5), 5631–5646. (<a
href="https://doi.org/10.1109/TCSS.2024.3368171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of social computing, the task of aspect-based sentiment analysis (ABSA) aims to classify the sentiment polarity of a given aspect in a sentence. The absence of explicit opinion words in the implicit aspect sentiment expressions poses a greater challenge for capturing their sentiment features in the reviews from social media. Many recent efforts use dependency trees or attention mechanisms to model the association between the aspect and other contextual words. However, dependency tree-based methods are inefficient in constructing valuable associations for sentiment classification due to the lack of explicit opinion words. In addition, the use of attention mechanisms to obtain global semantic information easily leads to an undesired focus on irrelevant words that may have sentiments but are not directly related to the specific aspect. In this article, we propose a novel prototype-based demonstration (PD) model for the ABSA task, which contains prototype learning and PD stages. In the prototype learning stage, we employ mask-aware attention to capture the global sentiment feature of aspect and learn sentiment prototypes through contrastive learning. This allows us to acquire comprehensive central semantics of the sentiment polarity that contains the implicit sentiment features. In the PD stage, to provide explicit guidance for the latent knowledge within the T5 model, we utilize prototypes similar to the aspect sentiment as the neural demonstration. Our model outperforms others with a 1.68%/0.28% accuracy gain on the Laptop/Restaurant datasets, especially in the ISE slice, showing improvements of 1.17%/0.26%. These results confirm the superiority of our PD-ABSA in capturing implicit sentiment and improving classification performance. This provides a solution for implicit sentiment classification in social computing.},
  archive      = {J_TCSS},
  author       = {Huizhe Su and Xinzhi Wang and Jinpeng Li and Shaorong Xie and Xiangfeng Luo},
  doi          = {10.1109/TCSS.2024.3368171},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5631-5646},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Enhanced implicit sentiment understanding with prototype learning and demonstration for aspect-based sentiment analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multipattern integrated networks with contrastive
pretraining for graph anomaly detection. <em>TCSS</em>, <em>11</em>(5),
5619–5630. (<a href="https://doi.org/10.1109/TCSS.2024.3362393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a challenge of practical significance, fraud detection has great potential for telecom fraud prevention, economic crime prevention, and personal property preservation. Fraudulent activities are always buried in massive regular transactions, making it hard to find them. Traditional rule-based approaches need multiple domain-specific rules and multistep verification, which limits their transferability and efficiency. Machine learning-based methods might ignore the intricate interactions or the temporal relations among accounts. Meanwhile, the lack of sufficient manual labels restricts their performance. To overcome the above limitations, we present a multipattern integrated network (MPIN) in this article to identify fraudulent accounts in transaction networks. Specifically, MPIN considers the interactions among nodes from three perspectives: inflows, outflows, and their mutual influences. To learn the behavior pattern of each node, MPIN first applies an attention mechanism to integrate the short-term information and then learns the long-term patterns by aggregating multiple short-term patterns. Behavior patterns from different perspectives together with long short-term modeling enable the model to precisely distinguish fraudulent accounts from the normal ones. Moreover, contrastive pretraining with temporal consistency and local tightness guarantee is adopted to alleviate the label sparsity issue and provide the model with low-variance performance. We conducted experiments on two real-world transaction networks, and the results showed the effectiveness of MPIN compared with five state-of-the-art baselines.},
  archive      = {J_TCSS},
  author       = {Manzhi Yang and Jian Zhang and Liyuan Lin and Jinpeng Han and Xiaoguang Chen and Zhen Wang and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3362393},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5619-5630},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Multipattern integrated networks with contrastive pretraining for graph anomaly detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel method for bitcoin price manipulation identification
based on graph representation learning. <em>TCSS</em>, <em>11</em>(5),
5607–5618. (<a href="https://doi.org/10.1109/TCSS.2024.3368690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bitcoin is a cryptocurrency designed based on the concept of “decentralization,” and its price fluctuation is much larger than those of traditional financial assets, which has raised concerns about intentioned Bitcoin price manipulation. Most of the existing research on Bitcoin price manipulation is limited to the analysis of manipulation behaviors, lacking effective identification methods and performance metrics of identification methods. In this article, we use MtGox real trading data to build a trading network and analyze the diverse price manipulation patterns in the trading network. Based on this, we improve the classical graph representation learning method to effectively identify the price manipulation accounts. Specifically, considering that Bitcoin has special financial investment properties, and its price condenses important information from the financial market, we propose a novel identification algorithm, called Finan2vec, by feeding the time-series information of the price into the transfer strategy of the Node2vec algorithm. This algorithm makes it easier to detect nodes with large trades or significant price-raising behavior. We then use two classification algorithms to complete the identification of abnormal nodes and finally draw on the knowledge of financial market experts to construct a hit rate indicator to measure the effectiveness of the proposed method. The experimental results show that our method can effectively identify price manipulation accounts for Bitcoin and other public blockchain systems.},
  archive      = {J_TCSS},
  author       = {Yanmei Zhang and Ziyu Li and Yuwen Su and Jianjun Li and Shiping Chen},
  doi          = {10.1109/TCSS.2024.3368690},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5607-5618},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A novel method for bitcoin price manipulation identification based on graph representation learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SINCERE: A hybrid framework with graph-based compact textual
models using emotion classification and sentiment analysis for twitter
sarcasm detection. <em>TCSS</em>, <em>11</em>(5), 5593–5606. (<a
href="https://doi.org/10.1109/TCSS.2023.3315754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm is an expression of contempt expressed through verbal irony. It is a nuanced form of language that individuals use to imply the opposite of what they are actually saying, and thus it can be difficult to detect at times. The lack of large, annotated datasets is one of the major challenges and limitations of building systems to detect sarcasm automatically. To address this issue, we propose a hybrid graph-based framework, namely, SINCERE, to build compact sarcasm detection models with sentiment and emotion analysis by leveraging only a small amount of prior data. To automatically extract patterns from a small dataset collected by distant supervision, a graph is first constructed. This approach is used to discover latent representations of vertices in a network, as the basis for a language model. We demonstrate that simple classifiers built from the model can detect sarcasm and generalize better than the state-of-the-art approach. According to the experimental results, the proposed SINCERE framework is able to outperform the SOTA baselines on accuracy by 5%.},
  archive      = {J_TCSS},
  author       = {Axel Rodríguez and Yi-Ling Chen and Carlos Argueta},
  doi          = {10.1109/TCSS.2023.3315754},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5593-5606},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {SINCERE: A hybrid framework with graph-based compact textual models using emotion classification and sentiment analysis for twitter sarcasm detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Twofold structured features-based siamese network for
infrared target tracking. <em>TCSS</em>, <em>11</em>(5), 5577–5592. (<a
href="https://doi.org/10.1109/TCSS.2024.3391631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, infrared target tracking has been a critical technology in the field of computer vision and has many computational social system-related applications, such as urban security, pedestrian counting, smoke and fire detection, and so forth. Unfortunately, due to the absence of detailed information such as texture or color, it is easy for tracking drift to occur when the tracker encounters infrared targets that vary in shape or size. In order to address this issue, we present a twofold structured features-based Siamese network for infrared target tracking. Above all, a novel feature fusion network is proposed to make full use of both shallow spatial information and deep semantic information in a comprehensive manner, so as to improve the discriminative capacity for infrared targets. Then, a multitemplate update module is designed to effectively deal with interferences from target appearance changes which are prone to cause early tracking failures. Finally, both qualitative and quantitative experiments are implemented on VOT-TIR 2016 and GTOT datasets, which demonstrates that our method achieves the balance of promising tracking performance and real-time tracking speed against other state-of-the-art trackers.},
  archive      = {J_TCSS},
  author       = {Weijie Yan and Guohua Gu and Yunkai Xu and Xiaofang Kong and Ajun Shao and Qian Chen and Minjie Wan},
  doi          = {10.1109/TCSS.2024.3391631},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5577-5592},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Twofold structured features-based siamese network for infrared target tracking},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computational aids on mental health: Revolutionizing care in
the digital age. <em>TCSS</em>, <em>11</em>(5), 5559–5576. (<a
href="https://doi.org/10.1109/TCSS.2024.3458128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCSS},
  author       = {Shiqiu Meng and Jie Shi and Bin Hu},
  doi          = {10.1109/TCSS.2024.3458128},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {10},
  number       = {5},
  pages        = {5559-5576},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Computational aids on mental health: Revolutionizing care in the digital age},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Corrections to “opinion dynamic games under one step ahead
optimal control.” <em>TCSS</em>, <em>11</em>(4), 5554. (<a
href="https://doi.org/10.1109/TCSS.2024.3408596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We add a missing hypothesis, inadvertently omitted in [1], to Theorems 1, 2, and 3, namely that the sets of agents (nodes) influenced by players are disjoint. All the experimental results and simulations shown in the article satisfy the disjoint set hypothesis and remain valid, with no changes. The abstract and conclusion are modified to include the words “disjoint set” (of agents).},
  archive      = {J_TCSS},
  author       = {Gabriel Gentil and Amit Bhaya},
  doi          = {10.1109/TCSS.2024.3408596},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5554},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Corrections to “Opinion dynamic games under one step ahead optimal control”},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time discovery and mining system of blockchain
extractable value for decentralized finance protocol optimization.
<em>TCSS</em>, <em>11</em>(4), 5536–5553. (<a
href="https://doi.org/10.1109/TCSS.2024.3386716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of blockchain technology has catalyzed the expansion of decentralized finance (DeFi), leading to the harnessing of blockchain platforms. However, the decentralization of blockchain has given rise to blockchain extractable value (BEV) activities, influenced by consensus mechanisms. This study centers on BEV, unveiling a real-time discovery and mining system (RDMS) tailored for arbitrage-based DeFi activities. The system employs innovative methodologies for localized computation and execution. It establishes a comprehensive monitoring system for arbitrage and liquidation activities, contributing positively to the DeFi ecosystem. Leveraging round-the-clock on-chain data indexing and event-driven parsing methods, the RDMS enables automated and periodic analysis of BEV activities. This system provides valuable insights for BEV research, particularly in the context of arbitrage and liquidation activities. And we are able to consistently extract value using arbitrage strategies on blockchains, using RDMS that monitors the chain in real time and applies gas cost reduction mechanisms. Experimental testing and comparative analysis validate the RDMS&#39;s effectiveness, showcasing minimal latency and remarkable gas optimization capabilities.},
  archive      = {J_TCSS},
  author       = {Fangzhou Tang and Yuhang Liu and Qian Zhao and Yayun Cheng},
  doi          = {10.1109/TCSS.2024.3386716},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5536-5553},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Real-time discovery and mining system of blockchain extractable value for decentralized finance protocol optimization},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decoding activist public opinion in decentralized
self-organized protests using LLM. <em>TCSS</em>, <em>11</em>(4),
5525–5535. (<a href="https://doi.org/10.1109/TCSS.2024.3398815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on an investigation of online public opinion on the Nahel Merzouk protests in France, an approach for analyzing and predicting public opinion on protests based on large language model (LLM) is proposed, revealing the impact of emerging social media on the protests. We demonstrate that protests generate public opinion on social media with some lag, but that comment sentiment and expression are consistent with protest trends. As the protests unfolded, we analyzed the evolution of public sentiment. We constructed the prompt based on historical data to predict the protests using the p-tuning and Lora approach to fine-tune LLM. In addition, we discuss how to use blockchain technology to optimize distributed, self-organizing protests and reduce the potential for disinformation and violent conflict.},
  archive      = {J_TCSS},
  author       = {Baoyu Zhang and Tao Chen and Xiao Wang and Qiang Li and Weishan Zhang and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3398815},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5525-5535},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Decoding activist public opinion in decentralized self-organized protests using LLM},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust synthetic-to-real ensemble dehazing algorithm with
the intermediate domain. <em>TCSS</em>, <em>11</em>(4), 5510–5524. (<a
href="https://doi.org/10.1109/TCSS.2024.3392288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-based dehazing methods using synthetic datasets cannot generalize well on real-world hazy images due to the large domain discrepancy. To tackle this issue, we propose a robust synthetic-to-real dehazing framework with the construction of an intermediate domain and ensemble learning strategy. First, by mapping all examples to the intermediate domain, the bidirectional match strategy with adversarial training and the constraint of intermediated results is proposed to suppress the rich domain-specific information, which can facilitate the adaptation and perform image dehazing simultaneously. Furthermore, an ensemble dehazing algorithm based on the intermediate domain is proposed in a semisupervised manner. The reconstruction constraint and the enhanced ground-truths are employed to keep the visual fidelity and remove the dim artifacts of unsupervised dehazing results. Finally, we propose the domain-aware residual groups to deal with the distribution discrepancy between the synthetic and real hazy images. Extensive experiments of various real-world hazy images demonstrate that the proposed method outperforms the state-of-the-art dehazing methods and significantly improves the generalization in the real world.},
  archive      = {J_TCSS},
  author       = {Yingxu Qiao and Xing Wang and Hongmin Liu and Zhanqiang Huo},
  doi          = {10.1109/TCSS.2024.3392288},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5510-5524},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Robust synthetic-to-real ensemble dehazing algorithm with the intermediate domain},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Traffic origin-destination demand prediction via
multichannel hypergraph convolutional networks. <em>TCSS</em>,
<em>11</em>(4), 5496–5509. (<a
href="https://doi.org/10.1109/TCSS.2024.3372856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of origin-destination (OD) demand is critical for service providers to efficiently allocate limited resources in regions with high travel demands. However, OD distributions pose significant challenges, characterized by high sparsity, complex spatial correlations within regions or chains, and potential repetition due to the recurrence of similar semantic contexts. These challenges impede traditional graph-based approaches, which connect two vertices through an edge, from performing effectively in OD prediction. Thus, we present a novel multichannel hypergraph convolutional neural network (MC-HGCN) to overcome the above challenges. The model innovatively extracts distinctive features from the channels of inflows, outflows, and OD flows, to conquer the high sparsity in OD matrices. High-order spatial proximity within regions and OD chains are then modeled by the three adjacency hypergraphs constructed for the above three channels. In each adjacency hypergraph, multiple neighboring stations are treated as vertices, while multiple OD pairs constitute hyperedges. These structures are learned by hypergraph convolutional networks for latent spatial correlations. On this basis, a semantic hypergraph is created for the OD channel to model OD distributions lacking spatial proximity but sharing semantic correlations. It utilizes hyperedges to represent semantic correlations among OD pairs whose origins and destinations both possess similar point-of-interest (POI) functions, before learned by a hypergraph convolutional network (HGCN). Both spatial and semantic correlations intrinsic to OD flows are accordingly captured and embedded into a gated recurrent unit (GRU) to unveil hidden spatiotemporal dependencies among OD distributions. These embedded correlations are ultimately integrated through a multichannel fusion module to enhance the prediction of OD flows, even for minor ones. Our model is validated through experiments on three public datasets, demonstrating its robust performances across long and short time steps. Findings may contribute theoretical insights for practical applications, such as coordinating traffic scheduling or route planning.},
  archive      = {J_TCSS},
  author       = {Ming Wang and Yong Zhang and Xia Zhao and Yongli Hu and Baocai Yin},
  doi          = {10.1109/TCSS.2024.3372856},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5496-5509},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Traffic origin-destination demand prediction via multichannel hypergraph convolutional networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ConteNXt: A graph-based approach to assimilate content and
context for event detection in OSN. <em>TCSS</em>, <em>11</em>(4),
5483–5495. (<a href="https://doi.org/10.1109/TCSS.2024.3372399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks are rapidly expanding due to their imperative role in disseminating information in a split second, emerging as the primary source for breaking news. As a result, the rich, user-generated information entices researchers to delve deeper and extract valuable insights. Event detection in online social networks (OSNs) is a research problem that has shifted researchers attention from traditional news media to online social media data. Event detection in OSNs is an automated process, addressing the impractical task of manually filtering potential events from vast amounts of online data. Unfortunately, the informality and semantic sparsity of online social networking text pose significant challenges to the event detection task. To this end, we present an approach named conteNXt for detecting events from Twitter (currently “X”) posts (also known as Tweets). To handle large amounts of data, the proposed method divides tweets into bins and uses postprocessing methods to extract bursty keyphrases. These keyphrases are then used to generate a weighted keyphrase graph using the Word2Vec model. Finally, Markov clustering is employed to cluster and detect events in the bursty keyphrase graph. conteNXt is evaluated on the EventCorpus2012 benchmark dataset and two additional datasets extracted from the archive, Archive2020 and Archive2021 , using performance evaluation metrics: #events, precision, recall, and F1-score. The proposed approach outperforms state-of-the-art methods, including SEDTWik , Twevent , Sentence-BERT , MABED , EDED , CommunityINDICATOR , and EventX . Additionally, the proposed approach is capable of detecting vital events that are not identified by the aforementioned state-of-the-art methods. https://github.com/Sielvi/conteNXt},
  archive      = {J_TCSS},
  author       = {Sielvie Sharma and Muhammad Abulaish and Tanvir Ahmad},
  doi          = {10.1109/TCSS.2024.3372399},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5483-5495},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {ConteNXt: A graph-based approach to assimilate content and context for event detection in OSN},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive density subgraph clustering. <em>TCSS</em>,
<em>11</em>(4), 5468–5482. (<a
href="https://doi.org/10.1109/TCSS.2024.3370669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density peak clustering (DPC) has garnered growing interest over recent decades due to its capability to identify clusters with diverse shapes and its resilience to the presence of noisy data. Most DPC-based methods exhibit high computational complexity. One approach to mitigate this issue involves utilizing density subgraphs. Nevertheless, the utilization of density subgraphs may impose restrictions on cluster sizes and potentially lead to an excessive number of small clusters. Furthermore, effectively handling these small clusters, whether through merging or separation, to derive accurate results poses a significant challenge, particularly in scenarios where the number of clusters is unknown. To address these challenges, we propose an adaptive density subgraph clustering algorithm (ADSC). ADSC follows a systematic three-step procedure. First, the high-density regions in the dataset are recognized as density subgraphs based on k-nearest neighbor (KNN) density. Second, the initial clustering is carried out by utilizing an automated mechanism to identify the important density subgraphs and allocate outliers. Last, the obtained initial clustering results are further refined in an adaptive manner using the cluster self-ensemble technique, ultimately yielding the final clustering outcomes. The clustering performance of the proposed ADSC algorithm is evaluated on nineteen benchmark datasets. The experimental results demonstrate that ADSC possesses the ability to automatically determine the optimal number of clusters from intricate density data, all while maintaining high clustering efficiency. Comparative analysis against other well-known density clustering algorithms that require prior knowledge of cluster numbers reveals that ADSC consistently achieves comparable or superior clustering results.},
  archive      = {J_TCSS},
  author       = {Hongjie Jia and Yuhao Wu and Qirong Mao and Yang Li and Heping Song},
  doi          = {10.1109/TCSS.2024.3370669},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5468-5482},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Adaptive density subgraph clustering},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UCF-PKS: Unforeseen consumer fraud detection with prior
knowledge and semantic features. <em>TCSS</em>, <em>11</em>(4),
5454–5467. (<a href="https://doi.org/10.1109/TCSS.2024.3372519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of text classification techniques has demonstrated great promise in the field of detecting consumer fraud based on consumer reviews. However, persistent challenges remain in handling large samples at the borders and identifying unforeseen fraud behaviors. To address these challenges, we propose a novel approach that combines a channel biattention convolutional neural network (CNN) with a pretrained language model. Specifically, we propose a similarity computation module for implicitly learning a metric matrix to characterize the similarity between prior knowledge and consumer reviews in vector space. Through this process, the model is able to learn and understand the relationship between prior knowledge and corresponding samples during training, thereby improving its ability to identify unforeseen fraudulent behaviors. Additionally, we propose a channel biattention CNN module to adaptively emphasize the importance of relevant prior knowledge to enhance the model&#39;s ability to accurately classify boundary samples. To ensure effective model training, we expand and organize a real-world dataset, reducing noise and increasing the number of fraud samples available for analysis. Experimental results demonstrate that our approach achieves state-of-the-art performance in fraud detection. Notably, our model is capable of detecting unforeseen fraud cases without the need for retraining or fine-tuning, making it highly adaptable and efficient in practical applications.},
  archive      = {J_TCSS},
  author       = {Shanyan Lai and Junfang Wu and Chunyang Ye and Zhiwei Ma},
  doi          = {10.1109/TCSS.2024.3372519},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5454-5467},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {UCF-PKS: Unforeseen consumer fraud detection with prior knowledge and semantic features},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extracting higher order topological semantic via motif-based
deep graph neural networks. <em>TCSS</em>, <em>11</em>(4), 5444–5453.
(<a href="https://doi.org/10.1109/TCSS.2024.3372775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are efficient techniques for learning graph representations and have shown remarkable success in tackling diverse graph-related tasks. However, in the context of the neighborhood aggregation paradigm, conventional GNNs have limited capabilities in capturing the higher order structures and topological semantics of graphs. Researchers have attempted to overcome this limitation by designing new GNNs that explore the impacts of motifs to capture potentially higher order graph information. However, existing motif-based GNNs often ignore lower order connectivity patterns such as nodes and edges, which leads to poor representation of sparse networks. To address these limitations, we propose an innovative approach. First, we design convolution kernels on both motif-based and simple graphs. Second, we introduce a multilevel graph convolution framework for extracting higher order topological semantics of graphs. Our approach overcomes the limitations of prior methods, demonstrating state-of-the-art performance in downstream tasks with excellent scalability. Extensive experiments on real-world datasets validate the effectiveness of our proposed method.},
  archive      = {J_TCSS},
  author       = {Ke-Jia Zhang and Xiao Ding and Bing-Bing Xiang and Hai-Feng Zhang and Zhong-Kui Bao},
  doi          = {10.1109/TCSS.2024.3372775},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5444-5453},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Extracting higher order topological semantic via motif-based deep graph neural networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TriMPA: Triggerless targeted model poisoning attack in DNN.
<em>TCSS</em>, <em>11</em>(4), 5431–5443. (<a
href="https://doi.org/10.1109/TCSS.2023.3349269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its admirable accuracy and performance across a wide range of classification and identification tasks, deep learning algorithms have gained popularity in several applications. However, the models’ security has become a serious concern, as antagonists could use them to promote their malicious goals. This work proposes a triggerless targeted model poisoning attack (TriMPA) against deep neural network without requiring any change in input to trigger the backdoor. TriMPA identifies active neurons that highly contribute to the prediction of the victim output label and replaces those neurons with that corresponding to the target output label. The performance of the proposed mechanism is evaluated through experiments as well as analyzed theoretically. It is shown that TriMPA achieves a higher attack success rate.},
  archive      = {J_TCSS},
  author       = {Debasmita Manna and Somanath Tripathy},
  doi          = {10.1109/TCSS.2023.3349269},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5431-5443},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {TriMPA: Triggerless targeted model poisoning attack in DNN},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Layer-adapted implicit distribution alignment networks for
cross-corpus speech emotion recognition. <em>TCSS</em>, <em>11</em>(4),
5419–5430. (<a href="https://doi.org/10.1109/TCSS.2024.3362690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a new unsupervised domain adaptation (DA) method called layer-adapted implicit distribution alignment networks (LIDANs) to address the challenge of cross-corpus speech emotion recognition (SER). LIDAN extends our previous ICASSP work, deep implicit distribution alignment networks (DIDANs), whose key contribution lies in the introduction of a novel regularization term called implicit distribution alignment (IDA). This term allows DIDAN trained on source (training) speech samples to remain applicable to predicting emotion labels for target (testing) speech samples, regardless of corpus variance in cross-corpus SER. To further enhance this method, we extend IDA to layer-adapted IDA (LIDA), resulting in LIDAN. This layer-adapted extension consists of three modified IDA terms that consider emotion labels at different levels of granularity. These terms are strategically arranged within different fully connected layers in LIDAN, aligning with the increasing emotion-discriminative abilities with respect to the layer depth. This arrangement enables LIDAN to more effectively learn emotion-discriminative and corpus-invariant features for SER across various corpora compared to DIDAN. It is also worthy to mention that unlike most existing methods that rely on estimating statistical moments to describe preassumed explicit distributions, both IDA and LIDA take a different approach. They utilize an idea of target sample reconstruction to directly bridge the feature distribution gap without making assumptions about their distribution type. As a result, DIDAN and LIDAN can be viewed as implicit cross-corpus SER methods. To evaluate LIDAN, we conducted extensive cross-corpus SER experiments on EmoDB, eNTERFACE, and CASIA corpora. The experimental results demonstrate that LIDAN surpasses recent state-of-the-art explicit unsupervised DA methods in tackling cross-corpus SER tasks.},
  archive      = {J_TCSS},
  author       = {Yan Zhao and Yuan Zong and Jincen Wang and Hailun Lian and Cheng Lu and Li Zhao and Wenming Zheng},
  doi          = {10.1109/TCSS.2024.3362690},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5419-5430},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Layer-adapted implicit distribution alignment networks for cross-corpus speech emotion recognition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Key nodes evaluation method based on combination weighting
VIKOR in social networks. <em>TCSS</em>, <em>11</em>(4), 5404–5418. (<a
href="https://doi.org/10.1109/TCSS.2024.3360618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation of key nodes is a hot issue in social networks. Existing research primarily evaluates the importance of nodes in social networks based on centrality metrics, neglecting the node’s own attributes. After analyzing the topology attributes and the basic attributes of nodes, this article proposes a key nodes evaluation method for social networks, which is based on analytic hierarchy process (AHP) and improved Vise Kriterijumska Optimizacija I Kompromisno Resenje (VIKOR), termed AE-VIKOR. Considering global attributes, local attributes, and positional attributes of nodes, three evaluation metrics are constructed. The subjective and objective weights are computed by AHP and entropy weight method, respectively. The comprehensive weights of metrics are determined by combination weighting method based on square sums of distance. Due to the excessive weight of specific metrics and excessive difference in data distribution, the computation of individual regret value depends too much on a single metric in VIKOR method, individual regret value is optimized by weighted sum of closeness between the scheme to be evaluated and the negative ideal scheme. Multimetric evaluation schemes are ranked to achieve the evaluation of key nodes. Experiments on two real social network datasets show that the key nodes evaluated by AE-VIKOR have stronger information spread ability and more fans than the ones of the existing methods. In addition, the validity of the three metrics and the two improvements on the VIKOR method are verified by ablation experiments.},
  archive      = {J_TCSS},
  author       = {Jian Shu and Yao Liang and Wanli Ma and Linlan Liu},
  doi          = {10.1109/TCSS.2024.3360618},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5404-5418},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Key nodes evaluation method based on combination weighting VIKOR in social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multimodal latent-features-based service recommendation
system for the social internet of things. <em>TCSS</em>, <em>11</em>(4),
5388–5403. (<a href="https://doi.org/10.1109/TCSS.2024.3360518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Social Internet of Things (SIoT) is revolutionizing how we interact with our everyday lives. By adding the social dimension to connecting devices, the SIoT has the potential to drastically change the way we interact with smart devices. This connected infrastructure allows for unprecedented levels of convenience, automation, and access to information, allowing us to do more with less effort. However, this revolutionary new technology also brings an eager need for service recommendation systems. As the SIoT grows in scope and complexity, it becomes increasingly important for businesses and individuals, and SIoT objects alike to have reliable sources for products, services, and information that are tailored to their specific needs. Few works have been proposed to provide service recommendations for SIoT environments. However, these efforts have been confined to only focusing on modeling user-item interactions using contextual information, devices’ SIoT relationships, and correlation social groups but these schemes do not account for latent semantic item–item structures underlying the sparse multimodal contents in SIoT environment. In this article, we propose a latent-based SIoT recommendation system that learns item–item structures and aggregates multiple modalities to obtain latent item graphs which are then used in graph convolutions to inject high-order affinities into item representations. Experiments showed that the proposed recommendation system outperformed state-of-the-art SIoT recommendation methods and validated its efficacy at mining latent relationships from multimodal features.},
  archive      = {J_TCSS},
  author       = {Amar Khelloufi and Huansheng Ning and Abdenacer Naouri and Abdelkarim Ben Sada and Attia Qammar and Abdelkader Khalil and Lingfeng Mao and Sahraoui Dhelim},
  doi          = {10.1109/TCSS.2024.3360518},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5388-5403},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A multimodal latent-features-based service recommendation system for the social internet of things},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GANI: Global attacks on graph neural networks via
imperceptible node injections. <em>TCSS</em>, <em>11</em>(4), 5374–5387.
(<a href="https://doi.org/10.1109/TCSS.2024.3361027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have found successful applications in various graph-related tasks. However, recent studies have shown that many GNNs are vulnerable to adversarial attacks. In a vast majority of existing studies, adversarial attacks on GNNs are launched via direct modification of the original graph such as adding/removing links, which may not be applicable in practice. In this article, we focus on a realistic attack operation via injecting fake nodes. The proposed global attack strategy via node injection (GANI) is designed under the comprehensive consideration of an unnoticeable perturbation setting from both structure and feature domains. Specifically, to make the node injections as imperceptible and effective as possible, we propose a sampling operation to determine the degree of the newly injected nodes, and then generate features and select neighbors for these injected nodes based on the statistical information of features and evolutionary perturbations obtained from a genetic algorithm, respectively. In particular, the proposed feature generation mechanism is suitable for both binary and continuous node features. Extensive experimental results on benchmark datasets against both general and defended GNNs show strong attack performance of GANI. Moreover, the imperceptibility analyses also demonstrate that GANI achieves a relatively unnoticeable injection on benchmark datasets.},
  archive      = {J_TCSS},
  author       = {Junyuan Fang and Haixian Wen and Jiajing Wu and Qi Xuan and Zibin Zheng and Chi K. Tse},
  doi          = {10.1109/TCSS.2024.3361027},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5374-5387},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {GANI: Global attacks on graph neural networks via imperceptible node injections},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Smoking dynamics: Factors supplementing tobacco smoking in
pakistan. <em>TCSS</em>, <em>11</em>(4), 5367–5373. (<a
href="https://doi.org/10.1109/TCSS.2024.3350675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smoking tobacco is not only a public health issue but also has severe economic connotations too. Due to substantial economic and health effects of tobacco pandemic, it is now an urgent and obvious public health priority worldwide. Increased rate of its usage in Pakistan has negatively impacted people&#39;s health, families, and society. In order to cure issue, there is need to find factors responsible for pervasiveness of tobacco use in Pakistan. Thus, study will explore determinants of tobacco smoking in Pakistan. Study uses Pakistan demographic and health survey data. Analysis comprises of theoretical reasoning, association tests, and logistic regression. In analysis, tobacco use has been used as dependent variable, while age, occupation, region, place of residence, household wealth status, and education level have been used as independent variables. Results indicate that odds of any kind of tobacco use are highest for Punjab, it is more prevalent in urban areas, highest odds are for people 40 years of age and above, lowest odds are for people with higher education level, highest odds are for people either self-employed or engaged in agricultural activities, and it is more prevalent in poor households. Based upon results of study, it is conferred that in order to control tobacco use targeted interventions are needed and there is need to focus on: urban areas, less educated people, poor households, people of age 40 years and above, and people who are self-employed or engaged in agricultural activities.},
  archive      = {J_TCSS},
  author       = {Muhammad Nadeem and Muhammad Irfan Malik and Arif Ullah and Novaira Junaid},
  doi          = {10.1109/TCSS.2024.3350675},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5367-5373},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Smoking dynamics: Factors supplementing tobacco smoking in pakistan},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). STIDNet: Identity-aware face forgery detection with
spatiotemporal knowledge distillation. <em>TCSS</em>, <em>11</em>(4),
5354–5366. (<a href="https://doi.org/10.1109/TCSS.2024.3356549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impressive development of facial manipulation techniques has raised severe public concerns. Identity-aware methods, especially suitable for protecting celebrities, are seen as one of promising face forgery detection approaches with additional reference video. However, without in-depth observation of fake video&#39;s characteristics, most existing identity-aware algorithms are just naive imitation of face verification model and fail to exploit discriminative information. In this article, we argue that it is necessary to take both spatial and temporal perspectives into consideration for adequate inconsistency clues and propose a novel forgery detector named SpatioTemporal IDentity network (STIDNet). To effectively capture heterogeneous spatiotemporal information in a unified formulation, our STIDNet is following a knowledge distillation architecture that the student identity extractor receives supervision from a spatial information encoder (SIE) and a temporal information encoder (TIE) through multiteacher training. Specifically, a regional sensitive identity modeling paradigm is proposed in SIE by introducing facial blending augmentation but with uniform identity label, thus encourage model to focus on spatial discriminative region like outer face. Meanwhile, considering the strong temporal correlation between audio and talking face video, our TIE is devised in a cross-modal pattern that the audio information is introduced to supervise model exploiting temporal personalized movements. Benefit from knowledge transfer from SIE and TIE, STIDNet is able to capture individual&#39;s essential spatiotemporal identity attributes and sensitive to even subtle identity deviation caused by manipulation. Extensive experiments indicate the superiority of our STIDNet compared with previous works. Moreover, we also demonstrate STIDNet is more suitable for real-world implementation in terms of model complexity and reference set size.},
  archive      = {J_TCSS},
  author       = {Mingqi Fang and Lingyun Yu and Hongtao Xie and Qingfeng Tan and Zhiyuan Tan and Amir Hussain and Zezheng Wang and Jiahong Li and Zhihong Tian},
  doi          = {10.1109/TCSS.2024.3356549},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5354-5366},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {STIDNet: Identity-aware face forgery detection with spatiotemporal knowledge distillation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MEFaND: A multimodel framework for early fake news
detection. <em>TCSS</em>, <em>11</em>(4), 5337–5353. (<a
href="https://doi.org/10.1109/TCSS.2024.3355300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alongside social media platforms’ rise in popularity, fake news circulation has increased, highlighting the need for more practical methods to detect this phenomenon. The constantly evolving format of fake news makes it difficult for approaches that rely on a single modality of news to generalize the different types of false news. Furthermore, earlier approaches require extensive propagation data to determine the veracity of news, which can be challenging to collect in the early stages of news dissemination. Thus, we propose a multimodal early fake news detection approach that leverages latent insights into both news content and propagation knowledge. We design a multimodule architecture using graph neural networks (GNNs) to represent edge-enhanced and node-enhanced propagation graphs and bidirectional encoder representations from transformers (BERTs) to generate contextualized representations of news content. Our approach tackles the challenge of early detection in a more realistic scenario, accessing early propagation data in a single social media post and short-length news content. Moreover, we conduct comprehensive studies on user characteristics using statistical techniques to identify attributes with strong discriminative capability for identifying false news. We also analyze temporal and structural properties of fake news propagation graphs to demonstrate distinguishable patterns of false and real news behavior. Our model outperforms several state-of-the-art methods, achieving an impressive F1-score of 99% and 96% on two public datasets. The individual contribution of various components in our model to the final performance is also measured, which can be insightful for future research on multimodal false news detection.},
  archive      = {J_TCSS},
  author       = {Asma Sormeily and Sajjad Dadkhah and Xichen Zhang and Ali A. Ghorbani},
  doi          = {10.1109/TCSS.2024.3355300},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5337-5353},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {MEFaND: A multimodel framework for early fake news detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal interaction embedding for link prediction in global
news event graph. <em>TCSS</em>, <em>11</em>(4), 5327–5336. (<a
href="https://doi.org/10.1109/TCSS.2024.3357696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global news events graphs (GNEG) are designed for the noisy and ungrammatical world&#39;s news media, aiming at capturing the true insight and providing explanations by incorporating potential dimensions and network structures of global news. This article focuses on the temporal representation learning of GNEG to eliminate misunderstanding or ambiguity caused by missing information. Although some temporal models have been developed, the crossover interactions among entity, relation, and time have not been explicitly discussed. The multidirectional effects between entities, relations, and timestamps matter in predicting the establishment of quadruples. This motivates the proposal of learning temporal interaction embeddings (TIE) to benefit GNEG link prediction performance. Specifically, we propose the following. 1) We propose a crossover convolution layer to learn the two-by-two and common interaction features of entity, relation, and time in GNEG to capture their potential effect patterns in the context of different quadruples. 2) For the learned interaction information, we adopt tensor neural network (TNN) to maintain the multiple order structure and further extract effective features to improve prediction. 3) A tensor temporal consistency constraint (TCC) is proposed to enhance the learning of time-weakly sensitive information and induce the embeddings to have a certain compatibility over time. Finally, we carried out extensive experiments on three benchmark datasets, the results proved that the performance of the proposed TIE model is competitive with the state-of-the-art methods.},
  archive      = {J_TCSS},
  author       = {Jing Yang and Laurence T. Yang and Hao Wang and Yuan Gao},
  doi          = {10.1109/TCSS.2024.3357696},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5327-5336},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Temporal interaction embedding for link prediction in global news event graph},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An emoticon-based novel sarcasm pattern detection strategy
to identify sarcasm in microblogging social networks. <em>TCSS</em>,
<em>11</em>(4), 5319–5326. (<a
href="https://doi.org/10.1109/TCSS.2023.3306908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks are one of the prime modes of communication used by people to voice their opinions and sentiments, especially after the advancement of digital gadgets and overall technology. Mining such sentiments and analyzing the polarity of user opinions is a trending research issue with high business value. Identifying, detecting, and understanding sarcasm is an important topic in the field of sentiment analysis. Despite being complex and challenging, automated detection of sarcasm is also a relatively less explored research area. In this article, we present a novel sarcasm pattern detection technique using emoticons to identify sarcasm in microblogging social networks like Twitter. Initially, we classify the tweets only with emoticons based on a decision tree classification approach. Afterward, we incorporate the SentiWordNet library and a separate emoticon library to find the polarities of the tokenized words and emoticons. Finally, we present a comparison of the polarity of the tweets and the polarity of the emoticons to detect sarcasm in tweets.},
  archive      = {J_TCSS},
  author       = {M. Nirmala and Amir H. Gandomi and Madda Rajasekhara Babu and L. D. Dhinesh Babu and Rizwan Patan},
  doi          = {10.1109/TCSS.2023.3306908},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5319-5326},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An emoticon-based novel sarcasm pattern detection strategy to identify sarcasm in microblogging social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An entity ontology-based knowledge graph embedding approach
to news credibility assessment. <em>TCSS</em>, <em>11</em>(4),
5308–5318. (<a href="https://doi.org/10.1109/TCSS.2023.3342873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news is a prevalent issue in modern society, leading to misinformation, and societal harm. News credibility assessment is a crucial approach for evaluating the accuracy and authenticity of news. It plays a significant role in enhancing public awareness and understanding of news, while also effectively mitigating the dissemination of fake news. However, news credibility assessment meets challenges when processing large-scale and constantly growing data, due to insufficient and unreliable labels and standards, and diversity and semantic ambiguity of news contents. Recently, machine learning models have been well developed to address these issues, but suffer from limited effectiveness. A unified framework is also required for them to represent various entities and relationships involved in news stories. This article proposes an entity ontology-based knowledge graph network (EKNet) to leverage knowledge graphs and entity frameworks for news credibility assessment. The model utilizes the information from knowledge graphs by combining entities and relationships from news and knowledge graphs. Experimental results show that the EKNet has advantages in evaluating news credibility over existing methods. Specifically, compared to several strong baselines, the model demonstrates a significant performance improvement in scores across various tasks. Which indicates that using the EKNet to address the challenges in news credibility assessment is highly effective and can conduct better performance for the problem of fake news in the social media environment.},
  archive      = {J_TCSS},
  author       = {Qi Liu and Yuanyuan Jin and Xuefei Cao and Xiaodong Liu and Xiaokang Zhou and Yonghong Zhang and Xiaolong Xu and Lianyong Qi},
  doi          = {10.1109/TCSS.2023.3342873},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5308-5318},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An entity ontology-based knowledge graph embedding approach to news credibility assessment},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised dimensional media sentiment analysis via
exploring sample relationships. <em>TCSS</em>, <em>11</em>(4),
5298–5307. (<a href="https://doi.org/10.1109/TCSS.2023.3307685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensional sentiment analysis (DSA) aims to recognize continuous real-valued annotations in multidimensional spaces such as valence-arousal space. It can serve as a sentiment analysis that is more fine-grained than traditional polarity classification. Existing methods primarily focused on supervised learning, which requires a large number of training samples. To address this issue, recent studies have suggested the use of a generative model for semi-supervised DSA. However, these methods lack the exploration of relationships between samples, which may limit their effectiveness. In this study, we proposed a sample relationships (SRs) model for semi-supervised DSA. Compared with the conventional methods, the SR module can integrate the interactive information from different samples, effectively capturing their interdependencies. The results of experiments conducted on three datasets indicated that the performance of the proposed method was better than those of the existing models and that the performance was effective and competitive even with insufficient data.},
  archive      = {J_TCSS},
  author       = {Peng Liu and Wenhua Qian and Huaguang Li and Jinde Cao},
  doi          = {10.1109/TCSS.2023.3307685},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5298-5307},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Semi-supervised dimensional media sentiment analysis via exploring sample relationships},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trusted multimodal socio-cyber sentiment analysis based on
disentangled hierarchical representation learning. <em>TCSS</em>,
<em>11</em>(4), 5287–5297. (<a
href="https://doi.org/10.1109/TCSS.2023.3324462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of the digital age has led to a qualitative leap in social media. To meet the cognitive needs of users, social media platforms have been mining users’ private information and disseminating information through various means. However, these platforms lack effective management of information release and various forms of emotional expressions make public propaganda increasingly diverse and complex. Therefore, accurately identifying the relationships between multimodal data poses a challenge. An effective modal representation must consider both the consistency of multimodal data and the complementarity of single-modal data. However, existing methods focus on fusing different modal features into a unified feature representation, while neglecting to evaluate the reliability of prediction results. In this article, we disentangle the consistency and complementarity in the fused representation problem of multimodal data. We construct the modal private task (unique) by using the Dirichlet distribution and evidence theory to solve the uncertainty of each modal prediction. The model can output the uncertainty of prediction and learn complementary information through the fusion of decision layers. At the same time, we construct the modal common task using a low-rank tensor fusion model to learn consistent features. Finally, we compare the model with the current mainstream methods on three public datasets, and the experimental results show that the performance of our method reaches the level of current advanced algorithms.},
  archive      = {J_TCSS},
  author       = {Guoxia Xu and Lizhen Deng and Yansheng Li and Yantao Wei and Xiaokang Zhou and Hu Zhu},
  doi          = {10.1109/TCSS.2023.3324462},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5287-5297},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Trusted multimodal socio-cyber sentiment analysis based on disentangled hierarchical representation learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rough-fuzzy graph learning domain adaptation for fake news
detection. <em>TCSS</em>, <em>11</em>(4), 5275–5286. (<a
href="https://doi.org/10.1109/TCSS.2023.3312182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread dissemination of fake news across the internet has profound detrimental consequences for society, governments, and citizens. To address this pressing issue, numerous machine learning-based models have been developed for detecting fake news. However, the challenge of acquiring sufficient labeled news data in a new domain, coupled with the presence of inconsistent data distribution, necessitates the integration of unsupervised domain adaptation (DA) methods to enhance the reliability of cross-domain fake news detection. In this article, a rough-fuzzy graph learning DA for fake news detection is proposed. First, a rough-fuzzy graph learning method is proposed to effectively handle the representation of cross-domain sample uncertainty structural information, thereby learning a more discriminative subspace. Second, a rough-fuzzy region division strategy is designed to perform different analysis on target domain samples, thus achieving a more accurate description of the relationships between cross-domain samples. Furthermore, considering that domain private features may negatively affect the knowledge transfer process, a sparse structure preserving strategy is proposed to better capture shared general features across domains. Experimental evaluations conducted on three news datasets demonstrate the efficacy of the proposed method in cross-domain fake news detection.},
  archive      = {J_TCSS},
  author       = {Jiao Shi and Xin Zhao and Nan Zhang and Yu Lei and Lingtong Min},
  doi          = {10.1109/TCSS.2023.3312182},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5275-5286},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Rough-fuzzy graph learning domain adaptation for fake news detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A framework to overcome the dark side of generative
artificial intelligence (GAI) like ChatGPT in social media and
education. <em>TCSS</em>, <em>11</em>(4), 5266–5274. (<a
href="https://doi.org/10.1109/TCSS.2023.3315237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the performance of generative artificial intelligence (GAI), such as ChatGPT, improves, content created by GAI will be distributed in the social media space, and knowledge and writings from unknown sources will be disseminated and reproduced. Now that GAI is becoming widespread, it is necessary to distinguish GAI from human intelligence, which constitutes knowledge. The data, information, knowledge, and work (DIKW) hierarchy is a useful framework for teaching and for checking metacognitive and explainable artificial intelligence (XAI) literacy. There are two types of collaboration between GAI and human intelligence: a combined intelligence model and a parallel intelligence model. The combined intelligence model is a method of using GAI for creating works by collecting data, organizing information, and deriving knowledge from information. This model is suitable for GAI-assisted tasks (GAIATs). The parallel intelligence model is suitable for GAI-assisted learning (GAIAL); it is a method in which a person develops abilities by analyzing and comparing tasks created by GAI after going through the data-information-knowledge-work process. The zone of proximal development (ZPD) created by educational scaffolding is a quantitative framework that is appropriate for evaluating the effects of GAI. The ZPD generated by GAI that corresponds to scaffolding should be managed so as not to favor or disadvantage specific individuals.},
  archive      = {J_TCSS},
  author       = {Pyoung Won Kim},
  doi          = {10.1109/TCSS.2023.3315237},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5266-5274},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A framework to overcome the dark side of generative artificial intelligence (GAI) like ChatGPT in social media and education},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SockDef: A dynamically adaptive defense to a novel attack on
review fraud detection engines. <em>TCSS</em>, <em>11</em>(4),
5253–5265. (<a href="https://doi.org/10.1109/TCSS.2023.3321345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake reviews are having a devastating negative influence on online shopping sites. The proliferation of fake reviews is exacerbated by the presence of SockFarms, companies that create and operate huge sets of “sockpuppet” accounts to promote their customers’ products by posting fake reviews. Our proposed SockAttack algorithm allows such companies to optimize their actions to maximize profits. We show that SockAttack compromises the F1-score of four well-known review fraud detection engines on real-world datasets (up to 27.1% more than baselines). We then propose a defense algorithm called SockDef and show that it mitigates the impact of SockAttack (up to 69.2% with respect to F1-score).},
  archive      = {J_TCSS},
  author       = {Youzhi Zhang and Sayak Chakrabarty and Rui Liu and Andrea Pugliese and V. S. Subrahmanian},
  doi          = {10.1109/TCSS.2023.3321345},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5253-5265},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {SockDef: A dynamically adaptive defense to a novel attack on review fraud detection engines},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-attention mechanism-based model for early detection
of fake news. <em>TCSS</em>, <em>11</em>(4), 5241–5252. (<a
href="https://doi.org/10.1109/TCSS.2023.3322160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extensive studies have indicated that fake news has become one of the major threats to our social system (e.g., influencing public opinion, financial markets, journalism, and health system), and its impact cannot be understated, particularly in our current socially and digitally connected society. In the past years, this problem has been investigated from different perspectives and various disciplines, such as computer science, political science, information science, and linguistics. Even though such efforts have proposed many helpful solutions, it remains challenging to detect fake news in its early phases of dissemination. Based on previously reported studies, detecting fake news early after its propagation is a very tough task due to the unavailability of context-based features within the first hours of spreading and the ineffectiveness of merely content-based features methods. To address this challenge, we propose a new framework for detecting fake news in the early stages of its propagation. The first three components of the proposed framework convert each news article’s propagation network into a sequence of nodes after preprocessing and feature extraction. The last module of our framework leverages a self-attention mechanism-based encoder. Self-attention technique is the core of the well-known transformer model, which has achieved promising results in different areas, especially in complex tasks such as language translation. In the module, a new representation of the input sequence is generated, which is mapped to a label for the news article by a binary classifier. We evaluated our method on two datasets and achieved promising results. The achieved F1 scores by the proposed model on the GossipCop and PolitiFact datasets are higher than the best baseline model by 9% and 6%, respectively.},
  archive      = {J_TCSS},
  author       = {Bahman Jamshidi and Saqib Hakak and Rongxing Lu},
  doi          = {10.1109/TCSS.2023.3322160},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5241-5252},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A self-attention mechanism-based model for early detection of fake news},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the feasibility of predicting volumes of fake news—the
spanish case. <em>TCSS</em>, <em>11</em>(4), 5230–5240. (<a
href="https://doi.org/10.1109/TCSS.2023.3297093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing amount of news shared on the Internet makes it hard to verify them in real-time. Malicious actors take advantage of this situation by spreading fake news to impact society through misinformation. An estimation of future fake news would help to focus the detection and verification efforts. Unfortunately, no previous work has addressed this issue yet. Therefore, this work measures the feasibility of predicting the volume of future fake news in a particular context—Spanish contents related to Spain. The approach involves different artificial intelligence (AI) mechanisms on a dataset of 298k real news and 8.9k fake news in the period 2019–2022. Results show that very accurate predictions can be reached. In general words, the use of long short-term memory (LSTM) with attention mechanisms offers the best performance, being headlines useful when a small amount of days is taken as input. In the best cases, when predictions are made for periods, an error of 10.3% is made considering the mean of fake news. This error raises to 28.7% when predicting a single day in the future.},
  archive      = {J_TCSS},
  author       = {Luis Ibañez-Lissen and Lorena González-Manzano and José M. de Fuentes and Manuel Goyanes},
  doi          = {10.1109/TCSS.2023.3297093},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5230-5240},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {On the feasibility of predicting volumes of fake News—The spanish case},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A meta-analysis of state-of-the-art automated fake news
detection methods. <em>TCSS</em>, <em>11</em>(4), 5219–5229. (<a
href="https://doi.org/10.1109/TCSS.2023.3296627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, various artificial intelligence (AI)-based methods have been proposed to support humans in detecting disinformation and fake news. The goal of this article is to provide a meta-analysis, and formally evaluate, compare, and benchmark various classes of fake news detection approaches. To this end, the following paper performs a comprehensive analysis of the performance-related results of different models using a range of benchmark datasets. The performed and disclosed meta-analysis compares the statistical significance of differences in a range of performance metrics, including precision, $F1$ -score, recall, and balanced accuracy (BACC). The utilized approach features the $5 \times 2$ cross-validation methodology. The models undergoing the formal evaluation constitute state-of-the-art (SOTA) solutions meeting acceptance criteria. The evaluated approaches draw from the most recent advancements in natural language processing (NLP). The outcome of this work is the formal benchmarking and meta-analysis of fake news detection methods that can be further utilized by the research community, but more importantly by the practitioners and decision-makers that counter fake news on a daily basis, e.g., in press agencies, homeland security agencies, fact-checkers, and so on. This work is the natural extension of the authors’ previous systematic analysis of fake news detection methods and authors’ own fake news detection methods based on machine learning (ML)/artificial intelligence (AI) techniques.},
  archive      = {J_TCSS},
  author       = {Rafał Kozik and Aleksandra Pawlicka and Marek Pawlicki and Michał Choraś and Wojciech Mazurczyk and Krzysztof Cabaj},
  doi          = {10.1109/TCSS.2023.3296627},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5219-5229},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A meta-analysis of state-of-the-art automated fake news detection methods},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Offensive language detection for low resource language using
deep sequence model. <em>TCSS</em>, <em>11</em>(4), 5210–5218. (<a
href="https://doi.org/10.1109/TCSS.2023.3280952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media platforms are heavily used by people to express their views in their native languages. Besides positive views, people often use abusive or offensive language to express their anger or frustration. Resource-rich languages have offensive language detection systems which automatically monitor and block offensive content, however, they are very rare for low-resourced languages. This is because of the nonavailability of datasets for local languages. This article proposes a model which automatically detects offensive language for a very low-resource language, i.e., Pashto. The Roman Pashto dataset is created by picking 60 thousand comments from different social media and labeling them manually. The proposed model is trained and tested using three different feature extraction approaches, i.e., bag-of-words (BoW), term frequency-inverse document frequency (TF-IDF), and sequence integer encoding. Four traditional classifiers and a deep sequence model are used to train on this task. Experimental result shows that the random forest classifier works best and give 94.07 % testing accuracy on a combination of unigrams, bigrams, and trigrams. The same classifier gives maximum accuracy of 93.90 % with TF-IDF. However, the overall highest testing accuracy of 97.21% is achieved by using bidirectional long short-term memory (BLSTM). The corpus created in this work is made available for the researcher working in this domain.},
  archive      = {J_TCSS},
  author       = {Anas Ali Khan and M. Hammad Iqbal and Shibli Nisar and Awais Ahmad and Waseem Iqbal},
  doi          = {10.1109/TCSS.2023.3280952},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5210-5218},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Offensive language detection for low resource language using deep sequence model},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting adversarial examples of fake news via the neurons
activation state. <em>TCSS</em>, <em>11</em>(4), 5199–5209. (<a
href="https://doi.org/10.1109/TCSS.2023.3293718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the development of technologies, such as the Internet and mobile communication, news production is increasing day by day. Proper news delivery can lead to a thriving economy and disseminate knowledge. However, in addition to disrupting the existing order, fake news may create incorrect values and even beliefs. Therefore, detecting the authenticity of news is an extremely important issue. At present, many scholars have used artificial intelligence (AI) to detect fake news, achieving excellent results. However, once humans become dependent on AI, adversarial examples (AEs) can deceive the AI model and allow humans to receive false information. We have discovered that samples from different categories result in distinct and independent activation state distributions for each neuron. Therefore, this study proposes a method that detects adversarial samples of fake news by observing the activation states of neurons and modeling them as a Poisson distribution. The results of the experiment showed that our method can effectively detect AEs mixed in normal data and remove them, thereby improving the classification accuracy of the model by about 17%. The experimental results show that the method proposed in this article can improve the detection accuracy of fake news AEs.},
  archive      = {J_TCSS},
  author       = {Fan-Hsun Tseng and Jiang-Yi Zeng and Hsin-Hung Cho and Kuo-Hui Yeh and Chi-Yuan Chen},
  doi          = {10.1109/TCSS.2023.3293718},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5199-5209},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Detecting adversarial examples of fake news via the neurons activation state},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time fake news detection using big data analytics and
deep neural network. <em>TCSS</em>, <em>11</em>(4), 5189–5198. (<a
href="https://doi.org/10.1109/TCSS.2023.3309704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s fast-paced world, the Internet has become a prevalent source of information for people worldwide. With the increasing use of various applications, people can get updates in real time, making access to information more convenient than ever. However, this easy access to the Internet has also led to the rise of fake news, making it difficult for individuals to differentiate between true and false information. This is where deep learning (DL) comes into play, offering a solution to identify and combat fake news. In this era of technology, DL can be a game-changer in detecting fake news and preventing potential damage to individuals and organizations. A hybrid N-gram and long short-term memory (LSTM) model improves accuracy, recall rate, and computation time, making the fake news detection process more elegant. This proposed model utilizes a classifier to classify fake news. It is based on the parallel and distributed platform, enabling it to build the DL model using big data analytics. This platform improves the training and testing time and enhances the accuracy of the proposed model. The proposed system classifies news into two categories, “fake news” and “real news,” while quantifying the results to develop a system that can detect fake news with high accuracy and a meager mistake rate. Integrating the deep neural network (DNN) and Spark architecture of big data makes the proposed model highly efficient, as demonstrated by the results.},
  archive      = {J_TCSS},
  author       = {Muhammad Babar and Awais Ahmad and Muhammad Usman Tariq and Sarah Kaleem},
  doi          = {10.1109/TCSS.2023.3309704},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5189-5198},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Real-time fake news detection using big data analytics and deep neural network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TOFDS: A two-stage task execution method for fake news in
digital twin-empowered socio-cyber world. <em>TCSS</em>, <em>11</em>(4),
5178–5188. (<a href="https://doi.org/10.1109/TCSS.2023.3262958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the breakthrough in mobile wireless communication technologies, almost everyone has been immersed into social networks, while fake news and misinformation are also being pushed into people’s minds with astonishing speed and breadth. The rising disparity between limited computing resources and the exploding news size necessitates innovative solutions to handle the challenge posed by booming data volume and make it more likely to differentiate fake news. In response to the aforementioned dilemma, the social-aware computation offloading system is analyzed, where the digital twin (DT) paradigm is used to simulate tasks offloading and assess the associated costs. Next, to obtain the best offloading choice, we fully consider the social relationship constraints and further propose an online task execution method that includes two stages of cluster selection and computing offloading, named TOFDS. Specifically, it exploits the technologies from multiobjective optimization and deep reinforcement learning (DRL) and realizes the joint optimization of resource utilization, load balancing, service latency, and energy consumption. Eventually, the comparative experiments demonstrate that TOFDS performs well when dealing with fake news data and can adapt to changes in dataset size and service clusters.},
  archive      = {J_TCSS},
  author       = {Kai Peng and Bohai Zhao and Chengfang Ling and Muhammad Bilal and Xiaolong Xu and Joel J. P. C. Rodrigues},
  doi          = {10.1109/TCSS.2023.3262958},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5178-5188},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {TOFDS: A two-stage task execution method for fake news in digital twin-empowered socio-cyber world},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Believe in artificial intelligence? A user study on the
ChatGPT’s fake information impact. <em>TCSS</em>, <em>11</em>(4),
5168–5177. (<a href="https://doi.org/10.1109/TCSS.2023.3291539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technological evolution has enabled the development of new artificial intelligence (AI) models with generative capabilities. Among them, one of the most discussed is the virtual agent ChatGPT. This chatbot may occasionally produce fake information, as also declared by the producer OpenAI. Such a model may provide very useful support in several tasks, ranging from text summarization to programming. The research community has marginally investigated the impact that fake information created by AI models has on the users’ perceptions and on their belief in AI. We analyzed the impact of the fake information produced by AI on user perceptions, specifically trust and satisfaction, by performing a user study on ChatGPT. An additional issue is assessing whether the early or late knowledge of the possibility of the tool generating fake information has a different impact on the users’ perceptions. We conducted an experiment, involving 62 university students, a category of users who may employ tools such as ChatGPT extensively. The experiment consisted of a guided interaction with ChatGPT. Some of the participants experienced the failure of the chatbot, while a control group only received correct and reliable answers. We collected participants’ perceptions of trust, satisfaction, and usability, together with the net promoter score (NPS). The results demonstrated a statistically significant difference in trust and satisfaction between the users who early experienced fake information production compared to those who discovered ChatGPT’s faulty behaviors later during the interaction. Also, there is no statistically significant difference among the users who received the late fake information and the control group (no fake information). Usability and the NPS also resulted higher when the fake news was detected in the late interaction. When users are aware of the fake information generated by ChatGPT their trust and satisfaction decrease, especially when they impact on this at the early stage of use of the chatbot. Nevertheless, the perception of trust and satisfaction still remains high, as some of the users are still enthusiastic; others consider a more conscious use of the tool in terms of support to be verified. A useful strategy could be to favor a critical use of ChatGPT, letting young people to verify the provided information. This should be a new way to perform learning activities.},
  archive      = {J_TCSS},
  author       = {Ilaria Amaro and Paola Barra and Attilio Della Greca and Rita Francese and Cesare Tucci},
  doi          = {10.1109/TCSS.2023.3291539},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5168-5177},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Believe in artificial intelligence? a user study on the ChatGPT’s fake information impact},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph contrastive learning with feature augmentation for
rumor detection. <em>TCSS</em>, <em>11</em>(4), 5158–5167. (<a
href="https://doi.org/10.1109/TCSS.2023.3269303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While online social media brings convenience to people’s communication, it has also caused the widespread spread of rumors and brought great harm. Recent deep-learning approaches attempt to identify rumors by engaging in interactive user feedback. However, the performance of these models suffers from insufficient and noisy labeled data. In this article, we propose a novel rumor detection model called graph contrastive learning with feature augmentation (FAGCL), which injects noise into the feature space and learns contrastively by constructing asymmetric structures. FAGCL takes user preference and news embedding as the initial features of the rumor propagation tree and then adopts a graph attention network to update node representations. To obtain the graph-level representation for rumor classification, FAGCL fuses multiple pooling techniques. Moreover, FAGCL adopts graph contrastive learning as an auxiliary task to constrain the representation consistency. Contrastive learning on noisy data mines the supervision information of the rumor propagation tree itself, making the model more robust and effective. Results on two real-world datasets demonstrate that our proposed FAGCL model achieves significant improvements over the baseline models.},
  archive      = {J_TCSS},
  author       = {Shaohua Li and Weimin Li and Alex Munyole Luvembe and Weiqin Tong},
  doi          = {10.1109/TCSS.2023.3269303},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5158-5167},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Graph contrastive learning with feature augmentation for rumor detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fake news detection using stance extracted multimodal
fusion-based hybrid neural network. <em>TCSS</em>, <em>11</em>(4),
5146–5157. (<a href="https://doi.org/10.1109/TCSS.2023.3269087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public and governmental concerns over online rumors’ widespread diffusion and deceptive impact on social media have increased. For users to obtain accurate information and preserve social peace, finding and controlling social media rumors is challenging. Automatically, identifying fake news (FN) is a critical yet challenging topic that is still little understood because the consequences are so high. The text, visual features, the acceptance of the user’s reply, stance, and social context are a few aspects of FN that are universally acknowledged. Current research has concentrated on modifying results to one specific trait, which has been partially the reason for their success. This article proposes Fakefind, a convolutional neural network (CNN) + recurrent neural networks (RNNs) hybrid model that integrates multimodal features for efficient rumor detection (RD). Additionally, the stance is extracted from indirectly implied postreply pairs using a CNN-based knowledge extractor (KE), and the stance representations are integrated for FN detection (FND). Extensive research findings are based on three multimedia rumor datasets from Weibo, Fakeddit, and PHEME. The outcomes show how well the recommended Fakefind identifies rumors with multimodal content.},
  archive      = {J_TCSS},
  author       = {Sudhakar Sengan and Subramaniyaswamy Vairavasundaram and Logesh Ravi and Ahmad Qasim Mohammad AlHamad and Hamzah Ali Alkhazaleh and Meshal Alharbi},
  doi          = {10.1109/TCSS.2023.3269087},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5146-5157},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Fake news detection using stance extracted multimodal fusion-based hybrid neural network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A literature review on detecting, verifying, and mitigating
online misinformation. <em>TCSS</em>, <em>11</em>(4), 5119–5145. (<a
href="https://doi.org/10.1109/TCSS.2023.3289031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media use has transformed communication and made social interaction more accessible. Public microblogs allow people to share and access news through existing and social-media-created social connections and access to public news sources. These benefits also create opportunities for the spread of false information. False information online can mislead people, decrease the benefits derived from social media, and reduce trust in genuine news. We divide false information into two categories: unintentional false information, also known as misinformation; and intentionally false information, also known as disinformation and fake news. Given the increasing prevalence of misinformation, it is imperative to address its dissemination on social media platforms. This survey focuses on six key aspects related to misinformation: 1) clarify the definition of misinformation to differentiate it from intentional forms of false information; 2) categorize proposed approaches to manage misinformation into three types: detection, verification, and mitigation; 3) review the platforms and languages for which these techniques have been proposed and tested; 4) describe the specific features that are considered in each category; 5) compare public datasets created to address misinformation and categorize into prelabeled content-only datasets and those including users and their connections; and 6) survey fact-checking websites that can be used to verify the accuracy of information. This survey offers a comprehensive and unprecedented review of misinformation, integrating various methodological approaches, datasets, and content-, user-, and network-based approaches, which will undoubtedly benefit future research in this field.},
  archive      = {J_TCSS},
  author       = {Arezo Bodaghi and Ketra A. Schmitt and Pierre Watine and Benjamin C. M. Fung},
  doi          = {10.1109/TCSS.2023.3289031},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5119-5145},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A literature review on detecting, verifying, and mitigating online misinformation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toxic fake news detection and classification for combating
COVID-19 misinformation. <em>TCSS</em>, <em>11</em>(4), 5101–5118. (<a
href="https://doi.org/10.1109/TCSS.2023.3276764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of COVID-19 has led to a surge in fake news on social media, with toxic fake news having adverse effects on individuals, society, and governments. Detecting toxic fake news is crucial, but little prior research has been done in this area. This study aims to address this gap and identify toxic fake news to save time spent on examining nontoxic fake news. To achieve this, multiple datasets were collected from different online social networking platforms such as Facebook and Twitter. The latest samples were obtained by collecting data based on the topmost keywords extracted from the existing datasets. The instances were then labeled as toxic/nontoxic using toxicity analysis, and traditional machine-learning (ML) techniques such as linear support vector machine (SVM), conventional random forest (RF), and transformer-based ML techniques such as bidirectional encoder representations from transformers (BERT) were employed to design a toxic-fake news detection (FND) and classification system. As per the experiments, the linear SVM method outperformed BERT SVM, RF, and BERT RF with an accuracy of 92% and $F_{1}$ -score, $F_{2}$ -score, and $F_{0.5}$ -score of 95%, 85%, and 87%, respectively. Upon comparison, the proposed approach has either suppressed or achieved results very close to the state-of-the-art techniques in the literature by recording the best values on performance metrics such as accuracy, F1-score, precision, and recall for linear SVM. Overall, the proposed methods have shown promising results and urge further research to restrain toxic fake news. In contrast to prior research, the presented methodology leverages toxicity-oriented attributes and BERT-based sequence representations to discern toxic counterfeit news articles from nontoxic ones across social media platforms.},
  archive      = {J_TCSS},
  author       = {Mudasir Ahmad Wani and Mohammad ELAffendi and Kashish Ara Shakil and Ibrahem Mohammed Abuhaimed and Anand Nayyar and Amir Hussain and Ahmed A. Abd El-Latif},
  doi          = {10.1109/TCSS.2023.3276764},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5101-5118},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Toxic fake news detection and classification for combating COVID-19 misinformation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Do sentence-level sentiment interactions matter? Sentiment
mixed heterogeneous network for fake news detection. <em>TCSS</em>,
<em>11</em>(4), 5090–5100. (<a
href="https://doi.org/10.1109/TCSS.2023.3269090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of fake news, the spread of misleading information can easily cause social panic and group polarization. Many existing methods for detecting fake news rely on linguistic and semantic features extracted from the content of the news. Some existing approaches focus on sentiment analysis for fake news detection, but the sentiment changes and sentence-level emotional interactions in news classification are not fully analyzed. Fortunately, we observe that in long-form news, the change and mutual influence of sentiment between sentences are different. To extract the features of sentiment interaction between sentences in the article, we propose a graph attention network-based model that combines both sentiment and external knowledge comparison to meet the needs of fake news classification. We obtain the contextual sentiment representation and entity representation of the sentence through the heterogeneous network and the emotion interaction network and obtain the change of the sentiment vector through the emotion comparison network. We compare the entity vectors in the context with those corresponding knowledge base (KB)-based, combine them with the contextual semantic representation of the sentence, and finally input them into the classifier. In experiments, our model performs well in both single and multiclass classification, achieving the state-of-the-art accuracy on existing datasets.},
  archive      = {J_TCSS},
  author       = {Hao Zhang and Zonglin Li and Sanya Liu and Tao Huang and Zhouwei Ni and Jian Zhang and Zhihan Lv},
  doi          = {10.1109/TCSS.2023.3269090},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5090-5100},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Do sentence-level sentiment interactions matter? sentiment mixed heterogeneous network for fake news detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel fake news detection model for context of mixed
languages through multiscale transformer. <em>TCSS</em>, <em>11</em>(4),
5079–5089. (<a href="https://doi.org/10.1109/TCSS.2023.3298480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news detection has been a more urgent technical demand for operators of online social platforms, and the prevalence of deep learning well boosts its development. From the model structure, existing research works can be categorized into three types: convolution filtering-based neural network approaches, sequential analysis-based neural network approaches, and attention mechanism-based neural network approaches. However, almost all of them were developed oriented to scenes of a single language, without considering the context of mixed languages. To bridge such gap, this article extends to the basic pretraining language processing model transformer into the multiscale format and proposes a novel fake news detection model for the context of mixed languages through a multiscale transformer to fully capture the semantic information of the text. By extracting more fruitful feature levels of initial textual contents, it is expected to obtain more resilient feature spaces for the semantics characteristics of mixed languages. Finally, experiments are conducted on a postprocessed real-world dataset to illustrate the efficiency of the proposal by comparing performance with four baseline methods. The results obtained show that the proposed method has an accuracy of about 2%–10% higher than commonly used baseline models, indicating that the scheme has appropriate detection efficiency in mixed language scenarios.},
  archive      = {J_TCSS},
  author       = {Zhiwei Guo and Qin Zhang and Feng Ding and Xiaogang Zhu and Keping Yu},
  doi          = {10.1109/TCSS.2023.3298480},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5079-5089},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A novel fake news detection model for context of mixed languages through multiscale transformer},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural collaborative learning for user preference discovery
from biased behavior sequences. <em>TCSS</em>, <em>11</em>(4),
5068–5078. (<a href="https://doi.org/10.1109/TCSS.2023.3268682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid increase of the data of user behaviors on the Internet brings a promising chance to better discover user preferences. Recommender systems have become a popular tool for the discovery of user preferences. One key issue is how to employ user behavior sequences to develop effective sequential recommendations, especially when behavior sequences are biased. The current sequential recommendation methods either can only mine data dependencies but ignores bias or only can learn bias but cannot mine data dependencies. To solve these problems, in this article, we propose a neural collaborative sequential learning mechanism, which learns sequential information from user behavior sequences that contain bias. We propose a neural collaborative filtering (NCF) model that fully takes advantage of all data dependencies among users, items, and biased sequential behaviors. Our sequential learning mechanism employs a self-attention mechanism to learn sequential features into an embedding space and inputs this sequential embedding into the generalized matrix factorization (GMF) model and the multilayer perceptron (MLP) model. We performed experiments on two real-world datasets and compared our model with many well-known baselines. The experimental results demonstrate that our model achieves superior performance. We also give a thorough analysis through ablation experiments and sensitivity experiments.},
  archive      = {J_TCSS},
  author       = {Honghao Gao and Yinchen Wu and Yueshen Xu and Rui Li and Zhiping Jiang},
  doi          = {10.1109/TCSS.2023.3268682},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5068-5078},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Neural collaborative learning for user preference discovery from biased behavior sequences},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Defending deepfakes by saliency-aware attack. <em>TCSS</em>,
<em>11</em>(4), 5060–5067. (<a
href="https://doi.org/10.1109/TCSS.2023.3271121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of deep learning, especially the generative adversarial network (GAN), face modification has been substantially advanced and enables the generated images to look more realistic. Given an image or a video frame of a person, such a system can create fake images, which manipulates the movement, expression, and even appearance, e.g., hair color, eye color, and age. Such a system is termed Deepfake, which has raised significant ethical issues, especially for celebrities. With the pretrained Deepfake models being widely available on the Internet, its negative applications, such as face manipulation and pornographic generation, have exposed the dark side of the Deepfake technology to the sociocyber world. In this article, we aim to defend a well-trained Deepfake model by manipulating the raw image with unperceived perturbation. To minimize the alterations to the original image while effectively fooling the Deepfake model, we propose to selectively perturb only the foreground person region and maintain the irrelevant background. This is based on the observation that the salient object in a person’s image is always the foreground face region. Such a strategy introduces negligible alterations to the original image, which makes the attack remain effective. We experimentally demonstrate the superiority of the proposed attacking framework over the existing models and show our approach is ready to be applied for out-of-the-box development.},
  archive      = {J_TCSS},
  author       = {Qilei Li and Mingliang Gao and Guisheng Zhang and Wenzhe Zhai},
  doi          = {10.1109/TCSS.2023.3271121},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5060-5067},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Defending deepfakes by saliency-aware attack},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection and analysis of fake news users’ communities in
social media. <em>TCSS</em>, <em>11</em>(4), 5050–5059. (<a
href="https://doi.org/10.1109/TCSS.2023.3282572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of social media platforms has led to an increase in the dissemination of fake news with the intention of manipulating public opinion and causing chaos and panic among the population. To address this issue, we focus on detecting the organized groups that participate together in fake news campaigns without prior knowledge of the news content or the profiles of social accounts. To this end, we propose a spatial–temporal similarity graph, a novel graph structure that connects social accounts that participate in the early stage of similar fake news campaigns. A community detection algorithm is applied on the similarity graph to cluster the users into communities. We propose a community labeling algorithm to label the communities as benign or malicious based on the output of a fake news classifier. Evaluation results show that the community labeling algorithm can correctly label the communities with an accuracy of 99.61%. In addition, we perform a statistical comparison analysis to identify the structural community features that are statistically significant between benign and malicious communities.},
  archive      = {J_TCSS},
  author       = {Abdelouahab Amira and Abdelouahid Derhab and Samir Hadjar and Mustapha Merazka and Md. Golam Rabiul Alam and Mohammad Mehedi Hassan},
  doi          = {10.1109/TCSS.2023.3282572},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5050-5059},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Detection and analysis of fake news users’ communities in social media},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). How information manipulation on social media influences the
NFT investors’ behavior: A case study of goblintown.wtf. <em>TCSS</em>,
<em>11</em>(4), 5038–5049. (<a
href="https://doi.org/10.1109/TCSS.2023.3234183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People favor nonfungible token (NFT) because of the attribute to prove digital assets’ ownership and promote interactions. Investors are keen to buy and use NFT pictures as social media avatars and participate in online communities around NFT collections. However, information manipulation in the NFT market has led to investors significant losses. Our work explored a way to correspond social media accounts with Ethereum addresses and studied the microstructure of NFT market. Taking Goblintown.wtf as an example, we analyzed the participants, mechanism, and impact of Twitter information manipulation in the market. We found five categories of investors in the NFT market under information manipulation: primary investors, amateur investors, fanatic investors, short-term rational investors, and long-term rational investors. We argue that investors will consume their limited attention more likely when joining NFT online communities. This will lead to more complicated for them to make investment decisions rationally.},
  archive      = {J_TCSS},
  author       = {Hongzhou Chen and Wei Cai},
  doi          = {10.1109/TCSS.2023.3234183},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5038-5049},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {How information manipulation on social media influences the NFT investors’ behavior: A case study of Goblintown.Wtf},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hateful sentiment detection in real-time tweets: An
LSTM-based comparative approach. <em>TCSS</em>, <em>11</em>(4),
5028–5037. (<a href="https://doi.org/10.1109/TCSS.2023.3260217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is undeniable that social media has improved our lives in many ways, like allowing interactions with others all over the world and network expansion for businesses. However, there are detrimental effects of such accessibility, including the rapid spread of hate through offensive messages typically directed toward gender, religion, race, and disability, which can cause psychological harm. To address this problem of social media, many researchers have recently proposed various algorithms powered by machine learning (ML) and deep learning for the detection of hate speech. This work proposes a hate speech detection model based on long-short term memory (LSTM), using term frequency inverse document frequency (TF-IDF) vectorization, and makes comparisons with support vector machine (SVM), Naïve Bayes (NB), logistic regression (LR), XGBoost (XGB), random forest (RF), $K$ -nearest neighbor ( $k$ -NN), artificial neural network (ANN), and bidirectional encoder representations from transformers (BERT) models. To validate and authenticate our proposed work, we obtained and classified a real-time Twitter data stream of a trending topic using Twitter API into two classes: hate speech and nonhate speech. The precision, recall, and $F1$ score achieved by LSTM are 0.98, 0.99, and 0.98, respectively. The accuracy of LSTM for detecting hateful sentiment was found to be 97%, surpassing the accuracy of other models.},
  archive      = {J_TCSS},
  author       = {Sanjiban Sekhar Roy and Akash Roy and Pijush Samui and Mostafa Gandomi and Amir H. Gandomi},
  doi          = {10.1109/TCSS.2023.3260217},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5028-5037},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Hateful sentiment detection in real-time tweets: An LSTM-based comparative approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ETMA: Efficient transformer-based multilevel attention
framework for multimodal fake news detection. <em>TCSS</em>,
<em>11</em>(4), 5015–5027. (<a
href="https://doi.org/10.1109/TCSS.2023.3255242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this new digital era, social media has created a severe impact on the lives of people. In recent times, fake news content on social media has become one of the major challenging problems for society. The dissemination of fabricated and false news articles includes multimodal data in the form of text and images. The previous methods have mainly focused on unimodal analysis. Moreover, for multimodal analysis, researchers fail to keep the unique characteristics corresponding to each modality. This article aims to overcome these limitations by proposing an efficient transformer-based multilevel attention (ETMA) framework for multimodal fake news detection, which comprises the following components: a visual attention-based encoder, a textual attention-based encoder, and joint attention-based learning. Each component utilizes different forms of attention mechanisms and uniquely deals with multimodal data to detect fraudulent content. The efficacy of the proposed network is validated by conducting several experiments on four real-world fake news datasets: Twitter, Jruvika fake news dataset, Pontes fake news dataset, and Risdal fake news dataset using multiple evaluation metrics. The results show that the proposed method outperforms the baseline methods on all four datasets. Furthermore, the computation time of the model is also lower than the state-of-the-art methods.},
  archive      = {J_TCSS},
  author       = {Ashima Yadav and Shivani Gaba and Haneef Khan and Ishan Budhiraja and Akansha Singh and Krishna Kant Singh},
  doi          = {10.1109/TCSS.2023.3255242},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5015-5027},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {ETMA: Efficient transformer-based multilevel attention framework for multimodal fake news detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FIND: Privacy-enhanced federated learning for intelligent
fake news detection. <em>TCSS</em>, <em>11</em>(4), 5005–5014. (<a
href="https://doi.org/10.1109/TCSS.2023.3304649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development and popularity of social networks have made information dissemination unprecedentedly convenient and speedy. However, the spread of fake news can often cause serious harm to society and individuals. Therefore, machine learning-based fake news detection methods have become increasingly important. The existing work often needs to collect sufficient user-side data for training, which also boosts the privacy leakage risk to the users. Therefore, this article proposes an intelligent fake news detection system based on federated learning (FL) called FIND, which can train a global model while keeping user data locally. At the same time, we also designed a sparsified update perturbation method to enhance the system security further. Finally, we conduct simulation experiments to study and discuss multiple acoustic factors and prove the feasibility of our system in terms of accuracy, security, and efficiency.},
  archive      = {J_TCSS},
  author       = {Zhuotao Lian and Chen Zhang and Chunhua Su and Fayaz Ali Dharejo and Mutiq Almutiq and Muhammad Hammad Memon},
  doi          = {10.1109/TCSS.2023.3304649},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {5005-5014},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {FIND: Privacy-enhanced federated learning for intelligent fake news detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding large-scale network effects in detecting
review spammers. <em>TCSS</em>, <em>11</em>(4), 4994–5004. (<a
href="https://doi.org/10.1109/TCSS.2023.3243139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opinion spam detection is a challenge for online review systems and social forum operators. Opinion spamming costs businesses and people money since it deceives customers as well as automated opinion mining and sentiment analysis systems by bestowing undeserved positive opinions on target firms and/or bestowing fake negative opinions on others. One popular detection approach is to model a review system as a network of users, products, and reviews, for example using review graph models. In this article, we study the effects of network scale on network-based review spammer detection models, specifically on the trust model and the SpammerRank model. We then evaluate both network models using two large publicly available review datasets, namely: the Amazon dataset (containing 6 million reviews by more than 2 million reviewers) and the UCSD dataset (containing over 82 million reviews by 21 million reviewers). It has been observed that SpammerRank model provides a better scaling time for applications requiring reviewer indicators and in case of trust model distributions are flattening out indicating variance of reviews with respect to spamming. Detailed observations on the scaling effects of these models are reported in the result section.},
  archive      = {J_TCSS},
  author       = {Jitendra Kumar Rout and Kshira Sagar Sahoo and Anmol Dalmia and Sambit Bakshi and Muhammad Bilal and Houbing Song},
  doi          = {10.1109/TCSS.2023.3243139},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4994-5004},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Understanding large-scale network effects in detecting review spammers},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attack risk analysis in data anonymization in internet of
things. <em>TCSS</em>, <em>11</em>(4), 4986–4993. (<a
href="https://doi.org/10.1109/TCSS.2023.3243089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An enormous volume of data is generated in the Internet of Things (IoT), which needs to be anonymized before sharing with public or third parties to minimize reidentification risk and protect sensitive information. Data anonymization techniques can remove information capable of identifying individuals. However, inappropriate data anonymization can increase the risk of reidentification. This work focuses on potential attack risks of anonymized data by evaluating the potential attack risks. Specifically, we analyzed the attack risks over anonymized data with both randomization and generalization techniques. We also analyzed the risk of reidentification for five commonly used data anonymization techniques. The experimental results demonstrate that the proposed solution can well evaluate the potential attack risks.},
  archive      = {J_TCSS},
  author       = {Tianli Yang and Li Shan Cang and Muddesar Iqbal and Dhafer Almakhles},
  doi          = {10.1109/TCSS.2023.3243089},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4986-4993},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Attack risk analysis in data anonymization in internet of things},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-assisted deep NLP-based approach for prediction of fake
news from social media users. <em>TCSS</em>, <em>11</em>(4), 4975–4985.
(<a href="https://doi.org/10.1109/TCSS.2023.3259480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networking websites are now considered to be the best platforms for the dissemination of news articles. However, information sharing in social media platforms leads to explosion of fake news. Traditional detection methods were focusing on content analysis, while the current researchers examining social features of the news. In this work, we proposed a novel artificial intelligence (AI)-assisted fake news detection with deep natural language processing (NLP) model. The proposed work is characterized in four layers: publisher layer, social media networking layer, enabled edge layer, and cloud layer. In this work, four steps were carried out: 1) data acquisition; 2) information retrieval (IR); 3) NLP-based data processing and feature extraction; and 4) deep learning-based classification model that classifies news articles as fake or real using credibility score of publishers, users, messages, headlines, and so on. Three datasets, such as Buzzface, FakeNewsNet, and Twitter, were used for evaluation of the proposed model, and simulation results were computed. This proposed model obtained an average accuracy of 99.72% and an $F1$ score of 98.33%, which outperforms other existing methods.},
  archive      = {J_TCSS},
  author       = {Ganesh Gopal Devarajan and Senthil Murugan Nagarajan and Sardar Irfanullah Amanullah and S. A. Sahaaya Arul Mary and Ali Kashif Bashir},
  doi          = {10.1109/TCSS.2023.3259480},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4975-4985},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {AI-assisted deep NLP-based approach for prediction of fake news from social media users},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OptNet-fake: Fake news detection in socio-cyber platforms
using grasshopper optimization and deep neural network. <em>TCSS</em>,
<em>11</em>(4), 4965–4974. (<a
href="https://doi.org/10.1109/TCSS.2023.3246479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exposure to half-truths or lies has the potential to undermine democracies, polarize public opinion, and promote violent extremism. Identifying the veracity of fake news is a challenging task in distributed and disparate cyber-socio platforms. To enhance the trustworthiness of news on these platforms, in this article, we put forward a fake news detection model, OptNet-Fake. The proposed model is architecturally a hybrid that uses a meta-heuristic algorithm to select features based on usefulness and trains a deep neural network to detect fake news in social media. The $d$ -D feature vectors for the textual data are initially extracted using the term frequency inverse document frequency (TF-IDF) weighting technique. The extracted features are then directed to a modified grasshopper optimization (MGO) algorithm, which selects the most salient features in the text. The selected features are then fed to various convolutional neural networks (CNNs) with different filter sizes to process them and obtain the $n$ -gram features from the text. These extracted features are finally concatenated for the detection of fake news. The results are evaluated for four real-world fake news datasets using standard evaluation metrics. A comparison with different meta-heuristic algorithms and recent fake news detection methods is also done. The results distinctly endorse the superior performance of the proposed OptNet-Fake model over contemporary models across various datasets.},
  archive      = {J_TCSS},
  author       = {Sanjay Kumar and Akshi Kumar and Abhishek Mallik and Rishi Ranjan Singh},
  doi          = {10.1109/TCSS.2023.3246479},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4965-4974},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {OptNet-fake: Fake news detection in socio-cyber platforms using grasshopper optimization and deep neural network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dark-side avoidance of mobile applications with data biases
elimination in socio-cyber world. <em>TCSS</em>, <em>11</em>(4),
4955–4964. (<a href="https://doi.org/10.1109/TCSS.2023.3264696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accessibility of mobile apps takes into account the rights and interests of various social groups, which is vital for the millions of smartphone users who are visually impaired given the variety of mobile applications available on Google Play and the App Store. Most application icons, however, lack natural language labels. It is challenging for these users to engage with mobile phones utilizing screen readers featured in mobile operating systems. Millions of visually impaired smartphone Internet users’ inability to communicate with mobile applications have become the socio-cyber world’s dark side. COALA is a pilot work that solves this issue by generating the textual label from the imaging icon automatically. However, most icon datasets have imbalance distributions in the real-world scenario that only a few categories have rich-resource labeled samples, and the major rest categories have very limited samples. To address the data imbalance problem in the icon label generation task, we provide an interconnected two-stream language model with mean teacher learning, which learns a generalized feature representation from divergent data distributions. Extensive experiments demonstrate the superiority of our two-stream language model over previous single-language models on different low-resource datasets. More experimental results reveal that our method outperforms the COALA model by a wide margin in decreasing the dark side of the socio-cyber world.},
  archive      = {J_TCSS},
  author       = {Ying Ma and Chuyi Yu and Ming Yan and Arun Kumar Sangaiah and Youke Wu},
  doi          = {10.1109/TCSS.2023.3264696},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4955-4964},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Dark-side avoidance of mobile applications with data biases elimination in socio-cyber world},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The adaptation of concept drift: A fit prediction algorithm
based on local optimum. <em>TCSS</em>, <em>11</em>(4), 4944–4954. (<a
href="https://doi.org/10.1109/TCSS.2023.3264594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Internet industry, the learning methods based on data stream have attracted more and more attention owing to their great application value in many industries such as banking, insurance, and telecom industry. In the process of learning from stream data, one of the most significant challenges is how to adapt to the so-called concept drift which means that the data stream distribution changes over time in unpredictable ways. To deal with the problem, some methods have been put forward. However, most of them pay more attention to the whole entity of a given model and overlook the impact of local data on the model. In this article, we propose a novel ensemble algorithm to overcome the problem of ignoring local samples in previous methods, namely, the fit prediction algorithm based on local optimum (FPLO) which uses the information of local data to fit (predict) a concept drift. Furthermore, an adaptive method based on the so-called concept changing rate is proposed to choose those classifiers of suitable sizes to overcome the problem of selecting too much or too little historical drift information in previous methods and to make the prediction more accurate. The experimental results on nine synthetic stream datasets and eight real-world stream datasets which all have the concept drift problem show that our FPLO is able to tackle the problem more effectively in comparison to other state-of-the-art methods.},
  archive      = {J_TCSS},
  author       = {Qian Zhang and Guanjun Liu and Changjun Jiang},
  doi          = {10.1109/TCSS.2023.3264594},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4944-4954},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {The adaptation of concept drift: A fit prediction algorithm based on local optimum},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CDRec-CAS: Cross-domain recommendation using context-aware
sequences. <em>TCSS</em>, <em>11</em>(4), 4934–4943. (<a
href="https://doi.org/10.1109/TCSS.2022.3233781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender Systems (RSs) are a subclass of information filtering systems. RSs assist users in choosing interesting items from an extensive collection of items. This article addresses two research topics in RS, namely cross-domain RSs (CDRSs) and the context-aware RSs (CARSs). CDRSs were developed to improve the quality of recommendations in a target domain using the source domain information. Moreover, CDRSs look to limit the spread of fake information through RSs. CARSs are designed to utilize contextual information, such as location, time, companions, and others, in the recommendation as user interests change with context. In this work, CDRSs and CARSs are implemented in an integrated manner to construct a more specific RS that offers both these systems’ advantages. For including contextual information in data, contextual prefiltering is applied. These approaches recommend items more accurately, overcoming cold start, sparsity, and scalability issues, and provide a more personalized, novel, and diversified recommendation. The developed system, cross-domain recommendation using context-aware sequences (CDRec-CAS), is evaluated in terms of accuracy achieved in recommending preferred item sequences and the next preferred item. In recommending preferred item sequences, it is found that it improves recommendation accuracy that varied from approximately 7.85%–9.74% (considering the single context) and 4.41%–8.17% (considering dual-context) when compared with existing noncontextual RS. In recommending the next preferred item, it is found that it improves recommendation accuracy that varied from approximately 3.81%–9.81% (considering the single context) −2.24%–9.21% (considering dual-context) when compared with existing noncontextual RS. The results obtained by implementing CDRec-CAS are compared with existing approaches, proving that recommendations can be enhanced using cross-domain and contextual information.},
  archive      = {J_TCSS},
  author       = {Taushif Anwar and V. Uma and Gautam Srivastava},
  doi          = {10.1109/TCSS.2022.3233781},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4934-4943},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {CDRec-CAS: Cross-domain recommendation using context-aware sequences},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-modal attention network for detecting multimodal
misinformation from multiple platforms. <em>TCSS</em>, <em>11</em>(4),
4920–4933. (<a href="https://doi.org/10.1109/TCSS.2024.3373661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Misinformation detection in short videos on social media has become a pressing issue due to its popularity. However, datasets for misinformation detection are limited in terms of modality and sources, hindering the development of effective detection methods. In this article, we introduce a novel dataset denoted the multiplatform multimodal misinformation (3M) dataset. Our dataset is collected specifically to investigate and address misinformation in a multimodal context. A total of 17 352 videos were collected from two prominent social media platforms, namely TikTok and Weibo. The 3M dataset covers 30 different topics, such as sports, health, news, and art, providing a diverse range of content for analysis. We propose a novel approach named cross-modal attention misinformation detection (CAMD) for effectively detecting and addressing multimodal misinformation. CAMD leverages the cross-modal attention module to facilitate effective information exchange and fusion between modalities by learning the correlations and weights among them. The cross-modal attention module is capable of learning multilevel modality correlations, focuses primarily on the interaction between multimodal sequences across different time steps, and simultaneously adjusts the information from the source modality based on the information of the target modality. Extensive experiments on the 3M dataset show that the proposed method achieves state-of-the-art performance. Specifically, CAMD achieves accuracy, F1-score, precision, and recall values of 76.86%, 58.05%, 87.86%, and 58.70%, respectively, on the 3M dataset.},
  archive      = {J_TCSS},
  author       = {Zhiwei Guo and Yang Li and Zhenguo Yang and Xiaoping Li and Lap-Kei Lee and Qing Li and Wenyin Liu},
  doi          = {10.1109/TCSS.2024.3373661},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4920-4933},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Cross-modal attention network for detecting multimodal misinformation from multiple platforms},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing temporal knowledge graph alignment in news domain
with box embedding. <em>TCSS</em>, <em>11</em>(4), 4909–4919. (<a
href="https://doi.org/10.1109/TCSS.2023.3243240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many fields, such as social networks and recommendation systems with high time requirements, fake news and false information are often released in real time, impacting on people’s daily life. Entity alignment (EA) in temporal knowledge graph (TKG) can fuse the information contained in entities by finding equivalent entities, thus helping to determine the regular pattern of disinformation under time change. The existing methods either ignore the use of temporal attributes’ information and structural information or the modeling of that is insufficient, which has become a major obstacle to the further and wider application of TKG EA. In this article, we put forward a new idea of training for the processing of time attributes and relational structure information, to further enhance the ability in the EA process of TKGs. By forming box embedding matrix and name embedding matrix, and adaptively fusing the above information, we propose a new TKG EA solution. We carry out comparative experiments on standard news media and social media datasets collected from the real world, which validates the effectiveness of our proposal.},
  archive      = {J_TCSS},
  author       = {Bingchen Liu and Shihao Hou and Weiyi Zhong and Xiaoran Zhao and Yuwen Liu and Yihong Yang and Shijun Liu and Li Pan},
  doi          = {10.1109/TCSS.2023.3243240},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4909-4919},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Enhancing temporal knowledge graph alignment in news domain with box embedding},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A trust-aware and authentication-based collaborative method
for resource management of cloud-edge computing in social internet of
things. <em>TCSS</em>, <em>11</em>(4), 4899–4908. (<a
href="https://doi.org/10.1109/TCSS.2023.3241020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Social Internet of Things (S-IoT) paradigm is focused on topic of the Internet of Things (IoT), which accelerates the object issues by working with the concept of social networks. Searching and finding a new object in the community are considered to manage the number of friends and complex relationships between them and affect the ability to navigate at the cloud-edge layer, and resources, such as battery lifetime of S-IoT devices and energy resources, are important challenges in this field. In the processing of social messages of remote devices, increasing the battery life of devices that require such requirements plays the most important role. In this research, a collaboration scenario is presented to consider object attributes, friend’s functions and intelligent friend selection among objects for group messaging. First, a general reference model is designed and presented to select a friend to access group message remote processing services and minimize cloud-edge resources. The simulation results show that, for the correct communication of friends at the edge of the network and in each service discovery, according to the length of the path in the network, it is possible to establish stable communication and make better service with the least possible. The results show that if we want to develop a method for friendship between objects in communication in cloud computing, the proposed method can greatly improve the effectiveness of providing reliable message processing types.},
  archive      = {J_TCSS},
  author       = {Alireza Souri and Yanlei Zhao and Mingliang Gao and Asghar Mohammadian and Jin Shen and Eyhab Al-Masri},
  doi          = {10.1109/TCSS.2023.3241020},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4899-4908},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A trust-aware and authentication-based collaborative method for resource management of cloud-edge computing in social internet of things},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tensor factorization with sparse and graph regularization
for fake news detection on social networks. <em>TCSS</em>,
<em>11</em>(4), 4888–4898. (<a
href="https://doi.org/10.1109/TCSS.2023.3296479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media has a significant influence, which greatly facilitates people to stay up-to-date with information. Unfortunately, a great deal of fake news on social media misleads people and causes a lot of losses. Therefore, fake news detection is necessary to address this issue. Recently, social content category-based methods have become a crucial component of fake news detection. Different from news context-based category, which focuses on word embedding, it tends to explore the potential relationships and structures between users and news. In this article, a third-order tensor, which obtains massive information and connections, is constructed by the social links and engagements of social networks. Then, a sparse and graph-regularized CANDECOMP/PARAFAC (SGCP) tensor decomposition learning method is proposed for fake news detection on social network. In SGCP, a news factor matrix is constructed by CP decomposition of the tensor, which reflects the complex connections among users and news. Furthermore, SGCP retains sparsity of the news factor matrix and preserves the manifold structures from the original space. In addition, an efficient optimization algorithm, which is proven to be monotonically nonincreasing, is proposed to solve SGCP. Finally, abundant experiments are conducted on real-world datasets and demonstrate the effectiveness of the proposed SGCP.},
  archive      = {J_TCSS},
  author       = {Hangjun Che and Baicheng Pan and Man-Fai Leung and Yuting Cao and Zheng Yan},
  doi          = {10.1109/TCSS.2023.3296479},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4888-4898},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Tensor factorization with sparse and graph regularization for fake news detection on social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding the use and abuse of social media: Generalized
fake news detection with a multichannel deep neural network.
<em>TCSS</em>, <em>11</em>(4), 4878–4887. (<a
href="https://doi.org/10.1109/TCSS.2022.3221811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news has spread across social media platforms and with the ease of access, negative consequences have come with it on individuals and society. This issue has become a focus of interest among various research communities, including artificial intelligence (AI) researchers. Existing AI-based fake news detection techniques primarily make use of a 1-D convolutional neural network (1D-CNN) with unidirectional word embedding. We propose a multichannel deep convolutional neural network (CNN) with different kernel sizes and filters as an AI technique. Multiple embedding of the same dimension with different kernel sizes technically allows the news article to be processed at different resolutions of different n-grams at the same time. Different kernel sizes increase the learning ability of the proposed classification model. The proposed model determines how to integrate these interpretations (different n-grams) most suitably. Three real-world fake news datasets were used in experiments to validate the classification performance. The classification results showed that the proposed model has high accuracy in detecting fake news. Regardless of the dataset, the proposed model can be used for fake news detection in binary classification problems.},
  archive      = {J_TCSS},
  author       = {Rohit Kumar Kaliyar and Anurag Goswami and Pratik Narang and Vinay Chamola},
  doi          = {10.1109/TCSS.2022.3221811},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4878-4887},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Understanding the use and abuse of social media: Generalized fake news detection with a multichannel deep neural network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tweet spam detection using machine learning and swarm
optimization techniques. <em>TCSS</em>, <em>11</em>(4), 4870–4877. (<a
href="https://doi.org/10.1109/TCSS.2022.3230823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media networking platforms connect people living in every corner of the world. Twitter has now become a popular microblogging service, allowing users to express themselves and keep up with current events. Twitter has attracted spammers because to its popularity and ease of use. As a result, spam identification (ID) has become one of the most pressing issues. It is vital to detect and filter spam tweets as well as their owners in order to provide a spam-free environment. In this article, a spam detection method is proposed using a swarm optimization approach on a tweet-by-tweet basis. A spam tweet detection dataset is used to train the machine learning (ML) model. Metaheuristic features are created based on the input features in the dataset. Whale swam optimization algorithm (WOA) is used to select the important features before classification. The conventional objective function of WOA is modified into stochastic gradient descent (SGD) to perform feature selection. The selected subset of features is used to train the Adaboost (AB) classifier to detect the spam in the tweets. The AB classifier produced the best results in combination with WOA and SGD. The obtained accuracy is 99.85% in testing with a minimum subset of seven features and in the least possible minimum time of 17.9 s.},
  archive      = {J_TCSS},
  author       = {Pinnapureddy Manasa and Arun Malik and Khaled N. Alqahtani and Madani Abdu Alomar and Mohammed Salem Basingab and Mukesh Soni and Ali Rizwan and Isha Batra},
  doi          = {10.1109/TCSS.2022.3230823},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4870-4877},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Tweet spam detection using machine learning and swarm optimization techniques},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel model combining transformer and bi-LSTM for news
categorization. <em>TCSS</em>, <em>11</em>(4), 4862–4869. (<a
href="https://doi.org/10.1109/TCSS.2022.3223621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {News categorization (NC), the aim of which is to identify distinct categories of news through analyzing the contents, has acquired substantial progress since deep learning was introduced into the natural language processing (NLP) field. As a state-of-art model, transformer’s classification performance is not satisfied compared with recurrent neural network (RNN) and convolutional neural network (CNN) if it does not get pretrained. Based on the transformer model, this article proposes a novel framework that combines bidirectional long short-term memory (Bi-LSTM) network and transformer to solve this problem. In the suggested framework, the self-attention mechanism is substituted with Bi-LSTM to capture the semantic information from sentences. Meanwhile, an attention mechanism model is applied to focus on those important words and adjust their weights to solve the problem of long-distance information loss. With pooling network, the network complexity can be reduced and the main features can be highlighted by halving the dimension of the hidden state. Finally, after acquiring the hidden representation by the above structures, we utilize a contraction network to further capture the long-range associations from a text. Experiments on three large-scale corpora were performed to evaluate the suggested framework, and the results demonstrate that our model outperforms other models such as deep pyramid CNN (DPCNN), transformer.},
  archive      = {J_TCSS},
  author       = {Yuanzhi Liu and Min He and Mengjia Shi and Seunggil Jeon},
  doi          = {10.1109/TCSS.2022.3223621},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4862-4869},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A novel model combining transformer and bi-LSTM for news categorization},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multirelational collaborative filtering for global graph
neural networks to mine evolutional social relations. <em>TCSS</em>,
<em>11</em>(4), 4851–4861. (<a
href="https://doi.org/10.1109/TCSS.2022.3229400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the unstable and complex social network environment, the sole user–item interaction data become insufficient for generating precise recommendations. However, too much emphasis on user–item interactions prevents the discovery of internal connections among them, such as trustworthy user relations. In this work, we have integrated the collaborative and the sequential relations into an end-to-end graph neural network (GNN) simultaneously and proposed a novel framework, namely multirelational collaborative filtering (MRCF), to explore the evolutional social relations. MRCF mainly consists of two components: relational GNN (RGNN) and simple dot-product attention (SDPA), where RGNN is used to capture not only the collaborative but also the sequential relationship from reliable user–item historical interactions through the graph representation, while SDPA can further concentrate on the dominated interaction sequences between users and items. Moreover, a negative sampling method based on user interest is proposed to help train our model. Extensive experiments on three real-world datasets show that the proposed model performs competitively with other state-of-the-art methods in CF.},
  archive      = {J_TCSS},
  author       = {Xiaoheng Deng and Ping Jiang and Xuechen Chen},
  doi          = {10.1109/TCSS.2022.3229400},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4851-4861},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Multirelational collaborative filtering for global graph neural networks to mine evolutional social relations},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fake news detection using enhanced BERT. <em>TCSS</em>,
<em>11</em>(4), 4843–4850. (<a
href="https://doi.org/10.1109/TCSS.2022.3223786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since there are so many users on social media, who are not qualified to report news, fake news has become a major problem in recent years. Therefore, it is crucial to identify and restrict the dissemination of false information. Numerous deep learning models that make use of natural language processing have yielded excellent results in the detection of fake news. bidirectional encoder representations from transformers (BERT), based on transfer learning, is one of the most advanced models. In this work, the researchers have compared the earlier studies that employed baseline models versus the research articles where the researchers used a pretrained model BERT for the detection of fake news. The literature analysis revealed that utilizing pretrained algorithms is more effective at identifying fake news because it takes less time to train them and yields better results. Based on the results noted in this article, the researchers have advised the utilization of pretrained models that have already been taught to take advantage of transfer learning, which shortens training time and enables the use of large datasets, as well as a reputable model that performs well in terms of precision, recall, as well as the minimum number of false positive and false negative outputs. As a result, the researchers created an improved BERT model, while considering fine-tuning it to meet the demands of the fake news identification assignment. To obtain the most accurate representation of the input text, the final layer of this model is also unfrozen and trained on news texts. The dataset used in the study included 23502 articles of fake news and 21417 items of actual news. This dataset was downloaded from the Kaggle website. The results of this study demonstrated that the proposed model showed a better performance compared with other models, and achieved 99.96% and 99.96% in terms of accuracy and $F1$ score, respectively.},
  archive      = {J_TCSS},
  author       = {Shadi A. Aljawarneh and Safa Ahmad Swedat},
  doi          = {10.1109/TCSS.2022.3223786},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4843-4850},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Fake news detection using enhanced BERT},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fake news in virtual community, virtual society, and
metaverse: A survey. <em>TCSS</em>, <em>11</em>(4), 4828–4842. (<a
href="https://doi.org/10.1109/TCSS.2022.3220420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the trend of the accelerated progression of communication network technology, the emergence of virtual communities (VCs), virtual societies (VSs), metaverse, and other technologies not only makes data access and sharing easier but also leads to the proliferation of fake news (FN). To effectively monitor and identify FN in VC, VS, and metaverse, and to create a safer virtual space, this work takes FN in VC, VS, and metaverse as objects. First, the content and display methods of FN are reviewed and explained, and it is understood that FN is mainly displayed by single-modal and multimodal representations. Second, the application scenarios in many important fields such as transportation are reviewed and analyzed, so as to further understand the impact and detection effect of FN in different scenarios. Finally, an intelligent outlook and summary analysis are carried out on the detection and information security of FN, which provides theoretical reference and new opportunities for the detection and identification of FN in the virtual cyberspace.},
  archive      = {J_TCSS},
  author       = {Jinxia Wang and Stanislav Makowski and Alan Cieślik and Haibin Lv and Zhihan Lv},
  doi          = {10.1109/TCSS.2022.3220420},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4828-4842},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Fake news in virtual community, virtual society, and metaverse: A survey},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autoencoder-based feature extraction for identifying hate
speech spreaders in social media. <em>TCSS</em>, <em>11</em>(4),
4819–4827. (<a href="https://doi.org/10.1109/TCSS.2023.3240098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hate speech on social media has become a big problem, making regular users very upset and giving victims depression and suicidal thoughts. Early identification of the user spreading this type of hate speech may be a better solution, allowing hate speech to be stopped at source. In this article, we attempt to identify these hate speech spreaders by finding a representation for each user. Each user’s comments are aggregated and fed to an auto-encoder to train it. The encoder part of the auto-encoder is used to get an encoded vector for each user. The encoded vector is used with different machine learning (ML) classifiers to determine if a user is spreading hate speech. The proposed model was tested using the dataset released by PAN 2021 ( https://pan.webis.de/data.html ) hate speech spreader profiling competition in English and Spanish. The experimental results show that support vector machine (SVM) with encoded vectors as features outperforms existing models with an accuracy of 92% for both English and Spanish dataset. The proposed features extraction technique is found to be equally effective at identifying fake news spreaders on fake news datasets provided by PAN 2020 yielding accuracy values of 95% and 83% for English and Spanish, respectively.},
  archive      = {J_TCSS},
  author       = {Gunjan Kumar and Jyoti Prakash Singh and Amit Kumar Singh},
  doi          = {10.1109/TCSS.2023.3240098},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4819-4827},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Autoencoder-based feature extraction for identifying hate speech spreaders in social media},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Securing the socio-cyber world: Multiorder attribute node
association classification for manipulated media. <em>TCSS</em>,
<em>11</em>(4), 4809–4818. (<a
href="https://doi.org/10.1109/TCSS.2022.3213832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information technology, social network has become an indispensable part of daily life. People have been able to get news from all over the world through social networks for a long time. People spend more time online than they do in real life. However, the information we get in the world of social network is not purely benign. Due to the development of artificial intelligence technology, more and more tampered media information appears in social networks, some for entertainment, while others become the dark side of social networks, of which the most harmful is to people in the media tamper. For fake news and misinformation caused by media tampering, we need to trace the source and clearly distinguish the truth from the manipulated. This article proposes an image media forgery classification method of multiorder attribute nodes. First, we use different methods to extract the edge, texture, grayscale, and color attributes of the image. Second, according to the characteristics of different attributes, we calculate the first-order entropy of edge attributes, the second-order entropy of texture attributes, local entropy of grayscale, and color properties. Finally, we represent each image with some nodes and build a graph convolutional network (GCN) to classify real and fake images. Experimental results on mainstream media manipulation datasets show that our method is the state-of-the-art compared with similar methods.},
  archive      = {J_TCSS},
  author       = {Shuai Xiao and Guipeng Lan and Jiachen Yang and Yang Li and Jiabao Wen},
  doi          = {10.1109/TCSS.2022.3213832},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4809-4818},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Securing the socio-cyber world: Multiorder attribute node association classification for manipulated media},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discovering the correlation between phishing susceptibility
causing data biases and big five personality traits using c-GAN.
<em>TCSS</em>, <em>11</em>(4), 4800–4808. (<a
href="https://doi.org/10.1109/TCSS.2022.3201153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, on social media, various kinds of social engineering (SE) have made individuals more susceptible to attacks. A phishing attempt is a widely used SE technique that takes advantage of people’s vulnerabilities to acquire personal or confidential information. These attempts are growing at an astonishing speed, causing harm to both individuals and corporations. According to the latest studies, certain individuals are more vulnerable to such kinds of attacks than others. However, the relationship between psychological characteristics and phishing attacks has not been adequately investigated. This study empirically explores the connection between phishing vulnerability that causes data biases and the Big Five personality traits. Recognizing personality traits that make people more vulnerable to phishing attempts is a key step in developing protection and safeguarding individuals. The individuals who scored high in some traits are more probable to suffer from such assault. To the best of our knowledge, no prior quantitative study has attempted to find many genuine phishing victims and their personality behavior. This problem lacks the availability of publically accessible data. It is also challenging to estimate the probability distribution of rows in tabular data and generate realistic synthetic data to train/test the model on more data. This work employs a conditional generative adversarial network (C-GAN) for both data generation and classification to find the correlation between personality traits and phishing attacks.},
  archive      = {J_TCSS},
  author       = {Atta Ur Rahman and Feras Al-Obeidat and Abdallah Tubaishat and Babar Shah and Sajid Anwar and Zahid Halim},
  doi          = {10.1109/TCSS.2022.3201153},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4800-4808},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Discovering the correlation between phishing susceptibility causing data biases and big five personality traits using C-GAN},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mitigating information interruptions by COVID-19 face masks:
A three-stage speech enhancement scheme. <em>TCSS</em>, <em>11</em>(4),
4790–4799. (<a href="https://doi.org/10.1109/TCSS.2022.3210988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus disease 2019 (COVID-19) preventive measures have resulted in significant lifestyle changes. One of the COVID-19 new normal is the usage of face masks for protection against airborne aerosol which creates distractions and interruptions in voice communication. It has a different influence on speech than the standard concept of noise affecting speech communication. Furthermore, it has varied effects on speech in different frequency bands. To provide a solution to this problem, a three-stage adaptive speech enhancement (SE) scheme is developed in this article. In the first stage, the tunable $Q$ -factor wavelet transform (TQWT) features are extracted by properly setting the quality factor values and the number of levels from the input speech signal. In the second stage, the adjustable parameters of the preemphasis filter and modified multiband spectral subtraction (MBSS) are determined using bio-inspired techniques for different masking and signal-to-noise ratio (SNR) conditions. In the third stage, the weights, center values, standard deviation of the Gaussian radial basis functions, and input patterns of the radial basis function neural networks (RBFNNs) are updated to predict the optimized parameters from the input TQWT-based cepstral features (TQCFs). In the end, the performance of the proposed algorithm is compared with the standard SE algorithms using two speech datasets.},
  archive      = {J_TCSS},
  author       = {Tusar Kanti Dash and Chinmay Chakraborty and Satyajit Mahapatra and Ganapati Panda},
  doi          = {10.1109/TCSS.2022.3210988},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4790-4799},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Mitigating information interruptions by COVID-19 face masks: A three-stage speech enhancement scheme},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effect of text augmentation and adversarial training on fake
news detection. <em>TCSS</em>, <em>11</em>(4), 4775–4789. (<a
href="https://doi.org/10.1109/TCSS.2023.3344597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The action of spreading false information through fake news articles presents a significant danger to society because it has the ability to shape public opinion with inaccurate facts. This can lead to negative effects, such as reduced trust in institutions and the promotion of conflict, division, and even violence. In this article, a text augmentation technique is introduced as a means of generating new data from preexisting fake news datasets. This approach has the potential to enhance classifier performance by a range of 3%–11%. It can also be utilized to launch a successful attack on trained classifiers, with up to a 90% success rate. However, the success rate of these attacks decreased to less than 28% when the model was retrained with the generated adversarial examples. These results demonstrate the effectiveness of text augmentation as a viable method for detecting fake news and increasing classifier accuracy and performance, as well as its ability to be utilized to perform adversarial machine learning (ML) and improve the resilience of ML algorithms.},
  archive      = {J_TCSS},
  author       = {Hadeer Ahmed and Issa Traore and Sherif Saad and Mohammad Mamun},
  doi          = {10.1109/TCSS.2023.3344597},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4775-4789},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Effect of text augmentation and adversarial training on fake news detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guest editorial: Special issue on dark side of the
socio-cyber world: Media manipulation, fake news, and misinformation.
<em>TCSS</em>, <em>11</em>(4), 4766–4774. (<a
href="https://doi.org/10.1109/TCSS.2024.3426788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCSS},
  author       = {Gwanggil Jeon and Xiaochun Cheng and Abdellah Chehri and Giancarlo Fortino and Marcelo Albertini and Shiping Wen},
  doi          = {10.1109/TCSS.2024.3426788},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4766-4774},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Guest editorial: special issue on dark side of the socio-cyber world: media manipulation, fake news, and misinformation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Alzheimer’s disease diagnosis via intuitionistic fuzzy
random vector functional link network. <em>TCSS</em>, <em>11</em>(4),
4754–4765. (<a href="https://doi.org/10.1109/TCSS.2022.3146974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a prominent neurodegenerative disorder, which leads to memory loss and cognitive impairment. The progression is irreversible and shows atrophies in cerebral cortex. Multiple studies revealed that the early diagnosis and early treatment can slow the progress of dementia, and hence, further atrophies can be controlled. Brain imaging data, such as magnetic resonance imaging (MRI), have been prominently used for the diagnosis of AD. Multiple approaches have been proposed for the diagnosis of AD. We propose a novel intuitionistic fuzzy random vector functional link network (IFRVFL) for the diagnosis of AD. Unlike standard random vector functional link (RVFL) network, extreme learning machine (ELM), and kernel ridge regression (KRR), which uses a uniform weighting approach for generating the optimal classifier, the proposed IFRVFL uses a fuzzy weighted approach for generating the optimal classifier. A uniform weighting scheme assumes that all the data samples are equally important; however, in real-world scenarios, this assumption may not hold true due to the presence of outliers and noise. Hence, it results in lower generalization. The proposed IFRVFL assigns each sample an intuitionistic fuzzy number (IFN), which is a function of membership and nonmembership score of a sample. The membership score is a function of the sample distance from the centroid of its corresponding class and the nonmembership score is a function of sample distance from the centroid as well as the neighborhood of the given sample. The proposed IFRVFL effectively reduces the influence of outliers. To evaluate the efficiency of the proposed IFRVFL model, we employed it for the diagnosis of AD. Experimental results demonstrate that the proposed IFRVFL model is superior in mild cognitive impairment (MCI) versus AD case. Thus, IFRVFL can be used in the clinical setting for the early diagnosis of AD. Furthermore, to check the robustness of the proposed IFRVFL model, we also evaluated it on benchmark datasets. Experimental results and the statistical tests reveal that the proposed IFRVFL is better in comparison to baseline models. The source code of the proposed IFRVFL formulation is available at https://github.com/mtanveer1/ .},
  archive      = {J_TCSS},
  author       = {A. K. Malik and M. A. Ganaie and M. Tanveer and P. N. Suganthan},
  doi          = {10.1109/TCSS.2022.3146974},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4754-4765},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Alzheimer’s disease diagnosis via intuitionistic fuzzy random vector functional link network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Extended features based random vector functional link
network for classification problem. <em>TCSS</em>, <em>11</em>(4),
4744–4753. (<a href="https://doi.org/10.1109/TCSS.2022.3187461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random vector functional link (RVFL) network has been successfully employed in diverse domains such as computer vision and machine learning, due to its universal approximation capability. Recently, the shallow RVFL architecture has been extended to deep architectures. In deep architectures, multiple hidden layers are stacked for extracting informative features from the original feature space. Therefore, having rich features, deep models are very successful compared to shallow models. In this article, we propose an extended feature RVFL (efRVFL) model that is trained over extended feature space generated analytically from the original feature space. The proposed efRVFL model has three types of features, i.e., original features, supervised randomized (newly generated) features, and unsupervised randomized features, in its feature matrix. The proposed efRVFL model with additional features has capability to capture nonlinear hidden relationships within the dataset. The proposed efRVFL model is an unstable classifier, and thus, its performance can be improved further via ensemble learning. Ensemble models are stable and accurate and have better generalization performance than single models. Therefore, we also propose an ensemble of extended feature RVFL (en-efRVFL) model. Each base model of en-efRVFL is trained over different feature spaces so that more accurate and diverse base models can be generated. The outcome of the base models is integrated via average voting scheme. Empirical evaluation over 46 UCI classification datasets demonstrates that the proposed efRVFL and en-efRVFL models have better performance than RVFL and other given deep models. Furthermore, the experimental results over 12 sparse datasets show that the proposed en-efRVFL model has a winning performance among several deep feedforward neural networks (FNNs).},
  archive      = {J_TCSS},
  author       = {Ashwani Kumar Malik and M. A. Ganaie and M. Tanveer and P. N. Suganthan},
  doi          = {10.1109/TCSS.2022.3187461},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4744-4753},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Extended features based random vector functional link network for classification problem},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Natural language processing applied to forensics information
extraction with transformers and graph visualization. <em>TCSS</em>,
<em>11</em>(4), 4727–4743. (<a
href="https://doi.org/10.1109/TCSS.2022.3159677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital forensics analysis is a slow process mainly due to the large amount and variety of data. Some forensic tools help categorize files by type and allow automatization of tasks, like named entity recognition (NER). NER is a key component in many natural language processing (NLP) applications, such as relation extraction (RE) and information retrieval. The introduction of neural networks and transformer architectures in the last few years made it possible to develop more accurate models in different languages. This work proposes a reproducible setup to build a forensic pipeline for information extraction using NLP of texts. Our results show that it is possible to develop both NER and RE models in any language and tune its hyper-parameters to achieve state-of-art performance and build comprehensive knowledge graphs, decreasing the amount of time required for human supervision and review. We also find that solving this task in phases can further improve the performance, not only for digital investigation applications, but also for general-purpose information extraction and analysis.},
  archive      = {J_TCSS},
  author       = {Fillipe Barros Rodrigues and William Ferreira Giozza and Robson de Oliveira Albuquerque and Luis Javier García Villalba},
  doi          = {10.1109/TCSS.2022.3159677},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4727-4743},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Natural language processing applied to forensics information extraction with transformers and graph visualization},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PANNER: POS-aware nested named entity recognition through
heterogeneous graph neural network. <em>TCSS</em>, <em>11</em>(4),
4718–4726. (<a href="https://doi.org/10.1109/TCSS.2022.3159366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nested named entity recognition (Nested NER) in knowledge graph (KG) aims at obtaining all meaningful entities, including nested entities for sentences in longer text region. Those obtained entities are to facilitate downstream applications, such as relation extraction, entity resolution, and coreference resolution. This task, however, is challenging not only because of the demand to detect the boundary of the entity but also due to the complexity of those hierarchically nested entities. Since a substantial amount of work has been made to Flat NER (or Nested NER), a few of them can explicitly acquire the position of the entity and utilize the grammatical construction of text. In this work, we propose PANNER, a POS-aware Nested NER model, to solve all the above issues. Specifically, we first construct a heterogeneous graph by introducing the part-of-speech (POS) information of the word. Second, we design a dilated random walk (DRW) algorithm based on a grammatical path to sample a fixed size of neighbors for each node. Third, we aggregate the message from different types of neighbors through an attention mechanism. Finally, we use a bidirectional decoding module to recognize and categorize all the flat and nested entities based on the node embedding in a layer-wise manner. Our extensive experiments show the effectiveness of PANNER in both flat and nested NER.},
  archive      = {J_TCSS},
  author       = {Ling Zhou and Jianming Li and Zhaoquan Gu and Jing Qiu and Brij B. Gupta and Zhihong Tian},
  doi          = {10.1109/TCSS.2022.3159366},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4718-4726},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {PANNER: POS-aware nested named entity recognition through heterogeneous graph neural network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the usage of neural POS taggers for shakespearean
literature in social systems. <em>TCSS</em>, <em>11</em>(4), 4707–4717.
(<a href="https://doi.org/10.1109/TCSS.2022.3191340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Part-of-speech (POS) taggers are the primary requisite of any natural language processing (NLP) mechanism. Conventional POS tagger and libraries are expert-made or static and concentrate on the literature domain. These POS taggers limit the performance of subsequent mechanisms like polarity detection, sentiment analysis, opinion mining, and so on. The unsuitability of a tagger for a new genre of literature makes famous libraries, such as Natural Language Toolkit (NLTK) and University Centre for Computer Corpus Research on Language (UCREL) Constituent Likelihood Automatic Word-tagging System Seven (CLAWS7) create the need for a neural POS tagger to serve Shakespearean literature. This article reports a preliminary study on the suitability of the neural taggers over static or manual taggers, supported by the accuracy of 97% achieved on Hamlet. Furthermore, these neural networks are scalable over the literature domains irrespective of the stylistic variations, opening up this area to computer scientists to aid literary enthusiasts in contributing to domain of the social systems.},
  archive      = {J_TCSS},
  author       = {Avinash Samantra and Pankaj Kumar Sa and Tu N. Nguyen and Arun Kumar Sangaiah and Sambit Bakshi},
  doi          = {10.1109/TCSS.2022.3191340},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4707-4717},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {On the usage of neural POS taggers for shakespearean literature in social systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advanced learning analytics: Aspect based course feedback
analysis of MOOC forums to facilitate instructors. <em>TCSS</em>,
<em>11</em>(4), 4698–4706. (<a
href="https://doi.org/10.1109/TCSS.2022.3174640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Massive Online Open Courses (MOOCs) has been noticeably increased in recent times, especially after the COVID-19 pandemic. In the absence of one-to-one interaction with the students, the instructors are no longer able to understand the demands of their students in an intrinsic way. To overcome this problem, the MOOC platforms provide a discussion forum in which students can share their thoughts and problems about the course. The instructors must closely monitor the performance of their students so that they can improve their teaching methodology to enhance the students’ understanding. The instructors must go through the long chats in the discussion forums to identify specific problem areas faced by students. In this study, we propose a method that first categorizes discussion threads into topics and subtopics with the help of topic modeling and then performs sentiment analysis on comments to identify the sentiment of the posts. The primary objective of the study is to facilitate the instructors so that they can improve their teaching methodology, thus enhancing the understanding level of the students.},
  archive      = {J_TCSS},
  author       = {Tehmina Amjad and Zainab Shaheen and Ali Daud},
  doi          = {10.1109/TCSS.2022.3174640},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4698-4706},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Advanced learning analytics: Aspect based course feedback analysis of MOOC forums to facilitate instructors},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A blockchain-enabled explainable federated learning for
securing internet-of-things-based social media 3.0 networks.
<em>TCSS</em>, <em>11</em>(4), 4681–4697. (<a
href="https://doi.org/10.1109/TCSS.2021.3134463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media (SM) 3.0 integrates SM platforms, such as Facebook and Twitter, with the Internet of Things (IoT), and has a great potential to change how we interact with mobile devices, online platforms, and the world around us. This integration with end users produces large-scale and heterogeneous data sources that demand machine learning (ML)-based data analytics for decision-making and to provide security against ML and data privacy attacks. The development of privacy-aware ML models within a federated learning (FL) ecosystem can empower an entire network to learn from data in a decentralized manner. In this article, we propose a differentially privacy blockchain-based explainable FL (DP-BFL) framework by harnessing the ever-evolving power of SM 3.0 networks. This framework permits any Internet empowered device to partake and contribute data to a global privacy preserved model. In this framework, participants will upload the differentially private local updates to the miners of blockchain, where the local updates will be evaluated and rewarded. The experimental results obtained from real-world datasets, namely, SM 3.0 and MNIST, demonstrated that the proposed framework could achieve high utility, enhanced privacy, and elevated efficiency. More Specifically, the experimental analysis of our proposed framework reveals the following two key properties. First, our proposed DP-BFL yields noticeable performance improvements in the applied learning models with high privacy and comparable utility levels, in terms of accuracy and $f$ -measure metrics, to a standard FL and centralized learning approaches under the restriction of privacy preservation. Second, given a certain number of the malicious entities, DP-BFL allowed an enhanced recognition of users’ preferences in the SM 3.0 dataset and precise prediction of images’ class in the MNIST dataset while mitigating the impact of the malicious entities’ poisoned updates. Moreover, as the proposed DP-BFL attains DP on the local model’s update, it is considered the same as the standard FL-based setting, along with some kinds of privacy preservation on the uploaded model’s updates.},
  archive      = {J_TCSS},
  author       = {Sara Salim and Benjamin Turnbull and Nour Moustafa},
  doi          = {10.1109/TCSS.2021.3134463},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4681-4697},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A blockchain-enabled explainable federated learning for securing internet-of-things-based social media 3.0 networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Employing co-learning to evaluate the explainability of
multimodal sentiment analysis. <em>TCSS</em>, <em>11</em>(4), 4673–4680.
(<a href="https://doi.org/10.1109/TCSS.2022.3176403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural nets are opaque black-box models with little to no understanding of underlying model dynamics. This issue is more prevalent in the case of multimodal artificial intelligence (AI) systems, where model explainability and interpretability are prime concerns due to data integration from heterogeneous data streams and complex inter and intramodal interactions. However, the traditional explainable models are challenging to apply in the multimodal scenario. We propose a co-learning-based solution for fostering model explainability for the natural language processing (NLP)-based multimodal sentiment analysis application to address this issue. The proposed approach employs explainability by obeying the co-learning principles of dealing with noisy and missing modality either at train or test time to find the modality dominance by extracting the local and global model explanations. The proposed approach is validated with post hoc explainability methods such as local interpretable model-agnostic explanations (LIME) and SHapley Additive exPlanations (SHAP) gradient-based explanations to model the modality contributions and interactions at the fusion level. The co-learning-based system ensures trust and robustness in the model by providing some degree of model explainability along with robustness. The kind of explanations provided is multifaceted and is obtained through a peek inside the black box, hence is specifically helpful for the system designers and model developers to understand the complex model dynamics that are far more challenging in the case of multimodal applications.},
  archive      = {J_TCSS},
  author       = {Deepak Kumar Jain and Anil Rahate and Gargi Joshi and Rahee Walambe and Ketan Kotecha},
  doi          = {10.1109/TCSS.2022.3176403},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4673-4680},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Employing co-learning to evaluate the explainability of multimodal sentiment analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid text representation for explainable suicide risk
identification on social media. <em>TCSS</em>, <em>11</em>(4),
4663–4672. (<a href="https://doi.org/10.1109/TCSS.2022.3184984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media data that characterize users can provide mental health signals, including suicide risks. Existing methods for suicide risk identification on social media have demonstrated promising results; however, the limitation of existing methods is that they are unable to capture low- and high-level features with complex structured data on social media and are incapable of explaining the predicted labels. Explainable models are more useful when translated, so we aimed to evaluate a novel method that would produce explainable models. This article presents a hybrid text representation method that integrates word and document-level text representations to explain suicide risk identification on social media. The proposed method is then fed to a transformer-based encoder with ordinal classification to determine suicide risk. Our results show that our method outperforms state-of-the-art baselines with an FScore of 0.79 (an absolute increase of 15%) on a public suicide dataset. Our method shows that an explainable model can perform at a comparable level to the best nonexplainable models but has advantages if translated for use in clinical and public health practice.},
  archive      = {J_TCSS},
  author       = {Usman Naseem and Matloob Khushi and Jinman Kim and Adam G. Dunn},
  doi          = {10.1109/TCSS.2022.3184984},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4663-4672},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Hybrid text representation for explainable suicide risk identification on social media},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting and mitigating the dissemination of fake news:
Challenges and future research opportunities. <em>TCSS</em>,
<em>11</em>(4), 4649–4662. (<a
href="https://doi.org/10.1109/TCSS.2022.3177359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news is a major threat to democracy (e.g., influencing public opinion), and its impact cannot be understated particularly in our current socially and digitally connected society. Researchers from different disciplines (e.g., computer science, political science, information science, and linguistics) have also studied the dissemination, detection, and mitigation of fake news; however, it remains challenging to detect and prevent the dissemination of fake news in practice. In addition, we emphasize the importance of designing artificial intelligence (AI)-powered systems that are capable of providing detailed, yet user-friendly, explanations of the classification / detection of fake news. Hence, in this article, we systematically survey existing state-of-the-art approaches designed to detect and mitigate the dissemination of fake news, and based on the analysis, we discuss several key challenges and present a potential future research agenda, especially incorporating AI explainable fake news credibility system.},
  archive      = {J_TCSS},
  author       = {Wajiha Shahid and Bahman Jamshidi and Saqib Hakak and Haruna Isah and Wazir Zada Khan and Muhammad Khurram Khan and Kim-Kwang Raymond Choo},
  doi          = {10.1109/TCSS.2022.3177359},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4649-4662},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Detecting and mitigating the dissemination of fake news: Challenges and future research opportunities},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CNA-TCC: Campaign network attribute based thematic campaign
classification. <em>TCSS</em>, <em>11</em>(4), 4636–4648. (<a
href="https://doi.org/10.1109/TCSS.2022.3184387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of social media and computing, many users have utilized social media platforms (SMPs) in communicating and sharing their interests and preferences. One critical challenge is that social media have been employed for propaganda and influence campaigns for various purposes, such as spreading fake news. SMPs generate vast amounts of data that demand machine learning (ML) capabilities to efficiently learn and infer influence campaigns. This study proposes an ML framework for the thematic campaign classification (TCC), assisting decision-makers in understanding the impacts of social media toward end-users and aiding the mitigation of their side effects. The proposed framework relies on a newly developed characterization that we have termed the campaign network attribute (CNA), which adopts representative network features for the effective TCC by neural networks. The proposed CNA-TCC framework was validated using Twitter and Instagram data sources. The proposed framework can achieve a classification precision in the range of 68%–90% for two campaigns. Also, it can identify a known campaign in generic social media data with a 60% precision. The empirical results indicated high-performance levels of the proposed CNA-TCC framework that can substantially reduce the search spaces for social influence campaigns on specific themes. The proposed CNA-TCC framework has the potential to be applied in real-world SMPs and to process their large-scale data, so as to effectively classify influence campaigns.},
  archive      = {J_TCSS},
  author       = {Nathan Johnson and Benjamin Turnbull and Martin Reisslein and Nour Moustafa},
  doi          = {10.1109/TCSS.2022.3184387},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4636-4648},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {CNA-TCC: Campaign network attribute based thematic campaign classification},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep explainable hate speech active learning on social-media
data. <em>TCSS</em>, <em>11</em>(4), 4625–4635. (<a
href="https://doi.org/10.1109/TCSS.2022.3165136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hate speech is demonstrably aimed at social tension and violence. Detection becomes increasingly difficult as overlapping emotional feelings occur. However, there are still several unresolved issues with informal and indirect targeting of negative communication, including sarcasm, misrepresentation, and praise for the target’s or society’s immoral behavior. In this study, we proposed a method for instance selection based on attention network visualization. The goal is to categorize, modify, and expand the number of training instances. To this end, we first used the lexicons of hate speech and online forums to train the embedding using transfer learning. Then, we used synonym expansion to the semantic vectors. The active learning approach was used to train the task using the result-label pairs. The entropy-based selection and visualization techniques help select unlabeled text for each active learning cycle. The approach is improved, and the number of training instances is increased to improve the model’s accuracy. The active learning cycles are repeated until all unlabeled texts are converted to labeled text. The semantic embedding and lexicon expansion improve the model receiver operating characteristics (ROCs) from 0.89 to 0.91. The bidirectional LSTM with attention and active learning achieved 0.90 for precision–recall. The learned model can visualize the position-weighted terms to illustrate why hate speech is classified.},
  archive      = {J_TCSS},
  author       = {Usman Ahmed and Jerry Chun-Wei Lin},
  doi          = {10.1109/TCSS.2022.3165136},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4625-4635},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Deep explainable hate speech active learning on social-media data},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated disaster monitoring from social media posts using
AI-based location intelligence and sentiment analysis. <em>TCSS</em>,
<em>11</em>(4), 4614–4624. (<a
href="https://doi.org/10.1109/TCSS.2022.3157142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Worldwide disasters like bushfires, earthquakes, floods, cyclones, and heatwaves have affected the lives of social media users in an unprecedented manner. They are constantly posting their level of negativity over the disaster situations at their location of interest. Understanding location-oriented sentiments about disaster situation is of prime importance for political leaders, and strategic decision-makers. To this end, we present a new fully automated algorithm based on artificial intelligence (AI) and natural language processing (NLP), for extraction of location-oriented public sentiments on global disaster situation. We designed the proposed system to obtain exhaustive knowledge and insights on social media feeds related to disaster in 110 languages through AI- and NLP-based sentiment analysis, named entity recognition (NER), anomaly detection, regression, and Getis Ord Gi* algorithms. We deployed and tested this algorithm on live Twitter feeds from 28 September to 6 October 2021. Tweets with 67 515 entities in 39 different languages were processed during this period. Our novel algorithm extracted 9727 location entities with greater than 70% confidence from live Twitter feed and displayed the locations of possible disasters with disaster intelligence. The rates of average precision, recall, and $F_{1}$ -Score were measured to be 0.93, 0.88, and 0.90, respectively. Overall, the fully automated disaster monitoring solution demonstrated 97% accuracy. To the best of our knowledge, this study is the first to report location intelligence with NER, sentiment analysis, regression and anomaly detection on social media messages related to disasters and has covered the largest set of languages.},
  archive      = {J_TCSS},
  author       = {Fahim K. Sufi and Ibrahim Khalil},
  doi          = {10.1109/TCSS.2022.3157142},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4614-4624},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Automated disaster monitoring from social media posts using AI-based location intelligence and sentiment analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Deep tensor evidence fusion network for sentiment
classification. <em>TCSS</em>, <em>11</em>(4), 4605–4613. (<a
href="https://doi.org/10.1109/TCSS.2022.3197994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a multimodal sentiment analysis of social media has attracted increasing attention, and its core idea is to discovery heuristic fusion strategy to analyze the sentiment orientations over heterogeneous multimodal source from a learned compact multimodal representation. The existing multimodal fusion techniques not only struggle to achieve full heterogeneous data interaction, but also they are unable to dynamically assess the quality of various modal data to determine predictability. In this article, we present a novel deep tensor evidence fusion (DTEF) network for multimodal sentiment classification. First, we propose a common view evaluation network that uses a long short-term memory (LSTM) network and a tensor-based neural network to extract rich intermodal and intramodal information. Then, we propose a unique time cue evaluation network that takes advantage of the temporal granularity associated with numerous pattern sequences. To make reliable decisions, we finally incorporate uncertainty through the trusted fusion layer, which improves the accuracy and robustness of sentimental classification. Our model is validated using the CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) and CMU Multimodal Corpus of Sentiment Intensity (CMU-MOSI) datasets, and the experimental findings demonstrate the superior performance of the proposed network in terms of accuracy compared with the state-of-the-art methods.},
  archive      = {J_TCSS},
  author       = {Zhongyang Wang and Guoxia Xu and Xiaokang Zhou and Jung Yoon Kim and Hu Zhu and Lizhen Deng},
  doi          = {10.1109/TCSS.2022.3197994},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4605-4613},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Deep tensor evidence fusion network for sentiment classification},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of the pertinence of indian women’s institutions in
collaborative research. <em>TCSS</em>, <em>11</em>(4), 4595–4604. (<a
href="https://doi.org/10.1109/TCSS.2022.3183949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the relevance of women-only educational institutes is questionable due to various reasons that include social uplifting, ample opportunities, and a free mindset among the population. Though women colleges and universities bring many female students to the purview of the traditional education system every year, other activities like research works and collaborative projects are still a concern for the educationists. In the current manuscript, the role of leading women-only universities and institutions is analyzed throughout India, to scrutinize its impact and opportunities in the research domain. All types of educational institutions and collaborative research work among them are represented as a social network. Different centrality metrics, such as closeness, betweenness, and eigenvector, are utilized to examine the influence of the individual institutes in the collaborative research network. An overlapping community detection method is proposed to perceive the posture of gender-biased universities in the mixed institutional model. The supremacy of the proposed approach is presented over the real-life benchmark datasets. The analytical results exhibit notable improvement over the state-of-the-art approaches and unfold a contemporary framework for strategic analysis in the higher education sector.},
  archive      = {J_TCSS},
  author       = {Samya Muhuri and Suchi Kumari and Suyel Namasudra and Seifedine Kadry},
  doi          = {10.1109/TCSS.2022.3183949},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4595-4604},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Analysis of the pertinence of indian women’s institutions in collaborative research},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative steganography based on long readable text
generation. <em>TCSS</em>, <em>11</em>(4), 4584–4594. (<a
href="https://doi.org/10.1109/TCSS.2022.3174013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text steganography has received a lot of attention in the application of covert communication. How to ensure desirable capacity and imperceptibility has become a key issue in text steganography. There are two typical approaches, i.e., text-selection-based steganography and text-generation-based steganography. However, the text-selection-based approaches generally have the very low hidden capacity and are not applicable in practical scenarios. Although the text-generation-based approaches can embed secret messages with higher capacity during text generation, they are prone to semantic incoherence and semantic errors when generating long texts. To address the abovementioned issues, this article proposes a novel text steganography based on long readable text generation. It first determines the topic of the stego-text according to the scenarios of the communication parties. Then, the plug and play language model (PPLM) is explored to generate the long readable stego-text conforming to the topic with semantic coherency. A given secret message is hidden during text generation by selecting proper words in an established embeddable candidate word pool (ECWP). Establishing the ECWP prevents the language model (LM) from selecting words with low probability in the text generation, thereby avoiding the generation of low-quality or even grammatically incorrect stego-text. Experimental results show that the proposed approach significantly increases hidden capacity while maintaining good imperceptibility compared with the existing approaches.},
  archive      = {J_TCSS},
  author       = {Yi Cao and Zhili Zhou and Chinmay Chakraborty and Meimin Wang and Q. M. Jonathan Wu and Xingming Sun and Keping Yu},
  doi          = {10.1109/TCSS.2022.3174013},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4584-4594},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Generative steganography based on long readable text generation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable detection of fake news on social media using
pyramidal co-attention network. <em>TCSS</em>, <em>11</em>(4),
4574–4583. (<a href="https://doi.org/10.1109/TCSS.2022.3207993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world, fake news on social media is a universal trend and has severe consequences. There has been a wide variety of countermeasures developed to offset the effect and propagation of Fake News. The most common are linguistic-based techniques, which mostly use deep learning (DL) and natural language processing (NLP). Even government-sponsored organizations spread fake news as a cyberwar strategy. In literature, computational-based detection of fake news has been investigated to minimize it. The initial results of these studies are good but not significant. However, we argue that the explainability of such detection, particularly why a certain news item is detected as fake, is a vital missing element of the studies. In real-world settings, the explainability of the system’s decisions is just as important as its accuracy. This article explores explainable fake news detection and proposes a sentence-comment-based co-attention sub-network model. The proposed model uses user comments and news contents to mutually apprehend top- $k$ explainable check-worthy user comments and sentences for detecting fake news. The experimental result on real-world datasets shows that our proposed model outperforms state-of-the-art techniques by 5.56% in the $F1$ score. In addition, our model outperforms other baselines by 16.4% in normalized cumulative gain (NDCG) and 22.1% in Precision in identifying top- $k$ comments from users, which indicates why a news article can be fake.},
  archive      = {J_TCSS},
  author       = {Fazlullah Khan and Ryan Alturki and Gautam Srivastava and Foziah Gazzawe and Syed Tauhid Ullah Shah and Spyridon Mastorakis},
  doi          = {10.1109/TCSS.2022.3207993},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4574-4583},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Explainable detection of fake news on social media using pyramidal co-attention network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Citation count is not enough: Citation’s context-based
scientific impact evaluation. <em>TCSS</em>, <em>11</em>(4), 4567–4573.
(<a href="https://doi.org/10.1109/TCSS.2022.3193508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Qualitative analysis of citations received by a scientific manuscript is a challenging task in the field of citation analysis. In most cases, the existing approaches that involve citations for the scientific impact evaluation normally employ a quantitative parameter, such as the number of received citations, while ignoring the qualitative feature, such as the context of citations, while, in reality, a received citation might hold positive feedback and negative or neutral feedback. In this study, a measure is purposed for the scientific evaluation of the articles based on the context of the citations named the context-based article impact factor (CBAIF). CBAIF not only considers the positive, negative, or neutral context of the citations but also involves the citing and cited author’s conflict-of-interest relationship for the evaluation of their scientific impact. With the help of experimentation, it is observed that CBAIF performs a fair ranking of articles based on citation’s context, whether it is cited positively or being criticized by some authors. Experimental results show that the CBAIF value with the context of citations revealed accurate results rather than the article impact factor (AIF) value without the context of citations.},
  archive      = {J_TCSS},
  author       = {Ali Daud and Sehrish Ghaffar and Tehmina Amjad},
  doi          = {10.1109/TCSS.2022.3193508},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4567-4573},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Citation count is not enough: Citation’s context-based scientific impact evaluation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evidence mining for interpretable charge prediction via
prompt learning. <em>TCSS</em>, <em>11</em>(4), 4556–4566. (<a
href="https://doi.org/10.1109/TCSS.2022.3178551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, more and more researchers are committed to applying artificial intelligence technology to the legal field to support decision-making. Charge prediction is a subtask of legal judgment prediction (LJP). Its purpose is to analyze the fact description of natural language text and predict a charge corresponding to a case. At present, most of the research takes charge prediction as a multiclass classification task, which leads to unsatisfactory interpretation due to the weak semantic correlation between the fact descriptions and charge labels. In order to solve this problem, we propose a method of generative evidence mining based on prompt learning. Specifically, in the training phase, we reformulate the charge labels into the prompt template that we design to enhance the semantic correlation between the charge labels and the fact descriptions. In the testing phase, the charge labels are generated via the model based on prompt learning. Meanwhile, we calculate the attention score of each sentence from the multihead self-attention in the transformer encoder and choose the sentence with the highest attention score as the evidence. Our experimental results on a real dataset show that our method is better than the traditional fine-tuning-based classification method.},
  archive      = {J_TCSS},
  author       = {Lin Li and Dan Liu and Lingyun Zhao and Jianwei Zhang and Jinhang Liu},
  doi          = {10.1109/TCSS.2022.3178551},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4556-4566},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Evidence mining for interpretable charge prediction via prompt learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guest editorial: Special issue on generating human readable
explanations in NLP. <em>TCSS</em>, <em>11</em>(4), 4552–4555. (<a
href="https://doi.org/10.1109/TCSS.2024.3427223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCSS},
  author       = {Imran Razzak and Reda Bouadjenek and Aamir Cheema and Ibrahim A. Hameed and Guandong Xu and Amin Beheshti},
  doi          = {10.1109/TCSS.2024.3427223},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4552-4555},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Guest editorial: Special issue on generating human readable explanations in NLP},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constructing an optimal prediction system for infectious
disease. <em>TCSS</em>, <em>11</em>(4), 4544–4551. (<a
href="https://doi.org/10.1109/TCSS.2024.3427222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCSS},
  author       = {Jianping Huang and Licheng Li and Siyu Chen and Bin Chen and DanFeng Wang and Bin Hu},
  doi          = {10.1109/TCSS.2024.3427222},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {8},
  number       = {4},
  pages        = {4544-4551},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Constructing an optimal prediction system for infectious disease},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multisource-knowledge-based approach for crowd evacuation
navigation. <em>TCSS</em>, <em>11</em>(3), 4524–4539. (<a
href="https://doi.org/10.1109/TCSS.2024.3381840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In crowd evacuation research, the knowledge contained in crowd evacuation is very complex and is multisource. Crowd evacuation scenarios restrict pedestrians’ movement decision-making, and the movement states of the crowd imply the movement characteristics. However, the existing studies on crowd evacuation navigation approach cannot make full use of the complex and multisource crowd evacuation knowledge, which reduces the effect of the evacuation navigation. To solve this problem, a new crowd evacuation navigation approach based on multisource knowledge is proposed. First, we collect relevant data on crowd evacuation using an image sensor network and establish a crowd evacuation knowledge graph to organize and store this data. Second, the explicit knowledge of scene structure and crowd movements is represented based on the crowd evacuation knowledge graph. Then, a deep-learning-based tacit knowledge model (DLTKM) is designed to extract the tacit knowledge of different groups and scene entities. Finally, a new crowd evacuation navigation approach based on wireless sensor network and related knowledge representations is designed to plan evacuation paths for evacuees. The experiment results show that this approach can plan reasonable evacuation paths for pedestrians, and improve the efficiency of crowd evacuations.},
  archive      = {J_TCSS},
  author       = {Pengfei Zhang and Kun Zhao and Hong Liu and Wenhao Li},
  doi          = {10.1109/TCSS.2024.3381840},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4524-4539},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Multisource-knowledge-based approach for crowd evacuation navigation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Stability and parameter sensitivity analyses of SEI<span
class="math inline"><sub>3</sub></span>r<span
class="math inline"><sub>2</sub></span>d<span
class="math inline"><sub>2</sub></span>v model to control COVID-19
pandemic. <em>TCSS</em>, <em>11</em>(3), 4511–4523. (<a
href="https://doi.org/10.1109/TCSS.2024.3362885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we have employed the SEI ${}_{3}$ R ${}_{2}$ D ${}_{2}$ V model for our analysis. We conducted stability analysis for infection-free equilibrium ( $X^{\prime}$ ) and endemic equilibrium ( $X^{*}$ ). The obtained equilibrium points are globally asymptotically stable. Our findings reveal that the contact dynamics of the infected and uninfected populations primarily influence the dynamics of COVID-19. In managing COVID-19, it is crucial to ensure that the number of secondary infections ( $R_{t}$ ) remains below the threshold $\left(\boldsymbol{\gamma}+(\boldsymbol{1-\gamma})/(\boldsymbol{\alpha_{t}})\right)$ which determines the growth or decline of the disease. Additionally, we conducted a sensitivity analysis of $R_{t}$ to identify the key factors that significantly affect its value. It is observed that the recovery rate, transmission probability of the virus, contact rate of unreported infections, testing inaccuracy and hesitancy, vaccination rate, and its efficacy have the most substantial impact on the value of $R_{t}$ . The influential parameters are categorized into two sets based on their effective controllability, allowing for the prioritization of intervention strategies that require fewer resources and are easier to manage, thereby optimizing efforts to control disease transmission.},
  archive      = {J_TCSS},
  author       = {Vaishali Kansal and Pradumn Kumar Pandey},
  doi          = {10.1109/TCSS.2024.3362885},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4511-4523},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Stability and parameter sensitivity analyses of SEI${}_{3}$R${}_{2}$D${}_{2}$V model to control COVID-19 pandemic},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling information cocoons in networked populations:
Insights from backgrounds and preferences. <em>TCSS</em>,
<em>11</em>(3), 4497–4510. (<a
href="https://doi.org/10.1109/TCSS.2024.3354508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The formation of information cocoons, driven by limited disclosure and individual preferences, has resulted in the polarization of society. However, the underlying mechanisms and pathways to escape these cocoons remain unresolved. This article aims to solve it by developing an adaptive imitation process. In this process, the measurement of information cocoons across the population is based on Shannon&#39;s information entropy, taking into account neighborhood information. Incorporating the Dirac function to formulate information distribution over networks, theoretical results are validated by numerical simulation experiments. Results show that individual backgrounds and preferences are crucial factors in the formation of information cocoons, and the severity of information cocoon production increases with an individual capacity to stick to oneself. Encouraging connections among diverse communities can effectively mitigate the intensity of information cocoons. This research contributes to the advancement of computational communication systems and offers insights toward dismantling informational boundaries.},
  archive      = {J_TCSS},
  author       = {Ming Gu and Tian-Fang Zhao and Liang Yang and Xiao-Kun Wu and Wei-Neng Chen},
  doi          = {10.1109/TCSS.2024.3354508},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4497-4510},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Modeling information cocoons in networked populations: Insights from backgrounds and preferences},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Driving behavior prediction based on combined neural network
model. <em>TCSS</em>, <em>11</em>(3), 4488–4496. (<a
href="https://doi.org/10.1109/TCSS.2024.3350199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate behavior prediction of surrounding vehicles can greatly improve the operating safety of autonomous vehicles. However, in real traffic scence, the complexity and uncertainties of traffic flow bring great challenges to driving behavior prediction. This article proposes a driving behavior prediction model using a wide-deep framework that combines gradient boosting decision tree (GBDT), convolutional neural network (CNN), and long short-term memory network (LSTM) algorithm to fully mine driving behavior characteristics while improve interpretability of the CNN-LSTM model. The GBDT algorithm can quantitatively describe the interaction between the autonomous vehicle and its surrounding vehicles during the driving process, obtaining a series of driving behavior rules, and integrating the driving behavior rule features into the CNN-LSTM neural network. The CNN-LSTM neural network model is constructed to find the spatial features in driving trajectory by CNNs and the temporal features by LSTM networks. The accuracy of the driving behavior prediction model is further improved. Simulation experiments show the rationality and validity of the model and algorithm.},
  archive      = {J_TCSS},
  author       = {Runmei Li and Xiaoting Shu and Chen Li},
  doi          = {10.1109/TCSS.2024.3350199},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4488-4496},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Driving behavior prediction based on combined neural network model},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Factors influencing mental health among youth during the
COVID-19 lockdown: A cross-sectional study in bangladesh. <em>TCSS</em>,
<em>11</em>(3), 4478–4487. (<a
href="https://doi.org/10.1109/TCSS.2024.3350087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Coronavirus Disease of 2019 (COVID-19) pandemic has threatened the global economy, livelihoods, and physical and mental health since it began in 2019. This study aimed to examine how the COVID-19 pandemic affected the mental health of a representative sample of Bangladeshi youth and to identify the influencing factors. Through social media, 390 people were asked to participate in an online survey using the cross-sectional methodology. The chi-square test was used to examine the associations between the status of mental health and other variables. It was found that because of the lockdown, 59.3% and 21% of the participants were severely and moderately affected in terms of mental health, respectively. Poor mental health outcomes are strongly associated with family status, profession, marital status, avoiding shaking hands, cleaning and disinfecting objects and surfaces which are frequently used, knowledgeable community, impact on livelihood, food availability, routine behavior, impact on education, and impact on mental health. A multinomial logistic regression (MLR) model with 95% confidence interval (CI) with a p-value &lt; 0.05 was used to determine the effect of explanatory variables on the adjusted odds ratio (AOR) of mental health status. The results of MLR showed that age, marital status, the risk of participants of their family members getting sick from COVID-19, impact on wages, physical and mental abuse, closed schools, etc., significantly predicted mental health outcomes. This study facilitated a deeper understanding of mental health during the COVID-19 outbreak.},
  archive      = {J_TCSS},
  author       = {Al Muktadir Munam and Ahammad Hossain},
  doi          = {10.1109/TCSS.2024.3350087},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4478-4487},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Factors influencing mental health among youth during the COVID-19 lockdown: A cross-sectional study in bangladesh},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-path TokenLearner for remote photoplethysmography-based
physiological measurement with facial videos. <em>TCSS</em>,
<em>11</em>(3), 4465–4477. (<a
href="https://doi.org/10.1109/TCSS.2024.3356713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG)-based physiological measurement is an emerging yet crucial vision task, whose challenge lies in exploring accurate rPPG prediction from facial videos accompanied by noises of illumination variations, facial occlusions, head movements, etc., in a noncontact manner. Existing mainstream convolutional neural network (CNN)-based models make efforts to detect physiological signals by capturing subtle color changes in facial regions of interest (ROI) caused by heartbeats. However, such models are constrained by the limited local spatial or temporal receptive fields in the neural units. Unlike them, a native transformer-based framework called dual-path TokenLearner (dual-TL) is proposed in this article, which utilizes the concept of learnable tokens to integrate both spatial and temporal informative contexts from the global perspective of the video. Specifically, the proposed dual-TL uses a spatial TokenLearner (S-TL) to explore associations in different facial ROIs, which promises the rPPG prediction far away from noisy ROI disturbances. Complementarily, a temporal TokenLearner (T-TL) is designed to infer the quasi-periodic pattern of heartbeats, which eliminates temporal disturbances such as head movements. The two TokenLearners, S-TL and T-TL, are executed in a dual-path mode. This enables the model to reduce noise disturbances for final rPPG signal prediction. Extensive experiments on four physiological measurement benchmark datasets are conducted. The dual-TL achieves state-of-the-art performances in both intra and cross-dataset testings, demonstrating its immense potential as a basic backbone for rPPG measurement.},
  archive      = {J_TCSS},
  author       = {Wei Qian and Dan Guo and Kun Li and Xiaowei Zhang and Xilan Tian and Xun Yang and Meng Wang},
  doi          = {10.1109/TCSS.2024.3356713},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4465-4477},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Dual-path TokenLearner for remote photoplethysmography-based physiological measurement with facial videos},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TLP-NEGCN: Temporal link prediction via network embedding
and graph convolutional networks. <em>TCSS</em>, <em>11</em>(3),
4454–4464. (<a href="https://doi.org/10.1109/TCSS.2024.3367231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal link prediction (TLP) is a prominent problem in network analysis that focuses on predicting the existence of future connections or relationships between entities in a dynamic network over time. The predictive capabilities of existing models of TLP are often constrained due to their difficulty in adapting to the changes in dynamic network structures over time. In this article, an improved TLP model, denoted as TLP-NEGCN, is introduced by leveraging network embedding, graph convolutional networks (GCNs), and bidirectional long short-term memory (BiLSTM). This integration provides a robust model of TLP that leverages historical network structures and captures temporal dynamics leading to improved performances. We employ graph embedding with self-clustering (GEMSEC) to create lower dimensional vector representations for all nodes of the network at the initial timestamps. The node embeddings are fed into an iterative training process using GCNs across timestamps in the dataset. This process enhances the node embeddings by capturing the network&#39;s temporal dynamics and integrating neighborhood information. We obtain edge embeddings by concatenating the node embeddings of the end nodes of each edge, encapsulating the information about the relationships between nodes in the network. Subsequently, these edge embeddings are processed through a BiLSTM architecture to forecast upcoming links in the network. The performance of the proposed model is compared against several baselines and contemporary TLP models on various real-life temporal datasets. The obtained results based on various evaluation metrics demonstrate the superiority of the proposed work.},
  archive      = {J_TCSS},
  author       = {Akshi Kumar and Abhishek Mallik and Sanjay Kumar},
  doi          = {10.1109/TCSS.2024.3367231},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4454-4464},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {TLP-NEGCN: Temporal link prediction via network embedding and graph convolutional networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic guidance signage placement through multiobjective
evolutionary algorithm. <em>TCSS</em>, <em>11</em>(3), 4440–4453. (<a
href="https://doi.org/10.1109/TCSS.2024.3359905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Guidance signage placement is a fundamental operation for crowd control in public places. The current methods mainly rely on manual design or mathematical models, which are not flexible and effective enough for crowd control in large public places. To address this issue, this article proposes a multiobjective evolutionary framework that can search for high-quality guidance signage placement strategies automatically. In the proposed method, an agent-based crowd simulation model is proposed to simulate the wayfinding behaviors of pedestrians in public places. Furthermore, a new safety metric is proposed to quantitatively evaluate the quality of guidance signage placement strategies. On this basis, an indicator-based multiobjective evolutionary algorithm (IBEA) is utilized to search for optimal guidance signage placement strategies that have tradeoffs between crowd safety and pedestrians’ travel time. Simulation experiments on both synthetic and real-world scenes were conducted to evaluate the proposed method, and the simulation results show that the proposed framework can generate very promising guidance signage placement strategies in comparison with several existing methods.},
  archive      = {J_TCSS},
  author       = {Yixin Chen and Jinghui Zhong and Wei-Li Liu and Linbo Luo and Wentong Cai},
  doi          = {10.1109/TCSS.2024.3359905},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4440-4453},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Automatic guidance signage placement through multiobjective evolutionary algorithm},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differential game strategies for social networks with
self-interested individuals. <em>TCSS</em>, <em>11</em>(3), 4426–4439.
(<a href="https://doi.org/10.1109/TCSS.2024.3350736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A social network population engages in collective actions as a direct result of forming a particular opinion. The strategic interactions among the individuals acting independently and selfishly naturally portray a noncooperative game. Nash equilibrium allows for self-enforcing strategic interactions between selfish and self-interested individuals. This article presents a differential game approach to the opinion formation problem in social networks to investigate the evolution of opinions as a result of a Nash equilibrium. The opinion of each individual is described by a differential equation, which is the continuous-time Hegselmann–Krause model for opinion dynamics with a time delay in input. The objective of each individual is to seek optimal strategies for its own opinion evolution by minimizing an individual cost function. Two differential game problems emerge, one for a population that is not stubborn and another for a population that is stubborn. The open-loop Nash equilibrium actions and their associated opinion trajectories are derived for both differential games using Pontryagin&#39;s principle. Additionally, the receding horizon control scheme is used to practice feedback strategies where the information flow is restricted by fixed and complete social graphs, as well as the second neighborhood concept. The game strategies were executed on the well-known Zachary&#39;s Karate Club social network and a representative family opinion network. The resulting opinion trajectories associated with the game strategies showed consensus, polarization, and disagreement in final opinions.},
  archive      = {J_TCSS},
  author       = {Hossein B. Jond},
  doi          = {10.1109/TCSS.2024.3350736},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4426-4439},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Differential game strategies for social networks with self-interested individuals},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative steganography via live comments on streaming
video frames. <em>TCSS</em>, <em>11</em>(3), 4412–4425. (<a
href="https://doi.org/10.1109/TCSS.2024.3352979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative text steganography has received considerable attention in the covert communication community for the benefit of sending secret messages without the need to modify carriers. Existing methods typically choose the next word when generating a stego-text based on conditional probability encoding of candidates, which may lead to generating inadequate words for the underlying secret message. How to generate a semantically controllable stego-text with a high capacity on secure embedding of a secret message is a main challenge. We address this challenge by proposing a new paradigm to generative text steganography that takes advantage of certain social media through apparently normal behaviors from the sender. In particular, we make use of the live commenting feature provided by public video sharing platforms (PVSPs), which allow viewers to make comments on video scenes that will fly on screens when the scenes are shown. We show that this feature can be used to construct a generative steganographic system. The sender generates at random a number of distracting words and a certain invertible matrix called W- $d$ matrix based on the total number of message words and distracting words. The sender then transforms a sequence of indexes of these words to a sequence, selects one or more videos with a sufficiently large number of total frames, and generates a comment on each frame in the sequence. The receiver extracts commented frame indexes, uses the shared stego-key to generate the same W- $d$ matrix as the sender, and obtains the secret message using the inverse of the matrix. The stego-key consists of a vocabulary generator and a W- $d$ matrix generator (WMG) based on pseudorandomly generated numbers. To generate comments on frames that conform to comments made by viewers, we devise a neural ResNet-LSTM model to generate a comment for an input image based on its content. Theoretical analysis shows that commented video frames (CVF) is covert, secure, efficient, and feasible to conceal any message of arbitrary length. We implement CVF and present evaluation results from multiple aspects that our work outperforms the existing stego-methods.},
  archive      = {J_TCSS},
  author       = {Yuling Liu and Cuilin Wang and Jie Wang and Bo Ou and Xin Liao},
  doi          = {10.1109/TCSS.2024.3352979},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4412-4425},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Generative steganography via live comments on streaming video frames},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging hyperbolic dynamic neural networks for
knowledge-aware recommendation. <em>TCSS</em>, <em>11</em>(3),
4396–4411. (<a href="https://doi.org/10.1109/TCSS.2024.3353467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) is of growing significance in enabling explainable recommendations. Recent research works involve constructing propagation-based recommendation models. Nevertheless, most of the current propagation-based recommendation methods cannot explicitly handle the diverse relations of items, resulting in the inability to model the underlying hierarchies and diverse relations, and it is difficult to capture the high-order collaborative information of items to learn premium representation. To address these issues, we leverage hyperbolic dynamic neural networks for knowledge-aware recommendation (KHDNN). Technically speaking, we embed users and items (forming user–item bipartite graphs), along with entities and relations (constituting KGs), into hyperbolic space, followed by encoding these embeddings using an encoder. The encoded embedding is passed through a hyperbolic dynamic filter to explicitly handle relations and model different relational structures. Furthermore, we design a fresh aggregation strategy based on relations to propagate and capture higher-order collaborative signals as well as knowledge associations. Meanwhile, we extract semantic information via a bilateral memory network to fuse item collaborative signals and knowledge associations. Empirical results from four datasets show that KHDNN surpasses cutting-edge baseline methods. Additionally, we demonstrate that the KHDNN can perform knowledge-aware recommendations with complex relations.},
  archive      = {J_TCSS},
  author       = {Yihao Zhang and Kaibei Li and Junlin Zhu and Meng Yuan and Yonghao Huang and Xiaokang Li},
  doi          = {10.1109/TCSS.2024.3353467},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4396-4411},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Leveraging hyperbolic dynamic neural networks for knowledge-aware recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Let’s all laugh together: A novel multitask framework for
humor detection in internet memes. <em>TCSS</em>, <em>11</em>(3),
4385–4395. (<a href="https://doi.org/10.1109/TCSS.2024.3362811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing humor in meme data is a challenging task in natural language processing (NLP) and computer vision (CV) due to the complexity and variability of humor. With the explosive growth of Internet memes on social media platforms such as Facebook, Twitter, and Instagram, this task has become more important. However, there have been few studies that investigate humor recognition from memes, particularly in languages other than English. In this work, we hypothesize that humor is closely related to the valence and arousal dimensions of sentiment. We make the first attempt to release a new meme dataset for humor recognition in Hindi and propose a multitask deep learning framework to simultaneously solve three problems: humor recognition (the primary task) and valence and arousal classification (the two secondary tasks) for Internet memes. Empirical results on the Hindi meme dataset demonstrate the efficacy of our multitask learning approach over traditional pretrained models such as BERT and VGG19. The complete resources and codes will be made available for further research after acceptance of the manuscript.},
  archive      = {J_TCSS},
  author       = {Gitanjali Kumari and Dibyanayan Bandyopadhyay and Asif Ekbal and Santanu Pal and Arindam Chatterjee and Vinutha B. N.},
  doi          = {10.1109/TCSS.2024.3362811},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4385-4395},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Let&#39;s all laugh together: A novel multitask framework for humor detection in internet memes},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An evolutionary game theory-based cooperation framework for
countering privacy inference attacks. <em>TCSS</em>, <em>11</em>(3),
4367–4384. (<a href="https://doi.org/10.1109/TCSS.2024.3359254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy inference poses a significant threat to users of online social networks (OSNs). To deal with this issue, a number of privacy-enhancing technologies have been proposed with the goal of achieving a balance between the protection of privacy and the utility of data. Previous studies, however, failed to take into consideration the impact of the interdependency of privacy (IoP), which dictates that privacy decisions made by some users may affect the privacy of some other users. The implication of IoP is that too much privacy may be disclosed when multiple individuals share data with the same data accessor because privacy conflicts resulting from independent privacy decisions would make it possible for adversaries to infer the privacy of the target user. Ideally, cooperation that preserves privacy should allow OSN users to respect each other’s privacy specifications so as to resolve such privacy conflicts caused by independent privacy decisions of individuals. To facilitate the design, we propose a privacy-preserving cooperation framework based on the evolutionary game theory to facilitate such cooperation. Based on the framework, the dynamics of user strategies regarding whether to participate in the cooperation are analyzed and an evolutionary stable state is derived to serve as the basis for incentivizing users to participate in cooperative privacy protection. Experiments based on real OSN data show that the proposed cooperation framework is effective in modeling the behaviors of users and that the proposed incentive allocation method can incentivize users to participate in the cooperation. The proposed cooperation framework can not only helps lower the threat to user privacy resulting from privacy inference by data accessors but also allows OSN service providers to design effective privacy protection policies.},
  archive      = {J_TCSS},
  author       = {Yuzi Yi and Nafei Zhu and Jingsha He and Anca Delia Jurcut and Xiangjun Ma and Yehong Luo},
  doi          = {10.1109/TCSS.2024.3359254},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4367-4384},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An evolutionary game theory-based cooperation framework for countering privacy inference attacks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). User-centric modeling of online hate through the lens of
psycholinguistic patterns and behaviors in social media. <em>TCSS</em>,
<em>11</em>(3), 4354–4366. (<a
href="https://doi.org/10.1109/TCSS.2024.3359010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hate speech in social media is a growing problem that reinforces racial discrimination and mistrust between people, leading to physical crimes, violence, and fragmentation in world communities. Although previous studies showed the potential of user profiling in hate speech detection in social media, there has not been a thorough analysis of users’ characteristics and dispositions to understand the development of hate attitudes among users. To bridge this gap, we investigate the role of a wide range of psycholinguistic and behavioral traits in characterizing and distinguishing users prone to post hate speech on social media. Considering anti-Asian hate during the COVID-19 pandemic as a case study, we curate a dataset of 5 417 041 tweets from 3001 Twitter users prone to publish hate content (aka hateful-to-be users) and a corresponding matched set of 3001 control users. Our findings reveal significant statistical differences in most dimensions of psycholinguistic attributes and online activities of hateful-to-be users compared to control users. We further develop a classifier and demonstrate that features derived from user timelines are strong indicators for automatically predicting the onset of hateful behavior.},
  archive      = {J_TCSS},
  author       = {Zeinab Noorian and Amira Ghenai and Hadiseh Moradisani and Fattane Zarrinkalam and Soroush Zamani Alavijeh},
  doi          = {10.1109/TCSS.2024.3359010},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4354-4366},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {User-centric modeling of online hate through the lens of psycholinguistic patterns and behaviors in social media},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust asymmetric cross-modal hashing retrieval with dual
semantic enhancement. <em>TCSS</em>, <em>11</em>(3), 4340–4353. (<a
href="https://doi.org/10.1109/TCSS.2024.3352494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As social media faces with large amounts of data and multimodal properties, cross-modal hashing (CMH) retrieval gains extensive applications with its high efficiency and low storage consumption. However, there are two issues that hinder the performance of the existing semantics-learning-based CMH methods: 1) there exist some nonlinear relationships, noises, and outliers in the data, which may degrade the learning effectiveness of a model; and 2) the complementary relationships between the label semantics and sample semantics may be inadequately explored. To address the above two problems, a method called robust asymmetric cross-modal hashing retrieval with dual semantic enhancement (RADSE) is proposed. RADSE consists of three parts: 1) cross-modal data alignment (CDA) that applies kernel mapping and establishes a unified linear representation in the neighborhood to capture the nonlinear relationships between cross-modal data; 2) relaxed label semantic learning for robustness (RLSLR) that uses a relaxation strategy to expand label distinctiveness, and leverages $\ell_{2,1}$ norm to enhance the robustness of the model against noise and outliers; and 3) dual semantic enhancement learning (DSEL) that learns more interrelationships between samples under the label semantic guidance to ensure the mutual enhancement of semantic information. Extensive experiments and analyses on three popular datasets demonstrate that RADSE outperforms the most existing methods in terms of mean average precision (MAP), precision recall (P–R) curves, and top-N precision curves. In the comparisons of MAP, RADSE improves by an average of 2%–3% in two retrieval tasks.},
  archive      = {J_TCSS},
  author       = {Shaohua Teng and Tuhong Xu and Zefeng Zheng and NaiQi Wu and Wei Zhang and Luyao Teng},
  doi          = {10.1109/TCSS.2024.3352494},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4340-4353},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Robust asymmetric cross-modal hashing retrieval with dual semantic enhancement},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PEAE-GNN: Phishing detection on ethereum via augmentation
ego-graph based on graph neural network. <em>TCSS</em>, <em>11</em>(3),
4326–4339. (<a href="https://doi.org/10.1109/TCSS.2023.3349071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years, the successful application of block-chain in cryptocurrency has attracted a lot of attention, but it has also led to a rapid growth of illegal and criminal activities. Phishing scams have become the most serious type of crime in Ethereum. Some existing methods for phishing scams detection have limitations, such as high complexity, poor scalability, and high latency. In this article, we propose a novel framework named phishing detection on Ethereum via augmentation ego-graph based on graph neural network (PEAE-GNN). First, we obtain account labels and transaction records from authoritative websites and extract ego-graphs centered on labeled accounts. Then we propose a feature augmentation strategy based on structure features, transaction features and interaction intensity to augment the node features, so that these features of each ego-graph can be learned. Finally, we present a new graph-level representation, sorting the updated node features in descending order and then taking the mean value of the top n to obtain the graph representation, which can retain key information and reduce the introduction of noise. Extensive experimental results show that PEAE-GNN achieves the best performance on phishing detection tasks. At the same time, our framework has the advantages of lower complexity, better scalability, and higher efficiency, which detects phishing accounts at early stage.},
  archive      = {J_TCSS},
  author       = {Hexiang Huang and Xuan Zhang and Jishu Wang and Chen Gao and Xue Li and Rui Zhu and Qiuying Ma},
  doi          = {10.1109/TCSS.2023.3349071},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4326-4339},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {PEAE-GNN: Phishing detection on ethereum via augmentation ego-graph based on graph neural network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-stage information spreading evolution on the control
role of announcements. <em>TCSS</em>, <em>11</em>(3), 4315–4325. (<a
href="https://doi.org/10.1109/TCSS.2024.3367385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern social media networks have become an important platform for information competition among countries, regions, companies, and other parties. This article utilizes the research method of spread dynamics to investigate the influence of the control role of announcements in social networks on the spreading process. This article distinguishes two spreading phases using the authentication intervention as a boundary: the unconfirmed spreading phase and the confirmed spreading phase. Based on the actual rules of spreading in online social networks, two kinds of verification results are defined: true information and false information. The two-stage information spreading dynamics model is developed to analyze the changes in spreading effects due to different validation results. The impact of the intervention time on the overall spread process is analyzed by combining important control factors such as response cost and time sensitivity. The validity of the model is verified by comparing the model simulation results with real cases and the adaptive capacity experiments. This work is analyzed and visualized from multiple perspectives, providing more quantitative results. The research content will provide a scientific basis for the intervention behavior of information management control by relevant departments or authorities.},
  archive      = {J_TCSS},
  author       = {Jinhu Ren and Fuzhong Nian and Xiaochen Yang},
  doi          = {10.1109/TCSS.2024.3367385},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4315-4325},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Two-stage information spreading evolution on the control role of announcements},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TT-GCN: Temporal-tightly graph convolutional network for
emotion recognition from gaits. <em>TCSS</em>, <em>11</em>(3),
4300–4314. (<a href="https://doi.org/10.1109/TCSS.2024.3364378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human gait reflects substantial information about individual emotions. Current gait emotion recognition methods focus on capturing gait topology information and ignore the importance of fine-grained temporal features. This article proposes the temporal-tightly graph convolutional network (TT-GCN) to extract temporal features. TT-GCN comprises three significant mechanisms: the causal temporal convolution network (casual-TCN), the walking direction recognition auxiliary task, and the feature mapping layer. To obtain tight temporal dependencies and enhance the relevance among gait periods, the causal-TCN is introduced. Based on the assumption of emotional consistency in the walking directions, the auxiliary task is proposed to enhance the ability of fine-grained feature extraction. Through the feature mapping layer, affective features can be mapped into the appropriate representation and fused with deep learning features. TT-GCN shows the best performance across five comprehensive metrics. All experimental results verify the necessity and feasibility of exploring fine-grained temporal feature extraction.},
  archive      = {J_TCSS},
  author       = {Tong Zhang and Yelin Chen and Shuzhen Li and Xiping Hu and C. L. Philip Chen},
  doi          = {10.1109/TCSS.2024.3364378},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4300-4314},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {TT-GCN: Temporal-tightly graph convolutional network for emotion recognition from gaits},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An urban trajectory data-driven approach for COVID-19
simulation. <em>TCSS</em>, <em>11</em>(3), 4290–4299. (<a
href="https://doi.org/10.1109/TCSS.2024.3351886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus disease 2019 (COVID-19) pandemic has changed the world deeply. Urban trajectory big data collected by wireless sensing devices provide great assistance for COVID-19 prevention. However, except for contact tracing, trajectory data are rarely employed in other preventative scenarios against the pandemic. In this article, we try to extend the application of trajectories auto-collected by wireless sensing devices and simulate the epidemic spread in a trajectory data-driven manner. After that, the effects of three nonpharmacological measures are quantified. In contrast to existing studies, additional requirements such as the complex topological networks are needless in our simulation, where the interactions between agents are derived by the intersections of their trajectories. Concretely, the dynamic of virus propagation among individuals is first modeled, and then an agent-based microsimulation environment is built as an artificial system to conduct the epidemic spread simulation. Finally, the trajectories are loaded into the agents as the reliance for their interactions, and the macroscopic changes under different interventions are revealed in a bottom–up way. As a case study, we conduct the simulation based on the trajectories in a real region, in which we find the following. 1) Among the three examined nonpharmacological interventions, community containment is more effective than keeping social distance, which can lower the deaths to nearly 1/9 compared to no action, while travel restrictions play limited roles. 2) There is a strong positive correlation between population densities and mortality. 3) The timing of community containment triggered by confirmed diagnoses is proportional to the number of deaths, thus early containment will significantly decrease mortality.},
  archive      = {J_TCSS},
  author       = {Zhishuai Li and Gang Xiong and Yisheng Lv and Peijun Ye and Xiaoli Liu and Sasu Tarkoma and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3351886},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4290-4299},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An urban trajectory data-driven approach for COVID-19 simulation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Blockchain-driven privacy-preserving contact-tracing
framework in pandemics. <em>TCSS</em>, <em>11</em>(3), 4279–4289. (<a
href="https://doi.org/10.1109/TCSS.2024.3351191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology, recognized for its decentralized and privacy-preserving capabilities, holds potential for enhancing privacy in contact tracing applications. Existing blockchain-based contact tracing frameworks often overlook one or more critical design details, such as the blockchain data structure, a decentralized and lightweight consensus mechanism with integrated tracing data verification, and an incentive mechanism to encourage voluntary participation in bearing blockchain costs. Moreover, the absence of framework simulations raises questions about the efficacy of these existing models. To solve above issues, this article introduces a fully third-party independent blockchain-driven contact tracing (BDCT) framework, detailed in its design. The BDCT framework features an Rivest-Shamir-Adleman (RSA) encryption-based transaction verification method (RSA-TVM), achieving over 96% accuracy in contact case recording, even with a 60% probability of individuals failing to verify contact information. Furthermore, we propose a lightweight reputation corrected delegated proof of stake (RC-DPoS) consensus mechanism, coupled with an incentive model, to ensure timely reporting of contact cases while maintaining blockchain decentralization. Additionally, a novel simulation environment for contact tracing is developed, accounting for three distinct contact scenarios with varied population density. Our results and discussions validate the effectiveness, robustness of the RSA-TVM and RC-DPoS, and the low storage demand of the BDCT framework.},
  archive      = {J_TCSS},
  author       = {Xiao Li and Weili Wu and Tiantian Chen},
  doi          = {10.1109/TCSS.2024.3351191},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4279-4289},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Blockchain-driven privacy-preserving contact-tracing framework in pandemics},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The SIQRS propagation model with quarantine on simplicial
complexes. <em>TCSS</em>, <em>11</em>(3), 4267–4278. (<a
href="https://doi.org/10.1109/TCSS.2024.3351173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simplicial complexes successfully resolve the limitation of social networks to describe the spread of infectious diseases in group interactions. However, the effects of quarantines in the context of group interactions remain largely unaddressed. In this article, we therefore propose a susceptible-infectious-quarantine-recovered-susceptible (SIQRS) model with quarantines and study its evolution on simplicial complexes. In the model, a fraction of infected individuals is subject to quarantine, but individuals leaving quarantine may still be contagious. Using mean-field (MF) methods, we derive the propagation threshold and the steady state infection densities as well as conditions for their stability. Numerical simulations moreover show that longer quarantine times and higher quarantine ratios tend to disrupt discontinuous phase transition and bistable phenomena that are commonly due to group interactions. Additionally, when epidemic outbreaks are recurrent, although quarantine measures can reduce the peak of the first wave and delay the onset of future waves, they may also lead to an increase in subsequent peak infected densities. This highlights the need to prepare sufficient resources to deal with periodic infections after the initial wave is over.},
  archive      = {J_TCSS},
  author       = {Jiaxing Chen and Chengyi Xia and Matjaž Perc},
  doi          = {10.1109/TCSS.2024.3351173},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4267-4278},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {The SIQRS propagation model with quarantine on simplicial complexes},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph contrastive learning with negative propagation for
recommendation. <em>TCSS</em>, <em>11</em>(3), 4255–4266. (<a
href="https://doi.org/10.1109/TCSS.2024.3356071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous recommendation models build interest embeddings heavily relying on the observed interactions and optimize the embeddings with a contrast between the interactions and randomly sampled negative instances. To our knowledge, the negative interest signals remain unexplored in interest encoding, which merely serves losses for backpropagation. Besides, the sparse undifferentiated interactions inherently bring implicit bias in revealing users’ interests, leading to suboptimal interest prediction. The negative interest signals would be a piece of promising evidence to support detailed interest modeling. In this work, we propose a perturbed graph contrastive learning with negative propagation (PCNP) for recommendation, which introduces negative interest to assist interest modeling in a contrastive learning (CL) architecture. An auxiliary channel of negative interest learning generates a contrastive graph by negative sampling and propagates complementary embeddings of users and items to encode negative signals. The proposed PCNP contrasts positive and negative embeddings to promote interest modeling for recommendation. Extensive experiments demonstrate the capability of PCNP using two-level CL to alleviate interaction sparsity and bias issues for recommendation.},
  archive      = {J_TCSS},
  author       = {Meishan Liu and Meng Jian and Yulong Bai and Jiancan Wu and Lifang Wu},
  doi          = {10.1109/TCSS.2024.3356071},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4255-4266},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Graph contrastive learning with negative propagation for recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). When blockchain meets auction: A comprehensive survey.
<em>TCSS</em>, <em>11</em>(3), 4242–4254. (<a
href="https://doi.org/10.1109/TCSS.2024.3358176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed remarkable developments and increasingly deepened integrations between blockchain as a decentralized computing architecture and auction as an efficient resource allocation approach. Typically, blockchain can help provide a secured and trusted distributed environment for various auction scenarios, while auction is particularly suitable for designing resource allocation and pricing mechanisms in blockchain systems. As such, integrative research on blockchain and auction developed rapidly and attracted widespread attention in various fields ranging from academia to financial, industrial, and social services. However, a comprehensive survey on this interdisciplinary topic is still nonexistent, which motivates our work. In this article, we aim to fill this important research gap by reviewing the related literature. We first conducted a brief overview of blockchain technology and auction theory, and then systematically discussed the research progress on the existing blockchain research based on auction theory as well as auction research enabled by blockchain. Toward the end, we presented several open research issues and directions, aiming to provide useful guidance and reference for future research efforts.},
  archive      = {J_TCSS},
  author       = {Xuan Liu and Lu Liu and Yong Yuan and Yong-Hong Long and San-Xi Li and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2024.3358176},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4242-4254},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {When blockchain meets auction: A comprehensive survey},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Agent-network-computation-based evolutionary game model in
language competition. <em>TCSS</em>, <em>11</em>(3), 4226–4241. (<a
href="https://doi.org/10.1109/TCSS.2024.3351681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As language is intrinsic to the expression of culture, the rise and fall of a language directly affect the culture associated with it. Therefore, constructing a computational model to study the mechanisms of language competition and explore policies of language preservation is very important. We address the language system’s macroscopic aspects, such as the prestige of languages, the difficulty level of learning languages, and natives’ tolerance toward nonnative languages, as well as individual interactions at the microscopic level, and then propose an agent network computation-based evolutionary game model (ANC-EGM), including two major components—the definition of language attractiveness and the language competition game, to model a more realistic dynamic evolving language system. The replicator equation is adopted to solve the evolutionary equilibrium, and the stability of the equilibrium points is analyzed by the local stability analysis of the Jacobian matrix. The theoretical analysis and simulations illustrate that the ANC-EGM can comprehensively model the competition between two languages and estimate how individual interactions lead to the demise or coexistence of languages. We further validate the conclusions of the ANC-EGM on the empirical data of the Minnan dialect and Mandarin, which show that the ANC-EGM can provide an experimental computing platform for the in-depth study of language policy regulation and language evolution rules.},
  archive      = {J_TCSS},
  author       = {Hongrun Wu and Qiurong Wu and Zhenglong Xiang and Xiang Zhang and Lei Zhang and Yingpin Chen and Hui Wang and Jianhua Song},
  doi          = {10.1109/TCSS.2024.3351681},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4226-4241},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Agent-network-computation-based evolutionary game model in language competition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HGRec: Group recommendation with hypergraph convolutional
networks. <em>TCSS</em>, <em>11</em>(3), 4214–4225. (<a
href="https://doi.org/10.1109/TCSS.2024.3363843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems have shifted from personalization for individual users to consensus for groups as a result of people&#39;s growing tendency to join groups to participate in various everyday activities, like family meals and workplace reunions. This is because social networks have made it easier for people to participate in these kinds of events. Group recommendation is the process of suggesting items to groups. To derive group preferences, the majority of current approaches combine the individual preferences of group members utilizing heuristic or attention mechanism-based techniques. These approaches, however, have three issues. First, these approaches ignore the complex high-order interactions that occur both inside and outside of groups, just modeling the preferences of individual groups of users. Second, a group&#39;s ultimate decision is not always determined by the members’ preferences. Nevertheless, current approaches are not adequate to represent such preferences across groups. Last, data sparsity affects group recommendations due to the sparsity of group–item interactions. To overcome the aforementioned constraints, we propose employing hypergraph convolutional networks for group recommendation. Specifically, our design aims to achieve excellent group preferences by establishing a high-order preference extraction view represented by the hypergraph, a consistent preference extraction view represented by the overlap graph, and a conventional preference extraction view represented by the bipartite graph. The linkages between the three various views are then established by using cross-view contrastive learning, and the information between different views can be complementary, thereby improving each other. Comprehensive experiments on three publicly available datasets show that our method performs better than the state-of-the-art baseline.},
  archive      = {J_TCSS},
  author       = {Nan Wang and Dan Liu and Jin Zeng and Lijin Mu and Jinbao Li},
  doi          = {10.1109/TCSS.2024.3363843},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4214-4225},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {HGRec: Group recommendation with hypergraph convolutional networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Opinion dynamic games under one step ahead optimal control.
<em>TCSS</em>, <em>11</em>(3), 4202–4213. (<a
href="https://doi.org/10.1109/TCSS.2024.3364611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article generalizes two recently proposed opinion dynamics models with control. The generalized model consists of a standard model of agents interacting with each other, to which affine control inputs from players are added. The controls, influencing the opinions of agents, are exercised by entities called players, who specify targets, possibly conflicting, for agents. Three game-playing procedures are defined: sequential, parallel, and asynchronous. Each player has knowledge of the current state of all agents, but no other information about the other players. The player controls are designed using one step ahead optimization. This leads to several novel results: easily computable control policies for each player that depend only on the player&#39;s own information and conditions for convergence to the equilibrium as well as formulas for the latter. Comparisons showing advantages over prior Riccati equation-based methods for networks of different sizes are provided. The code to reproduce all examples and simulations is available on the GitHub site. Overall, the main contribution is the one step ahead optimal control (OSAOC) framework for influencing multiagent opinion dynamics in a decentralized game-theoretic setting.},
  archive      = {J_TCSS},
  author       = {Gabriel Gentil and Amit Bhaya},
  doi          = {10.1109/TCSS.2024.3364611},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4202-4213},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Opinion dynamic games under one step ahead optimal control},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DiEvD-SF: Disruptive event detection using continual machine
learning with selective forgetting. <em>TCSS</em>, <em>11</em>(3),
4189–4201. (<a href="https://doi.org/10.1109/TCSS.2024.3364544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting disruptive events (DEs), such as riots, protests, and natural calamities, from social media is essential for studying geopolitical dynamics. To automate the process, existing methods rely on classical machine learning (ML) models applied to static datasets, which is counterproductive. To detect DEs from dynamic data streams, this article introduces a novel DiEvD-SF framework, which uses continual machine learning (CML) with selective forgetting. Twitter (currently “X”) is used as a real-time and dynamic data source for validation. DiEvD-SF considers the temporal nature of DEs and “selectively forgets” outdated DEs through machine unlearning. To the best of our knowledge, this article is the first to apply CML with selective forgetting to discard outdated DEs and to continue learning about the new DEs. Extensive evaluation using a painstakingly collected Twitter dataset shows that the proposed framework continually identifies new DEs with an average incremental accuracy of 78.942% and successfully forgets old DEs with an average forgetting time of 118.498 seconds, which is better than the state-of-the-art. Additionally, computational analysis is performed to establish the effectiveness of the DiEvD-SF framework by applying various candidate selection strategies.},
  archive      = {J_TCSS},
  author       = {Aditi Seetha and Satyendra Singh Chouhan and Emmanuel S. Pilli and Vaskar Raychoudhury and Snehanshu Saha},
  doi          = {10.1109/TCSS.2024.3364544},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4189-4201},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {DiEvD-SF: Disruptive event detection using continual machine learning with selective forgetting},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). G-TransRec: A transformer-based next-item recommendation
with time prediction. <em>TCSS</em>, <em>11</em>(3), 4175–4188. (<a
href="https://doi.org/10.1109/TCSS.2024.3354315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, due to the surge in e-commerce, growing attention has been paid to how to recommend a customer&#39;s next purchase based on sequential or session-based data. However, most prior studies have generally focused on what items may be interesting for users, but have neglected the consideration of when the next items are likely to be purchased. Clearly, the timing information is an essential factor for companies to adopt proper selling strategies at the “right” time. In this study, a novel recommendation system, G-TransRec, is proposed to predict customers’ next items of interest with the potential purchase time by exploiting a user temporal interaction sequence. Moreover, by integrating the graph embedding technique, we include the global user information to explore more collaborative knowledge for effective recommendations. Several experiments were conducted on two real datasets to demonstrate the performance and superiority of the proposed model compared with the state-of-the-art methods on several evaluation metrics. We also use a case study to show the practicability of the proposed G-TransRec for users to recommend what they want at what time from a massive amount of merchandise.},
  archive      = {J_TCSS},
  author       = {Yi-Cheng Chen and Yen-Liang Chen and Chia-Hsiang Hsu},
  doi          = {10.1109/TCSS.2024.3354315},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4175-4188},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {G-TransRec: A transformer-based next-item recommendation with time prediction},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph-diffusion-based domain-invariant representation
learning for cross-domain facial expression recognition. <em>TCSS</em>,
<em>11</em>(3), 4163–4174. (<a
href="https://doi.org/10.1109/TCSS.2024.3355113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precondition that most of the existing facial expression recognition (FER) algorithms have succeeded lies in that the training (source) and test (target) samples are independent of each other and identically distributed. However, it is too strict to satisfy this precondition in the real-world. To this end, we propose a novel graph-diffusion-based domain-invariant representation learning (GDRL) model for the cross-domain FER scenario where there exist distribution shifts between various domains. Specifically, a low-dimensional space mapping strategy is first adopted to diminish the domain mismatch. Then, by skillfully combining the local graph embedding and affinity graph diffusion, the local geometric structures can be effectively modeled and the deeper higher-order relationships of samples from various domains can be captured. In addition, in order to better guide the transfer process and learn a more discriminative and invariant representation, we take into account the label consistency. Experimental results on four laboratory-controlled databases and two in-the-wild databases demonstrate that our proposed model can yield better recognition performance compared with state-of-the-art domain adaptation methods.},
  archive      = {J_TCSS},
  author       = {Run Wang and Peng Song and Wenming Zheng},
  doi          = {10.1109/TCSS.2024.3355113},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4163-4174},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Graph-diffusion-based domain-invariant representation learning for cross-domain facial expression recognition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding component relationships: A deep-learning-based
anomaly detection interpreter. <em>TCSS</em>, <em>11</em>(3), 4149–4162.
(<a href="https://doi.org/10.1109/TCSS.2024.3360435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the interpretability of deep learning (DL)-based models has been extensively explored in academia, applying existing interpretation methods to anomaly detection in industrial control systems (ICSs) poses challenges for two primary reasons. First, security experts in ICS have distinct interpretive priorities, emphasizing the need for stability and readability. Second, there are various types of device components in ICS, and the potential interactions between sensors and actuators are yet to be explored. To tackle the above challenges, we propose DeepINT, an interpreter for anomaly detection in ICS. In DeepINT, we adopt a search optimization algorithm to find the reference and capture feature importance by the backpropagation gradient to improve interpretation performance and reliability. In addition, we construct a finite difference-based interaction detection, which tests the interaction of different device components, in order to address the problem that actuators in ICS are not easily interpreted, meanwhile improving the comprehensiveness and accuracy of the interpretation results. In comprehensive experiments on two real water treatment datasets [secure water treatment (SWaT) and water distribution (WADI)], DeepINT shows excellent interpretation performance compared to the six state-of-the-art baseline methods, especially on the SWaT dataset, with a 60% improvement in interpretation accuracy. In addition, our method significantly improves the efficiency of interaction detection, which balances interpretation performance and time efficiency.},
  archive      = {J_TCSS},
  author       = {Lijuan Xu and Ziyu Han and Zhen Wang and Dawei Zhao},
  doi          = {10.1109/TCSS.2024.3360435},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4149-4162},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Finding component relationships: A deep-learning-based anomaly detection interpreter},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive understanding of code-mixed language
semantics using hierarchical transformer. <em>TCSS</em>, <em>11</em>(3),
4139–4148. (<a href="https://doi.org/10.1109/TCSS.2024.3360378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Being a popular mode of text-based communication in multilingual communities, code mixing in online social media has become an important subject to study. Learning the semantics and morphology of code-mixed language remains a key challenge due to the scarcity of data, the unavailability of robust, and language-invariant representation learning techniques. Any morphologically rich language can benefit from character, subword, and word-level embeddings, aiding in learning meaningful correlations. In this article, we explore a hierarchical transformer (HIT)-based architecture to learn the semantics of code-mixed languages. HIT consists of multiheaded self-attention (MSA) and outer product attention components to simultaneously comprehend the semantic and syntactic structures of code-mixed texts. We evaluate the proposed method across six Indian languages (Bengali, Gujarati, Hindi, Tamil, Telugu, and Malayalam) and Spanish for nine tasks on 17 datasets. The HIT model outperforms state-of-the-art code-mixed representation learning and multilingual language models on 13 datasets across eight tasks. We further demonstrate the generalizability of the HIT architecture using masked language modeling (MLM)-based pretraining, zero-shot learning (ZSL), and transfer learning approaches. Our empirical results show that the pretraining objectives significantly improve the performance of downstream tasks.},
  archive      = {J_TCSS},
  author       = {Tharun Suresh and Ayan Sengupta and Md Shad Akhtar and Tanmoy Chakraborty},
  doi          = {10.1109/TCSS.2024.3360378},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4139-4148},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A comprehensive understanding of code-mixed language semantics using hierarchical transformer},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on emergence of collective behavior for information
dissemination in complex networks. <em>TCSS</em>, <em>11</em>(3),
4127–4138. (<a href="https://doi.org/10.1109/TCSS.2024.3352611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collective behavior frequently emerges in this dynamic and interconnected world, making in-depth research into its societal impacts both highly significant and challenging. The emergence and development of collective behavior in social systems are intricately linked to the dissemination of event information. A rational dissemination model needs to be constructed as a foundation for analysis, exploring factors influencing collective behavior, and predicting the onset of such behaviors. During the information dissemination progress, individual interactions are exceedingly intricate and subject to dynamic changes, some of which may even involve nonlinear mutations. Therefore, this article dissects interpersonal interactions into psychological and behavioral dimensions, and establish an emergency dissemination model, considering the coevolution of dissemination strategies, and dissemination behaviors. Additionally, the influence of the initial probability distribution on strategies, dissemination cost, and time decay coefficients on the propagation trends was examined through simulation analysis. Building upon this model, a methodology is proposed for predicting the emergence timepoint from four indicators. Empirical validation and analysis substantiate the proposed approach, affirming its rationality, advancement, and efficacy in addressing the research objectives.},
  archive      = {J_TCSS},
  author       = {Shan Liu and Xiaoqing Wu},
  doi          = {10.1109/TCSS.2024.3352611},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4127-4138},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Research on emergence of collective behavior for information dissemination in complex networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DCL: Diversified graph recommendation with contrastive
learning. <em>TCSS</em>, <em>11</em>(3), 4114–4126. (<a
href="https://doi.org/10.1109/TCSS.2024.3355780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diversified recommendation systems have gained increasing popularity in recent years. Nowadays, the emerged graph neural networks (GNNs) have been used to improve the diversity performance. Although some progresses have been made, existing works purely focus on the user–item interactions and overlook the category information, which limits the capability to capture complex diversification among users or items and leads to poor performance. In this article, our target is to integrate full category information into user and item embeddings. To this end, we propose a diversified GNN-based recommendation systems diversified graph recommendation with contrastive learning (DCL). Specifically, we design three key components in our model: 1) the user–item interaction with category-related sampling enhances the interaction of unpopular items; 2) contrastive learning between users and categories shortens the distance of representations between users and their uninteracted categories; and 3) contrastive learning between items and categories diverges the distance of representations between items and their corresponding categories. By applying these three modules, we build a multitask training framework to achieve a balance between accuracy and diversity. Experiments on real-world datasets show that our proposed DCL achieves optimal diversity while paying a little price for accuracy.},
  archive      = {J_TCSS},
  author       = {Daohan Su and Bowen Fan and Zhi Zhang and Haoyan Fu and Zhida Qin},
  doi          = {10.1109/TCSS.2024.3355780},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4114-4126},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {DCL: Diversified graph recommendation with contrastive learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Core–periphery detection based on masked bayesian
nonnegative matrix factorization. <em>TCSS</em>, <em>11</em>(3),
4102–4113. (<a href="https://doi.org/10.1109/TCSS.2023.3347406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Core–periphery structure is an essential mesoscale feature in complex networks. Previous researches mostly focus on discriminative approaches, while in this work we propose a generative model called masked Bayesian nonnegative matrix factorization. We build the model using two pair affiliation matrices to indicate core–periphery pair associations and using a mask matrix to highlight connections to core nodes. We propose an approach to infer the model parameters and prove the convergence of variables with our approach. Besides the abilities as traditional approaches, it is able to identify core scores with overlapping core–periphery pairs. We verify the effectiveness of our method using randomly generated networks and real-world networks. Experimental results demonstrate that the proposed method outperforms traditional approaches.},
  archive      = {J_TCSS},
  author       = {Zhonghao Wang and Ru Yuan and Jiaye Fu and Ka-Chun Wong and Chengbin Peng},
  doi          = {10.1109/TCSS.2023.3347406},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4102-4113},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Core–Periphery detection based on masked bayesian nonnegative matrix factorization},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SEHF: A summary-enhanced hierarchical framework for
financial report sentiment analysis. <em>TCSS</em>, <em>11</em>(3),
4087–4101. (<a href="https://doi.org/10.1109/TCSS.2023.3323885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial reports serve as crucial resources for investors and researchers, providing analysts’ assessments of stocks that play a vital role in stock market applications. However, detecting analysts’ opinions and sentiments in financial reports is challenging. First, the formal and professional language used in these reports makes it difficult for previous methods to comprehend domain-specific knowledge. Second, financial reports often adopt lengthy and elaborate expressions to convey rich semantics, which exposes the existing methods to contextual information loss, especially on long-term dependencies. To address these problems, we propose a summary-enhanced hierarchical framework (SEHF), which leverages summary information to enhance financial report sentiment analysis. Our framework incorporates financial bidirectional and auto-regressive transformer (FinBART), equipped with extended position encoding to summarize lengthy report articles and capture long-range interactions. To mitigate information loss, we initially divide each report into segments and then propose the hierarchical analyst sentiment representation network (ASRN), which utilizes financial bidirectional encoder representation from transformer (FinBERT), bidirectional long short-term memory (BiLSTM)-Attention, and dendrite (DD) network to fuse information in the generated summary and report segments. Notably, FinBART and FinBERT are pretrained on large-scale financial corpora to effectively understand professional expressions. Furthermore, we construct a new dataset large-scale Chinese financial report (LCFR) for the lack of supervised datasets. Experimental results on LCFR and a benchmark dataset show that SEHF significantly outperforms state-of-the-art (SOTA) baselines, and the ablation study highlights the effectiveness of aggregating sentiment information in the summary and report segments.},
  archive      = {J_TCSS},
  author       = {Haozhou Li and Qinke Peng and Xinyuan Wang and Xu Mou and Yonghao Wang},
  doi          = {10.1109/TCSS.2023.3323885},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4087-4101},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {SEHF: A summary-enhanced hierarchical framework for financial report sentiment analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interaction trust-driven data distribution for vehicle
social networks: A matching theory approach. <em>TCSS</em>,
<em>11</em>(3), 4071–4086. (<a
href="https://doi.org/10.1109/TCSS.2023.3343084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid expansion of the Internet of Vehicles (IoVs), service providers deploy roadside units (RSUs), and base stations (BSs) close to vehicles. They can provide vehicles with computational offloading services quickly. In the context of vehicle social networks, where vehicles can communicate and share data with each other, the security and efficiency of data distribution are crucial. Unfortunately, the open nature of RSU BSs makes them vulnerable to malicious attackers, hence affecting the quality of the user experience. This article proposes a security trust degree incentive-based evaluation mechanism that calculates the security trust degree of vehicle users to RSU BSs through the continuous interaction between them in order to effectively address the aforementioned issues. Additionally, taking into account the competitive nature of task computation offloading between vehicle users and BSs, a stable matching algorithm is used to match each vehicle user with the most appropriate BS so that they can work together to prevent competition in task offloading and improve task offloading efficiency. Due to the limited number of BS matches and the dynamic position changes of vehicle users, we further increase the data distribution efficiency by calculating the vehicle user degree of relationship and connection probability to match vehicle users with similar preferences. Finally, our proposed scheme is validated via numerous simulations with enhanced security service performance in terms of vehicle task offloading, while data distribution efficiency are effectively improved.},
  archive      = {J_TCSS},
  author       = {Tengfei Cao and Jie Yi and Xiaoying Wang and Han Xiao and Changqiao Xu},
  doi          = {10.1109/TCSS.2023.3343084},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4071-4086},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Interaction trust-driven data distribution for vehicle social networks: A matching theory approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling the coupling propagation of information, behavior,
and disease in multilayer heterogeneous networks. <em>TCSS</em>,
<em>11</em>(3), 4058–4070. (<a
href="https://doi.org/10.1109/TCSS.2023.3306014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of internet, transportation network, and other technologies, the transmission of information and disease presents complex and diverse new modes, which are mainly manifested as the coupling transmission of information and disease in the cyber–physical–social space. Inspired by this phenomenon, this article proposes a multilayer network-based information–behavior–disease coupling (IBDN) transmission model for the process of information diffusion–behavior change–disease transmission. The IBDN model considers various factors such as psychological drivers of information dissemination, the impact of herd mentality on behavioral transmission, the disease transmission dynamics of the current COVID-19 Omicron mutant strain and relevant countermeasures, and the interconnections between information, behavior, and disease transmission. Furthermore, within the framework of the COVID-19 Omicron mutant strain pandemic, the proposed IBDN model was leveraged to assess the effects of the propagation parameters of each layer and the interlayer coupling parameters on the magnitude of the COVID-19 outbreak and the strain on medical resources. A sensitivity analysis was carried out to determine the variability of the basic reproductive number of the Omicron mutant strains across various nations. Finally, the findings of the experiment were subjected to a thorough examination of policy implications to furnish valuable perspectives for the formulation of effective epidemic prevention strategies in the face of severe COVID-19 situation.},
  archive      = {J_TCSS},
  author       = {Tianyi Luo and Duo Xu and Zhidong Cao and Pengfei Zhao and Jiaojiao Wang and Qingpeng Zhang},
  doi          = {10.1109/TCSS.2023.3306014},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4058-4070},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Modeling the coupling propagation of information, behavior, and disease in multilayer heterogeneous networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeGroot-based opinion formation under a global steering
mechanism. <em>TCSS</em>, <em>11</em>(3), 4040–4057. (<a
href="https://doi.org/10.1109/TCSS.2023.3330293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates how interacting agents arrive to a consensus or a polarized state. We study the opinion formation process under the effect of a global steering mechanism (GSM), which aggregates the opinion-driven stochastic agent states at the network level and feeds back to them a form of global information. We also propose a new two-layer agent-based opinion formation model, called GSM-DeGroot , that captures the coupled dynamics between agent-to-agent local interactions and the GSM&#39;s steering effect. This way, agents are subject to the effects of a DeGroot-like local opinion propagation, as well as to a wide variety of possible aggregated information that can affect their opinions, such as trending news feeds, press coverage, polls, elections, etc. Contrary to the standard DeGroot model, our model allows polarization to emerge by letting agents react to the global information in a stubborn differential way. Moreover, the introduced stochastic agent states produce event stream dynamics that can fit to real event data. We explore numerically the model dynamics to find regimes of qualitatively different behavior. We also challenge our model by fitting it to the dynamics of real topics that attracted the public attention and were recorded on Twitter. Our experiments show that the proposed model holds explanatory power, as it evidently captures real opinion formation dynamics via a relatively small set of interpretable parameters.},
  archive      = {J_TCSS},
  author       = {Ivan Conjeaud and Philipp Lorenz-Spreen and Argyris Kalogeratos},
  doi          = {10.1109/TCSS.2023.3330293},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4040-4057},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {DeGroot-based opinion formation under a global steering mechanism},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online summarization of microblog data: An aid in handling
disaster situations. <em>TCSS</em>, <em>11</em>(3), 4029–4039. (<a
href="https://doi.org/10.1109/TCSS.2023.3347520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During any natural disaster or unfortunate accident, both civilians and responders need information on an urgent basis. In such events, microblogging sites particularly Twitter plays an important role in providing real-time information. The raw form of microblog tweets is prodigiously informative but massive in size. The end-users and data analysts have to go through millions of tweets before extraction of any information. To ease the process and extract only relevant information, artificial intelligence (AI)-based techniques can be incorporated to generate summaries from the incoming information. Moreover, tweets keep on arriving continuously in a streaming manner, and therefore in ideal cases, the summaries also need to be updated continuously. In this work, we have proposed a clustering-based summary generation approach that takes multiviewed representations of data and utilizes a new variant of generative adversarial network (GAN) named triple-GAN to perform clustering. Triple-GAN consists of three networks, a generator, a discriminator, and a separator. Maintaining equilibrium among these networks requires proper parameter tuning which makes training of GAN difficult. In the literature, GAN-based techniques have been extensively applied to image datasets. In the proposed method, we have explored the usage of GAN for text data in an unsupervised manner and the analysis of the training of GAN has also been reported. The developed method opens up a new direction in utilizing GAN for solving clustering problem of text data. The proposed method is applied to two versions of four disaster-based microblog datasets and obtained results are compared with many existing and a few baseline methods. The comparative study illustrates the superiority and efficacy of the developed method.},
  archive      = {J_TCSS},
  author       = {Dipanjyoti Paul and Shivani Rana and Sriparna Saha and Jimson Mathew},
  doi          = {10.1109/TCSS.2023.3347520},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4029-4039},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Online summarization of microblog data: An aid in handling disaster situations},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge-associated embedding for memory-aware knowledge
tracing. <em>TCSS</em>, <em>11</em>(3), 4016–4028. (<a
href="https://doi.org/10.1109/TCSS.2023.3306909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT) refers to predicting learners’ performance in the future according to their historical learning interactions, which has become an essential task for the computer-aided education (CAE) system. Recent studies alleviate the data sparsity problem by mining higher-order information between questions and skills. However, the effect of multiple skills in the question is not distinguished, and various learning behaviors need to be better modeled. In this article, we propose a knowledge-associated embedding for the memory-aware KT (KMKT) framework. Specifically, we first construct a question-skill bipartite graph with attribute features. A knowledge-associated embedding (KAE) module is proposed to capture the distinctiveness of multiskills via the process of knowledge propagation and knowledge aggregation based on predefined knowledge-paths. Then, to simulate the memory recall phenomenon of the learners in KT, we design a memory-aware module for long short-term memory (MA-LSTM) networks. A temporal attention layer in MA-LSTM is proposed to learn the forgetting mechanism of the human brain. Finally, we introduce a learning-gain (LG) layer to obtain learners’ benefits after each exercise. Extensive experiments on four real-world datasets illustrate that our KMKT model performs better than the other baseline models, which verifies the effectiveness of our work.},
  archive      = {J_TCSS},
  author       = {Jiawei Li and Yuanfei Deng and Shun Mao and Yixiu Qin and Yuncheng Jiang},
  doi          = {10.1109/TCSS.2023.3306909},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4016-4028},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Knowledge-associated embedding for memory-aware knowledge tracing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ZETAR: Modeling and computational design of strategic and
adaptive compliance policies. <em>TCSS</em>, <em>11</em>(3), 4001–4015.
(<a href="https://doi.org/10.1109/TCSS.2023.3323539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compliance management plays an important role in mitigating insider threats. Incentive design is a proactive and noninvasive approach to achieving compliance by aligning an insider’s incentive with the defender’s security objective, which motivates (rather than commands) an insider to act in the organization’s interests. Controlling insiders’ incentives for population-level compliance is challenging because they are neither precisely known nor directly controllable. To this end, we develop ZEro-Trust Audit with strategic Recommendation (ZETAR), a zero-trust audit and recommendation framework, to provide a quantitative approach to model insiders’ incentives and design customized recommendation policies to improve their compliance. We formulate primal and dual convex programs to compute the optimal bespoke recommendation policies. We create the theoretical underpinning for understanding trust, compliance, and satisfaction, which leads to scoring mechanisms of how compliant and persuadable an insider is. After classifying insiders as malicious, self-interested, or amenable based on their incentive misalignment levels with the defender, we establish bespoke information disclosure principles for these insiders of different incentive categories. We identify the policy separability principle and the set convexity, which enable finite-step algorithms to efficiently learn the completely trustworthy (CT) policy set when insiders’ incentives are unknown. Finally, we present a case study to corroborate the design. Our results show that ZETAR can well adapt to insiders with different risk and compliance attitudes and significantly improve compliance. Moreover, trustworthy recommendations can provably promote cyber hygiene and insiders’ satisfaction.},
  archive      = {J_TCSS},
  author       = {Linan Huang and Quanyan Zhu},
  doi          = {10.1109/TCSS.2023.3323539},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {4001-4015},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {ZETAR: Modeling and computational design of strategic and adaptive compliance policies},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TEGDetector: A phishing detector that knows evolving
transaction behaviors. <em>TCSS</em>, <em>11</em>(3), 3988–4000. (<a
href="https://doi.org/10.1109/TCSS.2023.3323512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, phishing scams have posed a significant threat to blockchains. Phishing detectors direct their efforts in hunting phishing addresses. Most of the detectors extract target addresses’ transaction behavior features by random walking or constructing static subgraphs. The random walking methods, unfortunately, usually miss structural information due to limited sampling sequence length, while the static subgraph methods tend to ignore temporal features lying in the evolving transaction behaviors. More importantly, their performance undergoes severe degradation when the malicious users intentionally hide phishing behaviors. To address these challenges, we propose TEGDetector, a dynamic graph classifier that learns the evolving behavior features from transaction evolution graphs (TEGs). First, we cast the transaction series into multiple time slices, capturing the target address’s transaction behaviors in different periods. Then, we provide a fast nonparametric phishing detector (FD) to narrow down the search space of suspicious addresses. Finally, TEGDetector considers both the spatial and temporal evolutions toward a complete characterization of the evolving transaction behaviors. Moreover, TEGDetector utilizes adaptively learned time coefficient to pay distinct attention to different periods, which provides several novel insights. Extensive experiments on the large-scale Ethereum transaction dataset demonstrate that the proposed method achieves state-of-the-art (SOTA) detection performance. The code of TEGDetector is open sourced at https://github.com/Seaocn/TEGDetector .},
  archive      = {J_TCSS},
  author       = {Haibin Zheng and Minying Ma and Haonan Ma and Jinyin Chen and Haiyang Xiong and Zhijun Yang},
  doi          = {10.1109/TCSS.2023.3323512},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3988-4000},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {TEGDetector: A phishing detector that knows evolving transaction behaviors},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameter identification and refinement for parallel PCB
inspection in cyber–physical–social systems. <em>TCSS</em>,
<em>11</em>(3), 3978–3987. (<a
href="https://doi.org/10.1109/TCSS.2023.3330762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Replacing manual inspection, automated optical inspection (AOI) equipment is widely used in printed circuit board (PCB) factories for automatic PCB defect segmentation. However, parameter refinement of AOI devices has gradually become an efficiency bottleneck in AOI usage, posing a highly challenging task. Since a large number of AOI parameters and different types of inspected objects make timely proper parameter refinement for clear images quite difficult. Considering this, we propose the concept of parallel PCB inspection in cyber–physical–social systems (CPSSs). Based on artificial systems, computational experiments, and parallel execution (ACP) theory with automatic parameter identification and refinement, we perform descriptive intelligence to build an artificial imaging system, obtain knowledge about the mapping relationships of parameter settings and imaging results, and realize automatic parameter identification given image input; conduct predictive intelligence to obtain image quality assessment results and maximize quality score for refinement strategies; and carry out prescriptive intelligence to guide parameter refinement for better imaging. This system could guide engineers proactively with constructive suggestions on parameter refinement when imaging failures occur, greatly reducing the training cost of engineers while improving work efficiency and work quality. To validate that our parallel PCB inspection could perform automatic AOI results evaluation without human participation, we evaluate it on distortion-free and different distortion images and confirm image quality score is positively associated with segmentation accuracy.},
  archive      = {J_TCSS},
  author       = {Yansong Cao and Yutong Wang and Jiangong Wang and Yonglin Tian and Xiao Wang and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3330762},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3978-3987},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Parameter identification and refinement for parallel PCB inspection in Cyber–Physical–Social systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Social web in IoT: Can evolutionary computation and
clustering improve ontology matching for social web of things?
<em>TCSS</em>, <em>11</em>(3), 3966–3977. (<a
href="https://doi.org/10.1109/TCSS.2023.3332562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many Internet of Things (IoT) applications can benefit from Social Web of Things (S-WoT) methods that enable knowledge discovery and help solving interoperability problems. The semantic modeling of S-WoT is the main emphasis of this work where we suggest a novel solution, evolutionary clustering for ontology matching (ECOM), to explore correlations between S-WoT data using clustering and evolutionary computation methodologies. The ECOM approach uses a variety of clustering techniques to aggregate S-WoT data&#39;s strongly related ontologies into comparable categories. The principle is to match concepts of similar groups rather than full concepts of two ontologies, which necessitates splitting examples of each ontology into similar groups. We design two clustering algorithms for ontology matching using conventional methods, as well as sophisticated clustering techniques. Moreover, we develop an intelligent matching algorithm that uses evolutionary computation to quickly converge to (or ideally identify) optimal matches. Numerous simulations have been conducted using various ontology databases to demonstrate the application and precision of ECOM. Our findings clearly show that ECOM has better results when compared to cutting-edge ontology matching methods. The F-measure of ECOM exceeds 95% whereas it does not reach 90% for all baseline methods. The results also confirm that ECOM scales with big data in S-WoT environments.},
  archive      = {J_TCSS},
  author       = {Asma Belhadi and Djamel Djenouri and Youcef Djenouri and Ahmed Nabil Belbachir and Gautam Srivastava},
  doi          = {10.1109/TCSS.2023.3332562},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3966-3977},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Social web in IoT: Can evolutionary computation and clustering improve ontology matching for social web of things?},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-supervised contrastive learning for bundle
recommendation. <em>TCSS</em>, <em>11</em>(3), 3955–3965. (<a
href="https://doi.org/10.1109/TCSS.2023.3331255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised contrastive learning has well advanced the development of bundle recommendation. However, self-supervised contrastive learning may misclassify some positive samples as negative samples, resulting in suboptimal models. Therefore, the industry has proposed supervised contrastive learning to alleviate this drawback. Inspired by this idea, we seek a more elegant contrastive learning paradigm in the field of recommendation, so we propose a dual-supervised contrastive learning for bundle recommendation (DSCBR), which integrates supervised and self-supervised contrastive learning to exploit the full potential of contrastive learning. Specifically, we first construct self-supervised contrastive learning between the two different views (bundle view and item view), which encourages the alignment of the two separately learned views and boosts the effectiveness of learned representations. Second, we use the interaction information to construct supervised contrastive learning and leverage the bundle–bundle cooccurrence graph for further enhancement. By introducing supervised contrastive learning, our model explicitly models user and bundle proximity in different views, improving the model&#39;s robustness and generalization. Finally, we jointly perform self-supervised and supervised contrastive learning across multiple views. Extensive experiments on three public datasets demonstrate the effectiveness of our model.},
  archive      = {J_TCSS},
  author       = {Chuanjiu Wu and Huanhuan Yuan and Pengpeng Zhao and Jianfeng Qu and Victor S. Sheng and Guanfeng Liu},
  doi          = {10.1109/TCSS.2023.3331255},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3955-3965},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Dual-supervised contrastive learning for bundle recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GDN-CMCF: A gated disentangled network with cross-modality
consensus fusion for multimodal named entity recognition. <em>TCSS</em>,
<em>11</em>(3), 3944–3954. (<a
href="https://doi.org/10.1109/TCSS.2023.3323402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal named entity recognition (MNER) is a crucial task in social systems of artificial intelligence that requires precise identification of named entities in sentences using both visual and textual information. Previous methods have focused on capturing fine-grained visual features and developing complex fusion procedures. However, these approaches overlook the heterogeneity gap and loss of original modality uniqueness that may occur during fusion, leading to incorrect entity identification. This article proposes a novel approach for MNER called a gated disentangled network with cross-modality consensus fusion (GDN-CMCF) to address the above challenges. Specifically, to eliminate cross-modality variation, we propose a cross-modality consensus fusion module that generates a consensus representation by learning inter- and intramodality interactions with a designed commonality constraint. We then introduce a gated disentanglement module to separate modality-relevant features from support and auxiliary modalities, which further filters out extraneous information while retaining the uniqueness of unimodal features. Experimental results on two real public datasets are provided to verify the effectiveness of our proposed GDN-CMCF. The source code of this article can be found at https://github.com/HaoDavis/GDN-CMCF .},
  archive      = {J_TCSS},
  author       = {Guoheng Huang and Qin He and Zihao Dai and Guo Zhong and Xiaochen Yuan and Chi-Man Pun},
  doi          = {10.1109/TCSS.2023.3323402},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3944-3954},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {GDN-CMCF: A gated disentangled network with cross-modality consensus fusion for multimodal named entity recognition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximizing <span
class="math inline">(<em>k</em>, <em>L</em>)</span>-core with edge
augmentation in multilayer graphs. <em>TCSS</em>, <em>11</em>(3),
3931–3943. (<a href="https://doi.org/10.1109/TCSS.2023.3332091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While most previous work pays attention on extracting dense subgraphs, such as $k$ -cores, we argue that augmenting the graph to maximize the size of dense subgraphs is also very important and finds many applications. Therefore, in this article, we study the dense subgraph augmentation problem in multilayer graphs. Specifically, we propose the notion of $(k,L)$ -core to model the dense subgraphs in multilayer graphs and propose a new research problem, budgeted maximal $(k,L)$ -core augmentation (BMA) problem, which adds at most $b$ edges in the multilayer graphs to maximize the size of $(k,L)$ -core. We prove the NP-hardness of the general BMA problem when $k\geq 2$ and devise a polynomial-time algorithm to find the optimal solution for a special case of BMA, i.e., $(2,1)$ -BMA. We then devise an effective algorithm, named search for optimum and reorder adaptively (SORA), with various performance-improving strategies to tackle the general BMA problem. We evaluate the performance of the proposed approaches on multiple large-scale datasets and compare them with the state-of-the-art baselines. Experimental results indicate that our proposed approaches significantly outperform the baselines in terms of solution quality and efficiency.},
  archive      = {J_TCSS},
  author       = {Chih-Chieh Chang and Chia-Hsun Lu and Shun-Jen Teng and Ming-Yi Chang and Ya-Chi Ho and Chih-Ya Shen},
  doi          = {10.1109/TCSS.2023.3332091},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3931-3943},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Maximizing $(k,L)$-core with edge augmentation in multilayer graphs},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple views to free graph augmentations. <em>TCSS</em>,
<em>11</em>(3), 3920–3930. (<a
href="https://doi.org/10.1109/TCSS.2023.3332044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised graph representation learning (GRL) has shown great success in scientific research and real-world applications. Nevertheless, one obstacle in GRL is the demand for graph augmentation (GA), which deeply impacts the representation qualities. On the one hand, GA supplements the data amount and enhances the robustness and quality of the representations. On the other hand, collocating appropriate augmentations claims nontrivial attempts. In this article, a new method to free GA is provided building a novel fuzzy view and two crisp views of the original graph. As all the views are transformed from the original graph, they are semantically similar and naturally considered to possess high-quality positive samples. In this way, the data amount is compensated to a degree without changing the raw node attributes or graph topology. Additionally, to ensure the diversity of the positives, asymmetric renormalization and noise perturbation are adopted. Experiments toward node-level tasks on several real-world datasets demonstrate the competition against several state-of-the-art models.},
  archive      = {J_TCSS},
  author       = {Yue-Na Lin and Hai-Chun Cai and Chun-Yang Zhang and C. L. Philip Chen},
  doi          = {10.1109/TCSS.2023.3332044},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3920-3930},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Multiple views to free graph augmentations},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimized weights for heterogeneous epidemic spreading
networks: A constrained cooperative coevolution strategy. <em>TCSS</em>,
<em>11</em>(3), 3911–3919. (<a
href="https://doi.org/10.1109/TCSS.2023.3323400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wide spreading of COVID-19 all over the world raises numerous focus on the epidemic containment problem. Different from the traditional epidemic control strategies that focus on quarantine and vaccination, we seek to control the epidemic from a network science perspective, i.e., by adjusting the weights of the epidemic spreading networks. Moreover, considering the limitations on the available resources, the dynamic constrained optimization problem of weights’ adaptation for heterogeneous epidemic spreading networks is investigated. Due to the powerful ability of searching for global optimum, evolutionary algorithms (EAs) are used as optimizers. One major difficulty is that the dimension of the problem is increasing exponentially with the network size and most existing EAs cannot achieve satisfiable performance on large-scale optimization problems. To address this issue, a novel constrained cooperative coevolution ( $C^{3}$ ) strategy, which can separate the original large-scale problem into different subcomponents, is used to achieve the tradeoff between the constraint and objective function.},
  archive      = {J_TCSS},
  author       = {Yun Feng and Yaonan Wang and Bing-Chuan Wang and Li Ding},
  doi          = {10.1109/TCSS.2023.3323400},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3911-3919},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Optimized weights for heterogeneous epidemic spreading networks: A constrained cooperative coevolution strategy},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection and localization of firearm carriers in complex
scenes for improved safety measures. <em>TCSS</em>, <em>11</em>(3),
3900–3910. (<a href="https://doi.org/10.1109/TCSS.2023.3312335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting firearms and accurately localizing individuals carrying them in images or videos is of paramount importance in security, surveillance, and content customization. However, this task presents significant challenges in complex environments due to clutter and the diverse shapes of firearms. To address this problem, we propose a novel approach that leverages human–firearm interaction information, which provides valuable clues for localizing firearm carriers. Our approach incorporates an attention mechanism that effectively distinguishes humans and firearms from the background by focusing on relevant areas. Additionally, we introduce a saliency-driven locality-preserving constraint to learn essential features while preserving foreground information in the input image. By combining these components, our approach achieves exceptional results on a newly proposed dataset. To handle inputs of varying sizes, we pass paired human–firearm instances with attention masks as channels through a deep network for feature computation, utilizing an adaptive average pooling (AAP) layer. We extensively evaluate our approach against existing methods in human–object interaction (HOI) detection and achieve significant results (AP = 77.8%) compared to the baseline approach (AP = 63.1%). This demonstrates the effectiveness of leveraging attention mechanisms and saliency-driven locality preservation for accurate human–firearm interaction detection. Our findings contribute to advancing the fields of security and surveillance, enabling more efficient firearm localization and identification in diverse scenarios.},
  archive      = {J_TCSS},
  author       = {Arif Mahmood and Abdul Basit and Muhammad Akhtar Munir and Mohsen Ali},
  doi          = {10.1109/TCSS.2023.3312335},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3900-3910},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Detection and localization of firearm carriers in complex scenes for improved safety measures},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Social privacy-preserving modeling based on graphical
evolutionary game and infectious disease dissemination dynamics.
<em>TCSS</em>, <em>11</em>(3), 3882–3899. (<a
href="https://doi.org/10.1109/TCSS.2023.3339551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although social network provides more convenience for people&#39;s daily communication, it also faces the risk of personal privacy leakage. How to effectively evaluate and protect personal privacy has become a challenging issue in social networks. In this article, we propose a risk assessment-based privacy-preserving model for social networks, which is based on graphical evolutionary game theory and infectious disease dissemination dynamics model. In our scheme, a privacy risk assessment model is constructed to evaluate the importance degree of users’ privacy information and measure the leakage risk of users’ privacy information. Second, due to the heterogeneity of social networks, a graphical evolutionary game model of user privacy information forwarding behaviors is built to quantify and measure the strategy (or behavior) changes of different social users. Further, we construct a privacy-preserving information dissemination model, which is based on infectious disease dissemination model combined with graphical evolutionary game theory. Our risk assessment-based privacy-preserving model is to accurately characterize the dissemination of privacy information and reduce the transmission of privacy information, so as to protect social users’ privacy information. Related experimental results show the effectiveness of our privacy-preserving model by adjusting the payoff of social users.},
  archive      = {J_TCSS},
  author       = {Ke Gu and CaoQianJin Li and Yang Deng},
  doi          = {10.1109/TCSS.2023.3339551},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3882-3899},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Social privacy-preserving modeling based on graphical evolutionary game and infectious disease dissemination dynamics},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Building resilience in supply chains: A knowledge
graph-based risk management framework. <em>TCSS</em>, <em>11</em>(3),
3873–3881. (<a href="https://doi.org/10.1109/TCSS.2023.3334768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging technology, the knowledge graph (KG) has been successfully applied in various industries. Though some potential benefits of the KG have been identified, there is still little work on implementing the KG in supply chain risk management (SCRM). This study develops a KG-based risk management framework to improve the resilience of Supply Chains (SCs). Specifically, the construction of the SC knowledge graph (SC-KG) framework, including the implementation steps, is presented in detail for the purpose of SC knowledge retrieval, data visualization analysis, risk monitoring, early warning, and decision support. Furthermore, the SC-KG is well constructed to build a scenario-based SCRM framework under consideration of the severity of disruptions. Especially during long-term disruptions, the continuity of SCs is maintained through the employment of a product change strategy and a structurally scalable and dynamically adapted network design method. The findings of the study are instructive for SC managers in adopting digital technologies for SC mitigation and recovery under disruptions. Finally, a practical SC-KG containing over 2.5 million entities and 11 types of relationships has been developed and its basic functions have been implemented, which contributes to improving the quality of SC management.},
  archive      = {J_TCSS},
  author       = {Yi Yang and Chen Peng and En-Zhi Cao and Wenxuan Zou},
  doi          = {10.1109/TCSS.2023.3334768},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3873-3881},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Building resilience in supply chains: A knowledge graph-based risk management framework},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EAE-GAN: Emotion-aware emoji generative adversarial network
for computational modeling diverse and fine-grained human emotions.
<em>TCSS</em>, <em>11</em>(3), 3862–3872. (<a
href="https://doi.org/10.1109/TCSS.2023.3329434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing ubiquity and broad usage, emojis are widely used as a universal visual language, which complements the intentions and emotions beyond the textual data. Despite the critical role of representing emotion, existing emojis neglect the subtle and complex properties of human emotion in that only countable and finite face emojis exist in a categorical manner. In this article, we propose a novel approach to facial emoji generation, which can control the emotional degree of generated emojis for more complex and detailed usage on online conversations. In other words, we develop a new emotion-aware emoji generative adversarial network, which is capable of generating an emoji that expresses a given emotion distribution. In this way, our approach aims to map fine-grained emotions to expressive emojis. Both quantitative and qualitative evaluation demonstrate that our approach can successfully generate high-quality emoji-like images by representing a wide range of emotions. To the best of our knowledge, this is the first approach to use the deep generative model from the standpoint of the emoji&#39;s emotional role, which can further promote more interactive and effective online communication.},
  archive      = {J_TCSS},
  author       = {SangEun Lee and Seoyun Kim and Yeonju Chu and JeongWon Choi and Eunil Park and Simon S. Woo},
  doi          = {10.1109/TCSS.2023.3329434},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3862-3872},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {EAE-GAN: Emotion-aware emoji generative adversarial network for computational modeling diverse and fine-grained human emotions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mutual influence in citation and cooperation patterns.
<em>TCSS</em>, <em>11</em>(3), 3851–3861. (<a
href="https://doi.org/10.1109/TCSS.2023.3325264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring the influence of scientists and their activities on science and society is important and indeed essential for many studies. Despite the substantial efforts devoted to exploring the influence’s measures and patterns of an individual scientific enterprise, it remains unclear how to quantify the mutual impact of multiple scientific activities. This work quantifies the relationship between the scientists’ interactive activities and their influences with different patterns in the AMiner dataset. Specifically, inflation treatment and field normalization are introduced to process the big data of paper citations as the scientist’s influence, and then the evolution of the influence is investigated for scientific activities in the citation and cooperation patterns through the Hawkes process. The results show that elite scientists have higher individual and interaction influences than ordinary scientists in all patterns found in the study, with permutation tests verifying the significance of the new findings. Moreover, the study compares the patterns found in two largest disciplines, i.e., STEM and Humanities, revealing the higher value of individual influence in STEM than in Humanities. Furthermore, it is found that the opposite trend of STEM and Humanities in the cooperation pattern suggests different cooperation habits of scientists in different disciplines. Overall, this investigation provides a feasible approach to addressing the scientific influence issue and deepening the quantitative understanding of the mutual influence of multiple scientific activities in science and society.},
  archive      = {J_TCSS},
  author       = {Chenbo Fu and Haogeng Luo and Xuejiao Liang and Yong Min and Qi Xuan and Guanrong Chen},
  doi          = {10.1109/TCSS.2023.3325264},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3851-3861},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Mutual influence in citation and cooperation patterns},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GA-based multipopulation synergistic gene screening strategy
on critical nodes detection. <em>TCSS</em>, <em>11</em>(3), 3839–3850.
(<a href="https://doi.org/10.1109/TCSS.2023.3325263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Critical node detection (CND) is commonly used to detect nodes with a high impact on network robustness. It has been widely used in disease propagation, social networks, communications, and other fields. As a nondeterministic polynomial-time (NP)-complete problem, the efficiency of solving CND severely limits the scale of the available network. Fortunately, the evolutionary algorithm (EA) is an effective method to solve this problem. However, although EA improves the global search capability of the algorithm by preserving gene diversity, it also introduces many inferior genes, thus expanding the candidate solution space, reducing the search efficiency, and making it difficult to apply the pruning algorithm directly to its solution space. Hence, indirectly reducing the solution space of EA by deleting inferior genes is a feasible pruning method; however, the interaction of multiple genes affects the quality of CND solutions, making it a challenge to pick out inferior individual genes. Therefore, this work proposes a multipopulation synergistic gene screening algorithm based on the parallelism of EA and combined with Ensemble learning for identifying low-quality genes and removing them as a way of pruning the solution space of the algorithm and improving the search efficiency. The algorithm encodes all nodes in the graph as the gene pool of EA and treats a single population as a weak learner to screen the dominant genes in the gene pool and achieve fast pruning of EA’s solution space by integrating the dominant individuals in multiple populations. In this work, the experiments demonstrate the effectiveness of the proposed method and analyze the effect of different network structures on the algorithm.},
  archive      = {J_TCSS},
  author       = {Shanqing Yu and Jiaxiang Li and Xu Fang and Yongqi Wang and Jinhuan Wang and Qi Xuan and Chenbo Fu},
  doi          = {10.1109/TCSS.2023.3325263},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3839-3850},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {GA-based multipopulation synergistic gene screening strategy on critical nodes detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiattribute e-CARGO task assignment model based on
adaptive heterogeneous residual networks. <em>TCSS</em>, <em>11</em>(3),
3826–3838. (<a href="https://doi.org/10.1109/TCSS.2023.3344173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowd sensing (MCS) is an emerging approach to collect data using smart devices. In MCS, task assignment is described as assigning existing tasks to known workers outside the constraints of task demand attributes and worker attributes, and maximizing the profit of the platform. However, workers and tasks often exist in different environments and heterogeneous features such as workers with attributes are not considered, leading to nondeterministic polynomial (NP)-hard task assignment problems. To optimize such problems, this article proposes a multiattribute environments-classes, agents, roles, groups, and objects (E-CARGO) task assignment model based on adaptive heterogeneous residual networks (AHRNets). The AHRNet is integrated into deep reinforcement learning (DRL) to optimize the NP-hard problem, dynamically adjust task assignment decisions and learn the relationship between workers with different attributes and task requirements. Multiattribute E-CARGO uses group task assignment policy to obtain the ideal worker-task assignment relationship. Compared with traditional heuristic algorithms for solving NP-hard, this method has the flexibility and applicability of adaptive networks, enabling the solver to interact with and adapt to new environments and generalize its experience to different situations. Under various experimental conditions, a large number of numerical results show that this method can achieve better results than the reference scheme.},
  archive      = {J_TCSS},
  author       = {Zhaowei Liu and Zongxing Zhao},
  doi          = {10.1109/TCSS.2023.3344173},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3826-3838},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Multiattribute E-CARGO task assignment model based on adaptive heterogeneous residual networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Link prediction by combining local structure similarity with
node behavior synchronization. <em>TCSS</em>, <em>11</em>(3), 3816–3825.
(<a href="https://doi.org/10.1109/TCSS.2023.3335295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction plays a crucial role in discovering missing information and understanding evolutionary mechanisms in complex networks, so several algorithms have been proposed. However, existing link prediction algorithms usually rely only on structural information, limiting the potential for further accuracy improvement. Recently, the significance of node behavior synchronization in network reconstruction has emerged. Both link prediction and network reconfiguration aim to reveal the underlying network structure, so node behavior synchronization has the potential to improve link prediction accuracy. In this study, we propose a mutual information-based method to quantitatively measure node behavior synchronization, which is more suitable for link prediction and yields more stable performance than the methods based on node behavior&#39;s temporal similarity. Further, we propose a link prediction algorithm that combines local structural similarity with node behavior synchronization. Experimental results on real-life networks show that the proposed method is competitive in accuracy compared to methods relying solely on network structure or exploiting information about node behavior. In addition, the analysis of the prediction performance with different combination ratios reveals the role of node behavior synchronization in different types of real networks. Our study not only improves the performance of link prediction, but also helps to reveal the role of node behavior synchronization in different types of networks.},
  archive      = {J_TCSS},
  author       = {Sheng-yue Jiang and Xiao-Ke Xu and Jing Xiao},
  doi          = {10.1109/TCSS.2023.3335295},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3816-3825},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Link prediction by combining local structure similarity with node behavior synchronization},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced task allocation algorithm for mobile
crowdsourcing based on spatiotemporal attention network. <em>TCSS</em>,
<em>11</em>(3), 3803–3815. (<a
href="https://doi.org/10.1109/TCSS.2023.3332564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of GPS-enabled smart devices and the increased availability of wireless networks, mobile crowdsourcing system (MCS) has recently been proposed as a framework that automatically requests workers to perform location sensitive tasks. In the task allocation problem of MCS, existing algorithms lack consideration of the impact of nonadjacent and discontinuous execution of tasks on task allocation. Workers may have different task preferences in different time periods. Nonadjacent and discontinuous tasks provide important correlations for understanding workers’ behavior. This article introduces a novel task allocation algorithm based on spatiotemporal attention network (STATA). STATA takes into account factors such as the spatiotemporal distribution of tasks and workers as well as the location preferences and abilities of workers, and integrates them into a unified network for modeling. First, all historical tasks performed by workers are aggregated to obtain the correlation of all historical tasks. Then, the most plausible candidate tasks are recalled from the weighted representation for allocation. STATA utilizes the spatiotemporal attention mechanism to capture the relationship between these factors, ultimately improving the accuracy of task allocation. Extensive experiments demonstrate that the STATA model exhibits superior performance in terms of task allocation accuracy and practical application capabilities.},
  archive      = {J_TCSS},
  author       = {Bingxu Zhao and Hongbin Dong and Yingjie Wang and Xiaolin Gao and Tingwei Pan},
  doi          = {10.1109/TCSS.2023.3332564},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3803-3815},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An enhanced task allocation algorithm for mobile crowdsourcing based on spatiotemporal attention network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dynamic evolution model for decentralized autonomous car
clusters in a highway scene. <em>TCSS</em>, <em>11</em>(3), 3792–3802.
(<a href="https://doi.org/10.1109/TCSS.2023.3328930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster evolution is a challenging problem for vehicular ad hoc network (VANET) in a highway scene with fast moving autonomous vehicles and frequent cluster topology changes. Most of the existing studies analyze the cluster evolution behavior of cluster heads (CHs), and these approaches lead to frequent changes in vehicle structure when CHs change, which easily makes the cluster unstable. In this work, we propose a decentralized autonomous car cluster dynamic evolution model. First, we define a decentralized cluster structure. Then, we analyze the cluster evolution behavior and propose a maintenance method. Next, we define eight vehicle states and their transitions. Finally, we introduce the cluster dynamic evolution model and the collaboration model. The results of extensive simulation experiments show that our method can effectively maintain the consistency of cluster consensus and improve the stability of the cluster structure compared with the centralized cluster maintenance method.},
  archive      = {J_TCSS},
  author       = {Jiujun Cheng and Huiyu Sun and Zhangkai Ni and Aiguo Zhou},
  doi          = {10.1109/TCSS.2023.3328930},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3792-3802},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A dynamic evolution model for decentralized autonomous car clusters in a highway scene},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Open data in the digital economy: An evolutionary game
theory perspective. <em>TCSS</em>, <em>11</em>(3), 3780–3791. (<a
href="https://doi.org/10.1109/TCSS.2023.3324087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open data, as an essential element in the sustainable development of the digital economy, is highly valued by many relevant sectors in the implementation process. However, most studies suppose that there are only data providers and users in the open data process and ignore the existence of data regulators. In order to establish long-term green supply relationships between multistakeholders, we hereby introduce data regulators and propose an evolutionary game model to observe the cooperation tendency of multistakeholders (data providers, users, and regulators). The newly proposed game model enables us to intensively study the trading behavior which can be realized as strategies and payoff functions of the data providers, users, and regulators. Besides, a replicator dynamic system is built to study evolutionary stable strategies of multistakeholders. In simulations, we investigate the evolution of the cooperation ratio as time progresses under different parameters, which is proved to be in agreement with our theoretical analysis. Furthermore, we explore the influence of the cost of data users to acquire data, the value of open data, the reward (penalty) from the regulators, and the data mining capability of data users to group strategies and uncover some regular patterns. Some meaningful results are also obtained through simulations, which can guide stakeholders to make better decisions in the future.},
  archive      = {J_TCSS},
  author       = {Qin Li and Bin Pi and Minyu Feng and Jürgen Kurths},
  doi          = {10.1109/TCSS.2023.3324087},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3780-3791},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Open data in the digital economy: An evolutionary game theory perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hierarchical separation and classification network for
dynamic microexpression classification. <em>TCSS</em>, <em>11</em>(3),
3766–3779. (<a href="https://doi.org/10.1109/TCSS.2023.3334823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Macrolevel facial muscle variations, as used for building models of seven discrete facial expressions, suffice when distinguishing between macrolevel human affective states but won’t discretise continuous and dynamic microlevel variations in facial expressions. We present a hierarchical separation and classification network (HSCN) for discovering dynamic, continuous, and macro- and microlevel variations in facial expressions of affective states. In the HSCN, we first invoke an unsupervised cosine similarity-based separation method on continuous facial expression data to extract twenty-one dynamic facial expression classes from the seven common discrete affective states. The between-clusters separation is then optimized for discovering the macrolevel changes resulting from facial muscle activations. A following step in the HSCN separates the upper and lower facial regions for realizing changes pertaining to upper and lower facial muscle activations. Data from the two separated facial regions are then clustered in a linear discriminant space using similarities in muscular activation patterns. Next, the actual dynamic expression data are mapped onto discriminant features for developing a rule-based expert system that facilitates classifying twenty-one upper and twenty-one lower microexpressions. Invoking the random forest algorithm would classify twenty-one macrolevel facial expressions with 76.11% accuracy. A support vector machine (SVM), used separately on upper and lower facial regions in tandem, could classify them with respective accuracies of 73.63% and 87.68%. This work demonstrates a novel and effective method of dynamic assessment of affective states. The HSCN further demonstrates that facial muscle variations gathered from either upper, lower, or full-face would suffice classifying affective states. We also provide new insight into discovery of microlevel facial muscle variations and their utilization in dynamic assessment of facial expressions of affective states.},
  archive      = {J_TCSS},
  author       = {Jordan Vice and Masood Mehmood Khan and Tele Tan and Iain Murray and Svetlana Yanushkevich},
  doi          = {10.1109/TCSS.2023.3334823},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3766-3779},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A hierarchical separation and classification network for dynamic microexpression classification},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differential privacy and k-anonymity-based privacy
preserving data publishing scheme with minimal loss of statistical
information. <em>TCSS</em>, <em>11</em>(3), 3753–3765. (<a
href="https://doi.org/10.1109/TCSS.2023.3320141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Though anonymization mechanisms have made huge progress in fostering the secondary use of data, it is still very challenging to obtain adequate knowledge from anonymized data while preserving privacy. Most existing mechanisms anonymize entire sections of data and fail to maximally preserve the structure/values of real data. Consequently, the performance of those mechanisms and the output (i.e., the anonymized data) remain problematic in real-life scenarios due to the extensive and unneeded anonymization applied. To address these issues, we propose and implement a hybrid (differential privacy (DP) and $k$ -anonymity) anonymization scheme that produces supreme-quality anonymized data that offers knowledge similar to real data without compromising privacy. Specifically, we implement a pair of algorithms that divide the dataset into privacy-violating and nonprivacy-violating partitions. Afterward, in a nonprivacy-violating partition, a relaxed privacy budget $\epsilon $ is applied to numerical attributes, but most of the categorical attributes are retained (as is) for informative analysis. In privacy-violating partitions, fewer changes are applied to the data by using a reasonable value for $\epsilon $ and by exploiting the diversity in sensitive information. Experiments are conducted on three real-life datasets to prove the feasibility of our scheme for futuristic AI applications. Compared with state-of-the-art (SOTA) methods, our scheme preserves 60.81% of the originality in the anonymized data. The privacy risks are reduced by 20.05%, and utility is enhanced by 54.01% and 15.33% based on information loss (IL) and accuracy metrics. Furthermore, the time overhead is $3.13\times $ lower than the SOTA methods.},
  archive      = {J_TCSS},
  author       = {Abdul Majeed and Seong Oun Hwang},
  doi          = {10.1109/TCSS.2023.3320141},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3753-3765},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Differential privacy and k-anonymity-based privacy preserving data publishing scheme with minimal loss of statistical information},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Big tech dominance despite global mistrust. <em>TCSS</em>,
<em>11</em>(3), 3741–3752. (<a
href="https://doi.org/10.1109/TCSS.2023.3339183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technological and online experiences of billions worldwide are dominated by a handful of companies known as “Big Tech.” Despite this being a cause for concern in governmental, economic, and ethical spheres, the literature lacks a study exploring the impact of public scandals on, and the global sentiment toward, Big Tech. Here, we quantify the power of Big Tech by analyzing their acquisitions, market capitalization, and number of monthly active users. Moreover, we utilize the synthetic control method to estimate the effect of public scandals on the stock price of two Big Tech companies, and find that they had no lasting effect. We also analyze the number of tweets mentioning these scandals, and find that they quickly fade from the spotlight. To explore public sentiment, we survey 5300 participants across 25 countries, and find that those from countries with lower digital literacy and more authoritarian regimes are more trusting of Big Tech. Furthermore, we find that one in three feels they lack control over the data collected about them, and one in four feels that Big Tech knows what they are thinking, knows more about them than their best friend, and may even be secretly listening to their conversations. Additionally, one in four feels addicted to Big Tech products, have no choice but to use them, and wishes there were more companies to choose from. These findings highlight the adverse effect of the oligopolistic nature of Big Tech on consumer choice and help inform policy-makers aiming to curb their dominance.},
  archive      = {J_TCSS},
  author       = {Hazem Ibrahim and Mikolaj Debicki and Talal Rahwan and Yasir Zaki},
  doi          = {10.1109/TCSS.2023.3339183},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3741-3752},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Big tech dominance despite global mistrust},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spy balloon or sputnik moment: A comparative analysis of
public opinion in china and the united states. <em>TCSS</em>,
<em>11</em>(3), 3729–3740. (<a
href="https://doi.org/10.1109/TCSS.2023.3333954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Examining the perceptual differences between China and the United States can facilitate a better understanding of their opinions and perspectives, helping to promote peaceful interactions among the two nations as well as the world. This study presents a data-driven approach to measure cognitive differences, investigating these differences from topical and sentimental angles regarding the unmanned balloon event that had been shot down by U.S. warplanes. We also explore the cognitive differences between news media and the followers, and the evolution of topics over time. Our findings reveal those discussions about “balloons” on social media in China and the United States display certain differences in terms of sentiment. In addition, we assess the impact of this event on U.S.–China relationship, particularly in trade. To evaluate the analytical capabilities of the popular ChatGPT model, we use this event as a case study to demonstrate that ChatGPT-like models may have limited capabilities for such kind of specialized analysis. The dataset utilized here is made available for public usage for further investigation on public opinion dynamics for similar events.},
  archive      = {J_TCSS},
  author       = {Baoyu Zhang and Tao Chen and Qiang Li and Weishan Zhang and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3333954},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3729-3740},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Spy balloon or sputnik moment: A comparative analysis of public opinion in china and the united states},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-URG: Account identity-based uncertain graph framework for
fraud detection. <em>TCSS</em>, <em>11</em>(3), 3706–3728. (<a
href="https://doi.org/10.1109/TCSS.2023.3325739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cybercriminals controlling multiple accounts to conduct malicious activities are a threat to the security of online services. These accounts form malicious communities that are difficult to detect using conventional methods with single-factor identity, such as browser fingerprint or internet protocol (IP) address. Single-factor identity is prone to noise and uncertainty and does not capture dynamic relationships between accounts. To solve the problems of insufficient single-factor identity and uncertainty binding between accounts and identity, we propose AI- URG, a novel account identity-based uncertain graph with multifactor identity modeling for online service fraud detection. To find account groups, we embed account representation that preserves the uncertain graph’s possible world semantics and use the domain knowledge that accounts of family members also from small communities to filter these benign groups and detect malicious communities. The ablation study demonstrates how each component contributes to the effectiveness of AI- URG. The comparison results on two datasets show that AI- URG outperforms the alternatives with a higher F1-score (58.0%) and precision (46.0%) on a real-world online bank dataset and with a higher F1-score (36.5%) and precision (96.9%) on a large-scale single-sign-on online service dataset. The experimental results can provide valuable insights into online service fraud detection.},
  archive      = {J_TCSS},
  author       = {Yu-Wei Chang and Hsing-Yu Shih and Tsung-Nan Lin},
  doi          = {10.1109/TCSS.2023.3325739},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3706-3728},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {AI-URG: Account identity-based uncertain graph framework for fraud detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multiline customized bus planning method based on
reinforcement learning and spatiotemporal clustering algorithm.
<em>TCSS</em>, <em>11</em>(3), 3691–3705. (<a
href="https://doi.org/10.1109/TCSS.2023.3329990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand-responsive customized bus has been operated in real life, which is a crucial way to improve the service quality and efficiency of the urban public transportation system. Reasonable station and line planning can enhance customized bus competitiveness in residents&#39; travel mode. Most previous studies on optimizing customized bus lines rely on historical passenger volume and travel time to generate static schemes, but the actual operation process of customized bus is often in uncertain circumstances, such as road congestion. The static strategy will occur deviations in this situation. This study proposes a novel planning method to address the above issue. First, a spatiotemporal clustering algorithm is proposed to generate joint stations based on the passenger travel demand. Second, the method models the multiline customized bus optimization problem as a Markov decision process and uses a multiagent deep reinforcement learning algorithm to ensure effective training and response to incomplete information scenarios. Finally, the rationality of the proposed planning method is verified in a case study of customized bus area in Chongqing, China. Compared with the latest heuristic optimization algorithm, our method can effectively reduce the operating and passenger costs in complex environments.},
  archive      = {J_TCSS},
  author       = {Wengang Li and Linjiang Zheng and Longquan Liao and Xingze Yang and Dihua Sun and Weining Liu},
  doi          = {10.1109/TCSS.2023.3329990},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3691-3705},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A multiline customized bus planning method based on reinforcement learning and spatiotemporal clustering algorithm},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unifying star ratings and text reviews in linguistic terms
for product competitiveness analysis based on stochastic dominance.
<em>TCSS</em>, <em>11</em>(3), 3678–3690. (<a
href="https://doi.org/10.1109/TCSS.2023.3327173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online reviews, mainly consisted of star ratings and text reviews, provide enterprises with consumer feedback on product usage. From the perspective of a product designer, exploring the values of online reviews to help enterprises analyze product competitiveness and grasp market trends becomes necessary. However, heterogeneous and unstructured online reviews can confuse them. Previous research on online reviews mainly focused on comparing the different usefulness between star ratings and text reviews, whereas the research on combining these two types of information to compare product performances was relatively limited. In addition, the unified expression of heterogeneous star ratings and text reviews is the difficulty in information aggregation, and simple expressions may ignore differences in consumers’ psychological cognition. To solve these challenges, this study introduces the prospect theory to unify star ratings and text reviews of products and then takes two heterogeneous information as the basis for product designers analyzing competitiveness. First, we propose a unification model to express different grades of star ratings and text reviews as a unified evaluation system according to value consistency. Then, we use evidential reasoning (ER) theory to aggregate unified product evaluation results. According to the confidence distribution of evaluation results, stochastic dominance (SD) rules are used to determine the dominance relations of products under each criterion. Finally, comprehensive comparisons of products are carried out based on the characteristics of dominance relations of products. The applicability of the proposed method is illustrated by a case study of online review-based automobiles comparison on Autohome.com.cn.},
  archive      = {J_TCSS},
  author       = {Huchang Liao and Jiayi Wang and Zeshui Xu},
  doi          = {10.1109/TCSS.2023.3327173},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3678-3690},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Unifying star ratings and text reviews in linguistic terms for product competitiveness analysis based on stochastic dominance},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Context-aware civil unrest event prediction using
neutrosophic-aspect-based sentiment analysis, PSO, and hierarchical
LSTM. <em>TCSS</em>, <em>11</em>(3), 3667–3677. (<a
href="https://doi.org/10.1109/TCSS.2023.3338509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Civil unrest is among the important hurdles in the countries’ progress as it deteriorates gross domestic product (GDP), international relations, foreign direct investment (FDI), globalization, public opinion, tourism, and businesses. Due to civil unrest a variety of serious problems, viz. loss of life/injury, resources, political stability, and human rights occur. Recently, few researchers have given insights on the prediction of occurrences of civil unrest events by using hypothesis testing and some basic machine/deep learning models. Important factors such as people’s emotions/sentiments, contextual information, and civil unrest events feature’ importance are ignored presently. For the first time, the proposed work overcomes all these research gaps by hybridizing the neutrosophic set, aspect-based sentiment analysis, particle swarm optimization (PSO), and hierarchical long short-term memory (hierarchical LSTM). Neutrosophic set along with aspect-based sentiment analysis has been used to get the sentiment and features’ importance. The resulting features’ weights have been optimized using PSO. For a more comprehensive understanding of the input sequence and feature weights, hierarchical LSTM has been used. Doing so obtained results that are more accurately improved for civil unrest events prediction. The performance of the proposed model has been evaluated and compared with state of art methods. Experimentation and evaluation show the proposed model outperforms the baseline methods by 3% to 15% on the standard datasets in terms of accuracy.},
  archive      = {J_TCSS},
  author       = {Pratima Singh and Amita Jain},
  doi          = {10.1109/TCSS.2023.3338509},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3667-3677},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Context-aware civil unrest event prediction using neutrosophic-aspect-based sentiment analysis, PSO, and hierarchical LSTM},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mobile crowdsourcing quality control method based on
four-party evolutionary game in edge cloud environment. <em>TCSS</em>,
<em>11</em>(3), 3652–3666. (<a
href="https://doi.org/10.1109/TCSS.2023.3338370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsourcing (MCS) is a new paradigm that uses various mobile devices to collect sensed data. Mobile edge computing (MEC) can effectively utilize the device resources of mobile edge, greatly relieve the pressure of network bandwidth and improve the response speed. In this article, we construct a four-party evolutionary game model consisting of the platform, crowd workers, task requesters, and edge servers. The computing tasks are conducted on edge servers, which greatly reduce remote data transmission and network operating costs and improve service quality. Taking into account the collusion between the platform and workers, and that between the platform and requesters, we analyze the stability of the strategic equilibrium in MCS using replicator dynamics methods. The optimal payoff strategies of the participants in different initial states are obtained. To prevent cheating and false-reporting problems, reward and punishment strategies are provided. Finally, the stability of the equilibrium of the four-party evolutionary game system is verified by simulation experiments, and an incentive strategy is designed to motivate all parties to choose the trust strategies.},
  archive      = {J_TCSS},
  author       = {Ying Zhao and Yingjie Wang and Peiyong Duan and Haijing Zhang and Zhaowei Liu and Xiangrong Tong and Zhipeng Cai},
  doi          = {10.1109/TCSS.2023.3338370},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3652-3666},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Mobile crowdsourcing quality control method based on four-party evolutionary game in edge cloud environment},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolution of credit scores of enterprises in a social
network: A perspective based on opinion dynamics. <em>TCSS</em>,
<em>11</em>(3), 3637–3651. (<a
href="https://doi.org/10.1109/TCSS.2023.3324558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of social network to model the evolution of credit scores of networked enterprises is still a challenging task. This article develops an opinion dynamics model of the evolution of credit scores of enterprises in a social network. Firstly, based on the number of potential cooperated enterprises and the initial credit scores, the leader and follower enterprises are identified. Then, taking into consideration the cooperated benefit and discrimination cost, the cooperated utility between any two enterprises is calculated, which is used to compute the weights that one enterprise assigns to other enterprises. An opinion dynamics model on the evolution of credit scores of enterprises, inspired on the classical Friedkin–Johnsen’s social network model, is developed. Some desirable properties of the proposed opinion dynamics model are theoretically stated and proved. Finally, a numerical example is provided to illustrate the feasibility of the proposed opinion dynamics model, while a simulation analysis to investigate the joint influences of the connection probabilities and the network structure on the evolution of credit scores of enterprises is reported.},
  archive      = {J_TCSS},
  author       = {Haiming Liang and Weijun Xu and Francisco Chiclana and Shui Yu and Yucheng Dong and Enrique Enrique Herrera-Viedma},
  doi          = {10.1109/TCSS.2023.3324558},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3637-3651},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Evolution of credit scores of enterprises in a social network: A perspective based on opinion dynamics},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear opinion dynamics model with higher order
interactions. <em>TCSS</em>, <em>11</em>(3), 3627–3636. (<a
href="https://doi.org/10.1109/TCSS.2023.3324144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opinion dynamics is a central subject of computational social science, and various models have been developed to understand the evolution and formulation of opinions. Existing models mainly focus on opinion dynamics on graphs that only capture pairwise interactions between agents. In this article, we extend the popular Friedkin–Johnsen model for opinion dynamics on graphs to hypergraphs, which describe higher order interactions occurring frequently on real networks, especially social networks. To achieve this, based on the fact that for linear dynamics, the multiway interactions can be reduced to effective pairwise node interactions, we propose a method to decode the group interactions encoded in hyperedges by undirected edges or directed edges in graphs. We then show that higher order interactions play an important role in the opinion dynamics since the overall steady-state expressed opinion and polarization differ greatly from those without group interactions. We also provide an interpretation of the equilibrium expressed opinion from the perspective of the spanning converging forest, based on which we design a fast sampling algorithm to approximately evaluate the overall opinion and opinion polarization on directed weighted graphs. Finally, we conduct experiments on real-world hypergraph datasets, demonstrating the performance of our algorithm.},
  archive      = {J_TCSS},
  author       = {Wanyue Xu and Zhongzhi Zhang},
  doi          = {10.1109/TCSS.2023.3324144},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3627-3636},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Linear opinion dynamics model with higher order interactions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Teacher-guided peer learning with continuous action iterated
dilemma based on incremental network. <em>TCSS</em>, <em>11</em>(3),
3616–3626. (<a href="https://doi.org/10.1109/TCSS.2023.3335162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a teacher-guided peer learning approach that employs a continuous action iterated dilemma (CAID) model based on an incremental network. Traditional peer learning approaches often assume static communication relationships between students, which is not consistent with actual society, and this affects the effectiveness of peer learning. Additionally, every student is a highly unique individual, and using a single mathematical model to mimic their behavior would result in research findings with limited applicability. Therefore, this article presents several innovations. First, we propose an incremental network generation algorithm that generates an effective communication network to improve classroom efficiency by enhancing the convergence of information between classmates. Second, considering the multiple unknown nonlinear environmental impacts, we design a student dynamic model based on CAID with multiple layers of nonlinearity to fit the different environmental impacts that different students receive. Finally, based on the incremental network and student dynamic model, we design the Lyapunov function to prove the convergence of the proposed model. This mathematical proof ensures that the proposed model is stable and unaffected by parameters, making it more applicable.},
  archive      = {J_TCSS},
  author       = {Can Qiu and Dengxiu Yu and Zhen Wang and C. L. Philip Chen},
  doi          = {10.1109/TCSS.2023.3335162},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3616-3626},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Teacher-guided peer learning with continuous action iterated dilemma based on incremental network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Negative review or complaint? Exploring interpretability in
financial complaints. <em>TCSS</em>, <em>11</em>(3), 3606–3615. (<a
href="https://doi.org/10.1109/TCSS.2023.3338357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the financial service sector, customer service is the most critical tool for long-term business growth. A financial complaint detection (CD) system could aid in the identification of shortcomings in product features and service delivery. This could further ensure faster resolution of customer complaints and thereby help retain existing clients and attract new ones. Prior research has prioritized only complaint identification and prediction of the corresponding severity levels; the first aim is to categorize a textual element as a complaint or a noncompliant. The other attempts to classify complaints into several severity levels based on the degree of risk the complainant is willing to endure. Identifying the reason or source of a complaint in a text is a significant but underexplored area in natural language processing study. We propose an explainable complaint cause identification approach with a dyadic attention mechanism at the sentence and word levels, enabling it to give varying amounts of emphasis to more and less important information. As the first subtask, the model simultaneously trains CD, sentiment detection, and emotion recognition tasks. Afterwards, we identify the complaint&#39;s cause and its severity level. To do this, the causal span annotations for complaint tweets are added to an existing financial complaints corpus. The findings suggest that conventional computing techniques can be adapted to solve extremely relevant new problems, generating novel opportunities for research 1 1The code and dataset are available at https://github.com/sarmistha-D/Complaint-HaN .},
  archive      = {J_TCSS},
  author       = {Sarmistha Das and Apoorva Singh and Sriparna Saha and Alka Maurya},
  doi          = {10.1109/TCSS.2023.3338357},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3606-3615},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Negative review or complaint? exploring interpretability in financial complaints},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MSDGSD: A scalable graph descriptor for processing large
graphs. <em>TCSS</em>, <em>11</em>(3), 3594–3605. (<a
href="https://doi.org/10.1109/TCSS.2023.3338691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation methods have recently become the de facto standard for downstream machine learning tasks on graph-structured data and have found numerous applications, e.g., drug discovery &amp; development, recommendation, and forecasting. However, the existing methods are specially designed to work in a centralized environment, which limits their applicability to small or medium-sized graphs. In this work, we present a graph embedding method that extracts graph representations in a distributed environment with independent and parallel machines. The proposed method is built-upon the existing approach, distributed graph statistical distance (DGSD), to enhance the scalability on large graphs. The key innovation of our work lies in the proposition of a batching mechanism for client-server message passing, which reduces communication overhead during the computation of the distance matrix. In addition, we present a sampling approach for computing pairwise distances between the nodes to compute the desired graph embedding. Moreover, we systematically explore six distinct variations of a distributed graph embeddings and subsequently subject them to comprehensive evaluation. Our extensive evaluations on over 20 graph datasets and ten baseline methods demonstrate improved running time and comparative classification accuracy compared to state-of-the-art embedding techniques.},
  archive      = {J_TCSS},
  author       = {Muhammad Ali and Anwar Said and Iqra Safder and Saeed Ul Hassan and Naif Radi Aljohani and Mudassir Shabbir},
  doi          = {10.1109/TCSS.2023.3338691},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3594-3605},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {MSDGSD: A scalable graph descriptor for processing large graphs},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formal modeling and analysis of user activity sequence in
online social networks: A stochastic petri net-based approach.
<em>TCSS</em>, <em>11</em>(3), 3580–3593. (<a
href="https://doi.org/10.1109/TCSS.2023.3335935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous interaction of users and information aggregation has become a social phenomena over massive social media platforms. However, the uncertainty of users’ behavior is leading great challenges to social networks analysis in terms of system structure, evolution characteristics, dynamic behavior, and so forth. Thus, this article proposes a formal user behavior modeling and analysis approach. First, aiming at identifying the behavior patterns of user activity sequence, we present a user activity transition system model based on stochastic Petri net (SPN), which can formally depict the process and structures of social users click activities. Then, the average number of tokens in each place, the probability density function of the tokens, the token flow rate of transitions, and the time spent in each state are analyzed by isomorphic it into a Markov chain (MC), respectively. These four indicators are used to evaluate the performance of the proposed system model. The experimental results demonstrate that the proposed approach can help us to understand the rules of users’ first activity and activity preferences, so as to provide practical suggestions for the development of social networking platforms and content recommendation.},
  archive      = {J_TCSS},
  author       = {Wangyang Yu and Jinming Kong and Fei Hao and Jian Li and Yuan Liu},
  doi          = {10.1109/TCSS.2023.3335935},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3580-3593},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Formal modeling and analysis of user activity sequence in online social networks: A stochastic petri net-based approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of deep learning models for twitter sentiment
analysis: Challenges and opportunities. <em>TCSS</em>, <em>11</em>(3),
3550–3579. (<a href="https://doi.org/10.1109/TCSS.2023.3322002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microblogging site Twitter (re-branded to X since July 2023) is one of the most influential online social media websites, which offers a platform for the masses to communicate, expresses their opinions, and shares information on a wide range of subjects and products, resulting in the creation of a large amount of unstructured data. This has attracted significant attention from researchers who seek to understand and analyze the sentiments contained within this massive user-generated text. The task of sentiment analysis (SA) entails extracting and identifying user opinions from the text, and various lexicon- and machine learning-based methods have been developed over the years to accomplish this. However, deep learning (DL)-based approaches have recently become dominant due to their superior performance. This study briefs on standard preprocessing techniques and various word embeddings for data preparation. It then delves into a taxonomy to provide a comprehensive summary of DL-based approaches. In addition, the work compiles popular benchmark datasets and highlights evaluation metrics employed for performance measures and the resources available in the public domain to aid SA tasks. Furthermore, the survey discusses domain-specific practical applications of SA tasks. Finally, the study concludes with various research challenges and outlines future outlooks for further investigation.},
  archive      = {J_TCSS},
  author       = {Laxmi Chaudhary and Nancy Girdhar and Deepak Sharma and Javier Andreu-Perez and Antoine Doucet and Matthias Renz},
  doi          = {10.1109/TCSS.2023.3322002},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3550-3579},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A review of deep learning models for twitter sentiment analysis: Challenges and opportunities},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ASA-GNN: Adaptive sampling and aggregation-based graph
neural network for transaction fraud detection. <em>TCSS</em>,
<em>11</em>(3), 3536–3549. (<a
href="https://doi.org/10.1109/TCSS.2023.3335485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many machine learning methods have been proposed to achieve accurate transaction fraud detection, which is essential to the financial security of individuals and banks. However, most existing methods either leverage original features only or require manual feature engineering so that they show a weak ability to learn discriminative representations from transaction data. Moreover, criminals often commit fraud by imitating cardholders’ behaviors, which causes the poor performance of existing detection models. In this article, we propose an adaptive sampling and aggregation-based graph neural network (ASA-GNN) that learns discriminative representations to improve the performance of transaction fraud detection. A neighbor sampling strategy is performed to filter noisy nodes and supplement information for fraudulent nodes. Specifically, we use cosine similarity and edge weights to adaptively select neighbors with similar behavior patterns for target nodes and then find multihop neighbors for fraudulent nodes. A neighbor diversity metric is designed by calculating the entropy of neighbors to tackle the camouflage issue of fraudsters and explicitly alleviate the oversmoothing phenomena. Extensive experiments on three real financial datasets demonstrate that ASA-GNN outperforms state-of-the-art ones.},
  archive      = {J_TCSS},
  author       = {Yue Tian and Guanjun Liu and Jiacun Wang and Mengchu Zhou},
  doi          = {10.1109/TCSS.2023.3335485},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3536-3549},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {ASA-GNN: Adaptive sampling and aggregation-based graph neural network for transaction fraud detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated matrix factorization recommendation based on
secret sharing for privacy preserving. <em>TCSS</em>, <em>11</em>(3),
3525–3535. (<a href="https://doi.org/10.1109/TCSS.2023.3322824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommendation systems require users to upload local data to the server to generate recommendation results. In this process, users’ privacy is easy to disclose. Federated recommendations can solve the problem of local data privacy leakage, but the intermediate computing results are not protected. The existing work mainly protects the information in this process through encryption or disturbance schemes, which will result in complex calculations or low accuracy. Also, the two schemes only protect the rating data and process parameter information, but the existence information is not protected. Aiming at the above problems, this article proposes a federated matrix factorization based on secret sharing (FMFSS) to protect users’ privacy. The parameters are randomly divided into pieces, and then, the secret sharing technology is used to transmit private information between user–user and user–server, which does not introduce additional encryption cost and ensures value privacy, process privacy, and existence privacy. In addition, this article introduces the user–item interaction value, which is transmitted to the server with gradient information. In this way, the real gradient of the user cannot be inferred from the information received by the server from all parties, but the aggregated final average parameter information is real. The experimental comparison with the existing work and the analysis of computation time show that the proposed method can ensure the accuracy of model privacy recommendations without introducing additional encryption operations.},
  archive      = {J_TCSS},
  author       = {Xiaoyao Zheng and Manping Guan and Xianmin Jia and Liping Sun and Yonglong Luo},
  doi          = {10.1109/TCSS.2023.3322824},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3525-3535},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Federated matrix factorization recommendation based on secret sharing for privacy preserving},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An emotion-aware approach for fake news detection.
<em>TCSS</em>, <em>11</em>(3), 3516–3524. (<a
href="https://doi.org/10.1109/TCSS.2023.3335269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media has gradually become the main medium for news transmission. Rumors and real information are mixed on social platforms, which will have certain impact on social order and public psychology. To solve this problem, many fake news detection models based on content and propagation path have been proposed. However, most previous methods do not consider the emotional information contained in the news. Therefore, we propose a novel framework for detecting fake news, which leverages graph neural network to jointly model the content, emotional information and propagation structure of news conversations. Also, in order to use emotion to amplify the spread of fake news, we propose an edge-aware method to enhance the news graph representation. The experimental results indicate that our model achieves state-of-the-art performance on various fake news detection tasks.},
  archive      = {J_TCSS},
  author       = {Fei Liu and Xinsheng Zhang and Qi Liu},
  doi          = {10.1109/TCSS.2023.3335269},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3516-3524},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An emotion-aware approach for fake news detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A platform ecosystem evolution model with service dynamic
supply and matching. <em>TCSS</em>, <em>11</em>(3), 3504–3515. (<a
href="https://doi.org/10.1109/TCSS.2023.3332064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Governance strategies related to platform ecosystems have become a vital issue for developing a smart society, attracting governments’ and practitioners’ attention. Under the consensus of “service as a commodity” and “platform as market,” service providers, platforms, services, and various supply demand matching methods form new supply processes. These elements are continuously and uncertainly changing during supply demand matching, which makes platform ecosystems constantly evolving. However, when multiple supply demand matching methods coexist such as service composition and crossover fusion, dynamic service supply and matching cause dilemmas in the platform ecosystem governance. To this end, this article proposes a model for platform ecosystem evolution with four dynamics: 1) dynamics between ISPs (services) and platforms; 2) dynamics between users and platforms; 3) dynamics among services; and 4) dynamics between services and demands. The model considers multiple supply demand matching methods and considers both fully online services and incompletely online services. Then, according to the market operation law, we design six evaluation indexes such as demand matching rate, service diversity, and market concentration to evaluate the efficiency of the platform market. Finally, a computational experiment system is established to simulate the dynamic supply and matching processes. The experimental results show that reducing the cost of service release can increase the amount of demand and the diversity of services, and the monopoly of digital platforms is a natural trend to improve the efficiency of supply and demand. The model provides a reference for the governance of platform ecosystems and lays a foundation for further research on the value cocreation mechanism of platform ecosystems.},
  archive      = {J_TCSS},
  author       = {Xinyue Zhou and Jianmao Xiao and Xiao Xue and Shizhan Chen and Zhiyong Feng},
  doi          = {10.1109/TCSS.2023.3332064},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3504-3515},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A platform ecosystem evolution model with service dynamic supply and matching},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous graph attention networks for depression
identification by campus cyber-activity patterns. <em>TCSS</em>,
<em>11</em>(3), 3493–3503. (<a
href="https://doi.org/10.1109/TCSS.2023.3343689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most prevalent mental disorders, depression is associated with a high rate of self-harm and suicide, particularly among college students. It is urgently needed to discover prospective cases of depression disorder among college students, enabling timely intervention to reduce its impact on their academic performance and daily lives. This study investigates a method for identifying groups that may have early depressive tendencies through their Internet usage on campus networks. This article proposes a heterogeneous graph attention network (H-GAT) model that incorporates an attention mechanism based on ablation experiments in heterogeneous graphs to analyze the patterns and correlations within the surfing behavior data of students. This model makes full use of the interaction relationships between heterogeneous nodes in the graph to capture the affective tendencies reflected in the cyber-activity patterns. The proposed H-GAT model exhibits excellent performance, with nearly 80% accuracy and recall. Our work offers a potential approach to detect depression on college campuses using nonintrusive methods, which could ultimately contribute to early warnings for both individuals experiencing depression and higher education institutions.},
  archive      = {J_TCSS},
  author       = {Minqiang Yang and Zhuoheng Li and Yujie Gao and Chen He and Fuzhan Huang and Wenbo Chen},
  doi          = {10.1109/TCSS.2023.3343689},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3493-3503},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Heterogeneous graph attention networks for depression identification by campus cyber-activity patterns},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emergence of fairness behavior driven by reputation-based
voluntary participation in evolutionary dictator games. <em>TCSS</em>,
<em>11</em>(3), 3483–3492. (<a
href="https://doi.org/10.1109/TCSS.2023.3335396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, reputation-based indirect reciprocity has been widely applied to the study on fairness behavior. Previous works mainly investigate indirect reciprocity by considering compulsory participation. While in reality, individuals may choose voluntary participation according to the opponent&#39;s reputation. It is still unclear how such reputation-based voluntary participation influences the evolution of fairness. To address this question, we introduce indirect reciprocity with voluntary participation into the dictator game (DG). We respectively consider good dictators or recipients can voluntarily participate in games when the opponents are assessed as bad. We theoretically calculate the fairness level under all social norms of third-order information. Our findings reveal that several social norms induce the high fairness level in both scenarios. However, more social norms lead to a high fairness level for voluntary participation of recipients, compared with the one of good dictators. The results also hold when the probability of voluntary participation is not low. Our results demonstrate that recipients’ voluntary participation is more effective in promoting the emergence of fairness behavior.},
  archive      = {J_TCSS},
  author       = {Yanling Zhang and Yin Li and Xiaojie Chen and Guangming Xie},
  doi          = {10.1109/TCSS.2023.3335396},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3483-3492},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Emergence of fairness behavior driven by reputation-based voluntary participation in evolutionary dictator games},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The price is right? The economic value of sharing sensors.
<em>TCSS</em>, <em>11</em>(3), 3468–3482. (<a
href="https://doi.org/10.1109/TCSS.2023.3330071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study user&#39;s valuations of smartphone sensing resources and the factors mediating them through a systematic auction study with 108 bids from $N=18$ participants, two resource use conditions [fixed battery (FB) and variable battery (VB)] and three sensors (camera, microphone, and GPS) with differing energy and privacy costs. We use a second-price sealed-bid reverse auction as this allows us to elicit the participants’ truthful perceived value for sharing resources. We show that most users would be willing to share even highly-privacy intrusive sensors if they are sufficiently compensated. At the FB level, participants placed much lower value for sharing GPS (€13) than camera (€30) or microphone (€32.5). The values people place on sharing access to resources generally reflect four considerations: 1) the perceived value of the sensor type; 2) the value of the data captured by the sensor; 3) the impact of sharing on the device; and 4) personal variations related to sharing motives, personal tendencies, and the broader sharing context. We address the practical impact of our results by presenting two case studies (collaborative sensing and collaborative AI). Finally, we derive design implications for sharing sensing resources on personal devices.},
  archive      = {J_TCSS},
  author       = {Ngoc Thi Nguyen and Maria Zubair and Agustin Zuniga and Sasu Tarkoma and Pan Hui and Hyowon Lee and Simon Tangi Perrault and Mostafa H. Ammar and Huber Flores and Petteri Nurmi},
  doi          = {10.1109/TCSS.2023.3330071},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3468-3482},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {The price is right? the economic value of sharing sensors},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New paradigm for economic and financial research with
generative AI: Impact and perspective. <em>TCSS</em>, <em>11</em>(3),
3457–3467. (<a href="https://doi.org/10.1109/TCSS.2023.3334306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few years, we have witnessed the rapid development and exponential growth of generative artificial intelligence (GAI) technologies including large language models (LLMs)-enabled ChatGPT and peripheral innovations. These technologies are designed to be humanlike intelligence and intuitive by providing direct access to systems using application programming interfaces (APIs). The GAI applications can fundamentally change economic and financial activities, through revolutionizing the ways that humans interact with machines and giving rise to new modes of production and behavior patterns. It is imperative to develop a new research paradigm that is more suitable than the currently dominating conventional research paradigms. This article presents the new paradigm for economic and financial research with GAI, covering the research objectives, scientific data, and models, and explores the underlying impact and perspective that bring to this field. We elaborate on the potential five scenarios including portfolio management, economic and financial prediction, extreme scenario analysis, policy analysis, and financial fraud detection. The new research paradigm with GAI proposed in this article can provide significant insights for a comprehensive understanding of innovation and transformation in this domain.},
  archive      = {J_TCSS},
  author       = {Xiaolong Zheng and Jingyu Li and Mengyao Lu and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3334306},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3457-3467},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {New paradigm for economic and financial research with generative AI: Impact and perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep semi-supervised community detection based on
point-wise mutual information. <em>TCSS</em>, <em>11</em>(3), 3444–3456.
(<a href="https://doi.org/10.1109/TCSS.2023.3327810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network clustering is one of the fundamental unsupervised methods of knowledge discovery. Its goal is to group similar nodes together without supervision or prior knowledge of the nature of the clusters. Among various clustering methods, semi-supervised clustering detection is one of the most promising approaches for community detection because of its ability to employ side information to better understand network topology. However, most of the previous work faces two problems: the use of linear methods to reduce dimensionality and the random selection of side information, and as a result of these two drawbacks, semi-supervised community detection methods are less efficient. To fill these gaps, we developed an end-to-end deep semi-supervisor community detection (DSSC) for complex networks. A new learning objective is designed that uses a semi-autoencoder (SeAE) with a defined pair-wise constraint matrix based on point-wise mutual information (PMI) in the representation layer to accurately learn distinctive features and, in the clustering layer, adds a pair-wise constraint as a term to minimize distance within the cluster while the distance between clusters increases. The results show that our method performs unexpectedly well in comparison to the existing state-of-the-art community detection methods in complex networks.},
  archive      = {J_TCSS},
  author       = {Kamal Berahmand and Yuefeng Li and Yue Xu},
  doi          = {10.1109/TCSS.2023.3327810},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3444-3456},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A deep semi-supervised community detection based on point-wise mutual information},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fake social media news detection based on forwarding user
representation. <em>TCSS</em>, <em>11</em>(3), 3432–3443. (<a
href="https://doi.org/10.1109/TCSS.2023.3331446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the proliferation of fake news has imposed a dramatic impact on the public, so the fake news detection has been attracting increasing attention. Most of existing methods employ traditional classification models or neural networks that consider news content, comments, and context to detect fake news. However, the characteristics of news vary by type, topic, and context, which are difficult to uniformly represent for fake news detection. In this article, we propose a novel fake news detection model based on retweeting user embedding using only the stable and easily accessible information of retweeting users. Our model includes three components. First, we use all retweeting users to construct the retweeting graph and then learn the user representation. Second, for each tweet, we aggregate the representations of its retweeting users to learn the tweet representation. Finally, the tweet representations are fed into a feedforward neural network to train the news classifier. To demonstrate the effectiveness of our method, we conduct experiments on two public datasets. The results show that our classifier performs well and achieves better results than other state-of-the-art methods.},
  archive      = {J_TCSS},
  author       = {Zhaojie Yan and Yongjun Li and Lirong Huang and Wenli Ji},
  doi          = {10.1109/TCSS.2023.3331446},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3432-3443},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Fake social media news detection based on forwarding user representation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Equity, equality, and need: Digital twin approach for
fairness-aware task assignment of heterogeneous crowdsourced logistics.
<em>TCSS</em>, <em>11</em>(3), 3420–3431. (<a
href="https://doi.org/10.1109/TCSS.2023.3321940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industry 5.0 utilizes the Internet of Things (IoT) and autonomous computing to facilitate human–machine collaboration, where humans and machines coexist in a competitive economic ecosystem. In conventional workplaces, fairness is widely recognized as a driving force behind human motivation, loyalty, and productive collaboration. However, current fairness-aware task allocation methods have primarily focused on homogeneous workers, concentrating on either equity or equality as the sole fairness principle. With the rising trend of diverse worker fleets consisting of autonomous robots/vehicles and human-in-the-loop as service providers (e.g., crowdsourced logistics), novel approaches are necessary. Our contribution entails a fairness-aware task allocation approach for heterogeneous workers, leveraging the digital twin to understand the system’s behavior and facilitate real-time adaptation. Our proposed solution considers equity, equality, and need, utilizing the maximum-weight bipartite matching algorithm. Multiple incentive scenarios are utilized to evaluate the potential of the approach. The experimental results suggest that our multi-objective approach yields better overall fairness in various scenarios than the baselines.},
  archive      = {J_TCSS},
  author       = {Hargyo T. N. Ignatius and Rami Bahsoon},
  doi          = {10.1109/TCSS.2023.3321940},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3420-3431},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Equity, equality, and need: Digital twin approach for fairness-aware task assignment of heterogeneous crowdsourced logistics},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable AI for human-centric ethical IoT systems.
<em>TCSS</em>, <em>11</em>(3), 3407–3419. (<a
href="https://doi.org/10.1109/TCSS.2023.3330738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current era witnesses the notable transition of society from an information-centric to a human-centric one aiming at striking a balance between economic advancements and upholding the societal and fundamental needs of humanity. It is undeniable that the Internet of Things (IoT) and artificial intelligence (AI) are the key players in realizing a human-centric society. However, for society and individuals to benefit from advanced technology, it is important to gain the trust of human users by guaranteeing the inclusion of ethical aspects such as safety, privacy, nondiscrimination, and legality of the system. Incorporating explainable AI (XAI) into the system to establish explainability and transparency supports the development of trust among stakeholders, including the developers of the system. This article presents the general class of vulnerabilities that affect IoT systems and directs the readers’ attention toward intrusion detection systems (IDSs). The existing state-of-the-art IDS system is discussed. An attack model modeling the possible attacks is presented. Furthermore, since our focus is on providing explanations for the IDS predictions, we first present a consolidated study of the commonly used explanation methods along with their advantages and disadvantages. We then present a high-level human-inclusive XAI framework for the IoT that presents the participating components and roles. We also hint upon a few approaches to upholding safety and privacy using XAI that we will be taking up in our future work. An attack model based on the study of possible attacks on the system is also presented in the article. The article also presents guidelines to choose a suitable XAI method and a taxonomy of explanation evaluation mechanisms, which is an important yet less visited aspect of explainable AI.},
  archive      = {J_TCSS},
  author       = {Nancy Ambritta P. and Parikshit N. Mahalle and Rajkumar V. Patil and Nilanjan Dey and Rubén González Crespo and R. Simon Sherratt},
  doi          = {10.1109/TCSS.2023.3330738},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3407-3419},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Explainable AI for human-centric ethical IoT systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Dynamic dependence and hedging of stock markets: Evidence
from time-varying copula with asymmetric markovian models.
<em>TCSS</em>, <em>11</em>(3), 3391–3406. (<a
href="https://doi.org/10.1109/TCSS.2023.3346439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To study the asymmetric jump behaviors of the stock markets, we propose a novel autoregressive conditional jump intensity (ARJI)—generalized autoregressive conditional heteroskedasticity (GARCH) model with a Markov chain. Compared with the existing models, it considers the asymmetric effects of the positive and negative shocks on jump volatilities. It is proposed to estimate the asymmetric jump volatilities of the stock markets in mainland China and Hong Kong under different volatility regimes. Multiple time-varying copula models are used to analyze the dynamic dependences of the jump risks between the two markets. Furthermore, we construct dynamic hedging portfolios for their spot and futures markets, estimate the minimum risk hedging ratios, and measure the hedging performance. Compared with other benchmark models, the results show that the proposed one has the best fitting effect for the Chinese stock markets. The correlations between the Chinese mainland and Hong Kong markets are always positive. When constructing hedging portfolios, the proposed model is superior to other models, which means that introducing asymmetric shocks on both normal and jump volatilities into a Markovian ARJI-GARCH model can effectively improve the performance of hedging portfolios. In addition, the results of the robustness test indicates that our proposed model performs well and is robust.},
  archive      = {J_TCSS},
  author       = {Jia Wang and MengChu Zhou and Xiwang Guo and Xu Wang and Yusuf Al-Turki},
  doi          = {10.1109/TCSS.2023.3346439},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3391-3406},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Dynamic dependence and hedging of stock markets: Evidence from time-varying copula with asymmetric markovian models},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The largest social media ground-truth dataset for real/fake
content: TruthSeeker. <em>TCSS</em>, <em>11</em>(3), 3376–3390. (<a
href="https://doi.org/10.1109/TCSS.2023.3322303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic detection of fake content in social media such as Twitter is an enduring challenge. Technically, determining fake news on social media platforms is a straightforward binary classification problem. However, manually fact-checking even a small fraction of daily tweets would be nearly impossible due to the sheer volume. To address this challenge, we crawled and crowd-sourced one of the most extensive ground-truth tweet datasets. Utilizing Politifact and expert labeling as a base, it contains more than 180 000 labels from 2009 to 2022, creating five- and three-label classification using Amazon Mechanical Turk. We utilized multiple levels of validation to ensure an accurate ground-truth benchmark dataset. Then, we created and implemented numerous machine learning and deep learning algorithms, including different variations of bidirectional encoder representations from transformers (BERT)-based models and classical machine learning algorithms on the data to test the accuracy of real/fake tweet detection with both categories. Then, determining which versions gave us the highest result metrics. Further analysis is performed on the dataset by explicitly utilizing the DBSCAN text clustering algorithm combined with the YAKE keyword creation algorithm to determine topics’ clustering and relationships. Finally, we analyzed each user in the dataset, determining their bot score, credibility score, and influence score for a better understanding of what type of Twitter user posts, their influence with each of their tweets, and if there were any underlying patterns to be drawn from each score concerning the truthfulness of the tweet. The experiment’s results illustrated profound improvement for models dealing with short-length text in solving a real-life classification problem, such as automatically detecting fake content in social media.},
  archive      = {J_TCSS},
  author       = {Sajjad Dadkhah and Xichen Zhang and Alexander Gerald Weismann and Amir Firouzi and Ali A. Ghorbani},
  doi          = {10.1109/TCSS.2023.3322303},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3376-3390},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {The largest social media ground-truth dataset for Real/Fake content: TruthSeeker},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LCSEP: A large-scale chinese dataset for social emotion
prediction to online trending topics. <em>TCSS</em>, <em>11</em>(3),
3362–3375. (<a href="https://doi.org/10.1109/TCSS.2023.3334296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present our work in social emotion prediction to online trending topics. While most prior works focus on emotion from writers or the readers’ emotions evoked by news articles, we investigate discussions from massive social media users and explore the public feelings to the online trending topic. We employ user-generated “#hashtags” to indicate online trending topics and construct a large-scale Chinese dataset for social emotion prediction (LCSEP) to trending topics collected from the Chinese microblog Sina Weibo. It contains more than 20 000 trending topics, each with social emotions voted in 24 fine-grained types, and gathers hashtags, posts, comments, and related metadata to give each trending topic a thorough context. We also propose a Hashtag- and Topic-Enhanced Attention Model ( HTEAM ) that combines a pretrained BERT model, a neural topic model, and an attention mechanism via joint training to understand social emotion. Experiments show that HTEAM outperforms baselines and achieves the state-of-the-art result.},
  archive      = {J_TCSS},
  author       = {Keyang Ding and Chuang Fan and Yiwen Ding and Qianlong Wang and Zhiyuan Wen and Jing Li and Ruifeng Xu},
  doi          = {10.1109/TCSS.2023.3334296},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3362-3375},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {LCSEP: A large-scale chinese dataset for social emotion prediction to online trending topics},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NegEmotion: Explore the double-edged sword effect of
negative emotion on crowd evacuation. <em>TCSS</em>, <em>11</em>(3),
3348–3361. (<a href="https://doi.org/10.1109/TCSS.2023.3344172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In emergencies, negative emotion has a significant impact on decision-making during crowd evacuation. Psychological studies suggest that negative emotion in decision-making has a double-edged sword effect. Excessive negative emotion has adverse impacts, such as causing crowd chaos and congestion. Conversely, moderate negative emotion has a positive effect by speeding up crowd movement. However, current researches mainly focus on one aspect which is how to reduce the negative effects of negative emotion on crowd evacuation, while overlooking the benefits of negative emotion. How to fully explore the double-edged sword effect of negative emotion and regulate negative emotion to improve the efficiency of crowd evacuation is still an open issue. To achieve this, we propose the NegEmotion model which considers the positive impact of negative emotion on crowd evacuation, and regulates crowd emotion by controlling knowledge spreading according to Siminov&#39;s psychological principle. In this model, the knowledge spreading network (KSN) and the stress emotional contagion network (SECN) are constructed. Based on these networks, we study the evolution process of knowledge spreading and stress emotional contagion, respectively. Next, we formulate the emotional regulation as an optimization problem to maximize the efficiency of crowd evacuation. Then, a heuristic algorithm is used to solve for the optimal emotional regulation strategy. Finally, a crowd simulation system is implemented to verify the effectiveness of our NegEmotion model. The experimental results show that our method is effective to improve the efficiency of crowd evacuation.},
  archive      = {J_TCSS},
  author       = {Zena Tian and Guijuan Zhang and Hui Yu and Hong Liu and Dianjie Lu},
  doi          = {10.1109/TCSS.2023.3344172},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3348-3361},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {NegEmotion: Explore the double-edged sword effect of negative emotion on crowd evacuation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable cyberbullying detection in hinglish: A
generative approach. <em>TCSS</em>, <em>11</em>(3), 3338–3347. (<a
href="https://doi.org/10.1109/TCSS.2023.3333675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The escalating prevalence of online cyberbullying and trolling across various social media platforms has becomes a pressing concern. Extensive research demonstrates the detrimental impact of cyberbullying on the mental well-being of its victims. Given the sheer volume of online content, manual identification of cyberbullying instances proves unfeasible, necessitating the development of automated cyberbullying detection methods. This challenge has attracted considerable attention within the natural language processing (NLP) community, owing to advancements in machine learning techniques. However, most of the methods fail to provide reasoning for their decisions which warrants the use of interpretable models that can explain the model&#39;s output in real-time. Interpretable models rather than black-box models with high performance are becoming popular adhering the “right to explanations” laws. Motivated by this, we create a cyberbullying corpus BullyExplain in code-mixed language, where a post has been annotated with four labels, i.e., bully, sentiment, target, and rationales (explainability). Current work addresses the task of explainable cyberbully detection and proposes a unified generative framework, BullyGen by redefining this multitask problem as a text-to-text generation task. Our framework is capable of not only detecting whether the text is a cyberbully or not but also provides reasoning by predicting rationale, target group and sentiment of the text. Experimental results illustrate the efficacy of our proposed model by outperforming the state-of-the-art and several baselines by a significant margin and conclude that text-to-text generation model could be a good alternative for multitask classification problems.},
  archive      = {J_TCSS},
  author       = {Krishanu Maity and Raghav Jain and Prince Jha and Sriparna Saha},
  doi          = {10.1109/TCSS.2023.3333675},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3338-3347},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Explainable cyberbullying detection in hinglish: A generative approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NewsSlant: Analyzing political news and its influence
through a moral lens. <em>TCSS</em>, <em>11</em>(3), 3329–3337. (<a
href="https://doi.org/10.1109/TCSS.2023.3341910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Political news is often slanted toward its publisher&#39;s ideology and seeks to influence readers by focusing on selected aspects of contentious social and political issues. We investigate political slants in news and their influence on readers by analyzing election-related news and readers’ reactions to the news on Twitter. To this end, we collected election-related news from six major U.S. news publishers who covered the 2020 U.S. presidential election. We computed each publisher&#39;s political slant based on the favorability of its news toward the two major parties’ presidential candidates. We find that the election-related news coverage shows signs of political slant both in news headlines and on Twitter. The difference in news coverage of the two candidates between the left-leaning ( LEFT ) and right-leaning ( RIGHT ) news publishers is statistically significant. The effect size is larger for the news on Twitter than for headlines. And, news on Twitter expresses stronger sentiments than the headlines. We identify moral foundations in readers’ reactions to the news on Twitter based on the moral foundation theory. Moral foundations in readers’ reactions to LEFT and RIGHT differ statistically significantly, though the effects are small. Further, these shifts in moral foundations differ across social and political issues. User engagement on Twitter is higher for RIGHT than for LEFT . We posit that an improved understanding of slant and influence can enable better ways to combat online political polarization.},
  archive      = {J_TCSS},
  author       = {Amanul Haque and Munindar P. Singh},
  doi          = {10.1109/TCSS.2023.3341910},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3329-3337},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {NewsSlant: Analyzing political news and its influence through a moral lens},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Digital learning challenges in tertiary education in sri
lanka: A social capital perspective. <em>TCSS</em>, <em>11</em>(3),
3311–3328. (<a href="https://doi.org/10.1109/TCSS.2023.3306571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the underlying factors that contribute to the success of digital learning in higher education using a social capital perspective. It is important to address the issues faced in tertiary education as these students will soon be a part of the workforce. Although digital learning has advanced in developed countries, many developing nations, including Sri Lanka, are still in the early stages of adopting it. Previous research has not adequately explored the relationship between social capital and the challenges of digital learning in the Sri Lankan context. Thus, this study focuses on examining the structural, relational, and cognitive aspects of social capital in relation to the difficulties in digital education in tertiary institutions. The research uses a quantitative approach, and the data were collected through an online survey of students in nonstate universities in Sri Lanka. Structural equation modeling was used to analyze the data, and the results showed that the three dimensions of poor social capital have a negative impact on digital education in tertiary institutions. This study also used multigroup moderation analysis to examine the effect of gender and location. This article will provide new insights into the role of social capital in digital education and will help policy makers to improve the quality and accessibility of digital education for all.},
  archive      = {J_TCSS},
  author       = {Jayoda Weerapperuma and Dasuni Nawinna and Narmada Gamage},
  doi          = {10.1109/TCSS.2023.3306571},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3311-3328},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Digital learning challenges in tertiary education in sri lanka: A social capital perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Underreporting in COVID-19 case data causes policy
objectives being unmet. <em>TCSS</em>, <em>11</em>(3), 3299–3310. (<a
href="https://doi.org/10.1109/TCSS.2023.3325308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the start of the COVID-19 pandemic, social distancing has been key to curb the spread of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Social distancing policies have largely been made based on reported case data, which are often underreported. There is little to no understanding of how underreporting in case data may affect the performance of social distancing policies designed using such data. This article aims to fill this gap. We evaluate three policy-making rationales (called “controllers”): a flattening-the-curve (FC) controller that maximizes allowable transmission rate while ensuring hospital capacity is not exceeded, a time-limited-intervention (TLI) controller to minimize the number of infectious people with policies of fixed durations, and a minimizing-health-and-economic-costs-with-reinforcement-learning (MC-RL) controller to minimize weighted public health and economic costs. Each controller is applied in six scenarios where there is no underreporting, underreporting without correcting it, and underreporting with corrections. It is found that both the recommended policies by a controller and the resulting disease trajectories would be different under different scenarios, in which direction underreporting affects policies and disease trajectories depending on three factors: time elapsed since start of pandemic, local hospital capacity, and disease severity. Our findings demonstrate the high stakes of ignoring the underreporting issue or simply upscaling the case data: policies designed cannot achieve preset control objectives and could bring unexpected public health and economic outcomes.},
  archive      = {J_TCSS},
  author       = {Xiangyang Guan and Grace Jia and Krishna Chaitanya Kosaraju and Vijay Gupta and Cynthia Chen},
  doi          = {10.1109/TCSS.2023.3325308},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3299-3310},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Underreporting in COVID-19 case data causes policy objectives being unmet},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning to augment graphs: Machine-learning-based social
network intervention with self-supervision. <em>TCSS</em>,
<em>11</em>(3), 3286–3298. (<a
href="https://doi.org/10.1109/TCSS.2023.3340230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a machine learning (ML)-based approach to solve a graph optimization problem, named network intervention with limited degradation (NILD), which aims at adding new edges to augment the graph to minimize the local clustering coefficient (LCC) of a target node. The main application of NILD is to perform network intervention , to improve the mental well-being of individuals. This article proposes a new framework, named network intervention with self-supervision (NISS), which employs reinforcement learning and self-supervised learning (SSL) to effectively solve the problem. We propose two new effective pretext tasks in SSL, Distance-to-target prediction task and LCC increment prediction task to improve the model performance. In addition, we also propose two new embedding approaches, neighborhood embedding (NE) and constraint property embedding (CPE), to capture the structural information of the graph. Extensive experiments on multiple real social networks and synthetic datasets show that our proposed approach significantly outperforms the other state-of-the-art baselines, including ML-based baselines and deterministic algorithms.},
  archive      = {J_TCSS},
  author       = {Chih-Chieh Chang and Chia-Hsun Lu and Ming-Yi Chang and Chao-En Shen and Ya-Chi Ho and Chih-Ya Shen},
  doi          = {10.1109/TCSS.2023.3340230},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3286-3298},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Learning to augment graphs: Machine-learning-based social network intervention with self-supervision},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust weighted low-rank tensor approximation for multiview
clustering with mixed noise. <em>TCSS</em>, <em>11</em>(3), 3268–3285.
(<a href="https://doi.org/10.1109/TCSS.2023.3331366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiview clustering performs grouping a set of objects by utilizing complementary information from multiple views. Unfortunately, the clustering performance degenerates dramatically if the views are corrupted by noise. To overcome this limitation, we propose a robust multiview clustering approach based on weighted low-rank tensor approximation and noise separation. The proposed model improves the performance through a low-rank approximation function and weighted singular values. The weighted low-rank tensor approximation method considers both prior knowledge and the physical meanings associated with different singular values, leading to superior performance in capturing high-order correlations. Additionally, to eliminate mixed noise, a novel $\boldsymbol{l}_{\mathbf{Cauchy,1}}$ norm is developed to handle outliers, and the $\boldsymbol{l}_{\mathbf{1}}$ and Frobenius norms are used to handle random corruptions and slight perturbations, respectively. A high-efficiency optimization algorithm based on the alternating direction method of multipliers (ADMM) is designed to address the challenging proposed model. Experimental results on nine real-world datasets show that the proposed approach outperforms eight state-of-the-art multiview methods. Furthermore, experiments on various kinds of noise demonstrate the superior robustness of the proposed approach. Especially, in the mixed noise condition, the proposed approach is significantly superior to other methods.},
  archive      = {J_TCSS},
  author       = {Xinyu Pu and Hangjun Che and Baicheng Pan and Man-Fai Leung and Shiping Wen},
  doi          = {10.1109/TCSS.2023.3331366},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3268-3285},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Robust weighted low-rank tensor approximation for multiview clustering with mixed noise},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A max–min ant system with repetitive influence reduction
strategy for interactive dissemination of positive and negative
information. <em>TCSS</em>, <em>11</em>(3), 3255–3267. (<a
href="https://doi.org/10.1109/TCSS.2023.3328994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of online social networks (OSNs) has facilitated people to express opinions and share information. To optimize the utility of information dissemination in OSNs, problems such as influence maximization have received increasing attention in recent years. However, not only positive information but also negative information is spreading in OSNs. The dissemination of positive and negative information interacts with each other, making network dissemination analysis and utility optimization more challenging. To this end, we develop a negative–neutral–positive–susceptible (NNPS) model and propose a max–min ant system algorithm with a repetitive influence reduction strategy (MMAS-RIR). First, an NNPS model with a novel heterogenous influence indicator is constructed to simulate the interactive dissemination of positive and negative information. The influence of each user’s neighbors on each user is treated differently, producing heterogenous state transition probabilities for users. Second, we formulate the control of information dissemination as an optimization problem with a designed control scheme. The disruption strategy and counterbalance strategy are automatically implemented on the selected users according to their states in the control scheme. Third, we specially develop a MMAS-RIR algorithm for the formulated problem, where the repetitive influence reduction strategy is used to reduce the influence repeated range of the connected users. Moreover, to improve the exploitation, an adaptive local search is added in MMAS-RIR. Finally, various experiments are conducted to validate the effectiveness of our work.},
  archive      = {J_TCSS},
  author       = {Xuan-Li Shi and Wei-Neng Chen and Jing-Hui Zhong and Jun Zhang},
  doi          = {10.1109/TCSS.2023.3328994},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3255-3267},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A Max–Min ant system with repetitive influence reduction strategy for interactive dissemination of positive and negative information},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary dynamics of direct and indirect reciprocities
with directional interactions. <em>TCSS</em>, <em>11</em>(3), 3243–3254.
(<a href="https://doi.org/10.1109/TCSS.2023.3326352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reciprocity is a potent mechanism that drives cooperation within human societies. Direct reciprocity involves interacting with individuals, while indirect reciprocity is reliant on anticipated rewards from a third party rather than someone they have interacted with directly. Despite being closely intertwined, current research isolates these two mechanisms, with further division of indirect reciprocity into positive and negative based on the directionality of daily interactions. To capture the coevolution of direct and indirect reciprocities, this work has developed a simple yet comprehensive model, allowing individuals to choose among these reciprocities arbitrarily. A comprehensive equilibrium analysis discovers that the analogous strategy of negative indirect reciprocity, called negative scoring (NSCO), has a stronger control property than the well-known reciprocity strategies. Utilizing evolutionary simulations, we find that directionality can indeed promote the emergence of indirect reciprocity. Overall, our findings shed light on a novel passageway toward a universal theory of direct and indirect reciprocities.},
  archive      = {J_TCSS},
  author       = {Hui Wei and Jianlei Zhang and Chunyan Zhang},
  doi          = {10.1109/TCSS.2023.3326352},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3243-3254},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Evolutionary dynamics of direct and indirect reciprocities with directional interactions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated graph augmentation for semisupervised node
classification. <em>TCSS</em>, <em>11</em>(3), 3232–3242. (<a
href="https://doi.org/10.1109/TCSS.2024.3373633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semisupervised node classification is a prevalent task on graphs, which involves predicting the labels of unlabeled nodes based on limited labeled data available. At present, centralized approaches to training models for this task are unsustainable due to the increasing demand for computational power, storage capacity, and privacy. An approach of potential is federated graph learning (FGL), which allows multiple clients to collaborate on learning a model while maintaining data privacy. However, current methods suffer from the inability to consider the topology of the graph data and inadequate use of unlabeled data. To address these issues, we propose federated graph augmentation (FedGA) by combining graph neural network (GNN) models to utilize similar topologies existing in different client graphs and augment the client data. Furthermore, we develop FedGA-L based on FedGA, which integrates pseudolabeling and label-injection to improve the utilization of unlabeled data. FedGA-L allows pseudolabels to be used as additional information to enhance data augmentation and further improve the accuracy of node classification. We evaluate the effectiveness of FedGA and FedGA-L through experiments on multiple datasets. The results demonstrate improved accuracy in solving typical classification tasks and their compatibility with a variety of federated learning (FL) frameworks. On widely recognized datasets for graph learning, we achieve an accuracy improvement of 5%–7% compared to vanilla federated learning algorithms.},
  archive      = {J_TCSS},
  author       = {Zhichang Xia and Xinglin Zhang and Lingyu Liang and Yun Li and Yuejiao Gong},
  doi          = {10.1109/TCSS.2024.3373633},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3232-3242},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Federated graph augmentation for semisupervised node classification},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting targets of graph adversarial attacks with edge and
feature perturbations. <em>TCSS</em>, <em>11</em>(3), 3218–3231. (<a
href="https://doi.org/10.1109/TCSS.2023.3344642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) enable many novel applications and achieve excellent performance. However, their performance may be significantly degraded by the graph adversarial attacks, which intentionally add small perturbations to the graph. Previous countermeasures usually handle such attacks by enhancing model robustness. However, robust models cannot identify the target nodes of the adversarial attacks, and thus we are unable to pinpoint the weak spots and analyze the causes or the targets of the attacks. In this article, we study the important research problem to detect the target nodes of graph adversarial attacks under the black-box detection scenario, which is particularly challenging because our detection models do not have any knowledge about the attacker, while the attackers usually employ unnoticeability strategies to minimize the chance of being detected. To our best knowledge, this is the first work that aims at detecting the target nodes of graph adversarial attacks under the black-box detector scenario. We propose two detection models, named Det-H and Det-RL , which employ different techniques that effectively detect the target nodes under the black-box detection scenario against various graph adversarial attacks. To enhance the generalization of the proposed detectors, we further propose two novel surrogate attackers that are able to generate effective attack examples and camouflage their attack traces for training robust detectors. In addition, we propose three strategies to effectively improve the training efficiency. Experimental results on multiple datasets show that our proposed detectors significantly outperform the other baselines against multiple state-of-the-art graph adversarial attackers with various attack strategies. The proposed Det-RL detector achieves an averaged area under curve (AUC) of $0.945$ against all the attackers, and our efficiency-improving strategies are able save up to $91$ % of the training time.},
  archive      = {J_TCSS},
  author       = {Boyi Lee and Jhao-Yin Jhang and Lo-Yao Yeh and Ming-Yi Chang and Chia-Mei Chen and Chih-Ya Shen},
  doi          = {10.1109/TCSS.2023.3344642},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3218-3231},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Detecting targets of graph adversarial attacks with edge and feature perturbations},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bi-directional delay propagation analysis and modeling for
high-speed railway networks under disturbance. <em>TCSS</em>,
<em>11</em>(3), 3207–3217. (<a
href="https://doi.org/10.1109/TCSS.2023.3322747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {China’s high-speed railway (HSR) has entered the era of networked operation. Any internal disturbance or eternal disturbance may result in delays of some trains and even cascading delays, which will not only reduce the traffic efficiency of HSR, but also break passengers’ travel and lower their satisfaction. Studying the delay propagation mechanism could assist the dispatcher in suppressing the negative effect of disturbances. However, current studies seldom consider the withholding strategy’s impact on delay propagation. Inspired by this, this article proposes a novel bi-directional delay propagation model combined with the trains’ operation trajectory and stations’ withholding strategy. Moreover, the operation constraint, station capacity constraint, and interlocking constraint are also considered. Then, the primary delay under section disruption (SD) and section temporary speed limit (STSL) are derived based on the location of the disturbance, duration time of the disturbance, and the operation strategy. Then, a max-plus algebra-based delay propagation model is established to compute the corresponding secondary delays. Also, the All Pair Critical Path algorithm is modified to incorporate the station capacity constraint in the searching process. Simulations based on the real China HSR subnetwork are implemented to verify the proposed model. Compared with the current study, the proposed model could accurately unfold the delay propagation in the opposite train heading direction. Besides, the relationship among disturbance duration, primary delay, and accumulative delay for the SD scenario and the relationship among temporarily limited velocity, primary delay, and accumulative delay for the STSL scenario are revealed.},
  archive      = {J_TCSS},
  author       = {Wenbo Lian and Xingtang Wu and Min Zhou and Jinhu Lü and Hairong Dong},
  doi          = {10.1109/TCSS.2023.3322747},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3207-3217},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Bi-directional delay propagation analysis and modeling for high-speed railway networks under disturbance},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Member-augmented group recommendation with multi-interest
framework and knowledge graph embeddings. <em>TCSS</em>, <em>11</em>(3),
3193–3206. (<a href="https://doi.org/10.1109/TCSS.2023.3322732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People consume items not only by themselves but also in groups that include their family, friends, coworkers, and online social groups. Different from individual recommendation systems, group recommendation systems first consider group member’s preference separately. The impacts among members are considered, and then, the final group preference and decision would be generated. However, existing group recommendation models suffer severer data sparsity problems than traditional recommendation systems. There is currently lack of a systematic approach to properly address the above issue. What is worse, previous works less consider situations that users may have diverse interests, which means that users may change their preferences by considering the preferences of other group members. Here, we propose a member-augmented multi-interest model with knowledge graph (KG) embeddings to overcome the aforementioned drawbacks. Because only positive labels of groups can be identified in a dataset, precisely predicting a group’s opinion on items that members have not been exposed to is difficult. Accordingly, our model applies the member augmentation (MA) technique to precisely predict a group’s opinion on items. In addition, we leverage multi-interest framework to model the change of diverse user preferences. The framework can know which interests of the user will affect the decision of the group, and interests will vary with different group members. Experiments indicated that the proposed model improves the performance by around 20%, 10%, and 2% in MaFengWo, Yelp, and Meetup-NYC, respectively.},
  archive      = {J_TCSS},
  author       = {Sin-Jing Lin and Chiao-Ting Chen and Szu-Hao Huang},
  doi          = {10.1109/TCSS.2023.3322732},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3193-3206},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Member-augmented group recommendation with multi-interest framework and knowledge graph embeddings},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A knowledge-driven anomaly detection framework for social
production system. <em>TCSS</em>, <em>11</em>(3), 3179–3192. (<a
href="https://doi.org/10.1109/TCSS.2022.3217790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the social production system, image data are rapidly generated from almost all fields such as factories, hospitals, and transportation, promoting higher requirements for image anomaly detection technologies, including low consumption, higher adaptability, and accuracy. However, existing anomaly detection methods are fragile to heterogeneous image data generated by complex social production systems and tend to require strong computing power and resource support. To address the above problems, a knowledge-driven anomaly detection framework is proposed, in which a local feature enhancement method is designed to strengthen the knowledge representation of the initial features extracted from images. The attention mechanism in deep learning is introduced to adjust the feature attention dynamically according to prior knowledge, which solves the problem of feature loss in the cascade training. To verify the effectiveness of the proposed framework, extensive experiments on social production datasets are conducted. The results demonstrate that our framework outperforms the selected methods on image datasets with different complexity and sample distributions.},
  archive      = {J_TCSS},
  author       = {Zheng Li and Xiaolong Xu and Tian Hang and Haolong Xiang and Yan Cui and Lianyong Qi and Xiaokang Zhou},
  doi          = {10.1109/TCSS.2022.3217790},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3179-3192},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A knowledge-driven anomaly detection framework for social production system},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rumor localization, detection and prediction in social
network. <em>TCSS</em>, <em>11</em>(3), 3168–3178. (<a
href="https://doi.org/10.1109/TCSS.2022.3216923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the global epidemic of the COVID-19, various rumors spread wantonly on social networks, which has seriously affected the stability and harmony of the entire society. To purify the network environment, some researchers have proposed to fight rumors from the perspectives of tracing the source of rumors, detecting the authenticity of information, and predicting explosive fake news. But their works are fragmented, and their performance are not significant. So we need strong antirumor methods to fight rumors. To this end, this article proposes a more comprehensive antirumor mechanism, which can realize rumors source location, rumor detection, and popularity prediction (RLDP). In particular, in the task of localization, we propose graph neural network-based method, which does not need to specify the underlying propagation mode and the number of rumor sources; in the task of detection, utilizing lightGBM, we construct a rumor detection model; in the task of popularity prediction, we construct a model based on contrastive learning while considering user engagements and information propagation, and the text of rumor. Finally, we verify the performance of the proposed RLDP by conducting extensive experiments.},
  archive      = {J_TCSS},
  author       = {Yinan Jiang and Ranran Wang and Jianshan Sun and Yashen Wang and Haofang You and Yin Zhang},
  doi          = {10.1109/TCSS.2022.3216923},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3168-3178},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Rumor localization, detection and prediction in social network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Social-aware learning-based online energy scheduling for 5G
integrated smart distribution power grid. <em>TCSS</em>, <em>11</em>(3),
3157–3167. (<a href="https://doi.org/10.1109/TCSS.2022.3198684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A 5G integrated smart distribution power grid brings a new paradigm shift to realize base station (BS) operation cost reduction, efficient renewable energy utilization, and stable energy supply. However, energy scheduling still faces some major challenges, such as coupling between energy sharing and energy trading, dimensionality curse, and intertwinement of social network attributes and BS load. To tackle these challenges, we propose a social-aware learning-based online energy scheduling (SNES) algorithm, which minimizes BS operation cost minimization under the constraints of energy supply stability. SNES leverages a deep neural network (DNN) to learn the action-state value of energy scheduling and intelligently adjusts purchased, sold, and shared energy based on only casual information. Moreover, SNES achieves social awareness by approximating the nonlinear interconnection between energy scheduling and quality of service (QoS) requirements of social network services. Simulation results verify the superior performance of SNES compared with state-of-the-art energy scheduling algorithms.},
  archive      = {J_TCSS},
  author       = {Lurui Jia and Haijun Liao and Zhenyu Zhou and Xiyang Yin and Zhongyu Wang and Yizhao Liu and Zhixin Lu and Guoyuan Lv and Wenbing Lu and Xiufan Ma and Xiaoyan Wang},
  doi          = {10.1109/TCSS.2022.3198684},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3157-3167},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Social-aware learning-based online energy scheduling for 5G integrated smart distribution power grid},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A web knowledge-driven multimodal retrieval method in
computational social systems: Unsupervised and robust graph
convolutional hashing. <em>TCSS</em>, <em>11</em>(3), 3146–3156. (<a
href="https://doi.org/10.1109/TCSS.2022.3216621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal retrieval has received widespread consideration since it can commendably provide massive related data support for the development of computational social systems (CSSs). However, the existing works still face the following challenges: 1) rely on the tedious manual marking process when extended to CSS, which not only introduces subjective errors but also consumes abundant time and labor costs; 2) only using strongly aligned data for training, lacks concern for the adjacency information, which makes the poor robustness and semantic heterogeneity gap difficult to be effectively fit; and 3) mapping features into real-valued forms, which leads to the characteristics of high storage and low retrieval efficiency. To address these issues in turn, we have designed a multimodal retrieval framework based on web-knowledge-driven, called unsupervised and robust graph convolutional hashing (URGCH). The specific implementations are as follows: first, a “secondary semantic self-fusion” approach is proposed, which mainly extracts semantic-rich features through pretrained neural networks, constructs the joint semantic matrix through semantic fusion, and eliminates the process of manual marking; second, a “adaptive computing” approach is designed to construct enhanced semantic graph features through the knowledge-infused of neighborhoods and uses graph convolutional networks for knowledge fusion coding, which enables URGCH to sufficiently fit the semantic modality gap while obtaining satisfactory robustness features; Third, combined with hash learning, the multimodality data are mapped into the form of binary code, which reduces storage requirements and improves retrieval efficiency. Eventually, we perform plentiful experiments on the web dataset. The results evidence that URGCH exceeds other baselines about 1%–3.7% in mean average precisions (MAPs), displays superior performance in all the aspects, and can meaningfully provide multimodal data retrieval services to CSS.},
  archive      = {J_TCSS},
  author       = {Youxiang Duan and Ning Chen and Ali Kashif Bashir and Mohammad Dahman Alshehri and Lei Liu and Peiying Zhang and Keping Yu},
  doi          = {10.1109/TCSS.2022.3216621},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3146-3156},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A web knowledge-driven multimodal retrieval method in computational social systems: Unsupervised and robust graph convolutional hashing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable machine learning for data extraction across
computational social system. <em>TCSS</em>, <em>11</em>(3), 3131–3145.
(<a href="https://doi.org/10.1109/TCSS.2022.3164993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the explainable machine learning for data extraction on diverse datasets. In many cases, individual or specific approaches have been developed for feature selection (FS) on a certain dataset, but collecting the diversity dataset and demonstrating it through different FS methods are challenging. Thus, this article proposed multiapproaches for FS with the classification of diverse datasets. The proposed framework is developed using various methods, such as extendable particle swarm optimization (PSO), global and local searching, feature ranking, feature clustering, computational cost-based FS, and multiobjective optimization. We effectively used these methods in our proposed work in a single-setting framework. We focused on three essential computational items in our framework: classification accuracy, selected features, and computational times. Due to the diverse dataset, few methods have been considered challenging during computational evaluation for classification accuracy with test cost. We tried to manage the classification accuracy based on total cost and high accuracy with less cost. The proposed framework is experimented with the above methods and analyzed through comparative results on diversity datasets. For example, when regular parameter values are in the range of $2^{-13}$ – $2^{-6}$ , the evaluation result affects all items, i.e., decreasing during this range; other values do not affect results. We used thresholds ranging from 0.6 to 0.9 for highly correlated feature pairs as per the support vector machine (SVM) method for recursive feature elimination.},
  archive      = {J_TCSS},
  author       = {Hemanta Kumar Bhuyan and Chinmay Chakraborty},
  doi          = {10.1109/TCSS.2022.3164993},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3131-3145},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Explainable machine learning for data extraction across computational social system},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inductive link prediction via interactive learning across
relations in multiplex networks. <em>TCSS</em>, <em>11</em>(3),
3118–3130. (<a href="https://doi.org/10.1109/TCSS.2022.3176928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding is an important class of link prediction methods, which can use the distance between learned low-dimensional node representations to characterize the similarity between nodes. Traditional network embedding methods focus on single-layer networks, while in reality, a large part of complex networks are not isolated, but interdependent and interrelated, forming multiplex complex networks. Also, how to effectively exploit layer correlations in multiplex networks to learn more robust and valuable representations, to improve link prediction performance, has been a hot research topic in the field of complex network analysis. However, previous studies mainly focus on inferring intralinks in each layer of complex networks or anchor links among layers. Another issue that has not been discussed is how to predict potential links or reconstruct the network in unobserved relations based on existing multiplex networks. To this issue, we define a novel inductive link prediction problem in multiplex networks, in which most existing multichannel network embedding methods fail to solve. This is either because they only emphasize the specific structure information of an individual layer or only capture the common information for all layers. To effectively address this problem, we propose a novel embedding method termed interactive learning across relations (ILAR), to capture and fully exploit the multiple relations and complex layer correlations in multiplex networks. We leverage two convolutional modules and ILAR to capture the sufficient complementary and correlations in multiplex networks. Moreover, during interactive learning, a disparity constraint is introduced, which enforces the features encoded from two convolutional modules to be different and prevents information redundancy. Finally, the extensive experiments in several real-world datasets show that our model can significantly outperform the existing state-of-the-art network embedding methods on the novel link prediction problem in multiplex networks.},
  archive      = {J_TCSS},
  author       = {Mengzhou Gao and Pengfei Jiao and Ruili Lu and Huaming Wu and Yinghui Wang and Zhidong Zhao},
  doi          = {10.1109/TCSS.2022.3176928},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3118-3130},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Inductive link prediction via interactive learning across relations in multiplex networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MRFS: Mining rating fraud subgraph in bipartite graph for
users and products. <em>TCSS</em>, <em>11</em>(3), 3108–3117. (<a
href="https://doi.org/10.1109/TCSS.2022.3233821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fraud in e-commerce fields (e.g., Amazon, Taobao, and so on) and social networks (e.g., Twitter and Weibo) has recently brought a very bad user experience. Rating fraud detection is an urgent issue for improving user experiences. However, existing methods have lots of limitations in some respects, because it is always very hard to acquire sufficient labeled data for fraud detection and detect new fraud patterns. Fortunately, the relationship for users rating (e.g., purchasing and following) products can be represented as a bipartite graph. So the problem of rating fraud detection can be transformed into the problem of abnormal subgraph detection in the bipartite graph. The major challenge of fraud detection is to distinguish fake rates from real user rates. In this article, we focus on mining rating fraud-connected subgraphs in a bipartite graph. The motivation for this work is fraud detection tasks, which can usually be formulated as mining a bipartite graph formed by source nodes (followers and users) and target nodes (followees and products) for malicious patterns. Now, smart fraudsters evade existing detection methods by buying a large pool of users and hijacking honest users, making them look “normal”-this behavior is called “camouflage.” Accordingly, we propose a fraud detection approach for mining rating fraud subgraph (MRFS), which addresses the problem from the intrinsic metric (e.g., fraudulence, badness and unreliability). The proposed MRFS mines the intrinsic characteristics of nodes and edges from node behavior information, which is an effective and scalable (linear on the input size) algorithm. A large number of comparative experimental results on real-world rating networks show that our proposed MRFS is efficient and universal.},
  archive      = {J_TCSS},
  author       = {Wei Yu and Wenkai Wang and Guangquan Xu and Huaming Wu and Hongyan Li and Jun Wang and Xiaoming Li and Juan Liu},
  doi          = {10.1109/TCSS.2022.3233821},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3108-3117},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {MRFS: Mining rating fraud subgraph in bipartite graph for users and products},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enabling parity authenticator-based public auditing with
protection of a valid user revocation in cloud. <em>TCSS</em>,
<em>11</em>(3), 3090–3107. (<a
href="https://doi.org/10.1109/TCSS.2022.3165213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significance of the cloud enables the data owners (DOs) to store data remotely in cloud server (CS). The external and internal attacks on the stored data at CS can deliberately remove data. Furthermore, the CS removes the stored data to make empty location for the user’s upcoming new data. However, it is a legal expectation of DOs to know whether their data are correctly stored or altered in CS. In this article, we propose a novel privacy-aware and hash-parity-bits-based public auditing (PA-HPPA) framework to secure full data, left half of the data, and the right half of the data, generated by a DO. DO generates two private key pairs with the assistance of a virtual key and a user ID (IP). The virtual key is the sequence number of DO who is registered and provided by the trusted data manager (TDM) while IP is the sequence number of DO working in an organization. Subsequently, DO blinds the categorized data and generates their signatures and hashes. In addition, DO generates the parity bits using XOR and assigns to each hard drive (HD) in CS, which assistants to TDM in public auditing. Second, how to identify the error in the stored data and how to securely recover the error/missed data? Extension to the framework, the novel proposed data error identification and secure data recovery produce tags for installed HDs of CS using truth table and recover the altered/missed data via a authenticator, which is produced using XOR function. Third, how to protect a valid user from revocation and, in case a user has revoked on merit basis, then how to securely access the stored data of it? This novel work has proposed three conditions to meet the validity of the valid user from revocation and securely generating the public–private key pairs to access the stored data of the revoked user securely from CS. Fourth, there is an efficient novel proposed dynamic operation scheme to insert, update, or delete the stored data at CS without regenerating the signatures, hashes, and tags for the whole stored data in cloud. The security analysis and the performance evaluation of the proposed solutions are provably efficient and secure with reduced communication costs.},
  archive      = {J_TCSS},
  author       = {Fasee Ullah and Chi-Man Pun},
  doi          = {10.1109/TCSS.2022.3165213},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3090-3107},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Enabling parity authenticator-based public auditing with protection of a valid user revocation in cloud},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Edge server deployment for health monitoring with
reinforcement learning in internet of medical things. <em>TCSS</em>,
<em>11</em>(3), 3079–3089. (<a
href="https://doi.org/10.1109/TCSS.2022.3161996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Medical Things (IoMT) has recently gained a lot of interest in the health care industry. IoMT enables real-time and omnipresent monitoring of a patient’s health status, resulting in massive amounts of medical data being generated. The centralized massive data processing places enormous strain on the typical cloud computing, rendering it incapable of supporting a variety of real-time health care applications. Therefore, edge computing that moves application programs and data processing from central infrastructure to the edge nodes has attracted wide attention. However, adopting existing edge server (ES) deployment strategies for IoMT is not suitable due to the decentralized and high real-time service requirements of IoMT systems. In particular, traditional ES deployment strategies in IoMT system confront major load imbalance across ESs, latency issues, and energy consumption concerns. To address these challenges, a deployment strategy of ESs based on the state-action-reward-state-action (SARSA) learning, named ESL, is designed. Specifically, ESs are quantified by evaluating the silhouette coefficient (SC) and the sum of squared errors. Then, through fuzzy C-means (FCM) algorithm, the preliminary division of health monitoring units (HMUs) and the initial locations of ESs are obtained. Finally, SARSA learning is adopted to determine the deployment of ESs. Furthermore, extensive experiments and analyses confirm that ESL achieves the core objective of optimizing load balancing among ESs while also optimizing request–response latency and request processing energy consumption.},
  archive      = {J_TCSS},
  author       = {Hanzhi Yan and Muhammad Bilal and Xiaolong Xu and S. Vimal},
  doi          = {10.1109/TCSS.2022.3161996},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3079-3089},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Edge server deployment for health monitoring with reinforcement learning in internet of medical things},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A DRL-based service offloading approach using DAG for edge
computational orchestration. <em>TCSS</em>, <em>11</em>(3), 3070–3078.
(<a href="https://doi.org/10.1109/TCSS.2022.3161627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge infrastructure and Industry 4.0 required services are offered by edge-servers (ESs) with different computation capabilities to run social application’s workload based on a leased-price method. The usage of Social Internet of Things (SIoT) applications increases day-to-day, which makes social platforms very popular and simultaneously requires an effective computation system to achieve high service reliability. In this regard, offloading high required computational social service requests (SRs) in a time slot based on directed acyclic graph (DAG) is an $NP$ -complete problem. Most state-of-art methods concentrate on the energy preservation of networks but neglect the resource sharing cost and dynamic subservice execution time (SET) during the computation and resource sharing. This article proposes a two-step deep reinforcement learning (DRL)-based service offloading (DSO) approach to diminish edge server costs through a DRL influenced resource and SET analysis (RSA) model. In the first level, the service and edge server cost is considered during service offloading. In the second level, the R-retaliation method evaluates resource factors to optimize resource sharing and SET fluctuations. The simulation results show that the proposed DSO approach achieves low execution costs by streamlining dynamic service completion and transmission time, server cost, and deadline violation rate attributes. Compared to the state-of-art approaches, our proposed method has achieved high resource usage with low energy consumption.},
  archive      = {J_TCSS},
  author       = {M. S. Mekala and Gaurav Dhiman and Gautam Srivastava and Zulqar Nain and Haolin Zhang and Wattana Viriyasitavat and G. P. S. Varma},
  doi          = {10.1109/TCSS.2022.3161627},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3070-3078},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A DRL-based service offloading approach using DAG for edge computational orchestration},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). InfusedHeart: A novel knowledge-infused learning framework
for diagnosis of cardiovascular events. <em>TCSS</em>, <em>11</em>(3),
3060–3069. (<a href="https://doi.org/10.1109/TCSS.2022.3151643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the undertaken study, we have used a customized dataset termed “Cardiac-200” and the benchmark dataset “PhysioNet.” which contains 1500 heartbeat acoustic event samples (without augmentation) and 1950 samples (with augmentation) heartbeat acoustic events such as normal, murmur, extrasystole, artifact, and other unlabeled heartbeat acoustic events. The primary reason for designing a customized dataset, “cardiac-200,” is to balance the total number of samples into categories such as normal and abnormal heartbeat acoustic events. The average duration of the recorded heartbeat acoustic events is 10–12 s. In the undertaken study, we have analyzed and evaluated various heartbeat acoustic events using audio processing libraries such as Chromagram, Chroma-cq, Chroma-short-time Fourier transform (STFT), Chroma-cqt, and Chroma-cens to extract more information from the recorded heartbeat sound signals. The noise removal process has been carried out using local binary pattern (LBP) methodology. The noise-robust heartbeat acoustic images are classified using long short-term memory (LSTM)-convolutional neural network (CNN), recurrent neural network (RNN), LSTM, Bi-LSTM, CNN, K-means Clustering, and support vector machine (SVM) methods. The obtained results have shown that the proposed InfusedHeart Framework had outclassed all the other customized machine learning and deep learning approaches such as RNN, LSTM, Bi-LSTM, CNN, K-means Clustering, and SVM-based classification methodologies. The proposed Knowledge-infused Learning Framework has achieved an accuracy of 89.36% (without augmentation), 93.38% (with augmentation), and a standard deviation of 10.64 (without augmentation), and 6.62 (with augmentation). Furthermore, the proposed framework has been tested for various signal-to-noise ratio conditions such as SignaltoNoiseRatio0, SignaltoNoiseRatio3, SignaltoNoiseRatio6, SignaltoNoiseRatio9, SignaltoNoiseRatio12, SignaltoNoiseRatio15, and SignaltoNoiseRatio18. In the end, we have shown a detailed comparison of texture and without texture approaches and have discussed future enhancements and prospective ways for future directions.},
  archive      = {J_TCSS},
  author       = {Sharnil Pandya and Thippa Reddy Gadekallu and Praveen Kumar Reddy and Weizheng Wang and Mamoun Alazab},
  doi          = {10.1109/TCSS.2022.3151643},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3060-3069},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {InfusedHeart: A novel knowledge-infused learning framework for diagnosis of cardiovascular events},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CSCT: Charging scheduling for maximizing coverage of targets
in WRSNs. <em>TCSS</em>, <em>11</em>(3), 3049–3059. (<a
href="https://doi.org/10.1109/TCSS.2022.3169780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, wireless rechargeable sensor networks (WRSNs), as a crucial technology in cyber–physical–social systems (CPSSs), have gradually become a hotspot of research, with the development of wireless energy transmission technology. In previous works, the objective is to maximize the survival rate of sensor nodes. However, in this article, we focus on maintaining more targets. First, it details the charging scheduling problem of maximizing coverage of targets (CoT) in on-demand charging architecture of WRSNs. Also, the problem is formalized as a multiple-objective optimization problem, which aims at maximizing the CoT and the energy efficiency simultaneously. After that, the charging scheduling for maximizing coverage of targets (CSCT) scheme is proposed to achieve the above objectives. Then, the problem is reformulated as a Deadline-TSP problem that is NP-hard. To address this problem, we design an energy predictive model and propose the CSCT with an $n$ -path ( $n$ -CSCT) scheme that has an $O(|\mathcal {N}|^{n})$ computational complexity. In addition, the resurrection of sensor nodes is considered in this article. Thus, the $n$ -CSCT with node resurrection ( $n$ -CSCT-R) scheme is proposed for this case. Finally, we validate the effectiveness of the proposed schemes via extensive simulations.},
  archive      = {J_TCSS},
  author       = {Huansheng Xue and Honglong Chen and Qiuli Dai and Kai Lin and Junjian Li and Zhe Li},
  doi          = {10.1109/TCSS.2022.3169780},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3049-3059},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {CSCT: Charging scheduling for maximizing coverage of targets in WRSNs},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guest editorial: Special issue on knowledge-infused learning
for computational social systems. <em>TCSS</em>, <em>11</em>(3),
3045–3048. (<a href="https://doi.org/10.1109/TCSS.2024.3397406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This special issue comprises 12 articles, showcasing the latest advances in computational social systems research.},
  archive      = {J_TCSS},
  author       = {Tu Nguyen and Vincenzo Piuri and Joel Rodrigues and Lianyong Qi and Shahid Mumtaz and Warren Huang-Chen Lee},
  doi          = {10.1109/TCSS.2024.3397406},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3045-3048},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Guest editorial: Special issue on knowledge-infused learning for computational social systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Behavioral information feedback with large language models
for mental disorders: Perspectives and insights. <em>TCSS</em>,
<em>11</em>(3), 3026–3044. (<a
href="https://doi.org/10.1109/TCSS.2024.3397403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This edition of the publication includes a robust collection of 104 regular papers and features a Special Issue on Knowledge- Infused Learning for Computational Social Systems. This special issue delves into the sophisticated integration of advanced technologies and knowledge-based methodologies within the analysis of computational social systems. Spanning 12 articles, the issue addresses a wide spectrum of topics, from big data management to refining machine learning models with domain-specific insights. It encompasses areas such as energy management in sensor networks, acoustic analysis of heartbeats, detection of fraudulent activities in online ratings, and the management of rumors on social networks, exemplifying the significant role that knowledge-infused learning plays in enhancing technological applications and fostering innovation in social computational systems.},
  archive      = {J_TCSS},
  author       = {Minqiang Yang and Yongfeng Tao and Hanshu Cai and Bin Hu},
  doi          = {10.1109/TCSS.2024.3397403},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {6},
  number       = {3},
  pages        = {3026-3044},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Behavioral information feedback with large language models for mental disorders: Perspectives and insights},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CrowdDC: Ranking from crowdsourced paired comparison with
divide-and-conquer. <em>TCSS</em>, <em>11</em>(2), 3015–3021. (<a
href="https://doi.org/10.1109/TCSS.2023.3296632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a novel algorithm, named “CrowdDC,” that aims to solve the issue of ranking large datasets based on subjective factors using crowdsourced paired comparisons. In traditional paired comparison analysis, dealing with a sizeable dataset can become impractical as the number of comparisons required increases quadratically. To address this problem, CrowdDC is designed as a divide-and-conquer algorithm that partitions the dataset into smaller subsets and compares them independently. The results of these comparisons are then combined to generate an overall ranking. Simulation results showed that, when ranking more than 100 items, CrowdDC succeeded in reducing the number of requisite tasks by 45%–75%, while concurrently maintaining an accuracy range of 90%–95% relative to the baseline approach.},
  archive      = {J_TCSS},
  author       = {Ming-Hung Wang and Chia-Yuan Zhang and Jia-Ru Song},
  doi          = {10.1109/TCSS.2023.3296632},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {3015-3021},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {CrowdDC: Ranking from crowdsourced paired comparison with divide-and-conquer},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single-cell multiuser computation offloading in dynamic
pricing-aided mobile edge computing. <em>TCSS</em>, <em>11</em>(2),
3004–3014. (<a href="https://doi.org/10.1109/TCSS.2023.3308563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with emerging mobile Internet applications embedded in tremendous growth of computing demand, mobile edge computing (MEC) could effectively address the issue of compute-intensive and latency-sensitive computation imposed on mobile terminals through performing computation offloading strategies. However, how to find optimal decisions of transmission power, computing capacity demand, and offloading demand at the end-user and how to determine the resource pricing and allocation at the MEC server with the limited computing capacity still remain challenging issues in operating the MEC system in an optimal fashion. For multiuser in signal cell network with MEC, a dynamic pricing-based computation offloading solution is investigated in this article. Through the use of Q-learning algorithm comprehensively considering those sensitive factors, e.g., time cost, energy consumption and dynamic pricing, the offloading decision at the end-user is achieved with the consideration of time-varying wireless channel conditions. According to the resources supply and demand relationship, a dynamic pricing algorithm for the MEC server is designed to adjust the pricing strategy to achieve the win–win situation. Simulation results have been shown to demonstrate the efficiency in making offloading decision while the wireless channel is fast fading and the resource pricing is adjusted dynamically, and in enhancing utilities for both end-users and the MEC server.},
  archive      = {J_TCSS},
  author       = {Ming Tao and Xueqiang Li and Kaoru Ota and Mianxiong Dong},
  doi          = {10.1109/TCSS.2023.3308563},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {3004-3014},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Single-cell multiuser computation offloading in dynamic pricing-aided mobile edge computing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label-dependent graph neural network. <em>TCSS</em>,
<em>11</em>(2), 2990–3003. (<a
href="https://doi.org/10.1109/TCSS.2023.3312395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network (GNN) provides a powerful expressive way to embed graph-structured data, which has been widely applied and spans many fields. This article found an interesting but unreasonable phenomenon in some classical GNNs, namely label confusion. Theoretically, the dependence between prediction label and ground-truth should gradually increase and tend to converge with training epochs. On the contrary, label confusion shows that the dependence between the predicted label and ground-truth is strong first and then weak. This article explains it from the perspective of feature-noise dependence. Specifically, traditional GNN prediction usually assumes that the ground-truth consists of a mutually independent prediction label (dependent on node features) and noise (independent of node features). However, the propagation aggregation mechanism of GNN will integrate irrelevant information from neighboring nodes into the prediction label, resulting in the prediction label no longer being completely dependent on the node feature, or the noise no longer being completely independent of the node feature. Hence, this article proposes a Label-Dependent GNN to alleviate this problem, called LDGNN. LDGNN mainly consists of two limitations, namely feature-noise (the difference between predicted label and ground-truth) independence, and expectation-variance (EV) separation. Specifically, LDGNN introduces the Hilbert-Schmidt independence criterion (HSIC) as a regularization to minimize the dependence between input features and noise. Note that the main reason for adopting HSIC is that it can measure the nonlinear relationship between any two spatial variables. In this way, HSIC can guide GNN to retain more label-dependence information. Then, LDGNN designs an EV separation to centralize nodes within a class and disperse them between classes to further retain label-dependence information. Through these two strategies, the GNN’s expression ability can be enhanced. Next, we theoretically prove the essential reason why LDGNN alleviates label confusion and has been verified in experiments. To verify the performance of LDGNN, we apply it to four classical GNN models on three datasets, and experimental results demonstrate the effectiveness of LDGNN.},
  archive      = {J_TCSS},
  author       = {Yunfei He and Yiwen Zhang and Fei Yang and Dengcheng Yan and Victor S. Sheng},
  doi          = {10.1109/TCSS.2023.3312395},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2990-3003},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Label-dependent graph neural network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertainty-aware label contrastive distribution learning
for automatic depression detection. <em>TCSS</em>, <em>11</em>(2),
2979–2989. (<a href="https://doi.org/10.1109/TCSS.2023.3311013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is one of the most common mental illnesses, affecting people’s quality of life and posing a risk to their health. Low-cost and objective automatic depression detection (ADD) is becoming increasingly critical. However, existing ADD methods usually treat depression detection as a regression problem for predicting patient health questionnaire-8 (PHQ-8) scores, ignoring the scores’ ambiguity caused by multiple questionnaire issues. To effectively leverage the score labels, we propose an uncertainty-aware label contrastive and distribution learning (ULCDL) method to estimate PHQ-8 scores, thus detecting depression automatically. ULCDL first simulates the ambiguity within PHQ-8 scores by converting single-valued scores into discrete label distributions. Afterward, it learns to predict the PHQ-8 score distribution by minimizing the Kullback–Leibler (KL) divergence between the score distribution and the discrete label distribution. Finally, the predicted PHQ-8 score distribution outperforms the PHQ-8 score in ADD. Moreover, label-based contrastive learning (LBCL) is introduced to facilitate the model for learning common features related to depression in multimodal data. A multibranch fusion module is proposed to align and fuse multimodal data for better exploring the uncertainty of PHQ-8 labels. The proposed method is evaluated on the publicly available DAIC-WOZ dataset. Experiment results show that ULCDL outperforms regression-based depression detection methods and achieves state-of-the-art performance. The code will be released after acceptance.},
  archive      = {J_TCSS},
  author       = {Biao Yang and Peng Wang and Miaomiao Cao and Xianlin Zhu and Suhong Wang and Rongrong Ni and Changchun Yang},
  doi          = {10.1109/TCSS.2023.3311013},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2979-2989},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Uncertainty-aware label contrastive distribution learning for automatic depression detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LSHA: A local structure-based community detection attack
heuristic approach. <em>TCSS</em>, <em>11</em>(2), 2966–2978. (<a
href="https://doi.org/10.1109/TCSS.2023.3312394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abuse of community detection algorithms may bring the risk of privacy leakage. To protect personal privacy in complex networks, community detection attack algorithms are proposed, which can hide the true community structure of the whole network from the community detection algorithms by adding and deleting subtle edges. However, most of the existing algorithms perform attack based on a community structure so that a specific community detection method is usually adopted for obtaining the communities, which causes the algorithms to not perform well when the attacked community detection algorithm is unknown. To this end, a local structure-based community detection attack heuristic approach (LSHA) is proposed in this article, where the local structures, including several nodes with dense connections instead of the whole community structures, are considered. Unlike the whole community structures obtained by different community detection algorithms, which are usually different, the nodes in such a local structure are often assigned into the same community so that the attack is more general for different community detection algorithms. Specifically, in LSHA, a local structure selection strategy is proposed to maximize the attack effect, which selects two local structures for rewiring attack. Furthermore, two metrics, i.e., edge vulnerability and node entropy, are also suggested to select the nodes and edges for attack. In the experiments, the proposed LSHA is compared with five state-of-the-art attack algorithms. The experimental results against five representative community detection algorithms on nine real-world networks show that the proposed algorithm LSHA achieves good performance on both the attack effectiveness and the efficiency.},
  archive      = {J_TCSS},
  author       = {Haipeng Yang and Lin Chen and Fan Cheng and Jianfeng Qiu and Lei Zhang},
  doi          = {10.1109/TCSS.2023.3312394},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2966-2978},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {LSHA: A local structure-based community detection attack heuristic approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Node-centric community deception based on safeness.
<em>TCSS</em>, <em>11</em>(2), 2955–2965. (<a
href="https://doi.org/10.1109/TCSS.2023.3306787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has highlighted the importance of maintaining user privacy on online social networks. Specifically, despite their appealing applications, community detection algorithms expose personal relationships that might be misused against social network members. This concern has opened a new research area called community deception, which is about hiding the members of a target community from community detection algorithms. State-of-the-art deception methods only look at how community members must perform edge updates to guarantee some level of hiding. This article introduces node-centric deception, a novel approach considering nodes entering and leaving a target community. We theoretically study the effect of node updates by leveraging node safeness as a deception optimization function. Based on this analysis, we present an effective heuristic capable of hiding the target community with minimal node operations. We evaluated our approach against several community detection algorithms and compared it with state-of-the-art deception algorithms with encouraging results.},
  archive      = {J_TCSS},
  author       = {Saif Aldeen Madi and Giuseppe Pirrò},
  doi          = {10.1109/TCSS.2023.3306787},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2955-2965},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Node-centric community deception based on safeness},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring intercity mobility in urban agglomeration:
Evidence from private car trajectory data. <em>TCSS</em>,
<em>11</em>(2), 2940–2954. (<a
href="https://doi.org/10.1109/TCSS.2023.3315683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we explore intercity mobility in urban agglomerations by surveying people traveling across cities based on private car trajectory data. Specifically, we first adopt the statistical analysis method to mine the intercity mobility in terms of various metrics of travel trips, so as to gain a preliminary understanding of intercity mobility in urban agglomeration. Then, we utilize the tensor decomposition method to conduct in-depth study on the intercity mobility pattern from the perspectives of complexity and multidimensionality. We construct a 4-D tensor based on private car trajectory and point-of-interest (POI) datasets and define the functional similarity and geographic adjacency between regions. Finally, we design an alternating proximal gradient (APG)-based method to resolve the core tensor and factor matrix, leading to the fine-grained discovery of intercity mobility patterns on administrative divisions in the urban agglomeration. Extensive experiments are conducted to evaluate the analysis of intercity mobility, using a real-world dataset containing one-year private car trajectories from five cities in the selected urban agglomeration. The experiments show that the proposed method successfully captures 20 intercity mobility patterns, in which the factor matrices retrieve the patterns from different dimensions with core tensors characterizing correlations between patterns in factor matrices. Besides, the extracted intercity mobility patterns not only cover administrative areas with frequent intercity interactions, but also contain areas with less intercity interactions. It validates that the intercity mobility is consistent with the regional functions in urban agglomeration.},
  archive      = {J_TCSS},
  author       = {Zhu Xiao and Linshan Wu and Hongbo Jiang and Zheng Qin and Chengxi Gao and You Li and Hongyang Chen and Jiangchuan Liu},
  doi          = {10.1109/TCSS.2023.3315683},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2940-2954},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Exploring intercity mobility in urban agglomeration: Evidence from private car trajectory data},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LASGRec: A personalized recommender based on learnable
attribute sampling and graph neural network. <em>TCSS</em>,
<em>11</em>(2), 2930–2939. (<a
href="https://doi.org/10.1109/TCSS.2023.3311433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosion of information, personalized recommender plays a vital role in almost all economic platforms. Usually, the recommender exploits user–item (UI) interactive data to learn users’ latent interests, and then correspondingly conducts recommendations. To address the problem of sparse interactions, graph neural networks (GNNs) have been used to efficiently learn the latent representations of users and items, through structurally modeling the inter-relationships among users, items, and their attributes as graphs. However, most of the existing GNN-based methods ignore the issue of the irrelevant attributes, which means that some attributes of an item are irrelevant to a specific user’s preference. Incorporating them into a recommendation scheme may introduce noise and decrease recommendation accuracy. Thus, to address the issue above, this article proposes a novel personalized recommender based on learnable attribute sampling and heterogeneous graph neural network (LASGRec) to improve the recommender’s performance. The work’s contributions are mainly threefold. First, based on the user’s interactive history with items, the heterogeneous user–item–attribute (UIA) graph is constructed, and attributes of the items are sampled with a learnable neural network to alleviate the issue of irrelevant attributes. Second, using the pruned UIA, the heterogeneous GNN model is appropriately used to learn representations of users and items. Novelly, the learnt user’s embedding first aggregates the sampled attributes of items interactive with the user, and then aggregates these items. The learnt embedding of each item incorporates two relationships: the interacted users and its sampled attributes. Finally, comprehensive experiments on multiple real-world datasets demonstrate the superiority of the proposed LASGRec over the state-of-the-art deep neural network (DNN-) and GNN-based recommendation schemes.},
  archive      = {J_TCSS},
  author       = {Yufeng Wang and Xun Huang and Jianhua Ma and Qun Jin},
  doi          = {10.1109/TCSS.2023.3311433},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2930-2939},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {LASGRec: A personalized recommender based on learnable attribute sampling and graph neural network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Discriminative joint knowledge transfer with online
updating mechanism for EEG-based emotion recognition. <em>TCSS</em>,
<em>11</em>(2), 2918–2929. (<a
href="https://doi.org/10.1109/TCSS.2023.3314508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation (DA) has aroused a wide concern in electroencephalogram (EEG)-based cross-subject emotion recognition tasks. However, many existing DA algorithms focus more on transferability rather than discriminability. In addition, these algorithms typically rely on iterative optimization with pseudo-labels to attain the optimal model. In this study, a novel method with an online updating mechanism named discriminative joint knowledge transfer (DJKT) is proposed. A precise calculation of discriminative information for different emotional states within and across subjects is achieved by leveraging a small number of labeled target-domain samples. Furthermore, to accommodate the time-varying EEG, we extend the passive-aggressive (PA) algorithm to enable online adaptation of the emotion recognition model, thereby enhancing its suitability for real-world scenarios. Extensive experiments conducted on the SJTU emotion EEG dataset (SEED) and SEED-IV demonstrate the effectiveness of our approach. First, comprehensive incorporation of the discriminative information improves the performance of transfer learning significantly. In comparison with several state-of-the-art methods, DJKT exhibits significantly improved emotion recognition performance in both single-source to single-target (STS) and multisource to single-target (MTS) scenarios. Second, the online adjustment strategy effectively addresses the time-varying characteristics of EEG signals, leading to a more robust and stable model.},
  archive      = {J_TCSS},
  author       = {Xiaowei Zhang and Zhongyi Zhou and Qiqi Zhao and Kechen Hou and Xiangyu Wei and Sipo Zhang and Yikun Yang and Yanmeng Cui},
  doi          = {10.1109/TCSS.2023.3314508},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2918-2929},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Discriminative joint knowledge transfer with online updating mechanism for EEG-based emotion recognition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Motor vehicle insurance anti-fraud dynamic system based on
tripartite evolutionary game. <em>TCSS</em>, <em>11</em>(2), 2901–2917.
(<a href="https://doi.org/10.1109/TCSS.2023.3313626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insurance fraud not only increases the burden on policyholders but may even affect the normal operation of insurance companies. Based on the assumption of bounded rationality, this article establishes the tripartite evolutionary game matrix for policyholders, insurance companies, and government departments. In this article, Gaussian white noise is introduced to simulate the random interference encountered by each subject in the evolutionary game, and the evolutionary stability strategy of the tripartite stochastic evolutionary game under different conditions is discussed. Considering the importance of fraud recognition rate, the recognition accuracy rate is introduced into the stochastic evolutionary game, and the necessity of introducing fraud recognition rate into the game is proved by simulation. In the context of society, we have joined the government supervision department into the game and realized the supervision mode of social co-governance by using the social public opinion to reward and punish the government reputation.},
  archive      = {J_TCSS},
  author       = {Meixuan Li and Wei Liu and Chun Yan and Mengchao Zhang},
  doi          = {10.1109/TCSS.2023.3313626},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2901-2917},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Motor vehicle insurance anti-fraud dynamic system based on tripartite evolutionary game},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MIFI: Combining multi-interest activation and implicit
feature interaction for CTR predictions. <em>TCSS</em>, <em>11</em>(2),
2889–2900. (<a href="https://doi.org/10.1109/TCSS.2023.3313622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common paradigm is followed by several current click-through rate (CTR) prediction models based on user behavior sequences. They first apply embedding technology to map users’ past behavior to low-dimensional dense vectors and then utilize an attention technique to acquire user interest representation from behavior sequences, using current candidates as queries. However, these approaches overemphasize the role of items similar to the candidate items in the historical sequence and ignore the learning of other contextual features as well as the sequential behavior patterns of users. In this article, we present a deep click-through prediction model that incorporates a multigranularity interest activation and implicit feature interactions. Our model first incorporates the nonlinearly extended user representation in the user behavior sequence and uses multiple fully connected layers to obtain the global user interest representation, thereby improving the model’s memorization ability for users. Then, a multikernel convolutional network is employed to learn the behavior patterns of the user with different window sizes to solve the problem of pattern diversity and interest mutation noise in behavioral sequences. Finally, the model implements implicit second-order feature interactions across the user-side, item-side, and contextual features via a multihead self-attention network, which can maintain the model’s performance in the presence of scarce user behavior sequences. Compared with the benchmark model, deep interest network (DIN), our model achieved RelaImpr gains of 1.67%, 3.36%, and 3.04% on three publicly available datasets and 6.09%, 6.08%, and 10.22% with the elimination of user history behavior sequence information. Experiments and discussions on module ablation and parameters that have a significant impact on model performance are also presented.},
  archive      = {J_TCSS},
  author       = {Jungang Lou and Rongzhen Qin and Qing Shen and Chengjun Sha},
  doi          = {10.1109/TCSS.2023.3313622},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2889-2900},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {MIFI: Combining multi-interest activation and implicit feature interaction for CTR predictions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multimodal framework for depression detection during
COVID-19 via harvesting social media. <em>TCSS</em>, <em>11</em>(2),
2872–2888. (<a href="https://doi.org/10.1109/TCSS.2023.3309229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent coronavirus disease (COVID-19) has become a pandemic and has affected the entire globe. During the pandemic, we have observed a spike in cases related to mental health, such as anxiety, stress, and depression. Depression significantly influences most diseases worldwide, making it difficult to detect mental health conditions in people due to unawareness and unwillingness to consult a doctor. However, nowadays, people extensively use online social media platforms to express their emotions and thoughts. Hence, social media platforms are now becoming a large data source that can be utilized for detecting depression and mental illness. However, the existing approaches often overlook data sparsity in tweets and the multimodal aspects of social media. In this article, we propose a novel multimodal framework that combines textual, user-specific, and image analysis to detect depression among social media users. To provide enough context about the user’s emotional state, we propose the following: 1) an extrinsic feature by harnessing the URLs present in tweets and 2) extracting textual content present in images posted in tweets. We also extract five sets of features belonging to different modalities to describe a user. In addition, we introduce a deep learning model, the visual neural network (VNN), to generate embeddings of user-posted images, which are used to create the visual feature vector for prediction. We contribute a curated COVID-19 dataset of depressed and nondepressed users for research purposes and demonstrate the effectiveness of our model in detecting depression during the COVID-19 outbreak. Our model outperforms the existing state-of-the-art methods over a benchmark dataset by 2%–8% and produces promising results on the COVID-19 dataset. Our analysis highlights the impact of each modality and provides valuable insights into users’ mental and emotional states.},
  archive      = {J_TCSS},
  author       = {Ashutosh Anshul and Gumpili Sai Pranav and Mohammad Zia Ur Rehman and Nagendra Kumar},
  doi          = {10.1109/TCSS.2023.3309229},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2872-2888},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A multimodal framework for depression detection during COVID-19 via harvesting social media},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fréchet-statistics-based change point detection in dynamic
social networks. <em>TCSS</em>, <em>11</em>(2), 2863–2871. (<a
href="https://doi.org/10.1109/TCSS.2023.3297233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a method to detect change points in dynamic social networks using Fréchet statistics. We address two main questions: 1) what metric can quantify the distances between graph Laplacians in a dynamic network and enable efficient computation, and 2) how can the Fréchet statistics be extended to detect multiple change points while maintaining the significance level of the hypothesis test? Our solution defines a metric space for graph Laplacians using the log-Euclidean metric, enabling a closed-form formula for Fréchet mean and variance. We present a framework for change point detection using Fréchet statistics and extend it to multiple change points with binary segmentation. The proposed algorithm uses incremental computation for Fréchet mean and variance to improve efficiency and is validated on simulated and four real-world datasets, namely, the UCI message dataset, the SFHH interaction dataset, the stack overflow Q&amp;A dataset, and the Enron email dataset.},
  archive      = {J_TCSS},
  author       = {Rui Luo and Vikram Krishnamurthy},
  doi          = {10.1109/TCSS.2023.3297233},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2863-2871},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Fréchet-statistics-based change point detection in dynamic social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From cadCAD to casCAD2: A mechanism validation and
verification system for decentralized autonomous organizations based on
parallel intelligence. <em>TCSS</em>, <em>11</em>(2), 2853–2862. (<a
href="https://doi.org/10.1109/TCSS.2023.3287246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The governance technology of decentralized autonomous organizations (DAOs) provides an effective solution for solving existing organizational management issues. Governance mechanisms of DAOs are usually encoded in smart contracts in the form of rule sets and executed automatically. However, the mechanism’s logical flaws and code errors expose DAOs to unpredictable risks. Complex adaptive dynamics computer-aided design (CadCAD) can test the effectiveness of the mechanisms through simulation. Nonetheless, as DAOs are typical complex systems with social and engineering complexity, managing, controlling, and supervising their operation through traditional methods are difficult. The parallel intelligence theory based on artificial societies, computational experiments, and parallel execution (ACP) method provides an effective research framework and practical method for solving DAOs’ governance issues. Therefore, in this article, we propose a parallel mechanism verification method and execution system, namely, complex adaptive systems for computer-aided dynamic design (casCAD2) as an extension of cadCAD. Leveraging parallel intelligence and cyber–physical–social systems (CPSS), casCAD2 is capable of probing into the laws that govern system evolution within a simulated environment. It serves as a robust tool for verifying the efficacy of DAOs’ mechanisms and predicting their potential risks. We also build a parallel market-based anchoring mechanism (MAM) system to demonstrate how it can be used for DAOs’ mechanism verification. This study can provide a new research method and application system for DAOs’ effective governance.},
  archive      = {J_TCSS},
  author       = {Xiaolong Liang and Wenwen Ding and Rui Qin and Jiachen Hou and Yong Yuan and Xiao Wang and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3287246},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2853-2862},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {From cadCAD to casCAD2: A mechanism validation and verification system for decentralized autonomous organizations based on parallel intelligence},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FOOR: Be careful for outlier-score outliers when using
unsupervised outlier ensembles. <em>TCSS</em>, <em>11</em>(2),
2843–2852. (<a href="https://doi.org/10.1109/TCSS.2023.3280593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is a very important tool in analyzing patterns and detecting unexpected events in social systems. However, the process of outlier detection could be fraught with uncertainty, with difficulties in determining the veracity of an object’s outlier score. We propose a framework for outlier-score outlier removal (FOOR). FOOR is a selection method, which aims to remove inaccurate outlier scores prior to data processing by ensemble techniques, to improve the accuracy of all ensembles. FOOR has rigorously tested with 30 real-world datasets and seven state-of-the-art ensembles over 25 different base detectors. Simulated experiments showed that FOOR significantly improves the existing techniques, with an average (AVG) of +0.05 AUC (from 0.81 to 0.86 AUC). Thus, we recommend FOOR as the new standard for outlier-score preprocessing before ensembles.},
  archive      = {J_TCSS},
  author       = {Jiawei Yang and Sylwan Rahardja and Susanto Rahardja},
  doi          = {10.1109/TCSS.2023.3280593},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2843-2852},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {FOOR: Be careful for outlier-score outliers when using unsupervised outlier ensembles},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling inter-aspect relations with clause and contrastive
learning for aspect-based sentiment analysis. <em>TCSS</em>,
<em>11</em>(2), 2833–2842. (<a
href="https://doi.org/10.1109/TCSS.2023.3302331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis task that aims to identify the sentiment polarity of the given aspect. Recent studies fail to establish the relation among multiple aspects in one sentence. To address this issue, a clause-level relational graph attention network with contrastive learning (CLRCL) model is proposed. Specifically, the given sentence is segmented into clauses to obtain the relation between two aspects based on clause-level interaction. Then, to integrate multiple-aspect information, a clause-level relational graph which contains all aspects and inter-aspect relations is developed. Notably, to precisely learn the inter-aspect relations, the supervised contrastive learning strategy is used. Experimental results reveal that the proposed model is a competitive alternative compared with the state-of-the-art methods.},
  archive      = {J_TCSS},
  author       = {Zhixun Qiu and Kehai Chen and Yun Xue and Zhihao Ma and Zhengxuan Zhang},
  doi          = {10.1109/TCSS.2023.3302331},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2833-2842},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Modeling inter-aspect relations with clause and contrastive learning for aspect-based sentiment analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Topic to image: A rumor detection method inspired by image
forgery recognition technology. <em>TCSS</em>, <em>11</em>(2),
2819–2832. (<a href="https://doi.org/10.1109/TCSS.2023.3302307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is inspired by image forgery recognition techniques. If we regard topic comments as image pixels, the whole topic is a complete image. The image differences between rumor topics and nonrumor topics are reflected in image pixels just like forged images, and then, the problem of detecting rumor topics can be regarded as the problem of recognition images of rumor topics. First, the Topic2Image algorithm is proposed to use the semantic information to quantify the adversarial intensity among comments. It is mapped to the topological relationship among user comments. Also, the relative positions of the comment nodes are determined by the adversarial intensity. Second, considering the competitive relationship between positive and negative comments, a sentimental mutual influence model is proposed. Based on the evolutionary game theory, a transfer matrix of sentimental mutual influence is constructed. Internal and external factors of rumor detection are considered at the individual and group levels, respectively. Finally, considering the advantages of convolutional neural network (CNN) for image processing, a simple rumor detection algorithm topic image rumor detection (TIRD) based on topic image classification is proposed. Using CNNs and gray-level co-occurrence matrix to extract global and local features of topic images and combining them with the transfer matrix of sentimental mutual influence, the detection of topic rumor is realized. Experiments demonstrate the feasibility of transforming topic rumors into image. In addition, the effectiveness of image forgery recognition technology for detecting rumors is verified.},
  archive      = {J_TCSS},
  author       = {Yucai Pang and Xuehong Li and Shihong Wei and Qian Li and Yunpeng Xiao},
  doi          = {10.1109/TCSS.2023.3302307},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2819-2832},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Topic to image: A rumor detection method inspired by image forgery recognition technology},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VIEA: A visualization system for industrial economics
analysis based on trade data. <em>TCSS</em>, <em>11</em>(2), 2807–2818.
(<a href="https://doi.org/10.1109/TCSS.2023.3288671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the acceleration of economic globalization, a large amount of research studies have been conducted for the exploration of industrial economics. In the visualization community, common visualization tools present potential features of industrial economics. They hardly meet the various and complex user requirements for insightful analysis and decision-making. In this article, we design VIEA, a web-based visualization system that integrates a rich set of views and tailored interactions, enabling users to easily perceive economic features, such as geographical distributions, trade relationships, and pattern comparisons. Case studies and user studies based on real-world datasets have been conducted to demonstrate the effectiveness of our system in the exploration of industrial economics.},
  archive      = {J_TCSS},
  author       = {Ziliang Wu and Shi Liu and Yuefan Zhou and Tong Xu and Jiacheng Pan and Zhiguang Zhou and Wei Chen and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3288671},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2807-2818},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {VIEA: A visualization system for industrial economics analysis based on trade data},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting higher order links in social interaction
networks. <em>TCSS</em>, <em>11</em>(2), 2796–2806. (<a
href="https://doi.org/10.1109/TCSS.2023.3293075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is a significant research problem in network science and has widespread applications. To date, much efforts have focused on predicting the links generated by pairwise interactions, but little is known about the predictability of links created by higher order interaction patterns. In this study, we investigated a new framework for predicting the links of different orders in social interaction networks based on edge orbit degrees (EODs) characterized by three-node and four-node graphlets. First, we defined a new problem of different-order link prediction to examine the predictability of links generated by different-order interaction patterns. Second, we quantified EODs for different-order link prediction and examined the performance of different-order predictors. The experiments on real-world networks show that higher order links are more accessible to be predicted than lower order (two-order) links. We also found that the closed three-node EOD has strong predictive power, which can accurately predict for both lower order and higher order links. Finally, we proposed a new method fusing multiple EODs (MEOD) to predict different-order links, and experiments indicate that the MEOD outperforms state-of-the-art methods. Our findings can not only effectively improve the link prediction performance of different orders, but also contribute to a better understanding of the organizational principle of higher order structures.},
  archive      = {J_TCSS},
  author       = {Yong-Jian He and Xiao-Ke Xu and Jing Xiao},
  doi          = {10.1109/TCSS.2023.3293075},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2796-2806},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Predicting higher order links in social interaction networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LiFoL: An efficient framework for financial distress
prediction in high-dimensional unbalanced scenario. <em>TCSS</em>,
<em>11</em>(2), 2784–2795. (<a
href="https://doi.org/10.1109/TCSS.2023.3276059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corporate financial distress will significantly damage the company’s and its stakeholders’ interests and even lead to a global financial crisis. Therefore, finding an efficient method for financial distress prediction (FDP) to avoid greater losses is essential. Although there is a lot of research and progress in this field, the existing methods rarely consider the problems of high dimensionality and class imbalance, which will largely limit the models to achieve satisfactory performance. To alleviate these problems, this article first proposes a novel Lightspace-SMOTE upsampling method, which can reduce the feature dimensionality and increase the signal-to-noise ratio (SNR) of the original data and then upsample it to increase the number of minor class samples. In addition, this article proposes an efficient ensemble framework (LiFoL) that combines Lightspace-SMOTE, focal loss (FL), and LightGBM, which can not only focus more on minor class and the hard-to-class samples but also obtain better performance. At the same time, the feature importance provided by the model can provide strong support for model interpretability. Experimental results show that the Lightspace-SMOTE upsampling method can help the model achieve higher scores in area under ROC curve (AUC) and recall, especially in the case of longer prediction periods. Compared with current methods, LiFoL can achieve more than 10% improvement in AUC and more than 20% in recall.},
  archive      = {J_TCSS},
  author       = {Ying Chen and Xiaojun Kuang and Jifeng Guo},
  doi          = {10.1109/TCSS.2023.3276059},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2784-2795},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {LiFoL: An efficient framework for financial distress prediction in high-dimensional unbalanced scenario},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ICON: Instagram profile classification using image and
natural language processing methods. <em>TCSS</em>, <em>11</em>(2),
2776–2783. (<a href="https://doi.org/10.1109/TCSS.2023.3275428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of social media has grown significantly, and businesses are now using these platforms to promote their products and services. To do this, companies have created business accounts on social networks. However, social media platforms can also be a breeding ground for unwanted behaviors such as cyberbullying, sexual content, and promotional comments. To address this issue, a study was conducted to create a system that could classify public accounts on Instagram by analyzing comments, profile pictures, bios, and posts shared by users with business accounts. First, a crawler was developed, and data were collected using this crawler and then anonymized. Next, the collected data were processed using natural language processing (NLP) techniques for text and image processing methods for images to extract features and create a dataset. Nearly 10 000 profiles and 30 000 comments from public accounts were manually tagged to create the classification model. The final model had an accuracy rate of 95% on the dataset, allowing for the effective identification of different types of business accounts on Instagram.},
  archive      = {J_TCSS},
  author       = {Ebu Yusuf Güven and Ali Boyacı and Fatma Nur Sarıtemur and Zehra Türk and Gizem Sütçü and Özgür Can Turna},
  doi          = {10.1109/TCSS.2023.3275428},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2776-2783},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {ICON: Instagram profile classification using image and natural language processing methods},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parallel learning for legal intelligence: A HANOI approach
based on unified prompting. <em>TCSS</em>, <em>11</em>(2), 2765–2775.
(<a href="https://doi.org/10.1109/TCSS.2023.3301400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pretrained language models (PLMs) have made significant progress on various NLP tasks recently. However, PLMs encounter challenges when it comes to domain-specific tasks such as legal AI. These tasks often involve intricate expertise, expensive data annotation, and limited training data availability. To tackle this problem, we propose a human-oriented artificial–natural parallel system for organized intelligence (HANOI)-Legal based on the parallel learning (PL) framework. First, by regarding the description in PL as the pretraining process based on a large-scale corpus, we setup an artificial system based on a PLM. Second, to adapt the PLM to legal tasks with limited resources, we propose UniPrompt as a prescription. UniPrompt serves as a unified prompt-based training framework, enabling the utilization of diverse open datasets for these tasks. Third, we labeled a few task-specific legal data through distributed autonomous operations (DAO-II) for further fine-tuning. By combining a scalable unified-task-format reformulation and a unified-prompt-based training pipeline, HANOI-Legal leverages PLMs’ linguistic capabilities acquired from a variety of open datasets to generate task-specific models. Our experiments in two legal domain tasks show that HANOI-Legal achieved an excellent performance in low-resource scenarios compared to the state-of-the-art prompt-based approach.},
  archive      = {J_TCSS},
  author       = {Zhuoyang Song and Min Huang and Qinghai Miao and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3301400},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2765-2775},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Parallel learning for legal intelligence: A HANOI approach based on unified prompting},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic recommendation based on graph diffusion and
ebbinghaus curve. <em>TCSS</em>, <em>11</em>(2), 2755–2764. (<a
href="https://doi.org/10.1109/TCSS.2023.3267611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, many dynamic recommendations still suffer from the insufficiency of finding user online interest evolving patterns because of those complicated interactions. In general, each interaction is usually impacted by multiple underlying reasons, which needs us to open the “box” of each interaction instance instead of simply treating them as a pair-wise link. Besides, different users usually perform differently for their long-term and short-term tastes, leaving traditional sequential models far from personalized. In this article, we propose a novel recommendation model based on Graph Diffusion and Ebbinghaus Curve. Specifically, to explore the underline reasons for different interactions, we explore an underlying sub-graph for each interaction and find important reasoning paths within the sub-graph via a well-designed graph diffusion method. To capture users’ personalized strategies on long-term and short-term tastes, we are inspired by the Ebbinghaus Curve, which can naturally describe users’ memory patterns, and design an effective neural network to process users’ evolving behaviors. We conduct extensive experiments on four real-world datasets and the results further confirm the superiority of our model compared with existing state-of-the-art baselines.},
  archive      = {J_TCSS},
  author       = {Zhihong Cui and Xiangguo Sun and Hongxu Chen and Li Pan and Lizhen Cui and Shijun Liu and Guandong Xu},
  doi          = {10.1109/TCSS.2023.3267611},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2755-2764},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Dynamic recommendation based on graph diffusion and ebbinghaus curve},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of COVID-19 data usage in correctional institutions
from developing countries. <em>TCSS</em>, <em>11</em>(2), 2740–2754. (<a
href="https://doi.org/10.1109/TCSS.2023.3280912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is highly transmissible and pathogenic, representing a potential threat to health conditions in correctional environments worldwide. This threat could worsen in prison systems in developing countries due to high crowding levels, lack of individual hygiene materials, inadequate primary sanitary conditions, and difficulties in using health services. Attempts to provide a landscape of academic research findings on COVID-19 data usage from prison systems in developing countries have been limited. This scenario motivated us to carry out this systematic mapping study (SMS) to provide a comprehensive overview of the impacts that may prevent the effective use of COVID-19 data, critical issues, and gaps in the current academic research. Following the steps of a systematic mapping, we examined 79 studies returned from a search string and eight studies returned from the use of the snowballing technique and selected 37 from related journals and conferences published between 2020 and 2021. The results point to possible problems in the use of COVID-19, preventing its effective use in information systems.},
  archive      = {J_TCSS},
  author       = {Lucas dos Santos Nunes and Edward David Moreno and Glauco de Figueiredo Carneiro},
  doi          = {10.1109/TCSS.2023.3280912},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2740-2754},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A review of COVID-19 data usage in correctional institutions from developing countries},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OntoDSumm: Ontology-based tweet summarization for disaster
events. <em>TCSS</em>, <em>11</em>(2), 2724–2739. (<a
href="https://doi.org/10.1109/TCSS.2023.3266025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The huge popularity of social media platforms, such as Twitter, attracts a large fraction of users to share real-time information and short situational messages during disasters. A summary of these tweets is required by the government organizations, agencies, and volunteers for efficient and quick disaster response. However, the huge influx of tweets makes it difficult to manually get a precise overview of ongoing events. To handle this challenge, several tweet summarization approaches have been proposed. In most of the existing literature, tweet summarization is broken into a two-step process where, in the first step, it categorizes tweets, and in the second step, it chooses representative tweets from each category. There are both supervised and unsupervised approaches found in the literature to solve the problem of first step. Supervised approaches require a huge amount of labeled data, which incurs cost as well as time. On the other hand, unsupervised approaches could not cluster tweet properly due to the overlapping keywords, vocabulary size, lack of understanding of semantic meaning, and so on, while, for the second step of summarization, existing approaches applied different ranking methods where those ranking methods are very generic, which fail to compute proper importance of a tweet with respect to a disaster. Both problems can be handled far better with proper domain knowledge. In this article, we exploited already existing domain knowledge by the means of ontology in both steps and proposed a novel disaster summarization method OntoDSumm. We evaluate this proposed method with six state-of-the-art methods using 12 disaster datasets. Evaluation results reveal that OntoDSumm outperforms the existing methods by approximately 2%–66% in terms of ROUGE-1 F1-score.},
  archive      = {J_TCSS},
  author       = {Piyush Kumar Garg and Roshni Chakraborty and Sourav Kumar Dandapat},
  doi          = {10.1109/TCSS.2023.3266025},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2724-2739},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {OntoDSumm: Ontology-based tweet summarization for disaster events},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Compressing the multiobject tracking model via knowledge
distillation. <em>TCSS</em>, <em>11</em>(2), 2713–2723. (<a
href="https://doi.org/10.1109/TCSS.2023.3293882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent multiobject tracking (MOT) methods usually use very deep neural networks to achieve competitive accuracy, which inevitably results in degraded inference speed. To strike a better balance between tracking accuracy and speed, in this work, we propose to compress the MOT model via knowledge distillation (KD), enabling the more lightweight student model to obtain similar performance as the teacher model. Nonetheless, despite KD has been well studied for simpler tasks such as image classification, the complexity of MOT poses new challenges because the MOT model is more sensitive to foreground information than the classification model. To deal with that, we first propose attention-guided feature distillation, which focuses the student model on the crucial region (foreground and the region with strong discrepancy against itself) of the teacher’s feature map. Moreover, we propose foreground mask, which leverages the knowledge from the teacher model to filter out the low-quality soft labels from the background, thereby reducing their negative effects for distillation. Evaluations on several benchmarks demonstrate that the proposed KD method can make the student network achieve leading performance, meanwhile running faster than the teacher network 20.0%–27.4% and reducing the parameters 28.5%–87.1%. To the best of our knowledge, this is the first work to compress the MOT model via KD.},
  archive      = {J_TCSS},
  author       = {Tianyi Liang and Mengzhu Wang and Junyang Chen and Dingyao Chen and Zhigang Luo and Victor C. M. Leung},
  doi          = {10.1109/TCSS.2023.3293882},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2713-2723},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Compressing the multiobject tracking model via knowledge distillation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Why do some homeless succeed while others falter? A network
science perspective. <em>TCSS</em>, <em>11</em>(2), 2703–2712. (<a
href="https://doi.org/10.1109/TCSS.2023.3296376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Homelessness, a long-standing societal problem, appears to be on the rise, fueled in part by the Covid-19 pandemic. Looking at the homelessness system as a network of interconnected services which individuals traverse over time, we seek to shed light on their progression toward securing stable housing. We formalize the concept of stability upon exit and show that regardless of starting conditions, the ultimate goal is either reached quickly or not at all, indicating the importance of addressing the homeless’ needs early on to avoid them “giving up.” To better understand the causes that may contribute to positive outcomes for certain individuals versus others, we computationally analyze their pathways through the network of homeless services. We confirm the intuition that some individuals face more challenges than others based on their initial living conditions and initial placement to homelessness services. At the same time, we discover that simple signals can act as good indicators of individuals at risk of “falling through the cracks.” Being able to predict such outcomes is critical to design assistive technology that can retain individuals who would otherwise falter.},
  archive      = {J_TCSS},
  author       = {Charalampos Chelmis and Khandker Sadia Rahman},
  doi          = {10.1109/TCSS.2023.3296376},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2703-2712},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Why do some homeless succeed while others falter? a network science perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multiview sparse dynamic graph convolution-based
region-attention feature fusion network for major depressive disorder
detection. <em>TCSS</em>, <em>11</em>(2), 2691–2702. (<a
href="https://doi.org/10.1109/TCSS.2023.3291950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting and diagnosing major depressive disorder (MDD) is greatly crucial for appropriate treatment and support. In recent years, there have been efforts to develop automated methods for depression detection using machine learning techniques, which mainly analyze various data sources such as text, speech, and social media posts. However, the effectiveness and reliability of these methods may vary and more importantly, they fail to provide timely intervention and treatment to MDD patients. To address these challenges, we propose a novel electroencephalogram (EEG)-based MDD detection framework, which is named as multiview sparse dynamic graph convolution-based region-attention feature fusion network (MV-SDGC-RAFFNet). Specifically, we first design a multiview (MV) feature extractor to concurrently characterize EEG signals from temporal, spectral, and time-frequency views, providing rich semantic information on the emotional status of patients. Secondly, we introduce a sparse dynamic graph convolution network (SDGCN) to map the multidomain features into high-level representations, which avoids the limitation of over-smoothing and redundant edges existing in the conventional graph neural networks (GNNs). Finally, to efficiently fuse multidomain features, we propose a region-attention feature fusion network (RAFFNet), which applies different attention weights for brain regions and is greatly beneficial to boost the accuracy (ACC) of MDD detection. We validate the efficacy of the proposed MV-SDGC-RAFFNet framework on two public MDD datasets, and it achieves more promising detection performance against the state-of-the-art methods, indicating that our method has a prospect on clinical MDD detection.},
  archive      = {J_TCSS},
  author       = {Weigang Cui and Mingyi Sun and Qunxi Dong and Yuzhu Guo and Xiao-Feng Liao and Yang Li},
  doi          = {10.1109/TCSS.2023.3291950},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2691-2702},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A multiview sparse dynamic graph convolution-based region-attention feature fusion network for major depressive disorder detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cost-sensitive GNN-based imbalanced learning for mobile
social network fraud detection. <em>TCSS</em>, <em>11</em>(2),
2675–2690. (<a href="https://doi.org/10.1109/TCSS.2023.3302651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the increasing prevalence of mobile social network fraud has led to significant distress and depletion of personal and social wealth, resulting in considerable economic harm. Graph neural networks (GNNs) have emerged as a popular approach to tackle this issue. However, the challenge of graph imbalance, which can greatly impede the effectiveness of GNN-based fraud detection methods, has received little attention in prior research. Thus, we are going to present a novel cost-sensitive graph neural network (CSGNN) in this article. Initially, reinforcement learning is utilized to train a suitable sampling threshold, followed by neighbor sampling based on node similarity, which helps to alleviate the graph imbalance issue preliminarily. Subsequently, message aggregation is executed on the sampled graph using GNN to obtain node embeddings. Concurrently, the optimization objective for the cost matrix is formulated using the sample histogram matrix, scatter matrix, and confusion matrix. The cost matrix and GNN are collaboratively optimized through the backpropagation algorithm. Ultimately, the derived cost-sensitive node embedding is employed for fraudulent node detection. Furthermore, this study provides a theoretical demonstration of the effectiveness of adaptive cost-sensitive learning in GNN. Extensive experiments are carried out on two publicly accessible real-world mobile network fraud datasets, revealing that the proposed CSGNN effectively addresses the graph imbalance issue while outperforming state-of-the-art algorithms in detection performance. The CSGNN code and datasets can be accessed at https://github.com/xxhu94/CSGNN .},
  archive      = {J_TCSS},
  author       = {Xinxin Hu and Haotian Chen and Hongchang Chen and Shuxin Liu and Xing Li and Shibo Zhang and Yahui Wang and Xiangyang Xue},
  doi          = {10.1109/TCSS.2023.3302651},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2675-2690},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Cost-sensitive GNN-based imbalanced learning for mobile social network fraud detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficiency evaluation of insurance companies from
multiperiod perspective. <em>TCSS</em>, <em>11</em>(2), 2656–2674. (<a
href="https://doi.org/10.1109/TCSS.2023.3304906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The insurance industry plays a crucial role of the national financial system, and the operating efficiency of insurance companies has always been a significant subject of academic research. This study proposes a multiperiod DEA model to dynamically evaluate the operating efficiency of insurance companies, which not only overcomes the defect of the traditional DEA method ignoring the internal structure of decision-making units, but also extends the limitation of the leader–follower model in evaluating single-period efficiency. By analyzing the efficiency of seven listed insurance companies in China from 2009 to 2018, the following conclusions are drawn. The multiperiod DEA model demonstrates advantages over the leader–follower model. The profitability of insurance companies during the first five years is higher compared with the last five years. There is a significant correlation between premium financing efficiency and overall efficiency. Throughout both periods, the loss ratio, loss reserve ratio, and consumer price index (CPI) are always positively correlated with the efficiency of the insurer, while the gearing ratio is negatively related to the efficiency of the insurer. The correlation among gross domestic product (GDP), total insurance value, tradable financial assets, and corporate efficiency varies over time.},
  archive      = {J_TCSS},
  author       = {Qiwei Xie and Mengfan Zhao and Rong Li and Wen Li and Xiaolong Zheng and Yongjun Li and Rui Qin and Xiaojiong Wang and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3304906},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2656-2674},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Efficiency evaluation of insurance companies from multiperiod perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A greedy monitoring station selection for rumor source
detection in online social networks. <em>TCSS</em>, <em>11</em>(2),
2644–2655. (<a href="https://doi.org/10.1109/TCSS.2023.3284909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In monitoring station observation, for the best accuracy of rumor source detection, it is important to deploy monitors appropriately into the network. There are, however, a very limited number of studies on the monitoring station selection. This article will study the problem of detecting a single rumormonger based on an observation of selected infection monitoring stations in a complete snapshot taken at some time in an online social network (OSN) following the independent cascade (IC) model. To deploy monitoring stations into the observed network, we propose an influence-distance-based $k$ -station selection method where the influence distance is a conceptual measurement that estimates the probability that a rumor-infected node can influence its uninfected neighbors. Accordingly, a greedy algorithm is developed to find the best $k$ monitoring stations among all rumor-infected nodes with a 2-approximation. Based on the infection path, which is most likely toward the $k$ infection monitoring stations, we derive that an estimator for the “most like” rumor source under the IC model is the Jordan infection center in a graph. Our theoretical analysis is presented in the article. The effectiveness of our method is verified through experiments over both synthetic and real-world datasets. As shown in the results, our $k$ -station selection method outperforms off-the-shelf methods in most cases in the network under the IC model.},
  archive      = {J_TCSS},
  author       = {Rong Jin and Priyanshi Garg and Weili Wu and Qiufen Ni and Rosanna E. Guadagno},
  doi          = {10.1109/TCSS.2023.3284909},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2644-2655},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A greedy monitoring station selection for rumor source detection in online social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal contrastive transformer for explainable
recommendation. <em>TCSS</em>, <em>11</em>(2), 2632–2643. (<a
href="https://doi.org/10.1109/TCSS.2023.3276273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explanations play an essential role in helping users evaluate results from recommender systems. Various natural language generation methods have been proposed to generate explanations for the recommendation. However, they usually suffer from two problems. First, since user-provided review text contains noisy data, the generated explanations may be irrelevant to the recommended items. Second, as lacking some supervision signals, most of the generated sentences are similar, which cannot meet the diversity and personalized needs of users. To tackle these problems, we propose a multimodal contrastive transformer (MMCT) model for an explainable recommendation, which incorporates multimodal information into the learning process, including sentiment features, item features, item images, and refined user reviews. Meanwhile, we propose a dynamic fusion mechanism during the decoding stage, which generates supervision signals to guide the explanation generation. Additionally, we develop a contrastive objective to generate diverse explainable texts. Comprehensive experiments on two real-world datasets show that the proposed model outperforms comparable explainable recommendation baselines in terms of explanation performance and recommendation performance. Efficiency analysis and robustness analysis verify the advantages of the proposed model. While ablation analysis establishes the relative contributions of the respective components and various modalities, the case study shows the working of our model from an intuitive sense.},
  archive      = {J_TCSS},
  author       = {Zhuang Liu and Yunpu Ma and Matthias Schubert and Yuanxin Ouyang and Wenge Rong and Zhang Xiong},
  doi          = {10.1109/TCSS.2023.3276273},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2632-2643},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Multimodal contrastive transformer for explainable recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Method toward network embedding within homogeneous
attributed network using influential node diffusion-aware.
<em>TCSS</em>, <em>11</em>(2), 2620–2631. (<a
href="https://doi.org/10.1109/TCSS.2023.3276159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding (NE) focuses on discovering low-dimensional embeddings of nodes while retaining their intrinsic features and structure of nodes. It is essential for many practical applications, containing text mining, community detection, and node classification. However, the great majority of existing systems are incapable of combining structural and attribute information. To tackle the above-mentioned problem, considering the information diffusion process, we present a novel model for attribute NE (ANE), namely influential node diffusion-based matrix factorization (INDMF), which contains topology level and attribute level. In detail, we first propose a novel method to extract high-order information via influential node diffusion sequences. Then, we regard the optimization of our proposed structure-based and attribute-based loss functions as a matrix factorization problem. Furthermore, this model can be used to generate final node embedding by aggregating the topology level and attribute level hierarchically. Experiments are conducted on four real-world datasets, which indicates that INDMF beats all competing algorithms in node categorization, community detection, and graph visualization.},
  archive      = {J_TCSS},
  author       = {Weinan Niu and Wenan Tan and Wei Jia and Lida Xu},
  doi          = {10.1109/TCSS.2023.3276159},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2620-2631},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Method toward network embedding within homogeneous attributed network using influential node diffusion-aware},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertain commuters assignment through genetic programming
hyper-heuristic. <em>TCSS</em>, <em>11</em>(2), 2606–2619. (<a
href="https://doi.org/10.1109/TCSS.2023.3265727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic assignment problem (TAP) is of great significance for promoting the development of smart city and society. It usually focuses on the deterministic or predictable traffic demand and the vehicle traffic assignment. However, in the real world, traffic demand is usually unpredictable, especially the foot traffic assignment inside buildings such as shopping malls and subway stations. In this work, we consider the dynamic version of TAP, where uncertain commuters keep entering the traffic network constantly. These dynamically arriving commuters bring new challenges to this problem where planning paths for each commuter in advance is incompetent. To address this problem, we propose a genetic programming (GP) hyper-heuristic method to assign uncertain commuters in real-time. Specifically, a low-level heuristic rule called reactive assignment strategy (RAS) is proposed and is evolved by the proposed method. All commuters obey the same strategy to route themselves based on their local observations in a traffic network. Through training based on a designed heuristic template, all commuters will have the ability to find their appropriate paths in real-time to maximize the throughput of the traffic network. This decentralized control mechanism can address dynamically arriving commuters more efficiently than centralized control mechanisms. The experimental results show that our method significantly outperforms the state-of-the-art methods and the evolved RAS has a certain generalization ability.},
  archive      = {J_TCSS},
  author       = {Xiao-Cheng Liao and Ya-Hui Jia and Xiao-Min Hu and Wei-Neng Chen},
  doi          = {10.1109/TCSS.2023.3265727},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2606-2619},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Uncertain commuters assignment through genetic programming hyper-heuristic},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The convergence analysis of evolutionary dynamics for
continuous action iterated dilemma in information loss networks.
<em>TCSS</em>, <em>11</em>(2), 2595–2605. (<a
href="https://doi.org/10.1109/TCSS.2023.3273559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a convergence analysis method for evolution dynamics in information loss networks, which overcomes the analytical difficulties caused by complex network relationships. Evolutionary game theory is a widely-used tool for analyzing player behavior in networks, where players typically adopt binary strategies, either cooperation or defection. However, player behavior in real-world scenarios is often multidimensional and complex, and thus a dynamic model of continuous action iterated dilemma (CAID) with continuous strategy is proposed to enrich the strategies of players, allowing them to choose intermediate states between cooperation and defection, providing a more accurate representation of the evolution of cooperation than traditional dynamic models. Meanwhile, the convergence of traditional models is often analyzed using Jacobian matrices, which requires a significant amount of derivation related to the complex network structure, leading to inefficiencies. As such, a new convergence analysis method based on the Lyapunov function has been designed to circumvent these complex calculations. Additionally, as there is often noise present during the transfer of information between players, we further analyze the convergence of dynamic models in information loss networks using the Lyapunov function. Two examples based on the prisoner’s dilemma and snowdrift dilemma on networks are proposed to show the effectiveness of the designed convergence analysis.},
  archive      = {J_TCSS},
  author       = {Xiaoyue Jin and Zhen Wang and Dengxiu Yu and Xuelong Li},
  doi          = {10.1109/TCSS.2023.3273559},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2595-2605},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {The convergence analysis of evolutionary dynamics for continuous action iterated dilemma in information loss networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A weighted stacking ensemble model with sampling for fake
reviews detection. <em>TCSS</em>, <em>11</em>(2), 2578–2594. (<a
href="https://doi.org/10.1109/TCSS.2023.3268548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customers use reviews as a primary source of information to judge a product or service. Positive reviews help boost companies’ reputations, increasing their revenue by attracting new clients, and increasing the purchasing order size. On the other hand, negative reviews significantly reduce sales, which might be the case due to competitive advantage. Organizations can use fake (i.e., misleading or fraudulent) reviews to generate fast profits by deceiving customers into buying their products. Recently, various methods to assess the legitimacy of reviews have been introduced using advances in machine learning. However, existing methods fall short of achieving highly accurate detection results for unbalanced classes. We aimed to create a spam review identification model using ensemble-based learning while balancing classes using sampling techniques. This article proposes a weighted stacking ensemble model with sampling (WSEM-S) for efficient fake reviews detection. We used $n$ -gram models to effectively model language data for feature retrieval. The experimental results on three customer reviews datasets: YELPNYC, Deceptive Opinion Spam Corpus (DOSC) v1.4, and Deception datasets show that the proposed model outperforms the conventional machine learning techniques [Naïve Bayes, logistic regression, K-nearest neighbor (KNN), random forest, extreme gradient boosting (XGBoost), and convolutional neural network (CNN)] as well as the state-of-the-art ensemble models.},
  archive      = {J_TCSS},
  author       = {Rahul Singhal and Rasha Kashef},
  doi          = {10.1109/TCSS.2023.3268548},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2578-2594},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A weighted stacking ensemble model with sampling for fake reviews detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Age effects on spatiotemporal patterns in functional brain
networks over the human adult lifespan. <em>TCSS</em>, <em>11</em>(2),
2570–2577. (<a href="https://doi.org/10.1109/TCSS.2023.3289995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Growing evidence has unveiled the dynamic nature of human brain networks. However, the dynamic and hierarchical organization that supports information transmission in brain networks remains unexplored across the adult lifespan. In this study, we developed an analytical framework to investigate the spatiotemporal reorganization of dynamic brain networks during adult development and aging. Specifically, using resting-state fMRI data from the Cam-CAN lifespan dataset, we examined the age effects on the topological stability of egocentric structures and the average length of temporal paths. As the egocentric structure reflects the relationships between a node’s neighbors, we further explored whether the stability of egocentric structures mediates age effects on information diffusion. The results showed that the topological stability of egocentric structures has an impact on information processing in the spatiotemporal domain. In particular, the age-related changes observed in some functional systems followed different progressive patterns from that of other systems, which might be explained by some compensation mechanisms. Taken together, the present work may provide an additional perspective for understanding the underlying neuro-mechanisms of healthy aging.},
  archive      = {J_TCSS},
  author       = {Ziyang Zhao and Lirong Teng and Tongtong Li and Yin Wang and Lingyu Zhang and Xia Liu and Rui Xie and Jing Yang and Zhijun Yao},
  doi          = {10.1109/TCSS.2023.3289995},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2570-2577},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Age effects on spatiotemporal patterns in functional brain networks over the human adult lifespan},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep recommendation model considering the impact of time
and individual diversity. <em>TCSS</em>, <em>11</em>(2), 2558–2569. (<a
href="https://doi.org/10.1109/TCSS.2023.3272633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering (CF) technology has been widely used in recommendation systems. Usually, the latent factor model (LFM) is used as the basis for implementing CF recommendation in deep learning systems. This study differs from previous studies in two respects. First, for different target items, the user embedding vector should be dynamically adjusted according to the content of the target item. Therefore, we have added an attention mechanism to dynamically adjust the user’s embedding vector. However, people’s preferences usually change over time. Therefore, based on the above attention model, this study considers two time-decay functions to emphasize the user’s recent preferences. The first decay function considers the situation where the recent rating is more important than the long ago rating. The second time-decay function considers the situation, whereby users generally prefer movies that have been released recently rather than movies that have been released a long time ago. By combining these two time-decay functions with the attention model, we propose a time-decay adaptive latent factor model (TDADLFM) model for item score prediction. This study applies this model to a dataset integrating Movielens-10M and HetRec2011 and proves that all three new considerations can improve recommendation performance.},
  archive      = {J_TCSS},
  author       = {Chia-Chi Wu and Yen-Liang Chen and Yi-Hsin Yeh},
  doi          = {10.1109/TCSS.2023.3272633},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2558-2569},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A deep recommendation model considering the impact of time and individual diversity},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A generalized community-structure-aware optimization
framework for efficient subgraph matching in social network analysis.
<em>TCSS</em>, <em>11</em>(2), 2545–2557. (<a
href="https://doi.org/10.1109/TCSS.2023.3303476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subgraph matching is a common and important query for analyzing social networks. However, existing subgraph matching algorithms are still unsatisfactory in efficiency. As different subgraph matching algorithms are suitable for different conditions, this article aims to find optimization methods effective for different subgraph matching algorithms. Specifically, the contributions of this article mainly include three aspects. First, this article defines the concept of a community distribution scheme (c-scheme), and proposes an efficient generalized community-structure-aware optimization framework named GCF to accelerate the process of subgraph matching. Specifically, in the GCF framework, subgraph matching is performed by dealing with all c-schemes, and GCF can accelerate different subgraph matching algorithms by exploiting the community structure of the graph data. Second, three strategies are proposed and applied in GCF to further accelerate the process of subgraph matching. In detail, GCF analyzes the structure of the pattern graph and avoids redundant calculation with the strategy of two-level symmetry-breaking (2LS). Besides, GCF builds indexes on the community paths of the data graph to detect useless c-schemes in advance. Moreover, GCF performs community-structure-based boundary pruning and reduces the search space. Third, in the experiments, four state-of-the-art subgraph matching algorithms, i.e., TurboISO, VF3, VF3-Light, and DAF, are optimized with GCF. The results of the experiments conducted on both real-world and synthetic datasets show that the GCF is efficient and can significantly reduce the time consumption of different existing subgraph matching algorithms. Specifically, the optimized subgraph matching algorithms can be more than $2800\times $ faster than the original algorithms in the best condition. Moreover, the experimental results on datasets with different scales demonstrate that GCF has considerable scalability.},
  archive      = {J_TCSS},
  author       = {Yunkai Lou and Chaokun Wang},
  doi          = {10.1109/TCSS.2023.3303476},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2545-2557},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A generalized community-structure-aware optimization framework for efficient subgraph matching in social network analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integration of train regulation and speed profile
optimization based on feature learning and hybrid search algorithm.
<em>TCSS</em>, <em>11</em>(2), 2535–2544. (<a
href="https://doi.org/10.1109/TCSS.2023.3303473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The independent hierarchy of train dispatching command and train operation control in the existing urban rail transit systems restricts the improvement of operational efficiency and emergency handling capability. This article focuses on integrating train regulation and speed profile optimization by utilizing a feature learning and hybrid search algorithm. Specifically, a genetic algorithm (GA) is used to optimize the train speed profile for a fixed interval running time, and then, the generated labeled sample data are used to train a convolutional neural network (CNN) to learn and extract the features of the optimal speed profile. The nonlinear mapping relationship between input and output variables in trajectory optimization is characterized by a well-trained CNN to reduce the computation time of the optimal speed profile during train regulation. The input variables comprise line conditions and interval running times, while the output variables include the corresponding energy consumption and operating condition switching points of the optimal speed profile. An integrated model of train regulation and operation control is developed with the objective of minimizing total train delay time and energy consumption. To ensure convergence and global search capability, we design a hybrid search algorithm-based train regulation algorithm. Simulation experiments are conducted using data from the Beijing Yizhuang line to validate the effectiveness of the proposed model and algorithms. The experimental results demonstrate that the proposed method can provide an optimal scheme for train regulation and speed profiles.},
  archive      = {J_TCSS},
  author       = {Min Zhou and Zhuopu Hou and Xingtang Wu and Hairong Dong and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3303473},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2535-2544},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Integration of train regulation and speed profile optimization based on feature learning and hybrid search algorithm},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causal reinforcement learning in iterated prisoner’s
dilemma. <em>TCSS</em>, <em>11</em>(2), 2523–2534. (<a
href="https://doi.org/10.1109/TCSS.2023.3289470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The iterated prisoner’s dilemma (IPD) is an archetypal paradigm to model cooperation and has guided studies on social dilemmas. In this work, we develop a causal reinforcement learning (CRL) strategy in a PD game. An agent is designed to have an explicit causal representation of other agents playing strategies from the Axelrod tournament. The collection of policies is assembled in an ensemble RL to choose the best strategy. The agent is then tested against selected Axelrod tournament strategies as well as an adaptive agent trained using traditional RL. Results show that our agent is able to play against all other players and score higher while being adaptive in situations where the strategy of the other players’ changes. Furthermore, the decision taken by the agent can be explained in terms of the causal representation of the interactions. Based on the decision made by the agent, a human observer can understand the chosen strategy.},
  archive      = {J_TCSS},
  author       = {Yosra Kazemi and Caroline P. C. Chanel and Sidney Givigi},
  doi          = {10.1109/TCSS.2023.3289470},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2523-2534},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Causal reinforcement learning in iterated prisoner’s dilemma},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic graph construction framework for multimodal named
entity recognition in social media. <em>TCSS</em>, <em>11</em>(2),
2513–2522. (<a href="https://doi.org/10.1109/TCSS.2023.3303027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal named entity recognition (MNER) aims to detect named entities and identify the entity types based on texts and attached images, which also generates inputs for other comprehensive tasks, such as multimodal machine translation, visual dialog, and multimodal sentiment analysis. Existing studies have limitations in text-image matching and multimodal semantic disparity reduction. For one thing, current methods fail to resolve both overall and local text-image matching issues in a self-guided way. For another, the static graphs constructed in MNER models are challenging in bridging the semantic gap between different modalities. In this work, a dynamic graph construction framework (DGCF) is proposed to solve the above-mentioned limitations. A similarity vector-based text-image matching inferring strategy is designed to obtain the overall and local matching relation between text and image while the overall matching determines the retained proportion of visual information. Then, a multimodal dynamic graph interaction module is developed. Within each layer of the module, the local matching relations and part of speech (POS)-based multihead attention are integrated to construct a dynamic cross-modal graph and a semantic graph. Lastly, a CRF layer is used to predict entity label. Extensive experiments are performed on two benchmark datasets. The experimental results reveal that our model is a competitive alternative and achieves state-of-the-art performance.},
  archive      = {J_TCSS},
  author       = {Weixing Mai and Zhengxuan Zhang and Kuntao Li and Yun Xue and Fenghuan Li},
  doi          = {10.1109/TCSS.2023.3303027},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2513-2522},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Dynamic graph construction framework for multimodal named entity recognition in social media},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A novel dynamic multiobjective optimization algorithm with
hierarchical response system. <em>TCSS</em>, <em>11</em>(2), 2494–2512.
(<a href="https://doi.org/10.1109/TCSS.2023.3293331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a novel dynamic multiobjective optimization algorithm (DMOA) is proposed based on a designed hierarchical response system (HRS). Named HRS-DMOA, the proposed algorithm mainly aims at integrating merits from the mainstream ideas of dynamic behavior handling (i.e., the diversity-, memory-, and prediction-based methods) in order to make flexible responses to environmental changes. In particular, by two predefined thresholds, the environmental changes are quantified as three levels. In case of a slight environmental change, the previous Pareto set-based refinement strategy is recommended, while the diversity-based reinitialization method is applied in case of a dramatic environmental change. For changes occurring at a medium level, the transfer-learning-based response is adopted to make full use of the historical searching experiences. The proposed HRS-DMOA is comprehensively evaluated on a series of benchmark functions, and the results show an improved comprehensive performance as compared with four popular baseline DMOAs in terms of both convergence and diversity, which also outperforms other two state-of-the-art DMOAs in ten out of 14 testing cases, exhibiting the competitiveness and superiority of the algorithm. Finally, extensive ablation studies are carried out, and from the results, it is found that as compared with randomly selecting the response methods, the proposed HRS enables more reasonable and efficient responses in most cases. In addition, the generalization ability of the proposed HRS as a flexible plug-and-play module to handle dynamic behaviors is proven as well.},
  archive      = {J_TCSS},
  author       = {Han Li and Zidong Wang and Chengbo Lan and Peishu Wu and Nianyin Zeng},
  doi          = {10.1109/TCSS.2023.3293331},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2494-2512},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A novel dynamic multiobjective optimization algorithm with hierarchical response system},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motif-backdoor: Rethinking the backdoor attack on graph
neural networks via motifs. <em>TCSS</em>, <em>11</em>(2), 2479–2493.
(<a href="https://doi.org/10.1109/TCSS.2023.3267094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network (GNN) with a powerful representation capability has been widely applied to various areas. Recent works have exposed that GNN is vulnerable to the backdoor attack, i.e., models trained with maliciously crafted training samples are easily fooled by patched samples. Most of the proposed studies launch the backdoor attack using a trigger that is either the randomly generated subgraph [e.g., erdős-rényi backdoor (ER-B)] for less computational burden or the gradient-based generative subgraph [e.g., graph trojaning attack (GTA)] to enable a more effective attack. However, the interpretation of how is the trigger structure and the effect of the backdoor attack related has been overlooked in the current literature. Motifs, recurrent and statistically significant subgraphs in graphs, contain rich structure information. In this article, we are rethinking the trigger from the perspective of motifs and propose a motif-based backdoor attack, denoted as Motif-Backdoor. It contributes from three aspects. First, Interpretation, it provides an in-depth explanation for backdoor effectiveness by the validity of the trigger structure from motifs, leading to some novel insights, e.g., using subgraphs that appear less frequently in the graph as the trigger can achieve better attack performance. Second, Effectiveness, Motif-Backdoor reaches the state-of-the-art (SOTA) attack performance in both black-box and defensive scenarios. Third, Efficiency, based on the graph motif distribution, Motif-Backdoor can quickly obtain an effective trigger structure without target model feedback or subgraph model generation. Extensive experimental results show that Motif-Backdoor realizes the SOTA performance on three popular models and four public datasets compared with five baselines, e.g., Motif-Backdoor improves the attack success rate (ASR) by 14.73% compared with baselines on average. In addition, under a possible defense, Motif-Backdoor still implements satisfying performance, highlighting the requirement of defenses against backdoor attacks on GNNs. The datasets and code are available at https://github.com/Seaocn/Motif-Backdoor .},
  archive      = {J_TCSS},
  author       = {Haibin Zheng and Haiyang Xiong and Jinyin Chen and Haonan Ma and Guohan Huang},
  doi          = {10.1109/TCSS.2023.3267094},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2479-2493},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Motif-backdoor: Rethinking the backdoor attack on graph neural networks via motifs},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quaternion deformable local binary pattern and
pose-correction facial decomposition for color facial expression
recognition in the wild. <em>TCSS</em>, <em>11</em>(2), 2464–2478. (<a
href="https://doi.org/10.1109/TCSS.2023.3305616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) in the wild is a more challenging topic than that under laboratory-controlled conditions. The major obstacles of FER in the wild are head pose variations, illumination changes, and different skin colors. To address these problems, we propose a framework named quaternion deformable local binary pattern (QDLBP)-Net for color FER in the wild. First, to eliminate the interferences of head pose variations, a pose-correction facial decomposition (PCFD) strategy is proposed to correct the head pose and decompose the facial image into five emotion-related regions. Then, to handle the problems of illumination changes and different skin colors, an effective feature descriptor named “QDLBP” is developed. QDLBP extracts color quaternion features from each emotional region, which not only computes the strength of emotional features, but also maintains the spectral correlation between color channels. Finally, a quaternion classification network (QC-Net) is proposed to classify the quaternion features from five emotional regions into seven basic expressions. The experimental results on three in-the-wild FER datasets and two nonfrontal pose variation datasets exhibit the effectiveness and superiority of QDLBP-Net by showing clear performance improvements over other state-of-the-art (SOTA) FER methods.},
  archive      = {J_TCSS},
  author       = {Lianghai Jin and Yu Zhou and Guangzhi Ma and Enmin Song},
  doi          = {10.1109/TCSS.2023.3305616},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2464-2478},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Quaternion deformable local binary pattern and pose-correction facial decomposition for color facial expression recognition in the wild},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A community-based centrality measure for identifying key
nodes in multilayer networks. <em>TCSS</em>, <em>11</em>(2), 2448–2463.
(<a href="https://doi.org/10.1109/TCSS.2023.3297902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of important nodes (vertexes) in multilayer networks has aroused many scholars’ attention and various centrality methods have deen developed. However, the current centralities ignore the impact of community structure on node importance. In this article, we define a community-based centrality for finding key vertexes in multilayer networks, referred to as the CBCM. We first construct a multilayer network model with interlayer edges, which is represented by a fourth-order tensor. Based on the fourth-order tensor, we develop a centrality, called PR_BIS, to measure the importance of vertexes and network layers in multilayer networks, simultaneously. CBCM determines the importance of a vertex in each network layer by combining the following three factors: the PageRank centrality score of the vertex, the importance of the community where the vertex is located, and the ability of the vertex within a community to affect vertexes in other communities within two steps. Based on the importance of all the network layers measured by PR_BIS centrality, we perform weighted fusion for the importance of a vertex in all network layers to obtain the importance of the vertex in multilayer networks. Finally, numerical experiments are performed on several multilayer networks to verify the effectiveness and superiority of CBCM and PR_BIS.},
  archive      = {J_TCSS},
  author       = {Laishui Lv and Peng Hu and Zijun Zheng and Dalal Bardou and Ting Zhang and Heng Wu and Shanzhou Niu and Gaohang Yu},
  doi          = {10.1109/TCSS.2023.3297902},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2448-2463},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A community-based centrality measure for identifying key nodes in multilayer networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The configurational paths in BoP rural e-commerce
entrepreneurial opportunity: A fuzzy-set qualitative comparative
analysis. <em>TCSS</em>, <em>11</em>(2), 2433–2447. (<a
href="https://doi.org/10.1109/TCSS.2023.3265873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bottom of the pyramid (BoP) e-commerce entrepreneurship has emerged as a new phenomenon in China’s rural regions, but its origins have not been thoroughly explored. This study analyzed the shaping of entrepreneurial opportunity (EO) based on the entrepreneurial ecosystem theory as the study framework. A questionnaire survey was conducted among 213 rural e-commerce practitioners in Guangdong and Wuling Mountains, China, using the fuzzy-set qualitative comparative analysis approach to study the various factors and causal mechanisms affecting EOs. Our findings highlight the following: 1) there is no single necessary condition for high BoP rural e-commerce EO formation. However, low human capital leads to nonhigh BoP rural e-commerce EO formation; 2) the driving mechanisms for high BoP rural e-commerce EO are of three types (five paths): government-led, dual-interaction between government and potential subjects, and market-led; and 3) there is an asymmetry between the driving mechanisms of high and nonhigh entrepreneurship opportunity formation in rural e-commerce. The findings of this article contribute to the expansion of the entrepreneurial ecosystem theory’s application in rural e-commerce entrepreneurship and provide practical implications for the BoP population in effectively obtaining EOs in rural e-commerce.},
  archive      = {J_TCSS},
  author       = {Lijuan Huang and Guojie Xie and Yanling Zheng and Yu Tian and Weiwei Cai},
  doi          = {10.1109/TCSS.2023.3265873},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2433-2447},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {The configurational paths in BoP rural E-commerce entrepreneurial opportunity: A fuzzy-set qualitative comparative analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RDGT-GAN: Robust distribution generalization of transformers
for COVID-19 fake news detection. <em>TCSS</em>, <em>11</em>(2),
2418–2432. (<a href="https://doi.org/10.1109/TCSS.2023.3269595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media platforms have become a vital source of information during the outbreak of the pandemic (COVID-19). The phenomena of fake information or news spread through social media have become increasingly prevalent and a powerful tool for information proliferation. Detecting fake news is crucial for the betterment of society. Existing fake news detection models focus on increasing the performance which leads to overfitting and lag generalizability. Hence, these models require training for various datasets of the same domain with significant variations in the distribution. In our work, we have addressed this overfitting issue by designing a robust distribution generalization of transformers-based generative adversarial network (RDGT-GAN) architecture, which can generalize the model for COVID-19 fake news datasets with different distributions without retraining. Based on our experimental findings, it is evident that the proposed model outperforms the current state-of-the-art (SOTA) models in terms of performance.},
  archive      = {J_TCSS},
  author       = {U. Shivani Sri Varshini and R. Praneetha Sree and M. Srinivas and R. B. V. Subramanyam},
  doi          = {10.1109/TCSS.2023.3269595},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2418-2432},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {RDGT-GAN: Robust distribution generalization of transformers for COVID-19 fake news detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Group opinion consensus under moderate guidance.
<em>TCSS</em>, <em>11</em>(2), 2410–2417. (<a
href="https://doi.org/10.1109/TCSS.2023.3289399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opinions evolve rapidly on the Internet, where adverse opinion evolution such as echo chamber could occur. To facilitate group consensus formation, many studies on opinion guidance strategy have been conducted. However, previous guidance strategies are to impose target opinions on the public, without considering the individuals’ acceptance of the target opinions. To overcome this shortcoming, we propose an opinion dynamics model based on a moderate opinion guidance strategy. Through the simulation result, we illustrate the effect of guidance ratio and guidance strength on group consensus level. Moreover, we explain the counterintuitive result of increasing guidance strength by analyzing the opinion formation process. Then, we verify the stability of the moderate guidance in multiple networks and compare it with the traditional degree guidance in various network environments. The results show that the moderate guidance can not only effectively guide most individuals’ opinion to reach a consensus in the short term, but also guide an individual who has a large deviation to target opinion through long-term guidance.},
  archive      = {J_TCSS},
  author       = {Chenxi Ge and Yutong Liu and Xi Chen},
  doi          = {10.1109/TCSS.2023.3289399},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2410-2417},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Group opinion consensus under moderate guidance},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rumor propagation control with anti-rumor mechanism and
intermittent control strategies. <em>TCSS</em>, <em>11</em>(2),
2397–2409. (<a href="https://doi.org/10.1109/TCSS.2023.3277465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the intermittent control of a rumor propagation system with anti-rumor mechanism. The interaction with the anti-rumor mechanism is investigated, including the existence and stability of two boundary equilibriums, the condition of bistability behavior. Threshold parameters are identified which determine the global exponential stability of the rumor-free equilibrium. To combat rumor spreading, we design deterministic and stochastic control strategies with aperiodically intermittent control time. The expressions of the minimum control intensities are obtained, which are related to the control ratio and system parameters. Numerical examples are carried out to verify the validity of the theoretical results and evaluate the potential roles of the intermittent control strategies.},
  archive      = {J_TCSS},
  author       = {Xiaojing Zhong and Yukun Yang and Feiqi Deng and Guiyun Liu},
  doi          = {10.1109/TCSS.2023.3277465},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2397-2409},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Rumor propagation control with anti-rumor mechanism and intermittent control strategies},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An offline–online integration approach for security traffic
patrolling with frequency constraints. <em>TCSS</em>, <em>11</em>(2),
2383–2396. (<a href="https://doi.org/10.1109/TCSS.2023.3280494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing need to protect public security, this article studies the security traffic patrolling (STP) problem, where a collection of police officers plan to patrol around a city. In STP, the patrolling policy should not only take drivers’ opportunistic behaviors into consideration but also satisfy frequency constraints such that hot-spot regions are patrolled at least once every several periods. Existing randomized methods are efficient in reducing traffic law violations but can only satisfy the frequency constraints in a probabilistic manner. Traditional planning methods can be employed to meet the frequency constraints in a deterministic manner. However, it is difficult to find the deterministic patrolling paths for city-scale STP with hundreds of police officers and regions. Against this background, this article proposes a novel two-stage offline–online integration framework to guarantee frequency constraints while efficiently preventing traffic law violations of drivers. In the offline stage, a linear programming (LP)-based randomized policy is designed, where the patrolling efficiency is modeled as the objective and the frequency constraint is modeled in a probabilistic manner. Guided by the offline policy, in the online stage, by observing the real distribution of police officers, real-time planning is proposed to reschedule the police to guarantee the frequency constraints. Extensive empirical experiments on synthetic and real datasets are conducted to validate the proposed framework. The results demonstrate that compared with existing baseline solutions, the proposed two-stage STP framework can reduce the driver violation rate as much as possible, satisfy frequency constraints and scale well to STP in a real-time fashion.},
  archive      = {J_TCSS},
  author       = {Qian Che and Wanyuan Wang and Guiyi Liu and Wenyuan Zhang and Jiuchuan Jiang and Yichuan Jiang},
  doi          = {10.1109/TCSS.2023.3280494},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2383-2396},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An Offline–Online integration approach for security traffic patrolling with frequency constraints},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imperfect vaccination evolutionary game incorporating
individual social difference and subjective perception. <em>TCSS</em>,
<em>11</em>(2), 2369–2382. (<a
href="https://doi.org/10.1109/TCSS.2023.3271894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies have focused on the assumption that individual attitudes toward epidemics, epidemic-related information, and vaccination are identical with much less effort attempting to consider psychological factors and individual heterogeneity. In this article, we employ a two-layer susceptible–infected–recovered–vaccinated/unaware–aware–unaware (SIRV-UAU) coupled network to depict the interplay between epidemic spreading and information diffusion. We propose an imperfect vaccination evolutionary game model integrating prospect theory (PT) to explore the effect of individual subjective perception and social difference on epidemic spreading and vaccination equilibrium. We find that the individual social difference in the epidemic spreading layer has a more significant impact on the epidemic threshold than that in the information diffusion layer. Individual psychological perception and vaccination behavior decision-making determine the vaccination equilibrium: under the PT, vaccination equilibrium increases with the decrease of the rationality coefficient when the vaccination cost is small. Furthermore, we analyze the effect of social differences on individual vaccination behavior decision-making and find that vaccination equilibrium increases with the increase of social reinforcement strength and primary protective probability. Finally, we discuss the effect of infection cost on vaccination equilibrium when the infection cost of vaccinated individuals is less than that of unvaccinated individuals and observe that a small infection cost helps improve the vaccination equilibrium.},
  archive      = {J_TCSS},
  author       = {Cong Li and Jin-Ying Dai and Xiang Li},
  doi          = {10.1109/TCSS.2023.3271894},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2369-2382},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Imperfect vaccination evolutionary game incorporating individual social difference and subjective perception},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sentiment and objectivity in iranian state-sponsored
propaganda on twitter. <em>TCSS</em>, <em>11</em>(2), 2359–2368. (<a
href="https://doi.org/10.1109/TCSS.2023.3273729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2016, Russia attempted to use social media to influence the outcome of the U.S. presidential election, highlighting the potential real-world impacts of state-led online misinformation campaigns. Misinformation on social media is a growing concern, especially in the areas of politics and medicine, given their impact not only at the individual level but also for society as a whole. In this article, we investigate the potential to automatically label and detect the polarity (positive, neutral, or negative) of Iranian state-sponsored propaganda tweets on the Iranian nuclear deal. The SentiWordNet lexicon is used to automatically assign a polarity label and an objectivity score to each tweet. Using the labels, five machine learning algorithms are used to create polarity detection models. The experimental results show that the best performing models correctly identify polarity in approximately 77% of the tweets.},
  archive      = {J_TCSS},
  author       = {Michael Barrows and Ella Haig and Dara Conduit},
  doi          = {10.1109/TCSS.2023.3273729},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2359-2368},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Sentiment and objectivity in iranian state-sponsored propaganda on twitter},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Safety is our friend: A federated learning framework toward
driver’s state and behavior detection. <em>TCSS</em>, <em>11</em>(2),
2340–2358. (<a href="https://doi.org/10.1109/TCSS.2023.3273727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Safety is our friend, accidents our enemy” is the propaganda social information on traffic safety in several countries. This proves that safety is a top priority when using vehicles when participating in traffic. There have been several studies on driver behavior/state detection using machine learning (ML). In addition, in ML generally, the data must be provided to the server for training in a centralized setting. Sharing data will therefore expose data information to external interference and corruption, bringing many risks. Federated learning (FL) recently emerged as new research to solve the tricky problems above. Our research is one of the few first studies that applies longitudinal physiological sensor measurements in a naturalistic driving environment using the FL framework to assess driver behavior/state. The novelty of this study includes the following. First, we use techniques such as synthetic minority oversampling technique (SMOTE) to enrich and balance the Harmony dataset. The purpose is to increase the accuracy and improve the reliability of the assessment. Second, we incorporate essential deep learning (DL) models into the FL framework, including multilayer perceptron (MLP), long short-term memory (LSTM), 1-D convolutional neural network (1-D CNN), CNN-LSTM, and convolutional LSTM (ConvLSTM) models. By evaluating these models, we show that in the FL environment, the use of compact, lightweight models such as MLP provides higher efficiency than other large, complex models and is suitable for consistent research. Finally, our framework has higher results than other basic models such as support vector machines and decision trees while remaining highly competitive to other DL models with respect to network size, execution time, and stability. Primarily, our idea is the trend of the future. It can be practically applied in transportation, taxis, and self-driving car companies; each car is considered a client, and companies can manage their drivers instead of using a third-party service, which will cause data loss and privacy.},
  archive      = {J_TCSS},
  author       = {Tran Anh Khoa and Nguyen Dang Trac and Vo Phuc Tinh and Nguyen Hoang Nam and Duc Ngoc Minh Dang and Hoang Hai Son and Pham Duc Lam},
  doi          = {10.1109/TCSS.2023.3273727},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2340-2358},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Safety is our friend: A federated learning framework toward driver’s state and behavior detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effect of network structure and committed minority placement
in promoting social diffusion. <em>TCSS</em>, <em>11</em>(2), 2326–2339.
(<a href="https://doi.org/10.1109/TCSS.2023.3303568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social diffusion is the phenomenon whereby a population collectively adopts a novel (alternative) behavior, opinion, product, or technology to replace an existing status quo. Often the process is driven by a small number of individuals, termed committed minority, who stubbornly promote the alternative. In this work, we use an experimentally proven game-theoretic agent-based model to explore how social diffusion is influenced by the network of social interactions, the placement of committed minority, and the timing that committed minority are introduced into the network. Through a campaign of Monte Carlo simulations, we find that diffusion occurs quicker on sparse and highly clustered networks. In addition, we show that placing the committed minority at nodes with the highest Bonacich centrality with a negative attenuation factor seems to be the best approach for facilitating diffusion. Then, we find that the timing of introducing committed minority has a negligible effect on the diffusion process. Finally, our findings are tested and confirmed on two case studies of real-world networks.},
  archive      = {J_TCSS},
  author       = {Tianshu Gao and Lorenzo Zino and Mengbin Ye},
  doi          = {10.1109/TCSS.2023.3303568},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2326-2339},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Effect of network structure and committed minority placement in promoting social diffusion},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Defending against data poisoning attack in federated
learning with non-IID data. <em>TCSS</em>, <em>11</em>(2), 2313–2325.
(<a href="https://doi.org/10.1109/TCSS.2023.3296885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is an emerging paradigm that allows participants to collaboratively train deep learning tasks while protecting the privacy of their local data. However, the absence of central server control in distributed environments exposes a vulnerability to data poisoning attacks, where adversaries manipulate the behavior of compromised clients by poisoning local data. In particular, data poisoning attacks against FL can have a drastic impact when the participant’s local data is non-independent and identically distributed (non-IID). Most existing defense strategies have demonstrated promising results in mitigating FL poisoning attacks, however, fail to maintain their effectiveness with non-IID data. In this work, we propose an effective defense framework, FL data augmentation (FLDA), which defends against data poisoning attacks through local data mixup on the clients. In addition, to mitigate the non-IID effect by exploiting the limited local data, we propose a gradient detection strategy to reduce the proportion of malicious clients and raise benign clients. Experimental results on datasets show that FLDA can effectively reduce the poisoning success rate and improve the global model training accuracy under poisoning attacks for non-IID data. Furthermore, FLDA can increase the FL accuracy by more than 12% after detecting malicious clients.},
  archive      = {J_TCSS},
  author       = {Chunyong Yin and Qingkui Zeng},
  doi          = {10.1109/TCSS.2023.3296885},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2313-2325},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Defending against data poisoning attack in federated learning with non-IID data},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SHADE: Speaker-history-aware dialog generation through
contrastive and prompt learning. <em>TCSS</em>, <em>11</em>(2),
2302–2312. (<a href="https://doi.org/10.1109/TCSS.2023.3297051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional persona-based dialog generation models typically rely on textual descriptions of persona information, but this approach is limited by this and its inability to capture all aspects of a persona’s speaking style. To solve this problem, we propose a novel dialog generation model called Speaker-History-Aware Dialogue GEneration (SHADE) through Contrastive and Prompt Learning, which utilizes contrastive learning to model speaking style from historical conversation, resulting in more personalized and distinctive response. Based on the idea of, Prompt learning, on the one hand, we embed small-scale trainable parameters according to Continuous Prompts to stimulate the knowledge of the pre-trained language model, so as to improve the feature extraction ability of the model. On the other hand, we add speaker tag to the decoder input according to Discrete Prompts to improve the consistency of speaking style. We evaluate our model on two popular text-only datasets, DailyDialog and PersonaChat. The results show that SHADE outperforms other multiturn hierarchical dialog generation models in terms of response consistency, logic, and diversity. SHADE is optimal for metrics PPL, NIST, ROUGEL, METEOR, BLUE2, etc. Our proposed SHADE offers a promising direction for persona-based dialog generation, addressing the limitation of existing approaches and paving the way for more personalized and engaging conversational agents in various applications.},
  archive      = {J_TCSS},
  author       = {Futian Wang and Xuyang Zhao and Xiao Sun},
  doi          = {10.1109/TCSS.2023.3297051},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2302-2312},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {SHADE: Speaker-history-aware dialog generation through contrastive and prompt learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reconstructive classification for age and gender
identification in social networks. <em>TCSS</em>, <em>11</em>(2),
2291–2301. (<a href="https://doi.org/10.1109/TCSS.2023.3267766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Author profiling is a challenging task that consists of identifying a person’s relevant attributes based on the content he/she generates. In this article, we validate a classification method based on the reconstructive classification to identify two demographic attributes, age and gender, for users of social networks based on the text content they publish. For the problem, we consider balanced and unbalanced data, where a gender or age group has a larger presence than the others. The proposed method is based on using the reconstructive property of singular value decomposition (SVD), and its suitability to work with sparse data, to find a matrix with the main latent components to represent the information of specific gender or age classes. Afterward, we use such a matrix to project and reconstruct new users’ information to identify their demographic variables. We test our method with a set of datasets in several languages collected from Twitter and Pinterest users, and we use different evaluation metrics to compare their performance with the ones of several popular classifiers based on traditional machine learning, and on deep learning, and with some relevant works in the literature. The results show that the proposed classifier performs generally well in identifying the age and gender of users in social networks.},
  archive      = {J_TCSS},
  author       = {Juan Carlos Gomez and Jorge Moreno and Mario-Alberto Ibarra-Manzano and Dora-Luz Almanza-Ojeda},
  doi          = {10.1109/TCSS.2023.3267766},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2291-2301},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Reconstructive classification for age and gender identification in social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CSAT: Contrastive sampling-aggregating transformer for
community detection in attribute-missing networks. <em>TCSS</em>,
<em>11</em>(2), 2277–2290. (<a
href="https://doi.org/10.1109/TCSS.2023.3292145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection aims to identify dense subgroups of nodes within a network. However, in real-world networks, node attributes are often missing, making traditional methods less effective. In networks with missing attributes, the main challenge of community detection is to deal with the missing attribute information efficiently and use network structure information to make accurate predictions. This article proposes an innovative method called contrastive sampling-aggregating transformer (CSAT) for community detection in attribute-missing networks. CSAT incorporates the contrastive learning principle to capture hidden patterns among nodes and to aggregate information from different samples to create a more robust and accurate methodology for community detection. Specifically, CSAT utilizes a sampling and propagation strategy to obtain different samples and smooth attribute features of the network structure and leverages the Transformer architecture to model the pairwise relationships between nodes. Therefore, our method can address the attribute-missing issue by integrating the auxiliary information from both the network structure and other sources. Extensive experiments on several benchmark datasets demonstrate CSAT’s superior performance compared to the state-of-the-art methods for community detection.},
  archive      = {J_TCSS},
  author       = {Mengran Li and Yong Zhang and Wei Zhang and Shiyu Zhao and Xinglin Piao and Baocai Yin},
  doi          = {10.1109/TCSS.2023.3292145},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2277-2290},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {CSAT: Contrastive sampling-aggregating transformer for community detection in attribute-missing networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The blame game: Understanding blame assignment in social
media. <em>TCSS</em>, <em>11</em>(2), 2267–2276. (<a
href="https://doi.org/10.1109/TCSS.2023.3261242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Psychological studies on morality have proposed underlying linguistic and semantic factors. However, current empirical studies often lack the nuances and complexity of real life. This article examines how well the findings of prior studies generalize to a corpus of over 30000 narratives of tense social situations submitted to a popular social media forum. A poster describes interpersonal moral situations or misgivings; other users judge from the post whether the poster (protagonist) or an opposing side (antagonist) is morally culpable. We extend and apply natural language processing (NLP) techniques to understand the effects of descriptions of the people involved in these posts. We conduct extensive experiments to investigate the effect sizes of features to understand how they affect the assignment of blame on social media. Our findings show that aggregating psychological theories enables understanding real-life moral situations. We also find evidence of bias blame assignment on social media, such as that males are likelier to receive blame no matter whether they are protagonists or antagonists.},
  archive      = {J_TCSS},
  author       = {Ruijie Xi and Munindar P. Singh},
  doi          = {10.1109/TCSS.2023.3261242},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2267-2276},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {The blame game: Understanding blame assignment in social media},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A study of major depressive disorder based on resting-state
multilayer EEG function network. <em>TCSS</em>, <em>11</em>(2),
2256–2266. (<a href="https://doi.org/10.1109/TCSS.2023.3276755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is a complex mental disease with its pathological mechanism unclear. To depict the complete picture of the abnormal information interaction in a depressed brain, this study is the first to apply fully connected multilayer brain functional (FCMBF) network framework and proposed composite FCMBF (CFCMBF) network framework, combined with graph theory to analyze the within-frequency coupling (WFC) and cross-frequency coupling (CFC) of sensor-layer and source-layer electroencephalography (EEG) signals in relevant subjects. Results showed that in the sensor-layer FCMBF network, depressive patients showed significantly reduced functional connectivity, as well as abnormal global and local information processing abilities of the network, and these network properties were significantly correlated with depressive symptoms. In addition, from the perspective of depression recognition, we found that the sensor-layer CFCMBF network could achieve better classification accuracy, especially when using the overlapping degree of node under the right center region, its accuracy could reach $86.88\% \pm 9.25 \%$ . More importantly, the construction of the CFCMBF network has higher time efficiency and less information loss, since it not only measures the WFC and CFC between brain region representative signals (BRRSs) extracted from different brain regions, but also measures these two couplings between all nodes within each brain region. Although the FCMBF network contains more complete information by calculating WFC and CFC between all nodes distributed in each region, it will result in an enormous computational cost. In summary, this study proved the utility of multilayer brain network in revealing the abnormal brain interaction patterns of depression, and our proposed method might provide methodological support for efficient depression recognition research based on multilayer brain networks.},
  archive      = {J_TCSS},
  author       = {Shuting Sun and Shanshan Qu and Chang Yan and Gang Luo and Xuesong Liu and Qunxi Dong and Xiaowei Li},
  doi          = {10.1109/TCSS.2023.3276755},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2256-2266},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A study of major depressive disorder based on resting-state multilayer EEG function network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NRMG: News recommendation with multiview graph convolutional
networks. <em>TCSS</em>, <em>11</em>(2), 2245–2255. (<a
href="https://doi.org/10.1109/TCSS.2023.3266520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of a news recommendation system can effectively improve the news reading experience of users. The most important task of the system is how to learn news and user representations accurately. In the process of learning news representations, most of the current research works do not fully utilize the news features, which makes it difficult to learn more comprehensive news representations. Most research work only learns user representations from a single perspective, which may not be sufficient to learn diverse and dynamic user representations. Therefore, we propose a news recommendation system with a multiview graph convolutional network (NRMG). It contains two parts: news representation and user representation. The knowledge–content collaboration network is adapted to learn news representations from news content and entities, while the multiview graph convolutional network (GCN) is utilized to learn user representations from the user’s click history. The advantage of the NRMG system is that we not only expand the available features by constructing a subclass knowledge graph (KG), but also effectively improve the ability of the news recommendation system to accurately learn news and user representations. Experimental results on the real dataset MIcrosoft News Dataset (MIND) show that the NRMG achieves a 2.25% improvement in area under the receiver operating characteristic (ROC) curve (AUC) value compared with state-of-the-art methods.},
  archive      = {J_TCSS},
  author       = {Bao Chen and Yong Xu and Jingru Zhen and Xin He and Qun Fang and Jinde Cao},
  doi          = {10.1109/TCSS.2023.3266520},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2245-2255},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {NRMG: News recommendation with multiview graph convolutional networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aberrant reward anticipating and processing in abstinent
heroin addicts. <em>TCSS</em>, <em>11</em>(2), 2234–2244. (<a
href="https://doi.org/10.1109/TCSS.2023.3290969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug addicts have a strong desire for immediate reward, which are characterized by difficulty in controlling drug use. Whether chronic heroin intake impairs the reward-circuit function and behavioral regulation when confronted with monetary incentives is currently unknown. Thus, the present study explored the prospects of delayed reward by combining event-related potentials (ERPs) and standardized low-resolution brain electromagnetic tomography analyses (sLORETA). Behavioral and electroencephalography (EEG) data were collected from 23 abstinent heroin addicts (AHAs) and 23 age-, education-, and gender-matched healthy controls (HCs). We found that AHAs responded more quickly to monetary incentives compared with HCs across all conditions. AHAs exhibited a disappearing right hemisphere predominance of stimulus-preceding negativity (SPN) and a higher feedback-related negativity (FRN) compared to HCs. Moreover, sLORETA results showed AHAs had significant reduced activities in superior/medial frontal gyrus (SFG/MFG) at the cue detection stage and in superior temporal gyrus (STG) and insula at the reward anticipation stages, as well as in precuneus, anterior/posterior cingulate cortex (ACC and PCC), para-hippocampal gyrus (PHG), middle/inferior temporal gyrus (MTG/ITG), inferior parietal lobe (IPL), and SFG at the outcome notification stage, respectively, relative to HCs. Our findings revealed abnormalities in reward-related brain regions of AHAs, which further result in the insensitivity to potential punishments and deficits in impulsive control. This study contributes to the understanding of the neural basis of reward anticipation and processing by AHAs and provides a basis for further withdrawal treatment.},
  archive      = {J_TCSS},
  author       = {Jiasen Li and Huiping Yao},
  doi          = {10.1109/TCSS.2023.3290969},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2234-2244},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Aberrant reward anticipating and processing in abstinent heroin addicts},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CritiCoder: An end-to-end uncertain regression network for
robust macroscopic pressure models in water distribution systems.
<em>TCSS</em>, <em>11</em>(2), 2222–2233. (<a
href="https://doi.org/10.1109/TCSS.2023.3272330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the massive uncertain disturbances in water distribution systems (WDSs), it is rather challenging to construct robust macroscopic pressure models. In this article, we propose the CritiCoder, an end-to-end uncertain regression neural network, to build macroscopic pressure models in WDSs and estimate the distribution of uncertain disturbances. By separating the normal regression process into two parts, the CritiCoder decomposes the output into two parts brought by observable and unobservable variates separately. Two subnetworks, Coder and Critic, make up of the CritiCoder. Through the reconstruction of data flow, the Coder is expected to approximate ideal outputs from observable variates. Meanwhile, the loss function of the Critic is redesigned to consider the effectiveness of uncertain disturbances in output brought by unobservable variates. Experiments on a practical application of WDSs in a Chinese mega-city show superior performance of CritiCoder. Especially for pressure-monitoring nodes more severely impacted by disturbances, the performance decline of the CritiCoder is less compared with other baseline methods.},
  archive      = {J_TCSS},
  author       = {Shunyu Wu and Jingcheng Wang and Haotian Xu and Shangwei Zhao and Jiahui Xu},
  doi          = {10.1109/TCSS.2023.3272330},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2222-2233},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {CritiCoder: An end-to-end uncertain regression network for robust macroscopic pressure models in water distribution systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ToupleGDD: A fine-designed solution of influence
maximization by deep reinforcement learning. <em>TCSS</em>,
<em>11</em>(2), 2210–2221. (<a
href="https://doi.org/10.1109/TCSS.2023.3272331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at selecting a small subset of nodes with maximum influence on networks, the influence maximization (IM) problem has been extensively studied. Since it is #P-hard to compute the influence spread given a seed set, the state-of-the-art methods, including heuristic and approximation algorithms, are faced with great difficulties such as theoretical guarantee, time efficiency, generalization, and so on. This makes it unable to adapt to large-scale networks and more complex applications. On the other side, with the latest achievements of deep reinforcement learning (DRL) in artificial intelligence and other fields, lots of work have been focused on exploiting DRL to solve combinatorial optimization (CO) problems. Inspired by this, we propose a novel end-to-end DRL framework, ToupleGDD, to address the IM problem in this article, which incorporates three coupled graph neural networks (GNNs) for network embedding and double deep $Q$ -networks (DQNs) for parameters learning. Previous efforts to solve the IM problem with DRL trained their models on subgraphs of the whole network and then tested them on the whole graph, which makes the performance of their models unstable among different networks. However, our model is trained on several small randomly generated graphs with a small budget and tested on completely different networks under various large budgets, which can obtain results very close to IMM and better results than OPIM-C on several datasets and shows strong generalization ability. Finally, we conduct a large number of experiments on synthetic and realistic datasets and experimental results prove the effectiveness and superiority of our model.},
  archive      = {J_TCSS},
  author       = {Tiantian Chen and Siwen Yan and Jianxiong Guo and Weili Wu},
  doi          = {10.1109/TCSS.2023.3272331},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2210-2221},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {ToupleGDD: A fine-designed solution of influence maximization by deep reinforcement learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot synthetic online transfer learning for cross-site
neurological disease diagnosis. <em>TCSS</em>, <em>11</em>(2),
2201–2209. (<a href="https://doi.org/10.1109/TCSS.2023.3270569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-site datasets expand the data size and could improve the disease diagnosis capabilities of machine learning models. However, differences in data distribution between different sites can lead to poor model generalizability. Although transfer learning is a mainstream method often used to tackle the issue, most transfer learning studies assume that all the target samples are given in the training procedure, which is not available in clinical applications where the target samples arrive sequentially. Online transfer learning (OTL) aims to accomplish clinical diagnostic tasks by adaptively updating the ensemble model containing source and target classifiers. However, OTL is limited by zero initialization and requires numbers of samples to iterate. This results in the underperformance of OTL in clinical applications where few samples can be obtained. In this article, we propose a new framework named few-shot synthetic OTL (FSOTL) to address this issue. FSOTL uses synthetic data to warm up the model in an online fashion. It not only alleviates the problem of scarcity of samples in the target domain but also enables the model to gain more knowledge. Our experiments show that FSOTL performs more stably and achieves more accurate results with few target samples, thereby offering a promising cross-site online computer-aided diagnosis system for large-scale applications.},
  archive      = {J_TCSS},
  author       = {Zhaodi Pei and Fulin Wei and Zhiyuan Zhu and Xia Wu},
  doi          = {10.1109/TCSS.2023.3270569},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2201-2209},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Few-shot synthetic online transfer learning for cross-site neurological disease diagnosis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fake news classification using tensor decomposition and
graph convolutional network. <em>TCSS</em>, <em>11</em>(2), 2190–2200.
(<a href="https://doi.org/10.1109/TCSS.2023.3270331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread of fake news on social media, its impact has become a major concern of the public, so accurate detection methods are urgently needed. As content-based features are the most natural clues for fake news detection, many methods that rely solely on text content have been proposed. However, these methods rarely investigate the sentence interaction patterns of different news articles, and most of them do not consider fine-grained fake news classification. To overcome these issues, this article constructs a graph representation for news articles and employs a graph neural network (GNN) to classify fake news. The proposed method uses the local word co-occurrence information of sentences to obtain the interaction relationship between sentences, which is abstracted by the weight matrix of the graph representation. Accordingly, a third-order co-occurrence tensor is built, and the weight matrix is calculated based on the canonical polyadic (CP) decomposition of this tensor. Since our method considers the sentence interaction patterns, the computed representations can capture more accurate contextual information of news articles. The results on two real-world datasets demonstrate that our method outperforms the competing methods in both binary and multiclass classification tasks. In particular, for multiclass classification on the selected dataset with 70% of the training set for training, the improvements of accuracy and $F1$ -score are 1.82%p–16.98%p and 1.85%p–16.65%p, respectively.},
  archive      = {J_TCSS},
  author       = {Qingyun Ren and Bingyin Zhou and Dongli Yan and Wei Guo},
  doi          = {10.1109/TCSS.2023.3270331},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2190-2200},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Fake news classification using tensor decomposition and graph convolutional network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A reinforcement learning-based incentive mechanism for task
allocation under spatiotemporal crowdsensing. <em>TCSS</em>,
<em>11</em>(2), 2179–2189. (<a
href="https://doi.org/10.1109/TCSS.2023.3263821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Industrial Internet of Things (IoT), the work of large-scale data collection makes spatiotemporal crowdsensing (SC) play an important role. Mobile devices equipped with sensors could act as workers to collect and process data for uploading. In the task allocation process, a fully static allocation fails to meet the needs of realistic conditions, while a completely dynamic allocation fails to achieve the desired results. Therefore, we assume a task-scheduled execution scenario that combines the above two conditions. In the pre-allocation process, an original time location constraints (ORTA) allocation algorithm is first proposed. Then it is optimized (OPTA) to fully utilize the remaining time of the workers and increase the matched number. In addition, the design of the incentive mechanism is an effective means to improve the task completion rate of the platform. To efficiently utilize the limited platform budget in the long run, a Q-learning-based algorithm is proposed to identify target inspire tasks and subsequently increase their reward to attract workers’ participation. Finally, comparison experiments are conducted on real datasets to verify the effectiveness of our algorithm. Furthermore, the experiments on a Raspberry Pi local terminal are conducted under a satellite-based environment.},
  archive      = {J_TCSS},
  author       = {Kaige Jiang and Yingjie Wang and Haipeng Wang and Zhaowei Liu and Qilong Han and Ao Zhou and Chaocan Xiang and Zhipeng Cai},
  doi          = {10.1109/TCSS.2023.3263821},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2179-2189},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A reinforcement learning-based incentive mechanism for task allocation under spatiotemporal crowdsensing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Involution-cooperation-lying flat game on a
network-structured population in the group competition. <em>TCSS</em>,
<em>11</em>(2), 2160–2178. (<a
href="https://doi.org/10.1109/TCSS.2023.3287772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, on the Chinese internet, the term “involution” refers to intense but meaningless competition for limited resources, also known as “the inflation of effort.” Involution is a prevalent phenomenon in various social competition scenarios and can lead to significant social contradictions. On the other hand, “lying flat” refers to a conscious choice by individuals to withdraw from intense competition and pursue a self-centered and hollow existence. The propagation of lying flat culture may lead to nihilism or irrationalism. However, existing literature on involution and lying flat has two main limitations. First, previous studies have separately examined involution and lying flat as two opposite yet closely related outcomes of intense social competition. This approach fails to provide a comprehensive and in-depth understanding of involution and lying flat in the context of increasingly fierce social competition. Second, existing literature predominantly adopts value-based payoff allocation methods, disregarding the prevalence of rank-based payoff allocation methods. Consequently, the other prevalent rank-based allocation (RA) method remains understudied. To address these limitations, we propose an evolutionary game model on a square lattice to abstract the fierce social competition between involution, cooperation, and lying flat. Our experimental results demonstrate that various factors, including social resources, the cost of involution, the relative utility of the involution strategy, and the variance of agents’ competition abilities, play distinct yet significant roles in social competition. Furthermore, these factors exhibit interaction effects on the levels of cooperation, involution, and lying flat. The rank threshold ( $T$ ) positively affects the level of cooperation, exhibits a U-shaped effect on the level of lying flat, and an inverted U-shaped effect on the level of involution. The RA rule tends to result in a higher level of involution, whereas the value-based rule tends to result in a higher level of lying flat. These findings remain robust across different network sizes. Our study provides insights into strategies for suppressing the levels of involution and lying flat in social competitions.},
  archive      = {J_TCSS},
  author       = {He Chaocheng and Huang Qian and Li Xinru and Zuo Renxian and Liu Fuzhen and Wei Yuchi and Wu Jiang},
  doi          = {10.1109/TCSS.2023.3287772},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2160-2178},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Involution-cooperation-lying flat game on a network-structured population in the group competition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Fairness-aware competitive bidding influence maximization
in social networks. <em>TCSS</em>, <em>11</em>(2), 2147–2159. (<a
href="https://doi.org/10.1109/TCSS.2023.3285605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Competitive influence maximization (CIM) has been studied for years due to its wide application in many domains. Most current studies primarily focus on the microlevel optimization by designing policies for one competitor to defeat its opponents. Furthermore, current studies ignore the fact that many influential nodes have their own starting prices, which may lead to inefficient budget allocation. In this article, we propose a novel competitive bidding influence maximization (CBIM) problem, where the competitors allocate budgets to bid for the seeds attributed to the platform during multiple bidding rounds. To solve the CBIM problem, we propose a fairness-aware multiagent CBIM (FMCBIM) framework. In this framework, we present a multiagent bidding particle environment (MBE) to model the competitors’ interactions and design a starting price adjustment mechanism to model the dynamic bidding environment. Moreover, we put forward a novel multiagent CBIM (MCBIM) algorithm to optimize competitors’ bidding policies. Extensive experiments on five datasets show that our work has good efficiency and effectiveness.},
  archive      = {J_TCSS},
  author       = {Congcong Zhang and Jingya Zhou and Jin Wang and Jianxi Fan and Yingdan Shi},
  doi          = {10.1109/TCSS.2023.3285605},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2147-2159},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Fairness-aware competitive bidding influence maximization in social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large-scale parallelization of human migration simulation.
<em>TCSS</em>, <em>11</em>(2), 2135–2146. (<a
href="https://doi.org/10.1109/TCSS.2023.3292932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forced displacement of people worldwide, for example, due to violent conflicts, is common in the modern world, and today more than 82 million people are forcibly displaced. This puts the problem of migration at the forefront of the most important problems of humanity. The Flee simulation code is an agent-based modeling tool that can forecast population displacements in civil war settings, but performing accurate simulations requires nonnegligible computational capacity. In this article, we present our approach to Flee parallelization for fast execution on multicore platforms, as well as discuss the computational complexity of the algorithm and its implementation. We benchmark parallelized code using supercomputers equipped with AMD EPYC Rome 7742 and Intel Xeon Platinum 8268 processors and investigate its performance across a range of alternative rule sets, different refinements in the spatial representation, and various numbers of agents representing displaced persons. We find that Flee scales excellently to up to 8192 cores for large cases, although very detailed location graphs can impose a large initialization time overhead.},
  archive      = {J_TCSS},
  author       = {Derek Groen and Nikela Papadopoulou and Petros Anastasiadis and Marcin Lawenda and Lukasz Szustak and Sergiy Gogolenko and Hamid Arabnejad and Alireza Jahani},
  doi          = {10.1109/TCSS.2023.3292932},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2135-2146},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Large-scale parallelization of human migration simulation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mining multiplatform opinions during public health crisis: A
comparative study. <em>TCSS</em>, <em>11</em>(2), 2121–2134. (<a
href="https://doi.org/10.1109/TCSS.2023.3301951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging infectious diseases pose a growing threat to human society and have sparked extensive public discussions on social media. Although numerous efforts have been made in health data mining on social media, there is a lack of focus on quantitative comparisons across multiple platforms, despite their crucial role in the holistic social communication system. This study addresses this gap by developing a generalized regression model that considers the distinct attributes of social media platforms, including short-text, long-text, and Eastern or Western orientation. Using Monkeypox as an application case, this study examines differences among platforms based on four factors: user characteristics, text topics, text emotion, and text quality. The modeling and regression results reveal significant heterogeneity in public opinion expressions across different platforms, particularly between long-text and short-text platforms. Users on short-text platforms are more exposed to diverse information and tend to be susceptible to emotionally provocative content. On the other hand, users on long-text platforms prefer in-depth discussions and show greater receptivity to content infused with positive emotions. This study reveals the information bias brought by platform differences and contributes to data-driven modeling in social communication systems.},
  archive      = {J_TCSS},
  author       = {Kun Sun and Tian-Fang Zhao and Xiao-Kun Wu and Liang Yang and Di Jin and Wei-Neng Chen},
  doi          = {10.1109/TCSS.2023.3301951},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2121-2134},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Mining multiplatform opinions during public health crisis: A comparative study},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying influential nodes in complex networks from
semi-local and global perspective. <em>TCSS</em>, <em>11</em>(2),
2105–2120. (<a href="https://doi.org/10.1109/TCSS.2023.3295177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to accurately identify influential nodes in complex networks remains a challenge due to the increasing network scale, complex topology, and dynamic network behaviors. Although a variety of approaches have been proposed, most researchers have only considered single or limited dimensions of nodes to varying degrees. In this article, a new centrality model [semi-local and global centrality (SLGC)] built on the semi-local and global structure of the node is proposed, which can capture a larger scope and richer information to evaluate how crucial a node is. First, the generalized energy is defined based on the generalized matrix, and then, the first-order and second-order generalized energy entropies are constructed by integrating information entropy and generalized energy to reflect semi-local influence (SLI). Second, the global influence (GI) is constructed based on the clustering coefficients of nodes and the distance between nodes, and finally, the total influence of nodes is derived from the above two aspects. The SLGC is contrasted with seven benchmark methods on nine real networks to assess the algorithm’s performance, and the data indicated that the SLGC has good effectiveness and versatility in monotonicity, resolution, accuracy, and top-10 nodes.},
  archive      = {J_TCSS},
  author       = {Wenzhi Liu and Pengli Lu and Teng Zhang},
  doi          = {10.1109/TCSS.2023.3295177},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2105-2120},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Identifying influential nodes in complex networks from semi-local and global perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Progress tracking and responding to online public shaming
events on twitter. <em>TCSS</em>, <em>11</em>(2), 2091–2104. (<a
href="https://doi.org/10.1109/TCSS.2023.3295131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online public shaming events on Twitter often have devastating consequences for ordinary victims. Yet, little has been explored about such events from the perspective of these victims. The research gap is starker in comparison to the related domain of corporate crisis communication, which by virtue of a prolonged interest of both the academia and the industry spanning over decades has established theories and practices for managing a crisis event. This work attempts to bridge the gap by addressing two specific questions about managing an ongoing public shaming event. First, once an event has started, can the victim estimate the progress of the event? Second, how should a victim responds—whether by tendering an apology or posting a denial, based on the current progress to restrain the shamers efficiently? We try to address these by providing a way to measure and predict the progress of an ongoing shaming event with considerable accuracy and devising a response strategy depending on the present progress. The progress is measured from the event peak making it uniform for events of different lengths and intensities. The victim’s response can be one of denial or apology. Learning from past shaming events, we recommend the best response type depending on event progress. Moreover, the entire pipeline is language-agnostic benefiting even non-English tweet shamed victims.},
  archive      = {J_TCSS},
  author       = {Rajesh Basak and Shamik Sural and Soumya K. Ghosh},
  doi          = {10.1109/TCSS.2023.3295131},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2091-2104},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Progress tracking and responding to online public shaming events on twitter},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot learning for cross-target stance detection by
aggregating multimodal embeddings. <em>TCSS</em>, <em>11</em>(2),
2081–2090. (<a href="https://doi.org/10.1109/TCSS.2023.3264114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the increasing popularity of the stance detection task, existing approaches are predominantly limited to using the textual content of social media posts for the classification, overlooking the social nature of the task. The stance detection task becomes particularly challenging in cross-target classification scenarios, where even in few-shot training settings the model needs to predict the stance toward new targets for which the model has only seen a few relevant samples during training. To address the cross-target stance detection in social media by leveraging the social nature of the task, we introduce cross-target text-net (CT-TN), a novel model that aggregates multimodal embeddings derived from both textual and network features of the data. We conduct experiments in a few-shot cross-target scenario on six different combinations of source-destination target pairs. By comparing CT-TN with state-of-the-art cross-target stance detection models, we demonstrate the effectiveness of our model by achieving average performance improvements ranging from 11% to 21% across different baseline models. Experiments with different numbers of shots show that CT-TN can outperform other models after seeing 300 instances of the destination target. Further, ablation experiments demonstrate the positive contribution of each of the components of CT-TN toward the final performance. We further analyze the network interactions between social media users, which reveal the potential of using social features for cross-target stance detection.},
  archive      = {J_TCSS},
  author       = {Parisa Jamadi Khiabani and Arkaitz Zubiaga},
  doi          = {10.1109/TCSS.2023.3264114},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2081-2090},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Few-shot learning for cross-target stance detection by aggregating multimodal embeddings},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel lie hypergraph based lifetime enhancement routing
protocol for environmental monitoring in wireless sensor networks.
<em>TCSS</em>, <em>11</em>(2), 2070–2080. (<a
href="https://doi.org/10.1109/TCSS.2023.3262273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor network (WSN) is a rapid surging technology promising many fruitful innovations for the user community. The use of WSNs for continuous monitoring of environmental factors in severe situations, such as detection of volcanoes, forest fires, floods, and so on. Despite WSN’s various potential applications, energy and deployment are two major concerns influencing the network life span. The primary requirement is to monitor node energy consumption in order to improve network performance. Many approaches are proposed in recent times for energy efficiency, this article introduces an associated hypergraph with Lie algebra of upper triangular matrices for energy efficient clustering and routing. Initially, the sensor nodes are formulated as a hypergraph, and each hyperedge is treated as a cluster, from which cluster-head (CH) selection is exploited by minimum hypergraph transversal. The routing decision is employed by constructing the upper triangular matrix (UTM), and Lie commutators of the UTM Lie algebra identifies the best relay nodes for data forwarding. The performance of the proposed work is evaluated using simulation results which shows the effectiveness of the scheme over compared protocols in terms of, number of alive nodes, energy consumption and number of packets received in BS.},
  archive      = {J_TCSS},
  author       = {Supriya Sridharan and Swaminathan Venkatraman and S. P. Raja},
  doi          = {10.1109/TCSS.2023.3262273},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2070-2080},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A novel lie hypergraph based lifetime enhancement routing protocol for environmental monitoring in wireless sensor networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Community deception in large networks: Through the lens of
laplacian spectrum. <em>TCSS</em>, <em>11</em>(2), 2057–2069. (<a
href="https://doi.org/10.1109/TCSS.2023.3268564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many complex networks in the real world have community structures. Typical examples include online social networks and ecology networks. While the identification of communities bears numerous practical applications, with the increasing awareness of data security and privacy concerns, the need to protect the community affiliations of individuals from disclosing by attackers emerges. This raises the community deception (CD) problem, that is, the opposite of community detection, which asks for ways to minimally perturb the network structures by rewiring nodes so that the target communities maximally hide themself from community detection algorithms. To this end, we investigate the CD problem through a Laplacian spectrum lens and propose a method named $\mathtt {ComDeceptor}$ to hide a flexible target set of communities, which is more universal than most existing methods that either focus on hiding the entire communities or a single community. The key idea of $\mathtt {ComDeceptor}$ is to first allocate the resources of perturbations fairly and effectively. By proving that hiding communities through intercommunity edge addition and intracommunity edge deletion correspond to maximizing the second smallest eigenvalue $\lambda _{2}$ and minimizing the largest eigenvalue $\lambda _{n}$ of the graph Laplacian, respectively, $\mathtt {ComDeceptor}$ then incorporates efficient heuristics for approximately solving the problems, thus selecting the appropriate edge to perturb. Experimental results over nine real-world networks and six community detection algorithms not only demonstrate the efficiency of $\mathtt {ComDeceptor}$ , but also the superior performance on obfuscating community structures over the baselines.},
  archive      = {J_TCSS},
  author       = {Chong Zhang and Luoyi Fu and Jiaxin Ding and Xinde Cao and Fei Long and Xinbing Wang and Lei Zhou and Jing Zhang and Chenghu Zhou},
  doi          = {10.1109/TCSS.2023.3268564},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2057-2069},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Community deception in large networks: Through the lens of laplacian spectrum},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Common latent embedding space for cross-domain facial
expression recognition. <em>TCSS</em>, <em>11</em>(2), 2046–2056. (<a
href="https://doi.org/10.1109/TCSS.2023.3276990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical facial expression recognition (FER), the training data and test data are often obtained from different domains. It is obvious that the domain disparity could significantly degrade the recognition performance. To tackle this challenging cross-domain FER problem, we put forward a novel method termed common latent embedding space (CLES). To be specific, first, we obtain a common embedding space for cross-domain samples by matrix factorization (MF). Then, the dual-graph Laplacian is applied to this common embedding space to narrow the gap across distinct domains and, meanwhile, explores the inherent geometric information. Furthermore, to characterize the global relationship of the cross-domain samples, the self-representation strategy is used to guide the learning of the common embedding space. Finally, comprehensive experiments on four benchmark databases indicate that the proposed method can achieve better performance in comparison with the state-of-the-art methods on cross-domain FER tasks.},
  archive      = {J_TCSS},
  author       = {Run Wang and Peng Song and Shaokai Li and Liang Ji and Wenming Zheng},
  doi          = {10.1109/TCSS.2023.3276990},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2046-2056},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Common latent embedding space for cross-domain facial expression recognition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel intelligence evaluation framework: Exploring the
psychophysiological patterns of gifted students. <em>TCSS</em>,
<em>11</em>(2), 2036–2045. (<a
href="https://doi.org/10.1109/TCSS.2023.3303331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligence evaluation is a desirable intelligent application for sensing and interaction in various scenarios, e.g., education, office, and the aviation industry. For example, identifying gifted students, who learn faster and more efficiently than general students due to their neurophysiological advantages, and teaching different students according to their intelligence are urgent requirements in school education. However, current intelligence evaluation mainly relies on intelligence quotient (IQ) tests, which have a problem of decreasing reliability in repeated tests. In addition, no objective assessment criteria are available in the present intelligence evaluation process. Electroencephalogram (EEG) signals, which reflect the neuroelectrical activities of the brain, can be utilized to develop an objective and promising tool for investigating the neurophysiological advantages of gifted groups and augmenting the effects of intelligence evaluation. Consequently, we proposed a novel real-time intelligence evaluation framework based on users’ psychophysiological data. Then, we leveraged the framework to investigate a case study to asses which EEG patterns could be used to effectively characterize gifted students and distinguish them from average students. Experimental results reveal the great differences in the chaos degree of the brain (CDB) between different groups of subjects and the effectiveness of the model in identifying gifted students, thus verifying the practicability and validity of the proposed framework.},
  archive      = {J_TCSS},
  author       = {Jian Shen and Kexin Zhu and Zeguang Zhao and Huajian Liang and Yu Ma and Kun Qian and Yanan Zhang and Qunxi Dong},
  doi          = {10.1109/TCSS.2023.3303331},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2036-2045},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A novel intelligence evaluation framework: Exploring the psychophysiological patterns of gifted students},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Flow-edge-net: Video saliency detection based on optical
flow and edge-weighted balance loss. <em>TCSS</em>, <em>11</em>(2),
2026–2035. (<a href="https://doi.org/10.1109/TCSS.2023.3270164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical flow networks have been widely utilized for video saliency detection (VSD) due to their effective performance in capturing the motion of objects. However, the use of optical flow blurs the edges of salient objects and leads to the problems of poorly defined object boundaries. To address this issue, we propose an optical flow-based edge-weighted loss function, to train a network called Flow-Edge-Net, which can balance the weights of the foreground and background information at the edges of video frames. It has achieved superior performance in detecting salient boundaries. Specifically, we propose two complementary encoding and decoding networks based on the concept of decoupling. That is, the optical flow network focuses on moving objects, while the edge network, based on the encoder-decoder structure, focuses on edge information. As the two networks output features of the same dimension and are from the same input, our proposed self-designed adaptive weighted feature fusion module can compare and integrate the edge information and location information from the two networks through adaptive weighting. The proposed method has been evaluated on five widely used databases. Experiment results demonstrate the superior performance of the proposed Flow-Edge-Net in locating salient objects, with accurate and refined edges. The proposed method achieves superior performance over the state-of-the-art methods in detecting salient objects in videos.},
  archive      = {J_TCSS},
  author       = {Muwei Jian and Xiangwei Lu and Xiaoyang Yu and Yakun Ju and Hui Yu and Kin-Man Lam},
  doi          = {10.1109/TCSS.2023.3270164},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2026-2035},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Flow-edge-net: Video saliency detection based on optical flow and edge-weighted balance loss},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-cultural emotion recognition with EEG and eye movement
signals based on multiple stacked broad learning system. <em>TCSS</em>,
<em>11</em>(2), 2014–2025. (<a
href="https://doi.org/10.1109/TCSS.2023.3298324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With increasing social globalization, interaction between people from different cultures has become more frequent. However, there are significant differences in the expression and comprehension of emotions across cultures. Therefore, developing computational models that can accurately identify emotions among different cultures has become a significant research problem. This study aims to investigate the similarities and differences in emotion cognition processes in different cultural groups by employing a fusion of electroencephalography (EEG) and eye movement (EM) signals. Specifically, an effective adaptive region selection method is proposed to investigate the most emotion-related activated brain regions in different groups. By selecting these commonly activated regions, we can eliminate redundant features and facilitate the development of portable acquisition devices. Subsequently, the multiple stacked broad learning system (MSBLS) is designed to explore the complementary information of EEG and EM features and the effective emotional information still contained in the residual value. The intracultural subject-dependent (ICSD), intracultural subject-independent, and cross-cultural subject-independent (CCSI) experiments have been conducted on the SEED-CHN, SEED-GER, and SEED-FRA datasets. Extensive experiments manifest that MSBLS achieves superior performance compared with current state-of-the-art methods. Moreover, we discover that some brain regions (the anterior frontal, temporal, and middle parieto-occipital lobes) and Gamma frequency bands show greater activation during emotion cognition in diverse cultural groups.},
  archive      = {J_TCSS},
  author       = {Xinrong Gong and C. L. Philip Chen and Tong Zhang},
  doi          = {10.1109/TCSS.2023.3298324},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2014-2025},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Cross-cultural emotion recognition with EEG and eye movement signals based on multiple stacked broad learning system},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple knowledge-enhanced meteorological social briefing
generation. <em>TCSS</em>, <em>11</em>(2), 2002–2013. (<a
href="https://doi.org/10.1109/TCSS.2023.3298252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent meteorological disasters present new challenges for decision-making in disaster response. As a timely and effective source of intelligent information, social media plays a vital role in detecting and monitoring these situations. Meteorological social briefings summarize valuable information from numerous social media posts, providing essential decision-support services. This article proposes a multi-knowledge-enhanced summarization (MKES) model for automatically generating meteorological social briefing content from multiple Sina Weibo posts. The MKES model consists of a summary generation module and a knowledge enhancement module. The knowledge enhancement module guides and constrains the summary generation process using meteorological events and geographical location knowledge, resulting in summaries that focus on describing specific knowledge from the source text. The MKES model outperforms baseline models in content evaluation, as measured by $\text {ROUGE-1}$ , $\text {ROUGE-2}$ , and $\text {ROUGE-L}$ scores, and in sentiment evaluation, as measured by $F_{1}$ scores. Based on the MKES model, a framework for generating meteorological social briefings is developed, providing decision support services for the China Meteorological Administration (CMA).},
  archive      = {J_TCSS},
  author       = {Kaize Shi and Xueping Peng and Hao Lu and Yifan Zhu and Zhendong Niu},
  doi          = {10.1109/TCSS.2023.3298252},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {2002-2013},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Multiple knowledge-enhanced meteorological social briefing generation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Delanalty minimization with reinforcement learning in
UAV-aided mobile network. <em>TCSS</em>, <em>11</em>(2), 1991–2001. (<a
href="https://doi.org/10.1109/TCSS.2023.3283016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV)-assisted mobile communication has been studied in recent years. UAVs can be used as aerial base stations (BSs) to improve the performance of terrestrial mobile network. In this article, mobile data offloading with UAV trajectory optimization is investigated. To tackle with the delay of requesting data and the immediacy of requested data at the same time, a new metric named delanalty is newly proposed. The delanalty metric jointly considers the delay of user requesting data, the immediacy of requested data file, and the quantity of residual requesting data. A find max delanalty user mechanism is proposed to eliminate the user who has the largest delay time. Furthermore, an actor–critic (AC)-based deep reinforcement learning (DRL) algorithm called AC -based delanalty trajectory optimization (ACDTO) algorithm is proposed to solve UAV’s trajectory optimization problem. Simulation results show that the proposed ACDTO algorithm can find an optimal flight trajectory with minimal delanalty for all users.},
  archive      = {J_TCSS},
  author       = {Fan-Hsun Tseng and Yu-Jung Hsieh},
  doi          = {10.1109/TCSS.2023.3283016},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1991-2001},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Delanalty minimization with reinforcement learning in UAV-aided mobile network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Calibration of transformer-based models for identifying
stress and depression in social media. <em>TCSS</em>, <em>11</em>(2),
1979–1990. (<a href="https://doi.org/10.1109/TCSS.2023.3283009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s fast-paced world, the rates of stress and depression present a surge. People use social media for expressing their thoughts and feelings through posts. Therefore, social media provide assistance for the early detection of mental health conditions. Existing methods mainly introduce feature extraction approaches and train shallow machine learning (ML) classifiers. For addressing the need of creating a large feature set and obtaining better performance, other research studies use deep neural networks or language models based on transformers. Despite the fact that transformer-based models achieve noticeable improvements, they cannot often capture rich factual knowledge. Although there have been proposed a number of studies aiming to enhance the pretrained transformer-based models with extra information or additional modalities, no prior work has exploited these modifications for detecting stress and depression through social media. In addition, although the reliability of a machine learning (ML) model’s confidence in its predictions is critical for high-risk applications, there is no prior work taken into consideration the model calibration. To resolve the above issues, we present the first study in the task of depression and stress detection in social media, which injects extra-linguistic information in transformer-based models, namely, bidirectional encoder representations from transformers (BERT) and MentalBERT. Specifically, the proposed approach employs a multimodal adaptation gate for creating the combined embeddings, which are given as input to a BERT (or MentalBERT) model. For taking into account the model calibration, we apply label smoothing. We test our proposed approaches in three publicly available datasets and demonstrate that the integration of linguistic features into transformer-based models presents a surge in performance. Also, the usage of label smoothing contributes to both the improvement of the model’s performance and the calibration of the model. We finally perform a linguistic analysis of the posts and show differences in language between stressful and nonstressful texts, as well as depressive and nondepressive posts.},
  archive      = {J_TCSS},
  author       = {Loukas Ilias and Spiros Mouzakitis and Dimitris Askounis},
  doi          = {10.1109/TCSS.2023.3283009},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1979-1990},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Calibration of transformer-based models for identifying stress and depression in social media},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Information dissemination evolution driven by hierarchical
relationship. <em>TCSS</em>, <em>11</em>(2), 1967–1978. (<a
href="https://doi.org/10.1109/TCSS.2023.3293058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are hierarchical characteristics in real society, and people are often divided according to social attributes, such as salary and power. In order to better explore the laws of information dissemination in the network of hierarchical characteristics, this article first abstractly defines three ways of dissemination of information in the network of hierarchical structure. Then, the information dissemination model of the hierarchical network is constructed, and the model reflects the characteristics that the low-class people are willing to receive news from the high-class people, while the high-class people are less willing to the news from the low-class people. Finally, both the simulated data and the real data have concluded that the middle class is the most active in the uniformly distributed hierarchical network; while the lower class is more active in the power-law distributed hierarchical network, which promotes the dissemination of news in the hierarchical network.},
  archive      = {J_TCSS},
  author       = {Fuzhong Nian and Li Luo and Xirui Liu},
  doi          = {10.1109/TCSS.2023.3293058},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1967-1978},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Information dissemination evolution driven by hierarchical relationship},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SiamATTRPN: Enhance visual tracking with channel and spatial
attention. <em>TCSS</em>, <em>11</em>(2), 1958–1966. (<a
href="https://doi.org/10.1109/TCSS.2023.3271115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual tracking is an important research topic in the field of computer vision. The current Siamese tracker based on the region proposal network (SiamRPN) has achieved promising tracking results in terms of efficiency and performance. However, through our empirical study, we have observed that deep features learned by SiamRPN are of substandard quality, as the salient regions within the deep features fail to correspond accurately with meaningful objects. To address this limitation, we propose an approach to enhance the quality of the learned deep features through the incorporation of an attention mechanism. Attention mechanisms have been shown to be effective in distinguishing similar objects, as they suppress background objects while highlighting target information that is most relevant. As a result, a new tracking method with channel and spatial attention termed SiamATTRPN is explored. To verify the effectiveness of SiamATTRPN, experiments on benchmark datasets demonstrate that our proposed tracker outperforms the baseline tracker significantly.},
  archive      = {J_TCSS},
  author       = {Huayue Cai and Xiang Zhang and Long Lan and Liyang Xu and Wenxin Shen and Junyang Chen and Victor C. M. Leung},
  doi          = {10.1109/TCSS.2023.3271115},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1958-1966},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {SiamATTRPN: Enhance visual tracking with channel and spatial attention},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formation and dynamics of donation on social networks in the
post-epidemic era. <em>TCSS</em>, <em>11</em>(2), 1937–1957. (<a
href="https://doi.org/10.1109/TCSS.2023.3289090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The characteristics of donation during the COVID-19 breakout in Shanghai in 2022 are obviously different from those in Wuhan in 2020, and this article aims to explore the formation and dynamics of donation in the post-epidemic era. This article uses the scale-free network to describe the structure of a society. There are four types of players in our model based on reality: donors, illegal beneficiaries, legal beneficiaries, and inactive people. Then, this article gives and explains the benefits of four types of the scale-free network with several innovations. By the pair approximation, this article introduces the proportion of edges starting from some type of players as the population state. Based on the fast and slow system and under the weak selection, this article shows that the evolutionary dynamics of the population can be approximated by the slow system, which is a system of differential equations of the population state. Then, this article defines the equilibrium of the approximate dynamics as the global equilibrium of the population and further defines its stability. Because the analytical expressions of the global equilibrium are very complex, this article analyzes and seeks the influence of various parameters by simulation. Our conclusions reveal the evolutionary characteristics of donation in the post-epidemic era and thus give management suggestions to motivate donations and achieve a better society in different situations.},
  archive      = {J_TCSS},
  author       = {Xian-Jia Wang and Lin-Lin Wang},
  doi          = {10.1109/TCSS.2023.3289090},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1937-1957},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Formation and dynamics of donation on social networks in the post-epidemic era},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Equality or equity? E-CARGO perspectives on the fairness of
education. <em>TCSS</em>, <em>11</em>(2), 1926–1936. (<a
href="https://doi.org/10.1109/TCSS.2023.3276917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The educational equality or equity problem (EEEP) has a long-term debate in civilization. This problem is often discussed by sociologists, philosophers, educationists, and so on for various phenomena or decisions. However, there is hardly any absolutely convincing answer to this question. We believe that a series of quantitative methods may provide decision-makers with a clearer orientation in their discussions and help them make decisions. Therefore, this article depicts a common scenario to discuss the EEEP. It uses quantitative methods to conduct computational social simulations and obtain the results under equal or equitable conditions via role-base collaboration (RBC), environments-classes, agents, roles, groups, and objects (E-CARGO), and group role assignment (GRA). The simulation results show that educational equality or equity can be significantly improved by making a reasonable and optimized allocation plan through GRA. Finding the optimal allocation plan, which validates the reliability of the results by changing the experimental parameters of equality and equity, is helpful and interesting to relevant decision-makers.},
  archive      = {J_TCSS},
  author       = {Peiguang Zhang and Haibin Zhu and Dongning Liu},
  doi          = {10.1109/TCSS.2023.3276917},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1926-1936},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Equality or equity? E-CARGO perspectives on the fairness of education},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A qualitative study of app acquisition and management.
<em>TCSS</em>, <em>11</em>(2), 1907–1925. (<a
href="https://doi.org/10.1109/TCSS.2023.3288562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smartphone users rely on Apps for their daily lives but simultaneously struggle to protect their privacy and device security from potentially harmful and malicious Apps. However, scientific literature lacks in-depth studies mapping user struggles, factors undermining their efforts, and implications. We cover this gap by engaging 24 smartphone users in 44 interview sessions. We observe them performing different App acquisition and management tasks, seek explanations, and analyze collected data to make the following contributions. First, we develop a theoretical App acquisition and management model describing different phenomena involved in App acquisition and management in Android smartphones. Causal conditions of these phenomena and contexts, and intervening conditions influencing user strategies are discovered grounded in the data acquired through the interview sessions. It shows the challenges they face, the strategies they develop and use to deal with the faced challenges, and their consequences. Second, we systematically discover and relate different App acquisition and management concepts in 34 subcategories related to user struggles. None of the existing studies discovers, explains, and relates actual user behaviors involving this many factors in one place. Third, this research discovers six problems unaddressed by the literature: the usage of untrusted App repositories, mandatory and forced installations, the installation process changes, the Settings App complexities, the void contracts problem, and the psychological consequences of failure to protect privacy in Android phones. Finally, we provide general guidelines for users, App stores, developers, and regulators to assist them in enhancing privacy and security protection in the Android ecosystem.},
  archive      = {J_TCSS},
  author       = {Haroon Elahi and Guojun Wang and Wenjun Jiang and Alexandre Bartel and Yves Le Traon},
  doi          = {10.1109/TCSS.2023.3288562},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1907-1925},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A qualitative study of app acquisition and management},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conversational AI: An explication of few-shot learning
problem in transformers-based chatbot systems. <em>TCSS</em>,
<em>11</em>(2), 1888–1906. (<a
href="https://doi.org/10.1109/TCSS.2023.3281492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent advancements in conversational artificial intelligence (AI), the practical applications of chatbots have risen significantly in diverse domains such as healthcare, education, e-government, customer support systems, social platforms, and entertainment. The chatbot converses with humans in natural language and responds to their queries with precise and relevant answers. The relevant literature presents several methods for intent classification and slot mapping for chatbot question answering. However, the existing chatbot architectures still suffer from few-shot learning problem (imbalance ratio of class labels over samples) and ineffective dialog management to retain the context and slots mapping. This study aims to introduce the architecture of chatbot by focusing few-shot learning problem and context management in dialog-based conversations. First, to mitigate the few-shot learning problem with chatbots, we propose a novel hybrid intent and slots transformers (HIST) model. The HIST chatbot architecture utilizes transformers and self-attention mechanisms along with bigated recurrent unit and combines conditional random field algorithms for intent classification and slot extraction. Second, to address dialog management, we introduce a hybrid interaction strategy for slots mapping and effective conversational context management. To validate the proposed model’s effectiveness, comprehensive empirical analysis is carried out using three benchmark datasets including airline travel information system (ATIS), banking77, and conversational language interface for natural conversation 150 (CLINC150). The results show that HIST outperforms against the state-of-the-art existing methods with a clear margin and obtained an accuracy of 94.89% and 96.17% for intent classification and slots extraction, respectively. The empirical results confirm the effectiveness of the HIST chatbot for resolving the few-shot learning problem with effective dialog management in chatbot systems.},
  archive      = {J_TCSS},
  author       = {Muzamil Ahmed and Hikmat Ullah Khan and Ehsan Ullah Munir},
  doi          = {10.1109/TCSS.2023.3281492},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1888-1906},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Conversational AI: An explication of few-shot learning problem in transformers-based chatbot systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The hierarchical clustering of human mobility behaviors.
<em>TCSS</em>, <em>11</em>(2), 1876–1887. (<a
href="https://doi.org/10.1109/TCSS.2023.3281469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human mobility flow prediction forecasts the number of passengers coming into (inflows) or leaving from (outflows) every region of a city. It is crucial for many applications such as mobile marketing or route optimization. People have proposed deep learning methods to predict human mobility flows. However, existing methods neglect the hierarchical nature of human mobility behaviors. Each of us is unique, and we live beyond our neighborhoods. In the process of cross-regional activities, humans migrate in the hierarchical structure of buildings, neighborhoods, regions, cities, and countries. In this article, we propose a predictive framework, hierarchical fuzzy C-means (Hierarchical-FCM)-residual networks (ResNets), to capture the hierarchical structure of human mobility for prediction. First, we offer a Hierarchical-FCM clustering algorithm that is trained to learn the relationship between proximity and road network hierarchically on large human mobility data. Second, we design a fusion model to incorporate the knowledge learned from hierarchical clusters into deep ResNets to improve prediction accuracy. We compare our framework with 25 existing state-of-the-art models, ranging from traditional time-series and machine learning predictors, such as ARIMA and RNN, to the latest deep learning methods designed for human mobility prediction, such as ST-ResNets and DeepST. Our framework outperforms all existing models, by a margin of 2%–68% in terms of prediction accuracy, showing its effectiveness. We are among the first to incorporate the hierarchical structure of human mobility into location clustering for human mobility flow prediction. We empirically show that incorporating such knowledge significantly improves prediction performance.},
  archive      = {J_TCSS},
  author       = {Wenzhen Jia and Kai Zhao and Shengjie Zhao},
  doi          = {10.1109/TCSS.2023.3281469},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1876-1887},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {The hierarchical clustering of human mobility behaviors},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A general framework for account risk rating on ethereum:
Toward safer blockchain technology. <em>TCSS</em>, <em>11</em>(2),
1865–1875. (<a href="https://doi.org/10.1109/TCSS.2023.3263382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the largest blockchain platform that supports smart contracts, Ethereum has attracted wide attention from both academia and industry in recent years. Along with the prosperous development of Ethereum, the high-risk illegal practices on it are becoming more and more rampant, seriously jeopardizing the system’s trading security and long-term development. Therefore, the detection and quantification of account risk are of great importance for both cryptocurrency investors and blockchain security researchers. In this article, we propose the first general framework for account risk rating on Ethereum, which includes a devisable suspiciousness metric to adapt to various illicit fraud detection and a network propagation mechanism to formulate the relations between accounts and transactions. By conducting extensive experiments on a real-world dataset from Ethereum, we show the universality of the account risk rating framework. Particularly, statistical analyses on different risk levels of accounts demonstrate that the risk rating framework has access to detect various illicit accounts. And the metric analysis of risk rating results put forward some insights. Moreover, visualization of a suspicious transaction chain reveals the process of illicit activities on Ethereum, enabling investors to obtain an understanding of the risky accounts and avoid significant financial losses.},
  archive      = {J_TCSS},
  author       = {Qishuang Fu and Dan Lin and Jiajing Wu and Zibin Zheng},
  doi          = {10.1109/TCSS.2023.3263382},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1865-1875},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A general framework for account risk rating on ethereum: Toward safer blockchain technology},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). JargonFM: A framework with multiple interpretation modes for
jargon understanding in online communities. <em>TCSS</em>,
<em>11</em>(2), 1853–1864. (<a
href="https://doi.org/10.1109/TCSS.2023.3281674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Jargon words are commonly used in the communication of online communities. These words are characterized by special and implicit meanings that can only be comprehended by a small group of users, which brings challenges to community regulation and user engagement. For this problem, we present JargonFM, a framework with multiple interpretation modes for jargon understanding in online communities. JargonFM is designed based on the scientific explanation framework and supports three interpretation modes: jargon category prediction based on a jargon classifier, similar word identification based on a jargon synonyms selector, and representative text selection based on an example sentence selector. A jargon interpreter was also implemented to demonstrate the usage and usefulness of the interpretation framework. Automatic and human evaluations suggest that JargonFM can explain jargon words more accurately and more efficiently than the existing interpretation methods, leading to its wide acceptance among the evaluation participants.},
  archive      = {J_TCSS},
  author       = {Zhengqing Guan and Peng Zhang and Hansu Gu and Tun Lu and Baoxi Liu and Ning Gu},
  doi          = {10.1109/TCSS.2023.3281674},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1853-1864},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {JargonFM: A framework with multiple interpretation modes for jargon understanding in online communities},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HostileNet: Multilabel hostile post detection in hindi.
<em>TCSS</em>, <em>11</em>(2), 1842–1852. (<a
href="https://doi.org/10.1109/TCSS.2023.3244014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we deal with the task of hostile post detection in Hindi. The objective is to predict whether a social media post is hostile or not. Furthermore, if the post is hostile, we identify one or more fine-grained hostile dimensions out of the following four—fake, hate, offensive, and defamation. We propose HostileNet , a novel deep-learning framework that leverages HindiBERT-based contextual representations and hand-crafted features like lexicon, emoticon, and hashtag embeddings for hostile post classification. Moreover, we also propose a novel mechanism to fine-tune HindiBERT’s attention vectors with respect to each hostile dimension. We evaluate HostileNet on the CONSTRAINT-2021 shared task dataset on hostile post detection in Hindi for both coarse-grained (hostile versus nonhostile) and fine-grained (fake versus hate versus offensive versus defamation) setups. HostileNet outperforms the best-performing system as reported in the CONSTRAINT-2021 shared task for both the setups. Furthermore, we provide a thorough analysis of the obtained results in the form of an ablation study, error analysis, attention heatmap analysis, lexicon feature analysis, and so on. We also perform in-the-wild evaluation and conduct a user survey to assess the robustness of our proposed model. We make the code and the curated multilabel hostile lexicon available for research use at https://github.com/LCS2-IIITD/HostileNet .},
  archive      = {J_TCSS},
  author       = {Mohit Bhardwaj and Megha Sundriyal and Manjot Bedi and Md Shad Akhtar and Tanmoy Chakraborty},
  doi          = {10.1109/TCSS.2023.3244014},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1842-1852},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {HostileNet: Multilabel hostile post detection in hindi},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting k-vertex cuts in sparse networks via a fast local
search approach. <em>TCSS</em>, <em>11</em>(2), 1832–1841. (<a
href="https://doi.org/10.1109/TCSS.2023.3238042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ${k}$ -vertex cut ( ${k}$ -VC) problem belongs to the family of the critical node detection problems, which aims to find a minimum subset of vertices whose removal decomposes a graph into at least ${k}$ connected components. It is an important NP-hard problem with various real-world applications, e.g., vulnerability assessment, carbon emissions tracking, epidemic control, drug design, emergency response, network security, and social network analysis. In this article, we propose a fast local search (FLS) approach to solve it. It integrates a two-stage vertex exchange strategy based on neighborhood decomposition and cut vertex, and iteratively executes operations of addition and removal during the search. Extensive experiments on both intersection graphs of linear systems and coloring/DIMACS graphs are conducted to evaluate its performance. Empirical results show that it significantly outperforms the state-of-the-art (SOTA) algorithms in terms of both solution quality and computation time in most of the instances. To evaluate its generalization ability, we simply extend it to solve the weighted version of the ${k}$ -VC problem. FLS also demonstrates its excellent performance.},
  archive      = {J_TCSS},
  author       = {Yangming Zhou and Gezi Wang and MengChu Zhou},
  doi          = {10.1109/TCSS.2023.3238042},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1832-1841},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Detecting k-vertex cuts in sparse networks via a fast local search approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Link-backdoor: Backdoor attack on link prediction via node
injection. <em>TCSS</em>, <em>11</em>(2), 1816–1831. (<a
href="https://doi.org/10.1109/TCSS.2023.3260833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction, inferring the undiscovered or potential links of the graph, is widely applied in the real world. By facilitating labeled links of the graph as the training data, numerous deep learning-based link prediction methods have been studied, which have dominant prediction accuracy compared with nondeep methods. However, the threats of maliciously crafted training graphs will leave a specific backdoor in the deep model; thus, when some specific examples are fed into the model, it will make a wrong prediction, defined as a backdoor attack. It is an important aspect that has been overlooked in the current literature. In this article, we prompt the concept of a backdoor attack on link prediction and propose Link-Backdoor to reveal the training vulnerability of the existing link prediction methods. Specifically, the Link-Backdoor combines the fake nodes with the nodes of the target link to form a trigger. Moreover, it optimizes the trigger by the gradient information from the target model. Consequently, the link prediction model trained on the backdoored dataset will predict the link with a trigger to the target state. Extensive experiments on five benchmark datasets and five well-performing link prediction models demonstrate that the Link-Backdoor achieves the state-of-the-art attack success rate under both the white box (i.e., available of the target model parameter) and the black box (i.e., unavailable of the target model parameter) scenarios. In addition, we testify the attack under the defensive circumstance, and the results indicate that the Link-Backdoor still can construct a successful attack on the well-performing link prediction methods. The code and data are available at https://github.com/Seaocn/Link-Backdoor .},
  archive      = {J_TCSS},
  author       = {Haibin Zheng and Haiyang Xiong and Haonan Ma and Guohan Huang and Jinyin Chen},
  doi          = {10.1109/TCSS.2023.3260833},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1816-1831},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Link-backdoor: Backdoor attack on link prediction via node injection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative meta-path modeling for explainable
recommendation. <em>TCSS</em>, <em>11</em>(2), 1805–1815. (<a
href="https://doi.org/10.1109/TCSS.2023.3243939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although recommender systems have achieved considerable success, sometimes it is difficult to convince users due to the failure to explain the recommendation results. For this reason, explainable recommender systems have drawn a lot of attention in recent years. Among explainable recommendation models, the meta-path-based model plays a significant role because it can reason over the path connecting a user–item pair to achieve explainability. However, it is difficult for the meta-path-based model to achieve such a common explanation in collaborative filtering as “a user similar to you has purchased item $A$ ” because there is no such meta-path. In this article, we contribute a new model named collaborative meta-path modeling for explainable recommendation (COMPER). It models the similarity of user pairs and item pairs through rating information and constructs collaborative meta-paths for explainability. In addition, we design an attention mechanism to aggregate different paths connecting the target user and the target item. Moreover, the information of the subgraph composed of all paths connecting the target user and the target item is integrated for rating prediction. Extensive experiments on five real-world datasets demonstrate that COMPER achieves good performance in a variety of scenarios, achieving improvements over several baselines.},
  archive      = {J_TCSS},
  author       = {Zhe-Rui Yang and Zhen-Yu He and Chang-Dong Wang and Jian-Huang Lai and Zhihong Tian},
  doi          = {10.1109/TCSS.2023.3243939},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1805-1815},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Collaborative meta-path modeling for explainable recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NUS: Noisy-sample-removed undersampling scheme for
imbalanced classification and application to credit card fraud
detection. <em>TCSS</em>, <em>11</em>(2), 1793–1804. (<a
href="https://doi.org/10.1109/TCSS.2023.3243925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since minority samples are substantially less common than majority samples, many industrial applications, such as credit card fraud detection (CCFD) and defective part identification, call for imbalanced classification. The performance of a classifier tends to suffer from the noisy samples in majority or minority classes. This work proposes a new undersampling scheme, called a clustering-based noisy-sample-removed undersampling scheme (NUS) for imbalanced classification. The majority class samples are first clustered. The distance of the majority class sample from the cluster center that is furthest away is used as the radius to build a hypersphere, with each cluster’s center assumed to be a spherical center. We determine the Euclidean distance between the center of a cluster and each minority sample to find whether they are in the hypersphere or not. Afterward, we exclude noisy samples from the minority class. The noisy samples of majority classes are removed by using the same procedure. Second, we propose an NUS, which combines noisy sample removal with undersampling techniques. Finally, to prove the effectiveness of NUS, we integrate NUS with the basic classifiers random forest (RF), decision tree (DT), and logistics regression (LR). We conduct their comparison with seven undersampling, oversampling, and noisy-sample-removed methods. This work performs experiments on 13 public and three real transaction datasets related to e-commerce. The results show that NUS plays a positive role in promoting existing classifiers’ performance.},
  archive      = {J_TCSS},
  author       = {Honghao Zhu and MengChu Zhou and Guanjun Liu and Yu Xie and Shijun Liu and Cheng Guo},
  doi          = {10.1109/TCSS.2023.3243925},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1793-1804},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {NUS: Noisy-sample-removed undersampling scheme for imbalanced classification and application to credit card fraud detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BiCapsHate: Attention to the linguistic context of hate via
bidirectional capsules and hatebase. <em>TCSS</em>, <em>11</em>(2),
1781–1792. (<a href="https://doi.org/10.1109/TCSS.2023.3236527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social media (OSM) communications sometimes turn into hate-filled and offensive comments or arguments. It not just disrupts the social fabric online, but also leads to hate, violence, and crime, in the real physical world in worst scenarios. The existing content moderation practices of OSM platforms often fail to control the online hate. In this article, we develop a deep learning model called BiCapsHate to detect hate speech (HS) in OSM posts. The model consists of five layers of deep neural networks. It starts with an input layer to process the input text and follows on to an embedding layer to embed the text into a numeric representation. A BiCaps layer then learns the sequential and linguistic contextual representations, a dense layer prepares the model for final classification, and lastly the output layer produces the resulting class as either hate or non-HS (NHS). The BiCaps layer, being the most important component, effectively learns the contextual information with respect to different orientations in both forward and backward directions of the input text via capsule networks. It is further aided by our rich set of hand-crafted shallow and deep auxiliary features including the Hatebase lexicon, making the model well-informed. We conduct extensive experiments on five benchmark datasets to demonstrate the efficacy of the proposed BiCapsHate model. In the overall results, we outperform the existing state-of-the-art methods including fBERT, HateBERT, and ToxicBERT. BiCapsHate achieves up to 94% and 92% f-score on balanced and imbalanced datasets, respectively. Our complete source code is publicly available at GitHub repository https://github.com/Ashraf-Kamal/BiCapsHate .},
  archive      = {J_TCSS},
  author       = {Ashraf Kamal and Tarique Anwar and Vineet Kumar Sejwal and Mohd Fazil},
  doi          = {10.1109/TCSS.2023.3236527},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1781-1792},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {BiCapsHate: Attention to the linguistic context of hate via bidirectional capsules and hatebase},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computational experiments for complex social systems—part
III: The docking of domain models. <em>TCSS</em>, <em>11</em>(2),
1766–1780. (<a href="https://doi.org/10.1109/TCSS.2023.3243894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Powered by advanced information technology, more and more complex systems are exhibiting characteristics of the cyber–physical–social systems (CPSS). In consideration of the cost, legal, and institutional constraints on the study of CPSS in real world, computational experiments have emerged as a new method for quantitative analysis of CPSS. However, with the increase of application scenarios, how to map complex and diverse domain models to artificial society models has become a key challenge to hinder the wide use of computational experiments. In this article, the docking framework between the domain model and the artificial society model was proposed in this article, and the model docking specification is given from three aspects: the agent model, the environmental model, and the rules model. In addition, the effectiveness of the framework was verified by two classic cases: artificial stock market and epidemic prevention and control. The result showed that the proposed model docking framework can provide technical support for the multidisciplinary applications of computational experiments and significantly reduce the difficulty of using the method.},
  archive      = {J_TCSS},
  author       = {Xiao Xue and Xiangning Yu and Deyu Zhou and Chao Peng and Xiao Wang and Donghua Liu and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3243894},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1766-1780},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Computational experiments for complex social Systems—Part III: The docking of domain models},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Enforced block diagonal graph learning for multikernel
clustering. <em>TCSS</em>, <em>11</em>(2), 1753–1765. (<a
href="https://doi.org/10.1109/TCSS.2023.3234181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing multikernel graph clustering (MKGC) methods have emerged with notable success on nonlinear clustering tasks since the graph learning can effectively capture graph structure similarity between sample pair. Ideally, a high-quality graph should enjoy the good block diagonal property, i.e., the intercluster similarities correspond to zeros, while intracluster similarities represent nonzeros. Meanwhile, the number of diagonal blocks for a graph equals to the number of clusters on the dataset. However, most of the existing MKGC methods design a corpulent three-parts graph leaning process that poses challenges for hyperparameter tuning, time cost, and clustering performance. To overcome these challenging issues, we propose an enforced block diagonal graph learning for multikernel clustering (EBDGL-MKC) method, where we pursue a high-quality block diagonal graph via well-designed one-part graph leaning scheme rather than three parts. Inspired by symmetric matrix factorization (SMF), we first design a one-part block diagonal graph learning scheme to learn multiple block diagonal graphs, by exploring an explicit theoretical connection between the clustering partition of kernel $k$ -means and the excellent block diagonal graph. Then, these block diagonal graphs are stacked into a low-rank tensor for exploiting the high-order structure information hidden in the nonlinear data. After that, an effective alternate algorithm with convergence proof is performed on extensive experiments to demonstrate the superiority of EBDGL compared with the state-of-the-art multikernel clustering (MKC) methods.},
  archive      = {J_TCSS},
  author       = {Xingfeng Li and Yinghui Sun and Quansen Sun and Zhenwen Ren},
  doi          = {10.1109/TCSS.2023.3234181},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1753-1765},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Enforced block diagonal graph learning for multikernel clustering},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extraction of emergency elements and business process model
of urban rail transit plans. <em>TCSS</em>, <em>11</em>(2), 1744–1752.
(<a href="https://doi.org/10.1109/TCSS.2023.3235338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergency plan of the urban rail transit (URT) system is a guiding document for dealing with emergencies and formulating emergency plans. However, the emergency plan text described in natural language has some problems, such as poor visibility and enforceability. Effective help is difficult to provide for the rapid implementation of emergency response. Therefore, obtaining key emergency task information from the emergency response plan and visualizing the emergency disposal workflow are the main challenges. In this article, we propose a method of extracting emergency elements (EELs) from emergency plans and constructing a business process model. First, a nested entity extraction model incorporating adversarial training is proposed to extract EELs from the complex sentences in the emergency plan text. Second, the EELs are combined into emergency task units, and then the relations between emergency task units are identified to form the emergency task sequence flow, which is stored in matrix form. Finally, the emergency disposal workflow model is generated based on the emergency task sequence flow and the BPMN modeling method. Taking the actual emergency plan text as an example, the process from the extraction of EELs to the construction of the disposal workflow model is demonstrated. Experimental results prove that this method has advantages in comprehensively extracting EELs, visualizing the emergency disposal workflow, and improving the enforceability of emergency plans.},
  archive      = {J_TCSS},
  author       = {Guangyu Zhu and Rongzheng Yang and Edmond Q. Wu and Rob Law},
  doi          = {10.1109/TCSS.2023.3235338},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1744-1752},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Extraction of emergency elements and business process model of urban rail transit plans},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TrajSGAN: A semantic-guiding adversarial network for urban
trajectory generation. <em>TCSS</em>, <em>11</em>(2), 1733–1743. (<a
href="https://doi.org/10.1109/TCSS.2023.3235923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulating human mobility contributes to city behavior discovery and decision-making. Although the sequence-based and image-based approaches have made impressive achievements, they still suffer from respective deficiencies such as omitting the depiction of spatial properties or ordinal dependency in trajectory. In this article, we take advantage of the above two paradigms and propose a semantic-guiding adversarial network (TrajSGAN) for generating human trajectories. Specifically, we first devise an attention-based generator to yield trajectory locations in a sequence-to-sequence manner. The encoded historical visits are queried with semantic knowledge (e.g., travel modes and trip purposes) and their important features are enhanced by the multihead attention mechanism. Then, we designate a rollout module to complete the unfinished trajectory sequence and transform it into an image that can depict its spatial structure. Finally, a convolutional neural network (CNN)-based discriminator signifies how “real” the trajectory image looks, and its output is regarded as a reward signal to update the generator by the policy gradient. Experimental results show that the proposed TrajSGAN model significantly outperforms the benchmarks under the MTL-Trajet mobility dataset, with the divergence of spatial-related metrics such as radius of gyration and travel distance reduced by 10%–27%. Furthermore, we apply the real and synthetic trajectories, respectively, to simulate the COVID-19 epidemic spreading under three preventive actions. The coefficient of determination metric between real and synthetic results achieves 91%–98%, indicating that the synthesized data from TrajSGAN can be leveraged to study the epidemic diffusion with an acceptable difference. All of these results verify the superiority and utility of our proposed method.},
  archive      = {J_TCSS},
  author       = {Gang Xiong and Zhishuai Li and Meihua Zhao and Yu Zhang and Qinghai Miao and Yisheng Lv and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3235923},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1733-1743},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {TrajSGAN: A semantic-guiding adversarial network for urban trajectory generation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Topic-aware information coverage maximization in social
networks. <em>TCSS</em>, <em>11</em>(2), 1722–1732. (<a
href="https://doi.org/10.1109/TCSS.2023.3243936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization (IM) aims to identify a set of nodes $S$ to maximize the expected number of nodes influenced during the information propagation starting from $S$ . Some works had extended this problem to be topic-aware, where each node is associated with a topic distribution and tends to be activated with different probabilities by different topics. However, whether it is topic-aware or not, IM problem only focuses on the active nodes and overlooks all the inactive ones. Actually, an inactive node may receive the information from their active in-neighbors and become informed. Therefore, this type of nodes should also be considered when measuring the coverage of information propagation. Inspired by this, we formulate a new problem called topic-aware information coverage maximization (TAICM), which aims to maximize the sum of the expected number of both active and informed nodes in topic-aware social networks. Then we devise a heuristic method to solve it. Experiments on three real-world datasets demonstrate that our method can achieve similar or higher information coverage in much less or at least acceptable time than some commonly used IM algorithms.},
  archive      = {J_TCSS},
  author       = {Zhihang Li and Hongwei Du and Xiang Li},
  doi          = {10.1109/TCSS.2023.3243936},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1722-1732},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Topic-aware information coverage maximization in social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A privacy-aware and incremental defense method against
GAN-based poisoning attack. <em>TCSS</em>, <em>11</em>(2), 1708–1721.
(<a href="https://doi.org/10.1109/TCSS.2023.3263241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is usually utilized as a fraud detection framework in the domain of financial risk management, which promotes the model accuracy without training data exchange. One of the challenges in federated learning is the GAN-based poisoning attack. The GAN-based poisoning attack is a type of intractable poisoning attack that causes global model accuracy degradation and privacy leak. Most of the existing defenses for GAN-based poisoning attack have the three problems: 1) dependence on validation datasets; 2) incompetence of dealing with incremental poisoning attack; and 3) privacy leak. To address the above problems, we present a privacy-aware and incremental defense (PID) method to detect malicious participants and protect privacy. In PID, we design a method to accumulate the offset of model parameters from participants in all current epochs to represent the moving tendency for model parameters. Thus, we can distinguish the adversaries from normal participants based on the accumulations in this incremental poisoning attack. We also use multiple trust domains to reduce the rate of misjudging benign participants as adversaries. Moreover, a differentiated differential privacy is utilized before the global model sending to protect the privacy of participants’ training datasets in PID. The experiments conducted on two real-world datasets under financial fraud detection scenario demonstrate that the PID reduces the fallout of adversaries detection (the rate of misjudging benign participants as adversaries) by at least 51.1% and improve the speed of detecting all malicious participants by at least 33.4% compared with two popular defense methods. Besides, the privacy preserving of PID is also effective.},
  archive      = {J_TCSS},
  author       = {Feifei Qiao and Zhong Li and Yubo Kong},
  doi          = {10.1109/TCSS.2023.3263241},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1708-1721},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A privacy-aware and incremental defense method against GAN-based poisoning attack},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying washtrading cases in NFT sales networks.
<em>TCSS</em>, <em>11</em>(2), 1696–1707. (<a
href="https://doi.org/10.1109/TCSS.2023.3319554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Washtrading is a serious issue prevailing in nonfungible token (NFT) markets. Most current attempts to identify washtrading incidents use graph methods on transaction graphs to identify cyclical patterns. However, the intensive computational requirements hinder the practical applicability of the methods, and the single-level identification limits our view of the overall scope of the issue. In this article, we discuss the unique challenges of identifying washtrading scenarios in NFT markets and propose a solution that finds closed cycles in transaction graphs to identify potential washtrading cases at four different levels. Our identification method provides a measure of washtrading prevalence in the Nifty Gateway (NG) NFT market with approaches for evaluation that relay a measure of reliability that can be applied in other NFT markets. Acknowledging the newness of washtrading issues in NFT markets, we hope that the current study opens doors for new attempts to further investigate the problem and provide efficient and effective solutions to combat the issue.},
  archive      = {J_TCSS},
  author       = {Nargess Tahmasbi and Guohou Shan and Aaron M. French},
  doi          = {10.1109/TCSS.2023.3319554},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1696-1707},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Identifying washtrading cases in NFT sales networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multiinterest and social interest-field framework for
financial security. <em>TCSS</em>, <em>11</em>(2), 1685–1695. (<a
href="https://doi.org/10.1109/TCSS.2023.3252611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online payment has become an influential method of transaction. While improving convenience, this method of payment also brings great financial risks. Prevalidating transactions can be effective in reducing the number of frauds. For this reason, recommendation algorithms have been introduced to measure the credibility of transactions by predicting users’ ratings of items. However, most algorithms deal with the relationships in social networks without distinction, mixing positive and negative information into the recommender system, which brings huge noise. And, they only generate a single interest representation for each user to measure the similarity between users and spread interest, ignoring the diversity of user interests. Moreover, they did not consider the propagation of different interests would be different. In this article, we propose a multiinterest and social interest-field framework (MISIF) for social recommendations in financial security, which introduces capsule networks into social recommendation and extends the traditional single-interest representation to user multiinterest embedding by dynamic routing (DR) and other methods to improve the expressiveness of user embedding. After that, we construct social interest fields to integrate social interests based on multiinterest embedding, which alleviates the noise in social networks and user data sparsity problems. Finally, we aggregate user multiinterest embedding and additional information through neural networks to obtain the final prediction scores. Experiments with three publicly available datasets show that our proposed MISIF framework outperforms the state-of-the-art social recommendation methods.},
  archive      = {J_TCSS},
  author       = {Qin Zhao and Jingyi Huang and Gang Liu and Yaru Miao and Pengwei Wang},
  doi          = {10.1109/TCSS.2023.3252611},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1685-1695},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A multiinterest and social interest-field framework for financial security},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transductive semi-supervised metric network for reject
inference in credit scoring. <em>TCSS</em>, <em>11</em>(2), 1675–1684.
(<a href="https://doi.org/10.1109/TCSS.2023.3276274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit scoring is an essential technique for credit risk management in the financial industry. However, most credit scoring models face the challenge of reject inference, which refers to the lack of post-loan performance data for rejected applicants, leading to sample selection bias and inaccurate credit assessment. Traditional credit scoring methods tackle this issue by assuming that the missing labels for rejected samples are missing at random (MAR) and by measuring sample similarity directly in the original feature space. Nevertheless, these strategies are not suitable for real-world business scenarios. Inspired by metric learning and transductive learning, we propose a novel credit scoring model called transductive semi-supervised metric network (TSSMN), which formalizes reject inference as a semi-supervised binary classification problem with the prior assumption of missing not at random (MNAR). TSSMN consists of two interconnected modules: the embedding metric network (EMN) that maps samples from the original feature space to the metric space for similarity measurement, and the transductive propagation network (TPN) that performs label propagation based on sample similarity. We evaluate TSSMN on a real-world credit dataset and compare it with traditional credit scoring methods. The results indicate that TSSMN can overcome sample selection bias and more accurately classify credit applicants. Therefore, TSSMN has the potential to enhance credit risk assessment in real-world business scenarios.},
  archive      = {J_TCSS},
  author       = {Zhiyu Guo and Xiang Ao and Qing He},
  doi          = {10.1109/TCSS.2023.3276274},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1675-1684},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Transductive semi-supervised metric network for reject inference in credit scoring},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchain-enabled intelligent IoT protocol for
high-performance and secured big financial data transaction.
<em>TCSS</em>, <em>11</em>(2), 1667–1674. (<a
href="https://doi.org/10.1109/TCSS.2023.3268592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent era, the communication network with the support of many wireless technologies is giving benefits for remote access. Such a communication model increases the flexibility for data storage with the management of network resources efficiently with the integration of the Internet of Things (IoT). Although, the industrial Internet of Things (IIoT) has enabled the development of numerous machine learning-based solutions to provide real-time applications. However, most of the solutions are not prepared to cope with heterogeneous services and the huge amount of device data in the digital world. Furthermore, conducting financial transactions over the Internet raises several security issues. Such restrictions compromise the sensitive data of financial institutions and also degrade the trust of network users in the system. Thus, this article presents a secured blockchain model for high-performance computing in a big data environment, which aims to protect the business activities for financial interaction with intelligent services of software-defined network (SDN) architecture. First, to keep the security credentials, the SDN controller creates an association between the IoT devices and maintains local and global records. Second, the machine learning approach is explored using reliable and fault-tolerant methods to support the network scalability and extract the updated routing information for transmitting financial data. The proposed protocol also provides data integrity with a high level of network availability and copes with the financial security of big data by investigating cryptographic approaches. Our proposed protocol is tested using simulation, and various experiments are performed to show its efficacy in terms of network throughput, computing overhead, data delay, response time, and dropped packets as compared to tunicate swarm algorithm-based optimized routing mechanism (TORM) and RouteChain.},
  archive      = {J_TCSS},
  author       = {Tanzila Saba and Khalid Haseeb and Amjad Rehman and Gwanggil Jeon},
  doi          = {10.1109/TCSS.2023.3268592},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1667-1674},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Blockchain-enabled intelligent IoT protocol for high-performance and secured big financial data transaction},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-chain digital asset system for secure trading and
payment. <em>TCSS</em>, <em>11</em>(2), 1654–1666. (<a
href="https://doi.org/10.1109/TCSS.2023.3241065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain as a ledger technology is attractive without the need for central servers. There are many types of blockchains in different fields, such as digital asset trading and payment, which have business interactions. In the fields, the digital asset and payment information on their blockchains need to be securely cooperative with each other. However, some business activities are on different blockchains, which have different consensus algorithms and network architectures, thus limiting the interoperability among these activities and making each blockchain an island. Cross-chain technology can connect different blockchains and realize the interoperability and sharing of information among them. This work designs a cross-chain digital asset system for secure trading and payment. It builds two parallel chains, i.e., digital asset chain (DAC) and payment chain (PC), and their functions are analyzed and designed. The cross-chain, i.e., relay chain (RC), is used to realize cross-chain interoperability, where the cross-chain message format and authority setting are designed to endow parallel chains with the ability to recognize. The decentralized characteristic of the RC allows cross-chain messages to be safely transmitted to ensure secure trading and payment. Through testing and analysis, the proposed system can provide more secure trading and payment than its peers.},
  archive      = {J_TCSS},
  author       = {Peiyun Zhang and Xiaoqi Hua and Haibin Zhu},
  doi          = {10.1109/TCSS.2023.3241065},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1654-1666},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Cross-chain digital asset system for secure trading and payment},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Portfolio optimization: A return-on-equity network analysis.
<em>TCSS</em>, <em>11</em>(2), 1644–1653. (<a
href="https://doi.org/10.1109/TCSS.2023.3261881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes return-on-equity (ROE) networks for portfolio optimization, which integrate the DuPont analysis and graph theory. Portfolio diversification is interpreted as follows: An intercluster relationship of the network structure diversifies business models, whereas an innercluster relationship variegates different industries. The proposed approach is applied to the Chinese stock market. It shows that, in terms of the annualized return, the ROE network optimized portfolio reached 13.20% compared with 6.02% of the Shanghai Stock Exchange (SSE) Composite Index. It also shows that portfolios with 100–200 stocks, which are composed of the top 10%–20% ROE stocks, reached the highest return-risk efficiency.},
  archive      = {J_TCSS},
  author       = {Xiangzhen Yan and Hanchao Yang and Zhongyuan Yu and Shuguang Zhang and Xianrong Zheng},
  doi          = {10.1109/TCSS.2023.3261881},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1644-1653},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Portfolio optimization: A return-on-equity network analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Monetary policy, investor sentiment, and the asymmetric
jump risk of chinese stock market. <em>TCSS</em>, <em>11</em>(2),
1631–1643. (<a href="https://doi.org/10.1109/TCSS.2023.3234430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To investigate the impacts of monetary policies on the jump risk of Chinese stock market, we introduce them into an exponential generalized autoregressive conditional heteroskedasticity with autoregressive jump intensity (EGARCH-ARJI) model. A new jump model, i.e., the EGARCH-ARJI model with monetary policy (EGARCH-AM), is constructed. Moreover, investor sentiment is considered to investigate the interaction effect of a monetary policy and investor sentiment on the jump intensity. Results show that the announcement of an interest rate policy has significantly positive effect on it, while the effects of the announcement and implementation of a required reserve ratio policy are not significant. In addition, the interaction effect of an interest rate policy and investor sentiment on the jump intensity is positive. The interaction effect of the announcement of a required reserve ratio policy and investor sentiment is negative. The interaction effect of the implementation of a required reserve ratio policy and investor sentiment does not exist. The research results are of guiding significance for policy makers and investors to fully learn the time-varying volatility and jump risk of stock markets.},
  archive      = {J_TCSS},
  author       = {Jia Wang and Pu Chen and Jiacun Wang and Xiwang Guo and Xu Wang},
  doi          = {10.1109/TCSS.2023.3234430},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1631-1643},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Monetary policy, investor sentiment, and the asymmetric jump risk of chinese stock market},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fraud feature boosting mechanism and spiral oversampling
balancing technique for credit card fraud detection. <em>TCSS</em>,
<em>11</em>(2), 1615–1630. (<a
href="https://doi.org/10.1109/TCSS.2023.3242149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the flourishing of the credit card business and Internet technology, the risk of fraudulent credit card transactions is ever-increasing due to the complex information involved in the credit card business. Since the high redundancy of feature information and imbalance of class distribution in transaction data, the performance of the existing machine learning-based models for detecting credit card fraudulent transactions still needs to be improved. Therefore, it is crucial to build fraud detection models for effective feature engineering and sampling techniques. This article proposes a credit card fraud detection model incorporating a fraud feature-boosting mechanism with a spiral oversampling balancing technique (SOBT). Specifically, we present a compound grouping elimination strategy to exclude highly redundant and correlated features from the credit card transaction dataset and improve the data quality. Furthermore, we design a multifactor synchronous embedding mechanism, which combines the performance evaluation metrics of the embedding model for each feature and improves the decision-making ability of each feature for the target domain. Moreover, we propose an SOBT to balance the ratio of legitimate to fraudulent transactions, which improves the ability of the fraud detection model to distinguish legitimate from fraudulent transactions. Extensive experimental results based on two real-world datasets demonstrate that our methods can facilitate efficient credit card fraud detection and achieve better performance than state-of-the-art methods.},
  archive      = {J_TCSS},
  author       = {Lina Ni and Jufeng Li and Huixin Xu and Xiangbo Wang and Jinquan Zhang},
  doi          = {10.1109/TCSS.2023.3242149},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1615-1630},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Fraud feature boosting mechanism and spiral oversampling balancing technique for credit card fraud detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging adversarial augmentation on imbalance data for
online trading fraud detection. <em>TCSS</em>, <em>11</em>(2),
1602–1614. (<a href="https://doi.org/10.1109/TCSS.2023.3240968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the emergence of online trading greatly facilitates people’s life. Meanwhile, online trading also brings hidden dangers, such as online fraudulent trading. To solve the issue, researchers have proposed many different detection models. However, in actual business scenarios, fraudulent transactions usually only account for a small portion of normal transactions, resulting in extremely imbalanced data. Besides, the concealment of fraud is reflected in that the fraudsters are imitating the normal transactions of users, posing a huge challenge for fraudulent transaction detection modeling. Inspired by generative adversarial networks (GANs), we propose a GAN-based framework to detect online banking fraud on extremely imbalanced data, called BalanceGAN. A fraud detection model is first pretrained using the data generated by the generator and then the model is fine-tuned using transfer learning on real-world datasets, by using this approach to address data imbalances. Compared with the conventional methods for solving imbalanced data, our BalanceGAN can avoid over-fitting of the model relatively, experiments on two real datasets show that our BalanceGAN has more than 10% performance improvement in Precision and Recall.},
  archive      = {J_TCSS},
  author       = {Hu Teng and Cheng Wang and Qing Yang and Xue Chen and Rui Li},
  doi          = {10.1109/TCSS.2023.3240968},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1602-1614},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Leveraging adversarial augmentation on imbalance data for online trading fraud detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UBRMTC: User behavior recognition model with transaction
character. <em>TCSS</em>, <em>11</em>(2), 1589–1601. (<a
href="https://doi.org/10.1109/TCSS.2023.3257227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavior analysis has been used widely in antifraud transactions. However, existing methods of behavior analysis mainly focus on behavior patterns and do not fully consider the behavior psychology of users in the transaction process, which affects the precise recognition of fraudulent behaviors. It is difficult to recognize fraudulent transactions precisely how to describe the user’s behavioral psychology and integrate the behavioral psychology into the transaction behavior. Thus, this article first proposes the transaction character model based on the user’s cautiousness to reflect the user’s behavioral psychology. This model is built from the user’s historical normal interaction behavior data. Then, a user behavior benchmark is established to reflect the user’s behavior pattern from the user’s historical normal transaction behavior data. To integrate the user’s transaction character and user behavior, the mapping relationship model is built by using the least-squares generalized inverse method. This model is the core of the fraudulent behavior recognition method with transaction characters. Experiments in fraud detection scenarios show that the new method improved the average recognition performance of four fraud detection indicators (recall rate, precision rate, accuracy rate, and F1 value) by 23%. The method also shows that individual psychological character has a great influence on user behavior.},
  archive      = {J_TCSS},
  author       = {Zhaohui Zhang and Ziming Wei and Lina Ma},
  doi          = {10.1109/TCSS.2023.3257227},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1589-1601},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {UBRMTC: User behavior recognition model with transaction character},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). DeFiScanner: Spotting DeFi attacks exploiting logic
vulnerabilities on blockchain. <em>TCSS</em>, <em>11</em>(2), 1577–1588.
(<a href="https://doi.org/10.1109/TCSS.2022.3228122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of decentralized financial (DeFi), the total value locked (TVL) in DeFi continues to increase. A big number of adversaries exploit logic vulnerabilities to attack DeFi applications for profit, such as flash loan attacks and price manipulation attacks. However, the current vulnerability detection tools for smart contracts cannot be directly used to detect the logic vulnerabilities generated by the combination of different protocols. How to characterize and detect DeFi attacks that exploited logic vulnerabilities is a big challenge. In this work, we propose a deep-learning-based attack detection system on DeFi, called DeFiScanner, in which we design a novel neural network that includes a global model, a local model, and a fusion model to characterize DeFi attacks. First, the unstructured emitted events are automatically and efficiently normalized. Second, the transaction-related features of normalized emitted events are enriched with the global model and the semantic features of emitted events are extracted with the local model. Finally, the transaction-related features and the semantic features of emitted events are fused efficiently with the fusion model to detect DeFi attacks. We collect a dataset that consists of 50910 real-world DeFi transactions on Ethereum (ETH). The extensive experimental results demonstrate the effectiveness of DeFiScanner. The true positive rate (TPR) and the area under the receiver operating characteristic (ROC) curve of the system reach 0.91 and 0.97, respectively.},
  archive      = {J_TCSS},
  author       = {Bin Wang and Xiaohan Yuan and Li Duan and Hongliang Ma and Bin Wang and Chunhua Su and Wei Wang},
  doi          = {10.1109/TCSS.2022.3228122},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1577-1588},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {DeFiScanner: Spotting DeFi attacks exploiting logic vulnerabilities on blockchain},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multiperspective fraud detection method for
multiparticipant e-commerce transactions. <em>TCSS</em>, <em>11</em>(2),
1564–1576. (<a href="https://doi.org/10.1109/TCSS.2022.3232619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection and prevention of fraudulent transactions in e-commerce platforms have always been the focus of transaction security systems. However, due to the concealment of e-commerce, it is not easy to capture attackers solely based on the historic order information. Many works try to develop technologies to prevent frauds, which have not considered the dynamic behaviors of users from multiple perspectives. This leads to an inefficient detection of fraudulent behaviors. To this end, this article proposes a novel fraud detection method that integrates machine learning and process mining models to monitor real-time user behaviors. First, we establish a process model concerning the business-to-customer (B2C) e-commerce platform, by incorporating the detection of user behaviors. Second, a method for analyzing abnormalities that can extract important features from event logs is presented. Then, we feed the extracted features to a support vector machine (SVM)-based classification model that can detect fraud behaviors. We demonstrate the effectiveness of our method in capturing dynamic fraudulent behaviors in e-commerce systems through the experiments.},
  archive      = {J_TCSS},
  author       = {Wangyang Yu and Yadi Wang and Lu Liu and Yisheng An and Bo Yuan and John Panneerselvam},
  doi          = {10.1109/TCSS.2022.3232619},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1564-1576},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A multiperspective fraud detection method for multiparticipant E-commerce transactions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A scalable RF-XGBoost framework for financial fraud
mitigation. <em>TCSS</em>, <em>11</em>(2), 1556–1563. (<a
href="https://doi.org/10.1109/TCSS.2022.3209827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning offers the ability to analyze large financial data and extract hidden knowledge for anomalous patterns. In the current study, we propose an ensemble machine learning framework using eXtreme Gradient Boosting (XGBoost) and random forest for the detection of financial frauds. The model used an adaptive synthetic (ADASYN) algorithm over sampling technique with out-of-bag scoring on a grid search algorithm for the 11 input features. We tested our framework with IEEE-CIS fraud detection benchmark dataset from Kaggle. The performance metrics were F1-Score = 0.9982, area under curve = 0.9999, recall = 1.0, precision = 0.9965, and accuracy = 0.9999. A detailed comparison with state-of-the-art techniques, such as decision tree, logistic regression, gradient boosting, and particle swarm optimization models, shows scalability and robustness of the framework.},
  archive      = {J_TCSS},
  author       = {Isaac Kofi Nti and Arjun Remadevi Somanathan},
  doi          = {10.1109/TCSS.2022.3209827},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1556-1563},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A scalable RF-XGBoost framework for financial fraud mitigation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guest editorial: Special issue on big data and computational
social intelligence for guaranteed financial security. <em>TCSS</em>,
<em>11</em>(2), 1551–1555. (<a
href="https://doi.org/10.1109/TCSS.2024.3373929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The innovations in technologies have led to the emergence of digital finance such as online payment, online insurance, online lending, and supply chain finance. Digital finance has greatly facilitated people’s lives, accelerated the circulation of capital in various fields, and enhanced the vitality of financial markets. However, it exposes many increasing risks and hidden dangers such as stock volatility, trading fraud, credit card fraud, and privacy leakage [1] , [2] , [3] , [4] , [5] , [6] , [7] . How to effectively calculate, control, manage, and utilize financial big data and make full use of artificial intelligence technology to ensure financial security is an important research question. Solving it faces many challenges. These challenges not only include the complexity of data and computation but also the effectiveness of intelligent optimization algorithms and ways to deal with human behaviors and social environments [8] , [9] .},
  archive      = {J_TCSS},
  author       = {Changjun Jiang and Fei-Yue Wang and Mengchu Zhou and Asoke K. Nandi and Guanjun Liu},
  doi          = {10.1109/TCSS.2024.3373929},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1551-1555},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Guest editorial: Special issue on big data and computational social intelligence for guaranteed financial security},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sora for computational social systems: From counterfactual
experiments to artificiofactual experiments with parallel intelligence.
<em>TCSS</em>, <em>11</em>(2), 1531–1550. (<a
href="https://doi.org/10.1109/TCSS.2024.3373928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Welcome to the second issue of IEEE Transactions on Computational Social Systems (TCSS) of 2024. This issue showcases an impressive array of 104 regular papers alongside our Special Issue on Big Data and Computational Social Intelligence for Guaranteed Financial Security, highlighting cutting-edge research aimed at harnessing big data and computational techniques to fortify financial security amidst the digital finance evolution. With a focus on addressing the intricate challenges of financial big data, enhancing the efficacy of artificial intelligence, and covering critical topics from data mining to digital currencies, this issue underscores the vital role of cross-disciplinary efforts in mitigating financial security risks.},
  archive      = {J_TCSS},
  author       = {Rui Qin and Fei-Yue Wang and Xiaolong Zheng and Qinghua Ni and Juanjuan Li and Xiao Xue and Bin Hu},
  doi          = {10.1109/TCSS.2024.3373928},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {4},
  number       = {2},
  pages        = {1531-1550},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Sora for computational social systems: From counterfactual experiments to artificiofactual experiments with parallel intelligence},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint gaussian distribution and attention for time-aware
recommendation systems. <em>TCSS</em>, <em>11</em>(1), 1517–1526. (<a
href="https://doi.org/10.1109/TCSS.2023.3315756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential models have achieved admirable success in recommendation systems. However, most sequential models typically only consider the chronological order of items through timestamps and ignore the relative distances in the sequence, which weakens the temporal relationships between items. To address this issue, we propose a temporal recommendation system using the Gaussian distribution and attention mechanism, which considers the sequentiality and interaction among items. Technically, we first deploy the word vector space along the time dimension as sequence features. Then, we use the Gaussian process to effectively represent the duration influence of items and the context interaction between items as high-level features. Finally, an innovative attention mechanism is used to capture the hidden correlation relationships between representation subspaces of different levels of features. Experiments conducted on two widely used real public datasets show that our model outperforms the state-of-the-art recommendation systems.},
  archive      = {J_TCSS},
  author       = {Runqiang Zang and Meiyun Zuo and Rong Ma},
  doi          = {10.1109/TCSS.2023.3315756},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1517-1526},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Joint gaussian distribution and attention for time-aware recommendation systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Measuring spatiotemporal civil war dimensions using
community-based dynamic network representation (CoDNet). <em>TCSS</em>,
<em>11</em>(1), 1506–1516. (<a
href="https://doi.org/10.1109/TCSS.2023.3241173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Civil war exhibits complex geospatial trends over time, which may be missed by models that rely on count-based operationalizations. Here, the spatial and temporal correlation values of monthly civil war events are transformed into their influence degree symbol, which measures geospatial concentration, spread, and intensity of civil war. We then measure variation in these degrees over time to identify relevant spatiotemporal civil war aspects. The network model is constructed using 0.5 degree grid locations as nodes, counting nearby and over time connections. We then extract the temporal community structure behind the data. We use ground-truth data to visualize how our measures correlate with observed patterns, thereby illustrating our method provides accurate depictions of geospatial civil war dynamics. We also evaluate the impact of several indicators highlighted by past research and our community-based spatiotemporal measures and comparing it to the preprocessed count indicator. Our findings indicate that the relationship between state capacity and climate stress show opposite correlations with civil war as those identified by studies that use count-based indicators. Counterintuitively, our results show that conflict intensifies and spreads in locations where the state is stronger and where climate conditions are improved.},
  archive      = {J_TCSS},
  author       = {Didier A. Vega-Oliveros and Ore Koren},
  doi          = {10.1109/TCSS.2023.3241173},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1506-1516},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Measuring spatiotemporal civil war dimensions using community-based dynamic network representation (CoDNet)},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting offensive language based on graph attention
networks and fusion features. <em>TCSS</em>, <em>11</em>(1), 1493–1505.
(<a href="https://doi.org/10.1109/TCSS.2023.3250502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pervasiveness of offensive language on social networks has caused adverse effects on society, such as abusive behavior online. It is urgent to detect offensive language and curb its spread. In the popular datasets, the distribution of users and tweets is imbalanced, which limits the generalization ability of the model. In addition, existing research shows that methods with community information extracted from the social graphs effectively improve the performance of offensive language detection. However, the existing models deal with social graphs independently, which seriously affects the effectiveness of detection models. In this article, we release a new dataset with users and social relationships. To encode community information, we construct the social graphs based on the user historical behavior information and social relationships. Moreover, we propose a model based on graph attention networks (GATs) and fusion features for offensive language detection (GF-OLD). Specifically, the community information is directly captured by the GAT module, and the text embeddings are taken from the last hidden layer of bidirectional encoder representation from transformer (BERT). Attention mechanisms and position encoding are used to fuse these features. Our method outperforms baselines with the F1-score of 89.94%. The results show that our model effectively learns the potential information of social graphs and text, and user historical behavior information is more suitable for user attribute in the social graphs.},
  archive      = {J_TCSS},
  author       = {Zhenxiong Miao and Xingshu Chen and Haizhou Wang and Rui Tang and Zhou Yang and Tiemai Huang and Wenyi Tang},
  doi          = {10.1109/TCSS.2023.3250502},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1493-1505},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Detecting offensive language based on graph attention networks and fusion features},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Multidocument aspect classification for aspect-based
abstractive summarization. <em>TCSS</em>, <em>11</em>(1), 1483–1492. (<a
href="https://doi.org/10.1109/TCSS.2023.3252723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidocument aspect-based summarization (AspSumm) aims to generate focused summaries based on the target aspects from a cluster of relevant documents. Generating such summaries can better satisfy readers’ specific points of interest, as readers may have different concerns about the same articles. However, previous methods usually generate aspect-based summaries based on the given aspects without using the relationship among aspects to assist in the summarization. In this work, we propose a two-stage general framework for multidocument AspSumm. The model first discovers the latent relationship among aspects and then uses relevant sentences selected by aspect discovery to generate abstractive summaries. We exploit latent dependencies among aspects using a tag mask training (TMT) strategy, which increases the interpretability of the model. In addition to improvements in summarization over aspect-based strong baselines, experimental results show that our proposed model can accurately discover multidomain aspects on the WikiAsp dataset.},
  archive      = {J_TCSS},
  author       = {Ye Wang and Yingmin Zhou and Mengzhu Wang and Zhenghan Chen and Zhiping Cai and Junyang Chen and Victor C. M. Leung},
  doi          = {10.1109/TCSS.2023.3252723},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1483-1492},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Multidocument aspect classification for aspect-based abstractive summarization},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). The impact of network structure on knowledge adoption: A
network text analysis on knowledge-sharing platforms. <em>TCSS</em>,
<em>11</em>(1), 1467–1482. (<a
href="https://doi.org/10.1109/TCSS.2023.3255588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the public has increasingly relied on online knowledge-sharing platforms as credible and valuable sources to acquire information and knowledge. This work employed the network text analysis approach to explore the determinants of knowledge adoption from a structural perspective. First, we proposed a quantitative method to measure knowledge adoption behavior on a collective level based on the knowledge network. Then, we discussed knowledge concept adoption and knowledge relationship adoption. To build knowledge networks and analyze their structural features, this work collected 74761 knowledge concepts from the Zhihu platform and 62368 knowledge concepts in the Stack Overflow platform. The regression analysis results showed that the structural characteristics of knowledge concepts and knowledge relationships substantially affect their adoption. This study advances our understanding of knowledge adoption in an online knowledge-sharing platform and provides a structural analysis approach to large-scale online content data.},
  archive      = {J_TCSS},
  author       = {Yongning Li and Ye Wu and Lun Zhang and Jiawei Chen},
  doi          = {10.1109/TCSS.2023.3255588},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1467-1482},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {The impact of network structure on knowledge adoption: A network text analysis on knowledge-sharing platforms},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incentive mechanism in the sponsored content market with
network effects. <em>TCSS</em>, <em>11</em>(1), 1460–1466. (<a
href="https://doi.org/10.1109/TCSS.2023.3257233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an incentive mechanism for the sponsored content provider (CP) market in which the communication of users can be represented by a graph, and the private information of the users is assumed to have a continuous distribution function. The CP stipulates incentive rewards to encourage users to reveal their private information truthfully and increase their content demand, which leads to an increase in the advertising revenue. We prove that all users gain a nonnegative utility and disclose their private information truthfully. Moreover, we study the effectiveness and scalability of the proposed mechanism in a case study with different network structures.},
  archive      = {J_TCSS},
  author       = {Mina Montazeri and Pegah Rokhforoz and Hamed Kebriaei and Olga Fink},
  doi          = {10.1109/TCSS.2023.3257233},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1460-1466},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Incentive mechanism in the sponsored content market with network effects},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Flexible dual-branch siamese network: Learning location
quality estimation and regression distribution for visual tracking.
<em>TCSS</em>, <em>11</em>(1), 1451–1459. (<a
href="https://doi.org/10.1109/TCSS.2023.3235649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor-free based trackers introduce an extra branch in addition to classification and regression branches in the network to achieve comparable performance with anchor-based trackers. This extra branch is usually trained independently in the training phase and is used in combination with other branches in the inference phase. However, this can increase the inconsistency between the inference phase and the training phase, potentially degrading the tracking performance. To address this problem, we propose a new Siamese network-based object tracking framework that eliminates this inconsistency by unifying classification and additional branch tasks to achieve learning location quality estimation. Furthermore, regression tasks for bounding boxes are widely formulated based on Dirac $\delta $ distribution. Though this assumption works well for many scenarios, it restricts the prediction of regression branches. To overcome this restriction, we propose discretizing the continuous offset of the regression branch into multiple offset predictions, which enables the network to learn more flexible distributions automatically. Meanwhile, the discrete distribution prediction of regression branches is utilized to further guide the classification of the trackers. Extensive experiments on the widely accepted benchmarks demonstrate the effectiveness and efficiency of the proposed model.},
  archive      = {J_TCSS},
  author       = {Shuo Hu and Sien Zhou and Jinbo Lu and Hui Yu},
  doi          = {10.1109/TCSS.2023.3235649},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1451-1459},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Flexible dual-branch siamese network: Learning location quality estimation and regression distribution for visual tracking},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A recognizable expression line portrait synthesis method in
portrait rendering robot. <em>TCSS</em>, <em>11</em>(1), 1440–1450. (<a
href="https://doi.org/10.1109/TCSS.2023.3241003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An artistic line portrait robot can generate, process, and draw line portraits. Compared to real face images, line portraits lose some recognizable information. Maintaining recognizability during the process of expression edition of line portraits is an important challenge for artistic portrait robots. A recognizable expression line portrait synthesis method based on a triangle coordinate system (TCS) is proposed. First, based on public facial expression databases [JAFFE, Oulu CASIA, RaFD, and Cohn-Kanade (CK)], by studying the feature deviations between different expressions of the same person, an expression deformation constraint criterion (EDCC) that is conducive to maintaining recognizable features is proposed. Then, by comparing features between the source line portrait and reference expression portrait, the expression features are calculated. Finally, under the EDCC, based on expression features, a recognizable expression line portrait is generated through image topological deformation based on TCS. In addition, we can synthesize different degrees of expression line portraits. On the public face datasets (FHHQ, CelebA-HQ, and CK), we implemented qualitative and quantitative contrast experiments. Experimental results demonstrate that this method can automatically synthesize an expression line portrait with reference expression, where the expression degree of the reference expression is controllable, and the generated expression portrait still has high recognizability. The expression samples generated by the proposed method are used for face authentication on the CK dataset, and only 0.22% of the samples fail to pass the authentication.},
  archive      = {J_TCSS},
  author       = {Xiaoli Dong and Xin Ning and Jian Xu and Lina Yu and Weijun Li and Liping Zhang},
  doi          = {10.1109/TCSS.2023.3241003},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1440-1450},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A recognizable expression line portrait synthesis method in portrait rendering robot},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A prompt-based topic-modeling method for depression
detection on low-resource data. <em>TCSS</em>, <em>11</em>(1),
1430–1439. (<a href="https://doi.org/10.1109/TCSS.2023.3260080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression has a large impact on one’s personal life, especially during the COVID-19 pandemic. People have been trying to develop reliable methods for the depression detection task. Recently, methods based on deep learning have attracted much attention from the research community. However, they still face the challenge that data collection and annotation are difficult and expensive. In many real-world applications, only a small number of or even no training data are available. In this context, we propose a Prompt-based Topic-modeling method for Depression Detection (PTDD) on low-resource data, aiming to establish an effective way of depression detection under the above challenging situation. Instead of learning discriminating features from a small amount of labeled data, the proposed framework turns to leverage the generalization power of pretrained language models. Specifically, based on the question-and-answer routine during the interview, we first reorganize the text data according to the predefined topics for each interviewee. Via the prompt-based framework, we then predict whether the next-sentence prompt is emotionally positive or not. Finally, the depression detection task can be achieved based on the obtained topicwise predictions through a simple voting process. In the experiments, we validate the effectiveness of our model under several low-resource data settings. The results and analysis demonstrate that our PTDD achieves acceptable performance when only a few training samples or even no training samples are available.},
  archive      = {J_TCSS},
  author       = {Yanrong Guo and Jilong Liu and Lei Wang and Wei Qin and Shijie Hao and Richang Hong},
  doi          = {10.1109/TCSS.2023.3260080},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1430-1439},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A prompt-based topic-modeling method for depression detection on low-resource data},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient and autonomous planning scheme for deploying
IoT services in fog computing: A metaheuristic-based approach.
<em>TCSS</em>, <em>11</em>(1), 1415–1429. (<a
href="https://doi.org/10.1109/TCSS.2023.3254922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fog computing paradigm is a promising concept to overcome the exponential increase in data volume in Internet of Things (IoT) applications. This paradigm can support delay-sensitive IoT applications by extending cloud services to the network edge. However, fog computing faces challenges such as resource allocation for applications at the network edge due to limited resources as well as its heterogeneous and distributed nature. This is in line with the goals of microservice architecture and develops the placement of microservice-based IoT applications. The IoT service placement problem (SPP) on fog nodes is known as non-deterministic polynomial-time (NP)-hard. In this study, we introduce a meta-heuristic approach named SPP-differential evolution algorithm (DEA) to handle SPP, which originates from the DEA with a shared parallel architecture. The proposed method takes advantage of the scalable and deployable nature of microservices to minimize the resource utilization and delay as much as possible. SPP-DEA is developed based on monitoring, analysis, decision-making, and execution with knowledge bas (MADE-k) autonomous planning model with the aim of compromise between service cost, response time, resource utilization, and throughput. In order to address the computational complexity of the problem, we consider the resource consumption distribution and service deployment priority in the placement process. In order to evaluate the quality of placement in SPP-DEA, extensive experiments have been performed on a synthetic fog environment. The simulation results show that compared to the state-of-the-art approaches, SPP-DEA reduces the service cost and waiting time by 16% and 11%, respectively.},
  archive      = {J_TCSS},
  author       = {Zhen Lin and Liming Lu and Jianping Shuai and Hong Zhao and Ali Shahidinejad},
  doi          = {10.1109/TCSS.2023.3254922},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1415-1429},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An efficient and autonomous planning scheme for deploying IoT services in fog computing: A metaheuristic-based approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantitatively interpreting residents happiness prediction
by considering factor–factor interactions. <em>TCSS</em>,
<em>11</em>(1), 1402–1414. (<a
href="https://doi.org/10.1109/TCSS.2023.3246181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring the high-effect factors of residents’ happiness is good for a wide range of policy-making for economics and politics in most countries. Limited to the concerns of sociologists, previous efforts manually predefined the relationship among multifactors to analyze the factor–factor interactions with high interpretability by regression models. Recently, deep learning methods show great promising prediction accuracy by automatically learning additive interaction between factors, while it meets the challenges of interpretability. To this end, an unbiased post-hoc and model-agnostic method is promising to quantitatively interpret the results of the happiness prediction model. Thus, this article proposes a novel solution based on the deep neural network (DNN) and the Shapley value to compute the factor–factor interactions in different coalitions based on coalitional game theory. Aiming at evaluating the pairwise interactions interpretability quality of our solution, experiments are conducted on the Chinese General Social Survey (CGSS) and European Social Survey (ESS) questionnaire datasets. By systematic reviews, the experimental results are highly consistent with academic studies in social science. Analyzed by different factor categories, the new finding is that some factors, e.g., body mass index (BMI) and social media, play a crucial role in happiness prediction but are rarely considered in social science studies. Specifically, there are some heavy interactions across multicategories, such as personal information (health and age) with economics (insurance and income). Therefore, this solution can theoretically support the implications of social decision-making.},
  archive      = {J_TCSS},
  author       = {Lin Li and Xiaohua Wu and Miao Kong and Jinhang Liu and Jianwei Zhang},
  doi          = {10.1109/TCSS.2023.3246181},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1402-1414},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Quantitatively interpreting residents happiness prediction by considering Factor–Factor interactions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive semantic mining framework for heterogeneous
information network embedding. <em>TCSS</em>, <em>11</em>(1), 1384–1401.
(<a href="https://doi.org/10.1109/TCSS.2023.3260118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information network (HIN) embedding aims to map heterogeneous nodes to the low-dimensional vector space. The existing embedding models cannot determine the optimal length of semantics automatically and reveal full semantic information adaptively for different heterogeneous networks. To address this challenge, an HIN embedding model with adaptive semantic mining is proposed. First, we project heterogeneous nodes into the same space and aggregate the features of target types in the first-degree range. Then, the semantics of different node types is combined through the attention mechanism, and latent meta-paths are mined using the attention coefficients. Finally, multiple feature aggregation layers are stacked with residual blocks. The residual weights control the proportion of semantics transferred between layers to aggregate more distal features selectively. In addition, we designed the Selected DropLink unit to remove links which transfer negative information, which can further improve the resistance of model to over-smoothing. Experiments show that our model can obtain more accurate embedding results and can automatically mine complex semantic connections between heterogeneous nodes without prior definition of meta-path and semantic depth.},
  archive      = {J_TCSS},
  author       = {Hao Shao and Rangang Zhu and Hui Liu and Lunwen Wang},
  doi          = {10.1109/TCSS.2023.3260118},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1384-1401},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An adaptive semantic mining framework for heterogeneous information network embedding},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FDGNN: Feature-aware disentangled graph neural network for
recommendation. <em>TCSS</em>, <em>11</em>(1), 1372–1383. (<a
href="https://doi.org/10.1109/TCSS.2023.3259983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering (CF) is dedicated to learning the representations of users and items based on interactive data. Regrettably, the lack of fine-grained modeling of interactive motivation makes the model less interpretable. A feasible solution is to combine the disentangling idea with the graph neural network (GNN) and capture different types of interaction relationships by using a message propagation mechanism on the graph of user–item interaction. However, this process typically relies on the disentangling of users’ hidden intents, ignoring the significance of item features to user engagement. This fact leads to the inadequate interpretability of existing models. To make up for the deficiency, this article proposes a new feature-aware disentangled GNN (FDGNN) for the recommendation. By learning the relationship between user behavior and important features of items, the model aims to achieve better recommendation performance and model interpretability. In the end, we first realize the feature partition based on mutual information and then design an attention-based graph disentangling model to realize the fine-grained disentangling of user intents. In addition, to further ensure the independence of the disentangled intents, we augment the model with disagreement regularization. Through multilayer embedding propagation, FDGNN can display a capture CF effect in feature semantics. The interpretability and efficiency of our proposed approach are demonstrated by numerous pertinent experiments.},
  archive      = {J_TCSS},
  author       = {Xiao Liu and Shunmei Meng and Qianmu Li and Qiyan Liu and Qiang He and Dharavath Ramesh and Lianyong Qi},
  doi          = {10.1109/TCSS.2023.3259983},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1372-1383},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {FDGNN: Feature-aware disentangled graph neural network for recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Centralized CNN–GRU model by federated learning for COVID-19
prediction in india. <em>TCSS</em>, <em>11</em>(1), 1362–1371. (<a
href="https://doi.org/10.1109/TCSS.2023.3250656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2019, the corona virus was found in Wuhan, China. The corona virus has traveled several countries in the world from the beginning of 2020. The early estimation of COVID-19 cases is one of the efficient approaches to control the pandemic. Many researchers had proposed the deep learning model for the efficient estimation of COVID-19 cases for different provinces in the world. The research work had not focused on the discussion of robustness in the model. In this study, centralized federated-convolutional neural network–gated recurrent unit (Fed-CNN–GRU) model is proposed for the estimation of active cases per day in different provinces of India. In India, the uneven transmission of COVID-19 virus was seen in 36 provinces due to the different geographical areas and population densities. So, the methodology of this study had focused on the development of single deep learning algorithm, which is robust and reliable to estimate the active cases of COVID-19 in different provinces of India. The concept of transfer and federated learning is involved to enhance the estimation of active cases of COVID-19 by the CNN–GRU model. The study had considered the active cases per day dataset for 36 provinces in India from 12 March, 2020 to 17 January, 2022. Based on the study, it is proven that the centralized CNN–GRU model by federated learning had captured the transmission dynamics of COVID-19 in different provinces with an enhanced result.},
  archive      = {J_TCSS},
  author       = {Mredulraj S. Pandianchery and V. Sowmya and E. A. Gopalakrishnan and Vinayakumar Ravi and K. P. Soman},
  doi          = {10.1109/TCSS.2023.3250656},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1362-1371},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Centralized CNN–GRU model by federated learning for COVID-19 prediction in india},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel framework to forecast COVID-19 incidence based on
google trends search data. <em>TCSS</em>, <em>11</em>(1), 1352–1361. (<a
href="https://doi.org/10.1109/TCSS.2023.3255256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global outbreak of coronavirus disease 2019 (COVID-19) has spread to more than 200 countries worldwide, leading to severe health and socioeconomic consequences. As such, the topic of monitoring and predicting epidemics has been attracting a lot of interest. Previous work reported search volumes from Google Trends are beneficial in decoding influenza dynamics, implying its potential for COVID-19 prediction. Therefore, a predictive model using the Wiener methods was built based on epidemic-related search queries from Google Trends, along with climate variables, aiming to forecast the dynamics of the weekly COVID-19 incidence in Washington, DC, USA. The Wiener model, which shares the merits of interpretability, low computation costs, and adaptation to nonlinear fluctuations, was used in this study. Models with multiple sets of features were constructed and further optimized by the highest weight selecting strategy. Furthermore, comparisons to the other two commonly used prediction models based on the autoregressive integrated moving average (ARIMA) and long short-term memory (LSTM) were also performed. Our results showed the predicted COVID-19 trends significantly correlated with the actual (rho = 0.88, $p &amp;lt; 0.0001$ ), outperforming those with ARIMA and LSTM approaches, indicating Google Trends data as a useful tool in terms of COVID-19 prediction. Also, the model using 20 search queries with the highest weighting outperformed all other models, supporting the highest weight feature selection as a feasible criterion. Google Trends search query data can be used to forecast the outbreak of COVID-19, which might assist health policymakers to allocate health care resources and taking preventive strategies.},
  archive      = {J_TCSS},
  author       = {Yining Wang and Wenbin Shi and Yuxuan Sun and Chien-Hung Yeh},
  doi          = {10.1109/TCSS.2023.3255256},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1352-1361},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A novel framework to forecast COVID-19 incidence based on google trends search data},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attitude-based intuitionistic fuzzy graph model for conflict
resolution with soft consensus: Application to dam construction
projects. <em>TCSS</em>, <em>11</em>(1), 1339–1351. (<a
href="https://doi.org/10.1109/TCSS.2023.3244720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Construction of dam projects built on international rivers usually faces many conflicts due to different interests, values, and preferences of social entities. The graph model for conflict resolution (GMCR) is a powerful and flexible tool to model and analyze strategic conflicts. In this study, we introduce a GMCR model to address construction conflicts among different social entities. To process uncertain and vague information in preferences, this study allows decision-makers to use intuitionistic fuzzy information to express their preference information. First, we define necessary definitions, including the intuitionistic relative certainty of preference (IRCP), intuitionistic satisficing threshold (IST), and intuitionistic unilateral improvement (IUI). When using a graph model to represent real-world disputes, a decision-maker (DM) may have different attitudes toward other DMs. To analyze the influence of attitudes, we originally introduced the concept of soft consensus in GMCR. Then, three kinds of attitudes, i.e., positive attitude, neutral attitude, and negative attitude, are identified. Next, we propose four intuitionistic stability definitions considering the attitudes of DMs. Finally, an illustrative example regarding the Xayaburi Dam dispute that occurred in Indochina Peninsula is provided to demonstrate the applicability of the proposed model.},
  archive      = {J_TCSS},
  author       = {Ming Tang and Huchang Liao},
  doi          = {10.1109/TCSS.2023.3244720},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1339-1351},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Attitude-based intuitionistic fuzzy graph model for conflict resolution with soft consensus: Application to dam construction projects},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vaccine hesitancy hotspots in africa: An insight from
geotagged twitter posts. <em>TCSS</em>, <em>11</em>(1), 1325–1338. (<a
href="https://doi.org/10.1109/TCSS.2023.3236368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many social media users express concerns about vaccines and their side effects on Twitter. These concerns lead to a compromise of confidence which brings about vaccine hesitancy. In Africa, vaccine hesitancy is a major challenge faced by health policymakers in the fight against COVID-19. Given that most tweets are geotagged, clustering them according to their sentiments could help identify locations that may likely experience vaccine hesitancy for health policy and planning. In this study, we collected 70000 geotagged vaccine-related tweets in nine African countries, from December 2020 to February 2022. The tweets were classified into three sentiment classes—positive, negative, and neutral. The quality of the classification outputs was achieved using Naíve Bayes (NB), logistic regression (LR), support vector machines (SVMs), decision tree (DT), and K-nearest neighbor (KNN) machine learning classifiers. The LR achieved the highest accuracy of 71% with an average area under the curve of 85%. The point-based location technique was used to calculate the hotspots based on the locations of the classified tweets. Locations with green, red, and gray backgrounds on the map signify a hotspot for positive, negative, and neutral sentiments. The outcome of this research shows that discussions on social media can be analyzed to identify hotspots during a disease outbreak, which could inform health policy in planning and management of vaccine hesitancy in Africa.},
  archive      = {J_TCSS},
  author       = {Blessing Ogbuokiri and Ali Ahmadi and Zahra Movahedi Nia and Bruce Mellado and Jiahong Wu and James Orbinski and Ali Asgary and Jude Kong},
  doi          = {10.1109/TCSS.2023.3236368},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1325-1338},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Vaccine hesitancy hotspots in africa: An insight from geotagged twitter posts},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Detecting depression with heterogeneous graph neural
network in clinical interview transcript. <em>TCSS</em>, <em>11</em>(1),
1315–1324. (<a href="https://doi.org/10.1109/TCSS.2023.3263056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression has an intense impact on individuals, yet many cases go undiagnosed. Thus, it is imperative to design an effective model for the automated diagnosis of depression. However, existing methods do not adequately capture contextual information in a clinical interview. Inspired by the depression diagnosis process, we propose a new perspective on detecting depression as a dialog information extraction task. Specifically, this article constructs a heterogeneous graph that models the participant’s depression state and uses the graph attention network to aggregate the pieces of depressive clues. In addition, we use the focal loss as a loss function for dealing with class imbalance by reshaping the standard cross-entropy loss. Experimental results demonstrate that our proposed model depression state extraction with heterogeneous graph attention neural network (DSE-HGAT) surpasses the baseline models on the Distress Analysis Interview Corpus-Wizard of Oz (DAIC-WOZ) dataset. Meanwhile, agreement analysis between our proposed model and the gold standard shows that it is moderate ( $k$ = 0.528, $p 0.05$ ). Overall, our model is very effective in identifying depression in the clinical interview transcript, which has the potential to assist doctors with medical conditions.},
  archive      = {J_TCSS},
  author       = {Mingzheng Li and Xiao Sun and Meng Wang},
  doi          = {10.1109/TCSS.2023.3263056},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1315-1324},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Detecting depression with heterogeneous graph neural network in clinical interview transcript},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An overview of advanced deep graph node clustering.
<em>TCSS</em>, <em>11</em>(1), 1302–1314. (<a
href="https://doi.org/10.1109/TCSS.2023.3242145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph data have become increasingly important, and graph node clustering has emerged as a fundamental task in data analysis. In recent years, graph node clustering has gradually moved from traditional shallow methods to deep neural networks due to the powerful representation capabilities of deep learning. In this article, we review some representatives of the latest graph node clustering methods, which are classified into three categories depending on their principles. Extensive experiments are conducted on real-world graph datasets to evaluate the performance of these methods. Four mainstream evaluation performance metrics are used, including clustering accuracy, normalized mutual information, adjusted rand index, and F1-score. Based on the experimental results, several potential research challenges and directions in the field of deep graph node clustering are pointed out. This work is expected to facilitate researchers interested in this field to provide some insights and further promote the development of deep graph node clustering.},
  archive      = {J_TCSS},
  author       = {Shiping Wang and Jinbin Yang and Jie Yao and Yang Bai and William Zhu},
  doi          = {10.1109/TCSS.2023.3242145},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1302-1314},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An overview of advanced deep graph node clustering},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An individual evolutionary game model guided by global
evolutionary optimization for vehicle energy station distribution.
<em>TCSS</em>, <em>11</em>(1), 1289–1301. (<a
href="https://doi.org/10.1109/TCSS.2023.3237085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collective decision-making problems consisting of individual decisions are commonly seen in social applications. In this article, the vehicle energy station distribution problem (VESDP) is considered, which is modeled as a network-based collective decision-making problem fulfilling consumers’ requirements by arranging the distribution of energy stations rationally. This problem involves the game among the government and energy station investors. The government intends to maximize the satisfaction of both gas and electric vehicle (EV) customers through policy guidance, while investors aim to maximize their own profits. To solve this problem, we propose an individual evolutionary game model guided by global evolutionary optimization with the following three features. From the individual perspective, we use a network-based evolutionary game with a confidence mechanism to describe the behavior of investors. From the global perspective, we design a genetic algorithm to find out the global-optimized program, which considers the satisfaction of all customers. To heal the divergence between these two perspectives, we design a policy formulation method for the government to motivate selfish investors to adopt strategies in accordance with the overall interests of all customers by using subsidies and taxation. Experiments are performed on both square grid and real-world networks. Experimental results demonstrate the effectiveness of the proposed model.},
  archive      = {J_TCSS},
  author       = {Zhi-Xuan Zhang and Wei-Neng Chen and Wen Shi and Sang-Woon Jeon and Jun Zhang},
  doi          = {10.1109/TCSS.2023.3237085},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1289-1301},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An individual evolutionary game model guided by global evolutionary optimization for vehicle energy station distribution},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online spreading of topic tags and social behavior.
<em>TCSS</em>, <em>11</em>(1), 1277–1288. (<a
href="https://doi.org/10.1109/TCSS.2023.3235011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article explores information spreading in modern online social networks. According to the law of information spread in real social networks, information retweeting is divided into two types: topic retweeting and relationship retweeting. Social behavior is considered as a higher order interaction, and the nodal influence effect in the traditional approach is abstracted as part of it for analysis. The process of topic communities being subjected to social behavior is simulated by the social behavior model, and the dynamic retweeting rate is established. A network evolution model is constructed based on the centrality and noncontinuity characteristics of topic communities in the spread process. The social reinforcement effect in information spreading is described in two dimensions by defining topic expansion rate and topic diffusion rate. This work conducts multiple views of analysis and visualization, which provide more results of quantitative aspect. The validity of the model is verified by comparing the model simulation results with real cases and the generalization ability experiments.},
  archive      = {J_TCSS},
  author       = {Fuzhong Nian and Jinhu Ren and Xuelong Yu},
  doi          = {10.1109/TCSS.2023.3235011},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1277-1288},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Online spreading of topic tags and social behavior},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding residents’ behavior for smart city management
by sequential and periodic pattern mining. <em>TCSS</em>,
<em>11</em>(1), 1260–1276. (<a
href="https://doi.org/10.1109/TCSS.2023.3249740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the residents’ routine and repetitive behavior patterns is important for city planners and strategic partners to enact appropriate city management policies. However, the existing approaches reported in smart city management areas often rely on clustering or machine learning, which are ineffective in capturing such behavioral patterns. Aiming to address this research gap, this article proposes an analytical framework, adopting sequential and periodic pattern mining techniques, to effectively discover residents’ routine behavior patterns. The effectiveness of the proposed framework is demonstrated in a case study of American public behavior based on a large-scale venue check-in dataset. The dataset was collected in 2020 (during the global pandemic due to COVID-19) and contains 257 561 check-in data of 3995 residents. The findings uncovered interesting behavioral patterns and venue visit information of residents in the United States during the pandemic, which could help the public and crisis management in cities.},
  archive      = {J_TCSS},
  author       = {Cong Ma and Huy Quan Vu and Jinlong Wang and Van-Hau Trieu and Gang Li},
  doi          = {10.1109/TCSS.2023.3249740},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1260-1276},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Understanding residents’ behavior for smart city management by sequential and periodic pattern mining},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SIFDriveNet: Speed and image fusion for driving behavior
classification network. <em>TCSS</em>, <em>11</em>(1), 1244–1259. (<a
href="https://doi.org/10.1109/TCSS.2023.3303334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving behavior classification is an important direction in the field of social transportation systems and advanced driving assistance system (ADAS), which has attracted more and more attention in recent years. An accurate driving behavior classification algorithm plays a great role in traffic safety, energy saving, and other fields. In this article, we propose a novel vehicle speed and image fusion for driving behavior classification network (SIFDriveNet), which classifies driver behaviors into normal driving, aggressive driving, and drowsy driving. Our method has the following key advantages. First, in the research of driving behavior classification, we are the first to introduce a 2-D image with rich roadside information and convert speeds into a 2-D spectrogram expressing the time–frequency characteristics of speeds through short-time Fourier transform (STFT) while unifying the data space of image information and speed information. Second, we propose a tensor fusion method based on weight decomposition to fully fuse the vectors of the two modalities. This method maps the tensor outer product results to the low-dimensional space through weight decomposition and has a low computational cost while maintaining the fusion effect of the tensor outer product. In addition, we evaluated our model on the public UAH-DriveSet and compared it with the most advanced model. Experimental results show that our model has a better performance, and F1-score is 97.9% on all roads. Especially on the secondary road, our F1-score is 99.4%. Also, our model has strong generalization, and we have reached 99.3% F1 in distracted driving multimodal dataset. In addition, the inference speed reaches 411 FPS, enabling real-time needs. The code is available on https://github.com/alu222/SIFDriveNet .},
  archive      = {J_TCSS},
  author       = {Yan Gong and Jianli Lu and Wenzhuo Liu and Zhiwei Li and Xinmin Jiang and Xin Gao and Xingang Wu},
  doi          = {10.1109/TCSS.2023.3303334},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1244-1259},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {SIFDriveNet: Speed and image fusion for driving behavior classification network},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Threshold-based value-driven method to support consensus
reaching in multicriteria group sorting problems: A minimum adjustment
perspective. <em>TCSS</em>, <em>11</em>(1), 1230–1243. (<a
href="https://doi.org/10.1109/TCSS.2023.3251351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multicriteria group decision-making (MCGDM) problems, there exist the situations that alternatives need to be assigned to several predefined ordered categories rather than be ranked from the most preferred to the least preferred, which is called multicriteria group sorting problems. To address multicriteria group sorting problems, it is necessary to implement a consensus reaching process to fully consider the opinion of each decision maker and reduce the conflict among them. To do so, this article proposes a consensus reaching model for multicriteria group sorting problems based on the threshold-based value-driven sorting method from the perspective of minimum adjustment. Specifically, we first define the consensus measure to calculate the agreement degree among decision makers by considering the ordinal information and cardinal information at the same time. On this basis, we construct a minimum adjustment optimization model in terms of the threshold-based value-driven sorting method to assist decision makers in modifying their decision matrices and further promote consensus. Followed by this, an optimization model that aims to minimize the distance between all decision makers and the group with respect to alternatives’ comprehensive values and sorting results is developed to determine the group sorting result for alternatives. Moreover, a numerical application of urban park management, some sensitivity analysis, and simulation experiments are provided to justify the proposed method. Experimental results reveal that the proposed method is effective in promoting consensus.},
  archive      = {J_TCSS},
  author       = {Zhuolin Li and Zhen Zhang},
  doi          = {10.1109/TCSS.2023.3251351},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1230-1243},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Threshold-based value-driven method to support consensus reaching in multicriteria group sorting problems: A minimum adjustment perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalize deep neural networks with adaptive regularization
for classifying. <em>TCSS</em>, <em>11</em>(1), 1216–1229. (<a
href="https://doi.org/10.1109/TCSS.2023.3264804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regularization is a crucial technology to improve the generalization of deep neural networks. However, traditional regularization method approaches are all scenario-specific, because they are generally with ingeniously designed feature representations from input layer, hidden layer, and output layer, which increase the difficulty of model development and interpretation. To this end, a novel practical and flexible regularization method is presented to obtain higher generalization and interpretability. Specifically, the feature maps are decoupled by global suppression and partial suppression from various scales and locate the salient feature with strong low-resolution semantic information. Moreover, the guided discarding specification for feature decoupling by measuring the feature contributions to network decisions, leads to the logics with better interpretability. Subsequently, the max values of the feature map are suppressed by discarding the corresponding salient features. Comprehensive experiments demonstrate that the proposed adaptive regularization outperforms the state-of-the-art performance in image classification accuracy, generalization, and interpretability on several widely used datasets. And adaptive regularization helps the network to mine the connection between salient features, nonsalient features, and ground truth, encouraging the network to construct multiple layers of feature associations.},
  archive      = {J_TCSS},
  author       = {Kehua Guo and Ze Tao and Lingyan Zhang and Bin Hu and Xiaoyan Kui},
  doi          = {10.1109/TCSS.2023.3264804},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1216-1229},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Generalize deep neural networks with adaptive regularization for classifying},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Career mobility analysis with uncertainty-aware graph
autoencoders: A job title transition perspective. <em>TCSS</em>,
<em>11</em>(1), 1205–1215. (<a
href="https://doi.org/10.1109/TCSS.2023.3239038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Career mobility analysis aims at discovering the movement patterns of employees across different job positions or grades, which can benefit various human resource-related applications. Indeed, recent studies in this direction mainly focus on modeling individual career trajectories, while the macroguidance for labor market assessment has been largely ignored. To this end, in this article, we propose to study career mobility from a market-driven perspective based on large-scale online professional networks (OPNs). Specifically, we propose an uncertainty-aware graph autoencoders (UnGAEs) framework, which can simultaneously discover potential job title transition patterns and predict job durations. In this phase, we first construct a job title transition graph based on massive career trajectory data from OPNs. Then, considering the inherent uncertainty in career mobility, we introduce a novel uncertainty-aware graph encoder (UnGE) to represent job titles as Gaussian embeddings. Furthermore, we design two task-specific decoders that can preserve the asymmetric relationships between job titles, namely the gravity-inspired decoder (GID) and the energy-inspired decoder (EID), for predicting potential transition patterns and corresponding duration, respectively. In particular, both tasks are modeled through a specially designed multitask learning approach. Finally, extensive experiments on a real-world dataset clearly demonstrate the effectiveness of UnGAE compared with state-of-the-art baselines, as well as some potential applications such as job title benchmarking and career path planning.},
  archive      = {J_TCSS},
  author       = {Rui Zha and Chuan Qin and Le Zhang and Dazhong Shen and Tong Xu and Hengshu Zhu and Enhong Chen},
  doi          = {10.1109/TCSS.2023.3239038},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1205-1215},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Career mobility analysis with uncertainty-aware graph autoencoders: A job title transition perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic emotional transition sampling and emotional guidance
of individuals based on conversation. <em>TCSS</em>, <em>11</em>(1),
1192–1204. (<a href="https://doi.org/10.1109/TCSS.2023.3256889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion is the vital path to achieving strong artificial intelligence. Therefore, it is significant to study the emotional guiding and controlling theory to enhance system intelligence. Conversational datasets in social media contain useful information, including individuals exhibiting continuously changing emotion states in response to external stimuli, and are the foundation for research on artificial emotions. We define dialog-based emotional guidance in reinforcement learning to research the emotional guidance of the discrete emotion model. This article proposes three strategies to obtain the optimal policy: 1) given the current emotional transition matrix, use the emotional Markov decision process (E-MDP) algorithm to calculate the optimal stimulus policy for each target emotion; 2) given the emotional transition sequences, use the emotional Monte Carlo algorithm to calculate the optimal stimulus policy; and 3) given the emotional transition sequences, use the $Q$ -learning algorithm to calculate the optimal stimulus policy. Besides, we improve the Markov chain Monte Carlo algorithm to sample emotional transition sequences and design a metric to evaluate the effectiveness of policies. Experimental results on three datasets show that these methods can more effectively guide emotion than traditional methods. Particularly, E-MDP achieves the best results while others can be more widely used in real-world scenarios.},
  archive      = {J_TCSS},
  author       = {Xiao Sun and Jiamin Wang and Fuji Ren and Meng Wang},
  doi          = {10.1109/TCSS.2023.3256889},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1192-1204},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Dynamic emotional transition sampling and emotional guidance of individuals based on conversation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LD-recognition: Classroom action recognition based on
passive RFID. <em>TCSS</em>, <em>11</em>(1), 1182–1191. (<a
href="https://doi.org/10.1109/TCSS.2023.3234423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classroom learning is one of the main ways for students to acquire knowledge because the class usually has a large number of students and it is difficult for teachers to pay attention to the learning status of each student at the same time. Therefore, mastering the learning status of each student and dealing with it is the key factor to determine the quality of course teaching, and classroom actions can accurately reflect the learning state of students. Based on this, in this article, a passive radio frequency identification (RFID)-based classroom action recognition system LD-recognition is proposed. The system pastes the label on the right side of the desk, and the learning state of the students was judged by recognizing the four movements of raising the left hand, raising the right hand, nodding off, and holding the book. The system uses a multichannel attentional graph convolutional neural network (ATGCN) to deeply learn the phase and signal strength of actions and conduct action recognition. LD-recognition verifies the accuracy of actions from different distances, different experimenters, and different network models. The experimental results show that the recognition accuracy of LD-recognition system is high, reaching 96.9% on average.},
  archive      = {J_TCSS},
  author       = {Qing Qiu and Taochun Wang and Fulong Chen and Chengtian Wang},
  doi          = {10.1109/TCSS.2023.3234423},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1182-1191},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {LD-recognition: Classroom action recognition based on passive RFID},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multilayer perceptron neural network approach to classifying
learning modalities under the new normal. <em>TCSS</em>, <em>11</em>(1),
1169–1181. (<a href="https://doi.org/10.1109/TCSS.2023.3251566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of community quarantines and lockdowns during COVID–19 times, the Philippine’s Department of Education (DepEd) implemented blended learning (BL) [both online and offline distance learning modalities (LM)] among basic educational institutions in the hope of continuing learners’ learning experiences amidst the pandemic. Learners’ LM are classified through the use of an Algorithm for Learning Delivery Modality as recommended by DepEd. Based on initial investigation, mismatches in learners’ LM were, however, observed, resulting in learners’ massive shifting from one LM to another in the middle of the school year. In this study, we introduced an approach to classifying learner’s LM using machine learning (ML) techniques. We compared the effectiveness of five ML classifiers, namely the random forest (RF), multilayer perceptron neural network (MLP NN), K-nearest neighbor (KNN), support vector machine (SVM), and Naïve Bayes (NB). Learner’s enrolment and survey form (LESF) data from the repository of a local private high school in the Philippines is used in model formulation. We also compared three existing feature selection (FS) algorithms (recursive feature elimination (RFE), Boruta algorithm (BA), and ReliefF)–integrated into the five ML classifiers as data feature reduction techniques. Results show that the combination of MLP NN and BA yielded a considerably high performance among the rest of the formulated models. Sensitivity analysis revealed that asynchronous LM is most sensitive to “existing health condition” feature, modified asynchronously, is highly characterized by low educational attainment and unstable employment status of parents or guardians, while synchronous learners have high socio–economic status as compared to other LM.},
  archive      = {J_TCSS},
  author       = {Gernel S. Lumacad and Rhoda A. Namoco},
  doi          = {10.1109/TCSS.2023.3251566},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1169-1181},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Multilayer perceptron neural network approach to classifying learning modalities under the new normal},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RLCA: Reinforcement learning model integrating cognition and
affection for empathetic response generation. <em>TCSS</em>,
<em>11</em>(1), 1158–1168. (<a
href="https://doi.org/10.1109/TCSS.2023.3258741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empathy is a crucial field of social science research. The current research on the dialog systems with empathy has two main limitations: 1) less adequate integration of the cognition and affection aspects of empathy for enhancing the perceptual and emotional expression abilities and 2) lack of the evaluation of the generated response at the sentence level in the training process for reducing the problem of exposure bias. Therefore, we proposed the reinforcement learning model integrating cognition and affection (RLCA) model that utilizes the RL framework integrating cognition and affection to evoke greater empathetic expression in the model. In particular, the cognitive response generator can reason commonsense information based on the user’s situation to improve the perceptual capabilities of the proposed model. Moreover, the emotional regulator can mitigate the exposure bias problem by distilling multiple emotion signals from predicted responses and imparting higher emotional intelligence to the proposed model. Furthermore, the interaction between the cognition and affection aspects helps the model to learn the features of empathic expressions in human conversation. Extensive experimental findings on a benchmark dataset indicate that the RLCA outperforms the popular baseline models of automatic metrics and human evaluations while generating more interpretable empathetic responses.},
  archive      = {J_TCSS},
  author       = {Yun Su and Haoran Bian and Bozhen Fan and Bingxu Lian and Chengrong Zhang and Bingtao Zhang and Runhe Huang},
  doi          = {10.1109/TCSS.2023.3258741},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1158-1168},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {RLCA: Reinforcement learning model integrating cognition and affection for empathetic response generation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pedestrian re-identification algorithm based on attention
pooling saliency region detection and matching. <em>TCSS</em>,
<em>11</em>(1), 1149–1157. (<a
href="https://doi.org/10.1109/TCSS.2022.3233864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition accuracy of the pedestrian re-identification algorithm is affected by factors such as the scale, posture, occlusion level, and appearance of a pedestrian in an image. These factors bring great challenges to the further development of deep learning theory in the field of person re-identification. On the one hand, existing pedestrian re-identification model cannot accurately extract attention information containing contextual information and discriminative pedestrian features. On the other hand, images of the same pedestrian taken with different cameras have the problem of different degrees of occlusion. Therefore, we introduce an attention pooling mechanism, which allows the model to automatically focus on discriminative regions of pedestrian images. The model can then learn attention maps by automatically focusing on visually salient pedestrian regions. It can effectively address the influence of factors on the accuracy of pedestrian re-identification. Furthermore, we propose a pedestrian re-identification method based on saliency region detection and matching. The method first extracts multiple local saliency regions from pedestrian images using the pedestrian joint point detection method, then marks and extracts the positions of the abovementioned saliency regions, and finally performs matching and sorting. It can correct the impact caused by occlusion on the accuracy of pedestrian re-identification. We conduct tests and experiments on three public person re-identification datasets, and the results show that our method not only achieves the best recognition accuracy on the aforementioned datasets but also has better robustness.},
  archive      = {J_TCSS},
  author       = {Fengping An and Jianrong Wang and Ruijun Liu},
  doi          = {10.1109/TCSS.2022.3233864},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1149-1157},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Pedestrian re-identification algorithm based on attention pooling saliency region detection and matching},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying always-the-same-rating reviewers on amazon.com
using big data analytics. <em>TCSS</em>, <em>11</em>(1), 1133–1148. (<a
href="https://doi.org/10.1109/TCSS.2023.3235727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study identifies “always-the-same-rating” reviewers (ASRs), that is, reviewers who give the same star rating for all reviewed products and who write many reviews on Amazon. This study identifies ASRs in 29 product categories by analyzing 230 million individual reviews on Amazon. The findings of this study show that: 1) all product categories contain reviews written by ASRs; 2) the majority of ASRs (99.99%) give the same star rating for all reviewed products in all categories; and 3) the rating distribution of ASRs’ reviews is extremely skewed toward the five-star rating (98.02%). The digital music category, in particular, shows a high share and volume of ASRs among all categories, making it an ideal focal category for further empirical analysis of ASRs. This study empirically demonstrates that star rating, the helpfulness of reviews, the length of headline and review, prior reviews, and holidays are potential indicators of reviews written by ASRs. The finding shows that reviews from verified and nonverified ASRs respond differently to some potential indicators. This article is the first step toward identifying irregular reviewer groups and their abnormal rating patterns, which would help in the segmentation of online consumers and a better understanding of online consumer review behaviors.},
  archive      = {J_TCSS},
  author       = {Jikhan Jeong},
  doi          = {10.1109/TCSS.2023.3235727},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1133-1148},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Identifying always-the-same-rating reviewers on Amazon.Com using big data analytics},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling group opinion evolution on online social networks:
A gravitational field perspective. <em>TCSS</em>, <em>11</em>(1),
1121–1132. (<a href="https://doi.org/10.1109/TCSS.2023.3256892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research on group behavior is effective for establishing a good network environment since people in social networks tend to form groups spontaneously. Most studies on group behavior on online social networks assume that all individuals are reduced to one cluster, ignoring the existence of potential clusters and their importance in group opinion dynamics. This article introduces a novel group-gravitational field (GGF) model to investigate the opinion evolution based on group behavior by the following aspects: 1) the GGF model reduces a cluster in the social network into a charge and the whole network into a gravitational field; 2) the GGF model calculates the initial influence of a cluster according to the topology information and further constructs a gravity matrix of the network based on the Coulomb law; and 3) opinion-leader clusters exert the internal field force on common opinion clusters inside the gravitational field. The GGF model simulates the evolution of opinions among clusters in a network and studies the law of group behavior according to the influence between clusters based on Coulomb’s law. Experiments on real social networks verify that the GGF model enhances the speed of opinion evolution significantly. The simulation experiments indicate that the existence of clusters promotes the rapid convergence of opinions, a gathering of followers influences information dissemination in social networks, and the GGF model fits the reality better. This article provides a new approach to network supervision and control.},
  archive      = {J_TCSS},
  author       = {Meizi Li and Xinyi Zhang and Maozhen Li and Yunwen Chen and Yanhong Bai and Bo Zhang and Ru Yang},
  doi          = {10.1109/TCSS.2023.3256892},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1121-1132},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Modeling group opinion evolution on online social networks: A gravitational field perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting fraudulent student communication in a multiple
choice online test environment. <em>TCSS</em>, <em>11</em>(1),
1108–1120. (<a href="https://doi.org/10.1109/TCSS.2023.3254504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online evaluation systems, pervasive nowadays, are known to be susceptible to higher fraud risks. This work proposes a novel and robust method to detect potential fraud acts in online multiple-choice question (MCQ) exams. For the first time, the communication probability between the examinees is statistically assessed based on the concordance of responses and answer time against null expectations and is subsequently used to identify potential fraud behavior. The model is sensitive to the direction of communication acts, distinguishing content consumption from production, as well as multiwise communication channels. Online remote tests from engineering courses at Técnico Lisboa are used as a case study. We show that the cumulative contribution of concordant responses between students, when recurrent, offers a way of signaling fraud behavior. Separating content production from consumption reveals the underlying student role played in potential fraud acts. Collusion behavior is assessed against null models of fraud and conformity, and therefore being statistically framed and offering a solid criterion to guide tutors in ascertaining fraud and discouraging communication.},
  archive      = {J_TCSS},
  author       = {Mariana Carrasco and António Rito Silva and Rui Henriques},
  doi          = {10.1109/TCSS.2023.3254504},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1108-1120},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Detecting fraudulent student communication in a multiple choice online test environment},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling digital personality: A fuzzy-logic-based
myers–briggs type indicator for fine-grained analytics of digital human.
<em>TCSS</em>, <em>11</em>(1), 1096–1107. (<a
href="https://doi.org/10.1109/TCSS.2023.3245127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital human in cyberspace can help provide humanized services in specific applications, such as question &amp; answer systems, recommender systems, chatter robots, and intelligent assistants. While most researches focus on behavior analytics, few of them integrate the personality that is also a closely related factor. As a classic indicator for personality representation, Myers–Briggs type indicator (MBTI) categorizes an individual into mutually exclusive types from four dichotomous axes (extraversion versus introversion, sensing versus intuition, thinking versus feeling, judging versus perceiving). Traditional recognition method using MBTI simply measures the user’s preference frequency in each axis through questionnaires, treating the dominant value as the identified result. Such a paradigm, however, represents all the people with only 16 types and cannot distinguish heterogeneous users clearly. This article proposes a novel personality recognition method using fuzzy logic. Different from previous classifications, our new method categorizes the individual in a continuous space and represents one’s personality in a more fine-grained level. We have designed comparative psychological tests for 77 people. The validation experiments on such tests indicate that the fuzzy-logic-based method is not only consistent with the classic MBTI tests (in the sense of defuzzification) but also provides the uncertainty for each personality type. Therefore, it can be viewed as a generalization of the classic MBTI tests and promotes the representation of individual’s heterogeneity for fine-grained analytics of digital human.},
  archive      = {J_TCSS},
  author       = {Tan Wang and Peijun Ye and Hongqiang Lv and Weichao Gong and Hao Lu and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3245127},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1096-1107},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Modeling digital personality: A fuzzy-logic-based Myers–Briggs type indicator for fine-grained analytics of digital human},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-agnostic meta-learning for multilingual hate speech
detection. <em>TCSS</em>, <em>11</em>(1), 1086–1095. (<a
href="https://doi.org/10.1109/TCSS.2023.3252401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hate speech in social media is a growing phenomenon, and detecting such toxic content has recently gained significant traction in the research community. Existing studies have explored fine-tuning language models (LMs) to perform hate speech detection, and these solutions have yielded significant performance. However, most of these studies are limited to detecting hate speech only in English, neglecting the bulk of hateful content that is generated in other languages, particularly in low-resource languages. Developing a classifier that captures hate speech and nuances in a low-resource language with limited data is extremely challenging. To fill the research gap, we propose HateMAML , a model-agnostic meta-learning (MAML)-based framework that effectively performs hate speech detection in low-resource languages. HateMAML utilizes a self-supervision strategy to overcome the limitation of data scarcity and produces better LM initialization for fast adaptation to an unseen target language (i.e., cross-lingual transfer) or other hate speech datasets (i.e., domain generalization). Extensive experiments are conducted on five datasets across eight different low-resource languages. The results show that HateMAML outperforms the state-of-the-art baselines by more than 3% in the cross-domain multilingual transfer setting. We also conduct ablation studies to analyze the characteristics of HateMAML .},
  archive      = {J_TCSS},
  author       = {Md Rabiul Awal and Roy Ka-Wei Lee and Eshaan Tanwar and Tanmay Garg and Tanmoy Chakraborty},
  doi          = {10.1109/TCSS.2023.3252401},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1086-1095},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Model-agnostic meta-learning for multilingual hate speech detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LUSTC: A novel approach for predicting link states on
dynamic attributed networks. <em>TCSS</em>, <em>11</em>(1), 1075–1085.
(<a href="https://doi.org/10.1109/TCSS.2023.3252261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting link states on dynamic attributed networks is one of the most fundamental problems for network analysis. To accurately predict the formations and disappearances of links, we need to utilize three types of information, that is, structural information, node content information, and temporal information, simultaneously. To this end, we propose a novel approach called LUSTC for predicting links and unlinks with structural information, temporal information, and node content information on dynamic attributed networks. For each snapshot, LUSTC first randomly chooses some sets of active nodes whose degree changes between adjacent snapshots and collects higher-order structural information using a random walk method based on the active nodes. Then, LUSTC generates two global matrices containing the temporal structural information and temporal node content information, respectively, as well as a sequence of auxiliary matrices for reconstructing the structural information and node content information of snapshots. These generated matrices are optimized using a nonnegative matrix factorization (NMF) method based on the structural information and node content information of snapshots. Finally, LUSTC estimates the similarity matrix for future snapshots to predict the links that are more likely to be formed or broken. The experimental results on various dynamic attributed networks demonstrate the effectiveness of LUSTC on the link prediction and unlink prediction tasks.},
  archive      = {J_TCSS},
  author       = {Christina Muro and Boyu Li and Kun He},
  doi          = {10.1109/TCSS.2023.3252261},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1075-1085},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {LUSTC: A novel approach for predicting link states on dynamic attributed networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large-scale medical crowdfunding data reveal determinants
and preferences of donation behaviors. <em>TCSS</em>, <em>11</em>(1),
1062–1074. (<a href="https://doi.org/10.1109/TCSS.2023.3251319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing usage of online crowdfunding platforms has fundamentally changed the traditional modes of fundraising and donation. Previous studies have mainly focused on the performance and ethical issues of online crowdfunding. In contrast, there is a dearth of information about the complexity of online donation behaviors. To explore the characteristics of fundraising and donation in online crowdfunding campaigns, we conduct a comprehensive analysis of fundraising and donation behaviors based on 151163 campaigns, with 188955849 donations created from 2016 to 2020 in one of the most popular medical crowdfunding (MCF) platforms called Easy Fundraising in China. We propose four indicators, namely, diversity, uncertainty, concentration, and consistency, to characterize the preferences of individual donors in choosing the donation amounts. Furthermore, we investigate the fundraising temporal dynamics and collective donation characteristics of crowdfunding campaigns using statistical methods. Results show that the first three days after the creation of a crowdfunding campaign is the most efficient fundraising period that largely determines the completion of the campaign. Donors who donate early are more generous than those who donate later. Individual donors prefer donation amounts in multiples of five, such as 5, 10, 20, and 50, and rarely change their donation amounts, which is irrelevant to the patients’ locations. The empirical results obtained in this study provide valuable insights to improve crowdfunding management, public welfare systems’ construction, and human donation behaviors’ understanding.},
  archive      = {J_TCSS},
  author       = {Mengning Wang and Mengsi Cai and Shuhui Guo and Mengjun Li and Xu Tan and Chaomin Ou and Xin Lu},
  doi          = {10.1109/TCSS.2023.3251319},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1062-1074},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Large-scale medical crowdfunding data reveal determinants and preferences of donation behaviors},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). User-specific loyalty measure and prediction using deep
neural network from twitter data. <em>TCSS</em>, <em>11</em>(1),
1046–1061. (<a href="https://doi.org/10.1109/TCSS.2023.3239523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing the social media data posted by users reveals insights about the business such as customers’ sentiment, limitations, improvements in services, users’ expectations, customer loyalty, and satisfaction. Customer satisfaction and loyalty are measured using net promoter score (NPS), which is based on a survey and often lacks the background of customer context. Several recent methods, net brand reputation (NBR) and net sentiment score (NSS), overcome NPS limitations and utilize social media data to gauge customer loyalty. The NBR and NSS also have the limitation that they do not provide the user-level score. In social media, existing user has an influence on a new user, which cannot be estimated in NBR and NSS. The main contribution of this research is developing novel user- and product-level metrics, which measure the influence, satisfaction, and customer loyalty. User sentiment score (USS) measures customer loyalty, overall influence factor (OIF) computes influence factor, effective influence on user (EIU) gives the effective impact on a new user, and satisfaction score (SATS) estimates satisfaction using user tweets. Social data influence score (SDIS) is proposed to measure the combined impact of user satisfaction and influence. We prepare a Twitter dataset of five popular online learning platforms: Coursera, Udemy, Udacity, Khanacademy, and edX, and analyzed our proposed metrics on them. Prediction of USS into loyal and not loyal customers is carried out using Twitter data and dense neural networks (DNNs). The performance of DNN is compared with random forest classifier (RFC), eXtreme gradient boosting (XGB), and support vector classifier (SVC). DNN gave the highest classification of 98.62% on tenfold cross validation.},
  archive      = {J_TCSS},
  author       = {Siddhaling Urolagin and Saifali Patel},
  doi          = {10.1109/TCSS.2023.3239523},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1046-1061},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {User-specific loyalty measure and prediction using deep neural network from twitter data},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge graph-based reinforcement federated learning for
chinese question and answering. <em>TCSS</em>, <em>11</em>(1),
1035–1045. (<a href="https://doi.org/10.1109/TCSS.2023.3246795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge question and answering (Q&amp;A) is widely used. However, most existing semantic parsing methods in Q&amp;A usually use cascading, which can incur error accumulation. In addition, using only one institution’s Q&amp;A data definitely will limit the Q&amp;A performance, while data privacy prevents sharing between institutions. This article proposes a knowledge graph-based reinforcement federated learning (KGRFL)-based Q&amp;A approach to address these challenges. We design an end-to-end multitask semantic parsing model [MSP-bidirectional and auto-regressive transformers (BART)] that identifies question categories while converting questions into SPARQL statements to improve semantic parsing. Meanwhile, a reinforcement learning (RL)-based model fusion strategy is proposed to improve the effectiveness of federated learning, which enables multi-institution joint modeling and data privacy protection using cross-domain knowledge. In particular, it also reduces the negative impact of low-quality clients on the global model. Furthermore, a prompt learning-based entity disambiguation method is proposed to address the semantic ambiguity problem because of joint modeling. The experiments show that the proposed method performs well on different datasets. The Q&amp;A results of the proposed approach outperform the approach of using only a single institution. Experiments also demonstrate that the proposed approach is resilient to security attacks, which is required for real applications.},
  archive      = {J_TCSS},
  author       = {Liang Xu and Tao Chen and Zhaoxiang Hou and Weishan Zhang and Chitin Hon and Xiao Wang and Di Wang and Long Chen and Wenyin Zhu and Yunlong Tian and Huansheng Ning and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3246795},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1035-1045},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Knowledge graph-based reinforcement federated learning for chinese question and answering},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Gated recursive and sequential deep hierarchical encoding
for detecting incongruent news articles. <em>TCSS</em>, <em>11</em>(1),
1023–1034. (<a href="https://doi.org/10.1109/TCSS.2023.3247445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase in misinformation across digital platforms, incongruent news detection is becoming an important research problem. Earlier, researchers have exploited various feature engineering approaches and deep learning models with embedding to capture incongruity between news headlines and their respective bodies. Studies have broadly considered different combinations of bag-of-words-based features, sequential encoding, hierarchical encoding, headline-guided attention-based encoding, and so on, of the text in headlines and bodies. In this article, we focus on addressing two important limitations observed with hierarchical encoding and headline-guided attention-based encoding methods. The existing hierarchical encoding-based studies limit the hierarchical structure of the body of a news article to paragraph level only, undermining the importance of incorporating long-term dependence from word level to sentence, paragraph, and body. Furthermore, the existing headline-guided attention-based encoding focuses on contextually similar contents in the body of the headline, undermining the importance of incorporating contextually dissimilar contents. Motivated by the above observations, this article proposes a gated recursive and sequential deep hierarchical encoding (GraSHE) method for detecting incongruent news articles by extending the hierarchical structure of the news body from the body to the word level and incorporating incongruity weight. From various experimental setups over three publicly available benchmarks datasets, the experimental results indicate that the proposed model outperforms baseline models with bag-of-word-based features, sequential, hierarchical, and headline-guided attention-based encoding methods. To further validate the performance of the proposed model, we conduct several ablation studies. The following key observations can be made from the ablation study: 1) models with hierarchical encoding outperform models with nonhierarchical encoding; 2) recursive encoding of sentences boosts the performance of models as compared with sequential encoding of sentences within paragraphs; and 3) incongruent news article detection is domain-dependent. Incorporating explicit features further boosts the performance of proposed model and also decreases the domain dependence of models.},
  archive      = {J_TCSS},
  author       = {Sujit Kumar and Durgesh Kumar and Sanasam Ranbir Singh},
  doi          = {10.1109/TCSS.2023.3247445},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1023-1034},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Gated recursive and sequential deep hierarchical encoding for detecting incongruent news articles},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online research topic modeling and recommendation utilizing
multiview autoencoder-based approach. <em>TCSS</em>, <em>11</em>(1),
1013–1022. (<a href="https://doi.org/10.1109/TCSS.2023.3253502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed tremendous growth in the publication of research articles as well as in the rise of new research topics. Articles get published in a streaming manner and therefore retrieving and recommending trending topics continuously by updating the trend of topics with time will be beneficial for young researchers. The proposed topic recommendation system is a clustering-based approach that utilizes an autoencoder framework for the generation of clusters. The autoencoder framework considers articles as input in a multiview framework and produces latent data in lower-dimensional space using graph attention-based encoder and decoder networks. The latent data is then partitioned with respect to its different views and finally, a single consensus overlapping partitioning is produced by satisfying all the views. Since the publication of articles is a continuous process, to update the trending topics continuously, the clustering-based approach is kept on and applied iteratively in a sliding window manner. The generated clusters are analyzed to extract the trending topics and recommendations for future scope. An article can belong to multiple topics and the proposed method is developed by considering such criteria and therefore tested with the modified version of the multilabel scientific article data ArXiv, named CSML.ArXiv. The superiority of the proposed method can be observed from its comparisons with existing methods, and a few baseline methods with respect to cluster formation, topic extraction, and trending topic evaluation.},
  archive      = {J_TCSS},
  author       = {Dipanjyoti Paul and Daipayan Chakdar and Sriparna Saha and Jimson Mathew},
  doi          = {10.1109/TCSS.2023.3253502},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {1013-1022},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Online research topic modeling and recommendation utilizing multiview autoencoder-based approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constrained community detection and multistage multicost
consensus in social network large-scale decision-making. <em>TCSS</em>,
<em>11</em>(1), 997–1012. (<a
href="https://doi.org/10.1109/TCSS.2023.3265701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a widely encountered decision-making scenario in modern society, social network large-scale decision-making (SNLSDM) is becoming a frontier topic in the field of decision science. Decision information usually includes social relationships among decision-makers (DMs) and individual opinions. This makes clustering and consensus building, which are two important processes for solving SNLSDM problems, significantly complex and requires the integration of multiple factors. This study designs a decision support method that consists of a constrained community detection (CCD) method and a multistage multicost consensus (MSMulCC) model. The CCD method takes the similarities among individual opinions as the mandatory constraint to guide the classification of DMs based on social relationships. The consensus-reaching process (CRP) is an effective tool for reducing differences of opinion. We hold that the DM with high compatibility but low consensus can reduce the adjustment amount by actively losing some compatibility. In this way, three types of consensus costs are generated, including individual adjustment cost, group adjustment cost, and compatibility loss cost. In this study, an MSMulCC model is developed, and the impact of different types of consensus costs on CRP. Finally, the feasibility and characteristics of the proposal are revealed through a case study and comparative analysis of the supply chain financing model selection.},
  archive      = {J_TCSS},
  author       = {Zhijiao Du and Sumin Yu and Chenguang Cai},
  doi          = {10.1109/TCSS.2023.3265701},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {997-1012},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Constrained community detection and multistage multicost consensus in social network large-scale decision-making},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Supplementary influence maximization problem in social
networks. <em>TCSS</em>, <em>11</em>(1), 986–996. (<a
href="https://doi.org/10.1109/TCSS.2023.3234437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to important applications in viral marketing, influence maximization (IM) has become a well-studied problem. It aims at finding a small subset of initial users so that they can deliver information to the largest amount of users through the word-of-mouth effect. The original IM only considers a singleton item. And the majority of extensions ignore the relationships among different items or only consider their competitive interactions. In reality, the diffusion probability of one item will increase when users adopted supplementary products in advance. Motivated by this scenario, we propose a supplementary independent cascade (IC) and discuss the supplementary IM problem. Our problem is NP-hard, and the computation of the objective function is #P-hard. We notice that the diffusion probability will change when considering the impact of its supplementary product. Therefore, the efficient reverse influence sampling (RIS) techniques cannot be applied to our problem directly even though the objective function is submodular. To address this issue, we utilize the sandwich approximation (SA) strategy to obtain a data-dependent approximate solution. Furthermore, we define the supplementary-based reverse reachable (SRR) sets and then propose a heuristic algorithm. Finally, the experimental results on three real datasets support the efficiency and superiority of our methods.},
  archive      = {J_TCSS},
  author       = {Yapu Zhang and Jianxiong Guo and Wenguo Yang and Weili Wu},
  doi          = {10.1109/TCSS.2023.3234437},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {986-996},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Supplementary influence maximization problem in social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SDIGRU: Spatial and deep features integration using
multilayer gated recurrent unit for human activity recognition.
<em>TCSS</em>, <em>11</em>(1), 973–985. (<a
href="https://doi.org/10.1109/TCSS.2023.3249152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart video surveillance plays a significant role in public security via storing a huge amount of continual stream data, evaluates them, and generates warns where undesirable human activities are performed. Recognition of human activities in video surveillance has faced many challenges such as optimal evaluation of human activities under growing volumes of streaming data with complex computation and huge time processing complexity. To tackle these challenges we introduce a lightweighted spatial-deep features integration using multilayer GRU (SDIGRU). First, we extract spatial and deep features from frames sequence of realistic human activity videos via utilizing a lightweight MobileNetV2 model and then integrate those spatial-deep features. Although deep features can be used for human activity recognition, they contain only the high-level appearance, which is insufficient to correctly identify the particular activity of human. Thus, we jointly apply deep information with spatial appearance to produce detailed level information. Furthermore, we select rich informative features from spatial-deep appearances. Then, we train multilayer gated recurrent unit (GRU) and feed informative features to learn the temporal dynamics of human activity frames sequence at each time step of GRU. We conduct our experiments on benchmark YouTube11, HMDB51, and UCF101 datasets of human activity recognition. The empirical results show that our method achieved significant recognition performance with low computational complexity and quick response. Finally, we compare the results with existing state-of-the-art techniques, which show the effectiveness of our method.},
  archive      = {J_TCSS},
  author       = {Tariq Ahmad and Jinsong Wu},
  doi          = {10.1109/TCSS.2023.3249152},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {973-985},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {SDIGRU: Spatial and deep features integration using multilayer gated recurrent unit for human activity recognition},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal fake news analysis based on image–text
similarity. <em>TCSS</em>, <em>11</em>(1), 959–972. (<a
href="https://doi.org/10.1109/TCSS.2023.3244068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the fast and extensive development of computer vision techniques, multimodal analyses are utilized more frequently for online fake news detection. To better understand the image–text relationship and its role in fake news detection, in this article, we proposed and evaluated four image–text similarities, namely, textual similarity, semantic similarity, contextual similarity, and post-training similarity. The textual and semantic similarities indicate the original image–text similarities in terms of the text information and image caption information. The contextual similarity reflects the image–text similarity in the format of meaningful named entities. The post-training similarity demonstrates how image–text similarity involves before and after a fake news detection model is trained. By evaluating the proposed similarity measurements on three real-world datasets, we find that fake news image–text similarity is higher than real news image–text similarity in most of the cases. Furthermore, the comparison of models’ performance further validates the significance of visual information in online fake news detection. These findings may be considered as the fundamental logic to explain the original purpose of fake news creation and can be used as influential features for improving models’ performance in the future.},
  archive      = {J_TCSS},
  author       = {Xichen Zhang and Sajjad Dadkhah and Alexander Gerald Weismann and Mohammad Amin Kanaani and Ali A. Ghorbani},
  doi          = {10.1109/TCSS.2023.3244068},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {959-972},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Multimodal fake news analysis based on Image–Text similarity},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Information propagation prediction based on spatial–temporal
attention and heterogeneous graph convolutional networks. <em>TCSS</em>,
<em>11</em>(1), 945–958. (<a
href="https://doi.org/10.1109/TCSS.2023.3244573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of deep learning and other technologies, the research of information propagation prediction has also achieved important research achievements. However, the existing information diffusion studies either focus on the attention relationships of users or they predict the information according to the diffusion relationships of users, which makes the prediction results have certain limitations. Therefore, a prediction model has been proposed spatial–temporal attention heterogeneous graph convolutional networks (STAHGCNs). First, we use GCN to learn user influence relationships and user behavior relationships, and we propose a user representation fusion mechanism to learn the user characteristics. Second, to account for the dynamics of user behavior, a temporal attention mechanism strategy is used to encode time into the heterogeneous graph to obtain a more expressive user representation. Finally, the obtained user representation is input into the multihead attention mechanism for information propagation prediction. Experimental results performed on the Twitter, Douban, Digg, and Memetracker datasets have shown that the proposed STAHGCN model increased by 8.80% and 6.74% at hits@N and map@N, respectively, which are significantly better than the original latest DyHGCN model. The proposed STAHGCN model effectively integrates spatial factors, such as time factor, user influence, and behavior, which greatly improves the accuracy of information propagation prediction and has great significance for rumor monitoring and malicious account detection.},
  archive      = {J_TCSS},
  author       = {Xiaoyang Liu and Chenxiang Miao and Giacomo Fiumara and Pasquale De Meo},
  doi          = {10.1109/TCSS.2023.3244573},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {945-958},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Information propagation prediction based on Spatial–Temporal attention and heterogeneous graph convolutional networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zooming into video conferencing privacy. <em>TCSS</em>,
<em>11</em>(1), 933–944. (<a
href="https://doi.org/10.1109/TCSS.2022.3231987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unprecedented growth in video conferencing usage is accompanied by multiple security and privacy threats. Importantly, protecting users’ privacy is not always in their own hands. Posting meeting images affects all participants, leading to an easy collection of personal data including age, gender and linkage with participation in other meetings. Here, we explored privacy issues that may be at risk by attending virtual meetings. We extracted private information from collage images of meeting participants that are publicly posted online. We used image processing, text recognition tools, as well as social network analysis to explore our curated dataset of over 15700 collage images, and over 142000 face images of meeting participants. We demonstrate that video conference users are facing prevalent security and privacy threats. Our results indicate that it is relatively easy to collect thousands of publicly available images of video conference meetings and extract personal information about the participants, including their face images, age, gender, usernames, and even full names. This type of data can vastly and easily jeopardize people’s security and privacy both in the online and real-world, affecting not only adults but also more vulnerable segments of society, such as children and older adults. Finally, we show that cross-referencing facial image data with social network data may put participants at additional privacy risks they may not be aware of and that it is possible to identify users that appear in several video conference meetings, thus providing a potential to maliciously aggregate different sources of information about a target individual.},
  archive      = {J_TCSS},
  author       = {Dima Kagan and Galit Fuhrmann Alpert and Michael Fire},
  doi          = {10.1109/TCSS.2022.3231987},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {933-944},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Zooming into video conferencing privacy},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-confidence rationality identification of group decision
making based on consensus analysis. <em>TCSS</em>, <em>11</em>(1),
919–932. (<a href="https://doi.org/10.1109/TCSS.2022.3223795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the consensus-reaching process (CRP) for group decision-making with self-confidence (SC) and considers personalized individual semantics (PIS). To identify the rationality of SC, this article first uses PIS to transform linguistic variables into numerical variables, by which initial SC-based adjustment intervals are derived. Further, maximum and minimum programming models at three layers are conducted to derive adjustment intervals in view of consensus analysis, by which SC-based revision adjustment intervals are obtained. Moreover, the rationality of SC-based revision adjustment intervals is judged by consensus models. When irrationality is identified, the model for minimizing consensus adjustment under the given consensus level is built. In this process, if corresponding decision-makers show non-cooperative behaviors, different penalty rules are recommended in various cases. Finally, the proposed method is applied to select ideal medical care and nursing institutions, and sensitivity and comparative analyses are performed.},
  archive      = {J_TCSS},
  author       = {Fan-Yong Meng and You Lv and Zong-Run Wang},
  doi          = {10.1109/TCSS.2022.3223795},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {919-932},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Self-confidence rationality identification of group decision making based on consensus analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic crowd navigation path planning in public scenes
through multiobjective differential evolution. <em>TCSS</em>,
<em>11</em>(1), 905–918. (<a
href="https://doi.org/10.1109/TCSS.2022.3217417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd navigation path planning is important in public scenes. Existing strategies are mainly based on manual design, which is not flexible or effective enough. This article proposes an evolutionary framework for automatic crowd navigation path planning in public scenes. The proposed framework contains a new fitness evaluation mechanism that can quantitatively evaluate the quality of a path planning strategy by considering both crowd safety and flow speed. Based on the fitness evaluation mechanism, a framework based on multiobjective differential evolution (DE) is developed to efficiently evolve path planning strategies. Simulation results on two synthetic scenes and a real-world metro station scene show that the proposed framework can provide good path planning strategies.},
  archive      = {J_TCSS},
  author       = {Jinghui Zhong and Dongrui Li and Wentong Cai and Wei-Neng Chen and Yuhui Shi},
  doi          = {10.1109/TCSS.2022.3217417},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {905-918},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Automatic crowd navigation path planning in public scenes through multiobjective differential evolution},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse graph transformer with contrastive learning.
<em>TCSS</em>, <em>11</em>(1), 892–904. (<a
href="https://doi.org/10.1109/TCSS.2022.3232117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information aggregation and propagation over networks via graph neural networks (GNNs) plays an important role in node or graph representation learning, which currently depend on the calculation with a fixed adjacency matrix, facing over-smoothing problem, and difficulty to stack multiple layers for high-level representations. In contrast, Transformer calculates an importance score for each node to learn its embedding via the attention mechanism and has achieved great successes in many natural language processing (NLP) and computer vision (CV) tasks. However, Transformer is inflexible to extend to graphs, as its input and output must have the same dimension. It will also become intractable to allocate attention over a large-scale graph due to distractions. Moreover, most graph Transformers are trained in supervised ways, which consume additional resources to annotate samples with potentially wrong labels and have limited generalization of representations. Therefore, this article attempts to build a new Sparse Graph Transformer with Contrastive learning for graph representation learning, called SGTC. Specifically, we first employ centrality measures to remove the redundant topological information from input graph according to the influences of nodes and edges, then disturb the pruned graph to get two different augmentation views, and learn node representations in a contrastive manner. Besides, a novel sparse attention mechanism is also proposed to capture structural features of graphs, which effectively save memory and training time. SGTC can produce low-dimensional and high-order node representations, which have better generalization for multiple tasks. The proposed model is evaluated on three downstream tasks over six networks, and experimental results confirm its superior performance against the state-of-the-art baselines.},
  archive      = {J_TCSS},
  author       = {Chun-Yang Zhang and Wu-Peng Fang and Hai-Chun Cai and C. L. Philip Chen and Yue-Na Lin},
  doi          = {10.1109/TCSS.2022.3232117},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {892-904},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Sparse graph transformer with contrastive learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep neural networks for location reference identification
from bilingual disaster-related tweets. <em>TCSS</em>, <em>11</em>(1),
880–891. (<a href="https://doi.org/10.1109/TCSS.2022.3213702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twitter is increasingly being used during disasters to communicate with authorities, ascertain the ground reality, and coordinate real-time rescue and recovery activities. Geographical location information about users and events is critical in these scenarios. Geotagged tweets are extremely infrequent, and other location fields, such as user location and place name, are unreliable. The extraction of geographical information from tweet text is limited by the fact that individuals frequently publish multilingual tweets that contain numerous grammatical and spelling errors, as well as nonstandard acronyms. As a result, determining the geographical location of the tweet is a challenging problem. This article presents a technique based on deep neural networks for extracting geographical references mentioned in bilingual tweets. Several deep learning-based models, including convolutional neural networks (CNNs), long short-term memory (LSTM), bidirectional LSTM (Bi-LSTM), and attention-based Bi-LSTM, are implemented on real-world English and Hindi language tweets to determine their suitability for extracting location references. The proposed CNN, along with a conditional random field at the last layer, is found to perform better than other models, with an $F_{1}$ -score of 0.858. The findings of this study can aid in early event detection, pinpointing the area of devastation and victims, real-time traffic management, and a number of other location-based applications. The suggested system’s code and trained model may be obtained at https://github.com/Abhinavkmr/Bi-lingual-location-reference-identification.git .},
  archive      = {J_TCSS},
  author       = {Abhinav Kumar and Jyoti Prakash Singh},
  doi          = {10.1109/TCSS.2022.3213702},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {880-891},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Deep neural networks for location reference identification from bilingual disaster-related tweets},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning embedding for signed network in social media with
global information. <em>TCSS</em>, <em>11</em>(1), 871–879. (<a
href="https://doi.org/10.1109/TCSS.2022.3217840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signed networks contain nodes connected by positive and negative signed links. Signed network representation learning concentrates on learning the low-dimensional representations of these nodes, which facilitates downstream tasks such as link prediction using general data mining framework. However, most signed network embedding (SiNE) approaches neglect global information in the networks, limiting the capacity to learn genuine signed graph topology. To overcome this limitation, a deep graph neural network (GNN) framework SiG to learn SiNE with global information is proposed. To be more explicit, a hierarchical pooling mechanism is developed to encode the high-level features of the networks. Moreover, a graph convolution layer is introduced to aggregate both positive and negative information from neighbor nodes, and the concatenation of two parts generates the final embedding of nodes. Extensive experiments on four large real-world signed network datasets demonstrate the effectiveness and excellence of the proposed method.},
  archive      = {J_TCSS},
  author       = {Jiawang Chen and Zhenqiang Wu and Mubarak Umar and Jun Yan and Xuening Liao and Bo Tian},
  doi          = {10.1109/TCSS.2022.3217840},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {871-879},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Learning embedding for signed network in social media with global information},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced syntactic and semantic graph convolutional network
with contrastive learning for aspect-based sentiment analysis.
<em>TCSS</em>, <em>11</em>(1), 859–870. (<a
href="https://doi.org/10.1109/TCSS.2023.3296476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) aims to predict the sentiment polarity of a given specific aspect in the sentence. Recent studies focus on leveraging graph convolutional neural networks to encode both syntactic and semantic information. However, current syntactic parsers, which are not specifically for ABSA, introduce noise to the syntactic information. Besides, ongoing studies ignore the distinctiveness of semantics and syntax. To address these issues, we proposed an enhanced syntactic and semantic graph convolutional network (GCN) with contrastive learning in this article. An aspect-oriented syntactic graph is constructed with aspect-specific perturbed masking for reducing the syntactic noise, and a semantic graph is established with self-attention weights from bidirectional encoder representation from transformers (BERT). The semantic and syntactic representations are further enhanced by both sentiment polarity-based supervised contrastive learning and syntactic reliability-based unsupervised contrastive learning. Furthermore, label embeddings of syntactic reliability are learned to determine the weights of syntactic and semantic information. Extensive experiments on four publicly available datasets demonstrate that our model is more competitive than the state-of-the-arts.},
  archive      = {J_TCSS},
  author       = {Minzhao Guan and Fenghuan Li and Yun Xue},
  doi          = {10.1109/TCSS.2023.3296476},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {859-870},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Enhanced syntactic and semantic graph convolutional network with contrastive learning for aspect-based sentiment analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MTBullyGNN: A graph neural network-based multitask framework
for cyberbullying detection. <em>TCSS</em>, <em>11</em>(1), 849–858. (<a
href="https://doi.org/10.1109/TCSS.2022.3230974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyberbullying is a malady of social media, and its automatic detection is critically important considering its virulence, velocity of spreading, and the scale of the havoc it can wreak. However, the problem is challenging due to its disguised behavior, noise in the content, and, in recent times, introduction of code-mixing. In this work, we propose MTBullyGNN a novel graph neural network (GNN)-based multitask (MT) framework that solves sentiment-aided cyberbullying detection (CD) from code-mixed language. The GNN helps detect unlabelled or noisy label nodes (sentences) accurately by aggregating information from similarly labeled nodes. To connect nodes, we apply cosine similarity between sentences and create a single text graph for a benchmark code-mixed cyberbullying corpus, BullySent. Experimental results illustrate that MTBullyGNN outperforms the state-of-the-art (SOTA) methods for both the single (CD) and MT (CD and sentiment) settings by up to 4.46% and 4.92% in classification accuracy, respectively. Furthermore, another benchmark Hindi–English code-mixed single-task dataset has also been considered to illustrate the robustness of our proposed model. The code will be made publicly available in the camera-ready version.},
  archive      = {J_TCSS},
  author       = {Krishanu Maity and Tanmay Sen and Sriparna Saha and Pushpak Bhattacharyya},
  doi          = {10.1109/TCSS.2022.3230974},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {849-858},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {MTBullyGNN: A graph neural network-based multitask framework for cyberbullying detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel DAO-based parallel enterprise management framework
in web3 era. <em>TCSS</em>, <em>11</em>(1), 839–848. (<a
href="https://doi.org/10.1109/TCSS.2023.3239059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel parallel management mode based on decentralized autonomous organizations (DAOs) for enterprises by utilizing the artificial systems, computational experiments, parallel execution (ACP) approach, parallel intelligence theory, and blockchain technologies, to realize the distributed management of an enterprise. The artificial enterprise DAO (EnDAO) corresponding to the actual enterprise is constructed, and they constitute a parallel system via virtual–real interaction and parallel execution. Through the non-fungible token (NFT)-based incentive mechanism, metaverse-based virtual learning and training, as well as DAO-based distributed management and decision-making, the management and control of the actual enterprise as well as its employees can be carried out. By virtue of the virtual–real interactions of three types of employees, as well as the virtual–real feedback of three closed loops in the parallel systems, DAO-based parallel management for enterprises can realize descriptive intelligence, predictive intelligence, and prescriptive intelligence. On this basis, this article takes the recruitment-oriented key performance indicator (KPI) management of a startup technology enterprise as the case to introduce the operation processes and illustrate the superiorities of the proposed DAO-based enterprise parallel management mode.},
  archive      = {J_TCSS},
  author       = {Ge Wang and Rui Qin and Juanjuan Li and Fei-Yue Wang and Yu Gan and Lihua Yan},
  doi          = {10.1109/TCSS.2023.3239059},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {839-848},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A novel DAO-based parallel enterprise management framework in web3 era},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A heterogeneous graph neural network with attribute
enhancement and structure-aware attention. <em>TCSS</em>,
<em>11</em>(1), 829–838. (<a
href="https://doi.org/10.1109/TCSS.2023.3239034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information network (HIN) has been applied in a wide variety of graph analysis tasks. At present, it is a trend of heterogeneous graph neural networks (HGNNs) to cast the meta-paths aside, since it solves the problem of structural information loss caused by artificially designed meta-paths. However, existing meta-path-free HGNNs fail to take into account that most node types in many HINs have no attributes, and they cannot make full use of sparse node attributes when applied to HINs with missing attributes. Furthermore, their computation of attention coefficients explores the correlations of node attributes while almost ignoring structural ones, which may limit the expression ability of the model and cause overfitting in model training. To alleviate these issues, we propose an HGNN with attribute enhancement and structure-aware attention (HGNN-AESA). First, we design an attribute enhancement module (AEM) to connect more useful attributed nodes to the target nodes. Specifically, AEM introduces a random walk with restart (RWR) strategy to obtain structural relevance scores of each node within its specific subgraph. The structural relevance scores are used to capture potentially influential attributed nodes in high-order neighborhood for each target node. Second, we propose heterogeneous structure-aware attention layers (HSALs) to learn node representations. HSALs follow a hierarchical attention framework, including node-level and type-level attention. The node-level attention aggregates feature (attribute) embeddings of same-type neighbors, and the relevant attention coefficients depend on the combination of node attributes and heterogeneous structural interventions. The type-level attention fuses all type-specific vector representations and generates the ultimate node embedding. Finally, extensive experiments on three different real-world HIN datasets demonstrate that our model outperforms state-of-the-art methods.},
  archive      = {J_TCSS},
  author       = {Shenghang Fan and Guanjun Liu and Jian Li},
  doi          = {10.1109/TCSS.2023.3239034},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {829-838},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A heterogeneous graph neural network with attribute enhancement and structure-aware attention},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-agent system for fine-grained opinion dynamics
analysis in online social networks. <em>TCSS</em>, <em>11</em>(1),
815–828. (<a href="https://doi.org/10.1109/TCSS.2022.3219036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The influence and dissemination of users’ opinions are the essence of the opinion dynamics in online social networks (OSNs). Understanding the process of users’ opinion formation and propagation can provide better service for public opinion monitoring and product advertising. However, most opinion dynamics research typically do not distinguish between user opinion formation and propagation, instead focusing on the process of mass opinion polarization. This article presents a multiagent system (MAS) to analyze fine-grained opinion dynamics (FOD) by agent-based modeling (ABM). At the macro level, the MAS-FOD system we designed can produce a statistical analysis of public opinion evolution based on different parameter constellations and analyze the changes in personalized agent opinions. At the micro level, the agent-based model is presented to describe the single user in OSNs as an individualized agent in MAS-FOD. Specifically, we propose two mechanisms, agent-based opinion formation (AOF) mechanism and agent-based opinion propagation (AOP) mechanism, for agents to form and disseminate opinions, respectively. Meanwhile, multidimensional social influence features mining from self, local neighbors, and global topic community are defined and used in two mechanisms to train personalized agents to self-adapt to the MAS-FOD system. We demonstrate the rationality and effectiveness of the MAS-FOD system from two types of experiments: empirical analysis and simulation analysis. The former is driven by empirical social network data to analyze the predictive performance of AOF; the latter simulates the public opinion propagation through the AOP mechanism in the MAS-FOD system. The results demonstrate that: 1) the AOF outperforms SOTA methods in the accuracy of agent opinion prediction; 2) the dissemination effect based on the AOP is more closer to the actual evolution trend of public opinion than the baseline; and 3) the MAS-FOD system can perform fine-grained analysis of opinion dynamics by adjusting different parameters.},
  archive      = {J_TCSS},
  author       = {Huiyu Min and Jiuxin Cao and Jiawei Ge and Bo Liu},
  doi          = {10.1109/TCSS.2022.3219036},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {815-828},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A multi-agent system for fine-grained opinion dynamics analysis in online social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A streaming graph partitioning method to achieve high
cohesion and equilibrium via multiplayer repeated game. <em>TCSS</em>,
<em>11</em>(1), 803–814. (<a
href="https://doi.org/10.1109/TCSS.2022.3226230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of 5G era, Internet-of-Things will become possible, and a large amount of correlative data, namely the streaming graph (SG), is continuously generated in various application fields, which poses a great challenge to analyze and make good use of such graph data. The balanced partition of a big graph, especially a dynamic SG, has always been basic research in graph theory, and there are many classical methods. However, this article explores a novel method, that is, an SG $k$ -way partitioning via a multiplayer repeated game so as to realize the equilibrium of the total number of nodes in different partitions and achieve high cohesion or low edge-cut in each partition. We regard the SG partitioning process during each time window as a multiplayer game process, treat $k$ target partitions as game players, and use all possible actions that players select new nodes as the strategy set. Some effective constraints are given to reduce the strategy space and accelerate the game process. Moreover, we define equilibrium degree (ED) and modularity degree (MD), which are used to design the utility function of game players. All game players finally reach the Nash equilibrium via multiplayer repeated games. At this time, each player corresponds to a strategy. Under the guidance of these strategies, the new nodes are added to each target partition, and then the goal of optimal partitioning is achieved. The above operations are carried out in each time window. The subsequent time windows can reuse the partitioning results of the previous time window in order to realize dynamic incremental partitioning for an SG. Extensive experiments indicate that while ensuring the partition quality of an SG, our proposed algorithm also greatly improves the speed of online partitioning. Even compared with the state-of-the-art SG partitioning algorithm PLDG, our algorithm still obtains better performance.},
  archive      = {J_TCSS},
  author       = {Zhipeng Sun and Guosun Zeng and Chunling Ding and Tengteng Cheng},
  doi          = {10.1109/TCSS.2022.3226230},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {803-814},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A streaming graph partitioning method to achieve high cohesion and equilibrium via multiplayer repeated game},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An approach to modeling cognitive antagonism with incomplete
information. <em>TCSS</em>, <em>11</em>(1), 795–802. (<a
href="https://doi.org/10.1109/TCSS.2022.3233365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cognitive antagonism is one of the core aspects in electromagnetic spectrum warfare. Since it is impossible for the opposing parties to perceive the state information of each other completely, the existing evaluation methods are inappropriate for evaluating the cognitive antagonistic effectiveness. For solving this problem, a Stackelberg game-based method of modeling the cognitive antagonism with incomplete information is proposed in this article, i.e., depending on the domain knowledge and public information, we first tease out the antijamming measures of radars and then propose the empirical formulas of antijamming improve factors accordingly. Similarly, the method to calculate the jamming payoff is proposed for the power suppression and spoofing patterns of jammers. Furthermore, the method of constructing the strategy matrices for bimatrix Stackelberg game is presented. By taking the probability of radar recognizing false targets as uncertain information, we test the effect of game in a specified antagonistic environment and draw out some useful conclusions from the testing results.},
  archive      = {J_TCSS},
  author       = {Hongguang Ma and Jinku Guo and Xiaoshan Song and Zhengping Long and Dongming Lei},
  doi          = {10.1109/TCSS.2022.3233365},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {795-802},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An approach to modeling cognitive antagonism with incomplete information},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy protection for marginal-sensitive community
individuals against adversarial community detection attacks.
<em>TCSS</em>, <em>11</em>(1), 782–794. (<a
href="https://doi.org/10.1109/TCSS.2022.3229162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks especially the social communities facilitate the rapid and rich social activities of all individuals in the world. However, advanced community detection brings serious privacy disclosure (e.g., whether two important and sensitive individuals belong to the same community?) to us. For instance, online plainclothes policemen can be regarded as marginal community users who are often in the same community initially and in need of penetrating into as many as possible different communities to collect illegal evidence of network criminals, but adversarial community inference which can maliciously disclose the sensitive user relationships within a target community will expose their privacy and lead to task failure. Thus, privacy protection for the marginal community users becomes an urgent issue which is still open so far. In this work, we aim to study the community privacy protection for target marginal individuals of a community against multiple adversarial community detection (ACD) attacks. First, we define the marginal community user hiding problem and propose a marginal user pair selection strategy. Second, to enhance the privacy effectiveness of conventional methods, we propose a deep graph learning approach to maximally find the minimum link perturbation cost. Finally, we conduct various community detection attacks on many real social graphs, and the experimental results show that our method can more effectively hide the marginal-sensitive user pairs than baselines.},
  archive      = {J_TCSS},
  author       = {Cong Chen and Zhongyuan Jiang and Jianfeng Ma},
  doi          = {10.1109/TCSS.2022.3229162},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {782-794},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Privacy protection for marginal-sensitive community individuals against adversarial community detection attacks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New computing tasks offloading method for MEC based on
prospect theory framework. <em>TCSS</em>, <em>11</em>(1), 770–781. (<a
href="https://doi.org/10.1109/TCSS.2022.3228692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) provides reliable solutions for networked vehicles, mobile phones, and other mobile devices to complete intensive computing and delay-sensitive tasks. Most of the existing studies design a series of methods to achieve the expected goals based on assuming that users are absolutely rational. However, due to the subjectivity of users, the actual results will deviate from the real situation. Using the prospect theory (PT) framework, this article studies the problem of computing task offloading in real situations. Aiming at the task offloading problem in the small cellular network scenario, the artificial fish swarm algorithm is used to optimize the system energy with limited delay. Finally, the experimental tests verify the impact of user behavior on the system energy optimization and the effectiveness of the task offloading method proposed in this article.},
  archive      = {J_TCSS},
  author       = {De-Gan Zhang and Wen-Miao Dong and Ting Zhang and Jie Zhang and Ping Zhang and Gui-Xiang Sun and Ya-Hui Cao},
  doi          = {10.1109/TCSS.2022.3228692},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {770-781},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {New computing tasks offloading method for MEC based on prospect theory framework},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diversity-optimized group extraction in social networks.
<em>TCSS</em>, <em>11</em>(1), 756–769. (<a
href="https://doi.org/10.1109/TCSS.2022.3224935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose to study a novel research problem to boost group performance, that is, social-aware diversity-optimized group extraction (SDGE), which takes into consideration the two important factors: 1) group diversity and 2) social tightness. We prove the NP-hardness of SDGE and propose an effective algorithm, named group shrinking for diversity maximization (GSDM) with a performance guarantee, that is, GSDM is a three-approximation algorithm to the SDGE problem studied in this article. We further propose three effective pruning strategies that are able to boost the efficiency of GSDM but do not deteriorate its performance. We conduct extensive experiments on multiple large-scale real datasets to evaluate the performance of GSDM. The experimental results show that our proposed GSDM outperforms the other baseline approaches significantly, in terms of solution quality and efficiency. Moreover, the experimental results also confirm that our proposed pruning strategies indeed boost the efficiency of the algorithm.},
  archive      = {J_TCSS},
  author       = {Bay-Yuan Hsu and Yi-Ling Chen and Ya-Chi Ho and Po-Yuan Chang and Chih-Chieh Chang and Ben-Chang Shia and Chih-Ya Shen},
  doi          = {10.1109/TCSS.2022.3224935},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {756-769},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Diversity-optimized group extraction in social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A similarity measurement method of normal cloud models for
the operational status perception and computing of urban rail transit.
<em>TCSS</em>, <em>11</em>(1), 746–755. (<a
href="https://doi.org/10.1109/TCSS.2022.3215893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The similarity measurement method is the key part of the normal cloud model as well as its applications. Too much attention has been paid on geometric and numerical features, leading to the weak interpretability and unreasonable results in the similarity measurement method of the normal cloud models. A bidirectional and weighted similarity measurement (BWSM) method is proposed by the number distribution and membership of cloud droplets on a normal cloud model. First, the cloud droplets are analyzed, and their characteristics of number distribution and membership that belong to different cloud models are obtained. Second, the similarity measurement strategy of the normal cloud models is analyzed and used to propose a BWSM method, which is compared with two commonly used similarity measurement methods of normal cloud models. The influence of expectation, entropy, and hyper entropy on the similarity measurement method of the normal cloud models is analyzed. Finally, the method is applied on the operational status perception and computing of urban rail transit. Results show the method has high rationality, validity, and applicability for perceiving and computing the operational status of urban rail transit. The method improves the interpretability of the similarity measurement of the normal cloud models and the credibility of the research based on the similarity measurement of the normal cloud models.},
  archive      = {J_TCSS},
  author       = {Guangyu Zhu and Yubo Yang and Ranran Sun and Edmond Q. Wu and Rob Law},
  doi          = {10.1109/TCSS.2022.3215893},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {746-755},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A similarity measurement method of normal cloud models for the operational status perception and computing of urban rail transit},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual analysis of money laundering in cryptocurrency
exchange. <em>TCSS</em>, <em>11</em>(1), 731–745. (<a
href="https://doi.org/10.1109/TCSS.2022.3231687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain-based cryptocurrencies, such as Bitcoin (BTC) and Ethereum (ETH), are newly emerging financial assets. Cryptocurrency exchanges are marketplaces for cryptocurrency circulation while becoming a new venue for money laundering. In this work, we cooperate with a cryptocurrency exchange to investigate new solutions for anti-money laundering in cryptocurrency exchanges. First, we learn the domain knowledge of cryptocurrency transactions and summarize data analytical requirements of transaction supervisors in their daily work of anti-money laundering. Then, we propose a visual analysis approach to support their daily work. The approach consists of a new algorithm that automatically detects suspicious money laundering accounts and a multiviewed user interface that visualizes the algorithm results and relevant transaction data. An abacus-inspired visualization is designed in the interface to depict transaction patterns contained in numerous cryptocurrency transactions, which can help supervisors find money laundering clues and deduce the trading tactic adopted by launderers. Finally, an algorithm performance experiment, a case study, and a field study are conducted with real-world data to demonstrate the effectiveness of our solution.},
  archive      = {J_TCSS},
  author       = {Fangfang Zhou and Yunpeng Chen and Chunyao Zhu and Lijia Jiang and Xincheng Liao and Zengsheng Zhong and Xiaohui Chen and Yi Chen and Ying Zhao},
  doi          = {10.1109/TCSS.2022.3231687},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {731-745},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Visual analysis of money laundering in cryptocurrency exchange},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PANDORA: Deep graph learning based COVID-19 infection risk
level forecasting. <em>TCSS</em>, <em>11</em>(1), 717–730. (<a
href="https://doi.org/10.1109/TCSS.2022.3229671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus disease 2019 (COVID-19) as a global pandemic causes a massive disruption to social stability that threatens human life and the economy. An effective forecasting system is arguably important to provide an early signal of the risk of COVID-19 infection so that the authorities are ready to protect the people from the worst. However, making a good forecasting model for infection risks in different cities or regions is not an easy task, because it has a lot of influential factors that are difficult to be identified manually. To address the current limitations, we propose a deep graph learning model, called PANDORA, to predict the infection risks of COVID-19, by considering all essential factors and integrating them into a geographical network. The framework uses geographical position relationships and transportation frequency as higher order structural properties formulated by higher order network structures (i.e., network motifs). Moreover, four significant node attributes (i.e., multiple features of a particular area, including climate, medical condition, economy, and human mobility) are also considered. We propose three different aggregators to better aggregate node attributes and structural features, namely, Hadamard, Summation, and Connection. Experimental results over real data show that PANDORA outperforms the baseline methods with higher accuracy and faster convergence speed, no matter which aggregator is chosen.},
  archive      = {J_TCSS},
  author       = {Shuo Yu and Feng Xia and Yueru Wang and Shihao Li and Falih Gozi Febrinanto and Madhu Chetty},
  doi          = {10.1109/TCSS.2022.3229671},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {717-730},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {PANDORA: Deep graph learning based COVID-19 infection risk level forecasting},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CapsLSTM-based human activity recognition for smart
healthcare with scarce labeled data. <em>TCSS</em>, <em>11</em>(1),
707–716. (<a href="https://doi.org/10.1109/TCSS.2022.3223343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scarcity of labeled data in sensitive research areas such as healthcare limits the performance of artificially intelligent (AI) models. The effort required in labeling the acquired healthcare data for carrying out a classification task is a concern faced by healthcare researchers. In this work, we design a capsule-long short-term memory (LSTM) model, abbreviated as CapsLSTM, capable of classifying human activities with scarce labeled activity data. The proposed CapsLSTM model is used to recognize multiple human activities sensed by the accelerometer and the gyroscope sensors embedded in smartphones leveraging the spatio-temporal information. We validate the proposed framework based on two human activity recognition (HAR) databases, namely, UCI-HAR and MotionSense. The CapsLSTM model yields close test accuracies for different fractions of the training data unlike the other models such as LSTM, 1-D convolutional neural network (1D-CNN), convolutional LSTM (ConvLSTM), or CNN-LSTM. For the state-of-the-art models, the test accuracies decrease significantly with the decrease in training data. Our proposed model classifies the human activities using a minimum of 20% labeled training data from each database. There is less decrease in accuracies from that obtained using 70% of training data in comparison to the existing models. The classification performance of the proposed CapsLSTM model for a small fraction of training data proves the effectiveness and reliability of the same in a data-scarce situation.},
  archive      = {J_TCSS},
  author       = {Pritam Khan and Yogesh Kumar and Sudhir Kumar},
  doi          = {10.1109/TCSS.2022.3223343},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {707-716},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {CapsLSTM-based human activity recognition for smart healthcare with scarce labeled data},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). TFC: Transformer fused convolution for adversarial domain
adaptation. <em>TCSS</em>, <em>11</em>(1), 697–706. (<a
href="https://doi.org/10.1109/TCSS.2022.3229693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In unsupervised domain adaptation (UDA), a classifier is applied to the target domain without or with limited labels, when the target domain has no or few labels. Recently, inspired by their capabilities of long-distance feature dependencies, vision transformer (ViT)-based methods have been used in UDA, however, they ignore the fact that ViT lacks strength in extracting local feature details. To handle the above problems, the purpose of this article is to demonstrate how to take advantage of both convolutional operations and transformer mechanisms for adversarial UDA by using a hybrid network structure called transformer fused convolution (TFC). TFC integrates local features with global features to boost the representation capacity for UDA which can enhance the discrimination between foreground and background. Moreover, to improve the robustness of the TFC, we leverage an uncertainty penalty loss to make incorrect classes have consistently lower scores. Extensive experiments validate the significant performance gains compared to conditional adversarial domain adaptation (CDAN) on all five datasets including DomainNet ( $\uparrow ~8.5$ %), VisDA-2017 ( $\uparrow ~14.9$ %), Office-Home ( $\uparrow ~18.9$ %), Office-31 ( $\uparrow ~11.5$ %), and ImageCLEF-DA ( $\uparrow ~5.5$ %).},
  archive      = {J_TCSS},
  author       = {Mengzhu Wang and Junyang Chen and Ye Wang and Zhiguo Gong and Kaishun Wu and Victor C. M. Leung},
  doi          = {10.1109/TCSS.2022.3229693},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {697-706},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {TFC: Transformer fused convolution for adversarial domain adaptation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Referral strategy based on social network incentive.
<em>TCSS</em>, <em>11</em>(1), 683–696. (<a
href="https://doi.org/10.1109/TCSS.2022.3230876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customers’ social network is often regarded as valuable capital for companies and individuals. Although quite a few studies have empirically demonstrated the positive influence of customers’ social networks on boosting sale performance, it is still an open question that how to utilize customers’ social networks to design profitable and feasible referral incentive strategies. To this end, this work establishes a game model by introducing the referral incentive strategies of different forms based on the analysis of the marketing process. Regarding the modeled incentive strategy as the target of solving the game model, this work finds it is an NP-hard problem of solving the model and further proposes an approximate algorithm. In order to cope with large-scale data sets, the proposed algorithm is further extended into a new one with low time complexity. Then, theoretical analysis, numerical experiments, and real applications are conducted to validate the performance of the model. In all, the proposed model, algorithm, and findings contribute to both theoretic models and practical operations in the field of social networks and social computation.},
  archive      = {J_TCSS},
  author       = {Yongli Li and Chao Liu and Chuang Wei and Xiaochen Ma},
  doi          = {10.1109/TCSS.2022.3230876},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {683-696},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Referral strategy based on social network incentive},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessment of wealth distribution in blockchain online
social media. <em>TCSS</em>, <em>11</em>(1), 671–682. (<a
href="https://doi.org/10.1109/TCSS.2022.3228925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks (OSNs) revolutionized how people interact with each other, and nowadays, thanks to blockchain technology, new solutions are being considered, giving birth to blockchain online social media (BOSMs). BOSMs use the blockchain to redistribute with their users the wealth generated by the platform through a rewarding system, assigning better rewards to socially impactful users. Thus, these new systems are characterized by highly intertwined economical and social aspects and constitute a new scenario in the world of social networks. Many scenarios, economic and social alike, show a phenomenon known as “the rich-get-richer,” which states that the richest actors of a system tend to become richer over time. To the best of our knowledge, in the scenario of BOSMs, where users can acquire cryptocurrency through their social actions, this type of phenomenon was not yet studied. In this article, we propose a methodological framework composed of three hypotheses that can help study the rich-get-richer phenomenon through a set of measures and indices. In addition, we apply the proposed framework to the Steem case study, showing how unevenly wealth is distributed on its blockchain and comparing our results to other scenarios.},
  archive      = {J_TCSS},
  author       = {Barbara Guidi and Andrea Michienzi and Laura Ricci},
  doi          = {10.1109/TCSS.2022.3228925},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {671-682},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Assessment of wealth distribution in blockchain online social media},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complaint and severity identification from online financial
content. <em>TCSS</em>, <em>11</em>(1), 660–670. (<a
href="https://doi.org/10.1109/TCSS.2022.3215528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic detection of financial complaints (FINCORP) can benefit businesses and online merchants. Compared with manually tagged complaints, they can use this information to monitor and address issues and effectively route them to appropriate teams. This can also promote greater transparency and accountability when dealing with consumer financial products and services, strengthening the firm’s brand value. In linguistic studies, complaints have been classified into severity categories based on the level of risk the complainant is prepared to accept. Furthermore, since emotions influence every speech act, an individual’s emotional state considerably impacts the complaint expression. In this article, we introduce a FINCORP resource, a collection of annotated complaints arising between financial institutions and consumers expressed in English on Twitter. The dataset has been enriched with the associated emotion, sentiment, and complaint severity classes. The dataset comprises 3149 complaint and 3133 noncomplaint instances spanning over ten domains (e.g., credit cards, mortgages). For a comprehensive evaluation of our dataset, we develop a multitask framework for complaint detection and severity classification with emotion recognition (ER) and sentiment classification as the additional tasks and compare it with several existing baselines. The corpus and code are available here: https://github.com/RohanBh23/FINCORP .},
  archive      = {J_TCSS},
  author       = {Apoorva Singh and Rohan Bhatia and Sriparna Saha},
  doi          = {10.1109/TCSS.2022.3215528},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {660-670},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Complaint and severity identification from online financial content},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Governance of social welfare in networked markets.
<em>TCSS</em>, <em>11</em>(1), 652–659. (<a
href="https://doi.org/10.1109/TCSS.2022.3225279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article aims to investigate how a central authority (e.g., a government) can increase social welfare (SW) in a network of markets and firms. In these networks, modeled using a bipartite graph, firms compete with each other ` a la Cournot. Each firm can supply homogeneous goods in markets which it has access to. The central authority may take different policies for its aim. In this article, we assume that the government has a budget by which it can supply some goods and inject them into various markets. We discuss how the central authority can best allocate its budget for the distribution of goods to maximize SW. We show that the solution is highly dependent on the structure of the network. Then, using the network’s structural features, we present a heuristic algorithm for our target problem. Finally, we compare the performance of our algorithm with other heuristics with experimentation on real datasets.},
  archive      = {J_TCSS},
  author       = {Mohammadamin Fazli and Alireza Amanihamedani},
  doi          = {10.1109/TCSS.2022.3225279},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {652-659},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Governance of social welfare in networked markets},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Social system inference from noisy observations.
<em>TCSS</em>, <em>11</em>(1), 639–651. (<a
href="https://doi.org/10.1109/TCSS.2022.3229599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies social system inference from a single noisy trajectory of public evolving opinions, wherein observation noise leads to the statistical dependence of samples on time and coordinates. We first propose a cyber-social system that comprises individuals in a social network and a set of information sources in a cyber layer, whose opinion dynamics explicitly takes the asymmetric cognitive bias including confirmation bias and negativity bias and the process noise into account. Based on the proposed cyber-social model, we then study the sample complexity of least-square auto-regressive model estimation, which governs the length of a single observed trajectory that is sufficient for the identified model to achieve the prescribed levels of accuracy and confidence (PAC). Building on the identified social model, we then investigate social inference, with a particular focus on the weighted network topology and the model parameters of asymmetric cognitive bias. Finally, the theoretical results and the effectiveness of the proposed inference framework are validated by the U.S. Senate Member Ideology data.},
  archive      = {J_TCSS},
  author       = {Yanbing Mao and Naira Hovakimyan and Tarek Abdelzaher and Evangelos Theodorou},
  doi          = {10.1109/TCSS.2022.3229599},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {639-651},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Social system inference from noisy observations},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). SEI3R2D2V: Pandemic modeling and analysis of its latent
factors: A case study of COVID-19 in india. <em>TCSS</em>,
<em>11</em>(1), 625–638. (<a
href="https://doi.org/10.1109/TCSS.2022.3225639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For densely populated developing countries, such as India, where due to a lack of general and public awareness, limited data collection and compilation facilities, and inherent limitations of the available diagnostic test, accurate modeling of the pandemic is more challenging. Thus, a realistic model for predictions is required in order to formulate more effective strategic policies to control the COVID-19 pandemic using limited available resources. In this article, we propose a time-varying epidemiological model with two classes of compartments, reported and unreported, and consider influential latent factors, for example, undetectable infections, the false-negative rate of testing, testing hesitancy, vaccination efficacy, dual contact dynamics, and the possibility of reinfection in recovered as well as vaccinated individuals. For simulation purposes, we consider the COVID-19 data of India from March 13, 2020, to January 20, 2022. Furthermore, we provide a sensitivity analysis of various latent factors and predictions for the third wave in India. Simulated results suggest that India is able to control COVID-19 for the first time after the second wave, as observed from the trajectory of effective reproduction number. Moreover, for unseen or coming variants of virus for which vaccine efficacy is low, the available vaccine requires a high vaccination rate to control future waves.},
  archive      = {J_TCSS},
  author       = {Vaishali Kansal and Pradumn Kumar Pandey},
  doi          = {10.1109/TCSS.2022.3225639},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {625-638},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {SEI3R2D2V: pandemic modeling and analysis of its latent factors: a case study of COVID-19 in india},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MCARS-CC: A salable multicontext-aware recommender system.
<em>TCSS</em>, <em>11</em>(1), 612–624. (<a
href="https://doi.org/10.1109/TCSS.2022.3223516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context-aware recommendation systems (CARSs) leverage contextual information, e.g., time, location, or mood, to generate more personalized recommendations with high accuracy; however, existing CARSs fall short in: 1) handling the high sparsity of data; 2) designing scalable solutions in real time; and 3) providing more personalized solutions with the current limited static contexts. This article proposes a multi-CARS based on consensus clustering (MCARS-CC) to solve these challenges. The item-based contextual information is acquired using explicit static and inferred contexts by applying sentiment analysis to the users’ reviews. The proposed model is experimented using contextual prefiltering and postfiltering techniques applied to two benchmark datasets, Yelp and TripAdvisor. The model is evaluated using mean absolute error (MAE), root-mean-squared error (RMSE), response time, precision, recall, and F-measure. The experimental results show that the proposed MCARS-CC model outperforms other baseline techniques using the accuracy and error-based metrics. Incorporating hypergraph partitioning algorithm (HGPA) could improve the MAE and RMSE by 25.96% and 8.94% (Yelp), respectively. Also, HGPA led to an 18.47% and 15.94% improvement ratio in terms of MAE and RMSE (TripAdvisor), respectively.},
  archive      = {J_TCSS},
  author       = {Dina Nawara and Rasha Kashef},
  doi          = {10.1109/TCSS.2022.3223516},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {612-624},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {MCARS-CC: A salable multicontext-aware recommender system},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inferring individual human mobility from sparse check-in
data: A temporal-context-aware approach. <em>TCSS</em>, <em>11</em>(1),
600–611. (<a href="https://doi.org/10.1109/TCSS.2022.3231601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring individual human mobility at a given time is not only beneficial for personalized location-based services but also crucial for tracking trajectory of the confirmed cases in the COVID-19 pandemic. However, individual-generated trajectory data from mobile Apps are characterized by implicit feedback, which means only a few individual-location interactions can be observed. Existing studies based on such sparse trajectory data are not sufficient to infer an individual’s missing mobility in his/her historical trajectory and further predict an individual’s future mobility at a given time under a unified framework. To address this concern, in this article, we propose a temporal-context-aware framework that incorporates multiple factors to model the time-sensitive individual-location interactions in a bottom-up way. Based on the idea of feature fusion, the driving effect of heterogeneous information on an individual’s mobility is gradually strengthened, so that the temporal-spatial context when a check-in occurs can be accurately perceived. We leverage Bayesian personalized ranking (BPR) to optimize the model, where a novel negative sampling method is employed to alleviate data sparseness. Based on three real-world datasets, we evaluate the proposed approach with regard to two different tasks, namely, missing mobility inference and future mobility prediction at a given time. Experimental results encouragingly demonstrate that our approach outperforms multiple baselines in terms of two evaluation metrics. Furthermore, the predictability of individual mobility within different time windows is also revealed.},
  archive      = {J_TCSS},
  author       = {Shuai Xu and Xiaoming Fu and Dechang Pi and Zhuo Ma},
  doi          = {10.1109/TCSS.2022.3231601},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {600-611},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Inferring individual human mobility from sparse check-in data: A temporal-context-aware approach},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An emotion-aware multitask approach to fake news and rumor
detection using transfer learning. <em>TCSS</em>, <em>11</em>(1),
588–599. (<a href="https://doi.org/10.1109/TCSS.2022.3228312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networking sites, blogs, and online articles are instant sources of news for internet users globally. However, in the absence of strict regulations mandating the genuineness of every text on social media, it is probable that some of these texts are fake news or rumors. Their deceptive nature and ability to propagate instantly can have an adverse effect on society. This necessitates the need for more effective detection of fake news and rumors on the web. In this work, we annotate four fake news detection (EFN) and rumor detection datasets with their emotion class labels using transfer learning. We show the correlation between the legitimacy of a text with its intrinsic emotion for fake news and rumor detection, and prove that even within the same emotion class, fake and real news are often represented differently, which can be used for improved feature extraction. Based on this, we propose a multitask framework for fake news and rumor detection, predicting both the emotion and legitimacy of the text. We train a variety of deep learning models in single-task (STL) and multitask settings for a more comprehensive comparison. We further analyze the performance of our multitask approach for EFN in cross-domain settings to verify its efficacy for better generalization across datasets, and to verify that emotions act as a domain-independent feature. Experimental results verify that our multitask models consistently outperform their STL counterparts in terms of accuracy, precision, recall, and F1 score, both for in-domain and cross-domain settings. We also qualitatively analyze the difference in performance in STL and multitask learning (MTL) models.},
  archive      = {J_TCSS},
  author       = {Arjun Choudhry and Inder Khatri and Minni Jain and Dinesh Kumar Vishwakarma},
  doi          = {10.1109/TCSS.2022.3228312},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {588-599},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An emotion-aware multitask approach to fake news and rumor detection using transfer learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ArtCap: A dataset for image captioning of fine art
paintings. <em>TCSS</em>, <em>11</em>(1), 576–587. (<a
href="https://doi.org/10.1109/TCSS.2022.3223539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image captioning of fine art paintings aims at generating content descriptions for the paintings. Due to the complexity of modeling both image and language, this task usually needs sufficient training data. However, different from photographic image captioning, there are few satisfactory datasets for painting captioning. In this article, we introduce a painting captioning dataset (named the ArtCap dataset), which contains 3606 paintings and five descriptions for each painting. We present the carefully designed construction pipeline of our dataset and further evaluate our dataset from two aspects of annotation quality and application effectiveness, respectively. For the annotation quality, we compare the global characteristics, annotation content, and annotation consistency of our dataset with other painting descriptions datasets. For application effectiveness, we employ our dataset and other painting descriptions datasets to train image captioning models and analyze the captioning performances. The results demonstrate the promising annotation quality and application effectiveness of our dataset.},
  archive      = {J_TCSS},
  author       = {Yue Lu and Chao Guo and Xingyuan Dai and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2022.3223539},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {576-587},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {ArtCap: A dataset for image captioning of fine art paintings},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asynchronous threshold ECDSA with batch processing.
<em>TCSS</em>, <em>11</em>(1), 566–575. (<a
href="https://doi.org/10.1109/TCSS.2022.3230903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Threshold Elliptic Curve Digital Signature Algorithm (ECDSA) has attracted a lot of attention due to the wide applications of ECDSA in crypto asset. Although several variants of threshold signature protocols can provide functions, such as key generation and signing, they suffer from two shortfalls. First, these schemes only discuss a single signature computation task in a synchronous algorithm context, which is difficult to adapt to real crypto-asset applications, such as custody. Second, these schemes are computing intensive and not scalable, hence can hardly support large-scale processing operations in real life even after traditional optimization, such as multithreading, is applied. In this article, we propose an innovative computation method called asynchronous threshold ECDSA with batch processing, based on the interactive threshold signature protocols. The method provides a reliable solution for critical operational scenarios, such as threshold signing and distributed key generation (DKG) in crypto-asset custody, and can be a future reference in secure data distribution mechanisms. The performance and scalability of our methods are validated through a benchmark testing.},
  archive      = {J_TCSS},
  author       = {Hongxin Zhang and Guanghuan Xie and Xin Zou and Chi Zhang and Zhuo Li and Rui Qin and Gang Xiong and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2022.3230903},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {566-575},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Asynchronous threshold ECDSA with batch processing},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust training of social media image classification models.
<em>TCSS</em>, <em>11</em>(1), 546–565. (<a
href="https://doi.org/10.1109/TCSS.2022.3230839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images shared on social media help crisis managers gain situational awareness and assess incurred damages, among other response tasks. As the volume and velocity of such content are typically high, real-time image classification has become an urgent need for faster disaster response. Recent advances in computer vision and deep neural networks have enabled the development of models for image classification for a number of tasks, including detecting crisis incidents, filtering irrelevant images, classifying images into specific humanitarian categories, and assessing the severity of the damage. To develop robust models, it is necessary to understand the capability of the publicly available pretrained models for these tasks, which remains to be underexplored in the crisis informatics literature. In this study, we address such limitations by investigating ten different network architectures for four different tasks using the largest publicly available datasets for these tasks. We also explore various data augmentation strategies, semisupervised techniques, and a multitask learning setup. In our extensive experiments, we achieve promising results.},
  archive      = {J_TCSS},
  author       = {Firoj Alam and Tanvirul Alam and Ferda Ofli and Muhammad Imran},
  doi          = {10.1109/TCSS.2022.3230839},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {546-565},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Robust training of social media image classification models},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel grey stratified decision-making (GSDM) model for
social sustainability-based supplier selection. <em>TCSS</em>,
<em>11</em>(1), 531–545. (<a
href="https://doi.org/10.1109/TCSS.2022.3216814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social dimensions of sustainability are far less discussed in the spectrum of sustainability. As suppliers are able to influence decisions across a supply network, we argue that the considerations for the social aspects of sustainability should begin from the process of supplier selection. Integrating social sustainability into the supplier selection process can ensure that firms can focus on the wider aspects of sustainability. We use a sustainability framework for social sustainability to identify the social sustainability factors for supplier selection. Based on this and the related literature, we identify and classify the factors into six categories of human rights and equity, health and safety, wages and benefits, education and training, child and bonded labor, and, finally, philanthropy and ethics. Furthermore, we propose a two-layered grey stratified decision-making (GSDM) model for identifying the best suppliers, by considering the attributes of social sustainability, along with the primary performance attributes of supplier selection, subject to a set of diverse objectives. A case evaluation and implementation of the proposed methodology has been conducted in the context of an electronics manufacturing industry in India. Here, we address the specific problem of social sustainability-based supplier selection, and the methodology is novel, as it can address the problems with compensatory aggregation in multicriteria decision-making situations. This research helps in increasing the awareness among firms regarding social sustainability and the related factors, and their prominence for a supplier selection problem, focusing on the sustainability theory extended to firms. Considering the practical implications of the study, managers and practitioners can ascertain the importance of social sustainability and the related factors in any strategic decision-making situation, including supplier selection.},
  archive      = {J_TCSS},
  author       = {R. Rajesh and Basim Aljabhan},
  doi          = {10.1109/TCSS.2022.3216814},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {531-545},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A novel grey stratified decision-making (GSDM) model for social sustainability-based supplier selection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identification and evolutionary analysis of user collusion
behavior in blockchain online social media. <em>TCSS</em>,
<em>11</em>(1), 522–530. (<a
href="https://doi.org/10.1109/TCSS.2022.3215185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has given rise to a series of new blockchain online social media (BOSMs), of which Steemit is representative. Such communities are based on a token reward system and attempt to engross users in the knowledge activities of the community through knowledge payment. Studies have found that the reward system of such communities has been abused (e.g., collusion for profit), but few studies have performed an in-depth analysis for this phenomenon. Consequently, real data for Steemit are used as a case study herein to examine the collusion of users in BOSMs. Two user collusion behaviors (group-voting and vote-buying) are defined and measured. On this basis, an identification and evolutionary survival analysis of the two collusion behaviors are conducted for colluding users and colluding groups, and the behavior patterns of user collusion under the token system are deconstructed. The results of this study improve stakeholders’ understanding of user participation behavior in new online communities, and serve as a reference for decision-making in community governance and token design.},
  archive      = {J_TCSS},
  author       = {Hongting Tang and Jian Ni and Yanlin Zhang},
  doi          = {10.1109/TCSS.2022.3215185},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {522-530},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Identification and evolutionary analysis of user collusion behavior in blockchain online social media},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anti-drugs chatbot: Chinese BERT-based cognitive intent
analysis. <em>TCSS</em>, <em>11</em>(1), 514–521. (<a
href="https://doi.org/10.1109/TCSS.2023.3238477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug abuse has always been a severe issue, but the proportion of drug abuse and addiction is rising. According to research reports, youth are motivated to access drugs mainly due to curiosity and peer influence. Additionally, youth especially lack proper knowledge and education surrounding drug abuse. Analyzing whether potential addicts intend to access drugs is helpful in preventing drug abuse and addiction. We developed an Anti-drug Chatbot for young people on a popular online social platform. We can detect potential risks, obtain warnings from the user-entered query and provide these to professional consultants for help. In this article, we present a hierarchical system with bidirectional encoder representation from transformers (BERT) to efficiently recognize and classify a user’s intent. We use the Chinese BERT-based model to utilize contextual information to perform classification and recognition. We evaluate our proposed system on our conversational dataset.},
  archive      = {J_TCSS},
  author       = {Jui-Hsuan Lee and Eric Hsiao-Kuang Wu and Yu-Yen Ou and Yueh-Che Lee and Cheng-Hsun Lee and Chia-Ru Chung},
  doi          = {10.1109/TCSS.2023.3238477},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {514-521},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Anti-drugs chatbot: Chinese BERT-based cognitive intent analysis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed differentially private ranking aggregation.
<em>TCSS</em>, <em>11</em>(1), 503–513. (<a
href="https://doi.org/10.1109/TCSS.2022.3225096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key step in cooperative decision-making is for all participants to achieve a consensus that avoids individual favoritism. To reach a consensus, a quantitative systematic mechanism is sometimes preferred. An example of such a mechanism is ranking aggregation, where the task is to rank elements in a certain order. While participating in ranking activities, it is also critical under certain circumstances to protect each decision maker’s preference. A promising privacy-preserving technique that is suitable for such a need is differential privacy (DP), which ensures plausible deniability of the protected information with rigorous mathematical guarantee and adjustable privacy level. A concern of the standard DP model is its assumption of letting a curator collect and analyze sensitive information, where in practical situations such a trusted independent curator may not exist. This article proposed a mechanism to solve the above issue using the distributed DP (DDP) framework. The proposed mechanism collects locally differential private rankings from individuals, and then randomly permutes pairwise rankings using a shuffle model to further amplify privacy protection. The final representative is produced by hierarchical rank aggregation (HRA). The mechanism was theoretically analyzed and experimentally compared against the existing methods and demonstrated competitive results in both output accuracy and privacy protection.},
  archive      = {J_TCSS},
  author       = {Qiujun Lan and Baobao Song and Yang Li and Gang Li},
  doi          = {10.1109/TCSS.2022.3225096},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {503-513},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Distributed differentially private ranking aggregation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Kernel-based sparse representation learning with global and
local low-rank label constraint. <em>TCSS</em>, <em>11</em>(1), 488–502.
(<a href="https://doi.org/10.1109/TCSS.2022.3227406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the large-scale and multiscale natures of social media data, sparse representation (SR) learning methods are widely followed. However, there are three problems associated with the existing SR methods: 1) they neglect the fact that the semantic features of data may change during iterative learning, which leads to weak semantic learning; 2) they often assume that the data are linearly separable, while the data might be nonlinear in many real-world applications; and 3) they cannot ensure the low-rank and discriminative properties of the data at the same time and might neglect the global properties of the data, leading to suboptimal solutions. To solve these problems, we propose a novel method, named kernel-based SR learning with global and local low-rank label (KSR-GL3) constraint, which strengthens the semantic information and ensures the semantic features invariant during learning. First, we map the data into a high-dimensional feature space to learn the linear representation of samples. Second, global and local low-rank label (GL3) constraint is used to ensure the semantic invariance, low-rankness, and discrimination of features during learning. Third, an $\ell _{2,1}$ is imposed to explore the sparseness of the subspace. Mathematical analyses show that GL3 can retain the intrinsic properties of data during learning. By combining the above three components, a generalized power iteration (GPI) approach is applied to build the model and deal with the tricky optimization problem. By KSR-GL 3, a sparse, low-rank, and discriminative subspace is produced from the high-dimensional and orthogonal representation of the data under the guidance of semantics, while the intrinsic properties of data are preserved. Extensive experiments on six datasets compared with five advanced algorithms demonstrate its promising prospects.},
  archive      = {J_TCSS},
  author       = {Luyao Teng and Feiyi Tang and Zefeng Zheng and Peipei Kang and Shaohua Teng},
  doi          = {10.1109/TCSS.2022.3227406},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {488-502},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Kernel-based sparse representation learning with global and local low-rank label constraint},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RobinNet: A multimodal speech emotion recognition system
with speaker recognition for social interactions. <em>TCSS</em>,
<em>11</em>(1), 478–487. (<a
href="https://doi.org/10.1109/TCSS.2022.3228649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is essential to understand the underlying emotions that are imparted through speech in order to study social communications as well as to generate seamless human–computer interactions. Speech emotion recognition (SER) is a considerably challenging task due to the lack of sufficient data and the complex interdependence of phrases with the context and emotion they imply. This article presents RobinNet: a RoBERTa- and Inception-ResNet-V2-based novel multimodal network for SER. The model employs transfer learning to build two unimodal systems for text and audio features and then incorporates them into a single classifier through Intermediate Fusion. This work has been created after carefully analyzing the performance of various top-performing unimodal systems and then utilizing a fine-tuned RoBERTa-based model to represent the textual features. Furthermore, we utilize an Inception-ResNetV2 pretrained network for Speaker Identification and employ transfer learning to train it for the task of emotion recognition through speech using spectrogram augmentation. The proposed multimodal system combines the two modalities through intermediate fusion and gives out a weighted accuracy (WA) of 72.8% when evaluated against the interactive emotional dyadic motion capture (IEMOCAP) dataset. Experimental results reveal that the proposed multimodal system outperforms state-of-the-art (SOTA) solutions on the benchmark datasets IEMOCAP, multimodal emotion lines dataset (MELD), and CMU-MOSEI. The proposed model utilizes intermediate fusion unlike any of its predecessors that perform late fusion after significant independent processing, thereby improving the overall artificial multimodal representations.},
  archive      = {J_TCSS},
  author       = {Yash Khurana and Swamita Gupta and R. Sathyaraj and S. P. Raja},
  doi          = {10.1109/TCSS.2022.3228649},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {478-487},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {RobinNet: A multimodal speech emotion recognition system with speaker recognition for social interactions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Risk propagation decision-making for product and supply
chain change systems under COVID-19: An assessment-to-control support
scheme. <em>TCSS</em>, <em>11</em>(1), 465–477. (<a
href="https://doi.org/10.1109/TCSS.2022.3215260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamics in supply chains (SCs) can trigger risks due to the changing and propagating nature. In the context of COVID-19, this article presents an assessment-to-control decision-making support scheme to tackle propagation effect uncertainties of SCs considering product changes. First, a new decision model is proposed for risk warnings, with the potential advantages that: 1) propagation effects can be assessed generally and objectively and 2) permitting control theory to integrate and identify the interrelations between propagation effects. More specifically, the bullwhip effect (BE) with operational and behavioral causes is quantified as cascading amplified inventory fluctuations. The ripple effect (RE) from large-scale supplier disruptions driven by COVID-19 is quantified as increased entropy rates (ERs). Then, the system studied is integrated as a closed-loop control system under provided change control. Moreover, some criteria are derived for the existence of controller gains/decision coefficients to stabilize the closed-loop system with the BE mitigation under the RE. Finally, a mask SC case study under COVID-19 is performed for examining the effectiveness of the proposed scheme.},
  archive      = {J_TCSS},
  author       = {En-Zhi Cao and Chen Peng and Zhiru Cao},
  doi          = {10.1109/TCSS.2022.3215260},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {465-477},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Risk propagation decision-making for product and supply chain change systems under COVID-19: An assessment-to-control support scheme},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Centroid-based multiple local community detection.
<em>TCSS</em>, <em>11</em>(1), 455–464. (<a
href="https://doi.org/10.1109/TCSS.2022.3226178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the research of local community detection has attracted much attention. Most existing local community detection methods aim to find a single community of closely related nodes for a given query node, but in general, nodes are possible to belong to several communities, and detecting all the potential communities for a given query node is much more challenging. In this work, we propose a novel approach called the centroid-based multiple local community detection (C-MLC) to find all the communities for a query node. Differing from the existing local community detection methods that directly find a community from the query node, we assume that every community contains a “centroid” node, which locates in the core of the community and can be used to identify the community. Then, a query node corresponds to several centroid nodes if the query node belongs to multiple communities. The key ideas of C-MLC are that C-MLC automatically determines the number of communities containing the query node by finding the related centroid nodes and uses each query node together with the centroid node to uncover the corresponding community based on a set of high-quality seeds. Through extensive evaluations on real-world networks and synthetic networks, C-MLC outperforms the state-of-the-art methods significantly, demonstrating that finding the centroid nodes is a better approach to uncover the multiple local communities.},
  archive      = {J_TCSS},
  author       = {Boyu Li and Dany Kamuhanda and Kun He},
  doi          = {10.1109/TCSS.2022.3226178},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {455-464},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Centroid-based multiple local community detection},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Urban overtourism detection based on graph temporal
convolutional networks. <em>TCSS</em>, <em>11</em>(1), 442–454. (<a
href="https://doi.org/10.1109/TCSS.2022.3226177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban overtourism results in heavy traffic, degraded tourist experiences, and overloaded infrastructure. Detecting urban overtourism at the early stage is important to minimize the adverse effects. However, urban overtourism detection (UOD) is a challenging task due to ambiguity, sparsity, and complex spatiotemporal relations of overtourism. In this article, we propose a novel UOD framework based on graph temporal convolutional networks (TCNs) to tackle the challenges mentioned above. More specifically, we propose the grid overtourism mode (GOM) to detect urban overtourism on a grid level and propose the overtourism detection mechanism, which gives a quantitative definition of overtourism and screens out the regions where overtourism may occur as candidate regions. Then, we construct the GOM graphs of the candidate regions. Next, we employ the graph TCNs to model the complex spatiotemporal relations of urban overtourism and predict the future GOM graph at the next time interval. Finally, we calculate the urban overtourism scores based on the prediction results. The experiments are conducted based on a real-world dataset. The evaluation results demonstrate the effectiveness of our methods.},
  archive      = {J_TCSS},
  author       = {Xiangjie Kong and Zhiqiang Huang and Guojiang Shen and Hang Lin and Mingjie Lv},
  doi          = {10.1109/TCSS.2022.3226177},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {442-454},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Urban overtourism detection based on graph temporal convolutional networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchain oriented effective charity process during
pandemics and emergencies. <em>TCSS</em>, <em>11</em>(1), 431–441. (<a
href="https://doi.org/10.1109/TCSS.2022.3232325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During any emergency, a donation is considered a moral responsibility all over the globe. The lack of transparency and oversight in charity donations hurts people’s enthusiasm to donate. Donors are distrustful about how their funds are utilized. The use of blockchain technology (BCT) will provide a solution to make the donation procedure more viable. It is a distributed technology that offers a secure and transparent environment by avoiding the involvement of third parties between contributors and charities. This article proposed a blockchain-based donation mechanism for the convenience of charity organizations, donors, and beneficiaries during disasters, pandemics such as Covid-19, and other emergencies. All transactions can be traced in blockchain, giving donors visibility into where and how their funds are utilized. This article contributes to improving donations’ openness to strengthen public interest in donations and encourage BCT in charity. Ethereum blockchain is used to implement the proposed framework and provides a convenient donation platform. Smart contracts are used to make donations, which build trust between contributors, beneficiaries, and charity organizations. The blockchain-based donation method saves time, lowers donation costs, and eliminates the chances of dubious campaign funds. This study will contribute to improving emergency recovery efforts.},
  archive      = {J_TCSS},
  author       = {Mandeep Kaur and Pankaj Deep Kaur and Sandeep Kumar Sood},
  doi          = {10.1109/TCSS.2022.3232325},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {431-441},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Blockchain oriented effective charity process during pandemics and emergencies},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cost function learning in memorized social networks with
cognitive behavioral asymmetry. <em>TCSS</em>, <em>11</em>(1), 418–430.
(<a href="https://doi.org/10.1109/TCSS.2022.3218485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the cost function learning in social information networks, wherein human memory and cognitive bias are explicitly taken into account. We first propose a model for social information-diffusion dynamics, with a focus on the systematic modeling of asymmetric cognitive bias represented by confirmation bias and novelty bias. Building on the dynamics model, we then propose the M3IRL—a memorized model and maximum-entropy-based inverse reinforcement learning—for learning cost functions. Compared with the existing model-free IRLs, the characteristics of M3IRL are significantly different here: no dependence on the Markov decision process principle, the need for only a single finite-time trajectory sample, and bounded decision variables. Finally, the effectiveness of the proposed social information-diffusion model and the M3IRL algorithm is validated by the online social media data.},
  archive      = {J_TCSS},
  author       = {Yanbing Mao and Jinning Li and Naira Hovakimyan and Tarek Abdelzaher and Christian Lebiere},
  doi          = {10.1109/TCSS.2022.3218485},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {418-430},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Cost function learning in memorized social networks with cognitive behavioral asymmetry},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Social alignment contagion in online social networks.
<em>TCSS</em>, <em>11</em>(1), 399–417. (<a
href="https://doi.org/10.1109/TCSS.2022.3226346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers have already observed social contagion effects in both in-person and online interactions. However, such studies have primarily focused on users’ beliefs, mental states, and interests. In this article, we expand the state of the art by exploring the impact of social contagion on social alignment, i.e., whether the decision to socially align oneself with the general opinion of the users on the social network is contagious to one’s connections on the network or not. The novelty of our work in this article includes: 1) unlike earlier work, this article is among the first to explore the contagiousness of the concept of social alignment on social networks; 2) our work adopts an instrumental variable approach to determine reliable causal relations between observed social contagion effects on the social network; and 3) our work expands beyond the mere presence of contagion in social alignment and also explores the role of population heterogeneity on social alignment contagion. Based on the systematic collection and analysis of data from two large social network platforms, namely, Twitter and Foursquare, we find that a user’s decision to socially align or distance from social topics and sentiments influences the social alignment decisions of their connections on the social network. We further find that such social alignment decisions are significantly impacted by population heterogeneity.},
  archive      = {J_TCSS},
  author       = {Amin Mirlohi and Jalehsadat Mahdavimoghaddam and Jelena Jovanovic and Feras N. Al-Obeidat and Mehdi Khani and Ali A. Ghorbani and Ebrahim Bagheri},
  doi          = {10.1109/TCSS.2022.3226346},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {399-417},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Social alignment contagion in online social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MMGK: Multimodality multiview graph representations and
knowledge embedding for mild cognitive impairment diagnosis.
<em>TCSS</em>, <em>11</em>(1), 389–398. (<a
href="https://doi.org/10.1109/TCSS.2022.3216483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diagnosis of mild cognitive impairment (MCI), which is an early stage of Alzheimer’s disease (AD), has great clinical significance. Medical imaging and gene sequencing technologies have provided sufficient multimodality data for MCI diagnostic studies. However, how to effectively extract the rich representations from multimodality data remains a challenging task. To address this challenging task, we propose a new multimodality multiview graph representations and knowledge embedding (MMGK) framework to diagnose MCI. First, to obtain rich information from multimodality data, we extract multiview feature representations from magnetic resonance imaging (MRI) and genetic data. Afterward, considering the correlations between subjects, all subjects are constructed into a graph based on the different single-view feature representations, respectively. To further enrich the correlations between subjects, demographic data are utilized through knowledge embedding. Finally, to perform MCI diagnosis on multiview graphs, graph convolutional networks (GCNs) are utilized. In addition, to further improve the performance of MCI diagnosis, a two-step ensemble learning method is proposed. The proposed framework is evaluated on 188 subjects from the AD Neuroimaging Initiative (ADNI). Experimental results show that our proposed framework achieves good performance with accuracy reaching 0.888, and outperforms some state-of-the-art (SOTA) methods. In addition, the proposed framework is applied to Parkinson’s disease (PD) diagnosis and achieves 0.856 accuracy. Overall, our proposed method has potential for clinical application in MCI diagnosis and other diseases via integrating MRI, genetic data, and demographic data. Our code is available at: https://github.com/miacsu/MMGK .},
  archive      = {J_TCSS},
  author       = {Jin Liu and Hao Du and Rui Guo and Harrison X. Bai and Hulin Kuang and Jianxin Wang},
  doi          = {10.1109/TCSS.2022.3216483},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {389-398},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {MMGK: Multimodality multiview graph representations and knowledge embedding for mild cognitive impairment diagnosis},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DAG-BLOCK: A novel architecture for scaling
blockchain-enabled cryptocurrencies. <em>TCSS</em>, <em>11</em>(1),
378–388. (<a href="https://doi.org/10.1109/TCSS.2022.3224764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of blockchain technology and industries, scalability has been widely realized as one of the primary and urgent concerns for the large-scale adoption of blockchain, especially for cryptocurrencies. In this respect, directed acyclic graph (DAG) proves to be an elegant solution to scaling blockchain but suffers from weak consistency and security issues. In this article, we designed a novel DAG-BLOCK architecture for blockchain-enabled cryptocurrency markets in order to improve the scalability. In our work, DAG is used to replace the Merkel-tree-based transaction structure within the block, and a novel design of open blocks is proposed to enable user nodes to participate in verifying the transactions in blockchain systems. On this basis, we designed a new segmented market structure, in which each miner serves only a group of users instead of all users, so as to reduce miners’ workload and thus scale transaction processing capabilities. Our work can help improve the scalability of cryptocurrencies via evolving the underlying blockchain systems to graph-based distributed ledgers and is expected to shed new light on designing blockchain-based decentralized markets.},
  archive      = {J_TCSS},
  author       = {Naina Qi and Yong Yuan and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2022.3224764},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {378-388},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {DAG-BLOCK: A novel architecture for scaling blockchain-enabled cryptocurrencies},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emotion recognition from gait analyses: Current research and
future directions. <em>TCSS</em>, <em>11</em>(1), 363–377. (<a
href="https://doi.org/10.1109/TCSS.2022.3223251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human gait refers to a daily motion that represents not only mobility but can also be used to identify the walker by either human observers or computers. Recent studies reveal that gait even conveys information about the walker’s emotion. Individuals in different emotion states may show different gait patterns. The mapping between various emotions and gait patterns provides a new source for automated emotion recognition. Compared to traditional emotion detection biometrics, such as facial expression, speech, and physiological parameters, gait is remotely observable, more difficult to imitate, and requires less cooperation from the subject. These advantages make gait a promising source for emotion detection. This article reviews current research on gait-based emotion detection, particularly on how gait parameters can be affected by different emotion states and how the emotion states can be recognized through distinct gait patterns. We focus on the detailed methods and techniques applied in the whole process of emotion recognition: data collection, preprocessing, and classification. Finally, we discuss possible future developments of efficient and effective gait-based emotion recognition using state-of-the-art techniques in intelligent computation and big data.},
  archive      = {J_TCSS},
  author       = {Shihao Xu and Jing Fang and Xiping Hu and Edith Ngai and Wei Wang and Yi Guo and Victor C. M. Leung},
  doi          = {10.1109/TCSS.2022.3223251},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {363-377},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Emotion recognition from gait analyses: Current research and future directions},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). (Mis)leading the COVID-19 vaccination discourse on twitter:
An exploratory study of infodemic around the pandemic. <em>TCSS</em>,
<em>11</em>(1), 352–362. (<a
href="https://doi.org/10.1109/TCSS.2022.3225216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we collect a moderate-sized representative corpus of tweets (over 200 000) pertaining to COVID-19 vaccination spanning for a period of seven months (September 2020–March 2021). Following a transfer learning approach, we utilize a pretrained transformer-based XLNet model to classify tweets as misleading or nonmisleading and manually validate the results with random subsets of samples. We leverage this to study and contrast the characteristics of tweets in the corpus that are misleading in nature against non-misleading ones. This exploratory analysis enables us to design features such as sentiments, hashtags, nouns, and pronouns which can, in turn, be exploited for classifying tweets as (non-)misleading using various machine learning (ML) models in an explainable manner. Specifically, several ML models are employed for prediction, with up to 90% accuracy, with the importance of each feature is explained using SHAP Explainable AI (XAI) tool. While the thrust of this work is principally exploratory in nature to obtain insight on the online discourse on COVID-19 vaccination, we conclude the article by outlining how these insights provide the foundations for a more actionable approach to mitigate misinformation. We have made the curated data as well as the accompanying code available so that the research community at large can reproduce, compare against, or build upon this work.},
  archive      = {J_TCSS},
  author       = {Shakshi Sharma and Rajesh Sharma and Anwitaman Datta},
  doi          = {10.1109/TCSS.2022.3225216},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {352-362},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {(Mis)leading the COVID-19 vaccination discourse on twitter: An exploratory study of infodemic around the pandemic},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling human temporal and spatial structured contacts for
epidemic prediction. <em>TCSS</em>, <em>11</em>(1), 340–351. (<a
href="https://doi.org/10.1109/TCSS.2022.3214108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human travel and social contacts are deemed as the key force in driving the transmission of infectious diseases. Consequently, epidemic models should represent individuals’ spatiotemporal contacts in detail to investigate the complex process of epidemic diffusion. Mathematical epidemic models usually assume a homogeneous human population and describe unstructured contacts. Most network-based epidemic models do not synthetically consider the temporal and spatial features of human structured contact behaviors. We here combined a social network with a bipartite network to build a multilayer agent network to model heterogeneous individuals’ temporal and spatial structured contacts. We used the largest collective outbreak of H1N1 influenza at a Chinese university in 2009 as a case study. Experimental results indicate that our models can reproduce individuals’ daily travel and social contact patterns, as well as the H1N1 influenza outbreak. We found that only quarantining dormitories to stop interbuilding transmission could not achieve a great effect in mitigating epidemic outbreaks at a university. The prohibition of students’ visiting across dormitory rooms was indispensable to prevent intrabuilding transmission of infectious diseases. Furthermore, it would be better to quarantine admitted case patients’ close contacts to control potentially latent individuals.},
  archive      = {J_TCSS},
  author       = {Wei Duan and Xiao Wang and Gang Guo and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2022.3214108},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {340-351},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Modeling human temporal and spatial structured contacts for epidemic prediction},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Social influence in signed networks. <em>TCSS</em>,
<em>11</em>(1), 330–339. (<a
href="https://doi.org/10.1109/TCSS.2022.3220944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social influence has been widely discussed in various disciplines due to its important sociological significance. However, the dynamics of social influence in signed networks have nonetheless received fairly little attention. In this article, we propose a generalized Pólya urn model that considers the effect of negative relationships and is capable of comprehending the specific mechanisms of homophily and xenophobia in the dynamics. Based on the mathematical deduction, we find that the signed network guides social influence in a trend toward equality. Simulation shows that a higher effect or larger proportion of negative relationships may break the self-reinforcement and make the market more equal. The collective dynamics in the signed network are more predictable but generate path dependence. We also find that a balanced structure has no impact on the average market share but is helpful in removing path dependence and promoting system stability.},
  archive      = {J_TCSS},
  author       = {Xiaochen He and Jiali Lu and Haifeng Du and Xiaoyi Jin},
  doi          = {10.1109/TCSS.2022.3220944},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {330-339},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Social influence in signed networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Public opinion evolution in cyberspace: A case analysis of
pelosi’s visit to taiwan. <em>TCSS</em>, <em>11</em>(1), 319–329. (<a
href="https://doi.org/10.1109/TCSS.2023.3239046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamics of public opinion on social media affects people’s feeling and minds about international affairs and leads to the reconstruction of societal states for international conflicts. In this article, we analyze the topics’ evolution on social media during the Pelosi visit. Such kind of analysis should help the related departments sense and beware the situation effectively and efficiently, and may provide technical supports for proper policy making and responses. To facilitate this purpose, a new method is proposed and an abbreviated large-graph clustering (ALGC) algorithm has been designed to generate documents and topic representation for alleviating the overhead of high computational complexity of large graphs by reducing the dimensionality of the attention matrix and adjacency matrix. The evolution pattern of topics is also analyzed in and between different time periods. Experiment results show that the proposed method performs well, achieving a high clustering accuracy with lower computational cost. The dataset used in this article is also released for public analysis.},
  archive      = {J_TCSS},
  author       = {Tao Chen and Baoyu Zhang and Xiao Wang and Weishan Zhang and Chitin Hon and Wang Di and Long Chen and Qiang Li and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2023.3239046},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {319-329},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Public opinion evolution in cyberspace: A case analysis of pelosi’s visit to taiwan},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of public sentiment on COVID-19 mitigation measures
in social media in the united states using machine learning.
<em>TCSS</em>, <em>11</em>(1), 307–318. (<a
href="https://doi.org/10.1109/TCSS.2022.3214527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public sentiment can impact the implementation of public policies and even cause policy failure if public support is not received. Therefore, knowledge of public sentiment concerning new and emerging policies is critical for policymakers. During the coronavirus disease 2019 (COVID-19) pandemic, several precautionary measures have been suggested in an attempt to delay or mitigate the spread of the virus. This study presents a framework that applies natural language processing (NLP) techniques, such as sentiment and bigram analyses, to characterize the public sentiment on three prominent mitigation measures (mask wearing, social distancing, and quarantine) as shared by Twitter users in the United States. As part of the framework, we apply a bigram graph-based approach to visualize the most frequent topics in Twitter discussions during the COVID-19 pandemic. The objective is to provide insights into the most commonly discussed topics among Twitter users with similar demographic characteristics (e.g., age and gender). The sentiment and bigram analyses identified the most frequently discussed topics expressing both positive and negative sentiments among different age and gender groups. Discussions containing positive sentiment prevailed and revolved around the benefits of the measures and trust in the government, while the topics of negative sentiment involved conspiracy theories, skepticism, and distrust of government mandates. It is also notable that the discussions among people 19–29 and over 40 years old focus on government officials and political parties, benefits or inefficiency of mitigation measures, and conspiracy theories more often than other demographic groups. Our proposed approaches and results offer a novel and potentially valuable contribution to public policymakers.},
  archive      = {J_TCSS},
  author       = {Anastasia Angelopoulou and Konstantinos Mykoniatis and Alice E. Smith},
  doi          = {10.1109/TCSS.2022.3214527},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {307-318},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Analysis of public sentiment on COVID-19 mitigation measures in social media in the united states using machine learning},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A node classification-based multiobjective evolutionary
algorithm for community detection in complex networks. <em>TCSS</em>,
<em>11</em>(1), 292–306. (<a
href="https://doi.org/10.1109/TCSS.2022.3223159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective evolutionary algorithms (MOEAs) have been widely used in community detection in recent years. However, most of the existing MOEA-based ones adopted the same search strategies for all nodes and ignored the differences between the nodes. In fact, the nodes in a complex network have different structural characteristics and are of different importance during the search process of the community detection problem. To this end, in this article, a node classification-based search scheme is first proposed, where different kinds of nodes are searched in different ways. To be specific, the nodes in the network are classified into two types of nodes, candidate central (CC) nodes and noncentral (NC) nodes, by mapping the nodes into a structural similarity-based embedding space. The CC nodes are likely to be the centers of communities, and the rough structure can be searched quickly through activating the CC nodes. Then, the NC nodes are assigned to the communities with the activated central nodes. Based on the proposed scheme, a node classification-based MOEA named NCMOEA is then proposed. In NCMOEA, a mixed representation is designed to effectively encode the two different kinds of nodes. In addition, corresponding genetic operators are then suggested to search the two categories of nodes in different ways. Furthermore, an initialization strategy is also designed for initializing the population with high quality and good diversity. The experimental results on 15 real-world networks and several synthetic networks demonstrate the superiority of the proposed NCMOEA over nine representative algorithms for community detection.},
  archive      = {J_TCSS},
  author       = {Haipeng Yang and Bin Li and Fan Cheng and Peng Zhou and Renzhi Cao and Lei Zhang},
  doi          = {10.1109/TCSS.2022.3223159},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {292-306},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A node classification-based multiobjective evolutionary algorithm for community detection in complex networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A salp swarm algorithm for parallel disassembly line
balancing considering workers with government benefits. <em>TCSS</em>,
<em>11</em>(1), 282–291. (<a
href="https://doi.org/10.1109/TCSS.2023.3238965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proper disassembly operations organization and workstation assignment can help increase the efficiency of disassembly systems that are critical for recycling and remanufacturing of end-of-life (EOL) products. A parallel disassembly system layout allows diversification of disassembly tasks and increases flexibility. In this work, a parallel disassembly balancing model considering hiring workers with government benefits (WGB) is established. To quickly find an optimal solution to the model, a salp swarm algorithm (SSA) with a new encoding and decoding process is developed. Moreover, we use the well-known mathematical optimization technique CPLEX to verify the correctness of the proposed model and use a genetic algorithm (GA), a constrained decomposition approach with grids’ optimization (CDG), and a random search (RS) algorithm to show the effectiveness of the proposed algorithm. Experimental results show that the proposed algorithm can perform well on the proposed problem, which is conducive to the society accepting more WGB into the workplace.},
  archive      = {J_TCSS},
  author       = {Shujin Qin and Jiawei Li and Jiacun Wang and Xiwang Guo and Shixin Liu and Liang Qi},
  doi          = {10.1109/TCSS.2023.3238965},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {282-291},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A salp swarm algorithm for parallel disassembly line balancing considering workers with government benefits},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Market sentiment analysis based on image processing with
put-call volatility gap surface. <em>TCSS</em>, <em>11</em>(1), 267–281.
(<a href="https://doi.org/10.1109/TCSS.2022.3224054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing the market sentiment and forecasting movements in asset prices is extremely important and has been attempted by researchers and market practitioners. Asset volatilities, regardless of historical ones or implied from the option prices, are crucial barometers of the market. And this research proposes a new approach that combines image processing and machine learning to capture the relationships between sentiment-related features and asset movement. The proposed research is based on the tick-level SPY options transactions, and the dataset contains around 1.5 million trading records. Specially, we obtained the gap between the call surface and the put surface as the second-level implied volatility surface (IVS). After adopting the traditional convolutional neural network (CNN) to compare the predictive effects among implied volatility (IV) call surface, IV put surface, and IV gap surface, the results indicate that the IV gap provides the most significant predictability. Besides, our project creatively proposes the interframe difference approach to optimized CNN and a recurrent CNN (RCNN) to fully utilize spatial and temporal features of the IV surface data. According to experiment results, the directional accuracy of prediction ranges from 67.20% to 72.05% for asset movement forecasting at the millisecond level.},
  archive      = {J_TCSS},
  author       = {Yuanyuan Qi and Guoxiang Guo and Yang Wang and Jerome Yen},
  doi          = {10.1109/TCSS.2022.3224054},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {267-281},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Market sentiment analysis based on image processing with put-call volatility gap surface},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive 3DCNN-based interpretable ensemble model for early
diagnosis of alzheimer’s disease. <em>TCSS</em>, <em>11</em>(1),
247–266. (<a href="https://doi.org/10.1109/TCSS.2022.3223999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adaptive interpretable ensemble model based on a 3-D convolutional neural network (3DCNN) and genetic algorithm (GA), i.e., 3DCNN+EL+GA, was proposed to differentiate the subjects with Alzheimer’s disease (AD) or mild cognitive impairment (MCI) and also identify the discriminative brain regions significantly contributing to the classifications in a data-driven way. The testing results on the datasets from both the AD Neuroimaging Initiative (ADNI) and the Open Access Series of Imaging Studies (OASIS) indicated that 3DCNN+EL+GA outperformed other state-of-the-art deep learning algorithms. More importantly, in these identified brain regions, the discriminative brain subregions at a voxel level were further located with a gradient-based attribution method designed for CNN and illustrated intuitively. Besides these, the behavioral domains corresponding to every identified discriminative brain region (e.g., the rostral hippocampus) were analyzed. It was shown that the resultant behavioral domains were consistent with those brain functions (e.g., emotion) impaired early in the AD process. Further research is needed to examine the generalizability of the proposed ideas and methods in identifying discriminative brain regions and subregions for the diagnosis of other brain disorders (especially little-known ones), such as Parkinson’s disease, epilepsy, severe depression, autism, Huntington’s disease, multiple sclerosis, and amyotrophic lateral sclerosis, using neuroimaging.},
  archive      = {J_TCSS},
  author       = {Dan Pan and Genqiang Luo and An Zeng and Chao Zou and Haolin Liang and Jianbin Wang and Tong Zhang and Baoyao Yang},
  doi          = {10.1109/TCSS.2022.3223999},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {247-266},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Adaptive 3DCNN-based interpretable ensemble model for early diagnosis of alzheimer’s disease},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-informed targeted network interventions on social
networks among men who have sex with men in zhuhai, china.
<em>TCSS</em>, <em>11</em>(1), 238–246. (<a
href="https://doi.org/10.1109/TCSS.2022.3216756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Men who have sex with men (MSM) are at disproportionally high risk for human immunodeficiency virus (HIV) infection in China. The increasing HIV prevalence among MSM highlights the urgent need for effective prevention interventions among MSM. Interventions targeted at individuals who are highly vulnerable to HIV infection have been proven effective in reducing incidence rates. However, existing targeted interventions are limited to small-scale programs. To investigate the effectiveness of large-scale targeted network interventions in real-world settings, we build a stochastic agent-based network model informed by the comprehensive online social networking and dating behavior data and epidemiological data among MSM in Zhuhai, China. With the proposed model, we simulate HIV transmissions and compare the efficacy of different targeted intervention programs. We propose a new method, namely, RiskRank, to prioritize nodes for targeted interventions by incorporating: 1) their topological features on the online social network; 2) the underlying epidemic dynamics; and 3) the position of identified HIV-infected individuals on the sexual network. Results show that the targeted interventions are more effective than random interventions in large-scale HIV epidemic control. The proposed RiskRank method consistently outperforms state-of-the-art baselines in various intervention scenarios.},
  archive      = {J_TCSS},
  author       = {Yang Ye and Keyang Ni and Fengshi Jing and Yi Zhou and Weiming Tang and Qingpeng Zhang},
  doi          = {10.1109/TCSS.2022.3216756},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {238-246},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Model-informed targeted network interventions on social networks among men who have sex with men in zhuhai, china},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Community deception in attributed networks. <em>TCSS</em>,
<em>11</em>(1), 228–237. (<a
href="https://doi.org/10.1109/TCSS.2022.3213722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection algorithms that analyze networks to identify communities of nodes are an essential part of the network analysis toolkit used daily by different analysts (e.g., data scientists and law enforcement). However, there is not enough awareness that members of a community $\mathscr {C}$ (either revealed or not) inside a network $G$ could act strategically to evade such tools either for legitimate (e.g., activist groups in authoritarian regimes) or malicious (e.g., terrorists) purpose. Community deception offers this possibility. By identifying a certain number of $\mathscr {C}$ ’s member connections to be rewired, community deception algorithms can successfully hide a community that wants to stay below the radar of detection techniques. However, the state-of-the-art deception approaches have focused on networks without attributes, although real-world networks (e.g., Facebook) include attributes (e.g., age and sex) that play a central role in detecting more accurate communities. This article faces three novel challenges introduced when designing deception techniques for networks with attributes. The first concerns how to model and encode attributes most flexibly. The second is about framing attribute-aware community deception as an optimization problem. Finally, the challenge of solving the optimization problem by leveraging network topology and attributes also arises. We leverage a simple way to model network attributes as edge weights, a novel optimization function called community diffusion, and Diffuser a greedy algorithm to optimize diffusion, to solve the above challenges. We evaluated Diffuser against several community detection algorithms and compared it with state-of-the-art deception approaches on various real-world networks. From the evaluation, we can draw two main observations. First, adopting attribute-oblivious deception techniques leads to unsatisfactory results. Second, community diffusion as an optimization function specific to attributed networks is preferred to community safeness, the state-of-the-art deception optimization function, even when recasting the latter as an attribute-aware function.},
  archive      = {J_TCSS},
  author       = {Valeria Fionda and Giuseppe Pirrò},
  doi          = {10.1109/TCSS.2022.3213722},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {228-237},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Community deception in attributed networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal hierarchical graph collaborative filtering for
multimedia-based recommendation. <em>TCSS</em>, <em>11</em>(1), 216–227.
(<a href="https://doi.org/10.1109/TCSS.2022.3226862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimedia-based recommendation (MMRec) is a challenging task, which goes beyond the collaborative filtering (CF) schema that only captures collaborative signals from interactions and explores multimodal user preference cues hidden in complex multimedia content. Despite the significant progress of current solutions for MMRec, we argue that they are limited by multimodal noise contamination. Specifically, a considerable amount of preference-irrelevant multimodal noise (e.g., the background, layout, and brightness in the image of the product) is incorporated into the representation learning of items, which contaminates the modeling of multimodal user preferences. Moreover, most of the latest researches are based on graph convolution networks (GCNs), which means that multimodal noise contamination is further amplified because noisy information is continuously propagated over the user–item interaction graph as recursive neighbor aggregations are performed. To address this problem, instead of the common MMRec paradigm which learns user preferences in an integrated manner, we propose a hierarchical framework to separately learn collaborative signals and multimodal preferences cues, thus preventing multimodal noise from flowing into collaborative signals. Then, to alleviate the noise contamination for multimodal user preference modeling, we propose to extract semantic entities from multimodal content that are more relevant to user interests, which can model semantic-level multimodal preferences and thus remove a large fraction of noise. Furthermore, we use the full multimodal features to model content-level multimodal preferences like the existing MMRec solutions, which ensures the sufficient utilization of multimodal information. Overall, we develop a novel model, multimodal hierarchical graph CF (MHGCF), which consists of three types of GCN modules tailored to capture collaborative signals, semantic-level preferences, and content-level preferences, respectively. We conduct extensive experiments to demonstrate the effectiveness of MHGCF and its components. The complete data and codes of MHGCF are available at https://github.com/hfutmars/MHGCF .},
  archive      = {J_TCSS},
  author       = {Kang Liu and Feng Xue and Shuaiyang Li and Sheng Sang and Richang Hong},
  doi          = {10.1109/TCSS.2022.3226862},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {216-227},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Multimodal hierarchical graph collaborative filtering for multimedia-based recommendation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Captionomaly: A deep learning toolbox for anomaly captioning
in social surveillance systems. <em>TCSS</em>, <em>11</em>(1), 207–215.
(<a href="https://doi.org/10.1109/TCSS.2022.3230262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time video stream monitoring is gaining huge attention lately with an effort to fully automate this process. On the other hand, reporting can be a tedious task, requiring manual inspection of several hours of daily clippings. Errors are likely to occur because of the repetitive nature of the task causing mental strain on operators. There is a need for an automated system that is capable of real-time video stream monitoring in social systems and reporting them. In this article, we provide a tool aiming to automate the process of anomaly detection and reporting. We combine anomaly detection and video captioning models to create a pipeline for anomaly reporting in descriptive form. A new set of labels by creating descriptive captions for the videos collected from the UCF-Crime (University of Central Florida-Crime) dataset has been formulated. The anomaly detection model is trained on the UCF-Crime, and the captioning model is trained with the newly created labeled set UCF-Crime video description (UCFC-VD). The tool will be used for performing the combined task of anomaly detection and captioning. Automated anomaly captioning would be useful in the efficient reporting of video surveillance data in different social scenarios. Several testing and evaluation techniques were performed. Source code and dataset: https://github.com/Adit31/Captionomaly-Deep-Learning-Toolbox-for-Anomaly-Captioning .},
  archive      = {J_TCSS},
  author       = {Adit Goyal and Murari Mandal and Vikas Hassija and Moayad Aloqaily and Vinay Chamola},
  doi          = {10.1109/TCSS.2022.3230262},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {207-215},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Captionomaly: A deep learning toolbox for anomaly captioning in social surveillance systems},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Crowding types and price dynamics in tourism destinations
choice. <em>TCSS</em>, <em>11</em>(1), 197–206. (<a
href="https://doi.org/10.1109/TCSS.2022.3230201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article analyzes how the preferences of tourists for types of resorts, crowding types of tourists, and the pricing strategies of the resorts interact to determine the occupancy rate, price, and distribution of welfare in the market of resorts. The model captures the process of acquisition of information of the consumers for making the choice of resorts and a dynamic strategy adopted by the resorts to manage their revenue. After describing the difficulties to introduce an analytical description of the model, an agent-based model (ABM) is presented to explore the properties of the market. The study shows that crowding types of tourists in destinations together with a very simple revenue management heuristic can produce counterintuitive results affecting the distribution of surplus in the markets. When all the managers in a market overreact by raising prices as consequence of a high occupancy rate, they appropriate a larger portion of the surplus of the market. When managers are risk-averse and rapidly reduce prices when occupancy is low, they deliver more welfare to tourists.},
  archive      = {J_TCSS},
  author       = {Emiliano Alvarez and Juan Gabriel Brida and Nicolás Garrido},
  doi          = {10.1109/TCSS.2022.3230201},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {197-206},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Crowding types and price dynamics in tourism destinations choice},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative optimization of learning team formation based
on multidimensional characteristics and constraints modeling: A team
leader-centered approach via e-CARGO. <em>TCSS</em>, <em>11</em>(1),
184–196. (<a href="https://doi.org/10.1109/TCSS.2022.3224762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the massive popularization of e-learning, collaborative learning via learning teams has become indispensable to enhancing the learning efficiency and learning quality of overall learners. The team leader usually plays a key role in collaborative learning. However, the existing research ignores the key characteristics of learners and constraints relevant to e-learners when identifying appropriate team leaders and compatible members. A novel collaborative optimization approach to learning team formation is proposed based on a refined learner model and the environments—classes, agents, roles, groups, and objects (E-CARGO) model. With the proposed approach, a learner is modeled by combining 5-D characteristics (i.e., cognitive ability, leadership, sociability, learning style, and personality) and three types of constraints (e.g., conflicts, genders, and the number of members), and an assessment mechanism is designed to measure the comprehensive abilities of learners for identifying an ideal team leader and selecting the team members for a team. By innovatively introducing the role-based collaboration theory and E-CARGO model, the leader-centered learning team formation problem is formalized as a collaborative optimization problem. The mathematical model and the constraint relations are established for this problem, which is solved based on the IBM CPLEX package. Finally, a case study and experiments demonstrate that the proposed approach is efficient and feasible, in favor of improving the satisfaction degree of learners.},
  archive      = {J_TCSS},
  author       = {Hua Ma and Jingze Li and Haibin Zhu and Wensheng Tang and Zhuoxuan Huang and Yuqi Tang},
  doi          = {10.1109/TCSS.2022.3224762},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {184-196},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Collaborative optimization of learning team formation based on multidimensional characteristics and constraints modeling: A team leader-centered approach via E-CARGO},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An emotion recognition method based on eye movement and
audiovisual features in MOOC learning environment. <em>TCSS</em>,
<em>11</em>(1), 171–183. (<a
href="https://doi.org/10.1109/TCSS.2022.3221128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, more and more people have begun to use massive online open course (MOOC) platforms for distance learning. However, due to the space–time isolation between teachers and students, the negative emotional state of students in MOOC learning cannot be identified timely. Therefore, students cannot receive immediate feedback about their emotional states. In order to identify and classify learners’ emotions in video learning scenarios, we propose a multimodal emotion recognition method based on eye movement signals, audio signals, and video images. In this method, two novel features are proposed: feature of coordinate difference of eyemovement (FCDE) and pixel change rate sequence (PCRS). FCDE is extracted by combining eye movement coordinate trajectory and video optical flow trajectory, which can represent the learner’s attention degree. PCRS is extracted from the video image, which can represent the speed of image switching. A feature extraction network based on convolutional neural network (CNN) (FE-CNN) is designed to extract the deep features of the three modals. The extracted deep features are inputted into the emotion classification CNN (EC-CNN) to classify the emotions, including interest, happiness, confusion, and boredom. In single modal identification, the recognition accuracies corresponding to the three modals are 64.32%, 74.67%, and 71.88%. The three modals are fused by feature-level fusion, decision-level fusion, and model-level fusion methods, and the evaluation experiment results show that the method of decision-level fusion achieved the highest score of 81.90% of emotion recognition. Finally, the effectiveness of FCDE, FE-CNN, and EC-CNN modules is verified by ablation experiments.},
  archive      = {J_TCSS},
  author       = {Jindi Bao and Xiaomei Tao and Yinghui Zhou},
  doi          = {10.1109/TCSS.2022.3221128},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {171-183},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {An emotion recognition method based on eye movement and audiovisual features in MOOC learning environment},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Disastrous event and sub-event detection from microblog
posts using bi-clustering method. <em>TCSS</em>, <em>11</em>(1),
161–170. (<a href="https://doi.org/10.1109/TCSS.2022.3213794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media has become a nondetachable part of our life, with the exponential growth of usage in the past decade. Social sites like Twitter, Facebook, Instagram, Flickr, Weibo, etc., with their millions of user base, apart from being a source of entertainment, has proven to be a very useful mean for public opinion generation, news propagation and information broadcasting by authorities. Social media data analysis has been a popular research area for the past few years. Detecting subevents from social media posts to identify an unusual event that requires special attention, especially in a disaster situation, is one of the key researches in this domain. In this article, we have proposed a novel biclustering-based subevent detection method from the Twitter dataset for retrospective analysis of disaster events. First, we have clustered the data matrix using spectral co-clustering. Then we identified subevents (words) and formulated a ranking framework to find the top-ranked subevents within the clusters. Finally, through statistical analysis, we have shown that the proposed framework works better than other existing subevent detection methods.},
  archive      = {J_TCSS},
  author       = {Shatadru Roy Chowdhury and Srinka Basu and Ujjwal Maulik},
  doi          = {10.1109/TCSS.2022.3213794},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {161-170},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Disastrous event and sub-event detection from microblog posts using bi-clustering method},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A graph sampling-based model for influence maximization in
large-scale social networks. <em>TCSS</em>, <em>11</em>(1), 144–160. (<a
href="https://doi.org/10.1109/TCSS.2022.3216587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks have attracted a great deal of attention and have, in fact, changed the way we produce, consume, and diffuse information. This change gave rise to the notion of social influence and today we talk about influential nodes. The process of detecting influential nodes in social networks aims to find entities that propagate information to a large portion of the network users. This process is often known as the influence maximization (IM) problem. Due to the explosive growth of social networks’ data, their structure is more complex and we talk about “big graph data.” Moreover, modern networks are dynamic and their topology or/and information is likely to change over time. Detecting influential nodes in such networks is a challenging task. Several methods have been developed in this context. However, they concentrate on static networks and there is little work on large-scale social networks. We propose in this article a new model for IM called MapReduce-based dynamic selection of influential nodes (MR-DSINs) that has the ability to cope with the huge size of real social networks. In fact, our approach is based on a graph sampling step in order to reduce the network’s size. Given that reduced version, MR-DSIN is able to select dynamically influential nodes. Our proposal has the advantage of considering the dynamics of information that can be modeled by users’ social actions (e.g., “share,” “comment,” “retweet”). Experimental results on real-world social networks and computer-generated artificial graphs demonstrate that MR-DSIN is efficient for identifying influential nodes, compared with three known proposals. We prove that our model is able to detect in the reduced graph an influence as important as in the original one.},
  archive      = {J_TCSS},
  author       = {Myriam Jaouadi and Lotfi Ben Romdhane},
  doi          = {10.1109/TCSS.2022.3216587},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {144-160},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A graph sampling-based model for influence maximization in large-scale social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strategic analysis of the parameter servers and participants
in federated learning: An evolutionary game perspective. <em>TCSS</em>,
<em>11</em>(1), 132–143. (<a
href="https://doi.org/10.1109/TCSS.2022.3224909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a new decentralized deep learning paradigm developed for collaborative model training and solving the problem of data privacy and has received extensive attention from both the academic and business worlds. However, FL still faces challenges in encouraging participants to contribute private data and computational resources. Although many studies have applied game theory models to improve the incentive mechanism design of FL, they assume that the players are absolutely rational and that the game models are static. In this study, a mathematical model based on evolutionary game theory (EGT) is established to analyze the interaction between parameter servers and participants, considering that the participants are not completely rational in the long-term dynamic decision-making process. The evolutionarily stable status of the FL system and the strategies of the parameter servers and participants were analyzed under eight different scenarios. Based on the model analysis and results of the numerical experiments, managerial insights for maintaining a sustainable FL system are summarized.},
  archive      = {J_TCSS},
  author       = {Xinggang Luo and Zhongliang Zhang and Jiahuan He and Shengnan Hu},
  doi          = {10.1109/TCSS.2022.3224909},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {132-143},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Strategic analysis of the parameter servers and participants in federated learning: An evolutionary game perspective},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy-preserving federated learning for value-added
service model in advanced metering infrastructure. <em>TCSS</em>,
<em>11</em>(1), 117–131. (<a
href="https://doi.org/10.1109/TCSS.2022.3204361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced metering infrastructure (AMI) is the backbone of the next generation smart city and smart grid; it not only provides near real-time two-way communication between the consumers and the energy systems, but also enables the third parties (TPs) to provide relevant value-added services to the consumers to improve user satisfaction. However, the existing services are implemented in a centralized manner, which has potential and associated security and privacy risks also increased with Internet-of-Things (IoT) devices. To better balance the quality of the services and ensure users’ privacy, a TP AMI service model based on differentially private federated learning (FL) is proposed in this article. Instead of sending the private energy data to the cloud server, the proposed service model trains the neural network models locally, and only model parameters are shared with the central server. Moreover, the identity of individuals is eliminated by adding random Gaussian noise during the secure aggregation. Furthermore, an attention-based bidirectional long short-term memory (ATT-BLSTM) neural network model is adopted to solve the long-range dependency problem of conventional neural networks. In the case study, a residential short-term load forecasting (STLF) task is implemented to evaluate the performance of the proposed model. Compared with other state-of-the-art energy service models, the proposed one can achieve similar accuracy as the typical centralized model and balances the trade-off between privacy loss and prediction accuracy flexibly.},
  archive      = {J_TCSS},
  author       = {Xiao-Yu Zhang and José-Rodrigo Córdoba-Pachón and Peiqian Guo and Chris Watkins and Stefanie Kuenzel},
  doi          = {10.1109/TCSS.2022.3204361},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {117-131},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Privacy-preserving federated learning for value-added service model in advanced metering infrastructure},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new perspective for computational social systems: Fuzzy
modeling and reasoning for social computing in CPSS. <em>TCSS</em>,
<em>11</em>(1), 101–116. (<a
href="https://doi.org/10.1109/TCSS.2022.3197421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of modern mobile terminals, social networks, and other intelligent services makes everyone become a ubiquitous information perceiver, producer, and propagator. Also known as “social sensor” and “social IoT,” these individuals and communities generate a huge volume of social signals, which has shown prominent value for mining. These unstructured social signals provide a new perspective in the research of complex systems, which makes the traditional cyber–physical system (CPS)-oriented information computing sublimate to the cyber–physical–social system (CPSS)-oriented knowledge computing. However, there still exist great uncertainties, ambiguities, and complexities in modeling behaviors of social individuals or groups. Especially when we apply big-data-driven learning-based models in specific fields and scenarios, the lack of domain expert knowledge and characteristics of system uncertainty severely limits the performance and accuracy of these models. The introduction of fuzzy system modeling integrates data and knowledge in the social computing area, which has shown its unique advantages in solving the above issues and has drawn more attention to this topic. In this article, we conduct a review of recent advances in social computing with fuzzy technologies in CPSS. First, we briefly review the development of social computing, and analyze the characteristics and advantages of social computing through fuzzy methods. Second, we refine core fuzzy system methods for social computing and elaborate on existing fuzzy-technology-empowered social computing methodologies. As in a range of social spaces, we also review and analyze related advances in human-in-the-loop systems. We also reveal the trend of decentralized, autonomous, and organized computing in cyber–physical–social space with fuzzy-based methods and proposed a framework to categorize related studies in CPSS. Finally, we conclude the research trends and hotspots based on current studies, and discuss the challenges for future research directions.},
  archive      = {J_TCSS},
  author       = {Tan Wang and Yifan Zhu and Peijun Ye and Weichao Gong and Hao Lu and Hong Mo and Fei-Yue Wang},
  doi          = {10.1109/TCSS.2022.3197421},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {101-116},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {A new perspective for computational social systems: Fuzzy modeling and reasoning for social computing in CPSS},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On implementing social community clouds based on markov
models. <em>TCSS</em>, <em>11</em>(1), 89–100. (<a
href="https://doi.org/10.1109/TCSS.2022.3213273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks reflect, to a wide extent, the real-world relationships that allow users to connect and share information. The number of people that interact in social networks keeps increasing, and the devices used are equipped with more and more computational capacities. This gives rise to the formulation of social clouds, which refer to resource-sharing infrastructures that enable friends to share their resources within the social network. As modern applications become more and more sophisticated, users should be able to share their own services and computing resources through social networks. This poses many challenges for the design options of a computing system composed of a set of trusted friends. The spotlight turns on the design of a proper trust model that considers the suitability of the trusted users to execute an application’s tasks and on the fair distribution of these tasks among these users. Therefore, social networks and their trust-based applications in a distributed environment have seen increasing attention in the research community. In this regard, we present a social community cloud implementation model, where friendly relationships determine resource provisioning. The issues of fairness and allocation of time are of great importance and they are thoroughly investigated. We use extensive simulations to illustrate that the communities can be employed to construct cloud infrastructures, such that the shared resources can be utilized fairly and efficiently. Our experiments have shown that our model achieves a higher allocation rate (percentage of tasks successfully allocated and completed) than competitive models and reduces the average response time and the total execution time. Finally, our work does not overutilize the resources.},
  archive      = {J_TCSS},
  author       = {Stavros Souravlas and Sofia D. Anastasiadou},
  doi          = {10.1109/TCSS.2022.3213273},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {89-100},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {On implementing social community clouds based on markov models},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeepInsight: Topology changes assisting detection of
adversarial samples on graphs. <em>TCSS</em>, <em>11</em>(1), 76–88. (<a
href="https://doi.org/10.1109/TCSS.2022.3213329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of artificial intelligence, a number of machine learning algorithms, such as graph neural networks (GNNs), have been proposed to facilitate network analysis or graph data mining. Although effective, recent studies show that these advanced methods may suffer from adversarial attacks, i.e., they may lose effectiveness when only a small fraction of links are unexpectedly changed. This article investigates three well-known adversarial attack methods, i.e., Nettack, Meta Attack, and GradArgmax. It is found that different attack methods have their specific attack preferences on changing the target network structures. Such attack patterns are further verified by experimental results on some real-world networks, revealing that, generally, the top-4 most important network attributes on detecting adversarial samples suffice to explain the preference of an attack method. Based on these findings, the network attributes are utilized to design machine learning models for adversarial sample detection and attack method recognition with outstanding performance.},
  archive      = {J_TCSS},
  author       = {Junhao Zhu and Jinhuan Wang and Yalu Shan and Shanqing Yu and Guanrong Chen and Qi Xuan},
  doi          = {10.1109/TCSS.2022.3213329},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {76-88},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {DeepInsight: Topology changes assisting detection of adversarial samples on graphs},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Co-activity maximization in online social networks.
<em>TCSS</em>, <em>11</em>(1), 66–75. (<a
href="https://doi.org/10.1109/TCSS.2022.3213260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media with online social networks has risen to be a prevalent force in information diffusion and public discourse. Despite its popularity and convenience, social media has been criticized for contributing to societal and ideological polarization as the result of trapping users in an echo chamber and filter bubbles. An emerging line of research focuses on ways to redesign content or link recommendation algorithms to mitigate the polarization phenomenon. However, existing works mainly concentrate on node-level balancing, while omitting the balancing effect that can be incurred by edge interaction in social networks. In this article, we take the first step to study the problem (CoAM) that assuming two campaigns are present in a network, how we should select seeds for each so as to maximize the interaction/activity between the followers of two campaigns (co-activity) after the diffusion process is finished. We begin our analysis by showing the hardness of CoAM under two diffusion models that are generalized from wildly used diffusion models and its objective function is neither submodular nor supermodular. This encourages us to design a submodular function that acts as a lower bound to the objective, by exploiting which we are able to devise a greedy algorithm with a provable approximation guarantee. To overcome the #P-hardness of diffusion calculation, we further extend the notion of random reverse-reachable (RR) set to devise a scalable instantiation of our approximation algorithm. We experimentally demonstrate the quality of our approximation algorithm on datasets collected from real-world social networks.},
  archive      = {J_TCSS},
  author       = {Dongyu Mao and Weili Wu and Ding-Zhu Du},
  doi          = {10.1109/TCSS.2022.3213260},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {66-75},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Co-activity maximization in online social networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective knowledge dissemination modeling and regulation in
blended learning networks. <em>TCSS</em>, <em>11</em>(1), 51–65. (<a
href="https://doi.org/10.1109/TCSS.2022.3213076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blended learning networks (BLNs) based on the integration of online learning networks and offline learning environments provide new opportunities and platforms for people to acquire and update useful knowledge and carry out all kinds of learning activities anytime and anywhere. Effective modeling and regulation of the knowledge dissemination process can accurately grasp its dissemination process, promote knowledge innovation and collaborative sharing among learners, and accelerate the maximization of knowledge dissemination. However, it is a challenge to establish a comprehensive dynamics model and adopt the optimal regulation for the knowledge dissemination process under the constraints of a limited budget in large-scale BLNs with diverse learners. To this end, we first explore the evolution process of knowledge dissemination in BLNs and the blended learning interaction process of learners. Based on the system dynamics modeling theory, a dynamics model of knowledge dissemination is established. Second, two kinds of effective regulation strategies are proposed. We establish an optimal regulation system intending to maximize the dissemination of knowledge and use the optimal control theory to tackle the optimal solution distribution of regulation strategies. Then, we propose a knowledge dissemination regulation task allocation method based on the collaborative participation of users, and the reverse auction theory is used to quickly solve the task allocation scheme while ensuring performance. Finally, we demonstrate the effectiveness of proposed models and methods through extensive simulation experiments based on real datasets.},
  archive      = {J_TCSS},
  author       = {Yaguang Lin and Xiaoming Wang and Fei Hao and Liang Wang and Changqin Huang},
  doi          = {10.1109/TCSS.2022.3213076},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {51-65},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Effective knowledge dissemination modeling and regulation in blended learning networks},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial–temporal urban mobility pattern analysis during
COVID-19 pandemic. <em>TCSS</em>, <em>11</em>(1), 38–50. (<a
href="https://doi.org/10.1109/TCSS.2022.3201590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the repeated outbreaks of the COVID-19, many countries implement the region-specific, multilevel epidemic prevention and control policies. To fully understand the impact of these interventions on urban mobility, it is urgent to analyze spatial–temporal mobility pattern at the neighborhood level and structural changes in urban mobility networks. Here, we construct urban mobility networks among points of interest (POIs), using large-scale anonymous mobility data from de-identified mobile phone users. We comprehensively investigate the changes of urban mobility networks during two waves of the COVID-19 pandemic in Beijing from both graph and subgraph perspectives. Beyond an overall mobility reduction in Beijing, we find that the mobility change is spatially and temporally heterogeneous among different urban regions. We uncover a disproportionately large reduction in long-distance, nighttime, and non-essential travel. This results in a more geographically fragmented, local, and regional network in the pandemic. We demonstrate that these structural changes slow down the spatial spread of the COVID-19 in the mobility network.},
  archive      = {J_TCSS},
  author       = {Yanggang Cheng and Chao Li and Yongtao Zhang and Shibo He and Jiming Chen},
  doi          = {10.1109/TCSS.2022.3201590},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {38-50},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Spatial–Temporal urban mobility pattern analysis during COVID-19 pandemic},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive collaboration with training plan considering role
correlation. <em>TCSS</em>, <em>11</em>(1), 25–37. (<a
href="https://doi.org/10.1109/TCSS.2022.3204052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on role-based collaboration (RBC), group role assignment (GRA) optimizes a team’s overall performance by assigning the most appropriate individual agents from the team’s viewpoint based on agents’ role-playing abilities. As an extension of GRA, GRA with a training plan (GRATP) deals with the impact of training on team management. Considering the correlation between roles, the training of one agent on one role also affects the performance of the agent in other roles. Moreover, in the adaptive collaboration (AC) problem, the training time also affects significantly the agent’s ability, as an agent’s ability changes over time. However, the existing GRATP models fail to consider these factors in the collaboration process. Therefore, we aim to address the role-correlation-based adaptive GRATP (RCA-GRATP) in this article. This article contributes two aspects to the literature on AC. 1) RCA-GRATP problem is abstracted based on RBC and GRA. To the best of the authors’ knowledge, this is the first article that explicitly considers role correlation in the RBC problems. 2) A comprehensive formalization of RCA-GRATP and two solving algorithms for diverse situations are proposed to solve the formalized problems. Experiments are carried out to verify the effectiveness of the proposed algorithms in diverse scenarios.},
  archive      = {J_TCSS},
  author       = {Libo Zhang and Zhihang Yu and Shiyu Wu and Haibin Zhu and Yin Sheng},
  doi          = {10.1109/TCSS.2022.3204052},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {25-37},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Adaptive collaboration with training plan considering role correlation},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physiological electrosignal asynchronous acquisition
technology: Insight and perspectives. <em>TCSS</em>, <em>11</em>(1),
5–24. (<a href="https://doi.org/10.1109/TCSS.2024.3350958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With great pride and enthusiasm, we present the inaugural edition of IEEE Transactions on Computational Social Systems (TCSS) for 2024. Reflecting on the year gone by, 2023 stands as a hallmark of academic excellence and prolific output, wherein our journal has successfully disseminated a substantial volume of scholarly work—301 articles encompassing approximately 3600 pages, distributed across six distinct issues.},
  archive      = {J_TCSS},
  author       = {Bin Hu and Lixian Zhu and Qunxi Dong and Kun Qian and Hanshu Cai and Fuze Tian},
  doi          = {10.1109/TCSS.2024.3350958},
  journal      = {IEEE Transactions on Computational Social Systems},
  month        = {2},
  number       = {1},
  pages        = {5-24},
  shortjournal = {IEEE Trans. Comput. Social Syst.},
  title        = {Physiological electrosignal asynchronous acquisition technology: Insight and perspectives},
  volume       = {11},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
