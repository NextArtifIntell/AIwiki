<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mis---55">MIS - 55</h2>
<ul>
<li><details>
<summary>
(2024). Artificial intelligence-based video saliency prediction:
Challenges and trends. <em>MIS</em>, <em>39</em>(6), 86–90. (<a
href="https://doi.org/10.1109/MIS.2024.3482950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video saliency prediction (VSP) aims to identify regions in videos that attract human attention and gaze. In the past, researchers have conducted extensive studies on VSP, establishing various video saliency datasets and prediction models. Leveraging the powerful end-to-end learning capabilities of deep learning techniques and the availability of large-scale video saliency datasets, the performance of saliency prediction models has significantly improved. Today, with the development of multimedia technologies, the task of VSP has generated numbers of promising directions, such as high dynamic range VSP and audio VSP, among others. This article focuses on the challenges of VSP in the context of multimedia technologies; reviews the research on video saliency, including video saliency datasets and prediction models; and then introduces potential research directions in conjunction with contemporary multimedia technologies.},
  archive      = {J_MIS},
  author       = {Jiongzhi Lin and Baitao Huang and Fei Zhou},
  doi          = {10.1109/MIS.2024.3482950},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {86-90},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Artificial intelligence-based video saliency prediction: Challenges and trends},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Streaming continual learning for unified adaptive
intelligence in dynamic environments. <em>MIS</em>, <em>39</em>(6),
81–85. (<a href="https://doi.org/10.1109/MIS.2024.3479469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing effective predictive models becomes challenging in dynamic environments that continuously produce data and constantly change. Continual learning (CL) and streaming machine learning (SML) are two research areas that tackle this arduous task. We put forward a unified setting that harnesses the benefits of both CL and SML: their ability to quickly adapt to nonstationary data streams without forgetting previous knowledge. We refer to this setting as streaming CL (SCL). SCL does not replace either CL or SML. Instead, it extends the techniques and approaches considered by both fields. We start by briefly describing CL and SML and unifying the languages of the two frameworks. We then present the key features of SCL. Finally, we highlight the importance of bridging the two communities to advance the field of intelligent systems.},
  archive      = {J_MIS},
  author       = {Federico Giannini and Giacomo Ziffer and Andrea Cossu and Vincenzo Lomonaco},
  doi          = {10.1109/MIS.2024.3479469},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {81-85},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Streaming continual learning for unified adaptive intelligence in dynamic environments},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Are foundation models the next-generation social media
content moderators? <em>MIS</em>, <em>39</em>(6), 70–80. (<a
href="https://doi.org/10.1109/MIS.2024.3477109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress in artificial intelligence (AI) tools and systems has been significant, especially in their reasoning and efficiency. Notable examples include generative AI-based large language models (LLMs) like Generative Pre-trained Transformer 3.5 (GPT-3.5), GPT-4, and Gemini, among others. In our work, we evaluated the effectiveness of fine-tuned deep learning models compared to general-purpose LLMs in moderating image-based content. We used deep learning models such as convolutional neural networks, ResNet50, and VGG-16, trained them for violence detection on an image dataset, and tested them on a separate dataset. The same test dataset was also evaluated using Large Language and Vision Assistant (LLaVa) and GPT-4, two LLMs that can process images. The results demonstrate that VGG-16 model had the highest accuracy at 0.94, while LLaVa had the lowest at 0.66. GPT-4 showed superiority over LLaVa with an accuracy value of 0.9242. LLaVa recorded the highest precision of all models.},
  archive      = {J_MIS},
  author       = {Mohammad Nadeem and Laeeba Javed and Shahab Saquib Sohail and Erik Cambria and Amir Hussain},
  doi          = {10.1109/MIS.2024.3477109},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {70-80},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Are foundation models the next-generation social media content moderators?},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multigradient siamese temporal model for the prediction of
clinical events in rapid response systems. <em>MIS</em>, <em>39</em>(6),
58–69. (<a href="https://doi.org/10.1109/MIS.2024.3408290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The early identification of emergency situations for intensive care unit patients is a critical component of precision medicine. We present a multigradient Siamese temporal (MG-SiameseTS) model to predict patients’ clinical status within an 8-h window and trigger an alarm when anticipating an emergent situation. It incorporates gradient extractors, contrastive learning, focal loss, and imbalanced loss to address challenges related to bias, data quality, and interpretability. Experimental results using a practical dataset collected from the rapid response team at Chonnam National University Hospital in Korea demonstrate that the MG-SiameseTS model exhibits superior predictive capabilities for clinical events compared to several state-of-the-art methods.},
  archive      = {J_MIS},
  author       = {Trong-Nghia Nguyen and Soo-Hyung Kim and Bo-Gun Kho and Hyung-Jeong Yang},
  doi          = {10.1109/MIS.2024.3408290},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {58-69},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Multigradient siamese temporal model for the prediction of clinical events in rapid response systems},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unraveling complexity: An exploration into large-scale
multimodal signal processing. <em>MIS</em>, <em>39</em>(6), 48–57. (<a
href="https://doi.org/10.1109/MIS.2024.3398592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced communication systems and military reconnaissance are increasingly prevalent in high-tech environments, greatly supported by the flourishing in signal processing technologies. The recent exponential proliferation of sensors led to an unprecedented expansion in the scale and diversity of signals across various modalities. Such an influx poses significant challenges in effectively integrating multimodal signal data to deliver comprehensive and interpretive solutions across a diverse range of applications. In this article, we provide an overview of the core issues, challenges, and future research directions in different stages of developing large-scale multimodal signal processing models. Additionally, we introduce a prior investigation into signal representation learning, where we propose a contrastive-learning-based framework to extract fine-grained signal features under few-shot conditions. Our proposed framework achieves a 24.1% performance improvement over baseline approaches, consistently demonstrating superiority over state-of-the-art methods. The code is accessible in this repository: https://github.com/YYH211/LSM.},
  archive      = {J_MIS},
  author       = {Zhenyu Wen and Yuheng Ye and Jie Su and Taotao Li and Jinhao Wan and Shilian Zheng and Zhen Hong and Shibo He and Haoran Duan and Yuexiang Li and Yawen Huang and Yefeng Zheng},
  doi          = {10.1109/MIS.2024.3398592},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {48-57},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Unraveling complexity: An exploration into large-scale multimodal signal processing},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiclass unlearning for image classification via weight
filtering. <em>MIS</em>, <em>39</em>(6), 40–47. (<a
href="https://doi.org/10.1109/MIS.2024.3412742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine unlearning is an emerging paradigm for selectively removing the impact of training datapoints from a network. Unlike existing methods that target a limited subset or a single class, our framework unlearns all classes in a single round. We achieve this by modulating the network’s components using memory matrices, enabling the network to demonstrate selective unlearning behavior for any class after training. By discovering weights that are specific to each class, our approach also recovers a representation of the classes which is explainable by design. We test the proposed framework on small- and medium-scale image classification datasets, with both convolution- and transformer-based backbones, showcasing the potential for explainable solutions through unlearning.},
  archive      = {J_MIS},
  author       = {Samuele Poppi and Sara Sarto and Marcella Cornia and Lorenzo Baraldi and Rita Cucchiara},
  doi          = {10.1109/MIS.2024.3412742},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {40-47},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Multiclass unlearning for image classification via weight filtering},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regulated federated learning against the effects of
heterogeneity and client attacks. <em>MIS</em>, <em>39</em>(6), 28–39.
(<a href="https://doi.org/10.1109/MIS.2024.3410372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL), as a new privacy learning paradigm, can complete the learning task without compromising user privacy. With the enhancement of user data protection awareness, FL has received much attention and has been widely applied. However, the FL mechanism, where clients train models using personal data locally and exchange model updates instead of raw data, gives rise to new challenges. The problems caused by data heterogeneity and malicious client behaviors are universal in practical applications. We proposed a regulated FL (RegulFL) that introduces a generator and uses weighted aggregations to regulate client model training and complete federated aggregation. In addition, we gave a weighted geometric median method to get client weights that can effectively reduce the influence of malicious clients in aggregation processes. Experimental results demonstrate that RegulFL is robust against malicious client attacks while effectively mitigating the effect of data heterogeneity.},
  archive      = {J_MIS},
  author       = {Fei Hu and Wuneng Zhou and Kaili Liao and Hongliang Li and Dongbing Tong},
  doi          = {10.1109/MIS.2024.3410372},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {28-39},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Regulated federated learning against the effects of heterogeneity and client attacks},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explaining imitation learning through frames. <em>MIS</em>,
<em>39</em>(6), 18–27. (<a
href="https://doi.org/10.1109/MIS.2024.3404988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the prevalent methods to achieve automation systems, imitation learning (IL) presents a promising performance in a wide range of domains. However, despite the considerable improvement in policy performance, the corresponding research on the explainability of IL models is still limited. Inspired by the recent approaches in explainable AI, we proposed a model-agnostic explaining framework for IL models called Remove and Retrain via Randomized Input Sampling for Explanation (R2RISE). R2RISE aims to explain the importance of frames with respect to the overall policy performance. It iteratively retrains the black-box IL model from the randomized masked demonstrations and uses the conventional evaluation outcome environment returns as the coefficient to build an importance map. We also conducted experiments to investigate three major questions concerning frames’ importance equality, the effectiveness of the importance map, and connections in importance maps from different IL models. The result shows that R2RISE distinguishes important frames from the demonstrations effectively.},
  archive      = {J_MIS},
  author       = {Boyuan Zheng and Jianlong Zhou and Chunjie Liu and Yiqiao Li and Fang Chen},
  doi          = {10.1109/MIS.2024.3404988},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {18-27},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Explaining imitation learning through frames},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neurosymbolic AI approach to attribution in large language
models. <em>MIS</em>, <em>39</em>(6), 10–17. (<a
href="https://doi.org/10.1109/MIS.2024.3477108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribution in large language models (LLMs) remains a significant challenge, particularly in ensuring the factual accuracy and reliability of the generated outputs. Current methods for citation or attribution, such as those employed by tools like Perplexity.ai and Bing-Search-integrated LLMs, attempt to ground responses by providing real-time search results and citations. However, so far, these approaches suffer from issues such as hallucinations; biases; surface-level relevance matching; and the complexity of managing vast, unfiltered knowledge sources. While tools like Perplexity.ai dynamically integrate Web-based information and citations, they often rely on inconsistent sources, such as blog posts or unreliable sources, which limits their overall reliability. We explain that these challenges can be mitigated by integrating neurosymbolic AI (NesyAI), which combines the strengths of neural networks, with structured symbolic reasoning. NesyAI offers transparent, interpretable, and dynamic reasoning processes, addressing the limitations of current attribution methods by incorporating structured symbolic knowledge with flexible, neural-based learning. This article explores how NesyAI frameworks can enhance existing attribution models, offering more reliable, interpretable, and adaptable systems for LLMs.},
  archive      = {J_MIS},
  author       = {Deepa Tilwani and Revathy Venkataramanan and Amit P. Sheth},
  doi          = {10.1109/MIS.2024.3477108},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {10-17},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Neurosymbolic AI approach to attribution in large language models},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). To thrive in the artificial intelligence age, stay
professionally fit—forever. <em>MIS</em>, <em>39</em>(6), 5–9. (<a
href="https://doi.org/10.1109/MIS.2024.3479468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MIS},
  author       = {San Murugesan},
  doi          = {10.1109/MIS.2024.3479468},
  journal      = {IEEE Intelligent Systems},
  month        = {11-12},
  number       = {6},
  pages        = {5-9},
  shortjournal = {IEEE Intell. Syst.},
  title        = {To thrive in the artificial intelligence age, stay professionally Fit—Forever},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint weakly supervised image emotion analysis based on
interclass discrimination and intraclass correlation. <em>MIS</em>,
<em>39</em>(5), 82–89. (<a
href="https://doi.org/10.1109/MIS.2024.3441408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regional information-based image emotion analysis has recently garnered significant attention. However, existing methods often focus on identifying region proposals through layered steps or merely rely on visual saliency. These approaches may lead to an underestimation of emotional categories and a lack of comprehensive interclass discrimination perception and emotional intraclass contextual mining. To address these limitations, we propose a novel approach named InterIntraIEA, which combines interclass discrimination and intraclass correlation joint learning capabilities for image emotion analysis. The proposed method not only employs category-specific dictionary learning for class adaptation, but also models intraclass contextual relationships and perceives correlations at the channel level. This refinement process improves interclass descriptive ability and enhances emotional categories, resulting in the production of pseudomaps that provide more precise emotional region information. These pseudomaps, in conjunction with top-level features extracted from a multiscale extractor, are then input into a weakly supervised fusion module to predict emotional sentiment categories.},
  archive      = {J_MIS},
  author       = {Xinyue Zhang and Zhaoxia Wang and Guitao Cao and Seng-Beng Ho},
  doi          = {10.1109/MIS.2024.3441408},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {82-89},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Joint weakly supervised image emotion analysis based on interclass discrimination and intraclass correlation},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Do ChatGPT 4o, 4, and 3.5 generate “similar” ratings?
Findings and implications. <em>MIS</em>, <em>39</em>(5), 78–81. (<a
href="https://doi.org/10.1109/MIS.2024.3441136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, I generate ratings for a set of innovation ideas using three versions of ChatGPT: 4o, 4, and 3.5. I find that, although the resulting ratings are highly correlated among those three versions, both 4o and 4 generate ratings whose means are statistically significantly greater than those generated with version 3.5. In addition, the variances of the ratings when using versions 4o and 4 are smaller than the variance for version 3.5. These results indicate that the more recent versions of ChatGPT have larger ratings estimates and less variation. These evolutionary changes suggest some implications of using ChatGPT for ratings of ideas, objects, people, and software and indicate that this property may limit applicability in some settings. I examine some other implications and also analyze what the findings potentially mean for the newly emerging concept of selectively advantageous instability.},
  archive      = {J_MIS},
  author       = {Daniel E. O’Leary},
  doi          = {10.1109/MIS.2024.3441136},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {78-81},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Do ChatGPT 4o, 4, and 3.5 generate “Similar” ratings? findings and implications},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SupRTE: Suppressing backdoor injection in federated learning
via robust trust evaluation. <em>MIS</em>, <em>39</em>(5), 66–77. (<a
href="https://doi.org/10.1109/MIS.2024.3392334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel scheme, SupRTE, to suppress backdoor injection in federated learning via robust trust evaluation, which effectively prevents malicious updates from infiltrating the model aggregation process. The robust trust evaluation process in SupRTE consists of two components: 1) the behavior representation extractor, which creates individual profiles for each client through multidimensional information, and 2) the trust scorer, which measures the discrepancies between malicious and benign clients as trust scores by utilizing grading and clustering strategies. According to these trust scores, SupRTE can dynamically adjust the weight of each participating client to effectively suppress the malicious backdoor injection. Remarkably, SupRTE can be easily deployed on the server without requiring any auxiliary information and is highly adaptable to various nonindependent identically distributed scenarios. Extensive experiments over three datasets against two kinds of backdoor variants are conducted. Experimental results demonstrate that SupRTE can significantly reduce the attack success rate to below 2% with a minimal impact on the main task accuracy and outperforms state-of-the-art defense methods.},
  archive      = {J_MIS},
  author       = {Wenkai Huang and Gaolei Li and Xiaoyu Yi and Jianhua Li and Chengcheng Zhao and Ying Yin},
  doi          = {10.1109/MIS.2024.3392334},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {66-77},
  shortjournal = {IEEE Intell. Syst.},
  title        = {SupRTE: Suppressing backdoor injection in federated learning via robust trust evaluation},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved small object detection algorithm based on YOLOv5.
<em>MIS</em>, <em>39</em>(5), 57–65. (<a
href="https://doi.org/10.1109/MIS.2024.3399053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {YOLOv5 is a popular object detection algorithm that is widely used in various industrial fields, especially in the field of autonomous driving. However, this algorithm has problems, such as false positives and false negatives when detecting small targets. The article proposes an improved method for small object detection using YOLOv5s. First, a multilevel feature fusion detection head is proposed to extract larger feature maps from the backbone of the model, improving the ability to extract features of small objects. Second, a decoupled attention mechanism is introduced at each detection head, which separates the detection of object box position, object box confidence, and class probability to reduce confusion between different feature information. Finally, the focal minimum points distance intersection over union loss function is adopted to mitigate the effects of class imbalance and poor-quality object pixels.},
  archive      = {J_MIS},
  author       = {Bo Xu and Bin Gao and Yunhu Li},
  doi          = {10.1109/MIS.2024.3399053},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {57-65},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Improved small object detection algorithm based on YOLOv5},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ship grid: A novel anchor-free ship detection algorithm.
<em>MIS</em>, <em>39</em>(5), 47–56. (<a
href="https://doi.org/10.1109/MIS.2024.3412750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-based ship detection is crucial for the real-time monitoring of maritime activities, aiding decision making in maritime traffic management, safety monitoring, and rescue operations. Current challenges include multiscale variations and occlusion issues affecting detection accuracy. Existing ship detection methods often address the multiscale problem by redesigning the network architecture, providing limited improvements. We present Ship Grid, an innovative anchor-free ship detection algorithm. Ship Grid tackles the challenges of ship feature capture in occluded scenarios by directly generating bounding boxes at the predicted centers during the label assignment phase. Moreover, it enables simultaneous ship feature extraction at multiple scales, effectively addressing the issues of insufficient feature extraction for small objects and imprecise localization for large objects caused by stark scale variations. In the bounding box regression phase, we introduce a scale-invariant localization loss that guides the regression process of prediction boxes at different scales. This approach allows the network to comprehensively learn ship features across multiple scales and further enhances performance in the presence of large ship scale variations. We rigorously evaluated the ship grid on the SeaShips dataset, achieving 0.988 and 0.835 on the evaluation metrics of mean average precision (mAP) at an intersection over union (IoU) threshold of 0.5 and mAP at IoU thresholds ranging from 0.5 to 0.95 This outperforms state-of-the-art methods, demonstrating its advantage in ship detection.},
  archive      = {J_MIS},
  author       = {Yantong Chen and Yanyan Zhang and Jialiang Wang and Yang Liu},
  doi          = {10.1109/MIS.2024.3412750},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {47-56},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Ship grid: A novel anchor-free ship detection algorithm},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient spiking variational graph autoencoders for
unsupervised graph representation learning tasks. <em>MIS</em>,
<em>39</em>(5), 37–46. (<a
href="https://doi.org/10.1109/MIS.2024.3391937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational graph autoencoders (VGAEs) are popular artificial neural network (ANN)-based models for unsupervised graph representation learning tasks, including link prediction and graph generation, which are critical in many real-world applications. Despite the promising results of VGAEs on these tasks, existing VGAEs typically suffer from extremely high energy cost. Recently, spiking neural networks (SNNs) have emerged as energy-efficient alternatives for applications on graph-structured data, while they are typically trained under supervised settings using label information. To leverage the energy efficiency of SNNs for unsupervised graph learning tasks, in this article, we propose an SNN-based spiking VGAE (S-VGAE) to efficiently learn spiking node representations using graph structural information. We conduct extensive experiments on two typical unsupervised graph learning tasks using benchmark datasets. The results demonstrate that our method can significantly save energy consumption with little or no loss on performances compared to both ANN- and SNN-based baselines.},
  archive      = {J_MIS},
  author       = {Hanxuan Yang and Qingchao Kong and Ruike Zhang and Wenji Mao},
  doi          = {10.1109/MIS.2024.3391937},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {37-46},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Efficient spiking variational graph autoencoders for unsupervised graph representation learning tasks},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring neural networks for musical instrument
identification in polyphonic audio. <em>MIS</em>, <em>39</em>(5), 25–36.
(<a href="https://doi.org/10.1109/MIS.2024.3392586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this article is to introduce neural network-based methods that surpass state-of-the-art models, either by training faster or having simpler architecture, while maintaining comparable effectiveness in musical instrument identification in polyphonic music. Several approaches are presented, including two authors’ proposals, i.e., spiking neural networks (SNNs) and a modular deep learning model named fully modular convolutional neural network (FMCNN). First, a CNN and a convolutional recurrent neural network (CRNN), adapted from literature, are built to detect up to 13 different instruments in polyphonic music. Furthermore, FMCNNs and SNNs are explored. The results obtained demonstrate that both FMCNNs and SNNs outperform traditional CNNs and CRNNs in terms of accurate instrument identification. Moreover, the SNN architecture is much less complex compared to other model sizes. These findings highlight the efficacy of the methods proposed in musical instrument identification in polyphonic audio.},
  archive      = {J_MIS},
  author       = {Maciej Blaszke and Gražina Korvel and Bożena Kostek},
  doi          = {10.1109/MIS.2024.3392586},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {25-36},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Exploring neural networks for musical instrument identification in polyphonic audio},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lights toward adversarial machine learning: The achilles
heel of artificial intelligence. <em>MIS</em>, <em>39</em>(5), 20–24.
(<a href="https://doi.org/10.1109/MIS.2024.3441137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI)-based technologies are starting to be adopted in the industrial world in many different contexts and sectors, from health care to the automotive, from agriculture to the industrial. As such applications operate in sensitive contexts, it is natural to question: Are they cyber-secure? Can attackers exploit AI applications for their attack? In this work, we discuss the Achilles heel of artificial intelligence: the “adversarial machine learning.” From a cybersecurity practitioner’s point of view, we discuss threats related to AI applications that include each component involved in the AI process, from the operative systems and libraries utilized to deploy the AI application, to the actual AI lifecycle.},
  archive      = {J_MIS},
  author       = {Luca Pajola and Mauro Conti},
  doi          = {10.1109/MIS.2024.3441137},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {20-24},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Lights toward adversarial machine learning: The achilles heel of artificial intelligence},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The longtail impact of generative AI on disinformation:
Harmonizing dichotomous perspectives. <em>MIS</em>, <em>39</em>(5),
12–19. (<a href="https://doi.org/10.1109/MIS.2024.3439109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative AI (GenAI) poses significant risks in creating convincing yet factually ungrounded content, particularly in “longtail” contexts of high-impact events and resource-limited settings. While some argue that current disinformation ecosystems naturally limit GenAI’s impact, we contend that this perspective neglects longtail contexts where disinformation consequences are most profound. This article analyzes the potential impact of GenAI’s disinformation in longtail events and settings, focusing on 1) quantity: its ability to flood information ecosystems during critical events; 2) quality: the challenge of distinguishing authentic content from high-quality GenAI content; 3) personalization: its capacity for precise microtargeting exploiting individual vulnerabilities; and 4) hallucination: the danger of unintentional false information generation, especially in high-stakes situations. We then propose strategies to combat disinformation in these contexts. Our analysis underscores the need for proactive measures to mitigate risks, safeguard social unity, and combat the erosion of trust in the GenAI era, particularly in vulnerable communities and during critical events.},
  archive      = {J_MIS},
  author       = {Jason S. Lucas and Barani Maung Maung and Maryam Tabar and Keegan McBride and Dongwon Lee},
  doi          = {10.1109/MIS.2024.3439109},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {12-19},
  shortjournal = {IEEE Intell. Syst.},
  title        = {The longtail impact of generative AI on disinformation: Harmonizing dichotomous perspectives},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neurosymbolic AI for enhancing instructability in generative
AI. <em>MIS</em>, <em>39</em>(5), 5–11. (<a
href="https://doi.org/10.1109/MIS.2024.3441128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative AI, especially via large language models (LLMs), has transformed content creation across text, images, and music, showcasing capabilities in following instructions through prompting, largely facilitated by instruction tuning. Instruction tuning is a supervised fine-tuning method where LLMs are trained on datasets formatted with specific tasks and corresponding instructions. This method systematically enhances the model’s ability to comprehend and execute the provided directives. Despite these advancements, LLMs still face challenges in consistently interpreting complex, multistep instructions and generalizing them to novel tasks, which are essential for broader applicability in real-world scenarios. This article explores why neurosymbolic AI offers a better path to enhance the instructability of LLMs. We explore the use of a symbolic task planner to decompose high-level instructions into structured tasks, a neural semantic parser to ground these tasks into executable actions, and a neuro-symbolic executor to implement these actions while dynamically maintaining an explicit representation of state.},
  archive      = {J_MIS},
  author       = {Amit Sheth and Vishal Pallagani and Kaushik Roy},
  doi          = {10.1109/MIS.2024.3441128},
  journal      = {IEEE Intelligent Systems},
  month        = {9-10},
  number       = {5},
  pages        = {5-11},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Neurosymbolic AI for enhancing instructability in generative AI},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Do large language models bias human evaluations?
<em>MIS</em>, <em>39</em>(4), 83–87. (<a
href="https://doi.org/10.1109/MIS.2024.3415208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article describes an experiment using the output from two different large language models (LLMs). I investigate whether the use of LLM’s to rate intellectual ideas, biases the evaluation of those ideas by their human users. I compare the human users’ evaluations when presented with different evaluations from those different LLM. I find that not only do the LLM’s generate different ratings for the same materials, but those different ratings and their explanations result in statistically significant different average ratings by their human users. These results suggest that LLMs can affect issues such as using LLMs to grade student or research papers or enterprises using LLM to evaluate employees, products, software or other intellectual objects.},
  archive      = {J_MIS},
  author       = {Daniel E. O’Leary},
  doi          = {10.1109/MIS.2024.3415208},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {83-87},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Do large language models bias human evaluations?},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Edge-weight-embedding graph convolutional network for person
reidentification. <em>MIS</em>, <em>39</em>(4), 74–82. (<a
href="https://doi.org/10.1109/MIS.2024.3385381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person reidentification (re-ID) aims to accurately identify the same person in images from a large dataset captured by nonoverlapping cameras. Recently, local-scale features of person representation have been shown to be effective in improving the performance of re-ID. However, most previous methods have overlooked the inherent and potential relationships among the joint parts of the human skeletal structure. There are inherent differences in the human skeletal structure, such as the bone length between joints, which can be considered a highly distinguishable feature for re-ID. To address this, we propose a novel graph-convolutional-network-based method that embeds the relationships between human joints and bones into a high-level representation for re-ID. In our method, the relationships between human joints and bones are represented by the biological information of the human skeletal and encoded into a learned adjacency matrix by an edge score predictor module. Our proposed method achieves competitive results on several benchmark datasets (Market-1501, DukeMTMC-ReID, and CUHK03), demonstrating its effectiveness.},
  archive      = {J_MIS},
  author       = {Yuanhai Lv and Gexuan Wang and Wanqing Zhao and Wei Zhao and Ziyu Guan},
  doi          = {10.1109/MIS.2024.3385381},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {74-82},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Edge-weight-embedding graph convolutional network for person reidentification},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tile-weighted rate-distortion optimized packet scheduling
for 360° virtual-reality video streaming. <em>MIS</em>, <em>39</em>(4),
60–72. (<a href="https://doi.org/10.1109/MIS.2024.3385313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key challenge of 360° virtual-reality (VR) video streaming is ensuring high quality with limited network bandwidth. Currently, most of the studies focus on tile-based adaptive bit-rate streaming to reduce bandwidth consumption, where resources in network nodes are not fully utilized. This article proposes a tile-weighted rate-distortion (TWRD) packet scheduling optimization system to reduce data volume and improve video quality. A multimodal spatial–temporal attention transformer is proposed to predict viewpoint with probability that is used to dynamically weight tiles and their corresponding packets. The packet scheduling problem of determining which packets should be dropped is formulated as an optimization problem solved by a dynamic programming solution. Experiment results demonstrate that the proposed method outperforms the existing methods under various conditions.},
  archive      = {J_MIS},
  author       = {Haopeng Wang and Haiwei Dong and Abdulmotaleb El Saddik},
  doi          = {10.1109/MIS.2024.3385313},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {60-72},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Tile-weighted rate-distortion optimized packet scheduling for 360° virtual-reality video streaming},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective adversarial examples identification of credit card
transactions. <em>MIS</em>, <em>39</em>(4), 50–59. (<a
href="https://doi.org/10.1109/MIS.2024.3378923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit cards are currently a prevalent method of transactions. However, credit cards are susceptible to forgery, leading to numerous cases of fraud. Such actions result in financial losses for consumers, merchants, and banks. Detecting a large number of well-crafted counterfeit credit cards is often challenging through manual means. As a result, much research has been focused on employing artificial intelligence (AI) to achieve high detection performance. However, the accuracy of these AI-based methods may be challenged by attack techniques using adversarial examples. To address this issue, this article utilizes neuron activation status distribution and deep neural networks as detection tools. Furthermore, the experiments employ three methods to generate adversarial examples, showcasing the effectiveness of the proposed detection approach. This ultimately aims to safeguard the rights of credit card users.},
  archive      = {J_MIS},
  author       = {Min-Yan Tsai and Hsin-Hung Cho and Chia-Mu Yu and Yao-Chung Chang and Han-Chieh Chao},
  doi          = {10.1109/MIS.2024.3378923},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {50-59},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Effective adversarial examples identification of credit card transactions},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Operationalizing explainable artificial intelligence in the
european union regulatory ecosystem. <em>MIS</em>, <em>39</em>(4),
37–48. (<a href="https://doi.org/10.1109/MIS.2024.3383155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The European Union’s (EU’s) regulatory ecosystem presents challenges with balancing legal and sociotechnical drivers for explainable artificial intelligence (XAI) systems. Core tensions emerge on dimensions of oversight, user needs, and litigation. This article maps provisions on algorithmic transparency and explainability across major EU data, AI, and platform policies using qualitative analysis. We characterize the involved stakeholders and organizational implementation targets. Constraints become visible between useful transparency for accountability and confidentiality protections. Through an AI hiring system example, we explore the complications with operationalizing explainability. Customization is required to satisfy explainability desires within confidentiality and proportionality bounds. The findings advise technologists on prudent XAI technique selection given multidimensional tensions. The outcomes recommend that policy makers balance worthy transparency goals with cohesive legislation, enabling equitable dispute resolution.},
  archive      = {J_MIS},
  author       = {Luca Nannini and Jose Maria Alonso-Moral and Alejandro Catalá and Manuel Lama and Senén Barro},
  doi          = {10.1109/MIS.2024.3383155},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {37-48},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Operationalizing explainable artificial intelligence in the european union regulatory ecosystem},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Electroencephalogram emotion recognition based on manifold
geomorphological features in riemannian space. <em>MIS</em>,
<em>39</em>(4), 23–36. (<a
href="https://doi.org/10.1109/MIS.2024.3363895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the electroencephalogram (EEG) emotion recognitions are conducted in linear euclidean space. However, it is difficult to accurately describe the nonlinear characteristics of multivariate EEG signals. Comparatively, the Riemannian manifold is a nonlinear space in which features of multivariate EEGs can be analyzed more thoroughly. Therefore, inspired by geographical knowledge, an EEG emotion recognition methodology based on geomorphological features of the Riemannian manifold (GFRM) is proposed. First, in terms of the Wasserstein scalar curvature, an automatic search strategy is developed to narrow down the domain of interest so as to reduce the computation load. Afterward, the geomorphological homogeneity function (GHF) is designed to evaluate regional features of the Riemannian manifold. Finally, we simultaneously devised the fuzzy $\mathbf{k}$k-nearest neighbor classifier of the Riemannian manifold and the local mean classifier of the Riemannian manifold for recognition. On the basis of the GHF, GFRM can automatically choose an appropriate classification strategy for every specific instance to greatly raise the efficiency and accuracy. Two public datasets and one practical lab dataset are utilized to validate the performance of GFRM.},
  archive      = {J_MIS},
  author       = {Yanbing Wang and Hong He},
  doi          = {10.1109/MIS.2024.3363895},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {23-36},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Electroencephalogram emotion recognition based on manifold geomorphological features in riemannian space},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Affective relevance. <em>MIS</em>, <em>39</em>(4), 12–22.
(<a href="https://doi.org/10.1109/MIS.2024.3391508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling information relevance aims to construct a conceptual understanding of information significant for users’ goals. Today, myriad relevance estimation methods are extensively used in various systems and services, mostly using behavioral signals such as dwell-time and click-through data and computational models of visual or textual correspondence to these behavioral signals. Consequently, these signals have become integral for personalizing social media, search engine results, and even supporting critical decision making. However, behavioral signals can only be used to produce rough estimations of the actual underlying affective states that users experience. Here, we provide an overview of recent alternative approaches for measuring and modeling more nuanced relevance based on physiological and neurophysiological sensing. Physiological and neurophysiological signals can directly measure users’ affective responses to information and provide rich data that are not accessible via behavioral measurements. With these data, it is possible to account for users’ affective experience and attentional correlates toward information.},
  archive      = {J_MIS},
  author       = {Tuukka Ruotsalo and V. Javier Traver and Aleksandra Kawala-Sterniuk and Luis A. Leiva},
  doi          = {10.1109/MIS.2024.3391508},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {12-22},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Affective relevance},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AdaCLF: An adaptive curriculum learning framework for
emotional support conversation. <em>MIS</em>, <em>39</em>(4), 5–11. (<a
href="https://doi.org/10.1109/MIS.2024.3411369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotional support conversation (ESC) aims to alleviate emotional distress using data-driven approaches trained on human-generated responses. However, the subjective and open-ended nature of human conversations presents challenges in training ESC models due to uneven complexities in query–response pairs. This uneven complexity impedes the efficiency and effectiveness of learning in ESC models. Based on this, we propose an adaptive curriculum learning framework (AdaCLF) to dynamically choose courses of varying complexity according to the learning status of the ESC model. AdaCLF consists of two main components: the student model (referred to as the ESC model) and the teacher model (responsible for selecting appropriate data to enhance the student model’s training). The framework operates within the reinforcement learning paradigm, where the teacher model utilizes feedback from the student model to optimize its teaching strategy, fostering collaborative evolution. Both automatic and human evaluations on benchmark datasets demonstrate that our framework significantly improves existing ESC methods, generating more effective supportive responses.},
  archive      = {J_MIS},
  author       = {Geng Tu and Taiyu Niu and Ruifeng Xu and Bin Liang and Erik Cambria},
  doi          = {10.1109/MIS.2024.3411369},
  journal      = {IEEE Intelligent Systems},
  month        = {7-8},
  number       = {4},
  pages        = {5-11},
  shortjournal = {IEEE Intell. Syst.},
  title        = {AdaCLF: An adaptive curriculum learning framework for emotional support conversation},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A comparison of numeric assessments of ideas from two large
language models: With implications for validating and choosing LLMs.
<em>MIS</em>, <em>39</em>(3), 73–76. (<a
href="https://doi.org/10.1109/MIS.2024.3396371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article compares numeric assessments generated by ChatGPT and Claude along four dimensions of novelty, feasibility, impact, and disruption, to study their ability to rate ideas. We find that those chatbots make numeric assessments that are consistent with the expected relationships between those dimensions, for example, novelty is negatively correlated with feasibility. We also find that the two chatbots make statistically significantly different numeric assessments of the same idea information. We suggest that this type of analysis can also be used to provide a type of validation of underlying chatbot capabilities. In addition, we suggest that, as part of their chatbot requirements analysis, enterprises use this approach to ensure that the chatbot appropriately “understands” concepts, in which they are directly interested.},
  archive      = {J_MIS},
  author       = {Daniel E. O’Leary},
  doi          = {10.1109/MIS.2024.3396371},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {73-76},
  shortjournal = {IEEE Intell. Syst.},
  title        = {A comparison of numeric assessments of ideas from two large language models: With implications for validating and choosing LLMs},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model predictive control-based value estimation for
efficient reinforcement learning. <em>MIS</em>, <em>39</em>(3), 63–72.
(<a href="https://doi.org/10.1109/MIS.2024.3386204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) suffers from limitations in real practices primarily due to the number of required interactions with virtual environments. It results in a challenging problem because we are implausible to obtain a local optimal strategy with only a few attempts for many learning methods. Hereby, we design an improved RL method based on model predictive control that models the environment through a data-driven approach. Based on the learned environment model, it performs multistep prediction to estimate the value function and optimize the policy. The method demonstrates higher learning efficiency, faster convergent speed of strategies tending to the local optimal value, and less sample capacity space required by experience replay buffers. Experimental results, both in classic databases and in a dynamic obstacle-avoidance scenario for an unmanned aerial vehicle, validate the proposed approaches.},
  archive      = {J_MIS},
  author       = {Qizhen Wu and Kexin Liu and Lei Chen},
  doi          = {10.1109/MIS.2024.3386204},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {63-72},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Model predictive control-based value estimation for efficient reinforcement learning},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A text-enhanced transformer fusion network for multimodal
knowledge graph completion. <em>MIS</em>, <em>39</em>(3), 54–62. (<a
href="https://doi.org/10.1109/MIS.2024.3378921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal knowledge graphs (MKGs) organize multimodal facts in the form of entities and relations, and have been successfully applied to several downstream tasks. As most MKGs are incomplete, the MKG completion task has been proposed to address this problem, which aims to complete missing entities in MKGs. Most of the previous works obtain reasoning ability by capturing the correlation between target triplets and related images, but they ignore contextual semantic information and the reasoning process is not easily explainable. To address these issues, we propose a novel text-enhanced transformer fusion network, which converts the context path between head and tail entities into natural language text and fuses multimodal features from both coarse and fine granularities through a multigranularity fuser. It not only effectively enhances text semantic information but also improves the interpretability of the model by introducing paths. Experimental results on benchmark datasets demonstrate the effectiveness of our model.},
  archive      = {J_MIS},
  author       = {Jingchao Wang and Xiao Liu and Weimin Li and Fangfang Liu and Xing Wu and Qun Jin},
  doi          = {10.1109/MIS.2024.3378921},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {54-62},
  shortjournal = {IEEE Intell. Syst.},
  title        = {A text-enhanced transformer fusion network for multimodal knowledge graph completion},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SHAPAttack: Shapley-guided multigranularity adversarial
attack against text transformers. <em>MIS</em>, <em>39</em>(3), 45–53.
(<a href="https://doi.org/10.1109/MIS.2024.3379377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the great success of text transformers, recent studies have revealed their vulnerability to textual adversarial attacks. Existing attack methods are limited to a single granularity and often suffer from a low attack success rate and a high query cost. To mitigate these issues, we propose a Shapley-guided multigranularity adversarial attack (SHAPAttack) that generates adversarial examples (AEs). SHAPAttack expands the perturbation space by combining granularities at both the word and phrase levels, which enhances the diversity of the generated AEs. To improve attack efficiency and reduce the query cost, SHAPAttack adopts a query-free constituent importance ranking method guided by the Shapley value to measure the importance of each constituent. We conduct extensive experiments on three benchmark datasets across three text transformers. The experimental results demonstrate that SHAPAttack outperforms strong baselines in terms of both attack success rate and model queries, indicating the effectiveness and efficiency of the proposed method.},
  archive      = {J_MIS},
  author       = {Jiahui Shi and Linjing Li and Daniel Zeng},
  doi          = {10.1109/MIS.2024.3379377},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {45-53},
  shortjournal = {IEEE Intell. Syst.},
  title        = {SHAPAttack: Shapley-guided multigranularity adversarial attack against text transformers},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detect2Interact: Localizing object key field in visual
question answering with LLMs. <em>MIS</em>, <em>39</em>(3), 35–44. (<a
href="https://doi.org/10.1109/MIS.2024.3384513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization plays a crucial role in enhancing the practicality and precision of visual question answering (VQA) systems. By enabling fine-grained identification and interaction with specific parts of an object, it significantly improves the system’s ability to provide contextually relevant and spatially accurate responses. In this article, we introduce “Detect2Interact,” which addresses the challenges in accurately mapping objects within images to generate nuanced and spatially aware responses by introducing an advanced approach for fine-grained object visual key field detection. First, we use the segment anything model to generate detailed spatial maps of objects in images. Next, we use Vision Studio to extract semantic object descriptions. Third, we employ GPT-4’s commonsense knowledge. As a result, Detect2Interact achieves consistent qualitative results on object key field detection across extensive test cases and outperforms the existing VQA system with object detection by providing a more reasonable and finer visual representation.},
  archive      = {J_MIS},
  author       = {Jialou Wang and Manli Zhu and Yulei Li and Honglei Li and Longzhi Yang and Wai Lok Woo},
  doi          = {10.1109/MIS.2024.3384513},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {35-44},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Detect2Interact: Localizing object key field in visual question answering with LLMs},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Are learnable prompts the right way of prompting? Adapting
vision-and-language models with memory optimization. <em>MIS</em>,
<em>39</em>(3), 26–34. (<a
href="https://doi.org/10.1109/MIS.2024.3386099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning (FSL) requires fine-tuning a pretrained model on a limited set of examples from novel classes. When applied to vision-and-language models, the dominant approach for FSL has been that of learning input prompts which can be concatenated to the input context of the model. Despite the considerable promise they hold, the effectiveness and expressive power of prompts are limited by the fact that they can only lie at the input of the architecture. In this article, we critically question the usage of learnable prompts, and instead leverage the concept of “implicit memory” to directly capture low- and high-level relationships within the attention mechanism at any layer of the architecture, thereby establishing an alternative to prompts in FSL. Our proposed approach, termed MemOp, exhibits superior performance across 11 widely recognized image classification datasets and a benchmark for contextual domain shift evaluation, effectively addressing the challenges associated with learnable prompts.},
  archive      = {J_MIS},
  author       = {Nicholas Moratelli and Manuele Barraco and Marcella Cornia and Lorenzo Baraldi and Rita Cucchiara},
  doi          = {10.1109/MIS.2024.3386099},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {26-34},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Are learnable prompts the right way of prompting? adapting vision-and-language models with memory optimization},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Foundation models for education: Promises and prospects.
<em>MIS</em>, <em>39</em>(3), 20–24. (<a
href="https://doi.org/10.1109/MIS.2024.3398191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of foundation models like ChatGPT, educators are excited about the transformative role that artificial intelligence (AI) might play in propelling the next education revolution. The developing speed and the profound impact of foundation models in various industries force us to think deeply about the changes they will make to education, a domain that is critically important for the future of humans. In this article, we discuss the strengths of foundation models, such as personalized learning, education inequality, and reasoning capabilities, as well as the development of agent architecture tailored for education, which integrates AI agents with pedagogical frameworks to create adaptive learning environments. Furthermore, we highlight the risks and opportunities of AI overreliance and creativity. Finally, we envision a future where foundation models in education harmonize human and AI capabilities, fostering a dynamic, inclusive, and adaptive educational ecosystem.},
  archive      = {J_MIS},
  author       = {Tianlong Xu and Richard Tong and Jing Liang and Xing Fan and Haoyang Li and Qingsong Wen},
  doi          = {10.1109/MIS.2024.3398191},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {20-24},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Foundation models for education: Promises and prospects},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causal neurosymbolic AI: A synergy between causality and
neurosymbolic methods. <em>MIS</em>, <em>39</em>(3), 13–19. (<a
href="https://doi.org/10.1109/MIS.2024.3395936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal neurosymbolic AI (NeSyAI) combines the benefits of causality with NeSyAI. More specifically, it 1) enriches NeSyAI systems with explicit representations of causality, 2) integrates causal knowledge with domain knowledge, and 3) enables the use of NeSyAI techniques for causal AI tasks. The explicit causal representation yields insights that predictive models may fail to analyze from observational data. It can also assist people in decision-making scenarios where discerning the cause of an outcome is necessary to choose among various interventions.},
  archive      = {J_MIS},
  author       = {Utkarshani Jaimini and Cory Henson and Amit Sheth},
  doi          = {10.1109/MIS.2024.3395936},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {13-19},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Causal neurosymbolic AI: A synergy between causality and neurosymbolic methods},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward responsible recommender systems. <em>MIS</em>,
<em>39</em>(3), 5–12. (<a
href="https://doi.org/10.1109/MIS.2024.3398190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have transformed our digital experiences in many regards. We enumerate six of their positive effects on the economy and humans, such as greater user satisfaction, time savings, broadening user horizons, and positive behavioral nudging. However, it is crucial to acknowledge the potential downsides inherent in their design. One significant concern is that these algorithms often prioritize the interests of the company deploying them, aiming to maximize profits and user engagement rather than solely focusing on enhancing user experience. Therefore, we also list and consider two use cases and six negative long-term impacts on humans, including addiction, reduced ability to think critically, less autonomy, and weakened human relationships caused by more and more human-like virtual assistants. Despite the undeniable utility of recommender systems, it is imperative to approach them critically, advocating for transparency, ethical considerations, and user empowerment to ensure that they serve as tools for enrichment rather than exploitation. To accomplish this, the idea and challenges of responsible recommender systems (RRSs) are presented. RRSs extend common recommender systems with components related to individual human values and goals as well as widely accepted well-being and lifestyle guidelines.},
  archive      = {J_MIS},
  author       = {Przemysław Kazienko and Erik Cambria},
  doi          = {10.1109/MIS.2024.3398190},
  journal      = {IEEE Intelligent Systems},
  month        = {5-6},
  number       = {3},
  pages        = {5-12},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Toward responsible recommender systems},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). Large language models and applications: The rebirth of
enterprise knowledge management and the rise of prompt libraries.
<em>MIS</em>, <em>39</em>(2), 72–75. (<a
href="https://doi.org/10.1109/MIS.2024.3366648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates how large language systems and the apps developed for them provide a platform for enterprise knowledge management. For those resulting systems to provide consistent and accurate responses for knowledge management, enterprises are using different approaches in their prompts, such as few-shot learning, specification of purpose, and chain-of-thought reasoning. As better and more successful prompts are being built, they are being captured and prompt libraries are being created.},
  archive      = {J_MIS},
  author       = {Daniel E. O’Leary},
  doi          = {10.1109/MIS.2024.3366648},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {72-75},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Large language models and applications: The rebirth of enterprise knowledge management and the rise of prompt libraries},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Grounding from an AI and cognitive science lens.
<em>MIS</em>, <em>39</em>(2), 66–71. (<a
href="https://doi.org/10.1109/MIS.2024.3366669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grounding is a challenging problem, requiring a formal definition and different levels of abstraction. This article explores grounding from both cognitive science and machine learning perspectives. It identifies the subtleties of grounding, its significance for collaborative agents, and similarities and differences in grounding approaches in both communities. The article examines the potential of neurosymbolic approaches tailored for grounding tasks, showcasing how they can more comprehensively address grounding. Finally, we discuss areas for further exploration and development in grounding.},
  archive      = {J_MIS},
  author       = {Goonmeet Bajaj and Valerie L. Shalin and Srinivasan Parthasarathy and Amit Sheth},
  doi          = {10.1109/MIS.2024.3366669},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {66-71},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Grounding from an AI and cognitive science lens},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Group behavior prediction and evolution in social networks.
<em>MIS</em>, <em>39</em>(2), 62–65. (<a
href="https://doi.org/10.1109/MIS.2024.3366668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group behavior prediction and evolution in social networks aims to accurately predict and model trends and patterns of group behavior through detailed analysis of massive user data, which is of great significance to the formulation of marketing strategies, user experience, and business strategies. Therefore, experts in various fields are actively exploring the potential of social network data to develop more accurate group behavior prediction and evolution models. This article provides an overview of these studies and explores the challenges and opportunities faced by group behavior prediction and evolution in social networks.},
  archive      = {J_MIS},
  author       = {Jingchao Wang and Xinyi Zhang and Weimin Li and Xiao Yu and Fangfang Liu and Qun Jin},
  doi          = {10.1109/MIS.2024.3366668},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {62-65},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Group behavior prediction and evolution in social networks},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overcoming the challenges of long-tail distribution in
nighttime vehicle detection. <em>MIS</em>, <em>39</em>(2), 51–60. (<a
href="https://doi.org/10.1109/MIS.2024.3350628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the basic task of an intelligent transportation system, nighttime vehicle detection is associated with many challenges. Existing methods usually ignore the significant challenges that arise from imbalanced class distribution among vehicles, which always leads to poor detection for vehicles that belong to tail classes. By analyzing the existing solutions for long-tail object detection and considering the complex and diverse characteristics of nighttime traffic scenarios, we propose an enhanced detection approach based on anomaly detection. In addition, to tackle disturbance from complex lights, we reconstruct the loss function for background proposals, thus allowing the detector to pay more attention to hard-classified proposals and learn to distinguish vehicle lights from disturbed light resources. Comprehensive experiments prove that, compared with generic approaches, our proposed method can effectively solve the problem of long-tail distribution in nighttime vehicle detection and improve robustness in complex environments.},
  archive      = {J_MIS},
  author       = {Houwang Zhang and Leanne Lai Hang Chan},
  doi          = {10.1109/MIS.2024.3350628},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {51-60},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Overcoming the challenges of long-tail distribution in nighttime vehicle detection},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reflecting on algorithmic bias with design fiction: The
MiniCoDe workshops. <em>MIS</em>, <em>39</em>(2), 40–50. (<a
href="https://doi.org/10.1109/MIS.2024.3352977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an increasingly complex everyday life, algorithms—often learned from data, i.e., machine learning (ML)—are used to make or assist with operational decisions. However, developers and designers usually are not entirely aware of how to reflect on social justice while designing ML algorithms and applications. Algorithmic social justice—i.e., designing algorithms including fairness, transparency, and accountability—aims at helping expose, counterbalance, and remedy bias and exclusion in future ML-based decision-making applications. How might we entice people to engage in more reflective practices that examine the ethical consequences of ML algorithmic bias in society? We developed and tested a design-fiction-driven methodology to enable multidisciplinary teams to perform intense, workshop-like gatherings to let potential ethical issues emerge and mitigate bias through a series of guided steps. With this contribution, we present an original and innovative use of design fiction as a method to reduce algorithmic bias in co-design activities.},
  archive      = {J_MIS},
  author       = {Tommaso Turchi and Alessio Malizia and Simone Borsci},
  doi          = {10.1109/MIS.2024.3352977},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {40-50},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Reflecting on algorithmic bias with design fiction: The MiniCoDe workshops},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mining the user’s personality with an attention-based label
prompt method. <em>MIS</em>, <em>39</em>(2), 31–39. (<a
href="https://doi.org/10.1109/MIS.2023.3320445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying personality traits from online posts is becoming a hot research topic and often plays an essential role in behavior analysis and recommender systems. Previous studies have adopted deep neural networks or pretrained language models to mine semantic information without considering the prompting role of personality labels and the connection between writing style and personality traits. This paper proposes an attention-based label-prompt method (ABLPM) to address the aforementioned challenges. The ABLPM utilizes label-prompt semantic learning to generate personality representations while integrating writing style into text semantics. Then, the style-enhanced attention mechanism further constructs the deep dynamic interaction among the personality label, text semantics, and writing style. Finally, multiple loss functions optimize the distribution of the generated personality representations. The experimental results with the MyPersonality and topic-oriented social media comment datasets demonstrate the efficacy of the proposed method.},
  archive      = {J_MIS},
  author       = {Liping Chen and Yilin Wu and Qiudan Li and Yuxuan Song and Chenyu Yuan and Daniel Zeng},
  doi          = {10.1109/MIS.2023.3320445},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {31-39},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Mining the user’s personality with an attention-based label prompt method},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From electroencephalogram data to brain networks:
Graph-learning-based brain disease diagnosis. <em>MIS</em>,
<em>39</em>(2), 21–29. (<a
href="https://doi.org/10.1109/MIS.2024.3352972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain networks are built according to the structures or neural activities of different brain regions, which can be modeled as complex networks. Many studies exploit brains from the perspective of graph learning to diagnose the nerve diseases of brains. However, many of these algorithms are unable to automatically construct brain function topology based on electroencephalogram (EEG) and fail to capture the global features of multichannel EEG signals for whole-graph embedding. To address these challenging issues, we propose an attention-based whole-graph learning model for the diagnosis of brain diseases, namely, MAINS, which can adaptively construct brain functional topology from EEG signals and effectively embed multiple node features and the global structural features of brain networks into the whole-graph representations. We validated the model by conducting classification (diagnosis) experiments on real EEG datasets. Comprehensive experimental results demonstrate the superiority of the proposed approach over state-of-the-art methods.},
  archive      = {J_MIS},
  author       = {Ke Sun and Ciyuan Peng and Shuo Yu and Zhuoyang Han and Feng Xia},
  doi          = {10.1109/MIS.2024.3352972},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {21-29},
  shortjournal = {IEEE Intell. Syst.},
  title        = {From electroencephalogram data to brain networks: Graph-learning-based brain disease diagnosis},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiagent cooperative search learning with intermittent
communication. <em>MIS</em>, <em>39</em>(2), 11–20. (<a
href="https://doi.org/10.1109/MIS.2024.3350530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication plays a crucial role in coordinating the behavior of multiple agents. However, unstable communication connections in complex environments may lead to intermittent communication, information delays, and control strategy failures. This study proposes the multiagent cooperative search learning (MACSL) algorithm to achieve efficient search tracking in dynamic, partially observable environments with intermittent communication. First, to enhance the search efficiency when global communication links are unreachable, we propose a cooperative search strategy based on reinforcement learning from the perspective of teammate strategy learning. By designing an environment-aware map to guide agent exploration and learning, an effective distributed coverage search is realized. Second, to mitigate the impact of communication interruptions on shared information loss, we investigate target information prediction based on a recurrent neural network. The update rule of the target probability map and the cooperative model are optimized. Experimental results validate the effectiveness of the MACSL algorithm for cooperative search with intermittent communication.},
  archive      = {J_MIS},
  author       = {Ruixue Zhang and Jiao Wang and Jun Ge and Qiyuan Huang},
  doi          = {10.1109/MIS.2024.3350530},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {11-20},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Multiagent cooperative search learning with intermittent communication},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Can generative AI models extract deeper sentiments as
compared to traditional deep learning algorithms? <em>MIS</em>,
<em>39</em>(2), 5–10. (<a
href="https://doi.org/10.1109/MIS.2024.3374582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in the context of deep learning have led to the development of generative artificial intelligence (AI) models which have shown remarkable performance in complex language understanding tasks. This study proposes an evaluation of traditional deep learning algorithms and generative AI models for sentiment analysis. Experimental results show that RoBERTa outperforms all models, including ChatGPT and Bard, suggesting that generative AI models are not yet able to capture the nuances and subtleties of sentiment in text. We provide valuable insights into the strengths and weaknesses of different models for sentiment analysis and offer guidance for researchers and practitioners in selecting suitable models for their tasks.},
  archive      = {J_MIS},
  author       = {Mohammad Anas and Anam Saiyeda and Shahab Saquib Sohail and Erik Cambria and Amir Hussain},
  doi          = {10.1109/MIS.2024.3374582},
  journal      = {IEEE Intelligent Systems},
  month        = {3-4},
  number       = {2},
  pages        = {5-10},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Can generative AI models extract deeper sentiments as compared to traditional deep learning algorithms?},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating graphs with large language models: Methods and
prospects. <em>MIS</em>, <em>39</em>(1), 64–68. (<a
href="https://doi.org/10.1109/MIS.2023.3332242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) such as Generative Pre-trained Transformer 4 have emerged as frontrunners, showcasing unparalleled prowess in diverse applications including answering queries, code generation, and more. Parallelly, graph-structured data, intrinsic data types, are pervasive in real-world scenarios. Merging the capabilities of LLMs with graph-structured data has been a topic of keen interest. This article bifurcates such integrations into two predominant categories. The first leverages LLMs for graph learning, where LLMs can not only augment existing graph algorithms but also stand as prediction models for various graph tasks. Conversely, the second category underscores the pivotal role of graphs in advancing LLMs. Mirroring human cognition, we solve complex tasks by adopting graphs in either reasoning or collaboration. Integrating with such structures can significantly boost the performance of LLMs in various complicated tasks. We also discuss and propose open questions for integrating LLMs with graph-structured data for the future direction of the field.},
  archive      = {J_MIS},
  author       = {Shirui Pan and Yizhen Zheng and Yixin Liu},
  doi          = {10.1109/MIS.2023.3332242},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {64-68},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Integrating graphs with large language models: Methods and prospects},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024e). The rise and design of enterprise large language models.
<em>MIS</em>, <em>39</em>(1), 60–63. (<a
href="https://doi.org/10.1109/MIS.2023.3345591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates a new phenomenon of enterprise large language models (ELLMs) focusing on what they are, why they are being developed, and what are some key capabilities. In addition, the article drills down on issues associated with integrating retrieval augmented generation approaches into ELLMs, including emerging research issues.},
  archive      = {J_MIS},
  author       = {Daniel E. O’Leary},
  doi          = {10.1109/MIS.2023.3345591},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {60-63},
  shortjournal = {IEEE Intell. Syst.},
  title        = {The rise and design of enterprise large language models},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Embracing LLMs for point-of-interest recommendations.
<em>MIS</em>, <em>39</em>(1), 56–59. (<a
href="https://doi.org/10.1109/MIS.2023.3343489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A point-of-interest (POI) recommendation becomes the core function of location-based services. Unlike a traditional item recommendation, a POI recommendation has distinct features, such as geographical influences, complex mobility patterns, and a balance between local and global user preferences. Past POI recommendation system research has focused mainly on integrating deep learning models like convolutional neural networks, recurrent neural networks, and attention-based architectures, demonstrating their effectiveness in addressing the dynamic nature of spatial–temporal data in POI recommendation areas. In recent years, with the rise of large language models (LLMs), POI recommendation has produced a number of promising directions. This article first discusses the characteristics and state-of-the-art solutions of POI recommendation, then it introduces potential research directions by integrating the latest LLMs.},
  archive      = {J_MIS},
  author       = {Tianxing Wang and Can Wang},
  doi          = {10.1109/MIS.2023.3343489},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {56-59},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Embracing LLMs for point-of-interest recommendations},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UCRI: A unified conversational recommender system based on
item-guided conditional generation. <em>MIS</em>, <em>39</em>(1), 46–55.
(<a href="https://doi.org/10.1109/MIS.2023.3330367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, great efforts have been made to develop a conversational recommender system (CRS). However, existing works always ignore the incorporation of the recommended items and the generated replies. This causes the performance of the recommendation to degrade in the conversations. To solve this problem, we propose a novel framework called unified conversational recommender system based on item-guided conditional generation (UCRI) to fuse the recommender module and the dialogue module seamlessly. UCRI captures the semantic similarity between the recommended items and the candidate words to realize the item-guided conditional generation. Besides, we further design the weight control mechanism and the recommender gating mechanism to make accurate recommendations in the conversations. Our approach can explicitly generate the recommended items in the replies and encourage the model to generate the related context for the items. Extensive experiments on the benchmark dataset REcommendations through DIALog show that our model achieves the best performance on both item recommendation and reply generation tasks.},
  archive      = {J_MIS},
  author       = {Xi Chen and Yuehai Wang and Jianyi Yang},
  doi          = {10.1109/MIS.2023.3330367},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {46-55},
  shortjournal = {IEEE Intell. Syst.},
  title        = {UCRI: A unified conversational recommender system based on item-guided conditional generation},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrated circuit mask–generative adversarial network for
circuit annotation with targeted data augmentation. <em>MIS</em>,
<em>39</em>(1), 37–45. (<a
href="https://doi.org/10.1109/MIS.2023.3306599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep-learning-based segmentation techniques have been applied to circuit annotation for the hardware assurance of integrated circuits (ICs). However, imperfections in circuit images often cause incorrectly segmented pixels, which result in critical circuit connection errors that are detrimental to subsequent circuit analysis. To mitigate such circuit connection errors, this article proposes a targeted data augmentation framework for deep-learning-based circuit annotation, termed IC Mask–Generative Adversarial Network (ICMG), which generates circuit images containing the aforementioned imperfections through generative-adversarial-network-based image translation from synthetic circuit masks. The circuit masks are synthesized by a novel mask generation process that incorporates our domain knowledge of IC layouts and is configurable to emulate various image imperfections, such as material residuals in the sample preparation or distortion in the imaging process. In our experiments on a microcontroller IC, our proposed ICMG greatly reduced the circuit connection errors and the required manual effort for data labeling compared to the reported techniques.},
  archive      = {J_MIS},
  author       = {Yee-Yang Tee and Deruo Cheng and Yiqiong Shi and Tong Lin and Bah-Hwee Gwee},
  doi          = {10.1109/MIS.2023.3306599},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {37-45},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Integrated circuit Mask–Generative adversarial network for circuit annotation with targeted data augmentation},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven deepfake forensics model based on large-scale
frequency and noise features. <em>MIS</em>, <em>39</em>(1), 29–35. (<a
href="https://doi.org/10.1109/MIS.2022.3217391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of deep learning and communication technology, the application of streaming media services and social software have gone deep into life. However, in the face of many uncertain factors in data dissemination, protecting privacy and security is particularly important. In order to solve the abovementioned problems, this study proposes a deep face forgery forensics method with frequency domain and noise features. In this method, discrete cosine transform is proposed to perceive the forgery trace features of different frequency bands in the frequency domain. At the same time, the spatial rich model is used for guidance to enhance the traces of forged noise. Then, large-scale network and single center loss function are introduced to improve the forensics ability of the model. Experimental results on several databases such as faceforensics++, celeb DF, and DFDC show that this method can effectively improve the accuracy of forensics.},
  archive      = {J_MIS},
  author       = {Guipeng Lan and Shuai Xiao and Jiabao Wen and Desheng Chen and Yong Zhu},
  doi          = {10.1109/MIS.2022.3217391},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {29-35},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Data-driven deepfake forensics model based on large-scale frequency and noise features},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An operational framework for guiding human evaluation in
explainable and trustworthy artificial intelligence. <em>MIS</em>,
<em>39</em>(1), 18–28. (<a
href="https://doi.org/10.1109/MIS.2023.3334639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of explanations by humans presents a significant challenge within the context of explainable and trustworthy artificial intelligence. This is attributed not only to the absence of universal metrics and standardized evaluation methods but also to the complexities tied to devising user studies that assess the perceived human comprehensibility of these explanations. To address this gap, we introduce a survey-based methodology for guiding the human evaluation of explanations. This approach amalgamates leading practices from existing literature and is implemented as an operational framework. This framework assists researchers throughout the evaluation process, encompassing hypothesis formulation, online user study implementation and deployment, and analysis and interpretation of collected data. The application of this framework is exemplified through two practical user studies.},
  archive      = {J_MIS},
  author       = {Roberto Confalonieri and Jose Maria Alonso-Moral},
  doi          = {10.1109/MIS.2023.3334639},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {18-28},
  shortjournal = {IEEE Intell. Syst.},
  title        = {An operational framework for guiding human evaluation in explainable and trustworthy artificial intelligence},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Responsible AI: An urgent mandate. <em>MIS</em>,
<em>39</em>(1), 12–17. (<a
href="https://doi.org/10.1109/MIS.2023.3343488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI is rapidly becoming essential in various industries, raising societal expectations. AI’s societal consequences include impacts on mental health; misinformation; workforce displacement; and economic, regulatory, and law enforcement challenges. Indeed, the regulation of AI usage is on the horizon, with the European Union and China already taking big steps, while the United States drafted its first AI-related bill of rights last year. Professional associations and other nonprofits are also contributing to AI ethics and regulations, increasing the urgency and criticality of this area. In this new context, public services and regulated institutions must ensure responsible AI to avoid biased or inaccurate decision-making. Similarly, companies using AI responsibly can stand out, increase efficiency, and avoid future legal problems. This article highlights the issues and problems that result in many organizations not knowing how to do responsible AI in practice, as they need to identify potential problems, set up safeguards, and conduct ethical impact assessments, among other actions. We present the issues to consider toward a comprehensive approach to responsible AI that should include defining a responsible AI strategy road map; assessing models, processes, and products; and training individuals at different levels. By covering the pressing issues related to the urgent need for adopting responsible AI, we hope to highlight the importance for corporations to seriously consider responsible AI as they rush to adopt this technology for competitive advantage.},
  archive      = {J_MIS},
  author       = {Ricardo Baeza-Yates and Usama M. Fayyad},
  doi          = {10.1109/MIS.2023.3343488},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {12-17},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Responsible AI: An urgent mandate},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neurosymbolic value-inspired artificial intelligence (why,
what, and how). <em>MIS</em>, <em>39</em>(1), 5–11. (<a
href="https://doi.org/10.1109/MIS.2023.3344353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid progression of artificial intelligence (AI) systems, facilitated by the advent of large language models (LLMs), has resulted in their widespread application to provide human assistance across diverse industries. This trend has sparked significant discourse centered around the ever-increasing need for LLM-based AI systems to function among humans as a part of human society. Toward this end, neurosymbolic AI systems are attractive because of their potential to enable and interpretable interfaces for facilitating value-based decision making by leveraging explicit representations of shared values. In this article, we introduce substantial extensions to Kahneman’s System 1 and System 2 framework and propose a neurosymbolic computational framework called value-inspired AI (VAI). It outlines the crucial components essential for the robust and practical implementation of VAI systems, representing and integrating various dimensions of human values. Finally, we further offer insights into the current progress made in this direction and outline potential future directions for the field.},
  archive      = {J_MIS},
  author       = {Amit Sheth and Kaushik Roy},
  doi          = {10.1109/MIS.2023.3344353},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {5-11},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Neurosymbolic value-inspired artificial intelligence (Why, what, and how)},
  volume       = {39},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
