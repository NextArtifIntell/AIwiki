<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aai---143">AAI - 143</h2>
<ul>
<li><details>
<summary>
(2024). A typical infrared background radiation prediction model
based on RF-VMD and optimized hybrid neural network. <em>AAI</em>,
<em>38</em>(1), Article: 2440835. (<a
href="https://doi.org/10.1080/08839514.2024.2440835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The short-term prediction and adjustment of a target’s infrared radiation hold significant value in military camouflage applications. Existing radiation prediction models generally require real-time environmental and meteorological data support, resulting in lag in active camouflage. To meet the demand for active camouflage of background infrared (IR) radiation, a short-term background IR radiation prediction method based on historical data is proposed. First, a random forest (RF) is used to filter the collected multidimensional meteorological parameters. Variational mode decomposition (VMD) is applied for time-frequency analysis on these parameters, optimizing them with Bayesian algorithms and decomposing them into multivariate intrinsic mode functions (IMFs) with similar frequencies to reduce the impact of nonlinearity in the data. Based on the superimposed IMFs as inputs, a hybrid deep neural network prediction model is established. The model optimizes the CNN-LSTM network with residual connections and introduces a multi-head self-attention mechanism to enhance spatiotemporal feature extraction of the multidimensional meteorological parameters, focusing on key temporal feature regions. According to the experimental results, the constructed model demonstrates high prediction accuracy and adaptability across different background environments, with a low parameter count and fast prediction capability, meeting the practical application needs for various complex backgrounds.},
  archive      = {J_AAI},
  author       = {Bentian Hao and Weidong Xu and Xin Yang and Feifei Xiao and Hao Li and Wei Huang},
  doi          = {10.1080/08839514.2024.2440835},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2440835},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A typical infrared background radiation prediction model based on RF-VMD and optimized hybrid neural network},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human-artificial intelligence in management functions: A
synergistic symbiosis relationship. <em>AAI</em>, <em>38</em>(1),
Article: 2439615. (<a
href="https://doi.org/10.1080/08839514.2024.2439615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review paper aims to investigate how the mutual interaction of artificial intelligence (AI) and human intelligence (HI) affects management functions. To achieve this, we use a question-based approach and a systematic literature review to elucidate the potential for AI and HI to interact and create a mutually beneficial symbiotic effect in management functions. We underscore the main issues that organizations must consider when transitioning to AI management. Specifically, in this review paper, we highlight the interaction between AI and HI; the investigation of this relationship in management functions such as planning and decision-making, organizing, leading, and controlling; the mutually beneficial impact of this symbiotic relationship in management; and possible ethical dilemmas. The paper concludes by identifying gaps in the existing literature, providing practical advice on integrating AI into various management functions, and exploring approaches that highlight specific areas requiring attention in future research.},
  archive      = {J_AAI},
  author       = {Xhavit Islami and Enis Mulolli},
  doi          = {10.1080/08839514.2024.2439615},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2439615},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Human-artificial intelligence in management functions: A synergistic symbiosis relationship},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing the recognition of collinear building patterns by
shape cognition based on graph neural networks. <em>AAI</em>,
<em>38</em>(1), Article: 2439611. (<a
href="https://doi.org/10.1080/08839514.2024.2439611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building patterns are important components of urban structures and functions, and their accurate recognition is the foundation of urban spatial analysis, cartographic generalization, and other tasks. Current building pattern recognition methods are often based on a shape index that can only characterize shape features from one aspect, resulting in significant errors. In this study, a building pattern recognition method based on a graph neural network is proposed to enhance shape cognition and focus on recognizing collinear patterns. First, a building shape classification model that integrates global shape and graph node structure features was constructed to quantitatively study shape cognition. Subsequently, a collinear pattern recognition (CPR) model was established based on a dual building graph. The shape cognition results were integrated into the model to enhance its recognition ability. The results show that the shape classification model can be used to effectively distinguish different shape categories and support building pattern recognition tasks. Based on the CPR model, false recognitions can be avoided, and recognition results similar to those of visual cognition can be obtained. Compared with the comparative methods, both models have significant advantages in terms of statistical results and implementation.},
  archive      = {J_AAI},
  author       = {Fubing Zhang and Qun Sun and Wenjun Huang and Youneng Su and Jingzhen Ma and Ruixing Xing},
  doi          = {10.1080/08839514.2024.2439611},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2439611},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Enhancing the recognition of collinear building patterns by shape cognition based on graph neural networks},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence in cybersecurity: A comprehensive
review and future direction. <em>AAI</em>, <em>38</em>(1), Article:
2439609. (<a
href="https://doi.org/10.1080/08839514.2024.2439609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As cybercrimes are becoming increasingly complex, it is imperative for cybersecurity measures to become more robust and sophisticated. The crux lies in extracting patterns or insights from cybersecurity data to build data-driven models, thus making the security systems automated and intelligent. To comprehend and analyze cybersecurity data, several Artificial Intelligence (AI) methods such as Machine Learning (ML) techniques, are employed to monitor network environments and actively combat cyber threats. This study explored the various AI techniques and how they are applied in cybersecurity. A comprehensive literature review was conducted, including a bibliometric analysis and systematic literature review following the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Using data extracted from two main scholarly databases: Clarivate’s Web of Science (WoS) and Scopus, this article examines relevant academic literature to understand the diverse ways in which AI techniques are employed to strengthen cybersecurity measures. These applications range from anomaly detection and threat identification to predictive analytics and automated incident response. A total of 14,509 peer-reviewed research papers were identified of which 9611 were from the Scopus database and 4898 from the WoS database. These research papers were further filtered, and a total of 939 relevant papers were eventually selected and used. The review offers insights into the effectiveness, challenges, and emerging trends in utilizing AI for cybersecurity purposes.},
  archive      = {J_AAI},
  author       = {Lizzy Ofusori and Tebogo Bokaba and Siyabonga Mhlongo},
  doi          = {10.1080/08839514.2024.2439609},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2439609},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Artificial intelligence in cybersecurity: A comprehensive review and future direction},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IHML: Incremental heuristic meta-learner. <em>AAI</em>,
<em>38</em>(1), Article: 2434309. (<a
href="https://doi.org/10.1080/08839514.2024.2434309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The landscape of machine learning constantly demands innovative approaches to enhance algorithms’ performance across diverse tasks. Meta-learning, known as “learning to learn” is a promising way to overcome these diversity challenges by blending multiple algorithms. This study introduces the IHML: Incremental Heuristic Meta-Learner, a novel meta-learning algorithm for classification tasks. By leveraging a variety of base-learners with distinct learning dynamics, such as Gaussian, tree, and instance, IHML offers a comprehensive solution adaptable to different data characteristics. Moreover, the core contributions of IHML lie in its ability to tackle the optimal base-learner and feature sets determination mechanism with the help of Explainable Artificial Intelligence (XAI) and heuristic elbow methods. Existing work in this context utilizes XAI mostly in pre-processing the data or post-analysis of the results, however, IHML incorporates XAI into the learning process in an iterative manner and improves the prediction performance of the meta-learner. To observe the performance of the proposed IHML, we used five different datasets from astrophysics, physics, biology, e-commerce, and economics. The results show that the proposed model achieves more accuracy (in average % 10 and at most % 71 improvements) compared to the baseline machine learning models in the literature.},
  archive      = {J_AAI},
  author       = {Onur Karadeli and Kıymet Kaya and Şule Gündüz Öğüdücü},
  doi          = {10.1080/08839514.2024.2434309},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2434309},
  shortjournal = {Appl. Artif. Intell.},
  title        = {IHML: Incremental heuristic meta-learner},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Text-to-text transfer transformer based method for
generating startup scenarios for new equipment in power grids.
<em>AAI</em>, <em>38</em>(1), Article: 2434301. (<a
href="https://doi.org/10.1080/08839514.2024.2434301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power grids often develop specialized startup plans for new equipment to standardize the commissioning process, which presents distinct challenges compared to other types of startup plans. Rule-based generation methods have limited transferability, making it difficult to adapt to the rapid evolution of power grid infrastructure. Current deep learning-based generation methods are primarily improvements on rule-based approaches, but they are still constrained by those rules. This paper proposes a startup plan generation method for new power grid equipment based on the Text-to-Text Transfer Transformer (T5). The method leverages a T5 model pretrained on Chinese text and fine-tunes it using historical startup plans for new power grid equipment to generate applicable startup texts. Additionally, a dynamic loss adjustment strategy, based on professional terminology judgment, is introduced to address inconsistencies in professional terminology during the generation process. The Adam optimizer is used for backpropagation and parameter updates. The trained model generates startup plan texts for new equipment using a beam search decoding strategy. Tests and validations using real-world data from four types of new equipment startup plans demonstrate that this method can effectively generate startup plans, meeting the requirements of practical applications.},
  archive      = {J_AAI},
  author       = {Wenbiao Tao and Liang Wang and Qingmeng Meng and Rui Li and Peng Han and Yuxin Shi and Lianfei Shan and Xiaofei Geng},
  doi          = {10.1080/08839514.2024.2434301},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2434301},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Text-to-text transfer transformer based method for generating startup scenarios for new equipment in power grids},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge graphs to accumulate and convey knowledge from
past experiences in search and rescue planning and resource allocation.
<em>AAI</em>, <em>38</em>(1), Article: 2434296. (<a
href="https://doi.org/10.1080/08839514.2024.2434296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning and allocation of resources in search and rescue operations is critical and complex. Those tasks require consideration of several factors such as the nature of the emergency, location, people involved, and weather conditions. In this paper, we investigate the specific requirements for effective decision-making and planning in search and rescue operations in Norway. These requirements were determined using data gathered through expert interviews and analysis of mission reports. We propose a framework designed for search and rescue decision support, including its architecture and components. We also discuss the implementation of the service layer. We used information retrieval methods, i.e. BM25 and TF-IDF, for distance computation and compared their performance using k-means and hierarchical agglomerative clustering methods. The evaluation through silhouette score and Davies-Bouldin score shows that the hierarchical agglomerative clustering using BM25 performs well for the given dataset. The search and rescue mission reports published by the Norwegian Safety Authority were used as a dataset. In addition, the overall framework is evaluated by the domain experts using qualitative analysis. Finally, we discuss potential framework implementation challenges and provide suggestions for future research directions, in addition to presenting insights from the framework design process.},
  archive      = {J_AAI},
  author       = {Wajeeha Nasar and Odd Erik Gundersen and Ricardo da Silva Torres and Anniken Karlsen},
  doi          = {10.1080/08839514.2024.2434296},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2434296},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Knowledge graphs to accumulate and convey knowledge from past experiences in search and rescue planning and resource allocation},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-world efficacy of explainable artificial intelligence
using the SAGE framework and scenario-based design. <em>AAI</em>,
<em>38</em>(1), Article: 2430867. (<a
href="https://doi.org/10.1080/08839514.2024.2430867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper demonstrates a design and evaluation approach for delivering real world efficacy of an explainable artificial intelligence (XAI) model. The first of its kind, it leverages three distinct but complementary frameworks to support a user-centric and context-sensitive, post-hoc explanation for fraud detection. Using the principles of scenario-based design, it amalgamates two independent real-world sources to establish a realistic card fraud prediction scenario. The SAGE (Settings, Audience, Goals and Ethics) framework is then used to identify key context-sensitive criteria for model selection and refinement. The application of SAGE reveals gaps in the current XAI model design and provides opportunities for further model development. The paper then employs a functionally-grounded evaluation method to assess its effectiveness. The resulting explanation represents real-world requirements more accurately than established models.},
  archive      = {J_AAI},
  author       = {Eleanor Mill and Wolfgang Garn and Chris Turner},
  doi          = {10.1080/08839514.2024.2430867},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2430867},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Real-world efficacy of explainable artificial intelligence using the SAGE framework and scenario-based design},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-source domain adaptation using ambient sensor data.
<em>AAI</em>, <em>38</em>(1), Article: 2429321. (<a
href="https://doi.org/10.1080/08839514.2024.2429321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart buildings have gained increasing interest recently by providing several advanced solutions, especially AI-based solutions. Activity recognition and occupancy estimation are among the outcomes of smart buildings that can help provide several advantages such as energy management and security solutions. Previously, domain adaptation (DA) has been widely considered by researchers to transfer knowledge from source domains, where we have abundant labeled data, to a target domain where labeled data is scarce. It is a tedious and time-consuming task to label data, especially with smart building applications which is why researchers have considered unsupervised DA where we do have labeled data in the source domain and unlabeled data in the target domain. Semi-supervised DA (SSDA) adaptation has also been considered by researchers where we have a small amount of labeled data in the target domain. Most unsupervised DA (UDA) and SSDA methods transfer knowledge from one source to one target. However, it is possible to exploit knowledge from multiple source domains instead of one single domain to enhance the performance of the target domain. Multi-source DA (MSDA) is more difficult than single-source DA but also it is more efficient. In this research, we adapt several MDSA methods and evaluate them using sensorial datasets.},
  archive      = {J_AAI},
  author       = {Jawher Dridi and Manar Amayri and Nizar Bouguila},
  doi          = {10.1080/08839514.2024.2429321},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2429321},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Multi-source domain adaptation using ambient sensor data},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing financial forecasts: Stock price prediction based
on time series and machine learning techniques. <em>AAI</em>,
<em>38</em>(1), Article: 2429188. (<a
href="https://doi.org/10.1080/08839514.2024.2429188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the beginning of stock trading, investors and researchers have tried to find effective ways to predict the direction of stock prices on the next day. However, predicting stock prices is a hard task because there exist many factors that may affect the next day’s stock prices. Recently, investors and researchers have adopted machine learning techniques with technical indicator analysis to make prediction. But the prediction accuracy is unsatisfactory. Thus, this study aims to examine the problem of stock price prediction with time series and proposes an effective way to filter out the datasets, which consists of three key steps: First, a time series model with long-short-term memory (LSTM) was used to identify the possible problems and solve them in the process of stock price prediction. Second, the results of LSTM were adopted to influence the stock trend prediction by a variety of machine learning techniques, including random forest, support vector machine, light gradient boosting machine (LightGBM). Third, a novel method was proposed to select suitable datasets through buying or selling. Hereby, FTSE TWSE Taiwan 50 Index stocks were used as training and testing datasets, respectively. Some important days were selected for prediction and decision making. The experimental results show that the highest prediction accuracy of 86% and the average prediction accuracy of 82% have been obtained. Consequently, when comparing to other existing methods, the accuracy of predicting stock price trend with our proposed approach has been significantly improved. Reference No .: 2024-UAAI-0010R1/243667820 Subject Area : Intelligent Investment System},
  archive      = {J_AAI},
  author       = {Cheng-Ying Yang and Min-Shiang Hwang and Yu-Wei Tseng and Chou-Chen Yang and Victor R. L. Shen},
  doi          = {10.1080/08839514.2024.2429188},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2429188},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Advancing financial forecasts: Stock price prediction based on time series and machine learning techniques},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Save a life maps-traffic clearance system for emergency
services. <em>AAI</em>, <em>38</em>(1), Article: 2429185. (<a
href="https://doi.org/10.1080/08839514.2024.2429185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Save a Life (SAL) Maps addresses the challenge of traffic congestion affecting emergency services and provides swift response during life-critical situations. A path clearance algorithm is integrated into an application, which identifies the most optimal routes enabling emergency services to navigate efficiently. The algorithm incorporates a mechanism that uses micro services to facilitate path clearance for emergency services, provide fastest routes, assist general public in accessing emergency services, and notify the traffic police during high traffic congestion to assist by manually clearing out the path. Docker is employed to containerize the micro services, allowing for efficient deployment and management on the Google Kubernetes Engine platform. This micro services-based algorithm achieves enhanced efficiency, optimal resource utilization, real-time decision-making, scalability, adaptability and offers a reliable solution which highlight the importance of adopting path clearance algorithms and micro services architecture for ambulances enabling a more agile and responsive system.},
  archive      = {J_AAI},
  author       = {Anusha Chaturvedi and J R Shruti and Himanshu Behl and Anushka Mittal and Ankita M Thakur and Sanjay Ha},
  doi          = {10.1080/08839514.2024.2429185},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2429185},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Save a life maps-traffic clearance system for emergency services},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Crime type identification using high-order deep residual
network with multiple attention algorithm. <em>AAI</em>, <em>38</em>(1),
Article: 2428552. (<a
href="https://doi.org/10.1080/08839514.2024.2428552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crime type identification is crucial for improving public safety through more accurate prevention and efficient responses. However, practical applications often suffer from a significant lack of effective samples features, making it difficult to focus on the most informative aspects during identification. This study addresses these challenges by proposing a novel crime type identification method that leverages a deep neural network enhanced with multiple attention mechanisms. The approach includes a tailored data processing method involving target encoding to convert categorical data into numerical form, L 2 normalizer to standardize data and ensure balanced feature contribution, and variance threshold feature selection to remove low-variance features. Additionally, a High-Order Deep Residual Network with Multiple Attention (HO-ResNet-MA) is developed, featuring an optimized Huta68 block (Huta-6(8)-MA ResBlock) with an enhanced Contextual Transformer (CoT) unit for local attention and a queue-and-exclusion layer for global attention. To validate the effectiveness of the proposed method, homicide reports data and Chicago crimes data are processed and fed into the crime type identification model, resulting in accuracies of over 84.1% and 99.5%, respectively. This study makes contributions to the field of crime analysis by validating the practical applicability of these approaches, and enhancing the efficiency of public safety workers.},
  archive      = {J_AAI},
  author       = {Dawei Qiu and Chang Liu and Yuangfeng Shang and Zixu Zhao and Jinlin Shi},
  doi          = {10.1080/08839514.2024.2428552},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2428552},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Crime type identification using high-order deep residual network with multiple attention algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new classification model using a decision tree generated
from hyperplanes in dimensional space. <em>AAI</em>, <em>38</em>(1),
Article: 2426377. (<a
href="https://doi.org/10.1080/08839514.2024.2426377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the issues addressed by machine learning, with applications in various disciplines or fields such as the health sector and the agricultural sector among others, involves data classification. For this purpose, various models within supervised learning have been proposed and developed that allow for the classification of these data. However, one of the implications of the No-Free-Lunch theorems is that there is no optimal general-purpose model, i.e. there is no classifier model that achieves the best results for all problems presented. Hence the importance of proposing and implementing new classifier models, evaluating their performance, and comparing them with other classifier models in order to achieve models with good results in specific problems. This work presents a new classifier model that, by constructing hyperplanes from the training set, generates a decision tree and partitions the dimensional space. The proposed model was applied to different problems such as the XOR logical function problem, where the proposed model managed to solve the problem, it was also applied to the Iris Dataset where one of the trees generated by the model managed to classify with 100% accuracy the test set, and finally, the proposed model was applied to the Pima Indians Diabetes Database and compared with other models using the accuracy value. The proposed model obtained an accuracy of 81.81%, achieving the best result in the same way as the Random Forest Classifier. The results obtained in this work show that the proposed model manages to partition the dimensional space adequately from the training set and thus competitively classify the data with other state-of-the-art models.},
  archive      = {J_AAI},
  author       = {Benjamín Luna-Benoso and José Cruz Martínez-Perales and Úrsula Samantha Morales-Rodríguez and Rolando Flores-Carapia and Víctor Manuel Silva-García},
  doi          = {10.1080/08839514.2024.2426377},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2426377},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A new classification model using a decision tree generated from hyperplanes in dimensional space},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards explainable machine learning for prediction of
disease progression. <em>AAI</em>, <em>38</em>(1), Article: 2423510. (<a
href="https://doi.org/10.1080/08839514.2024.2423510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on addressing the challenges surrounding interpretability of machine learning techniques in the field of prediction of disease progression. This paper summarizes the state-of-the-art in machine learning for disease progression modeling and challenges related to this context. Based on this state-of-the-art, we design and develop a pipeline consisting of data preparation, prediction, and explanation. Predictions are made using a deep recurrent neural network-based model which is followed by an integration of the LIME framework to provide explanations for each prediction. We demonstrate our pipeline by applying it to two diverse case studies on diabetes and Parkinson’s disease. Besides this, we compare the influence of three data imputation methods on predictive performance. Results of the comparison show that there is no statistically significant difference in performance due to different data imputation techniques. Furthermore, we provide a number of concrete recommendations and directions for future research, such as improving input flexibility of the prediction model and improving the visualization of generated explanations. Based on the results of this research, we conclude that the proposed pipeline achieves the goal of integrating a state-of-the-art prediction model and the LIME framework to make prediction of disease progression more transparent and interpretable.},
  archive      = {J_AAI},
  author       = {Stijn Berendse and Johannes Krabbe and Jonas Klaus and Faizan Ahmed},
  doi          = {10.1080/08839514.2024.2423510},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2423510},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Towards explainable machine learning for prediction of disease progression},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Remote assistance for bone-fractured patients using deep
learning models. <em>AAI</em>, <em>38</em>(1), Article: 2423326. (<a
href="https://doi.org/10.1080/08839514.2024.2423326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote diagnosis enables healthcare professionals to evaluate and diagnose patients from a distance using telecommunication technologies, enhancing healthcare delivery by improving accessibility, especially for those in remote or underserved areas. One of the significant sustainability challenges in remote medical diagnostics is offering timely assistance to vulnerable groups like the elderly, disabled, mentally impaired individuals, and wounded military personnel in combat zones. This becomes particularly difficult in emergencies when rapid analysis of medical records is needed, especially if the data is stored on secure blockchain networks. The proposed work addresses these challenges by deploying a comprehensive framework for large-scale analysis, utilizing both document and image classification for dual validation. It integrates advanced techniques such as Inception V3, VGG-16, VGG-19, RESNET-50, and Densenet-201 for bone fracture detection, with Inception V3 achieving the highest accuracy of 95.1%. In addition, a Document Classification Analysis (DCA) method is proposed, which automatically classifies the severity of fractures. Object detection techniques are also introduced for detecting minor fractures using region-based image segmentation, ensuring precise diagnosis even for subtle injuries. This pioneering integration of technologies provides a holistic solution for remote medical diagnostics.},
  archive      = {J_AAI},
  author       = {Nallakaruppan Kailasanathan and Sivaramakrishnan Somayaji and Mohamed Baza and Gautam Srivastava and SenthilKumaran Ulaganathan and Gokul Yenduri and Vaishali Ravindranath and Maazen Alsabaan},
  doi          = {10.1080/08839514.2024.2423326},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2423326},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Remote assistance for bone-fractured patients using deep learning models},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent design method and system of tin spraying steel
mesh for complex combiner. <em>AAI</em>, <em>38</em>(1), Article:
2422647. (<a
href="https://doi.org/10.1080/08839514.2024.2422647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of spraying tin into the combiner cavity, employing the Tin Spraying Steel Mesh (TSSM) is crucial. This operation is akin to covering a complex, maze-like area with multiple islands and branches. Manual operation is labor-intensive, time-consuming, and challenging to ensure high-quality results. Therefore, this paper presents an intelligent design method and system for the TSSM, based on graphic processing. Initially, isolated islands are used as nodes to establish the topology structure of complex paths. Then, an improved Delaunay triangulation method is utilized to extract intermediate paths for regions with branching paths, resulting in the division into multiple single path regions. Following this, the island regions undergo equal arc length segmentation, while the single path regions are subjected to random bidirectional segmentation to obtain the final TSSM. Finally, a TSSM intelligent segmentation system is developed by seamlessly integrating this method into the AutoCAD software platform using ObjectARX technology. The TSSM obtained by this method meets the quality requirements, demonstrating consistent segmentation direction and uniform gaps. Furthermore, the system can adjust segmentation parameters to cater to different combiner specifications, thereby significantly improving design efficiency and establishing itself as an indispensable auxiliary tool in the automated design of combiners.},
  archive      = {J_AAI},
  author       = {Gui Li and Zixi Ding and Ming Luo},
  doi          = {10.1080/08839514.2024.2422647},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2422647},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Intelligent design method and system of tin spraying steel mesh for complex combiner},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maize hybrids performance evaluation with data fusion by
matrix factorization algorithm. <em>AAI</em>, <em>38</em>(1), Article:
2421687. (<a
href="https://doi.org/10.1080/08839514.2024.2421687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crop breeders often face challenges due to limited data availability when making crucial decisions, such as selecting top-performing varieties/hybrids for further experiments, registration, and commercialization. Evaluating all varieties/hybrids across all fields is impractical due to high experimental and time costs, as well as the limited number of locations for planting. This article aims to evaluate the performance of various maize hybrids in untested locations using historical data. The problem is approached through a matrix framework, where hybrids and fields correspond to rows and columns, respectively, with entries representing the yield of a specific hybrid at a given location. As this matrix is typically sparse, the task is to fill in missing data. Agronomists are primarily interested in the performance of top hybrids at specific locations for smart seed selection. To address this, we introduce a novel application of the Data Fusion by Matrix Factorization (DFMF) algorithm for predicting crop yields using maize data from the 2019 Syngenta Crop Challenge. The DFMF results are compared with the Random Forest (RF) algorithm as a benchmark, focusing on model performance for smart seed selection. Our analysis highlights the advantages of the DFMF approach over the traditional RF method in this context.},
  archive      = {J_AAI},
  author       = {Milica Brkić and Stefan Hačko and Miloš Radovanović and Vladimir Crnojević and Sanja Brdar},
  doi          = {10.1080/08839514.2024.2421687},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2421687},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Maize hybrids performance evaluation with data fusion by matrix factorization algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing multimodal emotional information extraction in
film and television through adaptive feature fusion with DenseNe,
transformer, and 3D CNN models. <em>AAI</em>, <em>38</em>(1), Article:
2419609. (<a
href="https://doi.org/10.1080/08839514.2024.2419609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction of multimodal emotional information enables a more nuanced representation of the emotional subtleties embedded in film and television works. However, conventional approaches that independently extract features from images and text fail to capture the rich semantic interplay between these modalities, impeding the feature learning process within each modality. To address this, this paper presents an innovative model for extracting emotional information from multimodal film and television content. The model utilizes DenseNe for image feature extraction, enhancing network depth via the MSC module. Text feature extraction is achieved through a Transformer encoder, while video feature extraction employs a 3D CNN model. Refinements are made to the number and placement of convolutional layers, planar convolution size, and 3D convolution depth. Moreover, a multi-head scaled dot-product attention mechanism is incorporated into the interaction module to compute the similarity between each image block within the sequence and every word in the text sequence. Experimental evaluations on the CMU-MOSEI and CMU-MOSI datasets showcase superior performance compared to the baseline model, achieving accuracy and F1 scores of 0.708 and 0.698, respectively. Noteworthy is the proposed adaptive feature fusion module, which enriches the expressiveness of pivotal emotional features while eliminating redundant data.},
  archive      = {J_AAI},
  author       = {Shilei Liang},
  doi          = {10.1080/08839514.2024.2419609},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2419609},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Enhancing multimodal emotional information extraction in film and television through adaptive feature fusion with DenseNe, transformer, and 3D CNN models},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quality parameter adaptive optimization for spinning process
using dynamic non-dominated sorting algorithm. <em>AAI</em>,
<em>38</em>(1), Article: 2419575. (<a
href="https://doi.org/10.1080/08839514.2024.2419575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent textile equipment can discover potential patterns in the production process through data mining, and utilize these patterns through intelligent optimization, ultimately achieving intelligent and automated textile production. This paper focuses on the spinning process parameters optimization under changing spinning conditions and proposes a dynamic non-dominant ranking parameter quality adaptive optimization algorithm. The factors of spinning process condition changes are transformed into mathematical dynamic constraints and constructing an adaptive optimization model for spinning parameter quality. Based on this, the response mechanism of spinning environment is established to readjust the optimization direction according to the change of spinning conditions, and the DNSGA-II is used to solve the quality adaptive optimization model. A case study is designed to validate the effectiveness, results show that for different usage periods of wire rings, the optimal breaking strength is 5.6, and the number of details is 33.3, 31.1, and 41.6 respectively. In some degree, the proposed algorithm can effectively adapt to the quality optimization problem of spinning process parameters under different spinning conditions, which could provide corresponding parameter optimization combinations for different spinning conditions.},
  archive      = {J_AAI},
  author       = {Di Wu and Sheng Hu},
  doi          = {10.1080/08839514.2024.2419575},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2419575},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Quality parameter adaptive optimization for spinning process using dynamic non-dominated sorting algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visualization analysis of integrating college sports
training and psychology into basketball physical education teaching
system based on image recognition algorithm. <em>AAI</em>,
<em>38</em>(1), Article: 2419571. (<a
href="https://doi.org/10.1080/08839514.2024.2419571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On this basis, a basketball movement model based on ORB (Oriented FAST and Rotated BRIEF) local feature extraction has been proposed, and a basketball teaching visualization analysis system has been constructed. By extracting images from athletes’ videos in basketball, and using their training as a standard, tracking the frequency of their various celebration postures appearing and improving their scores in the game, corresponding feature points are extracted, and then the BP (back propagation) neural network algorithm is used to classify feature points. Ten different participants were selected from 10 games. Their movements were tracked, and then the extracted feature actions were imported into the visualization system for visual analysis, comparing the changes before and after psychological intervention. The results showed that there were significant differences in scores, errors, hit rates, steals, and motivation among subjects who received psychological cues and incentives compared to the data before psychological counseling. The scores and positive and negative values increased to 2–4 points, which had a certain positive impact on the competitive results.},
  archive      = {J_AAI},
  author       = {Junzhang Cheng and Lingtao Wen and Baolei Zhang},
  doi          = {10.1080/08839514.2024.2419571},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2419571},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Visualization analysis of integrating college sports training and psychology into basketball physical education teaching system based on image recognition algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing intent classifier training with large language
model-generated data. <em>AAI</em>, <em>38</em>(1), Article: 2414483.
(<a href="https://doi.org/10.1080/08839514.2024.2414483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intent classification is essential in Natural Language Processing, serving applications like virtual assistants and customer service by categorizing user inputs into predefined classes. Despite its importance, the effectiveness of intent classifiers is often constrained by the scarcity of labeled data, as acquiring substantial, annotated datasets is costly and impractical. Data augmentation addresses this by expanding datasets with modified or synthetic examples, a common practice in computer vision but more complex in NLP due to the discrete nature of language. Traditional NLP data augmentation methods have been explored but exhibit limitations. This paper investigates the use of Large Language Models for generating labeled data to enhance intent classification. We explore whether LLM-generated data can effectively augment training sets, comparing its impact on intent classifier performance against traditional augmentation methods. Our study reveals that LLMs can generate diverse and realistic data, potentially improving classifier accuracy in low-data scenarios, thereby providing valuable insights into leveraging generative AI for NLP tasks in real-world applications.},
  archive      = {J_AAI},
  author       = {Alberto Benayas and Sicilia Miguel-Ángel and Marçal Mora-Cantallops},
  doi          = {10.1080/08839514.2024.2414483},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2414483},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Enhancing intent classifier training with large language model-generated data},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis and research on intelligent logistics data under
internet of things and blockchain. <em>AAI</em>, <em>38</em>(1),
Article: 2413824. (<a
href="https://doi.org/10.1080/08839514.2024.2413824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To explore the security performance of logistics data transmission in an Intelligent Logistics System (ILS) under the Internet of Things (IoT) and Blockchain (BC), IoT is introduced to optimize the logistics transportation process. First, BC is adopted to improve the ILS under IoT, and ILS under IoT combined with BC is established. Next, an analysis of the relationship between the information service provider and the transportation provider in the logistics transaction process is conducted to perform data analysis and to establish an incentive mechanism for logistics transportation under BC. Finally, the simulation analysis of the constructed model is implemented. The results reveal that the constructed model is highly efficient. It can effectively solve the traceability problem of logistics transaction information, and the calculation cost is stable within 1,000 ms. In the comparative analysis of system transmission performance, the model exhibits outstanding results in transmission latency, consistently maintaining an average delay of approximately 350 ms. This stability is primarily attributed to the seamless integration of BC technology, which optimizes data packet transmission paths and mitigates waiting time. Furthermore, the system efficiently manages high data volumes while upholding robust data processing capabilities, owing to the optimization of smart contracts and decentralized storage mechanisms. As for energy consumption, the model notably reduces overall energy usage within the logistics network by curtailing unnecessary data transmission and computation, particularly in mobile nodes and wireless communication channels. The proposed algorithm excels across various transmission metrics, including transmission delay, data successful acceptance rate, network throughput, and energy consumption are all shown to be the best transmission performance of the proposed algorithm, in which the data successful acceptance rate is close to 1. As a result, the developed ILS model not only guarantees low latency performance but also demonstrates high data transmission security, facilitating more efficient and precise real-time information transmission. In this study, within the ILS framework, the relationship between information service providers and transportation service providers is established through BC, and an incentive mechanism is constructed. However, some shortcomings in this incentive mechanism are recognized. For instance, during the initial stages of BC integration, there are issues of information asymmetry concerning factors such as credit, transportation capacity, and effort level. Moreover, the open access policy of couriers in the model raises concerns, as the access policy itself constitutes sensitive information, which may result in privacy breaches. Hence, as part of future work, the introduction of attribute encryption schemes is planned to obfuscate access policies, thereby safeguarding the privacy of logistics personnel’s access policies.},
  archive      = {J_AAI},
  author       = {Yige Li},
  doi          = {10.1080/08839514.2024.2413824},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2413824},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Analysis and research on intelligent logistics data under internet of things and blockchain},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing metaphor recognition of literary works in applied
artificial intelligence: A multi-level approach with bi-LSTM and CNN
fusion. <em>AAI</em>, <em>38</em>(1), Article: 2413817. (<a
href="https://doi.org/10.1080/08839514.2024.2413817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding metaphorical language is essential for AI to interpret and communicate with humans accurately. However, current methods often struggle with the complexity of metaphors, making it difficult for AI systems to understand human language fully. Recognizing metaphors is challenging because they are frequently ambiguous and depend on context. In this study, we propose a new approach using a combination of Bi-directional Long Short-Term Memory (Bi-LSTM) networks, Convolutional Neural Networks (CNN), and uni-directional LSTM components to create a multi-level model for recognizing metaphors. Our model uses various features, including dependency, semantics, and part-of-speech, to improve its learning ability. Additionally, we introduce a new method for recognizing the emotional context of metaphors using a random walk model to determine the emotional tone of words. Our results show that this model improves performance in recognizing metaphors, enhancing AI’s ability to understand them.},
  archive      = {J_AAI},
  author       = {Na Zhao and Weijie Zhao},
  doi          = {10.1080/08839514.2024.2413817},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2413817},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Enhancing metaphor recognition of literary works in applied artificial intelligence: A multi-level approach with bi-LSTM and CNN fusion},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On short-term and long-term repeated game behavior- a case
study of oligopolistic transportation enterprises with government
intervention under fuzzy environment. <em>AAI</em>, <em>38</em>(1),
Article: 2413813. (<a
href="https://doi.org/10.1080/08839514.2024.2413813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transportation sector has always been dedicated to energy conservation and emission reduction. In an effort to optimize the transportation structure and promote the energy conservation and emission reduction of the transportation sector, the government has implemented numerous intervention policies. This paper aims to explore how the implementation objects of the intervention strategy interact with one another. Based on the price game model, the fuzzy triangular variables are used to construct the duopoly game competition model under the different situations of subsidy, carbon quota, and carbon tax. According to the results, (1) Subsidy policy will lead to excessive dependence, although it can improve the price competitive advantage of railway transport most significantly. (2) Under the carbon quota policy, transportation companies maximize predicted profits and social benefit. In the long-term repeated game, railway transport has more space to adjust price than road transport. (3) Under government intervention policies, increasing the substitution rate of transport products can improve social benefits.},
  archive      = {J_AAI},
  author       = {Qian Long and Qunqi Wu and Yahong Jiang},
  doi          = {10.1080/08839514.2024.2413813},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2413813},
  shortjournal = {Appl. Artif. Intell.},
  title        = {On short-term and long-term repeated game behavior- a case study of oligopolistic transportation enterprises with government intervention under fuzzy environment},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DRFL: Dynamic-recall focal loss for image classification and
segmentation. <em>AAI</em>, <em>38</em>(1), Article: 2411845. (<a
href="https://doi.org/10.1080/08839514.2024.2411845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of neural networks heavily depends on numerous precisely annotated samples. But in actual datasets, the number of samples for each category varies greatly. In the dataset, some classes may have a large sample size, called majority classes, while others may have a small sample size, called minority classes. Training model with imbalanced data is often conducive to the majority classes, while unfair to minority classes. As a result, the outputs return good performance on majority classes and bad performance on minority classes. This article proposes a new loss function called dynamic-recall focal loss (DRFL), which can solve the problem of imbalanced data categories in image classification and medical segmentation tasks. The DRFL assigns different weight coefficient to the classes according to their dynamic recall based on focal loss. Experimental results have shown that the newly proposed loss function DRFL can effectively improve the classification and segmentation accuracy of two imbalanced datasets.},
  archive      = {J_AAI},
  author       = {Xiaohong Liu and Lin Wang and Lijing Ma and Chaoli Wang},
  doi          = {10.1080/08839514.2024.2411845},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2411845},
  shortjournal = {Appl. Artif. Intell.},
  title        = {DRFL: Dynamic-recall focal loss for image classification and segmentation},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discovering the relationship between attributes of facial
masks and review rating in online customer reviews using explainable
artificial intelligence (XAI). <em>AAI</em>, <em>38</em>(1), Article:
2411780. (<a
href="https://doi.org/10.1080/08839514.2024.2411780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic led to a surge in facial mask usage. Analyzing customer feedback is crucial for enhancing this product, given the abundance of options and online reviews available. Techniques like Latent Dirichlet Allocation (LDA) combined with machine learning (ML) models help identify product attributes and their impact on reviews. However, successful models frequently employ black-box techniques that fail to explain how product attributes impact customer satisfaction. To address this, Explainable Artificial Intelligence (XAI) combined with advanced ML methods is suggested to create interpretable models. This paper evaluates the usefulness of combining LDA for topic modeling, Gradient Boost trees (GBT) for ML, and SHapley Additive exPlanations (SHAP) to develop an interpretable model for face mask attribute impact on online ratings. Analyzing 2,047 reviews of 35 mask products revealed seven key attributes. Labeling and nose-strap significantly influenced evaluations, while shopping experience, and packaging, filtering level, and fit were less impactful. This research supports the use of topic modeling combined with advanced ML techniques and XAI in analyzing online customer reviews to offer a time- and cost-effective method. It aids in understanding product attributes influencing satisfaction for product design and improvement, especially in the dynamic context of face mask preferences and purchasing decisions.},
  archive      = {J_AAI},
  author       = {Inmaculada Aparicio-Aparicio and Maria-Arantzazu Ruescas-Nicolau and Lirios Dueñas and José Luis Sánchez-Jiménez and M.Luz Sánchez-Sánchez and Enrique Alcántara},
  doi          = {10.1080/08839514.2024.2411780},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2411780},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Discovering the relationship between attributes of facial masks and review rating in online customer reviews using explainable artificial intelligence (XAI)},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integration of warrior artificial intelligence and
leadership reflexivity to enhance decision-making. <em>AAI</em>,
<em>38</em>(1), Article: 2411462. (<a
href="https://doi.org/10.1080/08839514.2024.2411462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the emerging literature on artificial intelligence (AI) and leadership, there is increasing recognition of the importance played by advanced technologies in decision-making. AI is viewed as the next frontier to improve decision-making processes and as a result enhance human decision-making in general. However, existing literature lacks studies on how AI, operating as a “warrior” or innovator in business, can in turn enhance leadership reflexivity, and thereby improve decision-making outcomes. This study is aimed at addressing this gap by drawing on the reflexivity perspective and existing research on AI and leadership to examine the integration of the concepts of warrior AI with leadership reflexivity to improve decision-making. The study used a systematic literature review to identify and map articles using specified inclusion and exclusion criteria to achieve this. Selected articles were included for in-depth analysis to address the issue under investigation. The study explored the potential benefits of blending advanced AI with reflective leadership strategies, offering insights into how organizations can optimize their decision-making processes through this innovative approach. A comprehensive literature review was thus the foundation for our investigation into how warrior AI may enhance human decision-making especially under high-stress conditions by providing real-time data analysis capabilities, pattern recognition skills, and predictive simulations. Our work emphasizes how leadership reflexivity plays a critical role in assessing AI-driven recommendations to ensure ethical soundness and contextual appropriateness of the decisions being taken. Based on our findings, we suggest that integrating AI capabilities with reflective leadership practices can lead to more effective and adaptable decision-making frameworks, particularly when swift yet well-informed action is necessary. This study adds to the existing body of knowledge by illustrating that, with the aid of a flow diagram, the integration of warrior AI into the reflective process can potentially amplify the benefits of AI, offering data-driven insights for leaders to reflect upon, thereby reinforcing the decision-making process with a more rigorous, ethical, and nuanced approach in alignment with organizational objectives and societal values. It is recommended that leadership actively engage in discussions regarding ethical AI use, ensuring alignment with organizational values and ethics. Ultimately, this study contributes valuable insights to discussions around AI and leadership by underscoring the significance of maintaining a balanced relationship between machine efficiency and human wisdom.},
  archive      = {J_AAI},
  author       = {Walter Matli},
  doi          = {10.1080/08839514.2024.2411462},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2411462},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Integration of warrior artificial intelligence and leadership reflexivity to enhance decision-making},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy issues, attacks, countermeasures and open problems
in federated learning: A survey. <em>AAI</em>, <em>38</em>(1), Article:
2410504. (<a
href="https://doi.org/10.1080/08839514.2024.2410504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AAI},
  author       = {Blessing Guembe and Sanjay Misra and Ambrose Azeta},
  doi          = {10.1080/08839514.2024.2410504},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2410504},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Privacy issues, attacks, countermeasures and open problems in federated learning: A survey},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing kernel transformations to handle binary class
imbalanced dataset classification. <em>AAI</em>, <em>38</em>(1),
Article: 2408933. (<a
href="https://doi.org/10.1080/08839514.2024.2408933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced class distributions pose a prevalent challenge in numerous classification problems, requiring effective strategies for learning from such skewed data. Traditional machine learning algorithms often struggle with imbalanced datasets, as they tend to bias their classification functions toward the majority class, resulting in suboptimal performance for minority classes. In our research, we propose a novel approach to address this challenge specifically tailored for Support Vector Machines (SVM), a well-established family of learning algorithms. Our method leverages a kernel trick to enhance the SVM’s classification capabilities on imbalanced datasets named KTI. It aims to streamline the classification process by incorporating adaptive data transformations within the algorithm itself, offering a more efficient and integrated solution for handling imbalanced data. Experimental evaluations conducted on diverse real-world datasets demonstrate the superior performance of our proposed strategy compared to existing methods, showcasing its potential for practical applications in classification tasks with skewed class distributions.},
  archive      = {J_AAI},
  author       = {Vaibhavi Patel and Hetal Bhavsar},
  doi          = {10.1080/08839514.2024.2408933},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2408933},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Optimizing kernel transformations to handle binary class imbalanced dataset classification},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot symbol detection in engineering drawings.
<em>AAI</em>, <em>38</em>(1), Article: 2406712. (<a
href="https://doi.org/10.1080/08839514.2024.2406712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been significant interest in digitizing engineering drawings due to their complexity and practical benefits. Symbol digitization, a critical aspect in this field, is challenging as utilizing Deep Learning-based methods to recognize symbols of interest requires a large number of training instances for each class of symbols. Acquiring and annotating sufficient diagrams is difficult due to concerns about confidentiality and availability. The conventional manual annotation process is time-consuming, costly, and prone to human error. Additionally, obtaining an adequate number of samples for rare classes proves to be exceptionally challenging. This paper introduces a few-shot framework to address these challenges. Several experiments with fewer than ten, and sometimes just one, training instance per class using complex engineering drawings from industry sources were carried out. The results suggest that our method not only significantly improves symbol detection performance compared to other state-of-the-art methods but also decreases the necessary number of training instances.},
  archive      = {J_AAI},
  author       = {Laura Jamieson and Eyad Elyan and Carlos Francisco Moreno-García},
  doi          = {10.1080/08839514.2024.2406712},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2406712},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Few-shot symbol detection in engineering drawings},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Digital human intelligent interaction system based on
multimodal pre-training mode. <em>AAI</em>, <em>38</em>(1), Article:
2405953. (<a
href="https://doi.org/10.1080/08839514.2024.2405953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the forefront of human–computer intelligent interaction, digital humans have increasingly diverse application scenarios, but also face many challenges. In order to enhance the intelligence level and interaction capability of digital human, the study first optimizes the traditional UniLM model, then introduces the mechanism of multi-head attention, and mitigates the exposure bias by using adversarial training and random replacement of decoder to design an improved UniLM model, and finally applies the improved model to the digital human management system. The results show that the precision rate of the improved UniLM model is improved by 7.68%, 6.4%, and 4.96%, the recall rate is improved by 11.94%, 9.69%, and 8.83%, and the F1-score is improved by 8.34%, 6.41%, and 7.68% compared with the other three models, which proves that it has a better precision rate, robustness, and generalization ability. The perplexity of the improved UniLM model is 135, 95, 76, 71, and 55 under five text lengths, which is significantly lower than the other models, proving that its text generation ability is better. The above results demonstrate the performance of the research-designed digital human system based on the Improved UniLM model, which provides a direction for the further development of digital human technology.},
  archive      = {J_AAI},
  author       = {Xuliang Yang and Yong Fang and Lili Wang and Rodolfo C. Raga Jr},
  doi          = {10.1080/08839514.2024.2405953},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2405953},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Digital human intelligent interaction system based on multimodal pre-training mode},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integration of neural embeddings and probabilistic models in
topic modeling. <em>AAI</em>, <em>38</em>(1), Article: 2403904. (<a
href="https://doi.org/10.1080/08839514.2024.2403904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topic modeling, a way to find topics in large volumes of text, has grown with the help of deep learning. This paper presents two novel approaches to topic modeling by integrating embeddings derived from Bert-Topic with the multi-grain clustering topic model (MGCTM). Recognizing the inherent hierarchical and multi-scale nature of topics in corpora, our methods utilize MGCTM to capture topic structures at multiple levels of granularity. We enhance the expressiveness of MGCTM by introducing the Generalized Dirichlet and Beta-Liouville distributions as priors, which provide greater flexibility in modeling topic proportions and capturing richer topic relationships. Comprehensive experiments on various datasets showcase the effectiveness of our proposed models in achieving superior topic coherence and granularity compared to state-of-the-art methods. Our findings underscore the potential of leveraging hybrid architectures, marrying neural embeddings with advanced probabilistic modeling, to push the boundaries of topic modeling.},
  archive      = {J_AAI},
  author       = {Pantea Koochemeshkian and Nizar Bouguila},
  doi          = {10.1080/08839514.2024.2403904},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2403904},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Integration of neural embeddings and probabilistic models in topic modeling},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of improved HF-DBSCAN algorithm in analyzing
complex trajectory data of wi-fi users in smart campus. <em>AAI</em>,
<em>38</em>(1), Article: 2403260. (<a
href="https://doi.org/10.1080/08839514.2024.2403260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of wireless network technology and the increasingly widespread application of mobile intelligent terminals, a large amount of wireless network data has been generated in smart campuses. By analyzing the trajectory data through clustering algorithms, more valuable user data information can be obtained. However, current clustering algorithms have high computational difficulty, long running time, and poor clustering accuracy for complex trajectories. Based on this background, the study proposes a spatial clustering of Application with Noise by Density-Based Spatial Clustering of Application with Noise combining Hausdorff and Frechet. The method is denoted as (Hausdorff and Frechet-Density Based Spatial Clustering of Application with Noise, HF-DBSCAN). DBSCAN denotes the Density Based Spatial Clustering of Application with Noise. In the experimental results, compared to the AH-DBSCAN, DBSCAN, and FD-DBSCAN algorithms, the running time of HF-DBSCAN algorithm in complex trajectory cluster analysis is reduced by 59.33%, 39.82%, and 35.12%, respectively, and the contour coefficient is closer to 1; the Davies-Boldin Index (DBI) values decreased by 59.24%, 64.42%, and 68.24%, respectively. The experiment shows that the optimized HF-DBSCAN algorithm has lower computational difficulty, better clustering performance, and higher clustering accuracy, which verifies the effectiveness of this study.},
  archive      = {J_AAI},
  author       = {Likun Li and Kun Yu},
  doi          = {10.1080/08839514.2024.2403260},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2403260},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Application of improved HF-DBSCAN algorithm in analyzing complex trajectory data of wi-fi users in smart campus},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Determining novice and expert status in human–automation
interaction through hidden markov models. <em>AAI</em>, <em>38</em>(1),
Article: 2402174. (<a
href="https://doi.org/10.1080/08839514.2024.2402174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting when operators achieve expert proficiency is critical for organizations that employ human–automation interaction (HAI) in operations, particularly in safety-critical settings. Training operators for complex systems demand substantial time and resources, necessitated by safety considerations and the expansive scale of these systems. Recognizing operator expertise becomes instrumental in resource optimization and training efficiency. This study explores a modeling framework for real-time analysis of HAI operator behavior and strategies. Proposing a departure from traditional assessments, the research advocates for leveraging hidden Markov models (HMMs) to provide a comprehensive portrayal of operator performance, facilitating a nuanced comparison of expert and novice strategies. Using data from a real-time strategy game, the paper details the development of HMMs and elucidates training and interface design implications. Results affirm the hypothesis that experts formulate more efficient strategies, reflected in HMMs with fewer hidden states compared to those describing novice behavior. This aligns with prior research emphasizing the organized nature of experts’ strategies. In-depth analysis delves into specific states, frequencies, and predominant strategies, revealing distinctions between experts’ offensive focus and novices’ emphasis on initial setup aspects of gameplay.},
  archive      = {J_AAI},
  author       = {Anne French and Mary L. Cummings and Haibei Zhu and Miroslav Pajic},
  doi          = {10.1080/08839514.2024.2402174},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2402174},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Determining novice and expert status in Human–Automation interaction through hidden markov models},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ge’ez digit recognition model based on convolutional neural
network. <em>AAI</em>, <em>38</em>(1), Article: 2400641. (<a
href="https://doi.org/10.1080/08839514.2024.2400641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the historical significance of the Ge’ez script, there is a notable scarcity of studies on Ge’ez digit recognition, compounded by the challenges posed by the absence of publicly accessible datasets. The complex structure of Ge’ez digits further complicates the recognition task. In response to this gap, our study addresses the development of a digit recognition model based on deep learning (DL) specifically tailored for printed Ge’ez digits, accompanied by the creation of a comprehensive study dataset. The proposed model architecture seamlessly integrates one input layer, six convolutional layers, and three Max-Pooling layers. To assess the model’s performance, we meticulously curated a Ge’ez digit dataset comprising 72,000 images, well-suited for DL applications using the ocropus-linegen model within OCRopus, a free document analysis tool. Leveraging cutting-edge DL algorithms, our proposed model demonstrates an impressive accuracy of 97.29%. This surpasses the performance of previous Ge’ez digit recognition models, marking a noteworthy advancement in this underexplored domain.},
  archive      = {J_AAI},
  author       = {Ruchika Malhotra and Maru Tesfaye Addis},
  doi          = {10.1080/08839514.2024.2400641},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2400641},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Ge’ez digit recognition model based on convolutional neural network},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distance based korean WordNet(alias. KorLex) embedding
model. <em>AAI</em>, <em>38</em>(1), Article: 2398920. (<a
href="https://doi.org/10.1080/08839514.2024.2398920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this study was to create graph embedding vectors using Korean WordNet (KorLex) and apply them to neural network word-embedding models. Semantic knowledge, especially lexical semantic knowledge in a language, can be represented by word-embedding vectors or graph structures of lexical databases, such as WordNet. Both representations capture common semantics; however, some semantic knowledge is only captured in a specific way or not at all. In a previous study, Path2vec mapped WordNet graphs to graph-embedding vectors using similarity scores between two words. In this study, we propose two main approaches. First, we mapped the knowledge in the Korean lexical database KorLex onto graph-embedding vectors. We then applied these embedding vectors to deep neural network word embeddings to capture additional semantic knowledge in the Korean language. On a custom test set, the proposed approach improved performance by capturing additional semantic knowledge in similarity and analogy analyses. We plan to apply a variant of this to other deep neural embedding models.},
  archive      = {J_AAI},
  author       = {SeongReol Park and JoongMin Shin and Sanghyun Cho and Hyuk-Chul Kwon and Jung-Hun Lee},
  doi          = {10.1080/08839514.2024.2398920},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2398920},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Distance based korean WordNet(alias. KorLex) embedding model},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Surrogate-assisted multi-objective optimization for
simultaneous three-dimensional packing and motion planning problems
using the sequence-triple representation. <em>AAI</em>, <em>38</em>(1),
Article: 2398895. (<a
href="https://doi.org/10.1080/08839514.2024.2398895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Packing problems are classical optimization problems with wide-ranging applications. With the advancement of robotic manipulation, there are growing demands for the automation of packing tasks. However, the simultaneous optimization of packing and the robot’s motion planning is challenging because these two decisions are interconnected, and no previous study has addressed this optimization problem. This paper presents a framework to simultaneously determine the robot’s motion planning and packing decision to minimize the robot’s processing time and the container’s volume. This framework comprises three key components: solution encoding, surrogate modeling, and evolutionary computation. The sequence-triple representation encodes complex packing solutions by a sequence of integers. A surrogate model is trained to predict the processing time for a given packing solution to reduce the computational burden. Training data is generated by solving the motion planning problem for a set of packing solutions using the rapidly exploring random tree algorithm. The Non-Dominated Sorting Genetic Algorithm II searches for the Pareto solutions. Experimental evaluations are conducted using a 6-DOF robot manipulator. The experimental results suggest that implementing the surrogate model can reduce the computational time by 91.1%. The proposed surrogate-assisted optimization method can obtain significantly better solutions than the joint angular velocity-based estimation method.},
  archive      = {J_AAI},
  author       = {Ziang Liu and Tomoya Kawabe and Tatsushi Nishi and Shun Ito and Tomofumi Fujiwara},
  doi          = {10.1080/08839514.2024.2398895},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2398895},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Surrogate-assisted multi-objective optimization for simultaneous three-dimensional packing and motion planning problems using the sequence-triple representation},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A red teaming framework for securing AI in maritime
autonomous systems. <em>AAI</em>, <em>38</em>(1), Article: 2395750. (<a
href="https://doi.org/10.1080/08839514.2024.2395750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) is being ubiquitously adopted to automate processes in science and industry. However, due to its often intricate and opaque nature, AI has been shown to possess inherent vulnerabilities which can be maliciously exploited with adversarial AI, potentially putting AI users and developers at both cyber and physical risk. In addition, there is insufficient comprehension of the real-world effects of adversarial AI and an inadequacy of AI security examinations; therefore, the growing threat landscape is unknown for many AI solutions. To mitigate this issue, we propose one of the first red team frameworks for evaluating the AI security of maritime autonomous systems. The framework provides operators with a proactive (secure by design) and reactive (post-deployment evaluation) response to securing AI technology today and in the future. This framework is a multi-part checklist, which can be tailored to different systems and requirements. We demonstrate this framework to be highly effective for a red team to use to uncover numerous vulnerabilities within a real-world maritime autonomous systems AI, ranging from poisoning to adversarial patch attacks. The lessons learned from systematic AI red teaming can help prevent MAS-related catastrophic events in a world with increasing uptake and reliance on mission-critical AI.},
  archive      = {J_AAI},
  author       = {Mathew J. Walter and Aaron Barrett and Kimberly Tam},
  doi          = {10.1080/08839514.2024.2395750},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2395750},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A red teaming framework for securing AI in maritime autonomous systems},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature-based dataset fingerprinting for clustered federated
learning on medical image data. <em>AAI</em>, <em>38</em>(1), Article:
2394756. (<a
href="https://doi.org/10.1080/08839514.2024.2394756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) allows multiple clients to train a common model without sharing their private training data. In practice, federated optimization struggles with sub-optimal model utility because data is not independent and identically distributed (non-IID). Recent work has proposed to cluster clients according to dataset fingerprints to improve model utility in such situations. These fingerprints aim to capture the key characteristics of clients’ local data distributions. Recently, a mechanism was proposed to calculate dataset fingerprints from raw client data. We find that this fingerprinting mechanism comes with substantial time and memory consumption, limiting its practical use to small datasets. Additionally, shared raw data fingerprints can directly leak sensitive visual information, in certain cases even resembling the original client training data. To alleviate these problems, we propose a Feature-based dataset FingerPrinting mechanism (FFP). We use the MedMNIST database to develop a highly realistic case study for FL on medical image data. Compared to existing methods, our proposed FFP reduces the computational overhead of fingerprint calculation while achieving similar model utility. Furthermore, FFP mitigates the risk of raw data leakage from fingerprints by design.},
  archive      = {J_AAI},
  author       = {Daniel Scheliga and Patrick Mäder and Marco Seeland},
  doi          = {10.1080/08839514.2024.2394756},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2394756},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Feature-based dataset fingerprinting for clustered federated learning on medical image data},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning ensemble classifiers for feature selection
in rice cultivars. <em>AAI</em>, <em>38</em>(1), Article: 2394734. (<a
href="https://doi.org/10.1080/08839514.2024.2394734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning (ML) has a big impact on smart farming, especially rice productivity. This is especially true for intelligent farming. Machine Learning is crucial for seed prediction, germination, crop production, soil moisture, and land suitability evaluation. Selecting a rice cultivar requires considering local environmental and seed factors. This research examines classification algorithms like K-Nearest Neighbor (KNN), Decision Tree (DT), NaiveBayes (NB), Support Vector Machine (SVM), and Random Forest (RF) with wrapper feature selection techniques like SFFS, SBEFS, CBFS, VIF, and RANDIM for environmental and seed data. This research study proposes the best feature selection approach with classifiers for the environmental &amp; seed factor dataset to select the rice cultivar. This study collected 10 rice cultivar characteristics (short, medium, and long duration, average yield, minimum and maximum days, seed types, grain weight, grain type, color, parentage, and other special characteristics) and 7 environmental characteristics (Starting Month, Ending Month, Rainfall Actual, Rainfall Normal, Temperature Minimum, Temperature Maximum, District) from 2002 to 2022 in Madurai, Tamilnadu. The variance inflation factor (VIF) of the wrapper feature selection approach with decision tree classification algorithm yields 99.63% accuracy and 4.3% error rate compared to other classification algorithms and wrapper feature selection techniques.},
  archive      = {J_AAI},
  author       = {Chandrakumar Thangavel and D Sakthipriya},
  doi          = {10.1080/08839514.2024.2394734},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2394734},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Machine learning ensemble classifiers for feature selection in rice cultivars},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding the dynamics of ocean wave-current
interactions through multivariate multi-step time series forecasting.
<em>AAI</em>, <em>38</em>(1), Article: 2393978. (<a
href="https://doi.org/10.1080/08839514.2024.2393978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding ocean wave-current interactions’ complex dynamics is crucial for coastal engineering, marine operations, and climate research applications. This study introduces a pioneering data-driven approach by employing advanced deep learning techniques, specifically Long Short-Term Memory (LSTM), and Bidirectional LSTM (BiLSTM) models, to forecast both wave and current parameters at varying depths. The models are designed to capture the complex temporal relationships inherent in ocean dynamics, considering wave speed and direction, current speed, and direction as multivariate time series inputs. Two comprehensive experiments are conducted, one utilizing historical values of all parameters and another focusing on using wave parameters to forecast current parameters. Model performance is rigorously evaluated across forecast horizons of 5, 12, and 24 hours ahead using metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE). BiLSTM emerges as the superior model, demonstrating lower errors, particularly at higher depths, while nearshore predictions reveal challenges in shallower waters. Furthermore, the methodology incorporates hyperparameter optimization and cross-validation techniques to enhance the model’s robustness. Ultimately, this work represents a transformative leap toward smarter oceans, emphasizing the fusion of fluid dynamics and bathymetry to advance our understanding of coupled wave-current dynamics. The results showcase high accuracy and reliability across various forecast horizons and depths, signifying the method’s potential applications in oceanography, hydrodynamics, coastal engineering, and ocean renewable energy.},
  archive      = {J_AAI},
  author       = {Zaharaddeeen Karami Lawal and Hayati Yassin and Daphne Teck Ching Lai and Azam Che Idris},
  doi          = {10.1080/08839514.2024.2393978},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2393978},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Understanding the dynamics of ocean wave-current interactions through multivariate multi-step time series forecasting},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fact or fake? How news title, sentiment and writing style
help AI to detect COVID-19 fake news? <em>AAI</em>, <em>38</em>(1),
Article: 2389502. (<a
href="https://doi.org/10.1080/08839514.2024.2389502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents a sophisticated model aimed at detecting COVID-19 related misinformation in Traditional Chinese, a critical response to the swift spread of fake news during the pandemic. The model employs an ensemble model of machine learning techniques, such as SVM, LSTM, BiLSTM, and BERT, along with a diverse array of input features including news structure, sentiment, and writing stylistic elements. Testing of the model has shown an impressive 97% accuracy in differentiating factual from fraudulent news. A significant finding is that in-depth content analysis offers more insights compared to mere headline scrutiny, though headlines do aid in marginally increasing accuracy. The integration of sentiment analysis and stylistic nuances further boosts the model’s effectiveness. This study is pivotal in establishing a robust Traditional-Chinese fake news detection mechanism for COVID-19, underscoring the effectiveness of combined machine learning strategies for more consistent and reliable outcomes.},
  archive      = {J_AAI},
  author       = {Chen-Shu Wang and Bo-Yi Li and Kai-Wen Wang and Zhi-Chi Lin},
  doi          = {10.1080/08839514.2024.2389502},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2389502},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Fact or fake? how news title, sentiment and writing style help AI to detect COVID-19 fake news?},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quasi-experimental quality evaluation of
educational-purposed user-generated contents under a stochastic
multi-criteria environment. <em>AAI</em>, <em>38</em>(1), Article:
2389501. (<a
href="https://doi.org/10.1080/08839514.2024.2389501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As social platforms experience an influx of diverse content from users, the need to determine high-quality contributions becomes crucial, especially for educational purposes. This paper highlights the pivotal role of quality in assessing how educational-purposed user-generated content (UGC) shapes user experiences, fosters engagement, and establishes credibility. This study proposes a computational framework using a quasi-experimental evaluation through the sorting-based ELimination Et Choice TRanslating Reality, termed ELECTRE-SORT, with a dataset randomly generated from normally distributed user evaluations. Considering the diverse nature of contents, the method evaluates 16 educational-purposed UGC videos from different online media platforms (i.e. Facebook, YouTube, TikTok). These videos were categorized based on their concordance and discordance to three (3) main criteria: content quality, design quality, and technology quality. Employing the ELECTRE-SORT reveals that most UGC videos (i.e. 14 out of 16) fall into the “medium quality” category, possessing a considerable standard for the quality of educational purpose content. Their characteristics generally satisfy the quality attributes and can be used to guide the development of future relevant UGC videos. Finally, to demonstrate the robustness of the proposed approach, we presented a sensitivity analysis by designing different weight assignments to the quality attributes. Practical insights are outlined in this work.},
  archive      = {J_AAI},
  author       = {Roberto Suson and Nadine May Atibing and Samantha Shane Evangelista and Charldy Wenceslao and Fatima Maturan and Rica Villarosa and Lanndon Ocampo},
  doi          = {10.1080/08839514.2024.2389501},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2389501},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Quasi-experimental quality evaluation of educational-purposed user-generated contents under a stochastic multi-criteria environment},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of gait neurodegenerative diseases by variational
mode decomposition using machine learning algorithms. <em>AAI</em>,
<em>38</em>(1), Article: 2389375. (<a
href="https://doi.org/10.1080/08839514.2024.2389375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Degeneration in brain cells is the cause of neurodegenerative illness, which cause motor function impairment. Anomaly in walking is one of this impairment’s adverse effects. Since sensor technologies and artificial intelligence applications have advanced in recent years, it is possible to predict a patient’s disease severity from their gait data using a model helps to grade the severity of the patient disease. The proposed research work is developed using the gait neurodegenerative data composed of gait signals collected from physionet database. The composite non stationary and nonlinear gait signals are decomposed into different modes of Intrinsic Mode Function (IMF) using Variational Mode Decomposition (VMD). IMFs ensure the signals retrieved are stationary and linear. Power Spectral Density (PSD) is used to choose best IMF. Feature extraction for the chosen IMF is done with Shannon entropy technique. Prediction of different neurodegenerative disease such as Parkinsons Disease (PD), Huntingtons Disease (HD), Amyotrophic Lateral Sclerosis (ALS) and healthy subjects are carried out by Multilayer Perceptron (MLP) with the parameters optimized with Genetic Algorithm (GA). The results of the experiments shows that the proposed model produces a better accuracy of 98.4% than the other existing algorithms for the gait dataset.},
  archive      = {J_AAI},
  author       = {P. Visvanathan and P.M. Durai Raj Vincent},
  doi          = {10.1080/08839514.2024.2389375},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2389375},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Prediction of gait neurodegenerative diseases by variational mode decomposition using machine learning algorithms},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep neural network-based temperature mapping technique for
heat sink on electronic devices using local thermocouple sensors.
<em>AAI</em>, <em>38</em>(1), Article: 2389374. (<a
href="https://doi.org/10.1080/08839514.2024.2389374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heat generated by electronic devices can lead to thermal deformation, damage, and fatigue failure, underscoring the importance of monitoring heat distribution. This study introduces an artificial neural network using two thermocouples for cost-effective temperature distribution prediction. Experimental data from heated systems on chip with attached heat sinks were used for training and validation, integrating thermocouple measurements and infrared camera data. The method’s applicability was verified across four different heat sinks. Additionally, finite element analysis compared stress and strain based on predicted and actual temperature distributions, addressing conventional limitations that focus solely on temperature validation. Furthermore, the temperature of any coordinate could be output by including the coordinate as an input of neural networks, eliminating the hassle of re-constructing or learning the DNN to obtain the temperature of the desired coordinate. Results showed that the temperature distribution could be predicted with high accuracy (over 0.95), and the maximum error rate for stress and strain predictions was 7% in the worst case. This confirmed the feasibility of artificial neural networks to predict the temperature distribution using a minimal number of sensors and ensure robust performance even if the heat sink changes.},
  archive      = {J_AAI},
  author       = {Jaehee Shin and Hyun Ahn and Gwang-Hyeon Mun and Jeongmin Lee and Pouria Zaghari and Young-Min Park and Jinhyoung Park and Jong Eun Ryu and Dong-Won Jang},
  doi          = {10.1080/08839514.2024.2389374},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2389374},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Deep neural network-based temperature mapping technique for heat sink on electronic devices using local thermocouple sensors},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Use of socio-economic, climatic, and land use land cover
patterns in solid waste forecasting with integrated gradient LSTNet
based model in lomé, togo. <em>AAI</em>, <em>38</em>(1), Article:
2387504. (<a
href="https://doi.org/10.1080/08839514.2024.2387504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few studies have explored recurrent neural network models in municipal solid waste (MSW) generation forecasting regarding the inefficiency of conventional and probabilistic tools. This study aimed to develop a new approach of Integrated Gradient Long- and Short-term Time series Network (LSTNet+IG)-based models, assess the baseline neural network models, and provide features influences explanation on MSW generation by using socio-economic, climatic, and Land Use Land Cover (LULC) patterns. Hence, the Random Forest Regressor and Gradient Boosting Regressor methods were used for feature selection, and the IG component was incorporated to LSTNet model for feature influence explanation alongside baseline models implementation. Moreover, the metrics such as root relative square error (RSE) and relative absolute error (RAE) were used to evaluate models’ performance. As a result, the LSTNet+IG outperforms others with the lowest RSE (0.9727) and RAE (0.9108). Moreover, five key influencing features were found, namely the number of households and institutions, mean relative humidity, electricity consumption, built area, and mean temperature. Hence, the socio-economic, climatic, and LULC features in MSW generation forecasting have shown to be important in decision-making for effective MSW management. Therefore, the LSTNet+IG model adoption by stakeholders could help to anticipate and mitigate MSW mismanagement through better planning.},
  archive      = {J_AAI},
  author       = {Kanlanféi Sambiani and Yendoubé Lare and Adamou Zanguina and Satyanarayana Narra},
  doi          = {10.1080/08839514.2024.2387504},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2387504},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Use of socio-economic, climatic, and land use land cover patterns in solid waste forecasting with integrated gradient LSTNet based model in lomé, togo},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring entropy measures with topological indices on
subdivided cage networks via linear regression analysis. <em>AAI</em>,
<em>38</em>(1), Article: 2387490. (<a
href="https://doi.org/10.1080/08839514.2024.2387490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigate entropy measurements for subdivided cage networks based on topological indices. We specifically calculate different entropy, redefining Zagreb entropy, HM ( G ) , M 1 ( G ) , M 2 ( G ) entropy, atom bond connection entropy, and Randic entropy. We examine the graphical behavior of various entropy measures using the line fit approach. The results highlight patterns in the distribution of entropy values and interactions between them, which shed light on the intricate connectivity and structural properties of segmented cage networks. This work improves our understanding of cage network dynamics and provides a visual framework for interpreting their behavior.},
  archive      = {J_AAI},
  author       = {Rongbing Huang and Muhammad Farhan Hanif and Muhammad Faisal Hanif and Muhammad Kamran Siddiqui and Mazhar Hussain and Eihab Bashier},
  doi          = {10.1080/08839514.2024.2387490},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2387490},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Exploring entropy measures with topological indices on subdivided cage networks via linear regression analysis},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive distributed consumer trust model for social
commerce. <em>AAI</em>, <em>38</em>(1), Article: 2385857. (<a
href="https://doi.org/10.1080/08839514.2024.2385857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumer trust is a crucial issue in social commerce, i.e. how to help consumers find trustworthy products. However, the current evaluation system in the market has significant shortcomings. This can be improved by trust and reputation modeling, but the existing models have flaws. This paper proposes an adaptive distributed trust model. The main features of its algorithm include (1) When calculating product trustworthiness, evaluations from consumers themselves, social networks, and e-commerce platforms are integrated, and the importance of these three sources of trust can change adaptively as consumers learn. (2) When selecting product providers and advisers, the Softmax algorithm is used to deal with the “exploration or exploitation” dilemma in reinforcement learning. (3) Consider the emotional attachment between consumers and advisers. (4) Design a blacklist mechanism to determine alternative product providers. The main contribution of this study lies in this model. Comparison with existing typical models shows that in various market scenarios, or when different market features change, this model can provide consumers with higher utility. This is because it better fits the characteristics of social commerce and has stronger adaptability. The results of this paper can not only provide a foundational model for related research but also can be used to develop a novel distributed product evaluation system for social commerce.},
  archive      = {J_AAI},
  author       = {Xiumu Weng and Ding Pan and Yun Jin},
  doi          = {10.1080/08839514.2024.2385857},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2385857},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An adaptive distributed consumer trust model for social commerce},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimized fake news classification: Leveraging ensembles
learning and parameter tuning in machine and deep learning methods.
<em>AAI</em>, <em>38</em>(1), Article: 2385856. (<a
href="https://doi.org/10.1080/08839514.2024.2385856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of misinformation across various domains necessitates robust detection mechanisms. With its ability to analyze vast datasets, machine learning emerges as a powerful tool. This research aims to explore fake news detection and emphasize the crucial role of preprocessing techniques. In addition to using individual models for training like SVMs, Logistic Regression, and LSTMs, we investigated the combined power of these methods through Stacking and Delegation. This paper analyzes frequently used preprocessing techniques like counter-vectorizer and TF-IDF to understand their impact on detection effectiveness. This is also aligned with the United Nations SDG 16, which seeks to promote informed decision-making by fighting against misinformation. The outcomes of this study underscored the significance of preprocessing steps for optimal classification performance. The ensemble methods consistently excelled, particularly with the probability-based stacking, achieving an AUC of 0.9394 and 0.9509 along with F1 Scores of 0.956248 and 0.945644. On the other hand, the delegation strategies also emerged as solid alternatives, with delegation (iterated) reaching AUCs of 0.9280 and 0.9477. The findings of this study confirm the efficacy of ensemble techniques and delegation for effective fake news detection. This study offers insights into model selection and optimization.},
  archive      = {J_AAI},
  author       = {Abubaker A. Alguttar and Osama A. Shaaban and Remzi Yildirim},
  doi          = {10.1080/08839514.2024.2385856},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2385856},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Optimized fake news classification: Leveraging ensembles learning and parameter tuning in machine and deep learning methods},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Fraud detection based on credit review texts with dual
channel memory networks. <em>AAI</em>, <em>38</em>(1), Article: 2385854.
(<a href="https://doi.org/10.1080/08839514.2024.2385854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the automotive finance market in China, fraudulent behaviors present new characteristics such as intellectualization and high concealment. Graph neural networks and memory networks have strong capabilities for processing the textual data containing massive complex associations, providing a new perspective for fraud detection. During the operation of an automotive finance company, a large amount of credit review texts with recording the customers’ multidimensional data are accumulated. These texts contain information that is helpful for risk management, but have not been well explored. In order to effectively identify fraud risks, we propose a fraud detection method based on credit review texts with dual-channel memory network, which combines graph and text memory networks. By utilizing pre-trained language models, the text data for credit review text is encoded into semantic vectors. The graph memory network module and the text memory network module are then employed to extract graph features and text features corresponding to the credit review text. Finally, the generated results from the three modules are fused and input into a classification network to obtain the final determination of financial fraud risk. Comparative experiments with baseline models demonstrate the validity of our model in fraud detection.},
  archive      = {J_AAI},
  author       = {Yansong Wang and Defu Lian and Enhong Chen},
  doi          = {10.1080/08839514.2024.2385854},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2385854},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Fraud detection based on credit review texts with dual channel memory networks},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new adapter tuning of large language model for chinese
medical named entity recognition. <em>AAI</em>, <em>38</em>(1), Article:
2385268. (<a
href="https://doi.org/10.1080/08839514.2024.2385268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) is a crucial step in extracting medical information from Chinese text, and fine-tuning large language models (LLMs) for this task is an effective approach. However, full parameter fine-tuning can potentially damage the model’s original parameters, resulting in catastrophic forgetting. To overcome this challenge, we introduce a novel adapter-based fine-tuning approach. Our adapter is integrated into the first and last transformers of the LLM, operating in parallel to the feed-forward network (FFN), following multi-head attention. It mirrors the FFN’s structure and uses the FFN’s weights for initializing. Additionally, to further enhance performance, we incorporate prefix embeddings into the first and last transformers. Our experiments on the Chinese medical NER benchmark demonstrate that our adapter, combined with prefix embeddings, achieves the highest F1-score of 65.90%, surpassing prompt templates (21.99%), in-context learning (18.65%), P-tuning (63.03%), and the benchmark for the Chinese medical NER task (62.40%). These results indicate that our adapter effectively fine-tunes the LLM for Chinese medical NER while preserving the original parameters.},
  archive      = {J_AAI},
  author       = {Lu Zhou and Yiheng Chen and Xinmin Li and Yanan Li and Ning Li and Xiting Wang and Rui Zhang},
  doi          = {10.1080/08839514.2024.2385268},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2385268},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A new adapter tuning of large language model for chinese medical named entity recognition},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic card fraud detection based on decision tree
algorithm. <em>AAI</em>, <em>38</em>(1), Article: 2385249. (<a
href="https://doi.org/10.1080/08839514.2024.2385249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper delves into the analysis of card fraud within the banking system. Its aim is to gain a comprehensive understanding of fraud in the banking sector and explore effective detection techniques. The paper examines advanced techniques such as data analysis, automatic learning algorithms, and real-time monitoring systems to detect suspicious patterns, anomalies, and deviations from normal behavior with precision. To achieve this, the research methodology employs a combination of qualitative and quantitative analysis. Furthermore, empirical research is conducted to evaluate the effectiveness of Machine Learning-based decision tree algorithms in identifying card fraud using real-world datasets. By understanding the nature of fraud and implementing robust detection methods, banks can safeguard their operations, assets, and customers, and uphold trust in the banking system.},
  archive      = {J_AAI},
  author       = {Elena Flondor and Liliana Donath and Mihaela Neamtu},
  doi          = {10.1080/08839514.2024.2385249},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2385249},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Automatic card fraud detection based on decision tree algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cyber battle management systems (CBMS) is considered as
systems of systems (SoS) and emergent behavior is present, where viable
system model (VSM) only controls system variety. <em>AAI</em>,
<em>38</em>(1), Article: 2384333. (<a
href="https://doi.org/10.1080/08839514.2024.2384333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript critically examines existing research on cyber battle management systems (CBMS) and underscores the importance of advancing complex structure thinking, cybernetics, wicked problem-solving, and emerging behavior analysis. It advocates for a systems-thinking approach to solving complex problems by identifying and understanding associated systems, predicting their behavior, and managing changes. The manuscript explores the integration of cybernetics meta-methodology and the viable system model with metasystems reductionism to address negative emergent behavior in complex systems. The study highlights the roles of individual systems, systems of systems, and metasystems, emphasizing the deterministic nature of single systems and the stochastic characteristics of systems of systems. By integrating cybernetics, viable system models, and meta-metasystems, the manuscript explores key parameters for building intelligent systems, revealing that meta-metasystems offer superior capabilities for coordinating and integrating multiple systems. The research results demonstrate the successful development of a meta-metasystem tailored for CBMS, providing a strategic framework for the future of cyber battle management.},
  archive      = {J_AAI},
  author       = {Aleksandar Seizovic and Steven Goh and David Thorpe and Lucas Skoufa},
  doi          = {10.1080/08839514.2024.2384333},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2384333},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Cyber battle management systems (CBMS) is considered as systems of systems (SoS) and emergent behavior is present, where viable system model (VSM) only controls system variety},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning for autonomous process control in
industry 4.0: Advantages and challenges. <em>AAI</em>, <em>38</em>(1),
Article: 2383101. (<a
href="https://doi.org/10.1080/08839514.2024.2383101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the integration of intelligent industrial process monitoring, quality prediction, and predictive maintenance solutions has garnered significant attention, driven by rapid advancements in digitalization, data analytics, and machine learning. As traditional production systems evolve into self-aware and self-learning configurations, capable of autonomously adapting to dynamic environmental and production conditions, the significance of reinforcement learning becomes increasingly apparent. This paper provides an overview of reinforcement learning developments and applications in the manufacturing industry. Various sectors within manufacturing, including robot automation, welding processes, the semiconductor industry, injection molding, metal forming, milling processes, and the power industry, are explored for instances of reinforcement learning application. The analysis focuses on application types, problem modeling, training algorithms, validation methods, and deployment statuses. Key benefits of reinforcement learning in these applications are identified. Particular emphasis is placed on elucidating the primary obstacles impeding the adoption and implementation of reinforcement learning technology in industrial settings, such as model complexity, accessibility to simulation environments, safety deployment constraints, and model interpretability. The paper concludes by proposing potential alternatives and avenues for future research to address these challenges, including improving sample efficiency and bridging the simulation-to-reality gap.},
  archive      = {J_AAI},
  author       = {Nuria Nievas and Adela Pagès-Bernaus and Francesc Bonada and Lluís Echeverria and Xavier Domingo},
  doi          = {10.1080/08839514.2024.2383101},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2383101},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Reinforcement learning for autonomous process control in industry 4.0: Advantages and challenges},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of encrypted network traffic for enhancing
cyber-security in dynamic environments. <em>AAI</em>, <em>38</em>(1),
Article: 2381882. (<a
href="https://doi.org/10.1080/08839514.2024.2381882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, encrypted data is the cornerstone of Internet communication, providing the maximum degree of privacy and security protection for all transmitted data while shielding users against potential cyber threats and attacks. However, since the Deep Packet Inspection (DPI) system is the primary layer of defense against numerous cyberattacks, applying encrypted network data poses severe issues for detection and prevention systems. In dynamic contexts such as the Internet of Things (IoT), detecting intrusion inside encrypted network traffic is vital. Yet, it is equally important to predict and prevent any cyber-attacks that may compromise the integrity and security of the network infrastructure. As a result, there is a fundamental need for methodologies based on intelligent analysis of patterns and attributes of encrypted network traffic. To satisfy security requirements in such a context, we propose an application of deep learning models for enhanced intrusion detection systems (IDS). The Tree-based Spider-Net Multipath (TBSNM) methodology is utilized, while an Advanced Encryption Standard (AES) technique is used to authenticate users. User selection is accomplished through robust Deep Reinforcement Learning with the Tabu Search (DRL-TS) algorithm, while channel selection is optimized through rigorous training employing Proximal Policy Optimization (PPO). Path selection is then determined by analyzing traffic statistics extracted from the Routing Information Protocol (RIP). Finally, an optimized IDS is established based on a Lightweight Deep Neural Network with Hunger Games Search and Remora Optimization Algorithm (LDNN-HGS-ROA). Evaluation results have shown that the proposed system architecture is effective in detecting attacks, achieving an enhanced IDS architecture with higher performance rates.},
  archive      = {J_AAI},
  author       = {Faeiz Alserhani},
  doi          = {10.1080/08839514.2024.2381882},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2381882},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Analysis of encrypted network traffic for enhancing cyber-security in dynamic environments},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting changeover events on manufacturing machines with
machine learning and NC data. <em>AAI</em>, <em>38</em>(1), Article:
2381317. (<a
href="https://doi.org/10.1080/08839514.2024.2381317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Changeover events occur in every industrial production when a machine is prepared and setup for production of the next product variant. Changeover times must be acquired with a high degree of validity for product cost calculations, order sequencing, and work schedules. The novelty of this article is a Machine Learning (ML) approach to automatically detect changeover events in production on manufacturing machines without direct human feedback. The machine learning approach uses several algorithms to classify different phases of the changeover process. The changeover of a milling process was defined using different phase concepts (2-phases, 6-phases, 23-phases) to be applicable to other types of manufacturing machines. Different machine learning methods were compared. The best results for the F1 score were achieved with the Random Forest , the CatBoost , and the Extra Trees algorithm (2-phases: 99.4–99.7%, 6-phases: 85.2–85.9%, 23-phases: 77.7–79.4%). It is shown that detecting changeover events can be realized based on data from an NC of a manufacturing machine without data from external sensors (2-phases: 98.9%, F1 score).},
  archive      = {J_AAI},
  author       = {Bastian Engelmann and Anna-Maria Schmitt and Moritz Heusinger and Vladyslav Borysenko and Niklas Niedner and Jan Schmitt},
  doi          = {10.1080/08839514.2024.2381317},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2381317},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Detecting changeover events on manufacturing machines with machine learning and NC data},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive coati optimization enabled deep CNN-based image
captioning. <em>AAI</em>, <em>38</em>(1), Article: 2381166. (<a
href="https://doi.org/10.1080/08839514.2024.2381166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of providing a natural language description of graphical information of the image is known as image captioning. As a result, it needs an algorithm to create a series of output words and understand the relations between textual and visual elements. The main goal of this research is to caption the image by extracting the features and detecting the object from the image. Here, the object is detected by employing Deep Embedding Clustering. The features from the input image are extracted such as Local Vector Pattern (LVP), Spider Local Image Features, and some statistical features like mean, variance, standard deviation, kurtosis, and skewness. The extracted features and detected objects are given to image captioning which is exploited by Deep Convolutional Neural Network (Deep CNN). The Deep CNN is trained by using the proposed Adaptive Coati Optimization Algorithm (ACOA). The proposed ACOA is attained by the integration of the Adaptive concept and Coati Optimization Algorithm (COA) and thus the image is captioned. The proposed ACOA achieved maximum values in the training data such as 90.5% of precision, 89.9% of recall 89.1% of F1-Score, 90.4% of accuracy, 90.4% of BELU, and 90.9% of ROUGE.},
  archive      = {J_AAI},
  author       = {Balasubramaniam S and Seifedine Kadry and Rajesh Kumar Dhanaraj and Satheesh Kumar K},
  doi          = {10.1080/08839514.2024.2381166},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2381166},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Adaptive coati optimization enabled deep CNN-based image captioning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trading strategy of the cryptocurrency market based on deep
q-learning agents. <em>AAI</em>, <em>38</em>(1), Article: 2381165. (<a
href="https://doi.org/10.1080/08839514.2024.2381165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As of December 2021, the cryptocurrency market had a market value of over US$270 billion, and over 5,700 types of cryptocurrencies were circulating among 23,000 online exchanges. Reinforcement learning (RL) has been used to identify the optimal trading strategy. However, most RL-based optimal trading strategies adopted in the cryptocurrency market focus on trading one type of cryptocurrency, whereas most traders in the cryptocurrency market often trade multiple cryptocurrencies. Therefore, the present study proposes a method based on deep Q-learning for identifying the optimal trading strategy for multiple cryptocurrencies. The proposed method uses the same training data to train multiple agents repeatedly so that each agent has accumulated learning experiences to improve its prediction of the future market trend and to determine the optimal action. The empirical results obtained with the proposed method are described in the following text. For Ethereum, VeChain, and Ripple, which were considered to have an uptrend, a horizontal trend, and a downtrend, respectively, the annualized rates of return were 725.48%, −14.95%, and − 3.70%, respectively. Regardless of the cryptocurrency market trend, a higher annualized rate of return was achieved when using the proposed method than when using the buy-and-hold strategy.},
  archive      = {J_AAI},
  author       = {Chester S. J. Huang and Yu-Sheng Su},
  doi          = {10.1080/08839514.2024.2381165},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2381165},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Trading strategy of the cryptocurrency market based on deep Q-learning agents},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent food safety: A prediction model based on
attention mechanism and reinforcement learning. <em>AAI</em>,
<em>38</em>(1), Article: 2379731. (<a
href="https://doi.org/10.1080/08839514.2024.2379731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food safety emerges as a locus of heightened concern across societal strata. The establishment of a robust bulwark, embodied in an adept food detection mechanism and prescient early warning system, assumes paramount importance in safeguarding the populace. As artificial intelligence strides forward in the realm of food safety, this investigation endeavors to address the challenge of prognosticating the compliance rate of food safety through a unified RL-ALSTM (Reinforcement learning-attention-long-short term memory) framework, amalgamating reinforcement learning, attention mechanism, and Long Short-Term Memory (LSTM). Anchored by historical correlation data and food-specific attributes, the framework initiates its journey by deploying a dual-layer LSTM network to extract salient features. Subsequently, the model undergoes feature augmentation via attention mechanism and reinforcement learning methodologies, culminating in the realization of highly precise food safety predictions. Examination of experimental outcomes, leveraging both public and internally curated datasets, attests that the performance of the RL-ALSTM approach, as gauged by Root Mean Square Error (RMSE) and Mean Absolute Error (MAE), surpasses that of the disparate LSTM and traditional machine learning methods by lower than 0.001 in the safety ratio. This contribution furnishes a theoretical and methodological foundation for prospective advancements in the realm of food safety prediction.},
  archive      = {J_AAI},
  author       = {Mingxia Wu and Wei Liu and Shengyang Zheng},
  doi          = {10.1080/08839514.2024.2379731},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2379731},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Intelligent food safety: A prediction model based on attention mechanism and reinforcement learning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic detection and 3D reconstruction of buildings from
historical maps. <em>AAI</em>, <em>38</em>(1), Article: 2378274. (<a
href="https://doi.org/10.1080/08839514.2024.2378274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an automatic 3D building reconstruction methodology for historical urban maps. It uses facade and openings detection on the maps, followed by rectification, regularization, and 3D model generation techniques. Evaluation metrics confirm the effectiveness of the approach, with high accuracy in detecting facades and their openings while maintaining geometric integrity. The flexibility and interoperability of the chosen 3D building representation method allow for adjustments in dimensions without compromising layout, making it suitable for completing the urban environments where facades may not be directly visible. This methodology represents a significant step toward automating the reconstruction of 3D historical urban landscapes, contributing to heritage preservation and architectural understanding.},
  archive      = {J_AAI},
  author       = {Fernando Pérez Nava and Isabel Sánchez Berriel},
  doi          = {10.1080/08839514.2024.2378274},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2378274},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Automatic detection and 3D reconstruction of buildings from historical maps},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time bearing fault classification of induction motor
using enhanced inception ResNet-v2. <em>AAI</em>, <em>38</em>(1),
Article: 2378270. (<a
href="https://doi.org/10.1080/08839514.2024.2378270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rolling bearing is a vital part used in different rotating electrical devices. Detecting defects in bearings is crucial for the safe operation of these machines. However, it is challenging to use Deep Learning techniques to identify bearing defects when the machine is not under load. To resolve this issue, this paper presents the Constant-Q Non-stationary Gabor Transform with enhanced Inception ResNet-V2, proposed for the early-stage classification of ball bearing faults in induction motors. The proposed model obtained the vibration images, i.e. time-frequency images of unfiltered vibration signals from the laboratory experimental setup. These images are applied to the proposed model, which classifies the ball bearing faults under various load conditions while adjusting its hyperparameter values instead of employing default ones. Furthermore, the model underwent training using k-fold method to assess its resilience with the use of optimal values obtained from hyperparameter tuning. The model is evaluated by performance metrics like F1-score, Recall, Precision, Confusion Matrix and Training time. The proposed model accomplished an average classification accuracy of 99.84% in low load and full load conditions within a few epochs. Ultimately, when compared to Inception-V4 and ResNet-50, which achieved 91.41% and 91.65%, respectively, the experimental findings unambiguously demonstrate the superior performance of the proposed model over both models.},
  archive      = {J_AAI},
  author       = {Karan Kumar K and Srihari Mandava},
  doi          = {10.1080/08839514.2024.2378270},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2378270},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Real-time bearing fault classification of induction motor using enhanced inception ResNet-v2},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized performance of LSTM in time-series forecasting.
<em>AAI</em>, <em>38</em>(1), Article: 2377510. (<a
href="https://doi.org/10.1080/08839514.2024.2377510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing the time-series forecasting performance is a multi-objective problem which enables the comparison of general applicability of methods across multiple use cases such as finance and demographics. Libra, a time-series forecasting framework which shifts the problem of optimization from minimizing single to multiple evaluation measures and use cases, is used as a benchmark to evaluate the performance of the Long Short-Term Memory (LSTM) neural network. LSTMs with parameter tuning have been shown to perform well with time-series forecasting. This paper applies LSTMs (mostly with standard parameters and variations of some of them) to the Libra framework and concludes that due to data characteristic variance and without increased hardware and time constraints LSTMs do not outperform the median measures of Libra.},
  archive      = {J_AAI},
  author       = {Ryan Prater and Thomas Hanne and Rolf Dornberger},
  doi          = {10.1080/08839514.2024.2377510},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2377510},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Generalized performance of LSTM in time-series forecasting},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A generalized and robust nonlinear approach based on machine
learning for intrusion detection. <em>AAI</em>, <em>38</em>(1), Article:
2376983. (<a
href="https://doi.org/10.1080/08839514.2024.2376983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection systems (IDS) play a critical role in ensuring the security and integrity of computer networks. There is a constant demand for the development of powerful, novel, and generalized methods for IDS that can accurately detect and classify intrusions. In this study, we aim to evaluate the benefits of linear classifiers (LC) and nonlinear classifiers (NLC) in IDS. We employed ten machine learning (ML) classifiers, consisting of five LC and five NLC. These classifiers underwent cross-validation for performance evaluation, unseen analysis, statistical tests, and power analysis on measuring the minimum sample size. Four hypotheses were formulated and validated on five processed intrusion attack datasets. NLC outperformed LC, with a mean accuracy (ACC)/area-under-the-curve (AUC) increase of 22.26%/20.3% on the WUSTL-EHMS dataset, with improvements of ACC/AUC by 5.5%/2.3% on the UNSW-NB15 dataset. In the unseen analysis, NLC achieved an ACC/AUC increase of 21.9%/21.8% when trained on WUSTL-EHMS and tested on UNSW-NB15. Lastly, when using a mixed dataset of WUSTL-EHMS and UNSW-NB15, NLC demonstrated an ACC/AUC increase of 11.67%/5.5%. The model performed well in cross-validation protocols, and the statistical tests yielded significant p-values. NLC provides generalized and robust solutions to detect intrusion attacks, ensuring the integrity and security of computer networks.},
  archive      = {J_AAI},
  author       = {Jakiur Rahman and Jaskaran Singh and Soumen Nayak and Biswajit Jena and Lopamudra Mohanty and Narpinder Singh and John R. Laird and Rajesh Singh and Deepak Garg and Narendra N. Khanna and Mostafa M. Fouda and Luca Saba and Jasjit S. Suri},
  doi          = {10.1080/08839514.2024.2376983},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2376983},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A generalized and robust nonlinear approach based on machine learning for intrusion detection},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design and deployment of ML in CRM to identify leads.
<em>AAI</em>, <em>38</em>(1), Article: 2376978. (<a
href="https://doi.org/10.1080/08839514.2024.2376978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s era, organizations are increasingly prioritizing process automation to optimize efficiency and drive sales. One area where Machine Learning (ML) techniques can be particularly valuable is in automating tasks such as lead classification for sales. In Jupyter Notebooks, logistic regression was utilized to design and to train a model to accurately predict whether a lead will convert into a client or not. Then, in Azure Machine Learning Studio which is a Machine Learning Operations platform (MLOps), the Two-Class Logistic Regression algorithm was used to design a pipeline, train a model, and deploy a web service, which is consumed by Salesforce system through an Apex code. The web service receives the variables of a particular lead record and then returns the prediction as a numeric ranking. By leveraging these ML techniques, firm’s resources can strategically be focused for maximum effectiveness. Overall, our work involves a C# windows application to extract CRM marketing interactions, leveraging the power of ML, a logistic regression model in AML and Apex code. This approach enables us to drive efficiency, enhance sales outcomes, and allocate resources more effectively.},
  archive      = {J_AAI},
  author       = {Alonso Yocupicio-Zazueta and Agustin Brau-Avila and Federico Cirett-Galán and Margarita Valenzuela-Galván},
  doi          = {10.1080/08839514.2024.2376978},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2376978},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Design and deployment of ML in CRM to identify leads},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An algorithmic multiple attribute decision-making context to
model uncertainty associated with hospital site selection problem using
complex sv-neutrosophic soft information. <em>AAI</em>, <em>38</em>(1),
Article: 2375110. (<a
href="https://doi.org/10.1080/08839514.2024.2375110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making approaches are often used in uncertain environments by people who must make difficult judgments in daily life, including elements of varied qualities and costs. These methods assist decision-makers in managing ambiguity and uncertainty, allowing for more informed and risk-reduced decisions. This research introduces an advanced framework called a complex single-valued neutrosophic soft set (csvNSS) to address uncertainties inherent in decision-making. The csvNSS framework is capable of managing information periodicity by introducing two components: amplitude and phase. The first deals with fuzzy membership, while the second manages periodicity within a complex plane. Some rudiments of csvNSS like properties, set operations and aggregations, are investigated. To make these ideas practically applicable in choosing an appropriate location for the hospital, an algorithm for handling csvNSS is proposed. An enhanced strategy is validated through the use of a specific example that takes site selection for hospital into account. The outcome demonstrates the efficacy of the suggested strategy. The method can be used in other domains where selection issues arise.},
  archive      = {J_AAI},
  author       = {Khuram Ali Khan and Ali Asghar and Atiqe Ur Rahman and Rostin Matendo Mabela},
  doi          = {10.1080/08839514.2024.2375110},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2375110},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An algorithmic multiple attribute decision-making context to model uncertainty associated with hospital site selection problem using complex sv-neutrosophic soft information},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bio-inspired ACO-based traffic aware QoS routing in software
defined internet of things. <em>AAI</em>, <em>38</em>(1), Article:
2371739. (<a
href="https://doi.org/10.1080/08839514.2024.2371739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising number of Internet of Things (IoT) devices, powered by inexpensive sensors and rapid wireless connections, places challenge on existing internet infrastructure and concerns sustainability issues. For networks to satisfy Quality-of-Service (QoS) standards in the Software-Defined IoT (SDIoT) network, efficient algorithms for routing are required. In SDIoT framework, this research proposes to develop a traffic-aware QoS routing algorithm dependent on ant behavior. In order to enhance QoS routing metrics, this work proposes an Ant Colony Optimization (ACO) based algorithm that focuses IoT device flows that are jitter, delay, and loss-sensitive. The proposed approach optimizes overall network performance with utilizing the fewest resources possible by optimizing the routing path to meet application-specific QoS standards using Yen’s k shortest path algorithm. The suggested approach outperforms current techniques in terms of fulfilling all three types of flows, resulting in sustained network performance enhancements of 5.25% in average delay, 5.15% in QoS-violated flows with Ant-inspired routing, 7% in average packet loss, and 4.65% in average jitter. This research provides an efficient practical way to deal with the growing challenges that IoT applications are posing for network sustainability.},
  archive      = {J_AAI},
  author       = {Shreyas J and Anand Jumnal and Udayaprasad P K and Rekha C and S. S. Askar and Mohamed Abouhawwash},
  doi          = {10.1080/08839514.2024.2371739},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2371739},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Bio-inspired ACO-based traffic aware QoS routing in software defined internet of things},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An image-text sentiment analysis method using multi-channel
multi-modal joint learning. <em>AAI</em>, <em>38</em>(1), Article:
2371712. (<a
href="https://doi.org/10.1080/08839514.2024.2371712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis is a technical approach that integrates various modalities to analyze sentiment tendencies or emotional states. Existing challenges encountered by this approach include redundancy in independent modal features and a lack of correlation analysis between different modalities, causing insufficient fusion and degradation of result accuracy. To address these issues, this study proposes an innovative multi-channel multimodal joint learning method for image-text sentiment analysis. First, a multi-channel feature extraction module is introduced to comprehensively capture image or text features. Second, effective interaction of multimodal features is achieved by designing modality-wise interaction modules that eliminate redundant features through cross-modal cross-attention. Last, to consider the complementary role of contextual information in sentiment analysis, an adaptive multi-task fusion method is used to merge single-modal context features with multimodal features for enhancing the reliability of sentiment predictions. Experimental results demonstrate that the proposed method achieves an accuracy of 76.98% and 75.32% on the MVSA-Single and MVSA-Multiple datasets, with F1 scores of 76.23% and 75.29%, respectively, outperforming other state-of-the-art methods. This research provides new insights and methods for advancing multimodal feature fusion, enhancing the accuracy and practicality of sentiment analysis.},
  archive      = {J_AAI},
  author       = {Lianting Gong and Xingzhou He and Jianzhong Yang},
  doi          = {10.1080/08839514.2024.2371712},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2371712},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An image-text sentiment analysis method using multi-channel multi-modal joint learning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring different dynamics of recurrent neural network
methods for stock market prediction - a comparative study. <em>AAI</em>,
<em>38</em>(1), Article: 2371706. (<a
href="https://doi.org/10.1080/08839514.2024.2371706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate and unpredictable nature of stock markets underscores the importance of precise forecasting for timely detection of downturns and subsequent rebounds. Various factors, including news, rumors surrounding events or companies, market sentiments, and governmental policies, can significantly impact stock prices. Nevertheless, the precision of current methods remained insufficient until the adoption of artificial neural network architectures like long short-term memory (LSTM). The aim of this study is to create a precise AI-driven platform tailored for both the Indian and international stock markets. This platform is designed to assist retail investors in navigating digital environments by employing various LSTM algorithms. Its primary goals include predicting stock price fluctuations, pinpointing potential investment prospects, and refining trading strategies. The application aims to leverage advanced LSTM algorithms to analyze historical market data, recognize patterns, and provide real-time insights. It will take past price and process it through LSTM algorithms to take a logical decision. In the quest to broaden retail participation in the capital markets, the effort is to develop an application for novice investors who either have no time in research or are the victims of financial mis-selling and enable them to leverage the technology to their advantage.},
  archive      = {J_AAI},
  author       = {Ajit Mohan Pattanayak and Aleena Swetapadma and Biswajit Sahoo},
  doi          = {10.1080/08839514.2024.2371706},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2371706},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Exploring different dynamics of recurrent neural network methods for stock market prediction - A comparative study},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Air quality index prediction using DNN-markov modeling.
<em>AAI</em>, <em>38</em>(1), Article: 2371540. (<a
href="https://doi.org/10.1080/08839514.2024.2371540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air quality measurements contribute to diverse socio-economic sectors, including the environment and healthcare. Many methods are commonly applied to present air-quality levels, reflecting differing national standards. This study presents an air quality index prediction model, to measure air pollution levels for healthcare applications in congested areas. DNN-Markov modeling techniques are used to predict air quality, based on environmental conditions at peak hours. The developed model presents different approaches for highly accurate prediction of the air quality index for the next hour at a given location, under specific environmental conditions. This system could be used to support planning decisions related to the consequences of air quality. The study was conducted in selected locations in Jordan and England as a comparative model prediction accuracy study using different big-data sets of multivariate time series in traffic-heavy locations. The air quality index was represented using Neuro Fuzzy Logic as a method to contribute in air quality index predictions within blurry (boundary) values. The selected DNN-Markov hybrid model could predict air quality with accuracy of around (RMSE 7.86) for the location in England, and around (RMSE 15.27) for the one in Jordan.},
  archive      = {J_AAI},
  author       = {Roba Zayed and Maysam Abbod},
  doi          = {10.1080/08839514.2024.2371540},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2371540},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Air quality index prediction using DNN-markov modeling},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding university students’ acceptance of ChatGPT:
Insights from the UTAUT2 model. <em>AAI</em>, <em>38</em>(1), Article:
2371168. (<a
href="https://doi.org/10.1080/08839514.2024.2371168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current study explores the determinants of ChatGPT adoption and utilization among a sample of Norwegian university students. The theoretical perspective of the study is anchored in the Unified Theory of Acceptance and Use of Technology (UTAUT2) and based on a previously tested model. The proposed model integrates six constructs to explain the Behavioral intentions and actual usage patterns of ChatGPT in a higher education context. The study analyzed responses from 104 students attending Universities in West and Central Norway using the partial-least squares approach to structural equation modeling. The data showed that performance expectancy emerged as the construct with the biggest impact on Behavioral intention, followed by Habit. This study contributes to the research on the factors influencing university students’ engagement with generative AI technologies. Furthermore, it contributes to a more comprehensive understanding of how tools like ChatGPT can be integrated effectively in educational contexts in both students learning and instructors teaching.},
  archive      = {J_AAI},
  author       = {Simone Grassini and Maren Linnea Aasen and Anja Møgelvang},
  doi          = {10.1080/08839514.2024.2371168},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2371168},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Understanding university students’ acceptance of ChatGPT: Insights from the UTAUT2 model},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Path planning of UAV using levy pelican optimization
algorithm in mountain environment. <em>AAI</em>, <em>38</em>(1),
Article: 2368343. (<a
href="https://doi.org/10.1080/08839514.2024.2368343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome the issues of simple strategy and easy fall into local optimum when solving UAV 3D path planning problem, we propose an improved Levy Pelican Optimization Algorithm (LPOA) that incorporates the hunter-prey algorithm and solves the UAV 3D path planning problem based on the improved LPOA. Based on the original algorithm, on the one hand, we introduce Levy flight and adaptive parameters to update the pelican position, balance the algorithm development phase and exploration phase, and effectively avoid the problem of falling into local optimum at the early stage of the algorithm. On the other hand, we use chaotic mapping to initialize the population, integrate the prey generation strategy to enhance the prey generation formula and improve algorithm orientation and convergence speed. The test results are compared and analyzed with those of classical, current mainstream, and recently released swarm intelligence optimization algorithms. Using 3D mountain range model experiments, the algorithm is compared before and after optimization, and the improved optimization algorithm is then applied to the actual problem of UAV 3D path planning. Research has found that the improved LPOA optimizes the total target cost of the algorithm by 9.75% and optimizes the planned average shortest path by 20.30%.},
  archive      = {J_AAI},
  author       = {Guiliang Zhou and Shuaiqi Lü and Lina Mao and Kaiwen Xu and Tianwen Bao and Xu Bao},
  doi          = {10.1080/08839514.2024.2368343},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2368343},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Path planning of UAV using levy pelican optimization algorithm in mountain environment},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward data-driven and multi-scale modeling for material
flow simulation: Characteristic analysis of modeling methods.
<em>AAI</em>, <em>38</em>(1), Article: 2367840. (<a
href="https://doi.org/10.1080/08839514.2024.2367840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Material flow simulation is a powerful tool to realize efficient operations in complicated production systems such as high-mix and low-volume production. Nevertheless, great effort and expertise are necessary to construct accurate simulation models. We have proposed a semi-automatic modeling approach designated as data-driven and multi-scale modeling. The approach combines various modeling methods to maximize the simulation accuracy. This article introduces the proposed method and presents the experimentally obtained results for simple production systems to examine the characteristics of modeling methods based on queue models or machine learning models. The results of computational experiments indicate that the superiority and inferiority of modeling methods depend on the complexity of the system and the background knowledge about the activity configuration in the system.},
  archive      = {J_AAI},
  author       = {Satoshi Nagahara and Toshiya Kaihara and Nobutada Fujii and Daisuke Kokuryo},
  doi          = {10.1080/08839514.2024.2367840},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2367840},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Toward data-driven and multi-scale modeling for material flow simulation: Characteristic analysis of modeling methods},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-paragraph machine reading comprehension with hybrid
reader over tables and text. <em>AAI</em>, <em>38</em>(1), Article:
2367820. (<a
href="https://doi.org/10.1080/08839514.2024.2367820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In machine reading comprehension, answers to questions may be found in either text or tables. Previous studies have shown that table-specific pre-trained language models perform well when applied to tables; however, applying such models to input data that consists of both tables and text can be challenging. To address this issue, we introduce the hybrid reader model that can manage both tables and text using a modified K-Adapter architecture for effectively encoding the structured information of tables. The training process infuses knowledge for tabular data into a pre-trained model while retaining its original weights from pre-training. Hence, the pre-trained model is able to learn and utilize table information without sacrificing its previous training. Our proposed hybrid reader model achieved comparable or superior performance to that of a specialized model on the Korean MRC dataset, KorQuAD 2.0, using the provided adapters. Furthermore, we conducted experiments on an additional English MRC dataset and confirmed that our proposed model achieves performance comparable to that of the existing model. Our study indicates that employing a single hybrid model instead of two separate models can require fewer computing resources and less time while achieving comparable or superior performance, especially for techniques that apply projection and adapter.},
  archive      = {J_AAI},
  author       = {Sanghyun Cho and SeongReol Park and Hye-Lynn Kim and Jung-Hun Lee and JoongMin Shin and Hyuk-Chul Kwon},
  doi          = {10.1080/08839514.2024.2367820},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2367820},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Multi-paragraph machine reading comprehension with hybrid reader over tables and text},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MobileDepth: Monocular depth estimation based on lightweight
vision transformer. <em>AAI</em>, <em>38</em>(1), Article: 2364159. (<a
href="https://doi.org/10.1080/08839514.2024.2364159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As deep learning takes off, monocular depth estimation based on convolutional neural networks (CNNs) has made impressive progress. CNNs are superior at extracting local characteristics from a single image; however, they are unable to manage long-range dependence and thus have a substantial impact on the performance of monocular depth estimation. In addition to this, as architectures based on CNNs frequently utilize down sampling operations, numbers of pixel-level features, which are extremely crucial for dense prediction tasks, are lost in the encoder phase. Unlike CNNs, ViT is capable of capturing global feature information, but it requires numbers of parameters and data augmentation owing to its lack of inductive bias. To address the aforementioned difficulties, in this study, we propose a Dilated Self Attention Block (DSAB) as well as a Local and Global Feature Extraction (LGFE) module. The former resolves the inference speed issue of standard ViT models, and we accomplish this by limiting the number of self-attention computations among tokens. The latter combines the advantages of CNNs and ViT, first extracting local representation information in low-dimensional space through standard convolution and then mapping the input tensor to high-dimensional space to capture global information, achieving the simultaneous extraction of global and local characteristics.},
  archive      = {J_AAI},
  author       = {Yundong Li and Xiaokun Wei},
  doi          = {10.1080/08839514.2024.2364159},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2364159},
  shortjournal = {Appl. Artif. Intell.},
  title        = {MobileDepth: Monocular depth estimation based on lightweight vision transformer},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An empirical job matching model based on expert human
knowledge: A mixed-methods approach. <em>AAI</em>, <em>38</em>(1),
Article: 2364158. (<a
href="https://doi.org/10.1080/08839514.2024.2364158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our research objective was to develop a model that calculates the affinity between candidates and job descriptions. We focused specifically on the fields of data science and software development. This endeavor addressed the challenge posed by the need for a systematic method for its evaluation. To overcome these obstacles, we adopted a mixed-methods design. This approach enabled us to identify two findings. Firstly, the essential elements that must be included in CVs to render them a valuable information source. Secondly, a comprehensive and systematic benchmark for human-level performance. We studied the candidate selection processes. The above involved the participation of professionals in these fields who, as part of their routine duties, are responsible for identifying, evaluating, and selecting job candidates for their teams. Subsequently, we designed a binary candidate-job matching model using Siamese networks in conjunction with the Choquet integral. This model’s original architecture combines a data-driven learning method with one for representing expert knowledge in decision-making. We assessed the effectiveness of this model against the established human-level performance. Our study highlights the challenges in effectively capturing professional preferences and biases in the candidate selection process. It provides insights into the complexities of integrating expert judgment into automated recruitment tools.},
  archive      = {J_AAI},
  author       = {María Elena Martínez-Manzanares and Jordan Joel Urias-Paramo and Julio Waissman-Vilanova and Gudelia Figueroa-Preciado},
  doi          = {10.1080/08839514.2024.2364158},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2364158},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An empirical job matching model based on expert human knowledge: A mixed-methods approach},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective skin cancer diagnosis through federated learning
and deep convolutional neural networks. <em>AAI</em>, <em>38</em>(1),
Article: 2364145. (<a
href="https://doi.org/10.1080/08839514.2024.2364145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer is a prevalent type of cancer that affects millions of people globally. However, detecting it can be a challenging task, even for specialized dermatologists. Early detection is crucial for successful treatment, and deep learning techniques, particularly deep convolutional neural networks (DCNNs), have shown tremendous potential in this area. However, achieving high accuracy results requires large volumes of data for training these DCNNs. Since medical organizations and institutions, individually, do not usually have such amounts of information available, and due to the current regulations regarding intellectual property and privacy of medical patient data, it is difficult to share data in a direct way. The primary objective of this work is to overcome this issue through a federated learning approach. We created a privacy-preserving and accurate skin cancer classification system that can assist dermatologists and specialists in making informed patient care decisions. The federated learning DCNNs architecture uses a combination of convolutional and pooling layers to extract relevant features from skin lesion images. It also includes a fully connected layer for classification. To evaluate the proposed architecture, we tested it on three datasets of varying complexity and size. The results demonstrate the applicability of the proposed solution and its efficiency for skin cancer classification.},
  archive      = {J_AAI},
  author       = {Mabrook S. Al-Rakhami and Salman A. AlQahtani and Abdulaziz Alawwad},
  doi          = {10.1080/08839514.2024.2364145},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2364145},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Effective skin cancer diagnosis through federated learning and deep convolutional neural networks},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Logistic resource allocation based on multi-agent supply
chain scheduling using meta-heuristic optimization algorithms.
<em>AAI</em>, <em>38</em>(1), Article: 2362516. (<a
href="https://doi.org/10.1080/08839514.2024.2362516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logistics resource allocation depends on the precise scheduling of Supply Chain (SC) agents. Coordination of management across all sites, products, and production divisions is essential for effective scheduling. For multi-agent systems in heterogeneous SCs, it is crucial to have a prior understanding of production, delivery, and connectivity. Hence, an innovative meta-heuristic optimization inspired by sparrow behavior is introduced as multi-agent-based scheduling and resource allocation (MA-SRA) to resolve delivery delays and errors during delivery in logistic SC management. Allocating resources efficiently and creating workable schedules in an SC with multiple agents are the primary significant problems focused on in this research. The MA-SRA algorithm provides an achievable solution to the problem of optimizing logistics operations by combining precise scheduling with production balance and multi-agent searchers. If the scheduling operations are inadequate, sparse agents are repurposed for production based on fitness. This maintains balance and connectivity by adjusting agent ratios. Delays are minimized, and connectivity is maximized because no adjustments need to be reversed. The research findings show that the proposed approach improves operational efficiency and brings significant advantages to the industry in terms of enhanced allocation of resources, connectivity, delivery efficiency, and fewer delays and scheduling errors.},
  archive      = {J_AAI},
  author       = {Lingjie Bu},
  doi          = {10.1080/08839514.2024.2362516},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2362516},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Logistic resource allocation based on multi-agent supply chain scheduling using meta-heuristic optimization algorithms},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Developing machine learning-based control charts for
monitoring different GLM-type profiles with different link functions.
<em>AAI</em>, <em>38</em>(1), Article: 2362511. (<a
href="https://doi.org/10.1080/08839514.2024.2362511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In certain situations, the quality of a process is determined by dependent variables in relation to independent variables, often modeled through a regression framework referred to as a profile. The practice of monitoring and preserving this relationship is known as profile monitoring. In this paper, we propose an innovative approach that uses different machine-learning (ML) techniques for constructing control charts and monitoring generalized linear model (GLM) profiles with three different GLM-type response distributions of Binomial, Poisson, and Gamma, and by examining different link functions for each response distribution. Through our simulation study, we undertake a comparative analysis of different training methods. We measure the charts’ performance using the average run length, which signifies the average number of samples taken before observing a data point that exceeds the predefined control limits. The result shows that the selection of ML control charts is contingent on the response distribution and link function, and depends on the shift sizes in the process and the utilized training method. To illustrate the practical application of the proposed ML control charts, we present two real-world cases as examples: a drug–response study and a volcano-eruption study, to demonstrate how each ML chart can be implemented in practice.},
  archive      = {J_AAI},
  author       = {Patrik Hric and Hamed Sabahno},
  doi          = {10.1080/08839514.2024.2362511},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2362511},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Developing machine learning-based control charts for monitoring different GLM-type profiles with different link functions},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generation of vessel track characteristics using a
conditional generative adversarial network (CGAN). <em>AAI</em>,
<em>38</em>(1), Article: 2360283. (<a
href="https://doi.org/10.1080/08839514.2024.2360283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) models often require large volumes of data to learn a given task. However, access and existence of training data can be difficult to acquire due to privacy laws and availability. A solution is to generate synthetic data that represents the real data. In the maritime environment, the ability to generate realistic vessel positional data is important for the development of ML models in ocean areas with scarce amounts of data, such as the Arctic, or for generating an abundance of anomalous or unique events needed for training detection models. This research explores the use of conditional generative adversarial networks (CGAN) to generate vessel displacement tracks over a 24-hour period in a constraint-free environment. The model is trained using Automatic Identification System (AIS) data that contains vessel tracking information. The results show that the CGAN is able to generate vessel displacement tracks for two different vessel types, cargo ships and pleasure crafts, for three months of the year (May, July, and September). To evaluate the usability of the generated data and robustness of the CGAN model, three ML vessel classification models using displacement track data are developed using generated data and tested with real data.},
  archive      = {J_AAI},
  author       = {Jessica N.A Campbell and Martha Dais Ferreira and Anthony W. Isenor},
  doi          = {10.1080/08839514.2024.2360283},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2360283},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Generation of vessel track characteristics using a conditional generative adversarial network (CGAN)},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Performance evaluation of hybrid machine learning algorithms
for online lending credit risk prediction. <em>AAI</em>, <em>38</em>(1),
Article: 2358661. (<a
href="https://doi.org/10.1080/08839514.2024.2358661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peer-to-Peer systems are still in the early stages of development when it comes to the processing of credit and the appraisal of the risk associated with it. In this study, we used a hybrid convolutional neural network with logistic regression, a gradient-boosting decision tree, and a k-nearest neighbor to predict the credit risk in a P2P lending club. The lending clubs publicly available P2P loan data was used to train the model. In order to address the issue of data imbalance within the dataset, specifically between the non-defaulter and defaulter classes, the synthetic minority oversampling technique sampling approach is utilized. We developed the architecture of our hybrid model by removing the fully connected layer with the soft-max, which is the final layer of the fully connected CNN model and replaced by LR, GBDT, and k-NN algorithms. The experimental results show that the hybrid CNN-kNN model outperforms the CNN-GBDT and CNN-LR models based on the performance metrics accuracy, recall, F1-score, and area under the curve for both all input and important features. This shows that hybrid machine learning models effectively identify and categorize credit risk in peer-to-peer lending clubs, hence assisting in financial loss prevention.},
  archive      = {J_AAI},
  author       = {Tesfahun Berhane and Tamiru Melese and Abdu Mohammed Seid},
  doi          = {10.1080/08839514.2024.2358661},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2358661},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Performance evaluation of hybrid machine learning algorithms for online lending credit risk prediction},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Applied artificial intelligence and prospect of internet of
everything (IoE) for the detection of tuberculosis. <em>AAI</em>,
<em>38</em>(1), Article: 2358654. (<a
href="https://doi.org/10.1080/08839514.2024.2358654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mycobacterium tuberculosis is a bacterium that causes disease known as Tuberculosis. Tuberculosis is highly contagious and can result in high mortality rate if left untreated. In order to screen individuals suspected of the disease, medical expert relies on several conventional approaches which are hindered by several limitations which include time consuming, high workload, false positive results, etc. This calls for the need to develop smart and automatic approaches that can address these challenges. Majority of existing studies reported the use of 1 or 2 pretrained models and the use of SoftMax as the classifier. Moreover, majority of the studies trained models using a single type of dataset which are mostly curated from public accessible domains. Thus, this study addressed these challenges by: (1) The use of several pretrained models (2) The use of 2 classifiers which include SVM and KNN and (3) Training and validating pretrained models fused with classifiers on microscopic slide and chest X-ray images. The result achieved in this study highlights the prospect of computer-assisted techniques in triaging and screening of TB. The integration of Internet of Everything (IoE) in medical diagnosis has the potential to increase healthcare outcome, boost productivity, and reduce workload.},
  archive      = {J_AAI},
  author       = {Ibrahim Omodamilola and Abdullahi Umar Ibrahim and Süleyman Aşır and Fadi Al-Turjman},
  doi          = {10.1080/08839514.2024.2358654},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2358654},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Applied artificial intelligence and prospect of internet of everything (IoE) for the detection of tuberculosis},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Statement of retraction. <em>AAI</em>, <em>38</em>(1),
Article: 2357925. (<a
href="https://doi.org/10.1080/08839514.2024.2357925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AAI},
  doi          = {10.1080/08839514.2024.2357925},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2357925},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Statement of retraction},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bi-modal bi-task emotion recognition based on transformer
architecture. <em>AAI</em>, <em>38</em>(1), Article: 2356992. (<a
href="https://doi.org/10.1080/08839514.2024.2356992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of emotion recognition, analyzing emotions from speech alone (single-modal speech emotion recognition) has several limitations, including limited data volume and low accuracy. Additionally, single-task models lack generalization and fail to fully utilize relevant information. To address these issues, this paper proposes a new bi-modal bi-task emotion recognition model. The proposed model introduces multi-task learning on the Transformer architecture. On one hand, unsupervised contrastive predictive coding is used to extract denser features from the data while preserving self-information and context-related information. On the other hand, model robustness against interfering information is enhanced by employing self-supervised contrastive learning. Furthermore, the proposed model utilizes a modality fusion module to incorporate textual and audio information to implicitly align features from both modalities. The proposed model achieved accuracy rates of 82.3% and 83.5% on the IEMOCAP and RAVDESS datasets, respectively, when considering weighted accuracy (WA). When weight is not considered (unweighted accuracy (UA)), the model achieved 83.0% and 82.4% accuracy. Compared to the existing methods, the performance is further improved.},
  archive      = {J_AAI},
  author       = {Yu Song and Qi Zhou},
  doi          = {10.1080/08839514.2024.2356992},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2356992},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Bi-modal bi-task emotion recognition based on transformer architecture},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Entropy-based deep neural network training optimization for
optical coherence tomography imaging. <em>AAI</em>, <em>38</em>(1),
Article: 2355760. (<a
href="https://doi.org/10.1080/08839514.2024.2355760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an optimization technique for the number of training epochs needed for deep learning models. The proposed method eliminates the need for separate validation data and significantly decreases training epochs. Using a four-class Optical Coherence Tomography (OCT) image dataset encompassing Choroidal Neovascularization (CNV), Diabetic Macular Edema (DME), Drusen, and Normal retina categories, we evaluated twelve architectures. These include general-purpose models (Alexnet, VGG11, VGG13, VGG16, VGG19, ResNet-18, ResNet-34, and ResNet-50) and OCT image-specific models (RetiNet, AOCT-NET, DeepOCT, and Octnet). The proposed technique reduced training epochs ranging from 4.35% to 58.27% for all architectures except Alexnet. Although the overall increase in accuracy ranges from 0.28% to 12.6%, with some architectures experiencing minor improvements, this is seen as acceptable considering the substantial reduction in training time. By achieving higher accuracy with fewer training epochs and eliminating the need for separate validation data, our methodology streamlines early stopping significantly. Statistical evaluations via Shapiro-Wilk and Kruskal-Wallis tests further affirm these results, showcasing the potential of this novel technique for efficient deep learning practices in scenarios constrained by time or computational resources.},
  archive      = {J_AAI},
  author       = {Karri Karthik and Manjunatha Mahadevappa},
  doi          = {10.1080/08839514.2024.2355760},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2355760},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Entropy-based deep neural network training optimization for optical coherence tomography imaging},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced sub-graph reconstruction graph neural network for
recommendation. <em>AAI</em>, <em>38</em>(1), Article: 2355425. (<a
href="https://doi.org/10.1080/08839514.2024.2355425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized recommendation can recommend items of interest to different users and is widely used in the real world. Among them, graph collaborative filtering is a method of personalized recommendation. It can enrich the connection between users and items on the basis of collaborative filtering, to learn the embedded representation of nodes more accurately. Since graph collaborative filtering is based on bipartite graphs, few exciting graph collaborative methods consider the relationships between users (or items), the message between homogeneous nodes are diluted or ignored. Predicting and constructing the relationship between users (or items) has become a challenging. To solve this problem, we propose an enhanced sub-graph reconstruction graph neural network for recommendation (SRCF), using a heterogeneous graph neural network based encoder-decoder learn potential relationships between users (or items), and reconstruct sub-graphs based on those relationships. In the proposed model, the information of user and item sub-graphs is merged with the network of graph collaborative filtering, which enhances effective information transfer between homogeneous nodes, thereby improving the model performance. We have selected a number of data sets of different scenarios and different scales to comprehensively evaluate the performance of the model, and the experimental results confirmed the superiority of our model.},
  archive      = {J_AAI},
  author       = {Zhe Liu and Xiaojun Lou and Jian Li and Guanjun Liu},
  doi          = {10.1080/08839514.2024.2355425},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2355425},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Enhanced sub-graph reconstruction graph neural network for recommendation},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Handling imbalanced classification problems by weighted
generalization memorization machine. <em>AAI</em>, <em>38</em>(1),
Article: 2355424. (<a
href="https://doi.org/10.1080/08839514.2024.2355424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced classification problems are of great significance in life, and there have been many methods to deal with them, e.g. eXtreme Gradient Boosting (XGBoost), Logistic Regression (LR), Decision Trees (DT), and Support Vector Machine (SVM). Recently, a novel Generalization-Memorization Machine (GMM) was proposed to maintain good generalization ability with zero empirical for binary classification. This paper proposes a Weighted Generalization Memorization Machine (WGMM) for imbalanced classification. By improving the memory cost function and memory influence function of GMM, our WGMM also maintains zero empirical risk with well generalization ability for imbalanced classification learning. The new adaptive memory influence function in our WGMM achieves that samples are described individually and not affected by other training samples from different category. We conduct experiments on 31 datasets and compare the WGMM with some other classification methods. The results exhibit the effectiveness of the WGMM.},
  archive      = {J_AAI},
  author       = {Chen Dou and Yan Lv and Zhen Wang and Lan Bai},
  doi          = {10.1080/08839514.2024.2355424},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2355424},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Handling imbalanced classification problems by weighted generalization memorization machine},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bagging vs. Boosting in ensemble machine learning? An
integrated application to fraud risk analysis in the insurance sector.
<em>AAI</em>, <em>38</em>(1), Article: 2355024. (<a
href="https://doi.org/10.1080/08839514.2024.2355024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the pressing challenge of insurance fraud, which significantly impacts financial losses and trust within the insurance industry, this study introduces an innovative automated detection system utilizing ensemble machine learning (EML) algorithms. The approach encompasses four strategic phases: 1) Tackling data imbalance through diverse re-sampling methods (Over-sampling, Under-sampling, and Hybrid); 2) Optimizing feature selection (Filtering, Wrapping, and Embedding) to enhance model accuracy; 3) employing binary classification techniques (Bagging and Boosting) for effective fraud identification; and 4) applying explanatory model analysis (Shapley Additive Explanations, Break-down plot, and variable-importance Measure) to evaluate the influence of individual features on model performance. Our comprehensive analysis reveals that while not every re-sampling technique improves model performance, all feature selection methods markedly bolster predictive accuracy. Notably, the combination of the Gradient Boosting Machine (GBM) algorithm with NCR re-sampling and GBMVI feature selection emerges as the most effective configuration, offering superior fraud detection capabilities. This study not only advances the theoretical framework for combating insurance fraud through AI but also provides a practical blueprint for insurance companies aiming to incorporate advanced AI strategies into their fraud detection arsenals, thereby mitigating financial risks and fostering trust systems.},
  archive      = {J_AAI},
  author       = {Ruixing Ming and Osama Mohamad and Nisreen Innab and Mohamed Hanafy},
  doi          = {10.1080/08839514.2024.2355024},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2355024},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Bagging vs. boosting in ensemble machine learning? an integrated application to fraud risk analysis in the insurance sector},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep recurrent reinforcement learning for intercept guidance
law under partial observability. <em>AAI</em>, <em>38</em>(1), Article:
2355023. (<a
href="https://doi.org/10.1080/08839514.2024.2355023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the rapid development of hypersonic vehicles brings great challenges to the missile defense system. As achieving successful interception depends highly on terminal guidance laws, research on guidance laws for intercepting highly maneuvering targets has aroused increasing attention. Artificial intelligence technologies, such as deep reinforcement learning (DRL), have been widely applied to improve the performance of guidance laws. However, the existing DRL guidance laws rarely consider the partial observability problem of onboard sensors, resulting in the limitations of their engineering applications. In this paper, a deep recurrent reinforcement learning (DRRL)-based guidance method is investigated to address the intercept guidance problem against maneuvering targets under partial observability. The sequence consisting of previous state observations is utilized as the input of the policy network. A recurrent layer is introduced into the networks to extract hidden information behind the temporal sequence to support policy training. The guidance problem is formulated as a partially observable Markov decision process model, and then a range-weighted reward function that considers the line-of-sight rate and energy consumption is designed to guarantee convergence of policy training. The effectiveness of the proposed DRRL guidance law is validated by extensive numerical simulations.},
  archive      = {J_AAI},
  author       = {Xu Wang and Yifan Deng and Yuanli Cai and Haonan Jiang},
  doi          = {10.1080/08839514.2024.2355023},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2355023},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Deep recurrent reinforcement learning for intercept guidance law under partial observability},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence to facilitate the conceptual stage
of interior space design: Conditional generative adversarial
network-supported long-term care space floor plan design of retirement
home buildings. <em>AAI</em>, <em>38</em>(1), Article: 2354090. (<a
href="https://doi.org/10.1080/08839514.2024.2354090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study uses Conditional Generative Adversarial Network (CGAN) to construct a method for generating floor plans for long-term care spaces in retirement home buildings to assist architects in improving interior space design. The results of this study show the following: (1) For the interior design of long-term care spaces in retirement home buildings, the CGAN model has strong understanding and calculation capabilities. The zoning layout of long-term care spaces in retirement home buildings has been completed, and the results show that the CGAN model has reference value. (2) Although there are several differences in the design of CGANs and authentic design, there are still many similarities. Some unreasonable results, such as space generation in corridors and elevator shafts, require further manual correction. (3) According to a later questionnaire survey on the satisfaction of architects and CGAN model design solutions, the difference between the two is not large, which also illustrates the great potential of CGANs for intervention in interior space design. This helps architects create more detailed plans based on the model, greatly increasing work efficiency. Moreover, additional interior space design possibilities can be explored, and to some extent, the architect’s subjective assumptions can also be corrected.},
  archive      = {J_AAI},
  author       = {Yanyu Li and Huanhuan Chen and Jingyi Mao and Yile Chen and Liang Zheng and Junjie Yu and Lina Yan and Lulu He},
  doi          = {10.1080/08839514.2024.2354090},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2354090},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Artificial intelligence to facilitate the conceptual stage of interior space design: Conditional generative adversarial network-supported long-term care space floor plan design of retirement home buildings},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-step dynamic ensemble selection to estimate software
effort. <em>AAI</em>, <em>38</em>(1), Article: 2351718. (<a
href="https://doi.org/10.1080/08839514.2024.2351718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Effort Estimation (SEE) is a foremost concern of software companies in order to successfully develop and deliver software products within a defined budget and time. Many software companies fail to deliver the product on time, either due to problems of over-estimation or under-estimation. In order to aid the decision-making process of the analyst and experts, the paper proposed a multi-step dynamic ensemble selection (MS-DES) approach. The DES works in two steps; I) in order to select the suitable models from the pool of models, which are anticipated to perform best when generating a prediction. II) to predict the labeled discretized effort more accurately. The paper utilized four software effort datasets discretized into labeled effort ranges. The performance of the proposed model is evaluated based on the K nearest neighbor oracle (KNORA) canonical approach to DES and in order to reduce the complexity, filter feature selection techniques are applied to extract the relevant feature set. The proposed feature selection-based MS-DES model outplayed the individual models in predicting labeled effort in terms of confusion metrics parameters with an accuracy of more than 90% with all datasets and the results are validated using the ROC curve.},
  archive      = {J_AAI},
  author       = {Akshay Jadhav and Shishir Kumar Shandilya and Ivan Izonin and Roman Muzyka},
  doi          = {10.1080/08839514.2024.2351718},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2351718},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Multi-step dynamic ensemble selection to estimate software effort},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An evaluation method of dental treatment quality combined
with deep learning and multi-index decomposition. <em>AAI</em>,
<em>38</em>(1), Article: 2351714. (<a
href="https://doi.org/10.1080/08839514.2024.2351714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dentists judge that the quality of dental treatment for each patient is very time-consuming and inefficient, lacks quantitative evaluation criteria, and is easy to cause errors. At the same time, the traditional method of extracting tooth and root canal image features based on experience is difficult to accurately extract the tooth area and root canal filling area, resulting in low accuracy of tooth and root canal segmentation, which in turn affects the accuracy of tooth treatment quality evaluation. In this paper, a deep learning convolutional neural network is used to segment the root canal filling area, tooth boundary, and the boundary between tooth and soft tissue for the real patient ‘s root canal treatment and filling image. Finally, the segmented image is quantitatively evaluated according to the multi-evaluation index of professional doctors. The experimental results show that the intelligent evaluation method of dental treatment quality combined with deep learning and multi-index decomposition proposed in this paper not only unifies the evaluation criteria of dental treatment quality but also the therapeutic effect of quantitative scoring can effectively improve the work efficiency of doctors, which has reference significance for the application of artificial intelligence in the medical field.},
  archive      = {J_AAI},
  author       = {Gang Peng and Jie Liu and Feng Yan and Beicun Liu},
  doi          = {10.1080/08839514.2024.2351714},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2351714},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An evaluation method of dental treatment quality combined with deep learning and multi-index decomposition},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Applying the cheetah algorithm to optimize resource
allocation in the fog computing environment. <em>AAI</em>,
<em>38</em>(1), Article: 2349982. (<a
href="https://doi.org/10.1080/08839514.2024.2349982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the application of heuristic and meta-heuristic algorithms to address resource allocation challenges in Internet of Things (IoT) applications within fog computing environments. The primary advantage of these algorithms lies in their ability to optimize functions without the need for stringent restrictions, allowing adaptability to various linear, nonlinear, continuous, or discrete problems. Through the implementation and comparison of the Cheetah algorithm, Gray Wolf algorithm, Particle Swarm-Gravitational Search algorithm, and Gray Wolf-Cuckoo Search algorithm using MATLAB software in a simulation environment, the study aims to minimize criterion function and total time and energy consumption for IoT applications. Preliminary results indicate that the statistical average performance of the Cheetah algorithm surpasses that of the Gray Wolf algorithm, the combined Particle Swarm-Gravitational Search algorithm, and the Gray Wolf-Cuckoo Search algorithm. This suggests the efficacy of the Cheetah algorithm in IoT resource allocation optimization within fog computing environments. The study provides insights into the comparative performance of these algorithms, laying the foundation for further exploration into enhancing resource allocation strategies in the dynamic and resource-constrained IoT and fog computing landscapes.},
  archive      = {J_AAI},
  author       = {Fatemeh Arvaneh and Faraneh Zarafshan and Abbas Karimi},
  doi          = {10.1080/08839514.2024.2349982},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2349982},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Applying the cheetah algorithm to optimize resource allocation in the fog computing environment},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeFRCN-MAM: DeFRCN and multi-scale attention mechanism-based
industrial defect detection method. <em>AAI</em>, <em>38</em>(1),
Article: 2349981. (<a
href="https://doi.org/10.1080/08839514.2024.2349981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the technology development, industrial defect detection based on deep learning has attracted extensive attention in the academic community. Different from general visual objects, industrial defects have the characteristics of small sample, weak visibility and irregular shape, which hinder the application of related studies. According to these problems, a few-shot object detection (FSOD) method based on Decoupled Faster R-CNN (DeFRCN) is proposed in this paper. Firstly, it includes fine-tuning processing, because of the small sample characteristics. To adapt to the invisible characteristics of defects, we introduce the Feature Pyramid Network (FPN) and Residual Attention Module (RAM) into DeFRCN, which can enhance the capture ability of multi-scale features and feature association information. Furthermore, the feature representation ability is strengthened by parallel connecting of two channels, consisting of R-CNN head, box classifier and box regression models. Finally, it is completed that the pre-training, fine-tuning and testing of the proposed network, with DAGM 2007 and NEU-DET public industrial defect datasets as the base class and flange shaft defect data collected in the laboratory as the new class. To verify the effectiveness of the proposed one, we compare them with other classical FSOD methods. The superiority of the proposed method is obvious.},
  archive      = {J_AAI},
  author       = {Tong Zheng and Liangbing Sa and Chongchong Yu and Aibin Song},
  doi          = {10.1080/08839514.2024.2349981},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2349981},
  shortjournal = {Appl. Artif. Intell.},
  title        = {DeFRCN-MAM: DeFRCN and multi-scale attention mechanism-based industrial defect detection method},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A human-in-one-loop active domain adaptation framework for
digit recognition. <em>AAI</em>, <em>38</em>(1), Article: 2349410. (<a
href="https://doi.org/10.1080/08839514.2024.2349410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation can effectively enhance a model’s performance on target domain data with limited data. However, when some target domain labels are obtainable, training the model with both source and target domain data simultaneously can lead to worse performance due to the lower density of target domain data. If a large amount of target domain data is labeled without discrimination, it will necessitate a considerable expenditure of human resources. To address this issue, this paper proposes a human-in-one-loop active domain adaptation framework based on Target Domain Feature Generation to solve the problems. The oracle participates in only one iteration of data labeling, and a target domain classifier will take over the subsequent rest iterations. An image generator based on multiple CycleGANs forms an iterative co-training mechanism, which can continuously generate more high-quality labeled fake target domain data in iterations to improve the performance of the target domain classifier. The Top-N labeled data selection method with high confidence is devised to select the most accurately predicted data for labeling, reducing manual labeling workload. This framework can achieve an average accuracy of 0.8869 on six domain pairs, doubling the classical domain adaptation method DSN, requiring only a small amount of manual labeling.},
  archive      = {J_AAI},
  author       = {Hao Xiu and Guanchen Li and Jie He and Xiaotong Zhang and Yue Qi},
  doi          = {10.1080/08839514.2024.2349410},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2349410},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A human-in-one-loop active domain adaptation framework for digit recognition},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Precision in insurance forecasting: Enhancing potential with
ensemble and combination models based on the adaptive neuro-fuzzy
inference system in the egyptian insurance industry. <em>AAI</em>,
<em>38</em>(1), Article: 2348413. (<a
href="https://doi.org/10.1080/08839514.2024.2348413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing the precision of retention ratio predictions holds profound significance for insurance industry decision-makers and those vested in advancing insurance services. Precision helps insurance companies navigate inflationary pressures and evaluate underwriting profitability, enabling reliable prognoses of future underwriting gains. As far as we know, although there have been multiple attempts to construct a predictive model for retention ratio, none of these attempts have used combining models or studied the Egyptian market. Therefore, this study contributes significantly to this developing field by providing combining models, which combined statistical time series models such as Exponential Smoothing (ES), and Autoregressive Integrated Moving Average (ARIMA), with Adaptive Neuro-Fuzzy Inference System (ANFIS). Two different types of combinations are employed with these models. Furthermore, the study introduces three ensemble models designed for the purpose of predicting the retention ratio within the Egyptian insurance market. Dataset was carefully gathered from the EFSA’s annual reports, focused on the property-liability insurance sector within the Egyptian insurance market and covers the time period from 1989 to 2021. Next, the proposed models are assessed employing well-established statistical assessment metrics, namely, Mean Absolute Error (MAE), Mean Absolute Percent Error (MAPE), R Square (R 2 ), and Root Mean Square Error (RMSE). The results show that combining and ensemble methods improve predicted accuracy. A multi-linear regression-based ensemble model that combines ARIMA, ES, and ANFIS models outperforms both single and combined models in robustness. The article concludes that the insurance industry can greatly benefit from modern predictive methods to make sound decisions.},
  archive      = {J_AAI},
  author       = {Ahmed Khalil and Zaiming Liu and Ahmed Ali},
  doi          = {10.1080/08839514.2024.2348413},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2348413},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Precision in insurance forecasting: Enhancing potential with ensemble and combination models based on the adaptive neuro-fuzzy inference system in the egyptian insurance industry},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Event assignment based on KBQA for government service
hotlines. <em>AAI</em>, <em>38</em>(1), Article: 2348162. (<a
href="https://doi.org/10.1080/08839514.2024.2348162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Government service hotlines are closely related to people’s lives, and the hotline events assignment task is very important in China, which affects people’s satisfaction with the Chinese government. To address the challenge of improving hotline event assignment accuracy, which is currently hindered by the lack of prior knowledge in the traditional direct departmental assignment approach, we introduce a novel hotline event assignment model based on Knowledge Base Question Answering (KBQA) to leverage prior knowledge and enhance assignment performance. The model extracts event key information by using event extraction module, and the key information of event extracte by this module is used to construct historical events knowledge graph. Then we employ subgraph retrieval module and text retrieval module to obtain relevant prior knowledge from the knowledge graph and “sanding” text respectively. The integrated prior knowledge is then used to predict department scores, guiding the selection of the optimal assignment department through ranking. The experiment results show that the proposed method outperforms existing baseline methods. Meanwhile, the Knowledge Graph (KG) edge elimination experiment also shows that the proposed model is better than other baseline models in terms of incomplete KG.},
  archive      = {J_AAI},
  author       = {Yongzhang Wang and Defu Lian and Enhong Chen},
  doi          = {10.1080/08839514.2024.2348162},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2348162},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Event assignment based on KBQA for government service hotlines},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An event log repair method based on masked transformer
model. <em>AAI</em>, <em>38</em>(1), Article: 2346059. (<a
href="https://doi.org/10.1080/08839514.2024.2346059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effectiveness of business process analysis heavily relies on the quality of event logs. However, the presence of outliers and missing values often compromises the integrity of event logs, consequently exerting adverse effects on process analysis and associated decision-making. Existing log repair research mainly focuses on the reconstruction of missing activity, whereas few efforts are carried out from the perspective of predicting missing activity. This paper introduces a log repair approach based on a masked Transformer, which innovatively combines the self-attention mechanism of Transformers with the task of event log repair. Firstly, by employing various masking strategies, we simulate diverse low-quality event log scenarios that may occur in practical situations. Subsequently, a Masked Language Model is trained on preprocessed datasets to predict masked activities by leveraging contextual information within traces, thereby capturing behavioral information of activities in the event log. Upon completion of model training, we apply it to real event log data for repair tasks. The proposed approach, originating from the perspective of event logs, does not rely on any a priori knowledge related to business process models for generating event logs. Experimental results demonstrate that the masked Transformer-based approach outperforms baseline methods in most event log repair tasks.},
  archive      = {J_AAI},
  author       = {Ping Wu and Xianwen Fang and Huan Fang and Ziyou Gong and Daoyu Kan},
  doi          = {10.1080/08839514.2024.2346059},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2346059},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An event log repair method based on masked transformer model},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying the AI-based solutions proposed for restricting
money laundering in financial sectors: Systematic mapping. <em>AAI</em>,
<em>38</em>(1), Article: 2344415. (<a
href="https://doi.org/10.1080/08839514.2024.2344415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Money laundering (ML) is a critical source of extracting the money illegally from the financial system. It is linked to various types of crimes, including corruption, exploitation of a specific community, drug use, and many others. Detection of ML operations is a difficult task on a global scale due to the large volume of financial transactions. However, it also allows criminals to use financial systems to carry out fraudulent transactions. It mainly concern minimizing the potentially risks associated with money laundering. Anti-money laundering-(AML) tools based on AI-driven applications are now tracking transactions to overcome this challenge. A total of 112 research papers are assessed to identify the literature’s gaps and suggest new directions for the research area accordingly. The findings of this systemic literature review work will not only open new paths for the research community, but will also assist the state agencies in developing an optimal AML system to counter these major issues and provide a healthy environment for their residents. This article seeks to assess the existing situation from various angles and open up new pathways for future research directions to investigate and build high levels of authenticity and security in the financial industry using artificial intelligence (AI).},
  archive      = {J_AAI},
  author       = {Habib Ullah Khan and Muhammad Zain Malik and Shah Nazir},
  doi          = {10.1080/08839514.2024.2344415},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2344415},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Identifying the AI-based solutions proposed for restricting money laundering in financial sectors: Systematic mapping},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel method for reducing vehicle emissions utilizing
IoT-based IS-APCPSO algorithm. <em>AAI</em>, <em>38</em>(1), Article:
2344144. (<a
href="https://doi.org/10.1080/08839514.2024.2344144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban road traffic network optimization based on the Internet of Things (IoT) is one of the important methods to reduce vehicle exhaust and ease traffic congestion. A two-level planning model on road traffic network optimization in IoT and the IS-APCPSO algorithm is deployed, which can effectively solve the above problems. The experimental results show that the total vehicle emissions of the proposed scheme are lower than those of traditional schemes. Moreover, the real-time perception, interactive coupling, and coordinated control of “people-vehicle-road-environment” can be achieved through the use of the IoT. We discuss the sensitivity of the model to establish a scene selection that takes into account different regional and road traffic conditions, avoiding the subjective randomness in model parameter selection. A novel multi-objective method based on IoT proposed in this paper helps to alleviate “urban diseases,” such as traffic congestion, vehicle emissions, and energy waste, and to emphasize the overall benefits of energy-saving and emission reduction in urban road networks. By setting up traffic lights reasonably and guiding the driver behavior, the integrated control and management of traffic flow and exhaust emission under multiple driving cycles are realized.},
  archive      = {J_AAI},
  author       = {Ke Huang and Jianjun Zhu},
  doi          = {10.1080/08839514.2024.2344144},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2344144},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A novel method for reducing vehicle emissions utilizing IoT-based IS-APCPSO algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing MIMO antenna isolation with novel electromagnetic
band gap (EBG) structure and genetic algorithm optimization.
<em>AAI</em>, <em>38</em>(1), Article: 2344143. (<a
href="https://doi.org/10.1080/08839514.2024.2344143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel Electromagnetic Band Gap (EBG) structure is proposed to minimize common connector between closely spaced rectangular patch antennas. The 2D EBG architecture is placed on the horizontal plane of a 1/2 rectangle patch antenna array, reducing mutual coupling by over 20 dB without compromising far-field performance, gain, or bandwidth. By optimizing the EBG structure using a genetic algorithm, noise is reduced by −60 dB compared to −25 dB without it, improving the isolation of the antenna array. Inserting 3 EBG modules between the two patches decreases the 2.45 GHz mutual coupling to −60 dB, showcasing the significant enhancement in isolation. This MIMO antenna design with an EBG structure is suitable for wireless LAN communication systems, offering improved signal separation and performance. The proposed method integrates square patch antennas operating at 24 GHz with a metamaterial EBG structure on a Rogers R04350B substrate, using a genetic algorithm for optimization. Experimental results demonstrate over 22 dB improvement in isolation between antenna elements, maintaining consistent radiation patterns across frequencies.},
  archive      = {J_AAI},
  author       = {Shalini E and Prakash G},
  doi          = {10.1080/08839514.2024.2344143},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2344143},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Enhancing MIMO antenna isolation with novel electromagnetic band gap (EBG) structure and genetic algorithm optimization},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid secure cluster-based routing algorithm for enhanced
security and efficiency in mobile ad hoc networks. <em>AAI</em>,
<em>38</em>(1), Article: 2341357. (<a
href="https://doi.org/10.1080/08839514.2024.2341357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research addresses critical gaps in Mobile Ad hoc Networks (MANETs) by proposing a hybrid secure cluster-based routing algorithm, focusing on enhancing network security, robustness, and reliability through multipath routing. Methodologically, the approach integrates Convolutional Neural Networks (CNN) for optimal path routing and Emperor Penguin Optimization (EPO) for clustering, introducing a novel combination for efficient cluster head selection. A novel contribution lies in the development of a prediction technique utilizing a trust assessment algorithm to calculate direct trust ratings at each node, incorporating fuzzy values between zero and one. Trust values are further influenced by node performance, adding a dynamic dimension to the trust evaluation process. Key novelties include the emphasis on energy efficiency, network longevity, remaining energy, security level, bandwidth, and packet delivery ratio as evaluation criteria. The proposed CNN-EPO model demonstrates superior results compared to traditional routing protocols, achieving a remarkable 95% energy efficiency, a heightened security level of 99%, and a throughput reaching up to 8 Mbps. Additionally, the Packet Delivery Ratio (PDR) attains close to 99% and routing overhead remains below 0.5, ensuring efficiency in challenging network scenarios with 50 adversaries. In summary, this research contributes a comprehensive solution to MANET challenges, introducing a novel hybrid routing algorithm, incorporating advanced methodologies for path optimization and clustering. These outcomes highlight how important the suggested strategy is to improve the existing state of the art in MANETs.},
  archive      = {J_AAI},
  author       = {Aravindan S and Rajaram A},
  doi          = {10.1080/08839514.2024.2341357},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2341357},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Hybrid secure cluster-based routing algorithm for enhanced security and efficiency in mobile ad hoc networks},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predication of water pollution peak concentrations by hybrid
BP artificial neural network coupled with genetic algorithm.
<em>AAI</em>, <em>38</em>(1), Article: 2341356. (<a
href="https://doi.org/10.1080/08839514.2024.2341356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water pollutions can severely affect water environment, causing water quality degradation and threatening aquatic wildlife. Deemed as guideline for maximum environmental impact assessment, water pollution peak concentration (WPPC) has been intensively studied to organize effective countermeasures. In this study, a back propagation artificial neural network (BPANN) coupled with genetic algorithm (GA) was constructed to predict peak concentrations. Compared with BPANN, multiple linear regressions model (MLRM) and step-wise multiple linear regressions model (SMLRM), GA-BPANN model showed superior accuracy in both simulating and predicting peak concentrations (R 2 = 0.93 and 0.67 0.69 respectively). In 12 peak concentration cases, GA-BPANN model’s mean absolute relative error (MARE) ranges from 0.0 to 0.58, averaged at 0.09, significantly lower than BPANN, MLRM and SMLRM ( MARE = 0.29, 0.45 and 0.48). Further analysis revealed that GA-BPANN model can be used as an effective and efficient tool for water quality simulation and early warning prediction.},
  archive      = {J_AAI},
  author       = {Yanbo Lu and Tong Li and Ying Deng},
  doi          = {10.1080/08839514.2024.2341356},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2341356},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Predication of water pollution peak concentrations by hybrid BP artificial neural network coupled with genetic algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A security-enhanced advertising platform based on blockchain
and edge computing in generative AI. <em>AAI</em>, <em>38</em>(1),
Article: 2340395. (<a
href="https://doi.org/10.1080/08839514.2024.2340395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of advertising technology, especially the emergence of generative artificial intelligence, the generation and editing of advertising content has become more convenient and efficient. However, this also brings new security risks to digital advertising. For example, in order to generate personalized advertising content, AI can collect user behavior data without the user’s knowledge and automatically generate ads that are beneficial to advertisers. In addition, the main issue regarding outdoor advertising is whether the outdoor advertising platform can deliver the advertising content required by the advertiser at the designated place and time according to the actual requirements of the customer. Combining blockchain and edge computing technology, this paper builds a security-enhanced outdoor advertising platform. The decentralized, non-tamperable and traceable features of blockchain technology provide the advertising platform with credibility between users and advertisers, as well as credibility between advertisers and the advertising platform. At the same time, the terminal controller with edge processing capabilities improves the efficiency of advertising and enhances the task balance between the server and the playback side. Experimental results show that the platform can effectively manage user identities and maintain advertising plans. It not only improves data security and credibility, but also has good performance.},
  archive      = {J_AAI},
  author       = {Zhengjun Jing and Xiaolong Xu and Chunseng Gu and Yan Zhang and Qiang Shu},
  doi          = {10.1080/08839514.2024.2340395},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2340395},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A security-enhanced advertising platform based on blockchain and edge computing in generative AI},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Utilizing machine learning techniques for classifying
translated and non-translated corporate annual reports. <em>AAI</em>,
<em>38</em>(1), Article: 2340393. (<a
href="https://doi.org/10.1080/08839514.2024.2340393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globalization has led to the widespread adoption of translated corporate annual reports in international markets. Nonetheless, it remains largely unexplored whether these translated documents fulfill the same function and communicate as effectively to international investors as their non-translated counterparts. Considering their significance to stakeholders, differentiating between these two types of reports is essential, yet research in this area is insufficient. This study seeks to bridge this gap by leveraging machine learning algorithms to classify corporate annual reports based on their translation status. By constructing corpora of comparable texts and employing thirteen syntactic complexity indices as features, we analyzed the reports using eight different algorithms: Naïve Bayes, Logistic Regression, Support Vector Machine, k-Nearest Neighbors, Neural Network, Random Forest, Gradient Boosting and Deep Learning. Additionally, ensemble models were created by combining the three most effective algorithms. The best-performing model in our study achieved an Area Under the Curve (AUC) of 99.3%. This innovative approach demonstrates the effectiveness of syntactic complexity indices in machine learning for classifying translational language in corporate reporting, contributing valuable insights to text classification and translational language research. Our findings offer critical implications for stakeholders in multilingual contexts, highlighting the need for further research in this field.},
  archive      = {J_AAI},
  author       = {Zhongliang Wang and Ming Liu and Kanglong Liu},
  doi          = {10.1080/08839514.2024.2340393},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2340393},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Utilizing machine learning techniques for classifying translated and non-translated corporate annual reports},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing vocal performance using variational onsager neural
network and optimized with golden search optimization algorithm.
<em>AAI</em>, <em>38</em>(1), Article: 2340389. (<a
href="https://doi.org/10.1080/08839514.2024.2340389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Singing Muscle Ability Training System (SMATS) represents a cutting-edge technological solution dedicated to honing an individual’s vocal prowess. By employing a sophisticated combination of techniques, exercises, and methodologies, this system strategically targets and cultivates the muscle groups integral to singing. In its innovative approach, SMATS integrates Artificial Intelligence (AI) to elevate vocal capabilities further. The proposed SMATS-AI-VONN-GSOA stands out by incorporating the Variational Onsager Neural Network (VONN) alongside the Golden Search Optimization Algorithm (GSOA). This amalgamation tailors training routines based on the user’s progress and preferences, emphasizing the development of muscle memory and control for enhanced vocal performance. Noteworthy is the system’s capacity to analyze data through AI, enabling the creation of personalized training plans. In comparative evaluations, the SMATS-AI-VONN-GSOA method demonstrates a significant performance boost, surpassing existing methods like SMATS-AI-CNN, SMATS-AI-DNN, and SMATS-AI-DNN-HSV by 26.78%, 29.55%, and 21.41% in accuracy, respectively.},
  archive      = {J_AAI},
  author       = {Lian Sun},
  doi          = {10.1080/08839514.2024.2340389},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2340389},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Enhancing vocal performance using variational onsager neural network and optimized with golden search optimization algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection-based machine learning comparative
analysis for predicting breast cancer. <em>AAI</em>, <em>38</em>(1),
Article: 2340386. (<a
href="https://doi.org/10.1080/08839514.2024.2340386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is a serious disease, and therefore early detection is crucial for successful treatment and patient management. Unfortunately, globally, the number of breast cancer cases is increasing due to various multifaceted factors. It is currently one of the leading causes of cancer deaths in women, worldwide. Cancerous cells in the breast can form lumps that impact the patient’s health, and even seemingly harmless tumors could be fatal if undiagnosed early enough. Fortunately, artificial intelligence techniques have proven effective in detecting diseases, and doctors can therefore use them to effectively and accurately diagnose breast cancer early. This paper explores the use of genetic algorithms, ant colony optimization, and Hybrid Hopfield Neural Network-E2SAT (HHNN-E2SAT) models, for breast cancer prediction. The HHNN-E2SAT models outperform standard algorithms like the Random Forest and Support Vector Machines, achieving over 98% on all performance metrics (i.e. Accuracy, F1-score, Sensitivity, Specificity, and Precision).},
  archive      = {J_AAI},
  author       = {Chour Singh Rajpoot and Gajanand Sharma and Praveen Gupta and Pankaj Dadheech and Umar Yahya and Nagender Aneja},
  doi          = {10.1080/08839514.2024.2340386},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2340386},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Feature selection-based machine learning comparative analysis for predicting breast cancer},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Circular intuitionistic fuzzy median ranking model with a
novel scoring mechanism for multiple criteria decision analytics.
<em>AAI</em>, <em>38</em>(1), Article: 2335416. (<a
href="https://doi.org/10.1080/08839514.2024.2335416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to pioneer an innovative circular intuitionistic fuzzy (C-IF) scoring-mediated median ranking model designed for multiple criteria decision analytics. The primary goal is to establish a comprehensive precedence ranking for competing alternatives, effectively addressing the inherent uncertainties present in decision-analytic challenges within the C-IF environment. The core content delves into the creation of an original scoring mechanism tailored to navigate the complexities of C-IF uncertainties. Moreover, the research introduces a specialized C-IF median ranking model for decision analytics, leveraging the foundational concept of the C-IF scoring mechanism. A significant contribution is made through the formulation of a robust implementation procedure, specifically tailored for the seamless operation of the C-IF scoring-mediated median ranking model within the framework of C-IF information. Drawing from the suggested C-IF scoring mechanism, this research introduces novel concepts related to comprehensive C-IF scoring functions and comprehensive disagreement metrics. Subsequently, a comprehensive disagreement matrix is formulated, with its entries quantifying the extent of disagreement in assigning specific ranks to each alternative across all criterion-wise precedence relationships. This paves the way for the development of a new C-IF scoring-mediated median ranking model, offering decision analysts a tool to navigate intricate C-IF information and derive dependable decision-analytic outcomes.},
  archive      = {J_AAI},
  author       = {Ting-Yu Chen},
  doi          = {10.1080/08839514.2024.2335416},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2335416},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Circular intuitionistic fuzzy median ranking model with a novel scoring mechanism for multiple criteria decision analytics},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cone beam computerized tomography preoperative guidance
under feature point extraction algorithm combined with autologous
concentrated growth factors in maxillary dental implantation with
insufficient bone mass. <em>AAI</em>, <em>38</em>(1), Article: 2335415.
(<a href="https://doi.org/10.1080/08839514.2024.2335415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AAI},
  author       = {Fang Liu and Wenjing Cui and Tingting Wang and Cheng Qian and Ren Yang and Rongxiu Zhang and Li Xu and Jie Hu and Liang Liu and Kai Zhang},
  doi          = {10.1080/08839514.2024.2335415},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2335415},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Cone beam computerized tomography preoperative guidance under feature point extraction algorithm combined with autologous concentrated growth factors in maxillary dental implantation with insufficient bone mass},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coupled spatial-spectral constrained convolutional fusion
network for hyperspectral and panchromatic images. <em>AAI</em>,
<em>38</em>(1), Article: 2335101. (<a
href="https://doi.org/10.1080/08839514.2024.2335101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target monitoring is an important subject in machine vision. Hyperspectral image (HSI) can effectively assist the target detection and recognition effect of traditional optical images because of its rich spectral information. However, limited by pixel mixing, the resolution of HSI is generally lower than that of optical image, which restricts the monitoring distance and accuracy. Therefore, a fusion method of HSI and panchromatic image (PAN) based on coupled spatial-spectral constrained convolution neural network is proposed in this paper to improve the spatial resolution of HSI and reduce the spectral distortion. Through this approach, the linear spectral mixing model and the spatial-spectral transformation constraint model are incorporated into the learning stage of the coupled convolutional neural network, aiming to make full use of the spatial-spectral information of HSI and PAN, and improve the spectral fidelity of fused images. Experiments on several groups of HSI and PAN data sets show that compared with some currently proposed HSI and PAN fusion methods, the proposed approach has better spectral fidelity and lower fusion errors, so as to improve the monitoring distance and accuracy of machine vision in engineering applications and expand the engineering application scenarios.},
  archive      = {J_AAI},
  author       = {Jingwei Chen},
  doi          = {10.1080/08839514.2024.2335101},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2335101},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Coupled spatial-spectral constrained convolutional fusion network for hyperspectral and panchromatic images},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VBNet: A visually-aware biomimetic network for simulating
the human eye’s visual system. <em>AAI</em>, <em>38</em>(1), Article:
2335100. (<a
href="https://doi.org/10.1080/08839514.2024.2335100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the rapidly advancing realms of computer vision and artificial intelligence, the quest for human-like intelligence is escalating. Central to this pursuit is visual perception, with the human eye as a paragon of efficiency in the natural world. Recent research has prominently embraced the emulation of the human eye’s visual system in computer vision. This paper introduces a pioneering approach, the visually-aware biomimetic network (VBNet), composed of a dual-branch parallel architecture: a Transformer branch emulating the peripheral retina for global feature dependencies and a CNN branch resembling the macular region for local details. Furthermore, it employs feature converter modules (CFC and TFC) to enhance information fusion between the branches. Empirical results highlight VBNet’s superiority over RegNet and PVT in ImageNet classification and competitive performance in MSCOCO object detection and instance segmentation. The dual-branch design, akin to the human visual system, enables simultaneous focus on local and global features, offering fresh perspectives for future research in the field of computer vision and artificial intelligence.},
  archive      = {J_AAI},
  author       = {Zhaofei Li and Yufan Mao and Mingshan Zhong and Jun Zhao},
  doi          = {10.1080/08839514.2024.2335100},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2335100},
  shortjournal = {Appl. Artif. Intell.},
  title        = {VBNet: A visually-aware biomimetic network for simulating the human eye’s visual system},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adapted ant colony optimization for feature selection.
<em>AAI</em>, <em>38</em>(1), Article: 2335098. (<a
href="https://doi.org/10.1080/08839514.2024.2335098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As information technologies evolve, they generate vast and ever-expanding datasets. This wealth of high-dimensional data presents challenges, including increased computational demands and difficulties in extracting valuable insights. The aim of feature selection is to address this complexity by reducing data dimensions with minimal information loss. Our proposed feature selection approach, the Feature Selection via Ant Colony Optimization algorithm, employs heuristic distance directly in its probability function, instead of using its inverse. The algorithm bypasses the need for sub-attribute sets, running multiple iterations to create a frequency order list from the collected routes, which informs feature importance. The efficacy of this technique has been validated through comparative experiments with other methods from scientific literature. To ensure fairness, these experiments used identical datasets, data partitioning strategies, classifiers, and performance metrics. Initially, the algorithm was compared with fifteen different algorithms, and subsequently benchmarked against three selected methods. The impact of feature selection on classification performance was statistically verified through comparisons before and after the feature selection process. Convergence performance of the proposed method has also been evaluated. Our findings robustly support the efficacy of the introduced approach in managing complex, multidimensional data effectively.},
  archive      = {J_AAI},
  author       = {Duygu Yilmaz Eroglu and Umut Akcan},
  doi          = {10.1080/08839514.2024.2335098},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2335098},
  shortjournal = {Appl. Artif. Intell.},
  title        = {An adapted ant colony optimization for feature selection},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of solar concentration flux distribution for a
heliostat based on lunar concentration image and generative adversarial
networks. <em>AAI</em>, <em>38</em>(1), Article: 2332114. (<a
href="https://doi.org/10.1080/08839514.2024.2332114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The predictive analysis of solar flux distribution on the receiver surface is critical in optimizing the concentration processes of concentrating solar power (CSP) plants. Due to the difficulties of directly measuring the solar flux distribution of the heliostat field, tracking the Moon and measuring the lunar concentration ratio distribution become a promising option. However, many factors affect the flux distribution of a heliostat field. To obtain an accurate predictive model for the solar flux distribution, we propose a deep-learning method using conditional generative adversarial networks (cGAN) and lunar concentration images. The method can take account of tracking errors of individual heliostats, defects of reflecting surfaces, as well as atmospheric attenuation effects, and has the potential to give a reliable prediction of solar flux distribution. Mathematical relations between the solar flux distribution and the solar concentration ratio distribution are discussed in the paper. Experiments have been designed and carried out with an ordinary heliostat at the Beijing Badaling solar concentrating power station. Experimental results show that the AI-generated solar concentration ratio distributions are very close to the actual solar concentration ratio distributions, demonstrating the feasibility of AI models for the prediction of solar flux distribution.},
  archive      = {J_AAI},
  author       = {Fen Xu and Jian Wang and Minghuan Guo and Zhifeng Wang},
  doi          = {10.1080/08839514.2024.2332114},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2332114},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Prediction of solar concentration flux distribution for a heliostat based on lunar concentration image and generative adversarial networks},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Critical factor analysis for prediction of diabetes mellitus
using an inclusive feature selection strategy. <em>AAI</em>,
<em>38</em>(1), Article: 2331919. (<a
href="https://doi.org/10.1080/08839514.2024.2331919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes mellitus is a metabolic disorder that significantly implicates serious consequences in various parts of the human body, such as the Eye, Heart, kidney, Nerves, Foot, etc. The identification of consistent features significantly helps us to assess their impact on various organs of the human body and prevent further damage when detected at an early stage. The selection of appropriate features in the data set has potential benefits such as accuracy, minimizing complexity in terms of storage, computation, and positive decision-making. The left features might contain potential information that would be useful for analysis. In order to do effective analysis, additionally, all features should be studied and analyzed in plausible ways, such as using more feature selection (FS) methods with and without standardization. This article focuses on analyzing the critical factors of diabetes by using univariate, wrapper, and brute force FS techniques. To identify critical features, we used info gain, chi-square, RFE, and correlation using the NIDDK data. Later, distinct machine learning models were applied to both phases of the feature sets. This study was carried out in two phases to evaluate the efficacy of the techniques employed. The performance has been assessed using accuracy, F1score, and recall metrics.},
  archive      = {J_AAI},
  author       = {E. Sreehari and L. D. Dhinesh Babu},
  doi          = {10.1080/08839514.2024.2331919},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2331919},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Critical factor analysis for prediction of diabetes mellitus using an inclusive feature selection strategy},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label noise robust crowd counting with loss filtering
factor. <em>AAI</em>, <em>38</em>(1), Article: 2329859. (<a
href="https://doi.org/10.1080/08839514.2024.2329859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting, a crucial computer vision task, aims at estimating the number of individuals in various environments. Each person in crowd counting datasets is typically annotated by a point at the center of the head. However, challenges like dense crowds, diverse scenarios, significant obscuration, and low resolution lead to inevitable label noise, adversely impacting model performance. Driven by the need to enhance model robustness in noisy environments and improve accuracy, we propose the Loss Filtering Factor (LFF) and the corresponding Label Noise Robust Crowd Counting (LNRCC) training scheme. LFF innovatively filters out losses caused by label noise during training, enabling models to focus on accurate data, thereby increasing reliability. Our extensive experiments demonstrate the effectiveness of LNRCC, which consistently improves performance across all models and datasets, with an average enhancement of 3.68% in Mean Absolute Error (MAE), 6.7% in Mean Squared Error (MSE) and 4.68% in Grid Average Mean Absolute Error (GAME). The universal applicability of this approach, coupled with its ease of integration into any neural network model architecture, marks a significant advancement in the field of computer vision, particularly in addressing the pivotal issue of accuracy in crowd counting under challenging conditions.},
  archive      = {J_AAI},
  author       = {Zhengmeng Xu and Hai Lin and Yufeng Chen and Yanli Li},
  doi          = {10.1080/08839514.2024.2329859},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2329859},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Label noise robust crowd counting with loss filtering factor},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). English vocabulary learning aid system using digital twin
wasserstein generative adversarial network optimized with jelly fish
optimization algorithm. <em>AAI</em>, <em>38</em>(1), Article: 2327908.
(<a href="https://doi.org/10.1080/08839514.2024.2327908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural Language Processing (NLP) is a technology that permits computers to recognize human languages. Words are the fundamental unit of analysis in deep-level grammatical and semantic analysis. The main goal of NLP is typically word segmentation. Since the machine learning techniques cannot be directly applied to the practical issue of significant structural disparities between various data modalities in a multi-modal context. In this paper, English Vocabulary Learning Aid System Using Digital Twin Wasserstein Generative Adversarial Network Optimized using Jelly Fish Optimization Algorithm is proposed. The problematic of multiple modal data heterogeneity is handled by the feature extraction of Parameterized Local Maximum Synchro squeezing Transform and extract the features such as Phonetic features, sentence length, word embedding’s, part of speech tags, word frequencies, N-grams. Then, the Digital twin Wasserstein generative adversarial network classifies the English vocabulary to easy words, intermediate words, and difficult words. The performance of the proposed EVLS-DtwinWGAN-NLP approach attains 3.101%, 7.12%, 7.73% higher accuracy, 24.13%, 13.04%, 29.51% lower computation Time and 2.292%, 5.365%, 1.551% higher AUC compared with existing methods like Feature extraction and analysis of natural language processing for deep learning English language (EVLS-BiLSTM-NLP), State of art for semantic analysis of natural language processing (EVLS-SA-NLP) respectively.},
  archive      = {J_AAI},
  author       = {Fei Wu},
  doi          = {10.1080/08839514.2024.2327908},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2327908},
  shortjournal = {Appl. Artif. Intell.},
  title        = {English vocabulary learning aid system using digital twin wasserstein generative adversarial network optimized with jelly fish optimization algorithm},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Smart grids data aggregation method on paillier homomorphic
encryption. <em>AAI</em>, <em>38</em>(1), Article: 2327901. (<a
href="https://doi.org/10.1080/08839514.2024.2327901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart grid (SGs) is a highly integrated power system, it is gradually replacing the traditional power grid, but at present there are problems in the SGs data aggregation, such as user privacy leakage, grid data query inflexibly and data leakage. In order to solve these problems, this paper studied the SGs data aggregation method based on Paillier homomorphic encryption (HE). In this paper, the Paillier HE algorithm was used to study the power grid data, and the encrypted data was numerically calculated under different encryption states. It used the cloud computing center in the blockchain to directly aggregate the ciphertext data generated by users, and used the hash function to set the secret key to prevent the ciphertext data from being tampered with, and obtained the aggregate result of the original data after decryption by the power grid management center. When the number of security parameters was 30,000, the encryption time required by this method was 21.71 seconds. When the number of smart meters (SMs) was 80, the signature verification time required by this method was 2.31 seconds.},
  archive      = {J_AAI},
  author       = {Shaodong Zhao},
  doi          = {10.1080/08839514.2024.2327901},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2327901},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Smart grids data aggregation method on paillier homomorphic encryption},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative intelligence: A scoping review of current
applications. <em>AAI</em>, <em>38</em>(1), Article: 2327890. (<a
href="https://doi.org/10.1080/08839514.2024.2327890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review provides a novel examination of the emerging field of collaborative intelligence and demonstrates the value that human-AI teams can deliver. Humans and artificial intelligence (AI) systems have complementary strengths. This complementarity creates the potential to achieve a step-change in performance by combining inputs from human and AI on a common task. We introduce the construct of “collaborative intelligence” and develop a set of criteria, for evaluating whether an AI system enables collaborative intelligence. Applications utilizing collaborative intelligence had to have (1) complementarity (i.e. the collaboration draws upon complementary human and AI capability to improve outcomes), (2) a shared objective and outcome, and (3) sustained, two-way task-related interaction between human and AI. A systematic review of 1,250 AI applications published between 2012 and 2021 was carried out to investigate whether real-world examples of “collaborative intelligence” could be identified. The review yielded 16 AI systems which met the criteria, demonstrating that collaboration between humans and AI systems is possible and that these systems offer a wide range of performance benefits including efficiency, quality, creativity, safety, and human enjoyment.},
  archive      = {J_AAI},
  author       = {Emma Schleiger and Claire Mason and Claire Naughtin and Andrew Reeson and Cecile Paris},
  doi          = {10.1080/08839514.2024.2327890},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2327890},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Collaborative intelligence: A scoping review of current applications},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimized attention enhanced temporal graph convolutional
network espoused research of intelligent customer service system based
on natural language processing technology. <em>AAI</em>, <em>38</em>(1),
Article: 2327867. (<a
href="https://doi.org/10.1080/08839514.2024.2327867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumers have begun to move their attention away from product functioning and toward value probably extracted from items. Companies have begun to use customer service systems (CSS) in response to this trend, which are business models that give clients with not solitary tangible items as well as intangible facilities. Even with substantial investigation on Smart CSS frameworks, rare of this frameworks considered customers active data producers actively creating data for the Smart CSS. Furthermore, the majority of them offered a generic remedy rather than a personalized one. To classify customer service systems, performance metrics, such as precision, accuracy, F1-score, Recall (Sensitivity), Specificity, Error rate, Computation time, and RoC are considered. The performance of AETGCN-NGOA-CSS approach attains 19.11%, 24.12% and 28.13% high specificity, 24.93%, 23.04%, and 9.51% lower computation time, 15.2%, 25.45% and 13.91% higher ROC and 8.45%, 20.98%, and 27.55% higher accuracy compared with existing methods, such as developing personalized recommendation system in smart product service system depend on unsupervised learning model (CSS-BERT), Cognitive Decision-Making approaches in Data-driven Retail Intelligence: Consumer Sentiments, Choices, Shopping Behaviors (CSS-CDMA), e-Commerce Online Intelligent Customer Service System under Fuzzy Control (CSS-FFNN), respectively.},
  archive      = {J_AAI},
  author       = {Zhifeng Wei and Hongyan Wang and Qiang Xu and Yi Qu and Wei Xing},
  doi          = {10.1080/08839514.2024.2327867},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2327867},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Optimized attention enhanced temporal graph convolutional network espoused research of intelligent customer service system based on natural language processing technology},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analyzing topological indices and heat of formation for
copper(II) fluoride network via curve fitting models. <em>AAI</em>,
<em>38</em>(1), Article: 2327235. (<a
href="https://doi.org/10.1080/08839514.2024.2327235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important fields in current materials research is the examination of materials through the prism of topological indices. An extensive statistical investigation of topological indices relevant to the characterization of copper(II) fluoride is presented in this paper. Our goal is to use the well-understood structural features of copper(II) fluoride, a chemical that is well known for its crystalline qualities, to uncover a variety of properties inherent in its network. This work makes use of the structural information available for copper(II) fluoride. After a thorough computational investigation, a rigorous statistical analysis is conducted to determine the distributions and correlations between heat of formation and the different topological indices. The findings reveal significant patterns and trends in the copper(II) fluoride network structure, providing insights into the underlying principles governing its material behavior.},
  archive      = {J_AAI},
  author       = {Rongbing Huang and Muhammad Farhan Hanif and Muhammad Faisal Hanif and Muhammad Kamran Siddiqui and Tayyaba Noor and Douhadji Abalo},
  doi          = {10.1080/08839514.2024.2327235},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2327235},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Analyzing topological indices and heat of formation for Copper(II) fluoride network via curve fitting models},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retracted article: Binding mechanism of aviation wire
harness based on improved particle swarm optimization. <em>AAI</em>,
<em>38</em>(1), Article: 2327009. (<a
href="https://doi.org/10.1080/08839514.2024.2327009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We, the Editor and Publisher of Applied Artificial Intelligence , have retracted the following article: Zhang Maoyun, Xi Huizhuang, Tang Chen, Jiang Yuheng, Zhang Ziyan &amp; Tian Chunlin, Binding Mechanism of Aviation Wire Harness Based on Improved Particle Swarm Optimization, Applied Artificial Intelligence https://doi.org/10.1080/08839514.2024.2327009 Since publication, concerns have been raised by the authors about the integrity of the data presented in the article. The authors have identified issues with the programming statistics that have led to conclusions which are not credible and have requested the retraction of the article. We have been informed in our decision-making by our policy on publishing ethics and integrity and the COPE guidelines on retractions. The retracted article will remain online to maintain the scholarly record, but it will be digitally watermarked on each page as “Retracted”.},
  archive      = {J_AAI},
  author       = {Zhang Maoyun and Xi Huizhuang and Tang Chen and Jiang Yuheng and Zhang Ziyan and Tian Chunlin},
  doi          = {10.1080/08839514.2024.2327009},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2327009},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Retracted article: Binding mechanism of aviation wire harness based on improved particle swarm optimization},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent extraction of multi-style and multi-template
title block information based on fuzzy matching. <em>AAI</em>,
<em>38</em>(1), Article: 2327005. (<a
href="https://doi.org/10.1080/08839514.2024.2327005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Title blocks are crucial primary data on drawings necessary for the operation of modern manufacturing enterprises. However, their uniform export poses a challenge due to the heterogeneity across multiple sources and the variety of export templates. Therefore, this paper proposes an intelligent extraction method for title block information (TBI) based on fuzzy matching. This method evaluates the geometrical composition of the title block, the logical relationship between information cells, and the diversification of the title block. It establishes a weighted intersection point matrix for the title block as the topological structure model. The fuzzy matching, based on the intersection matrix points, disregards the variations in the size and position of the title block and focuses only on the style that impacts the extraction of information. The matched title blocks are categorized, and the base table of each type determines the information distribution of the title block. A hash table is then created between the description cell and the value cell of information to accumulate the TBI. The method is integrated into the AutoCAD software and presented with an interactive program interface. Finally, an example is presented to further demonstrate the stability, reliability, and efficiency of the method and the system.},
  archive      = {J_AAI},
  author       = {Gui Li and Qinluan Peng and Ming Luo},
  doi          = {10.1080/08839514.2024.2327005},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2327005},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Intelligent extraction of multi-style and multi-template title block information based on fuzzy matching},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective optimization for green delivery routing
problems with flexible time windows. <em>AAI</em>, <em>38</em>(1),
Article: 2325302. (<a
href="https://doi.org/10.1080/08839514.2024.2325302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a model and heuristic solution algorithms for the Green Vehicle Routing Problem with Flexible Time Windows. A scenario of new vehicle routing is analyzed in which customers are asked to provide alternative time windows to offer flexibility to help route planners find more fuel-efficient routes (“green delivery”). Customers can rank their preferred time windows as first, second, and third. The optimization model aims to reduce tour costs, promote electromobility over fossil fuels, such as diesel, and meet customer preferences when possible and affordable. The study incorporates a multi-objective optimization model with three objectives, which are overall cost, use of fossil fuel, and customer satisfaction. For the new problem, a set of realistic benchmark problems is created and four mainstream solvers are applied for the Pareto front approximation: NSGA-II, NSGA-III, MOEA/D, and SMS-EMOA. These algorithms are compared in terms of their effectiveness in achieving the objectives of minimizing travel costs, promoting electromobility, and meeting customer preferences. The study uses five different problems of single-vehicle route planning. Two major findings are that the selection of the metaheuristic can make a big difference in terms of algorithm performance. The resulting 3-D Pareto fronts reveal the nature of this new class of problems: Interestingly, in the new model with flexible time windows, most users can still be delivered in their most preferred time windows with only small concessions to the other objectives. However, using only one time window per user can lead to an increasingly drastic cost and fossil fuel consumption.},
  archive      = {J_AAI},
  author       = {Burak Gülmez and Michael Emmerich and Yingjie Fan},
  doi          = {10.1080/08839514.2024.2325302},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2325302},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Multi-objective optimization for green delivery routing problems with flexible time windows},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial-temporal offshore current field forecasting using
residual-learning based purely CNN methodology with attention mechanism.
<em>AAI</em>, <em>38</em>(1), Article: 2323827. (<a
href="https://doi.org/10.1080/08839514.2024.2323827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial-temporal current forecasting is indispensable for ocean engineering and marine science exploration, for instance aiding in the conservation and protection of marine ecosystems, planning shipping-routes and determining the length and fuel consumption of sea-going voyages, obtaining deeper insights into the distribution of heat flux within the ocean, which is vital for better understanding climate changes, and so on. Most present related-studies primarily focused on single location or grid-cell-based forecasting, such methodologies are site-specific and neglect the importance of spatial-temporal fidelity. Furtherly, the Recurrent Neural Networks-based methods previously employed exhibit low efficiency in terms of model convergence concerning practical engineering purposes, and numerical weather models are time-consuming and computational expensive. A newly improved Unet-based model using residual-learning with attention strategy is proposed for 2D sea surface current (SSC) velocity predictions with a more efficient perspective. Several machine-learning methodologies were adopted for a better performance comparison. The final predictions demonstrated its superiorities that the proposed neural-learning method outperforms the other established approaches with spatial-resolved mean RMSE less than 0.009 m/s and 0.006 m/s. As a promising surrogate for SSC predictions, the proposed methodology has strong potential in operation marine monitoring and engineering constructions.},
  archive      = {J_AAI},
  author       = {Zeguo Zhang and Jianchuan Yin},
  doi          = {10.1080/08839514.2024.2323827},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2323827},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Spatial-temporal offshore current field forecasting using residual-learning based purely CNN methodology with attention mechanism},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Control charts for exponentially distributed
characteristics: SD, ED, ESD with taguchi’s loss function. <em>AAI</em>,
<em>38</em>(1), Article: 2322362. (<a
href="https://doi.org/10.1080/08839514.2024.2322362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenge of quality characteristics that follow an exponential distribution, which can significantly impact decision-making in various fields. Existing approaches rely on approximations to convert exponential distributions to normal distributions, upon which control charts are constructed. However, such conversions introduce errors that can lead to incorrect outcomes, particularly for highly sensitive characteristics. To address this limitation, we propose the development of control charts specifically designed for exponential characteristics, without relying on approximations. Our objective is to introduce four different schemes for constructing these control charts: a statistical scheme, an economic scheme, an economic-statistical scheme combined with Taguchi’s loss function, and an economic-statistical scheme without the application of a loss function. To determine optimal design parameter values for each scheme, we employ the artificial bee colony algorithm. Additionally, we conduct a sensitivity analysis to investigate the impact of design parameters on each proposed design. To illustrate the practical implementation of these control charts, we provide a numerical example that demonstrates their effectiveness. By addressing the limitations of existing approaches and offering novel control chart designs, this paper contributes to enhancing decision-making accuracy and reliability in scenarios involving exponentially distributed quality characteristics.},
  archive      = {J_AAI},
  author       = {Masoud Tavakoli and Ali Akbar Heydari and Sahera Hussein Zain AL–Thalabi},
  doi          = {10.1080/08839514.2024.2322362},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2322362},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Control charts for exponentially distributed characteristics: SD, ED, ESD with taguchi’s loss function},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised machine learning approaches for test suite
reduction. <em>AAI</em>, <em>38</em>(1), Article: 2322336. (<a
href="https://doi.org/10.1080/08839514.2024.2322336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring quality and reliability mandates thorough software testing at every stage of the development cycle. As software systems grow in size, complexity, and functionality, the parallel expansion of the test suite leads to an inefficient utilization of computational power and time, presenting challenges to optimization. Therefore, the Test Suite Reduction (TSR) process is of great importance, contributing to the reduction of time and costs in executing test suites for complex software by minimizing the number of test cases to be executed. Over the past decade, machine learning-based solutions have emerged, demonstrating remarkable effectiveness and efficiency. Recent studies have delved into the application of Machine Learning (ML) in the software testing domain, where the high cost and time consumption associated with data annotation have prompted the use of unsupervised algorithms. In this research, we conducted a Systematic Mapping Study (SMS), examining the types of unsupervised algorithms implemented in developed models and thoroughly exploring the evaluation metrics employed. This study highlighted the prevalence of the K-Means clustering algorithm and the coverage metric for validation in various studies. Additionally, we identified a gap in the literature regarding scalability considerations. Our findings underscore the effective use of unsupervised learning approaches in test suite reduction.},
  archive      = {J_AAI},
  author       = {Anila Sebastian and Hira Naseem and Cagatay Catal},
  doi          = {10.1080/08839514.2024.2322336},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2322336},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Unsupervised machine learning approaches for test suite reduction},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Behavior analysis of the new PSO-CGSA algorithm in solving
the combined economic emission dispatch using non-parametric tests.
<em>AAI</em>, <em>38</em>(1), Article: 2322335. (<a
href="https://doi.org/10.1080/08839514.2024.2322335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new metahaeuristic algorithm named particle swarm optimization and chaotic gravitational search algorithm (PSO-CGSA) for solving the combined economic and emission dispatch (CEED) problem. First, we determine the efficiency and effectiveness measures of the algorithm and compare it with other well-known algorithms. Then, we analyze the obtained solutions using the statistical procedure proposed in the paper. The proposed procedure contains the following: (i) the behavior analysis of the algorithms when solving the CEED problem, using non-parametric tests, and (ii) the ranking of the algorithms using the PROMETHEE/GAIA multi-criteria decision-making method. The behavior analysis is performed for two cases: (i) when solving individual variants of the CEED problem (single-problem analysis) and (ii) when solving a set of CEED variants (multiple-problem analysis). The results of the applied procedure for the test system with six generators show that PSO-CGSA has (i) the best solution for each tested variant of the CEED problem; (ii) the best standard deviation, mean value, error rate, and behavior for the CEED variant with a bi-objective function that simultaneously minimizes fuel cost and emission, taking into account the valve point effect; and (iii) the best rank when solving a set of CEED variants.},
  archive      = {J_AAI},
  author       = {Milena Gajić and Sanela Arsić and Jordan Radosavljević and Miroljub Jevtić and Bojan Perović and Dardan Klimenta and Miloš Milovanović},
  doi          = {10.1080/08839514.2024.2322335},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2322335},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Behavior analysis of the new PSO-CGSA algorithm in solving the combined economic emission dispatch using non-parametric tests},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy-preserving process mining: A blockchain-based
privacy-aware reversible shared image approach. <em>AAI</em>,
<em>38</em>(1), Article: 2321556. (<a
href="https://doi.org/10.1080/08839514.2024.2321556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deeper integration of cross-organizational business process sharing and process mining has advanced the Industrial Internet. Privacy breaches and data security risks limit its use. Scrambling or anonymizing event data frequently preserves privacy in established studies. The scrambling mechanism or random noise injection corrupts event log process information and lowers process mining outcomes. This research presents a blockchain-based privacy-aware reversible shared image approach using chaotic image and privacy-aware theory for privacy-preserving process mining. Avoiding data loss, disclosure concerns, correlation attacks, and encrypted sharing is possible with the method. First, process data is turned into color images with chaotic image encryption to safeguard privacy and allow reversible reproduction. Second, the on-chain-off-chain paradigm helps handle information lightly; finally, attribute encryption of multi-view event data for correlation resistance and on-demand data encryption sharing. Simulations on common datasets reveal that: 1. The system performance of the proposed method outperforms the baseline method by 57%. 2. The strategy greatly enhances categorical and numerical data privacy. 3. It performs better in event data privacy protection and process mining fitness and precision. The proposed method ensures the secure flow of cross-organizational information in the Industrial Internet and provides a novel privacy-secure computational approach for the growing Artificial Intelligence.},
  archive      = {J_AAI},
  author       = {Xianwen Fang and Mengyao Li},
  doi          = {10.1080/08839514.2024.2321556},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2321556},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Privacy-preserving process mining: A blockchain-based privacy-aware reversible shared image approach},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sentiment analysis of short texts using SVMs and VSMs-based
multiclass semantic classification. <em>AAI</em>, <em>38</em>(1),
Article: 2321555. (<a
href="https://doi.org/10.1080/08839514.2024.2321555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our approach, a hybrid machine learning model is proposed which uses Enhanced Vector Space Model (EVSM) along with Hybrid Support Vector Machine (HSVM) classifier. Initially the social media-based information is retrieved using Enhanced Vector Space Model (EVSM). EVSMs are employed in order to characterize the text content by mapping them into high-dimensional vector spaces, capturing the relationships between words and their contextual meanings. Rigorous feature selection methods are employed to designate texts for review, and a multiclass semantic classification algorithm, specifically the HSVM classifier, is utilized for categorization. Decision tree algorithm is used along with SVM to refine the selection process. To enhance sentiment analysis accuracy, sentiment dictionaries are not only presented but also extended through the expansion of Stanford’s GloVE tool. To enhance precision, the proposed work introduces weight-enhancing methods for processing renowned text weights. Sentiments are classified into positive, negative, and neutral categories. Notably, the achieved results demonstrate improved accuracy, attributed to the incorporation of an emotional sentiment enhancement factor for determining weights and leveraging sentiment dictionaries for word availability. The accuracy is obtained to be 92.78% with 91.33% positive sentiment rate and 97.32% negative sentiment rate.},
  archive      = {J_AAI},
  author       = {K. Suresh Kumar and A.S. Radha Mani and T. Ananth Kumar and Ahmad Jalili and Mehdi Gheisari and Yasir Malik and Hsing-Chung Chen and Ata Jahangir Moshayedi},
  doi          = {10.1080/08839514.2024.2321555},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2321555},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Sentiment analysis of short texts using SVMs and VSMs-based multiclass semantic classification},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). STSG: A short text semantic graph model for similarity
computing based on dependency parsing and pre-trained language models.
<em>AAI</em>, <em>38</em>(1), Article: 2321552. (<a
href="https://doi.org/10.1080/08839514.2024.2321552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short text semantic similarity is a crucial research area in nature language processing, which is used to predict the similarity between two sentences. Due to the sparsity features of short texts, words are isolated in the sentence and the correlations of words are ignored, it is very difficult to calculate the global semantic information. Based on this, short text semantic graph (STSG) model based on dependency parsing and pre-trained language models is proposed in this paper. It utilizes the syntactic information to obtain word dependency relationships and incorporate it into pre-trained language models to enhance the global semantic information of sentences. So it can address the semantic sparsity more effectively. A text semantic graph layer based on the graph attention network (GAT) is also realized, which regards word vectors as node features and word dependency as edge features. The attention mechanism of GAT can identify the importance of different word correlations and solve the word dependency modeling effectively. On the challenging short text semantic benchmark dataset MRPC, the STSG model achieves an F1-score of .946, which is further improved 2.16% over previous SOTA approaches. At the time of writing, STSG has achieved a new SOTA performance on the MRPC dataset.},
  archive      = {J_AAI},
  author       = {Hai Liao and Yan Liang and Song Chen and Lingyun Xiang and Zhimin Chang and Yun Xiao},
  doi          = {10.1080/08839514.2024.2321552},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2321552},
  shortjournal = {Appl. Artif. Intell.},
  title        = {STSG: A short text semantic graph model for similarity computing based on dependency parsing and pre-trained language models},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human activity detection events through human eye reflection
using bystander analyzer. <em>AAI</em>, <em>38</em>(1), Article:
2321551. (<a
href="https://doi.org/10.1080/08839514.2024.2321551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic video-based human activity recognition has shown promise and is mostly used in video surveillance applications for diverse purposes. However, there are still substantial performance issues that make real-world implementation challenging. The main barrier to the accurate detection of human movement remains to the perspective problem, which results from the fact that video sequences are frequently shot from random camera angles. Therefore, the main focus of this study is on how human eyesight reflects in different camera views that are used to detect human activity or identify intruders. First, a gaussian mixture model that previously used the Minimal Spanning Tree for segmentation is used for pre-processing. Using the pixel-based Kruskal methodology and this method, the input data set’s minimal weight is precisely determined. Segmentation comes next. Independent discriminant features are extracted using transformation using Karhunen-Loeve expansion, which isolates human behavior based on the Person Correlation Coefficient. To effectively identify data, Deep Lens Classifier is also employed to look for any suspect human behavior. With an impressive 78.8774% accuracy, 28.6961% sensitivity, 98.50% specificity, 75.6734% precision, 48.781% recall, and 65.10% F-measure, this approach is unique in the field of detecting human activity. Finally, our proposed system’s MATLAB performance retrieves the accurate detection.},
  archive      = {J_AAI},
  author       = {P. Nagalakshmi},
  doi          = {10.1080/08839514.2024.2321551},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2321551},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Human activity detection events through human eye reflection using bystander analyzer},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of density-based clustering approaches for stock
market analysis. <em>AAI</em>, <em>38</em>(1), Article: 2321550. (<a
href="https://doi.org/10.1080/08839514.2024.2321550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Present economy is largely dependent on the precise forecasting of the business avenues using the stock market data. As the stock market data falls under the category of big data, the task of handling becomes complex due to the presence of a large number of investment choices. In this paper, investigations have been carried out on the stock market data analysis using various density-based clustering approaches. For experimentation purpose, the stock market data from Quandl stock market was used. It was observed that the effectiveness of Dynamic Quantum clustering approach were better. This is because it has better adopting capability according of changing patterns of the stock market data. Similarly performances of other density-based clustering approaches like Weighted Adaptive Mean Shift Clustering, DBSCAN and Expectation Maximization and also partitive clustering methods such as k-means, k-medoids and fuzzy c means were also experimented on the same stock market data. The performance of all the approaches was tested in terms of standard measures. It was found that in majority of the cases, Dynamic Quantum clustering outperforms the other density-based clustering approaches. The algorithms were also subjected to paired t-tests which also confirmed the statistical significance of the results obtained.},
  archive      = {J_AAI},
  author       = {Tanuja Das and Anindya Halder and Goutam Saha},
  doi          = {10.1080/08839514.2024.2321550},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2321550},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Application of density-based clustering approaches for stock market analysis},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3D gaussian geometric moment invariants. <em>AAI</em>,
<em>38</em>(1), Article: 2318983. (<a
href="https://doi.org/10.1080/08839514.2024.2318983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D moment invariants are important tools for 3D image feature representation. In this paper, we introduced a novel approach for constructing 3D moment invariants using Gaussian geometric moments. Our proposed method demonstrated invariance under translation, rotation, and scale transformations. The numerical experiments validate the invariance and robustness of the proposed method, comparing it with traditional 3D geometric moments and revealing superior performance in the presence of noise and transformations. Additionally, the method is applied to content-based 3D image retrieval, exhibiting promising results through Minkowski distance-based retrieval on the Princeton Shape Benchmark (PSB) database.},
  archive      = {J_AAI},
  author       = {Tao Sun},
  doi          = {10.1080/08839514.2024.2318983},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2318983},
  shortjournal = {Appl. Artif. Intell.},
  title        = {3D gaussian geometric moment invariants},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DWS-YOLO: A lightweight detector for blood cell detection.
<em>AAI</em>, <em>38</em>(1), Article: 2318673. (<a
href="https://doi.org/10.1080/08839514.2024.2318673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peripheral blood cell detection is an essential component of medical practice and is used to diagnose and treat diseases, as well as to monitor the progress of therapies. Our objective is to construct an efficient deep learning model for peripheral blood cell analysis that achieves an optimized balance between inference speed, computational complexity, and detection accuracy. In this article, we propose the DWS-YOLO blood detector, which is a lightweight blood detector. Our model includes several improved modules, including the lightweight C3 module, the increased combined attention mechanism, the Scylla-IoU loss function, and the improved soft non-maximum suppression. Improved attention, loss function, and suppression enhance detection accuracy, while lightweight C3 module reduces computation time. The experiment results demonstrate that our proposed modules can enhance a detector’s detection performance, and obtain new state-of-the-art (SOTA) results and excellent robustness performance on the BCCD dataset. On the white blood cell detection dataset (Raabin-WBC), the proposed detector’s generalization performance was confirmed to be satisfactory. Our proposed blood detector achieves high detection accuracy while requiring few computational resources and is very suitable for resource-limited but efficient medical device environments, providing a reliable and advanced solution for blood detection that greatly improves the efficiency and effectiveness of peripheral blood cell analysis in clinical practice.},
  archive      = {J_AAI},
  author       = {Yihai Mao and Hongyi Zhang and Wanqing Wu and Xingen Gao and Zhibin Lin and Juqiang Lin},
  doi          = {10.1080/08839514.2024.2318673},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2318673},
  shortjournal = {Appl. Artif. Intell.},
  title        = {DWS-YOLO: A lightweight detector for blood cell detection},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of a vision- based anti-drone identification
friend or foe model to recognize birds and drones using deep learning.
<em>AAI</em>, <em>38</em>(1), Article: 2318672. (<a
href="https://doi.org/10.1080/08839514.2024.2318672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the growing use of drones has paved the way for limitless applications in all the domains. However, their malicious exploitations have affected the airspace safety, making them double-edged weapons. Therefore, intelligent anti-drone systems capable of recognizing and neutralizing airborne targets become highly required. In the existing literature, most of the attention has been centered on recognizing drones as unique airborne target, whereas the real challenge is to distinguish between drones and non-drone targets. To address this issue, this study develops an Identification Friend or Foe (IFF) model able to classify the aerial targets in foe or friend categories by determining whether the aerial target is a drone or bird, respectively. To achieve this objective, artificial intelligence and computer vision approaches have been combined through transfer learning, data augmentation and other techniques in our model. Another contribution of this work is the study of the impact of depth on the classification performance, which is demonstrated through our experiments. A comparison is performed based on eight models, where EfficientNetB6 shows the best results with 98.12% accuracy, 98.184% precision, 98.115% F1 score and 99.85% Area Under Curve (AUC). The computational results demonstrate the practicality of the developed model.},
  archive      = {J_AAI},
  author       = {Yasmine Ghazlane and Maha Gmira and Hicham Medromi},
  doi          = {10.1080/08839514.2024.2318672},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2318672},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Development of a vision- based anti-drone identification friend or foe model to recognize birds and drones using deep learning},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The SAGE framework for explaining context in explainable
artificial intelligence. <em>AAI</em>, <em>38</em>(1), Article: 2318670.
(<a href="https://doi.org/10.1080/08839514.2024.2318670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scholars often recommend incorporating context into the design of an explainable artificial intelligence (XAI) model in order to ensure successful real-world adoption. However, contemporary literature has so far failed to delve into the detail of what constitutes context. This paper addresses that gap by firstly providing normative and XAI-specific definitions of key concepts, thereby establishing common ground upon which further discourse can be built. Second, far from pulling apart the body of literature to argue that one element of context is more important than another, this paper advocates a more holistic perspective which unites the recent discourse. Using a thematic review, this paper establishes that the four concepts of setting, audience, goals and ethics (SAGE) are widely recognized as key tools in the design of operational XAI solutions. Moreover, when brought together they can be employed as a scaffold to create a user-centric XAI real-world solution.},
  archive      = {J_AAI},
  author       = {Eleanor Mill and Wolfgang Garn and Nick Ryman-Tubb and Chris Turner},
  doi          = {10.1080/08839514.2024.2318670},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2318670},
  shortjournal = {Appl. Artif. Intell.},
  title        = {The SAGE framework for explaining context in explainable artificial intelligence},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Designing a block chain based network for the secure
exchange of medical data in healthcare systems. <em>AAI</em>,
<em>38</em>(1), Article: 2318164. (<a
href="https://doi.org/10.1080/08839514.2024.2318164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An identity-based cryptosystem called signcryption is investigated in this study in order to efficiently and securely exchange healthcare information inside a data-sharing network, utilizing the idea of bilinear pairings. A distributed tamperproof database protects all health records and is uploaded to it and replicated over a group of nodes that are linked to form a peer-to-peer network. As a result, each health record is treated as an individual event that is time stamped and assigned a cryptographic hash. On a similar note, transaction blocks include all the record events. Every node in the network has a copy of the ledger of hashed records and events. Additional information such as user permission lists are also included in this health care blockchain network, which serve as instructions for the network. To guarantee the data integrity of EHRs, this article provides security for exchanging EHRs across medical institutions and inside the organization, and ultimately safe exchange of EHRs by removing a third-party trustworthy third-party provider. Various cryptographic methods are being utilized on the blockchain in order to ensure security for the exchange of health care data. Signcryption is utilized in the suggested design approach for secure health care data exchange.},
  archive      = {J_AAI},
  author       = {Katru Rama Rao and Satuluri Naganjaneyulu},
  doi          = {10.1080/08839514.2024.2318164},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2318164},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Designing a block chain based network for the secure exchange of medical data in healthcare systems},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning model with axial attention for radar echo
extrapolation. <em>AAI</em>, <em>38</em>(1), Article: 2311003. (<a
href="https://doi.org/10.1080/08839514.2024.2311003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radar echo extrapolation is an important approach in precipitation nowcasting which utilizes historical radar echo images to predict future echo images. In this paper, we introduce the self-attention mechanism into Trajectory Gated Recurrent Unit (TrajGRU) model. Under the sequence-to-sequence framework, we have developed a novel convolutional recurrent neural network called Self-attention Trajectory Gated Recurrent Unit (SA-TrajGRU), which incorporates the self-attention mechanism. The SA-TrajGRU model which combines spatiotemporal variant structure in TrajGRU and self-attention module is simple and effective. We evaluate our approach on the Moving MNIST-2 dataset and the CIKM AnalytiCup 2017 radar echo dataset. The experimental results show that the performance of the proposed SA-TrajGRU model is comparable to other convolutional recurrent neural network models. HSS and CSI scores of the SA-TrajGRU model are higher than scores of other models under the radar echo threshold of 25 dBZ, indicating that the SA-TrajGRU model has the most accurate prediction results under this threshold.},
  archive      = {J_AAI},
  author       = {Yu-Mei Xie and Ying-Liang Zhao and Shu-Yan Huang},
  doi          = {10.1080/08839514.2024.2311003},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2311003},
  shortjournal = {Appl. Artif. Intell.},
  title        = {A deep learning model with axial attention for radar echo extrapolation},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autonomous behavior selection for self-driving cars using
probabilistic logic factored markov decision processes. <em>AAI</em>,
<em>38</em>(1), Article: 2304942. (<a
href="https://doi.org/10.1080/08839514.2024.2304942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose probabilistic logic factored Markov decision processes ( PL-fMDPs ) as a behavior selection scheme for self-driving cars. Probabilistic logic combines logic programming with probability theory to achieve clear, rule-based knowledge descriptions of multivariate probability distributions, and a flexible mixture of deductive and probabilistic inferences. Factored Markov decision processes ( fMDPs ) are widely used to generate reward-optimal action policies for stochastic sequential decision problems. For evaluation, we developed a simulated self-driving car with reliable modules for behavior selection, perception, and control. The behavior selection module is composed of a two-level structure of four action policies obtained from PL-fMDPs. Three main tests were conducted focused on the selection of the appropriate actions in specific driving scenarios, and the overtaking of static obstacle vehicles and dynamic obstacle vehicles. We performed 520 repetitions of these tests. The self-driving car completed its task without collisions in 99.2% of the repetitions. Results show the suitability of the overall self-driving strategy and PL-fMDPs to construct safe action policies for self-driving cars.},
  archive      = {J_AAI},
  author       = {Héctor Avilés and Marco Negrete and Alberto Reyes and Rubén Machucho and Karelly Rivera and Gloria de-la-Garza and Alberto Petrilli},
  doi          = {10.1080/08839514.2024.2304942},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2304942},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Autonomous behavior selection for self-driving cars using probabilistic logic factored markov decision processes},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessment of wind shear severity in airport runway vicinity
using interpretable TabNet approach and doppler LiDAR data.
<em>AAI</em>, <em>38</em>(1), Article: 2302227. (<a
href="https://doi.org/10.1080/08839514.2024.2302227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Severe wind shear events near airport runways pose serious safety risks and are a growing concern in civil aviation. Identification of severe wind shear risk factors may enhance aviation safety. Although rare, severe wind shear impacts safety by affecting the airspeed, lift, and maneuverability of aircraft. This study presents TabNet, a novel deep learning technique coupled with Bayesian optimization (BO) to predict wind shear severity in the runway vicinity using Doppler LiDAR data from Hong Kong International Airport. To address imbalanced wind shear data, it was first processed by resampling techniques and then used as input to TabNet. The analysis demonstrated that Bayesian-tuned TabNet (BO-TabNet) with SVM-SMOTE-processed data led to better performance compared to other strategies. The TabNet architecture employs the attention mechanism to enable model-specific interpretability. Analysis showed that the most important contributing factor was the summer season, followed by the wind shear encounter location (1 nautical miles from the runway at the departure end). Additionally, a more comprehensive model-agnostic LIME method was used to elucidate the model from a local perspective. By predicting severe wind shear and assessing contributing factors, aviation stakeholders can proactively manage and mitigate the associated risks, leading to safer and more efficient operations.},
  archive      = {J_AAI},
  author       = {Afaq Khattak and Jianping Zhang and Pak-Wai Chan and Feng Chen},
  doi          = {10.1080/08839514.2024.2302227},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2302227},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Assessment of wind shear severity in airport runway vicinity using interpretable TabNet approach and doppler LiDAR data},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-criteria decision making model for hotel selection
problem under complex dual hesitant fuzzy information. <em>AAI</em>,
<em>38</em>(1), Article: 2300215. (<a
href="https://doi.org/10.1080/08839514.2023.2300215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of the “complex dual hesitant fuzzy set (CDHFS)” is the combination of the “dual hesitant fuzzy set (DHFS)” and the “complex fuzzy set (CFS).” It is characterized by two degrees, namely the membership and nonmembership, in the form of a finite subset on a unit disc in the complex plane. CDHFS is useful for dealing with real-world problems involving uncertain or hard-to-predict information. Also, to approximate smoothly, the Einstein operators are well-known aggregation operators, while prioritized operators are effective tools for prioritization among criteria. Therefore, the goal of this study is to develop some prioritized aggregation operators under the CDHFS environment; namely the complex dual hesitant fuzzy prioritized averaging (CDHFPA) operator, the complex dual hesitant fuzzy prioritized geometric (CDHFPG) operator, the complex dual hesitant fuzzy Einstein prioritized averaging (CDHFEPA) operator, and complex dual hesitant fuzzy Einstein prioritized geometric (CDHFEPG) operator. Some properties of the proposed operators are investigated in detail. In addition, a multi-criteria decision-making (MCDM) method based on the proposed operators with the complex dual hesitant fuzzy setting is developed. Moreover, a numerical example is given for the application and effectiveness of the developed MCDM approach. A comparison study is also done with existing methods to show that the proposed MCDM method is better and more reliable. The study finds that if the expert’s preference is used to choose the right aggregation operators, the decision maker will have access to a wide range of compromise solutions.},
  archive      = {J_AAI},
  author       = {Rasool Niaz Khan and Muhammad Sajjad Ali Khan and Wali Khan Mashwani and Muhammad Ibrar and Tapan Senapati and Sarbast Moslem},
  doi          = {10.1080/08839514.2023.2300215},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2300215},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Multi-criteria decision making model for hotel selection problem under complex dual hesitant fuzzy information},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved word segmentation system for chinese criminal
judgment documents. <em>AAI</em>, <em>38</em>(1), Article: 2297524. (<a
href="https://doi.org/10.1080/08839514.2023.2297524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a system for automatic word segmentation of Chinese criminal judgment documents is proposed. The system uses a hybrid model composed of fine-tuned BERT (Bidirectional Encoder Representations from Transformers), BiLSTM (Bidirectional Long Short Term Memory) and CRF (Conditional Random Field) for named entity recognition, and introduces a custom dictionary that includes common professional terms in Chinese criminal trial documents, as well as a rule system based on judicial system and litigation procedure related regulations, to further improve the accuracy of word segmentation. BERT uses a deep bidirectional Transformer encoder to pre-train general language representations from large-scale unlabeled text corpora. BiLSTM uses two LSTM networks, one for the forward direction and one for the backward direction, to capture the context from both sides of the input sequence. CRF uses a set of features and weights to define a log-linear distribution over the output sequence. Experimental results show that the proposed system has significantly improved word segmentation accuracy compared to the current commonly used Chinese word segmentation models. In the results of the segmentation of the test data, the F1 scores for jieba, THULAC and the segmentation system proposed in this paper are 85.59%, 87.94% and 94.82%, respectively.},
  archive      = {J_AAI},
  author       = {Chi Zhang},
  doi          = {10.1080/08839514.2023.2297524},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2297524},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Improved word segmentation system for chinese criminal judgment documents},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Managing emotion in the workplace: An empirical study with
enterprise instant messaging. <em>AAI</em>, <em>38</em>(1), Article:
2297518. (<a
href="https://doi.org/10.1080/08839514.2023.2297518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enterprise Instant Messaging (EIM) has become an increasingly important tool for enterprises to operate efficiently and for the employees to communicate smoothly, especially with the recent outbreak of the pandemic. This means that employers and employees are having to adapt to new ways of working, e.g. teleworking or home-based working, and they could experience emotional stress, irritability and anxiety. However, few studies have used sentiment analysis to help employees manage their emotions and past studies mostly applied retrospective sentiment analysis on user-generated content as such as Twitter or the internal enterprise data. In this study we present an Employee Sentiment Analysis and Management System (ESAMS) that continuously monitors the emotions of the employees in real time by analyzing the conversations so the managerial members and the team members can actively manage their emotions or adjust their actions on the spot. As a proof-of-concept, we use Naïve Bayes as our sentiment classifier and achieve an average classification accuracy of 74%. The ESAMS was pilot-tested for one month by 10 participants, who were later interviewed as part of the evaluation. The results show that the ESAMS was helpful in improving team performance and team management.},
  archive      = {J_AAI},
  author       = {Shih-Wen Ke and Chih-Fong Tsai and Yi-Jun Chen},
  doi          = {10.1080/08839514.2023.2297518},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2297518},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Managing emotion in the workplace: An empirical study with enterprise instant messaging},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Engineering responsible and explainable models in
human-agent collectives. <em>AAI</em>, <em>38</em>(1), Article: 2282834.
(<a href="https://doi.org/10.1080/08839514.2023.2282834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In human-agent collectives, humans and agents need to work collaboratively and agree on collective decisions. However, ensuring that agents responsibly make decisions is a complex task, especially when encountering dilemmas where the choices available to agents are not unambiguously preferred over another. Therefore, methodologies that allow the certification of such systems are urgently needed. In this paper, we propose a novel engineering methodology based on formal model checking as a step toward providing evidence for the certification of responsible and explainable decision making within human-agent collectives. Our approach, which is based on the MCMAS model checker, verifies the decision-making behavior against the logical formulae specified to guarantee safety and controllability, and address ethical concerns. We propose the use of counterexample traces and simulation results to provide a judgment and an explanation to the AI engineer as to the reasons actions may be refused or allowed. To demonstrate the practical feasibility of our approach, we evaluate it using the real-world problem of human-UAV (unmanned aerial vehicle) teaming in dynamic and uncertain environments.},
  archive      = {J_AAI},
  author       = {Dhaminda B. Abeywickrama and Sarvapali D. Ramchurn},
  doi          = {10.1080/08839514.2023.2282834},
  journal      = {Applied Artificial Intelligence},
  month        = {12},
  number       = {1},
  pages        = {Article: 2282834},
  shortjournal = {Appl. Artif. Intell.},
  title        = {Engineering responsible and explainable models in human-agent collectives},
  volume       = {38},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
