<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NPL_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="npl---194">NPL - 194</h2>
<ul>
<li><details>
<summary>
(2024). A study of the state of the art approaches and datasets for
multilingual natural language inference. <em>NPL</em>, <em>56</em>(6),
1–23. (<a href="https://doi.org/10.1007/s11063-024-11673-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural language inference is critical in Natural Language Processing where semantics is involved. Also known as textual entailment recognition, it defines a directional relationship between pair of sentences, namely the text and the hypothesis. Identifying entailment, contradiction, and neutrality in text pairs is necessary for various language processing applications to reduce text redundancy. An overview of the critical works in this aspect for all languages, including the Indian language perspective, is detailed here. There is a high volume of textual entailment and related attempts in English and foreign languages. In contrast, there are only a few attempts for low resource languages. This article presents the progress in textual entailment for various languages and the development of different datasets for textual entailment. Over these years, the datasets developed differ in size and kind. Most of the datasets are raw or generated, and a few of the latest are translated datasets. The article also points to observation notes on the progress that has happened throughout these years.},
  archive      = {J_NPL},
  author       = {Renjit, Sara and Idicula, Sumam Mary},
  doi          = {10.1007/s11063-024-11673-2},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {A study of the state of the art approaches and datasets for multilingual natural language inference},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature enhancement based oriented object detection in
remote sensing images. <em>NPL</em>, <em>56</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11699-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since objects in remote sensing imagery often have arbitrary orientations and high densities, the features of small objects are inclined to be contaminated by the background and other instances. To address the issues, we propose a new oriented object detection framework where a series of feature enhancement schemes are implemented so as to improve robustness and accuracy of the detector. Firstly, we design a weighted bidirectional feature pyramid network, which can be used to fuse both high-level semantic features and low-level detail features for effectively handling with multi-scale objects. Accordingly, we apply the convolutional block attention module that exploits both spatial- and channel-wise attention in our detector, and study how to effectively integrate it into the framework for adaptive feature refinement. In the meanwhile, we present a semantic segmentation guided module to generate naive mask, which is used to multiple with pyramid features to filter out background noise and improve feature representation for small objects. The experimental results on two public datasets, i.e., UCAS-AOD and DOTA, validate the effective performance of the proposed method for oriented object detection in remote sensing images.},
  archive      = {J_NPL},
  author       = {Guo, Hongjian and Zhou, Xianlin and Yang, Peng},
  doi          = {10.1007/s11063-024-11699-6},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Feature enhancement based oriented object detection in remote sensing images},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time synchronization of memristive neural networks
with uncertainties and external disturbances. <em>NPL</em>,
<em>56</em>(6), 1–12. (<a
href="https://doi.org/10.1007/s11063-024-11700-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An improved synchronization approach is proposed, designed and proved by employing SMC technique and wavelet Hopfield neural networks. Firstly, a novel memristive celluar neural network (MCNN) is introduced and its dynamics are analyzed. Then, based on Lyapunov theory, The sliding mode controllers are also designed to robust the uncertain mode and the adaptive update laws are derived so that the synchronization error of MCNNs with uncertainties and external disturbances can be reached zero in finite time by using SMC with activation function. Finally, taking the proposed MCNN as an example, the efficacy of proposed method is validated.},
  archive      = {J_NPL},
  author       = {Wang, S.-f.},
  doi          = {10.1007/s11063-024-11700-2},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1-12},
  shortjournal = {Neural Process. Lett.},
  title        = {Finite-time synchronization of memristive neural networks with uncertainties and external disturbances},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-channel lightweight contrast prediction coding for
features extraction of radar emitter signals. <em>NPL</em>,
<em>56</em>(6), 1–13. (<a
href="https://doi.org/10.1007/s11063-024-11702-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This letter presents a novel multi-channel improved contrastive predictive coding (CPC) method to extract signals features. Specifically, to extract low pulse width radar signals features and meet the real-time requirements of signals identification, we design a lightweight encoder to realize the CPC features encoding function. Then, we construct a multi-channel CPC features decoder to mine and extract subtle individual signals features from the perspective of multi-domain and multi-channel information input. Simulation results verify the effectiveness of our proposed method, which can achieve state-of-the-art results in both accuracy and running time compared to the existing optimal methods. All our models and code are available at https://github.com/jn-z/MC-CPC.},
  archive      = {J_NPL},
  author       = {Zhang, Junning and Wei, Zhanyang and Ding, Guoru and Liang, Junli and Zhang, Zefeng},
  doi          = {10.1007/s11063-024-11702-0},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1-13},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-channel lightweight contrast prediction coding for features extraction of radar emitter signals},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Policy optimization algorithm with activation
likelihood-ratio for multi-agent reinforcement learning. <em>NPL</em>,
<em>56</em>(6), 1–27. (<a
href="https://doi.org/10.1007/s11063-024-11705-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a ubiquitous on-policy reinforcement learning algorithm, proximal policy optimization (PPO) has achieved the state-of-the-art performance in both single-agent and cooperative multi-agent scenarios. However, it still suffers from the instability and inefficiency of the policy optimization with the non-strictly restricted likelihood-ratio in clipping strategy. In this work, we propose an activation likelihood-ratio (ALR) for solving this issue. The ALR is restricted by a tanh activation function, and it can be employed in multiple functional clipping strategies. The resulted ALR clipping strategy produces a smooth but precipitous objective curve, which can provide high policy update stationarity and efficiency. The ALR clipping strategy is incorporated into the PPO loss function, thus resulting in the method proximal policy optimization with activation likelihood-ratio (PPO-ALR). The rationality and superiority of the ALR-based target function are proved and analyzed. Moreover, experiments on the Pistonball cooperative multi-agent game show that PPO-ALR produces competitive and superior results compared with the standard PPO, PPO with rollback, and PPO smoothed algorithms, especially its high efficiency and success probability in searching optimal policies in multi-agent environments.},
  archive      = {J_NPL},
  author       = {Jia, Lu and Su, Binglin and Xu, Du and Wang, Yewei and Fang, Jing and Wang, Jun},
  doi          = {10.1007/s11063-024-11705-x},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1-27},
  shortjournal = {Neural Process. Lett.},
  title        = {Policy optimization algorithm with activation likelihood-ratio for multi-agent reinforcement learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy aware optimal virtual machine scheduling in cloud
environment using hybridized egret swarm with sea lion optimization
algorithm. <em>NPL</em>, <em>56</em>(6), 1–32. (<a
href="https://doi.org/10.1007/s11063-024-11706-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With emergence of advanced technologies, the internet plays as the essential role to share the information across the world. With emergence of large number of users, the data quality gets affected thus; it leads to cause burden in scheduling where it provides fewer services to the users. Due to this existence, the cloud computing technology emerges to offer better services. Certainly, the optimal scheduling process of a Virtual Machine (VM) becomes challenging in the larger size of data in cloud environments. Modern systems and data centers place a high priority on energy consumption. Thus, it provides poor performance regarding energy usage and throughput analysis marked in the traditional techniques. In order to consider aforementioned issues, a novel VM scheduling mechanism is introduced for allocating and managing resources in cloud. The major scope of this developed VM scheduling process tends to minimize energy consumption. The developed Hybrid Egret Swarm-based Sea Lion Optimization (HES-SLO) algorithm is implemented to allocate resources based on several objective functions like execution time, energy or power consumption, cost, and resource utilization. Thus, the overall performance analysis takes place, where the developed VM scheduling model is compared with the traditional VM allocation mechanisms to verify the efficacy. In this validation, the HES-SLO attains 21.16%, 4.903%, 0.17%, and 7.86% for energy consumption, resource utilization, execution time, and throughput analysis. Based on the entire validation, it shows greater performance by compared with existing approaches.},
  archive      = {J_NPL},
  author       = {Vhatkar, Kapil and Kathole, Atul B. and Lonare, Savita and Gandhewar, Nisarg},
  doi          = {10.1007/s11063-024-11706-w},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1-32},
  shortjournal = {Neural Process. Lett.},
  title        = {Energy aware optimal virtual machine scheduling in cloud environment using hybridized egret swarm with sea lion optimization algorithm},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hebbian learning with kernel-based embedding of input data.
<em>NPL</em>, <em>56</em>(6), 1–21. (<a
href="https://doi.org/10.1007/s11063-024-11707-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although it requires simple computations, provides good performance on linear classification tasks and offers a suitable environment for active learning strategies, the Hebbian learning rule is very sensitive to how the training data relate to each other in the input space. Since this spatial arrangement is inherent to each set of samples, the practical application of this learning paradigm is limited. Thus, representation learning may play an important role in projecting the input data into a new space where linear separability is improved. Earlier methods based on orthogonal coding addressed this issue but presented many side effects, impoverishing the generalization of the model. Hence, this paper considers a recently proposed method based on kernel density estimators, which performs a likelihood-based projection where linear separability and generalization capacity are enhanced in an autonomous fashion. Results show that this novel method allows one to use linear classifiers to solve many binary classification problems and overcome the performance of well-established classifiers.},
  archive      = {J_NPL},
  author       = {Ushikoshi, Thiago A. and Freitas, Elias J. R. and Menezes, Murilo and Junior, Wagner J. A. and Torres, Luiz C. B. and Braga, Antonio P.},
  doi          = {10.1007/s11063-024-11707-9},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Hebbian learning with kernel-based embedding of input data},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mechanism isomorphism identification based on decision tree
algorithm and hybrid particle swarm optimization algorithm.
<em>NPL</em>, <em>56</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s11063-024-11711-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanism isomorphism identification is a typical quadratic assignment problem similar to traveling salesman and job-shop scheduling. For the complex mechanism with more components, common methods of isomorphism identification may fail due to low solving efficiency and reliability. Based on the decision tree algorithm and hybrid particle swarm optimization (HPSO) algorithm, the global-local search method is proposed to identify isomorphism of mechanisms. More precisely, based on the intrinsic relationship between links and vertices in the mechanism, the decision tree algorithm globally searches the characteristic path with mapping properties of different mechanisms. On this basis, HPSO algorithm combines genetic algorithm with particle swarm optimization algorithm to find the exact global optimal solution instead of local optimal solution. Some complex cases such as 14-link kinematic chains, 18-vertex topological graphs, and 8-vertex planetary gear trains are used to evaluate the efficiency and reliability of the proposed method. Results show that the proposed method can accurately identify isomorphism of mechanisms in a relatively short time. It can improve the solving efficiency of isomorphism identification in structural synthesis.},
  archive      = {J_NPL},
  author       = {Yu, Luchuan and Zhou, Shunqing and Wang, Hongbin},
  doi          = {10.1007/s11063-024-11711-z},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Mechanism isomorphism identification based on decision tree algorithm and hybrid particle swarm optimization algorithm},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label-based disentanglement measure among hidden units of
deep learning. <em>NPL</em>, <em>56</em>(6), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11708-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capability to disentangle underlying factors hidden in the observable data, thereby obtaining their abstract representations, is considered one important ingredient for the subsequent success of deep networks in various application scenarios. Recently, numerous practical measures and learning strategies have been established for disentanglement, showcasing their potential in improving the model’s explainability, controlability, and robustness. However, when the downstream tasks come to the classification issues, there is still no consensus in the community on the definition or measurement for disentanglement, and its connection to the generalization capacity remains not very clear. Aiming at this, we explore the highly non-linear effect of a specified hidden layer on the generalization capacity from an information perspective and obtain a tight bound. Upon decompsing the bound, we find that besides the unsupervised disentanglement measure term in the conventional sense, a new supervised disentanglement term also emerges with a nonnegligible effect on the generality. Consequently, a novel label-based disentanglement measure (LDM) is naturally introduced as the discrepancy between these two terms under the supervised learning settings to substitute the commonly used unsupervised disentanglement measure. The theoretical analysis reveals an inverse relationship between the defined LDM and the generalization capacity. Finally, using LDM as regularizer, the experiments show that the deep neural networks (DNNs) can effectively reduce generalization error while improving classification accuracy when noise is added to the data features or labels, which strongly supports our points.},
  archive      = {J_NPL},
  author       = {Zhang, Chenguang and Hou, Yuexian and Song, Dawei},
  doi          = {10.1007/s11063-024-11708-8},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {Label-based disentanglement measure among hidden units of deep learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MAFD: Multiple adversarial features detector for enhanced
detection of text-based adversarial examples. <em>NPL</em>,
<em>56</em>(6), 1–24. (<a
href="https://doi.org/10.1007/s11063-024-11710-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks in the field of Natural Language Processing greatly undermine the effectiveness and safety of models, raising significant challenges when it comes to real-world implementation. The researchers suggested using detection methods to identify and reject hostile samples while maintaining the accuracy of the original model. Nevertheless, current detection methods depend on analyzing a single characteristic, resulting in restricted resilience and flexibility. To address these constraints, we proposed the Multiple Adversarial Features Detector (MAFD), an innovative detection technique that utilizes a wide range of adversarial features, such as segmented perplexity, word frequency, and probability distribution, to enhance the effectiveness of detecting adversarial examples. Our comprehensive experiments shows that MAFD outperforms existing advanced methods in terms of detection accuracy and displays significant robustness and adaptability when applied to various base detectors and attack scenarios. In addition, the design of MAFD facilitates the seamless integration of further adversarial features, hence enhancing its detection capabilities.},
  archive      = {J_NPL},
  author       = {Jin, Kaiwen and Xiong, Yifeng and Lou, Shuya and Yu, Zhen},
  doi          = {10.1007/s11063-024-11710-0},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1-24},
  shortjournal = {Neural Process. Lett.},
  title        = {MAFD: Multiple adversarial features detector for enhanced detection of text-based adversarial examples},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A neural network-based poisson solver for fluid simulation.
<em>NPL</em>, <em>56</em>(5), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11620-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pressure Poisson equation is usually the most time-consuming problem in fluid simulation. To accelerate its solving process, we propose a deep neural network-based numerical method, termed Deep Residual Iteration Method (DRIM), in this paper. Firstly, the global equation is decomposed into multiple independent tridiagonal sub-equations, and DRIM is capable of solving all the sub-equations simultaneously. Moreover, we employed Residual Network and a correction iteration method to improve the precision of the solution achieved by the neural network in DRIM. The numerical results, including the Poiseuille flow, the backwards-facing step flow, and driven cavity flow, have proven that the numerical precision of DRIM is comparable to that of classic solvers. In these numerical cases, the DRIM-based algorithm is about 2–10 times faster than the conventional method, which indicates that DRIM has promising applications in large-scale problems.},
  archive      = {J_NPL},
  author       = {Jiang, Zichao and Wang, Zhuolin and Yao, Qinghe and Yang, Gengchao and Zhang, Yi and Jiang, Junyang},
  doi          = {10.1007/s11063-024-11620-1},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {A neural network-based poisson solver for fluid simulation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Training artificial neural network with a cultural
algorithm. <em>NPL</em>, <em>56</em>(5), 1–28. (<a
href="https://doi.org/10.1007/s11063-024-11636-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks are amongst the artificial intelligence techniques with their ability to provide machines with some functionalities such as decision making, comparison, and forecasting. They are known for having the capability of forecasting issues in real-world problems. Their acquired knowledge is stored in the interconnection strengths or weights of neurons through an optimization system known as learning. Several limitations have been identified with commonly used gradient-based optimization algorithms, including the risk of premature convergence, the sensitivity of initial parameters and positions, and the potential for getting trapped in local optima. Various meta-heuristics are proposed in the literature as alternative training algorithms to mitigate these limitations. Therefore, the primary aim of this study is to combine a feed-forward artificial neural network (ANN) with a cultural algorithm (CA) as a meta-heuristic, aiming to establish an efficient and dependable training system in comparison to existing methods. The proposed artificial neural network system (ANN-CA) evaluated its performance on classification tasks over nine benchmark datasets: Iris, Pima Indians Diabetes, Thyroid Disease, Breast Cancer Wisconsin, Credit Approval, Glass Identification, SPECT Heart, Wine and Balloon. The overall experimental results indicate that the proposed method outperforms other methods included in the comparative analysis by approximately 12% in terms of classification error and approximately 7% in terms of accuracy.},
  archive      = {J_NPL},
  author       = {Tümay Ateş, Kübra and Kalkan, İbrahim Erdem and Şahin, Cenk},
  doi          = {10.1007/s11063-024-11636-7},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-28},
  shortjournal = {Neural Process. Lett.},
  title        = {Training artificial neural network with a cultural algorithm},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distance enhanced hypergraph learning for dynamic node
classification. <em>NPL</em>, <em>56</em>(5), 1–18. (<a
href="https://doi.org/10.1007/s11063-024-11645-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic node classification aims to predict the labels of nodes in the dynamic networks. Existing methods primarily utilize the graph neural networks to acquire the node features and original graph structure features. However, these approaches ignore the high-order relationships between nodes and may lead to the over-smoothing issue. To address these issues, we propose a distance enhanced hypergraph learning (DEHL) method for dynamic node classification. Specifically, we first propose a time-adaptive pre-training component to generate the time-aware representations of each node. Then we utilize a dual-channel convolution module to construct the local and global hypergraphs which contain the corresponding local and global high-order relationships. Moreover, we adopt the K-nearest neighbor algorithm to construct the global hypergraph in the embedding space. After that, we adopt the node convolution and hyperedge convolution to aggregate the features of neighbors on the hypergraphs to the target node. Finally, we combine the temporal representations and the distance enhanced representations of the target node to predict its label. In addition, we conduct extensive experiments on two public dynamic graph datasets, i.e., Wikipedia and Reddit. The experimental results show that DEHL outperforms the state-of-the-art baselines in terms of AUC.},
  archive      = {J_NPL},
  author       = {Liu, Dengfeng and Pan, Zhiqiang and Hu, Shengze and Cai, Fei},
  doi          = {10.1007/s11063-024-11645-6},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {Distance enhanced hypergraph learning for dynamic node classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning with decoupled state representation
for robot manipulations. <em>NPL</em>, <em>56</em>(5), 1–19. (<a
href="https://doi.org/10.1007/s11063-024-11650-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has significantly advanced robot manipulations by providing an alternative solution for designing control strategies using raw images as direct inputs. While images offer additional environmental information, the end-to-end policy training manner (from image to action) requires simultaneous representation and task learning by the agent. This often necessitates a substantial number of interaction samples to achieve satisfactory policy performance. Previous works has attempted to address this challenge by learning a visual representation model that encodes the entire image into a low-dimensional vector before the policy training. However, since this vector contains both robot and object information, it inevitably introduces coupling within the state, which can mislead the policy training process. In this study, a novel method called Reinforcement Learning with Decoupled State Representation is proposed to effectively decouple robot and object information within the state representation. Experimental results demonstrate that the proposed method exhibits faster learning speed and achieves superior performance compared to previous methods across various robot manipulation tasks. Moreover, with only 3096 offline images, the proposed method successfully applies to real-world robot pushing tasks, which demonstrates its high practicability.},
  archive      = {J_NPL},
  author       = {Dong, Kun and Zeng, Yu and Wang, Kun and Luo, Yongle and Wang, Yuxin and Cheng, Erkang and Sun, Zhiyong and Zhang, Qiang and Song, Bo},
  doi          = {10.1007/s11063-024-11650-9},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {Reinforcement learning with decoupled state representation for robot manipulations},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging hybrid deep learning models for enhanced
multivariate time series forecasting. <em>NPL</em>, <em>56</em>(5),
1–25. (<a href="https://doi.org/10.1007/s11063-024-11656-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is crucial in various domains, ranging from finance and economics to weather prediction and supply chain management. Traditional statistical methods and machine learning models have been widely used for this task. However, they often face limitations in capturing complex temporal dependencies and handling multivariate time series data. In recent years, deep learning models have emerged as a promising solution for overcoming these limitations. This paper investigates how deep learning, specifically hybrid models, can enhance time series forecasting and address the shortcomings of traditional approaches. This dual capability handles intricate variable interdependencies and non-stationarities in multivariate forecasting. Our results show that the hybrid models achieved lower error rates and higher $$R^2$$ values, signifying their superior predictive performance and generalization capabilities. These architectures effectively extract spatial features and temporal dynamics in multivariate time series by combining convolutional and recurrent modules. This study evaluates deep learning models, specifically hybrid architectures, for multivariate time series forecasting. On two real-world datasets - Traffic Volume and Air Quality - the TCN-BiLSTM model achieved the best overall performance. For Traffic Volume, the TCN-BiLSTM model achieved an $$R^2$$ score of 0.976, and for Air Quality, it reached an $$R^2$$ score of 0.94. These results highlight the model’s effectiveness in leveraging the strengths of Temporal Convolutional Networks (TCNs) for capturing multi-scale temporal patterns and Bidirectional Long Short-Term Memory (BiLSTMs) for retaining contextual information, thereby enhancing the accuracy of time series forecasting.},
  archive      = {J_NPL},
  author       = {Mahmoud, Amal and Mohammed, Ammar},
  doi          = {10.1007/s11063-024-11656-3},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-25},
  shortjournal = {Neural Process. Lett.},
  title        = {Leveraging hybrid deep learning models for enhanced multivariate time series forecasting},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time series prediction based on LSTM and high-order fuzzy
cognitive map with attention mechanism. <em>NPL</em>, <em>56</em>(5),
1–26. (<a href="https://doi.org/10.1007/s11063-024-11666-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy cognitive map (FCM) has been successfully applied to time series prediction due to its powerful dynamic system modeling and inference ability. Although many FCM-based methods have been proposed, their performance is far from satisfactory. The existing FCM-based methods have two limitations: First, the feature extraction of some methods is unreasonable and even leads to overfitting. Second, most methods ignore the local temporal features of time series. In this work, we propose a novel framework for time series prediction based on long short-term memory (LSTM) and high-order FCMs (HFCM) with an attention mechanism, termed LSTM-HFCMAM. To overcome the first limitation, different from other FCM-based methods that use Autoencoder to forcibly decompose each point of the time series into multiple points to represent the original sequences, we use a sliding window to preprocess the original time series and use the Encoder-Decoder framework to represent the sequences. This way makes the model has better generalization and interpretability. Then, HFCM is used to predict representations of sequences due to its powerful causal inference ability. Finally, self-attention is applied to restore the predicted sliding window data with focus, effectively improving the performance. To overcome the second limitation, we use the LSTM to learn the temporal features of time series fragments, thereby learning the local features of the whole time series. We validate the performance of LSTM-HFCMAM on twelve benchmark datasets. Compared with current methods, LSTM-HFCMAM has a maximum improvement of 51.02%. The experimental results demonstrate the effectiveness of LSTM-HFCMAM and overcome the above limitations.},
  archive      = {J_NPL},
  author       = {Teng, Yingzhi and Liu, Jing and Wu, Kai},
  doi          = {10.1007/s11063-024-11666-1},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-26},
  shortjournal = {Neural Process. Lett.},
  title        = {Time series prediction based on LSTM and high-order fuzzy cognitive map with attention mechanism},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lagrange stability of competitive neural networks with
multiple time-varying delays. <em>NPL</em>, <em>56</em>(5), 1–25. (<a
href="https://doi.org/10.1007/s11063-024-11667-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the Lagrange stability of competitive neural networks (CNNs) with leakage delays and mixed time-varying delays is investigated. By constructing delay-dependent Lyapunov functional, combining inequality analysis technique, the delay-dependent Lagrange stability criterion are obtained in the form of linear matrix inequalities. And the corresponding global exponentially attractive set (GEAS) is obtained. On this basis, by exploring the relationship between the leakage delays and the discrete delay, a better GEAS of the system is obtained from the six different sizes of the two types of delays. Finally, three examples of numerical simulation are given to illustrate the effectiveness of the obtained results.},
  archive      = {J_NPL},
  author       = {Tang, Dandan and Wang, Baoxian and Jian, Jigui and Hao, Caiqing},
  doi          = {10.1007/s11063-024-11667-0},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-25},
  shortjournal = {Neural Process. Lett.},
  title        = {Lagrange stability of competitive neural networks with multiple time-varying delays},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Siamese tracking network with multi-attention mechanism.
<em>NPL</em>, <em>56</em>(5), 1–23. (<a
href="https://doi.org/10.1007/s11063-024-11670-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object trackers based on Siamese networks view tracking as a similarity-matching process. However, the correlation operation operates as a local linear matching process, limiting the tracker’s ability to capture the intricate nonlinear relationship between the template and search region branches. Moreover, most trackers don’t update the template and often use the first frame of an image as the initial template, which will easily lead to poor tracking performance of the algorithm when facing instances of deformation, scale variation, and occlusion of the tracking target. To this end, we propose a Simases tracking network with a multi-attention mechanism, including a template branch and a search branch. To adapt to changes in target appearance, we integrate dynamic templates and multi-attention mechanisms in the template branch to obtain more effective feature representation by fusing the features of initial templates and dynamic templates. To enhance the robustness of the tracking model, we utilize a multi-attention mechanism in the search branch that shares weights with the template branch to obtain multi-scale feature representation by fusing search region features at different scales. In addition, we design a lightweight and simple feature fusion mechanism, in which the Transformer encoder structure is utilized to fuse the information of the template area and search area, and the dynamic template is updated online based on confidence. Experimental results on publicly tracking datasets show that the proposed method achieves competitive results compared to several state-of-the-art trackers.},
  archive      = {J_NPL},
  author       = {Xu, Yuzhuo and Li, Ting and Zhu, Bing and Wang, Fasheng and Sun, Fuming},
  doi          = {10.1007/s11063-024-11670-5},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {Siamese tracking network with multi-attention mechanism},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generation of rule-based explanations of CNN classifiers
using regional features. <em>NPL</em>, <em>56</em>(5), 1–16. (<a
href="https://doi.org/10.1007/s11063-024-11678-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Deep Learning networks generally outperform traditional machine learning approaches based on tailored features, they often lack explainability. To address this issue, numerous methods have been proposed, particularly for image-related tasks such as image classification or object segmentation. These methods generate a heatmap that visually explains the classification problem by identifying the most important regions for the classifier. However, these explanations remain purely visual. To overcome this limitation, we introduce a novel CNN explainability method that identifies the most relevant regions in an image and generates a decision tree based on meaningful regional features, providing a rule-based explanation of the classification model. We evaluated the proposed method on a synthetic blob’s dataset and subsequently applied it to two cell image classification datasets with healthy and pathological patterns.},
  archive      = {J_NPL},
  author       = {Philipp, William and Yashwanthika, R. and Sikha, O. K. and Benitez, Raul},
  doi          = {10.1007/s11063-024-11678-x},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Generation of rule-based explanations of CNN classifiers using regional features},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robot ground medium classification algorithm based on
feature fusion and adaptive spatio-temporal cascade networks.
<em>NPL</em>, <em>56</em>(5), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11679-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With technological advancements and scientific progress, mobile robots have found widespread applications across various fields. To enable robots to perform tasks safely and effectively in diverse and unknown environments, this paper proposes a ground medium classification algorithm for robots based on feature fusion and an adaptive spatio-temporal cascade network. Specifically, the original directional features in the dataset are first transformed into quaternion form. Then, spatio-temporal forward and reverse neighbors are identified using KD trees, and their connection strengths are evaluated via a kernel density estimation algorithm to determine the final set of neighbors. Subsequently, based on the connection strengths determined in the previous step, we perform noise reduction on the features using discrete wavelet transform. The noise-reduced features are then weighted and fused to generate a new feature representation.After feature fusion, the Adaptive Dynamic Convolutional Neural Network (ADC) proposed in this paper is cascaded with the Long Short-Term Memory (LSTM) network to further extract hybrid spatio-temporal feature information from the dataset, culminating in the final terrain classification. Experiments on the terrain type classification dataset demonstrate that our method achieves an average accuracy of 97.46% and an AUC of 99.80%, significantly outperforming other commonly used algorithms in the field. Furthermore, the effectiveness of each module in the proposed method is further demonstrated through ablation experiments.},
  archive      = {J_NPL},
  author       = {Feng, Changqun and Dong, Keming and Ou, Xinyu},
  doi          = {10.1007/s11063-024-11679-w},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {A robot ground medium classification algorithm based on feature fusion and adaptive spatio-temporal cascade networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Within-class constraint based multi-task autoencoder for
one-class classification. <em>NPL</em>, <em>56</em>(5), 1–18. (<a
href="https://doi.org/10.1007/s11063-024-11681-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autoencoders (AEs) have attracted much attention in one-class classification (OCC) based unsupervised anomaly detection. The AEs aim to learn the unity features on targets without involving anomalies and thus the targets are expected to obtain smaller reconstruction errors than anomalies. However, AE-based OCC algorithms may suffer from the overgeneralization of AE and fail to detect anomalies that have similar distributions to target data. To address these issues, a novel within-class constraint based multi-task AE (WC-MTAE) is proposed in this paper. WC-MTAE consists of two different task: one for reconstruction and the other for the discrimination-based OCC task. In this way, the encoder is compelled by the OCC task to learn the more compact encoded feature distribution for targets when minimizing OCC loss. Meanwhile, the within-class scatter based penalty term is constructed to further regularize the encoded feature distribution. The aforementioned two improvements enable the unsupervised anomaly detection by the compact encoded features, thereby addressing the issue of the overgeneralization in AEs. Comparisons with several state-of-the-art (SOTA) algorithms on several non-image datasets and an image dataset CIFAR10 are provided where the WC-MTAE is conducted on 3 different network structures including the multilayer perception (MLP), LeNet-type convolution network and full convolution neural network. Extensive experiments demonstrate the superior performance of the proposed WC-MTAE. The source code would be available in future.},
  archive      = {J_NPL},
  author       = {Xie, Guojie and Wang, Tianlei and Liu, Dekang and Zhang, Wandong and Lai, Xiaoping},
  doi          = {10.1007/s11063-024-11681-2},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {Within-class constraint based multi-task autoencoder for one-class classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label-only membership inference attack based on model
explanation. <em>NPL</em>, <em>56</em>(5), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11682-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that machine learning models (e.g., image recognition) can unintentionally leak information about the training set. Conventional membership inference relies on posterior vectors, and this task becomes extremely difficult when the posterior is masked. However, current label-only membership inference attacks require a large number of queries during the generation of adversarial samples, and thus incorrect inference generates a large number of invalid queries. Therefore, we introduce a label-only membership inference attack based on model explanations. It can transform a label-only attack into a traditional membership inference attack by observing neighborhood consistency and perform fine-grained membership inference for vulnerable samples. We use feature attribution to simplify the high-dimensional neighborhood sampling process, quickly identify decision boundaries and recover a posteriori vectors. It also compares different privacy risks faced by different samples through finding vulnerable samples. The method is validated on CIFAR-10, CIFAR-100 and MNIST datasets. The results show that membership attributes can be identified even using a simple sampling method. Furthermore, vulnerable samples expose the model to greater privacy risks.},
  archive      = {J_NPL},
  author       = {Ma, Yao and Zhai, Xurong and Yu, Dan and Yang, Yuli and Wei, Xingyu and Chen, Yongle},
  doi          = {10.1007/s11063-024-11682-1},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Label-only membership inference attack based on model explanation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding efficient graph embeddings and processing them by a
CNN-based tool. <em>NPL</em>, <em>56</em>(5), 1–25. (<a
href="https://doi.org/10.1007/s11063-024-11683-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce new tools to support finding efficient graph embedding techniques for graph databases and to process their outputs using deep learning for classification scenarios. Accordingly, we investigate the possibility of creating an ensemble of different graph embedding methods to raise accuracy and present an interconnected neural network-based ensemble to increase the efficiency of the member classification algorithms. We also introduce a new convolutional neural network-based architecture that can be generally proposed to process vectorized graph data provided by various graph embedding methods and compare it with other architectures in the literature to show the competitiveness of our approach. We also exhibit a statistical-based inhomogeneity level estimation procedure to select the optimal embedding for a given graph database efficiently. The efficiency of our framework is exhaustively tested using several publicly available graph datasets and numerous state-of-the-art graph embedding techniques. Our experimental results for classification tasks have proved the competitiveness of our approach by outperforming the state-of-the-art frameworks.},
  archive      = {J_NPL},
  author       = {Tiba, Attila and Hajdu, Andras and Giraszi, Tamas},
  doi          = {10.1007/s11063-024-11683-0},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-25},
  shortjournal = {Neural Process. Lett.},
  title        = {Finding efficient graph embeddings and processing them by a CNN-based tool},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A clustering pruning method based on multidimensional
channel information. <em>NPL</em>, <em>56</em>(5), 1–18. (<a
href="https://doi.org/10.1007/s11063-024-11684-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pruning convolutional neural networks offers a promising solution to mitigate the computational complexity challenges encountered during application deployment. However, prevalent pruning techniques primarily concentrate on model parameters or feature mapping analysis to devise static pruning strategies, often overlooking the underlying feature extraction capacity of convolutional kernels. To address this, the study first quantitatively expresses the feature extraction capability of convolutional channels from three aspects: global features, distribution metrics, and directional metrics. It explores the multi-dimensional information of the channels, calculates the overall expectation, variance, and cosine distance from the unit vector as the quantitative results of the channels. Subsequently, a clustering algorithm is employed to categorize the multidimensional information. This approach ensures that convolutional channels grouped within each cluster possess similar feature extraction capabilities. An enhanced differential evolutionary algorithm is utilized to optimize the number of clustering centers across all convolutional layers, ensuring optimal grouping. The final step involves achieving channel sparsification through the calculation of crowding distances for each sample within its designated cluster. This preserves a diverse subset of channels that are critical for maintaining model accuracy. Extensive empirical evaluations conducted on three benchmark image classification datasets demonstrate the efficacy of this method. For instance, on the ImageNet dataset, the ResNet-50 model experiences a substantial reduction in FLOPs by 58.43% while incurring a minimal decrease in TOP-1 accuracy of only 1.15%.},
  archive      = {J_NPL},
  author       = {Chuanmeng, Sun and Jiaxin, Chen and Zhibo, Wu and Yong, Li and Tiehua, Ma},
  doi          = {10.1007/s11063-024-11684-z},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {A clustering pruning method based on multidimensional channel information},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning-based hybrid CNN-LSTM model for
location-aware web service recommendation. <em>NPL</em>, <em>56</em>(5),
1–25. (<a href="https://doi.org/10.1007/s11063-024-11687-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advertising is the most crucial part of all social networking sites. The phenomenal rise of social media has resulted in a general increase in the availability of customer tastes and preferences, which is a positive development. This information may be used to improve the service that is offered to users as well as target advertisements for customers who already utilize the service. It is essential while delivering relevant advertisements to consumers, to take into account the geographic location of the consumers. Customers will be ecstatic if the offerings displayed to them are merely available in their immediate vicinity. As the user’s requirements will vary from place to place, location-based services are necessary for gathering this essential data. To get users to stop thinking about where they are and instead focus on an ad, location-based advertising (LBA) uses their mobile device’s GPS to pinpoint nearby businesses and provide useful information. Due to the increased two-way communication between the marketer and the user, mobile consumers’ privacy concerns and personalization issues are becoming more of a barrier. In this research, we developed a collaborative filtering-based hybrid CNN-LSTM model for recommending geographically relevant online services using deep neural networks. The proposed hybrid model is made using two neural networks, i.e., CNN and LSTM. Geographical information systems (GIS) are used to acquire initial location data to collect precise locational details. The proposed LBA for GIS is built in a Python simulation environment for evaluation. Hybrid CNN-LSTM recommendation performance beats existing location-aware service recommender systems in large simulations based on the WS dream dataset.},
  archive      = {J_NPL},
  author       = {Pandey, Ankur and Mannepalli, Praveen Kumar and Gupta, Manish and Dangi, Ramraj and Choudhary, Gaurav},
  doi          = {10.1007/s11063-024-11687-w},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-25},
  shortjournal = {Neural Process. Lett.},
  title        = {A deep learning-based hybrid CNN-LSTM model for location-aware web service recommendation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Microblog negative comments data analysis model based on
multi-scale convolutional neural network and weighted naive bayes
algorithm. <em>NPL</em>, <em>56</em>(5), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11688-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a form of public supervision, Microblog’s negative reviews allow people to share their opinions and experiences and express dissatisfaction with unfair and unreasonable phenomena. This form of supervision has the potential to promote social fairness, drive governments, businesses, and individuals to correct mistakes and enhance transparency. To characterize the sentiment trend and determine the influence of Microblog negative reviews, we propose a multi-scale convolutional neural network and weighted naive bayes algorithm (MCNN–WNB). We define the feature vector characterization index for Microblog negative review data and preprocess the data accordingly. We quantify the relationship between attributes and categories using the weighted Naive Bayes method and use the quantification value as the weighting coefficient for the attributes, addressing the issue of decreased classification performance in traditional methods. We introduce a sentiment classification model based on word vector representation and a multi-scale convolutional neural networks to filter out Microblog negative review data. We conduct simulation experiments using real data, analyzing key influencing parameters such as convergence time, training set sample size, and number of categories. By comparing with K-means, Naive Bayes algorithm, Spectral Clustering algorithm and Autoencoder algorithm, we validate the effectiveness of our proposed method. We discover that the convergence time of the MCNN–WNB algorithm increases as the number of categories increases. The average classification accuracy of the algorithm remains relatively stable with varying test iterations. The algorithm’s precision increases with the number of training set samples and eventually stabilizes.},
  archive      = {J_NPL},
  author       = {Zhou, Chunliang and Meng, XiangPei and Shen, Zhaoqiang},
  doi          = {10.1007/s11063-024-11688-9},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Microblog negative comments data analysis model based on multi-scale convolutional neural network and weighted naive bayes algorithm},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive missing data restoration method for UAV
confrontation based on deep regression model. <em>NPL</em>,
<em>56</em>(5), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11690-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Completing missions with autonomous decision-making unmanned aerial vehicles (UAV) is a development direction for future battlefields. UAV make decisions based on battlefield situation information collected by sensors and can quickly and accurately perform complex tasks such as path planning, cooperative reconnaissance, cooperative pursuit and attacks. Obtaining real-time situation information of enemy is the basis for realizing autonomous decision-making of the UAV. However, in practice, due to internal sensor failure or interference of enemy, the acquired situation information is prone to be missing, which affects the training and decision-making of autonomous UAV. In this paper, an adaptive missing situation data restoration method for UAV confrontation is proposed. The UAV confrontation situation data are acquired through JSBSim, an open-source UAV simulation platform. By fusing temporal convolutional network and long short-term memory sequences, we establish a deep regression method for missing data restoration and introduce an adaptive mechanism to reduce the training time of the restoration model in response to dynamic changes in the enemy’s strategy during UAV confrontation. In addition, we evaluate the reliability of the proposed method by comparing with different baseline models under different degrees of data missing conditions. The performance of our method is quantified by five metrics. The performance of our proposed method is better than the other benchmark algorithms. The experimental results show that the proposed method can solve the missing data restoration problem and provide reliable situation data while effectively reducing the training time of the restoration model.},
  archive      = {J_NPL},
  author       = {Wang, Huan and Zhou, Xu and Liu, Xiaofeng},
  doi          = {10.1007/s11063-024-11690-1},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {An adaptive missing data restoration method for UAV confrontation based on deep regression model},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CTCTime: A new model for unidimensional time series
classification. <em>NPL</em>, <em>56</em>(5), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11694-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-dimensional time series classification has always been an important research direction, playing an irreplaceable role in various fields. With the rapid development of deep learning, most traditional time series classification methods have gradually been replaced by neural network-based classification methods. At present, in the field of time series classification, models that perform well are mostly based on Convolutional Neural Networks (CNNs), while models with the Transformer architecture, which have shown outstanding performance in natural language processing and computer vision, do not stand out. In order to change this situation, We have investigated the feasibility of training models based on a single Transformer architecture directly on small datasets without additional data processing. Furthermore, we propose a new model called CTCTime, which combines the Transformer architecture with CNNs to address one-dimensional time series classification problems. We compared CTCTime with 13 traditional algorithms on 44 datasets from the UCR archive and with 7 advanced methods on 85 datasets. The UCR datasets are classic datasets for one-dimensional time series classification tasks. The experimental results demonstrate its feasibility, accuracy, and scalability.},
  archive      = {J_NPL},
  author       = {Lan, Gonghao and Tang, Jin and Guo, Fan},
  doi          = {10.1007/s11063-024-11694-x},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {CTCTime: A new model for unidimensional time series classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ISMOTE: A more accurate alternative for SMOTE. <em>NPL</em>,
<em>56</em>(5), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11695-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification models trained on imbalanced datasets tend to be biased towards the majority category, resulting in reduced accuracy for minority categories. A common approach to address this problem is to generate artificial data for underrepresented categories. The Synthetic Minority Over-sampling Technique (SMOTE) algorithm and its variants are widely used for this purpose. In this paper, we propose a modification to the data generation mechanism called Iteration-based SMOTE (ISMOTE). Unlike SMOTE, the ISMOTE algorithm trains the data for multiple iterations. In each iteration, the model generates new samples in the vicinity of appropriately misclassified data. These new samples are then fed into the classification model, thus improving classification accuracy over the course of multiple iterations. We compare the performance of ISMOTE with SMOTE and other commonly used oversampling algorithms. Our empirical results demonstrate that ISMOTE significantly improves the quality of the generated data compared to other oversampling methods. Additionally, we conduct experiments to verify the effect of parameters on the model and provide suggestions for choosing appropriate values to improve performance.},
  archive      = {J_NPL},
  author       = {Song, Jiuxiang and Liu, Jizhong},
  doi          = {10.1007/s11063-024-11695-w},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {ISMOTE: A more accurate alternative for SMOTE},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robust TrafficSignNet algorithm for enhanced traffic sign
recognition in autonomous vehicles under varying light conditions.
<em>NPL</em>, <em>56</em>(5), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11693-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed significant advancements in machine perception, particularly in the context of self-driving vehicles. The accurate detection and interpretation of road signs by these vehicles are crucial for enhancing safety, intelligence, and efficiency on the roads. Consequently, there is a growing body of research dedicated to improving traffic sign recognition technologies, a key component of intelligent transportation systems. Annual statistics highlight numerous accidents attributable to factors such as excessive speed, variable lighting conditions, and the misinterpretation of traffic signs. In response to these challenges, a novel approach for the rapid and reliable recognition of traffic signs by moving vehicles has been developed. This approach leverages a custom dataset encompassing twelve object categories and seven subcategories, reflective of road sign diversities encountered in India. A specialized algorithm, TrafficSignNet, was devised to specifically identify signs related to speed, turning, zones, and bumps. This algorithm was trained on a comprehensive dataset comprising 4,962 images, with its performance evaluated using 705 images from real traffic scenarios. The evaluation demonstrates that the model achieves remarkable accuracy across various lighting conditions, processing up to 12 frames per second. This processing rate is compatible with the high-definition standards of contemporary vehicle cameras, which is 1280 × 720 pixels. The model&#39;s effectiveness is quantified through accuracy, precision, recall, and F1 score, with respective values of 0.985, 0.978, 0.964, and 0.971, showcasing its potential to significantly contribute to the advancement of smart transportation systems.},
  archive      = {J_NPL},
  author       = {Kandasamy, Kathiresan and Natarajan, Yuvaraj and Sri Preethaa, K. R. and Ali, Ahmed Abdi Yusuf},
  doi          = {10.1007/s11063-024-11693-y},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {A robust TrafficSignNet algorithm for enhanced traffic sign recognition in autonomous vehicles under varying light conditions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A label information aware model for multi-label text
classification. <em>NPL</em>, <em>56</em>(5), 1–18. (<a
href="https://doi.org/10.1007/s11063-024-11692-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label text classification (MLTC) refers to that each document is associated with more than one label at the same time, which attract much attention from researchers in both academia and industry. Existing methods have difficulties in determining label-related components from documents, which cannot effectively establish the association between textual features and label information. In fact, there are some label information, such as label semantic information and co-occurrence relations among labels, could be used to improve the performance on multi-label text classification. In this paper, we propose a label information aware model to utilize these information. Our model makes use of label semantic information to determine label-related components from textual features for obtaining the label-specific textual presentation for each sample, and then take advantages of co-occurrence relations among labels to construct interaction among label-specific textual presentation. The superiority of our model has been proved through comparing our method with several existing models on two datasets.},
  archive      = {J_NPL},
  author       = {Tian, Xiaoyu and Qin, Yongbin and Huang, Ruizhang and Chen, Yanping},
  doi          = {10.1007/s11063-024-11692-z},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {A label information aware model for multi-label text classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gudermannian neural networks for two-point nonlinear
singular model arising in the thermal-explosion theory. <em>NPL</em>,
<em>56</em>(4), 1–27. (<a
href="https://doi.org/10.1007/s11063-024-11512-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this research is to design the Gudermannian neural networks (GNNs) to solve a type of two-point nonlinear singular boundary value problems (TPN-SBVPs) that arise within thermal-explosion theory. The results of these investigation are provided for different neurons (4, 12 and 20), as well as absolute error along with the time complexity. For solving the TPN-SBVPs, a genetic algorithm (GA) and sequential quadratic programming (SQP) are used to optimize the error function. The accuracy of designed GNNs is provided by using a hybrid GA–SQP combination, which is based on a comparison of obtained and actual solutions. Furthermore, statistical analysis of the data is proposed in order to establish the competence as well as effectiveness of designed and the efficacy of the designed computing framework for solving the TPN-SBVPs.},
  archive      = {J_NPL},
  author       = {Fatima, Samara and Sabir, Zulqurnain and Baleanu, Dumitru and Alhazmi, Sharifah E.},
  doi          = {10.1007/s11063-024-11512-4},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-27},
  shortjournal = {Neural Process. Lett.},
  title        = {Gudermannian neural networks for two-point nonlinear singular model arising in the thermal-explosion theory},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction: A new evolutionary ensemble learning of
multimodal feature selection from microarray data. <em>NPL</em>,
<em>56</em>(4), 1. (<a
href="https://doi.org/10.1007/s11063-024-11549-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Nekouie, Nadia and Romoozi, Morteza and Esmaeili, Mahdi},
  doi          = {10.1007/s11063-024-11549-5},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1},
  shortjournal = {Neural Process. Lett.},
  title        = {Correction: A new evolutionary ensemble learning of multimodal feature selection from microarray data},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved stability analysis of neural networks with time
delay based on variable augmented free weight matrix. <em>NPL</em>,
<em>56</em>(4), 1–13. (<a
href="https://doi.org/10.1007/s11063-024-11628-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the stability of time-delay neural network system by the free-weighting matrices based on variable-augmentation.In the process of accurately evaluating the stability of delayed neural network systems, the conservative simplification of stability criteria has received widespread attention. In this paper, a variable-augmented-based free-weighting matrix method is applied to time-varying delayed neural network systems, and unnecessary free weighting matrices are removed. Some results with fewer free-weighting matrices are obtained, while maintaining their stability and conservatism. Finally, a specific neural network numerical example was used to demonstrate the effectiveness of this method.},
  archive      = {J_NPL},
  author       = {Li, FuDong and Xie, Wei and Zhu, WeiYi and Shi, ZongHao},
  doi          = {10.1007/s11063-024-11628-7},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-13},
  shortjournal = {Neural Process. Lett.},
  title        = {Improved stability analysis of neural networks with time delay based on variable augmented free weight matrix},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PANet: Pluralistic attention network for few-shot image
classification. <em>NPL</em>, <em>56</em>(4), 1–23. (<a
href="https://doi.org/10.1007/s11063-024-11638-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional deep learning methods require a large amount of labeled data for model training, which is laborious and costly in real word. Few-shot learning (FSL) aims to recognize novel classes with only a small number of labeled samples to address these challenges. We focus on metric-based few-shot learning with improvements in both feature extraction and metric method. In our work, we propose the Pluralistic Attention Network (PANet), a novel attention-oriented framework, involving both a local encoded intra-attention(LEIA) module and a global encoded reciprocal attention(GERA) module. The LEIA is designed to capture comprehensive local feature dependencies within every single sample. The GERA concentrates on the correlation between two samples and learns the discriminability of representations obtained from the LEIA. The two modules are complementary to each other and ensure the feature information within and between images can be fully utilized. Furthermore, we also design a dual-centralization (DC) cosine similarity to eliminate the disparity of data distribution in different dimensions and enhance the metric accuracy between support and query samples. Our method is thoroughly evaluated with extensive experiments, and the results demonstrate that with the contribution of each component, our model can achieve high-performance on four widely used few-shot classification benchmarks of miniImageNet, tieredImageNet, CUB-200-2011 and CIFAR-FS.},
  archive      = {J_NPL},
  author       = {Cao, Wenming and Li, Tianyuan and Liu, Qifan and He, Zhiquan},
  doi          = {10.1007/s11063-024-11638-5},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {PANet: Pluralistic attention network for few-shot image classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KGR: A kernel-mapping based group recommender system using
trust relations. <em>NPL</em>, <em>56</em>(4), 1–37. (<a
href="https://doi.org/10.1007/s11063-024-11639-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A massive amount of information explosion over the internet has caused a possible difficulty of information overload. To overcome this, Recommender systems are systematic tools that are rapidly being employed in several domains such as movies, travel, E-commerce, and music. In the existing research, several methods have been proposed for single-user modeling, however, the massive rise of social connections potentially increases the significance of group recommender systems (GRS). A GRS is one that jointly recommends a list of items to a collection of individuals based on their interests. Moreover, the single-user model poses several challenges to recommender systems such as data sparsity, cold start, and long tail problems. On the contrary hand, another hotspot for group-based recommendation is the modeling of user preferences and interests based on the groups to which they belong using effective aggregation strategies. To address such issues, a novel “KGR” group recommender system based on user-trust relations is proposed in this study using kernel mapping techniques. In the proposed model, user-trust networks or relations are exploited to generate trust-based groups of users which is one of the important behavioral and social aspects. More precisely, in KGR the group kernels and group residual matrices are exploited as well as seeking a multi-linear mapping between encoded vectors of group-item interactions and probability density function indicating how groups will rate the items. Moreover, to emphasize the relevance of individual preferences of users in a group to which they belong, a hybrid approach is also suggested in which group kernels and individual user kernels are merged as additive and multiplicative models. Furthermore, the proposed KGR is validated on two different trust-based datasets including Film Trust and CiaoDVD. In addition, KGR outperforms with an RMSE value of 0.3306 and 0.3013 on FilmTrust and CiaoDVD datasets which are lower than the 1.8176 and 1.1092 observed with the original KMR.},
  archive      = {J_NPL},
  author       = {Bukhari, Maryam and Maqsood, Muazzam and Aadil, Farhan},
  doi          = {10.1007/s11063-024-11639-4},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-37},
  shortjournal = {Neural Process. Lett.},
  title        = {KGR: A kernel-mapping based group recommender system using trust relations},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SS-CRE: A continual relation extraction method through
SimCSE-BERT and static relation prototypes. <em>NPL</em>,
<em>56</em>(4), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11647-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual relation extraction aims to learn new relations from a continuous stream of data while avoiding forgetting old relations. Existing methods typically use the BERT encoder to obtain semantic embeddings, ignoring the fact that the vector representations suffer from anisotropy and uneven distribution. Furthermore, the relation prototypes are usually computed by memory samples directly, resulting in the model being overly sensitive to memory samples. To solve these problems, we propose a new continual relation extraction method. Firstly, we modified the basic structure of the sample encoder to generate uniformly distributed semantic embeddings using the supervised SimCSE-BERT to obtain richer sample information. Secondly, we introduced static relation prototypes and dynamically adjust their proportion with dynamic relation prototypes to adapt to the feature space. Lastly, through experimental analysis on the widely used FewRel and TACRED datasets, the results demonstrate that the proposed method effectively enhances semantic embeddings and relation prototypes, resulting in a further alleviation of catastrophic forgetting in the model. The code will be soon released at https://github.com/SuyueW/SS-CRE .},
  archive      = {J_NPL},
  author       = {Chen, Jinguang and Wang, Suyue and Ma, Lili and Yang, Bo and Zhang, Kaibing},
  doi          = {10.1007/s11063-024-11647-4},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {SS-CRE: A continual relation extraction method through SimCSE-BERT and static relation prototypes},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving neural radiance fields using near-surface sampling
with point cloud generation. <em>NPL</em>, <em>56</em>(4), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11654-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural radiance field (NeRF) is an emerging view synthesis method that samples points in a three-dimensional (3D) space and estimates their existence and color probabilities. The disadvantage of NeRF is that it requires a long training time since it samples many 3D points. In addition, if one samples points from occluded regions or in the space where an object is unlikely to exist, the rendering quality of NeRF can be degraded. These issues can be solved by estimating the geometry of 3D scene. This paper proposes a near-surface sampling framework to improve the rendering quality of NeRF. To this end, the proposed method estimates the surface of a 3D object using depth images of the training set and performs sampling only near the estimated surface. To obtain depth information on a novel view, the paper proposes a 3D point cloud generation method and a simple refining method for projected depth from a point cloud. Experimental results show that the proposed near-surface sampling NeRF framework can significantly improve the rendering quality, compared to the original NeRF and three different state-of-the-art NeRF methods. In addition, one can significantly accelerate the training time of a NeRF model with the proposed near-surface sampling framework.},
  archive      = {J_NPL},
  author       = {Yoo, Hye Bin and Han, Hyun Min and Hwang, Sung Soo and Chun, Il Yong},
  doi          = {10.1007/s11063-024-11654-5},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {Improving neural radiance fields using near-surface sampling with point cloud generation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On stage-wise backpropagation for improving cheng’s method
for fully connected cascade networks. <em>NPL</em>, <em>56</em>(4),
1–32. (<a href="https://doi.org/10.1007/s11063-024-11655-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this journal, Cheng has proposed a backpropagation (BP) procedure called BPFCC for deep fully connected cascaded (FCC) neural network learning in comparison with a neuron-by-neuron (NBN) algorithm of Wilamowski and Yu. Both BPFCC and NBN are designed to implement the Levenberg-Marquardt method, which requires an efficient evaluation of the Gauss-Newton (approximate Hessian) matrix $$\nabla \textbf{r}^\textsf{T} \nabla \textbf{r}$$ , the cross product of the Jacobian matrix $$\nabla \textbf{r}$$ of the residual vector $$\textbf{r}$$ in nonlinear least squares sense. Here, the dominant cost is to form $$\nabla \textbf{r}^\textsf{T} \nabla \textbf{r}$$ by rank updates on each data pattern. Notably, NBN is better than BPFCC for the multiple $$q~\!(&gt;\!1)$$ -output FCC-learning when q rows (per pattern) of the Jacobian matrix $$\nabla \textbf{r}$$ are evaluated; however, the dominant cost (for rank updates) is common to both BPFCC and NBN. The purpose of this paper is to present a new more efficient stage-wise BP procedure (for q-output FCC-learning) that reduces the dominant cost with no rows of $$\nabla \textbf{r}$$ explicitly evaluated, just as standard BP evaluates the gradient vector $$\nabla \textbf{r}^\textsf{T} \textbf{r}$$ with no explicit evaluation of any rows of the Jacobian matrix $$\nabla \textbf{r}$$ .},
  archive      = {J_NPL},
  author       = {Mizutani, Eiji and Kubota, Naoyuki and Truong, Tam Chi},
  doi          = {10.1007/s11063-024-11655-4},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-32},
  shortjournal = {Neural Process. Lett.},
  title        = {On stage-wise backpropagation for improving cheng’s method for fully connected cascade networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective evolutionary neural architecture search for
recurrent neural networks. <em>NPL</em>, <em>56</em>(4), 1–31. (<a
href="https://doi.org/10.1007/s11063-024-11659-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural network (NN) architecture design is a nontrivial and time-consuming task that often requires a high level of human expertise. Neural architecture search (NAS) serves to automate the design of NN architectures and has proven to be successful in automatically finding NN architectures that outperform those manually designed by human experts. NN architecture performance can be quantified based on multiple objectives, which include model accuracy and some NN architecture complexity objectives, among others. The majority of modern NAS methods that consider multiple objectives for NN architecture performance evaluation are concerned with automated feed forward NN architecture design, which leaves multi-objective automated recurrent neural network (RNN) architecture design unexplored. RNNs are important for modeling sequential datasets, and prominent within the natural language processing domain. It is often the case in real world implementations of machine learning and NNs that a reasonable trade-off is accepted for marginally reduced model accuracy in favour of lower computational resources demanded by the model. This paper proposes a multi-objective evolutionary algorithm-based RNN architecture search method. The proposed method relies on approximate network morphisms for RNN architecture complexity optimisation during evolution. The results show that the proposed method is capable of finding novel RNN architectures with comparable performance to state-of-the-art manually designed RNN architectures, but with reduced computational demand.},
  archive      = {J_NPL},
  author       = {Booysen, Reinhard and Bosman, Anna Sergeevna},
  doi          = {10.1007/s11063-024-11659-0},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-31},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-objective evolutionary neural architecture search for recurrent neural networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A single image high-perception super-resolution
reconstruction method based on multi-layer feature fusion model with
adaptive compression and parameter tuning. <em>NPL</em>, <em>56</em>(4),
1–21. (<a href="https://doi.org/10.1007/s11063-024-11660-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a simple image high-perception super-resolution reconstruction method based on multi-layer feature fusion model with adaptive compression and parameter tuning. The aim is to further balance the high and low-frequency information of an image, enrich the detailed texture to improve perceptual quality, and improve the adaptive optimization and generalization of the model in the process of super-resolution reconstruction. First, an effective multi-layer fusion super-resolution (MFSR) basic model is constructed by the design of edge enhancement, refine layering, enhanced super-resolution generative adversarial network and other sub-models, and effective multi-layer fusion. This further enriches the image representation of features of different scales and depths and improves the feature representation of high and low-frequency information in a balanced way. Next, a total loss function of the generator is constructed with adaptive parameter tuning performance. The overall adaptability of the model is improved through adaptive weight distribution and fusion of content loss, perceptual loss, and adversarial loss, and improving the error while reducing the edge enhancement model. Finally, a fitness function with the evaluation perceptual function as the optimization strategy is constructed, and the model compression and adaptive tuning of MFSR are carried out based on the multi-mechanism fusion strategy. Consequently, the construction of the adaptive MFSR model is realized. Adaptive MFSR can maintain high peak signal to noise ratio and structural similarity on the test sets Set5, Set14, and BSD100, and achieve high-quality reconstructed images with low learned perceptual image patch similarity and perceptual index, while having good generalization capabilities.},
  archive      = {J_NPL},
  author       = {Zhang, Rui and Ren, Wenyu and Pan, Lihu and Bai, Xiaolu and Li, Ji},
  doi          = {10.1007/s11063-024-11660-7},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {A single image high-perception super-resolution reconstruction method based on multi-layer feature fusion model with adaptive compression and parameter tuning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight task-agreement meta learning for low-resource
speech recognition. <em>NPL</em>, <em>56</em>(4), 1–14. (<a
href="https://doi.org/10.1007/s11063-024-11661-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-learning has proven to be a powerful paradigm for transferring knowledge from prior tasks to facilitate the quick learning of new tasks in automatic speech recognition. However, the differences between languages (tasks) lead to variations in task learning directions, causing the harmful competition for model’s limited resources. To address this challenge, we introduce the task-agreement multilingual meta-learning (TAMML), which adopts the gradient agreement algorithm to guide the model parameters towards a direction where tasks exhibit greater consistency. However, the computation and storage cost of TAMML grows dramatically with model’s depth increases. To address this, we further propose a simplification called TAMML-Light which only uses the output layer for gradient calculation. Experiments on three datasets demonstrate that TAMML and TAMML-Light achieve outperform meta-learning approaches, yielding superior results.Furthermore, TAMML-Light can reduce at least 80 $$\%$$ of the relative increased computation expenses compared to TAMML.},
  archive      = {J_NPL},
  author       = {Chen, Yaqi and Zhang, Hao and Zhang, Wenlin and Qu, Dan and Yang, Xukui},
  doi          = {10.1007/s11063-024-11661-6},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-14},
  shortjournal = {Neural Process. Lett.},
  title        = {A lightweight task-agreement meta learning for low-resource speech recognition},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection method of manipulator grasp pose based on RGB-d
image. <em>NPL</em>, <em>56</em>(4), 1–24. (<a
href="https://doi.org/10.1007/s11063-024-11662-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to better solve the visual detection problem of manipulator grasping non-cooperative targets, we propose a method of grasp pose detection based on pixel point and feature fusion. By using the improved U2net network as the backbone for feature extraction and feature fusion of the input image, and the grasp prediction layer detects the grasp pose on each pixel. In order to adapt the U2net to grasp pose detection and improve its detection performance, we improve detection speed and control sampling depth by simplifying its network structure, while retaining some shallow features in feature fusion to enhance its feature extraction capability. We introduce depthwise separable convolution in the grasp prediction layer, further fusing the features extracted from the backbone to obtain predictive feature maps with stronger feature expressiveness. FocalLoss is selected as the loss function to solve the problem of unbalanced positive and negative samples in network training. We use the Cornell dataset for training and testing, perform pixel-level labeling on the image, and replace the labels that are not conducive to the actual grasping. This adaptation helps the dataset better suit the network training and testing while meeting the real-world grasping requirements of the manipulator. The evaluation results on image-wise and object-wise are 95.65% and 91.20% respectively, and the detection speed is 0.007 s/frame. We also used the method for actual manipulator grasping experiments. The results show that our method has improved accuracy and speed compared with previous methods, and has strong generalization ability and portability.},
  archive      = {J_NPL},
  author       = {Huang, Cheng and Pang, Zhen and Xu, Jiazhong},
  doi          = {10.1007/s11063-024-11662-5},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-24},
  shortjournal = {Neural Process. Lett.},
  title        = {Detection method of manipulator grasp pose based on RGB-D image},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exponential stability of impulsive stochastic neutral neural
networks with lévy noise under non-lipschitz conditions. <em>NPL</em>,
<em>56</em>(4), 1–15. (<a
href="https://doi.org/10.1007/s11063-024-11663-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the exponential stability issue of stochastic impulsive neutral neural networks driven by Lévy noise is explored. By resorting to the Lyapunov-Krasovskii function that involves neutral time-delay components, the properties of the Lévy process, as well as various inequality approaches, some sufficient exponential stability criteria in non-Lipschitz cases are obtained. Besides, the achieved results depend on the time-delay, noise intensity, and impulse factor. At the end of the paper, two numerical examples with simulations are presented to demonstrate the effectiveness and feasibility of the addressed results},
  archive      = {J_NPL},
  author       = {Ma, Shuo and Li, Jiangman and Liu, Ruonan and Li, Qiang},
  doi          = {10.1007/s11063-024-11663-4},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-15},
  shortjournal = {Neural Process. Lett.},
  title        = {Exponential stability of impulsive stochastic neutral neural networks with lévy noise under non-lipschitz conditions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A transfer-learning-like neural dynamics algorithm for
arctic sea ice extraction. <em>NPL</em>, <em>56</em>(4), 1–24. (<a
href="https://doi.org/10.1007/s11063-024-11664-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sea ice plays a pivotal role in ocean-related research, necessitating the development of highly accurate and robust techniques for its extraction from diverse satellite remote sensing imagery. However, conventional learning methods face limitations due to the soaring cost and time associated with manually collecting sufficient sea ice data for model training. This paper introduces an innovative approach where Neural Dynamics (ND) algorithms are seamlessly integrated with a recurrent neural network, resulting in a Transfer-Learning-Like Neural Dynamics (TLLND) algorithm specifically tailored for sea ice extraction. Firstly, given the susceptibility of the image extraction process to noise in practical scenarios, an ND algorithm with noise tolerance and high extraction accuracy is proposed to address this challenge. Secondly, The internal coefficients of the ND algorithm are determined using a parametric method. Subsequently, the ND algorithm is formulated as a decoupled dynamical system. This enables the coefficients trained on a linear equation problem dataset to be directly generalized to solve the sea ice extraction challenges. Theoretical analysis ensures that the effectiveness of the proposed TLLND algorithm remains unaffected by the specific characteristics of various dataset. To validate its efficacy, robustness, and generalization performance, several comparative experiments are conducted using diverse Arctic sea ice satellite imagery with varying levels of noise. The outcomes of these experiments affirm the competence of the proposed TLLND algorithm in addressing the complexities associated with sea ice extraction.},
  archive      = {J_NPL},
  author       = {Peng, Bo and Zhang, Kefan and Jin, Long and Shang, Mingsheng},
  doi          = {10.1007/s11063-024-11664-3},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-24},
  shortjournal = {Neural Process. Lett.},
  title        = {A transfer-learning-like neural dynamics algorithm for arctic sea ice extraction},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge graph-aware deep interest extraction network on
sequential recommendation. <em>NPL</em>, <em>56</em>(4), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11665-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation is the mainstream approach in the field of click-through-rate (CTR) prediction for modeling users’ behavior. This behavior implies the change of the user’s interest, and the goal of sequential recommendation is to capture this dynamic change. However, existing studies have focused on designing complex dedicated networks to capture user interests from user behavior sequences, while neglecting the use of auxiliary information. Recently, knowledge graph (KG) has gradually attracted the attention of researchers as a structured auxiliary information. Items and their attributes in the recommendation, can be mapped to knowledge triples in the KG. Therefore, the introduction of KG to recommendation can help us obtain more expressive item representations. Since KG can be considered a special type of graph, it is possible to use the graph neural network (GNN) to propagate the rich information contained in the KG into the item representation. Based on this idea, this paper proposes a recommendation method that uses KG as auxiliary information. The method first propagates the knowledge information in the KG using GNN to obtain a knowledge-rich item representation. Then the temporal features in the item sequence are extracted using a transformer for CTR prediction, namely the Knowledge Graph-Aware Deep Interest Extraction network (KGDIE). To evaluate the performance of this model, we conducted extensive experiments on two real datasets with different scenarios. The results showed that the KGDIE method could outperform several state-of-the-art baselines. The source code of our model is available at https://github.com/gylgyl123/kgdie .},
  archive      = {J_NPL},
  author       = {Wang, Zhenhai and Xu, Yuhao and Wang, Zhiru and Fan, Rong and Guo, Yunlong and Li, Weimin},
  doi          = {10.1007/s11063-024-11665-2},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Knowledge graph-aware deep interest extraction network on sequential recommendation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A random focusing method with jensen–shannon divergence for
improving deep neural network performance ensuring architecture
consistency. <em>NPL</em>, <em>56</em>(4), 1–18. (<a
href="https://doi.org/10.1007/s11063-024-11668-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple hidden layers in deep neural networks perform non-linear transformations, enabling the extraction of meaningful features and the identification of relationships between input and output data. However, the gap between the training and real-world data can result in network overfitting, prompting the exploration of various preventive methods. The regularization technique called ’dropout’ is widely used for deep learning models to improve the training of robust and generalized features. During the training phase with dropout, neurons in a particular layer are randomly selected to be ignored for each input. This random exclusion of neurons encourages the network to depend on different subsets of neurons at different times, fostering robustness and reducing sensitivity to specific neurons. This study introduces a novel approach called random focusing, departing from complete neuron exclusion in dropout. The proposed random focusing selectively highlights random neurons during training, aiming for a smoother transition between training and inference phases while keeping network architecture consistent. This study also incorporates Jensen–Shannon Divergence to enhance the stability and efficacy of the random focusing method. Experimental validation across tasks like image classification and semantic segmentation demonstrates the adaptability of the proposed methods across different network architectures, including convolutional neural networks and transformers.},
  archive      = {J_NPL},
  author       = {Kim, Wonjik},
  doi          = {10.1007/s11063-024-11668-z},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {A random focusing method with Jensen–Shannon divergence for improving deep neural network performance ensuring architecture consistency},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive sliding mode fixed-/preassigned-time
synchronization of stochastic memristive neural networks with
mixed-delays. <em>NPL</em>, <em>56</em>(4), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11669-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper addresses the fixed-/preassigned-time synchronization of stochastic memristive neural networks (MNNs) with uncertain parameters and mixed delays. Adaptive sliding mode control (ASMC) technology is mainly utilized. First, a proper sliding surface is constructed and the adaptive laws are given. Also, the synchronization control scheme is designed, which can ensure error system to realize fixed-time stability. Second, preassigned-time sliding mode control scheme is mainly provided to realize fast synchronization of MNNs. The presented theoretical methods can guarantee the error system convergence and stability for reaching and sliding mode within preassigned-time. And the synchronization criteria and explicit expression of settling time (ST) are acquired, where ST is not related with initial values and controller parameters but can be predefined perferentially. Finally, the calculation example is offered to interpret the practicability and availability of the innovations in this paper.},
  archive      = {J_NPL},
  author       = {Gao, Jie and Chen, Xiangyong and Qiu, Jianlong and Wang, Chunmei and Jia, Tianyuan},
  doi          = {10.1007/s11063-024-11669-y},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {Adaptive sliding mode fixed-/Preassigned-time synchronization of stochastic memristive neural networks with mixed-delays},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MDGCL: Graph contrastive learning framework with multiple
graph diffusion methods. <em>NPL</em>, <em>56</em>(4), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11672-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, some classical graph contrastive learning(GCL) frameworks have been proposed to address the problem of sparse labeling of graph data in the real world. However, in node classification tasks, there are two obvious problems with existing GCL frameworks: first, the stochastic augmentation methods they adopt lose a lot of semantic information; second, the local–local contrasting mode selected by most frameworks ignores the global semantic information of the original graph, which limits the node classification performance of these frameworks. To address the above problems, this paper proposes a novel graph contrastive learning framework, MDGCL, which introduces two graph diffusion methods, Markov and PPR, and a deterministic–stochastic data augmentation strategy while retaining the local–local contrasting mode. Specifically, before using the two stochastic augmentation methods (FeatureDrop and EdgeDrop), MDGCL first uses two deterministic augmentation methods (Markov diffusion and PPR diffusion) to perform data augmentation on the original graph to increase the semantic information, this step ensures subsequent stochastic augmentation methods do not lose too much semantic information. Meanwhile, the diffusion matrices carried by the augmented views contain global semantic information of the original graph, allowing the framework to utilize the global semantic information while retaining the local-local contrasting mode, which further enhances the node classification performance of the framework. We conduct extensive comparative experiments on multiple benchmark datasets, and the results show that MDGCL outperforms the representative baseline frameworks on node classification tasks. Among them, compared with COSTA, MDGCL’s node classification accuracy has been improved by 1.07% and 0.41% respectively on two representative datasets, Amazon-Photo and Coauthor-CS. In addition, we also conduct ablation experiments on two datasets, Cora and CiteSeer, to verify the effectiveness of each improvement work of our framework.},
  archive      = {J_NPL},
  author       = {Li, Yuqiang and Zhang, Yi and Liu, Chun},
  doi          = {10.1007/s11063-024-11672-3},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {MDGCL: Graph contrastive learning framework with multiple graph diffusion methods},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A hybrid approach using the fuzzy logic
system and the modified genetic algorithm for prediction of skin cancer.
<em>NPL</em>, <em>56</em>(4), 1. (<a
href="https://doi.org/10.1007/s11063-024-11674-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Jha, Saurabh and Mehta, Ashok Kumar},
  doi          = {10.1007/s11063-024-11674-1},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1},
  shortjournal = {Neural Process. Lett.},
  title        = {Retraction note: A hybrid approach using the fuzzy logic system and the modified genetic algorithm for prediction of skin cancer},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Histo-quartic graph and stack entropy-based
deep neural network method for brain and tumor segmentation.
<em>NPL</em>, <em>56</em>(4), 1. (<a
href="https://doi.org/10.1007/s11063-024-11675-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Srividya, Kotagiri and Anilkumar, B. and Sowjanya, A. Mary},
  doi          = {10.1007/s11063-024-11675-0},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1},
  shortjournal = {Neural Process. Lett.},
  title        = {Retraction note: Histo-quartic graph and stack entropy-based deep neural network method for brain and tumor segmentation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Recent deep learning techniques, challenges
and its applications for medical healthcare system: A review.
<em>NPL</em>, <em>56</em>(4), 1. (<a
href="https://doi.org/10.1007/s11063-024-11676-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Pandey, Saroj Kumar and Janghel, Rekh Ram},
  doi          = {10.1007/s11063-024-11676-z},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1},
  shortjournal = {Neural Process. Lett.},
  title        = {Retraction note: recent deep learning techniques, challenges and its applications for medical healthcare system: a review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Kernel extreme learning machine with discriminative transfer
feature and instance selection for unsupervised domain adaptation.
<em>NPL</em>, <em>56</em>(4), 1–27. (<a
href="https://doi.org/10.1007/s11063-024-11677-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of domain adaptation (DA) is to develop a robust decision model on the source domain effectively generalize to the target domain data. State-of-the-art domain adaptation methods typically focus on finding an optimal inter-domain invariant feature representation or helpful instances from the source domain. In this paper, we propose a kernel extreme learning machine with discriminative transfer features and instance selection (KELM-DTF-IS) for unsupervised domain adaptation tasks, which consists of two steps: discriminative transfer feature extraction and classification with instance selection. At the feature extraction stage, we extend cross domain mean approximation(CDMA) by incorporating a penalty term and develop discriminative cross domain mean approximation (d-CDMA) to optimize the category separability between instances. Subsequently, d-CDMA is integrated into kernel ELM-AutoEncoder(KELM-AE) for extracting inter-domain invariant features. During the classification process, our approach uses CDMA metrics to compute a weights to each source instances based on their impact in reducing distribution differences between domains. Instances with a greater effect receive higher weights and vice versa. These weights are then used to distinguish and select source domain instances before incorporating them into weight KELM for proposing an adaptive classifier. Finally, we apply our approach to conduct classification experiments on publicly available domain adaptation datasets, and the results demonstrate its superiority over KELM and numerous other domain adaptation approaches.},
  archive      = {J_NPL},
  author       = {Zang, Shaofei and Li, Huimin and Lu, Nannan and Ma, Chao and Gao, Jiwei and Ma, Jianwei and Lv, Jinfeng},
  doi          = {10.1007/s11063-024-11677-y},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-27},
  shortjournal = {Neural Process. Lett.},
  title        = {Kernel extreme learning machine with discriminative transfer feature and instance selection for unsupervised domain adaptation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image classification based on low-level feature enhancement
and attention mechanism. <em>NPL</em>, <em>56</em>(4), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11680-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based image classification networks heavily rely on the extracted features. However, as the model becomes deeper, important features may be lost, resulting in decreased accuracy. To tackle this issue, this paper proposes an image classification method that enhances low-level features and incorporates an attention mechanism. The proposed method employs EfficientNet as the backbone network for feature extraction. Firstly, the Feature Enhancement Module quantifies and statistically processes low-level features from shallow layers, thereby enhancing the feature information. Secondly, the Convolutional Block Attention Module enhances the high-level features to improve the extraction of global features. Finally, the enhanced low-level features and global features are fused to supplement low-resolution global features with high-resolution details, further improving the model’s image classification ability. Experimental results illustrate that the proposed method achieves a Top-1 classification accuracy of 86.49% and a Top-5 classification accuracy of 96.90% on the ETH-Food101 dataset, 86.99% and 97.24% on the VireoFood-172 dataset, and 70.99% and 92.73% on the UEC-256 dataset. These results demonstrate that the proposed method outperforms existing methods in terms of classification performance.},
  archive      = {J_NPL},
  author       = {Zhang, Yong and Li, Xueqin and Chen, Wenyun and Zang, Ying},
  doi          = {10.1007/s11063-024-11680-3},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Image classification based on low-level feature enhancement and attention mechanism},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time series classification based on forward echo state
convolution network. <em>NPL</em>, <em>56</em>(3), 1–21. (<a
href="https://doi.org/10.1007/s11063-024-11449-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Echo state network (ESN) is an efficient recurrent neural network that has achieved good results in time series prediction tasks. Still, its application in time series classification tasks has yet to develop fully. In this study, we work on the time series classification problem based on echo state networks. We propose a new framework called forward echo state convolutional network (FESCN). It consists of two parts, the encoder and the decoder, where the encoder part is composed of a forward topology echo state network (FT-ESN), and the decoder part mainly consists of a convolutional layer and a max-pooling layer. We apply the proposed network framework to the univariate time series dataset UCR and compare it with six traditional methods and four neural network models. The experimental findings demonstrate that FESCN outperforms other methods in terms of overall classification accuracy. Additionally, we investigated the impact of reservoir size on network performance and observed that the optimal classification results were obtained when the reservoir size was set to 32. Finally, we investigated the performance of the network under noise interference, and the results show that FESCN has a more stable network performance compared to EMN (echo memory network).},
  archive      = {J_NPL},
  author       = {Xia, Lei and Tang, Jianfeng and Li, Guangli and Fu, Jun and Duan, Shukai and Wang, Lidan},
  doi          = {10.1007/s11063-024-11449-8},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Time series classification based on forward echo state convolution network},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A prototype-based neural network for image anomaly detection
and localization. <em>NPL</em>, <em>56</em>(3), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11466-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image anomaly detection and localization perform not only image-level anomaly classification but also locate pixel-level anomaly regions. Recently, it has received much research attention due to its wide application in various fields. This paper proposes ProtoAD, a prototype-based neural network for image anomaly detection and localization. First, the patch features of normal images are extracted by a deep network pre-trained on nature images. Then, the prototypes of the normal patch features are learned by non-parametric clustering. Finally, we construct an image anomaly localization network (ProtoAD) by appending the feature extraction network with L2 feature normalization, a $$1\times 1$$ convolutional layer, a channel max-pooling, and a subtraction operation. We use the prototypes as the kernels of the $$1\times 1$$ convolutional layer; therefore, our neural network does not need a training phase and can conduct anomaly detection and localization in an end-to-end manner. Extensive experiments on two challenging industrial anomaly detection datasets, MVTec AD and BTAD, demonstrate that ProtoAD achieves competitive performance compared to the state-of-the-art methods with a higher inference speed. The code and pre-trained models are publicly available at https://github.com/98chao/ProtoAD .},
  archive      = {J_NPL},
  author       = {Huang, Chao and Kang, Zhao and Wu, Hong},
  doi          = {10.1007/s11063-024-11466-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {A prototype-based neural network for image anomaly detection and localization},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CFDepthNet: Monocular depth estimation introducing
coordinate attention and texture features. <em>NPL</em>, <em>56</em>(3),
1–17. (<a href="https://doi.org/10.1007/s11063-024-11477-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling the depth estimation of low-texture regions using photometric error loss is a challenge due to the difficulty of achieving convergence due to the presence of multiple local minima for pixels in low-texture regions (or even no-texture regions). In this paper, based on the photometric loss, we also introduce texture feature metric loss as a constraint and combine the coordinate attention mechanism to improve the depth map&#39;s texture quality and edge detail. This paper uses a simple yet compact network structure, a unique loss function, and a relatively flexible embedded attention module, which is more effective and easier to arrange in robotic platforms with weak arithmetic power. The tests show that our network structure not only shows high quality and state-of-the-art results on the KITTI dataset, but the same training results also perform well on the cityscapes and Make3D datasets.},
  archive      = {J_NPL},
  author       = {Wei, Feng and Zhu, Jie and Wang, HuiBin and Shen, Jie},
  doi          = {10.1007/s11063-024-11477-4},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {CFDepthNet: Monocular depth estimation introducing coordinate attention and texture features},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyperbolic tangent-type variant-parameter and robust ZNN
solutions for resolving time-variant sylvester equation in
preassigned-time. <em>NPL</em>, <em>56</em>(3), 1–19. (<a
href="https://doi.org/10.1007/s11063-024-11482-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve a general time-variant Sylvester equation, two novel zeroing neural networks (ZNNs) solutions are designed and analyzed. In the foregoing ZNN solutions, the design convergent parameters (CPs) before the nonlinear stimulated functions are very pivotal because CPs basically decide the convergent speeds. Nonetheless, the CPs are generally set to be constants, which is not feasible because CPs are generally time-variant in practical hardware conditions particularly when the external noises invade. So, a lot of variant-parameter ZNNs (VP-ZNNs) with time-variant CPs have been come up with. Comparing with fixed-parameter ZNNs, the foregoing VP-ZNNs have been illustrated to own better convergence, the downside is that the CPs generally increases over time, and will be probably infinite at last. Obviously, infinite large CPs would lead to be non-robustness of the ZNN schemes, which are not permitted in reality when the exterior noises inject. Moreover, even though VP-ZNNs are convergent over time, the growth of CPs will waste tremendous computing resources. Based on these factors, 2 hyperbolic tangent-type variant-parameter robust ZNNs (HTVPR-ZNNs) have been proposed in this paper. Both the convergent preassigned-time of the HTVPR-ZNN and top-time boundary of CPs are theoretically investigated. Many numerical simulations substantiated the admirable validity of the HTVPR-ZNN solutions.},
  archive      = {J_NPL},
  author       = {Luo, Jiawei and Yu, Lei and Xiong, Bangshu},
  doi          = {10.1007/s11063-024-11482-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {Hyperbolic tangent-type variant-parameter and robust ZNN solutions for resolving time-variant sylvester equation in preassigned-time},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pattern control of neural networks with two-dimensional
diffusion and mixed delays. <em>NPL</em>, <em>56</em>(3), 1–24. (<a
href="https://doi.org/10.1007/s11063-024-11491-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a two-neuron reaction–diffusion neural network with discrete and distributed delays is proposed, and the state feedback control strategy is adopted to achieve control of its spatiotemporal dynamical behaviours. Adding two virtual neurons, the original system is transformed into a neural network only containing the discrete delay. The conditions under which Hopf bifurcation and Turing instability arise are determined through analysis of the characteristic equation. Additionally, the amplitude equations are derived with the aid of weakly nonlinear analysis, and the selection of the Turing patterns is determined. The simulation results demonstrate that the state feedback controller can delay the onset of Hopf bifurcation and suppress the generation of Turing patterns.},
  archive      = {J_NPL},
  author       = {Luan, Yifeng and Xiao, Min and Yang, Xinsong and Du, Xiangyu and Ding, Jie and Cao, Jinde},
  doi          = {10.1007/s11063-024-11491-6},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-24},
  shortjournal = {Neural Process. Lett.},
  title        = {Pattern control of neural networks with two-dimensional diffusion and mixed delays},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distantly supervised relation extraction based on residual
attention and self learning. <em>NPL</em>, <em>56</em>(3), 1–16. (<a
href="https://doi.org/10.1007/s11063-024-11497-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction is an important task in information extraction, which aims to identify the relation between two given entities. The algorithm based on distant supervision can automatically generate a large amount of annotated data, which becomes the main method to deal with the task of relation extraction. However, previous studies rely too much on the precision of supervision information and ignore the effective supervision information hidden in the case of mislabeling, which leads to the loss of supervision information. To solve this problem, we propose the distantly supervised relation extraction model based on residual attention and self-learning. The model uses residual attention to extract features, and then uses self-learning idea to generate corrected labels for training data, which are added into the training process as supervisory signals to prevent parameter error updates caused by noisy labels. The model can not only reduce the problem of mislabeling caused by distant supervision, but also makes full use of the available supervisory information in the data to improve data utilization. Experiments show that compared with the existing mainstream baseline methods, the proposed model has higher precision and recall.},
  archive      = {J_NPL},
  author       = {Zheng, Zhiyun and Xu, Yamei and Liu, Yun and Zhang, Xingjin and Li, Lun and Li, Dun},
  doi          = {10.1007/s11063-024-11497-0},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Distantly supervised relation extraction based on residual attention and self learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SSGAN: A semantic similarity-based GAN for small-sample
image augmentation. <em>NPL</em>, <em>56</em>(3), 1–21. (<a
href="https://doi.org/10.1007/s11063-024-11498-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image sample augmentation refers to strategies for increasing sample size by modifying current data or synthesizing new data based on existing data. This technique is of vital significance in enhancing the performance of downstream learning tasks in widespread small-sample scenarios. In recent years, GAN-based image augmentation methods have gained significant attention and research focus. They have achieved remarkable generation results on large-scale datasets. However, their performance tends to be unsatisfactory when applied to datasets with limited samples. Therefore, this paper proposes a semantic similarity-based small-sample image augmentation method named SSGAN. Firstly, a relatively shallow pyramid-structured GAN-based backbone network was designed, aiming to enhance the model’s feature extraction capabilities to adapt to small sample sizes. Secondly, a feature selection module based on high-dimensional semantics was designed to optimize the loss function, thereby improving the model’s learning capacity. Lastly, extensive comparative experiments and comprehensive ablation experiments were carried out on the “Flower” and “Animal” datasets. The results indicate that the proposed method outperforms other classical GANs methods in well-established evaluation metrics such as FID and IS, with improvements of 18.6 and 1.4, respectively. The dataset augmented by SSGAN significantly enhances the performance of the classifier, achieving a 2.2% accuracy improvement compared to the best-known method. Furthermore, SSGAN demonstrates excellent generalization and robustness.},
  archive      = {J_NPL},
  author       = {Ma, Congcong and Mi, Jiaqi and Gao, Wanlin and Tao, Sha},
  doi          = {10.1007/s11063-024-11498-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {SSGAN: A semantic similarity-based GAN for small-sample image augmentation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Target oriented dynamic adaption for cross-domain few-shot
learning. <em>NPL</em>, <em>56</em>(3), 1–18. (<a
href="https://doi.org/10.1007/s11063-024-11508-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning has achieved satisfactory progress over the years, but these methods implicitly hypothesize that the data in the base (source) classes and novel (target) classes are sampled from the same data distribution (domain), which is often invalid in reality. The purpose of cross-domain few-shot learning (CD-FSL) is to successfully identify novel target classes with a small quantity of labeled instances on the target domain under the circumstance of domain shift between the source domain and the target domain. However, in CD-FSL, the knowledge learned by the network on the source domain often suffers from the situation of inadaptation when it is transferred to the target domain, since the instances on the source and target domains do not obey the same data distribution. To surmount this problem, we propose a Target Oriented Dynamic Adaption (TODA) model, which uses a tiny amount of target data to orient the network to dynamically adjust and adapt during training. Specifically, this work proposes a domain-specific adapter to ameliorate the network inadaptability issues in transfer to the target domain. The domain-specific adapter can make the extracted features more specific to the tasks in the target domain and reduce the impact of tasks in the source domain by combining them with the mainstream backbone network. In addition, we propose an adaptive optimization method in the network optimization process, which assigns different weights according to the importance of different optimization tasks. Extensive experiments on several benchmark datasets demonstrate the effectiveness of our TODA method.},
  archive      = {J_NPL},
  author       = {Chang, Xinyi and Du, Chunyu and Song, Xinjing and Liu, Weifeng and Wang, Yanjiang},
  doi          = {10.1007/s11063-024-11508-0},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {Target oriented dynamic adaption for cross-domain few-shot learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-step transfer learning in natural language processing
for the health domain. <em>NPL</em>, <em>56</em>(3), 1–26. (<a
href="https://doi.org/10.1007/s11063-024-11526-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The restricted access to data in healthcare facilities due to patient privacy and confidentiality policies has led to the application of general natural language processing (NLP) techniques advancing relatively slowly in the health domain. Additionally, because clinical data is unique to various institutions and laboratories, there are not enough standards and conventions for data annotation. In places without robust death registration systems, the cause of death (COD) is determined through a verbal autopsy (VA) report. A non-clinician field agent completes a VA report using a set of standardized questions as guide to identify the symptoms of a COD. The narrative text of the VA report is used as a case study to examine the difficulties of applying NLP techniques to the healthcare domain. This paper presents a framework that leverages knowledge across multiple domains via two domain adaptation techniques: feature extraction and fine-tuning. These techniques aim to improve VA text representations for COD classification tasks in the health domain. The framework is motivated by multi-step learning, where a final learning task is realized via a sequence of intermediate learning tasks. The framework builds upon the strengths of the Bidirectional Encoder Representations from Transformers (BERT) and Embeddings from Language Models (ELMo) models pretrained on the general English and biomedical domains. These models are employed to extract features from the VA narratives. Our results demonstrate improved performance when initializing the learning of BERT embeddings with ELMo embeddings. The benefit of incorporating character-level information for learning word embeddings in the English domain, coupled with word-level information for learning word embeddings in the biomedical domain, is also evident.},
  archive      = {J_NPL},
  author       = {Manaka, Thokozile and Zyl, Terence Van and Kar, Deepak and Wade, Alisha},
  doi          = {10.1007/s11063-024-11526-y},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-26},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-step transfer learning in natural language processing for the health domain},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view multi-label learning with shared features
inconsistency. <em>NPL</em>, <em>56</em>(3), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11528-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view multi-label (MVML) learning is a framework for solving the problem of associating a single instance with a set of class labels in the presence of multiple types of data features. The extraction of shared features among multiple views for label prediction is a common MVML learning method. However, previous approaches assumed that the number and association degree of shared features were the same across views. In fact, they differ in the number and degree of association. The above assumption can lead to a poor communicability of the views. Therefore, this paper proposes an MVML learning method based on the inconsistent shared features extracted by the graph attention model. The first step is to extract the shared and private features of multiple views. Next, the graph attention mechanism is adopted to learn the association degree of shared features of different views and calculate the adjacency matrix and attention coefficient. The number of associations is determined by taking the obtained adjacency matrix as a mask matrix, while the association degree of shared features is measured by the attention weight matrix. Finally, the new shared features are obtained for multi-label prediction. We conducted experiments on seven MVML datasets to compare the proposed algorithm with seven advanced algorithms. The experimental results demonstrate the advantages of our algorithm.},
  archive      = {J_NPL},
  author       = {Li, Qingyan and Cheng, Yusheng},
  doi          = {10.1007/s11063-024-11528-w},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-view multi-label learning with shared features inconsistency},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking regularization with random label smoothing.
<em>NPL</em>, <em>56</em>(3), 1–10. (<a
href="https://doi.org/10.1007/s11063-024-11579-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regularization helps to improve machine learning techniques by penalizing the models during training. Such approaches act in either the input, internal, or output layers. Regarding the latter, label smoothing is widely used to introduce noise in the label vector, making learning more challenging. This work proposes a new label regularization method, Random Label Smoothing, that attributes random values to the labels while preserving their semantics during training. The idea is to change the entire label into fixed arbitrary values. Results show improvements in image classification and super-resolution tasks, outperforming state-of-the-art techniques for such purposes.},
  archive      = {J_NPL},
  author       = {dos Santos, Claudio Filipi Gonçalves and Papa, João Paulo},
  doi          = {10.1007/s11063-024-11579-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-10},
  shortjournal = {Neural Process. Lett.},
  title        = {Rethinking regularization with random label smoothing},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Investigating deep learning for early detection and
decision-making in alzheimer’s disease: A comprehensive review.
<em>NPL</em>, <em>56</em>(3), 1–38. (<a
href="https://doi.org/10.1007/s11063-024-11600-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a neurodegenerative disorder that affects millions of people worldwide, making early detection essential for effective intervention. This review paper provides a comprehensive analysis of the use of deep learning techniques, specifically convolutional neural networks (CNN) and vision transformers (ViT), for the classification of AD using brain imaging data. While previous reviews have covered similar topics, this paper offers a unique perspective by providing a detailed comparison of CNN and ViT for AD classification, highlighting the strengths and limitations of each approach. Additionally, the review presents an updated and thorough analysis of the most recent studies in the field, including the latest advancements in CNN and ViT architectures, training methods, and performance evaluation metrics. Furthermore, the paper discusses the ethical considerations and challenges associated with the use of deep learning models for AD classification, such as the need for interpretability and the potential for bias. By addressing these issues, this review aims to provide valuable insights for future research and clinical applications, ultimately advancing the field of AD classification using deep learning techniques.},
  archive      = {J_NPL},
  author       = {Hcini, Ghazala and Jdey, Imen and Dhahri, Habib},
  doi          = {10.1007/s11063-024-11600-5},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-38},
  shortjournal = {Neural Process. Lett.},
  title        = {Investigating deep learning for early detection and decision-making in alzheimer’s disease: A comprehensive review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TLCE: Transfer-learning based classifier ensembles for
few-shot class-incremental learning. <em>NPL</em>, <em>56</em>(3), 1–17.
(<a href="https://doi.org/10.1007/s11063-024-11605-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class-incremental learning (FSCIL) struggles to incrementally recognize novel classes from few examples without catastrophic forgetting of old classes or overfitting to new classes. We propose TLCE, which ensembles multiple pre-trained models to improve separation of novel and old classes. Specifically, we use episodic training to map images from old classes to quasi-orthogonal prototypes, which minimizes interference between old and new classes. Then, we incorporate the use of ensembling diverse pre-trained models to further tackle the challenge of data imbalance and enhance adaptation to novel classes. Extensive experiments on various datasets demonstrate that our transfer learning ensemble approach outperforms state-of-the-art FSCIL methods.},
  archive      = {J_NPL},
  author       = {Wang, Shuangmei and Cao, Yang and Wu, Tieru},
  doi          = {10.1007/s11063-024-11605-0},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {TLCE: Transfer-learning based classifier ensembles for few-shot class-incremental learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified asymmetric knowledge distillation framework for
image classification. <em>NPL</em>, <em>56</em>(3), 1–25. (<a
href="https://doi.org/10.1007/s11063-024-11606-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation is a model compression technique that transfers knowledge learned by teacher networks to student networks. Existing knowledge distillation methods greatly expand the forms of knowledge, but also make the distillation models complex and symmetric. However, few studies have explored the commonalities among these methods. In this study, we propose a concise distillation framework to unify these methods and a method to construct asymmetric knowledge distillation under the framework. Asymmetric distillation aims to enable differentiated knowledge transfers for different distillation objects. We designed a multi-stage shallow-wide branch bifurcation method to distill different knowledge representations and a grouping ensemble strategy to supervise the network to teach and learn selectively. Consequently, we conducted experiments using image classification benchmarks to verify the proposed method. Experimental results show that our implementation can achieve considerable improvements over existing methods, demonstrating the effectiveness of the method and the potential of the framework.},
  archive      = {J_NPL},
  author       = {Ye, Xin and Tian, Xiang and Zheng, Bolun and Zhou, Fan and Chen, Yaowu},
  doi          = {10.1007/s11063-024-11606-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-25},
  shortjournal = {Neural Process. Lett.},
  title        = {A unified asymmetric knowledge distillation framework for image classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Disentangled variational autoencoder for social
recommendation. <em>NPL</em>, <em>56</em>(3), 1–23. (<a
href="https://doi.org/10.1007/s11063-024-11607-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommendation aims to improve the recommendation performance by learning user interest and social representations from users’ interaction records and social relations. Intuitively, these learned representations entangle user interest factors with social factors because users’ interaction behaviors and social relations affect each other. A high-quality recommender system should provide items to a user according to his/her interest factors. However, most existing social recommendation models aggregate the two kinds of representations indiscriminately, and this kind of aggregation limits their recommendation performance. In this paper, we develop a model called Disentangled Variational autoencoder for Social Recommendation (DVSR) to disentangle interest and social factors from the two kinds of user representations. Firstly, we perform a preliminary analysis of the entangled information on three popular social recommendation datasets. Then, we present the model architecture of DVSR, which is based on the Variational AutoEncoder (VAE) framework. Besides the traditional method of training VAE, we also use contrastive estimation to penalize the mutual information between interest and social factors. Extensive experiments are conducted on three benchmark datasets to evaluate the effectiveness of our model.},
  archive      = {J_NPL},
  author       = {Zhang, Yongshuai and Huang, Jiajin and Yang, Jian},
  doi          = {10.1007/s11063-024-11607-y},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {Disentangled variational autoencoder for social recommendation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient visual metaphor image generation based on metaphor
understanding. <em>NPL</em>, <em>56</em>(3), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11609-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaphor has significant implications for revealing cognitive and thinking mechanisms. Visual metaphor image generation not only presents metaphorical connotations intuitively but also reflects AI’s understanding of metaphor through the generated images. This paper investigates the task of generating images based on text with visual metaphors. We explore metaphor image generation and create a dataset containing sentences with visual metaphors. Then, we propose a visual metaphor generation image framework based on metaphor understanding, which is more tailored to the essence of metaphor, better utilizes visual features, and has stronger interpretability. Specifically, the framework extracts the source domain, target domain, and metaphor interpretation from metaphorical sentences, separating the elements of the metaphor to deepen the understanding of its themes and intentions. Additionally, the framework introduces image data from the source domain to capture visual similarities and generate visual enhancement prompts specific to the domain. Finally, these prompts are combined with metaphorical interpretation sentences to form the final prompt text. Experimental results demonstrate that this approach effectively captures the essence of metaphor and generates metaphorical images consistent with the textual meaning.},
  archive      = {J_NPL},
  author       = {Su, Chang and Wang, Xingyue and Liu, Shupin and Chen, Yijiang},
  doi          = {10.1007/s11063-024-11609-w},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Efficient visual metaphor image generation based on metaphor understanding},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dissipativity analysis of memristive inertial competitive
neural networks with mixed delays. <em>NPL</em>, <em>56</em>(3), 1–24.
(<a href="https://doi.org/10.1007/s11063-024-11610-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Without altering the inertial system into the two first-order differential systems, this paper primarily works over the global exponential dissipativity (GED) of memristive inertial competitive neural networks (MICNNs) with mixed delays. For this purpose, a novel differential inequality is primarily established around the discussed system. Then, by applying the founded inequality and constructing some novel Lyapunov functionals, the GED criteria in the algebraic form and the linear matrix inequality (LMI) form are given, respectively. Furthermore, the estimation of the global exponential attractive set (GEAS) is furnished. Finally, a specific illustrative example is analyzed to check the correctness and feasibility of the obtained findings.},
  archive      = {J_NPL},
  author       = {Yang, Jin and Jian, Jigui},
  doi          = {10.1007/s11063-024-11610-3},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-24},
  shortjournal = {Neural Process. Lett.},
  title        = {Dissipativity analysis of memristive inertial competitive neural networks with mixed delays},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An overestimation reduction method based on the multi-step
weighted double estimation using value-decomposition multi-agent
reinforcement learning. <em>NPL</em>, <em>56</em>(3), 1–21. (<a
href="https://doi.org/10.1007/s11063-024-11611-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The joint action-value function (JAVF) plays a key role in the centralized training of multi-agent deep reinforcement learning (MADRL)-based algorithms using the value function decomposition (VFD) and in the generating process of a collaborative policy between agents. However, under the influence of multiple factors such as environmental noise, inadequate exploration and iterative updating mechanism, estimation bias is inevitably introduced, causing its overestimation problem, which in turn prevents agents from obtaining accurate reward signals during the learning process, and fails to correctly approximate the optimal policy. To address this problem, this paper first analyzes the causes of joint action-value function overestimation, gives the corresponding mathematical proofs and theoretical derivations, and obtains the lower bound of the overestimation error; then, a MADRL overestimation reduction method based on the multi-step weighted double estimation named λWD QMIX is proposed. Specifically, the λWD QMIX method effectively achieves more stable and accurate JAVF estimation results using the bias correction estimation mechanisms based on the weighted double estimation and multi-step updating based on eligibility trace backup, without additionally adding or changing any network structure. The results of a series of experiments on the StarCraft II micromanipulation benchmark show that the proposed λWD QMIX algorithm can effectively improve the final performance and learning efficiency of the baseline algorithm, and can be seamlessly integrated with the partially MADRL algorithms based on communication learning.},
  archive      = {J_NPL},
  author       = {Zhao, Li-yang and Chang, Tian-qing and Guo, Li-bin and Zhang, Jie and Zhang, Lei and Ma, Jin-dun},
  doi          = {10.1007/s11063-024-11611-2},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {An overestimation reduction method based on the multi-step weighted double estimation using value-decomposition multi-agent reinforcement learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A geometric theory for binary classification of finite
datasets by DNNs with relu activations. <em>NPL</em>, <em>56</em>(3),
1–13. (<a href="https://doi.org/10.1007/s11063-024-11612-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate deep neural networks for binary classification of datasets from geometric perspective in order to understand the working mechanism of deep neural networks. First, we establish a geometrical result on injectivity of finite set under a projection from Euclidean space to the real line. Then by introducing notions of alternative points and alternative number, we propose an approach to design DNNs for binary classification of finite labeled points on the real line, thus proving existence of binary classification neural net with its hidden layers of width two and the number of hidden layers not larger than the cardinality of the finite labelled set. We also demonstrate geometrically how the dataset is transformed across every hidden layers in a narrow DNN setting for binary classification task.},
  archive      = {J_NPL},
  author       = {Yang, Xiao-Song},
  doi          = {10.1007/s11063-024-11612-1},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-13},
  shortjournal = {Neural Process. Lett.},
  title        = {A geometric theory for binary classification of finite datasets by DNNs with relu activations},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WaveVC: Speech and fundamental frequency consistent raw
audio voice conversion. <em>NPL</em>, <em>56</em>(3), 1–13. (<a
href="https://doi.org/10.1007/s11063-024-11613-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voice conversion (VC) is a task for changing the speech of a source speaker to the target voice while preserving linguistic information of the source speech. The existing VC methods typically use mel-spectrogram as both input and output, so a separate vocoder is required to transform mel-spectrogram into waveform. Therefore, the VC performance varies depending on the vocoder performance, and noisy speech can be generated due to problems such as train-test mismatch. In this paper, we propose a speech and fundamental frequency consistent raw audio voice conversion method called WaveVC. Unlike other methods, WaveVC does not require a separate vocoder and can perform VC directly on raw audio waveform using 1D convolution. This eliminates the issue of performance degradation caused by the train-test mismatch of the vocoder. In the training phase, WaveVC employs speech loss and F0 loss to preserve the content of the source speech and generate F0 consistent speech using the pre-trained networks. WaveVC is capable of converting voices while maintaining consistency in speech and fundamental frequency. In the test phase, the F0 feature of the source speech is concatenated with a content embedding vector to ensure the converted speech follows the fundamental frequency flow of the source speech. WaveVC achieves higher performances than baseline methods in both many-to-many VC and any-to-any VC. The converted samples are available online.},
  archive      = {J_NPL},
  author       = {Ko, Kyungdeuk and Kim, Donghyeon and Oh, Kyungseok and Ko, Hanseok},
  doi          = {10.1007/s11063-024-11613-0},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-13},
  shortjournal = {Neural Process. Lett.},
  title        = {WaveVC: Speech and fundamental frequency consistent raw audio voice conversion},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view self-supervised learning and multi-scale feature
fusion for automatic speech recognition. <em>NPL</em>, <em>56</em>(3),
1–20. (<a href="https://doi.org/10.1007/s11063-024-11614-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenges of the poor representation capability and low data utilization rate of end-to-end speech recognition models in deep learning, this study proposes an end-to-end speech recognition model based on multi-scale feature fusion and multi-view self-supervised learning (MM-ASR). It adopts a multi-task learning paradigm for training. The proposed method emphasizes the importance of inter-layer information within shared encoders, aiming to enhance the model’s characterization capability via the multi-scale feature fusion module. Moreover, we apply multi-view self-supervised learning to effectively exploit data information. Our approach is rigorously evaluated on the Aishell-1 dataset and further validated its effectiveness on the English corpus WSJ. The experimental results demonstrate a noteworthy 4.6 $$\%$$ reduction in character error rate, indicating significantly improved speech recognition performance . These findings showcase the effectiveness and potential of our proposed MM-ASR model for end-to-end speech recognition tasks.},
  archive      = {J_NPL},
  author       = {Zhao, Jingyu and Li, Ruwei and Tian, Maocun and An, Weidong},
  doi          = {10.1007/s11063-024-11614-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-view self-supervised learning and multi-scale feature fusion for automatic speech recognition},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sub-one quasi-norm-based k-means clustering algorithm and
analyses. <em>NPL</em>, <em>56</em>(3), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11615-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing the pivotal role of choosing an appropriate distance metric in designing the clustering algorithm, our focus is on innovating the k-means method by redefining the distance metric in its distortion. In this study, we introduce a novel k-means clustering algorithm utilizing a distance metric derived from the $$\ell _p$$ quasi-norm with $$p\in (0,1)$$ . Through an illustrative example, we showcase the advantageous properties of the proposed distance metric compared to commonly used alternatives for revealing natural groupings in data. Subsequently, we present a novel k-means type heuristic by integrating this sub-one quasi-norm-based distance, offer a step-by-step iterative relocation scheme, and prove the convergence to the Kuhn-Tucker point. Finally, we empirically validate the effectiveness of our clustering method through experiments on synthetic and real-life datasets, both in their original form and with additional noise introduced. We also investigate the performance of the proposed method as a subroutine in a deep learning clustering algorithm. Our results demonstrate the efficacy of the proposed k-means algorithm in capturing distinctive patterns exhibited by certain data types.},
  archive      = {J_NPL},
  author       = {An, Qi and Jiang, Shan},
  doi          = {10.1007/s11063-024-11615-y},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Sub-one quasi-norm-based k-means clustering algorithm and analyses},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A parallel model for jointly extracting entities and
relations. <em>NPL</em>, <em>56</em>(3), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11616-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting relational triples from a piece of text is an essential task in knowledge graph construction. However, most existing methods either identify entities before predicting their relations, or detect relations before recognizing associated entities. This order may lead to error accumulation because once there is an error in the initial step, it will accumulate to subsequent steps. To solve this problem, we propose a parallel model for jointly extracting entities and relations, called PRE-Span, which consists of two mutually independent submodules. Specifically, candidate entities and relations are first generated by enumerating token sequences in sentences. Then, two independent submodules (Entity Extraction Module and Relation Detection Module) are designed to predict entities and relations. Finally, the predicted results of the two submodules are analyzed to select entities and relations, which are jointly decoded to obtain relational triples. The advantage of this method is that all triples can be extracted in just one step. Extensive experiments on the WebNLG*, NYT*, NYT and WebNLG datasets show that our model outperforms other baselines at 94.4%, 88.3%, 86.5% and 83.0%, respectively.},
  archive      = {J_NPL},
  author       = {Chen, Zuqin and Zheng, Yujie and Ge, Jike and Yu, Wencheng and Wang, Zining},
  doi          = {10.1007/s11063-024-11616-x},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {A parallel model for jointly extracting entities and relations},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A point-cluster-partition architecture for weighted
clustering ensemble. <em>NPL</em>, <em>56</em>(3), 1–25. (<a
href="https://doi.org/10.1007/s11063-024-11618-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering ensembles can obtain more superior final results by combining multiple different clustering results. The qualities of the points, clusters, and partitions play crucial roles in the consistency of the clustering process. However, existing methods mostly focus on one or two aspects of them, without a comprehensive consideration of the three aspects. This paper proposes a three-level weighted clustering ensemble algorithm namely unified point-cluser-partition algorithm (PCPA). The first step of the PCPA is to generate the adjacency matrix by base clusterings. Then, the central step is to obtain the weighted adjacency matrix by successively weighting three layers, i.e., points, clusters, and partitions. Finally, the consensus clustering is obtained by the average link method. Three performance indexes, namely F, NMI, and ARI, are used to evaluate the accuracy of the proposed method. The experimental results show that: Firstly, as expected, the proposed three-layer weighted clustering ensemble can improve the accuracy of each evaluation index by an average value of 22.07% compared with the direct clustering ensemble without weighting; Secondly, compared with seven other methods, PCPA can achieve better clustering results and the proportion that PCPA ranks first is 28/33.},
  archive      = {J_NPL},
  author       = {Li, Na and Xu, Sen and Xu, Heyang and Xu, Xiufang and Guo, Naixuan and Cai, Na},
  doi          = {10.1007/s11063-024-11618-9},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-25},
  shortjournal = {Neural Process. Lett.},
  title        = {A point-cluster-partition architecture for weighted clustering ensemble},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dialogues summarization algorithm based on multi-task
learning. <em>NPL</em>, <em>56</em>(3), 1–14. (<a
href="https://doi.org/10.1007/s11063-024-11619-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of social information, the number of texts in the form of dialogue between individuals has exponentially increased. However, it is very challenging to review the previous dialogue content before initiating a new conversation. In view of the above background, a new dialogue summarization algorithm based on multi-task learning is first proposed in the paper. Specifically, Minimum Risk Training is used as the loss function to alleviate the problem of inconsistent goals between the training phase and the testing phase. Then, in order to deal with the problem that the model cannot effectively distinguish gender pronouns, a gender pronoun discrimination auxiliary task based on contrast learning is designed to help the model learn to distinguish different gender pronouns. Finally, an auxiliary task of reducing exposure bias is introduced, which involves incorporating the summary generated during inference into another round of training to reduce the difference between the decoder inputs during the training and testing stages. Experimental results show that our model outperforms strong baselines on three public dialogue summarization datasets: SAMSUM, DialogSum, and CSDS.},
  archive      = {J_NPL},
  author       = {Chen, Haowei and Li, Chen and Liang, Jiajing and Tian, Lihua},
  doi          = {10.1007/s11063-024-11619-8},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-14},
  shortjournal = {Neural Process. Lett.},
  title        = {A dialogues summarization algorithm based on multi-task learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised domain adaptation depth estimation based on
self-attention mechanism and edge consistency constraints. <em>NPL</em>,
<em>56</em>(3), 1–19. (<a
href="https://doi.org/10.1007/s11063-024-11621-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the unsupervised domain adaptation (UDA) (Akada et al. Self-supervised learning of domain invariant features for depth estimation, in: 2022 IEEE/CVF winter conference on applications of computer vision (WACV), pp 3377–3387 (2022). 10.1109/WACV51458.2022.00107 ) depth estimation task, a new adaptive approach is to use the bidirectional transformation network to transfer the style between the target and source domain inputs, and then train the depth estimation network in their respective domains. However, the domain adaptation process and the style transfer may result in defects and biases, often leading to depth holes and instance edge depth missing in the target domain’s depth output. To address these issues, We propose a training network that has been improved in terms of model structure and supervision constraints. First, we introduce a edge-guided self-attention mechanism in the task network of each domain to enhance the network’s attention to high-frequency edge features, maintain clear boundaries and fill in missing areas of depth. Furthermore, we utilize an edge detection algorithm to extract edge features from the input of the target domain. Then we establish edge consistency constraints between inter-domain entities in order to narrow the gap between domains and make domain-to-domain transfers easier. Our experimental demonstrate that our proposed method effectively solve the aforementioned problem, resulting in a higher quality depth map and outperforming existing state-of-the-art methods.},
  archive      = {J_NPL},
  author       = {Guo, Peng and Pan, Shuguo and Hu, Peng and Pei, Ling and Yu, Baoguo},
  doi          = {10.1007/s11063-024-11621-0},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {Unsupervised domain adaptation depth estimation based on self-attention mechanism and edge consistency constraints},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-linear time series prediction using improved CEEMDAN,
SVD and LSTM. <em>NPL</em>, <em>56</em>(3), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11622-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study recommends a new time series forecasting model, namely ICEEMDAN - SVD - LSTM model, which coalesces Improved Complete Ensemble EMD with Adaptive Noise, Singular Value Decomposition and Long Short Term Memory network. It can be applied to analyse Non-linear and non-stationary data. The framework of this model is comprised of three levels, namely ICEEMDAN level, SVD level and LSTM level. The first level utilized ICEEMDAN to break up the series into some IMF components along with a residue. The SVD in the second level accounts for de-noising of every IMF component and residue. LSTM forecasts all the resultant IMF components and residue in third level. To obtain the forecasted values of the original data, the predictions of all IMF components and residue are added. The proposed model is contrasted with other extant ones, namely LSTM model, EMD - LSTM model, EEMD - LSTM model, CEEMDAN - LSTM model, EEMD - SVD - LSTM model, ICEEMDAN - LSTM model and CEEMDAN - SVD - LSTM model. The comparison bears witness to the potential of the recommended model over the traditional models.},
  archive      = {J_NPL},
  author       = {Poongadan, Sameer and Lineesh, M. C.},
  doi          = {10.1007/s11063-024-11622-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {Non-linear time series prediction using improved CEEMDAN, SVD and LSTM},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Use of a modified threshold function in fuzzy cognitive maps
for improved failure mode identification. <em>NPL</em>, <em>56</em>(3),
1–11. (<a href="https://doi.org/10.1007/s11063-024-11623-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy cognitive maps (FCMs) provide a rapid and efficient approach for system modeling and simulation. The literature demonstrates numerous successful applications of FCMs in identifying failure modes. The standard process of failure mode identification using FCMs involves monitoring crucial concept/node values for excesses. Threshold functions are used to limit the value of nodes within a pre-specified range, which is usually [0, 1] or [-1, + 1]. However, traditional FCMs using the tanh threshold function possess two crucial drawbacks for this particular.Purpose(i) a tendency to reduce the values of state vector components, and (ii) the potential inability to reach a limit state with clearly identifiable failure states. The reason for this is the inherent mathematical nature of the tanh function in being asymptotic to the horizontal line demarcating the edge of the specified range. To overcome these limitations, this paper introduces a novel modified tanh threshold function that effectively addresses both issues.},
  archive      = {J_NPL},
  author       = {Augustine, Manu and Yadav, Om Prakash and Nayyar, Ashish and Joshi, Dheeraj},
  doi          = {10.1007/s11063-024-11623-y},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-11},
  shortjournal = {Neural Process. Lett.},
  title        = {Use of a modified threshold function in fuzzy cognitive maps for improved failure mode identification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Class-balanced regularization for long-tailed recognition.
<em>NPL</em>, <em>56</em>(3), 1–18. (<a
href="https://doi.org/10.1007/s11063-024-11624-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-tailed recognition performs poorly on minority classes. The extremely imbalanced distribution of classifier weight norms leads to a decision boundary biased toward majority classes. To address this issue, we propose Class-Balanced Regularization to balance the distribution of classifier weight norms so that the model can make more balanced and reasonable classification decisions. In detail, CBR separately adjusts the regularization factors based on L2 regularization to be correlated with the class sample frequency positively, rather than using a fixed regularization factor. CBR trains balanced classifiers by increasing the L2 norm penalty for majority classes and reducing the penalty for minority classes. Since CBR is mainly used for classification adjustment instead of feature extraction, we adopt a two-stage training algorithm. In the first stage, the network with the traditional empirical risk minimization is trained, and in the second stage, CBR for classifier adjustment is applied. To validate the effectiveness of CBR, we perform extensive experiments on CIFAR10-LT, CIFAR100-LT, and ImageNet-LT datasets. The results demonstrate that CBR significantly improves performance by effectively balancing the distribution of classifier weight norms.},
  archive      = {J_NPL},
  author       = {Xu, Yuge and Lyu, Chuanlong},
  doi          = {10.1007/s11063-024-11624-x},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {Class-balanced regularization for long-tailed recognition},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A pilot study of observation poisoning on selective
reincarnation in multi-agent reinforcement learning. <em>NPL</em>,
<em>56</em>(3), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11625-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research explores the vulnerability of selective reincarnation, a concept in Multi-Agent Reinforcement Learning (MARL), in response to observation poisoning attacks. Observation poisoning is an adversarial strategy that subtly manipulates an agent’s observation space, potentially leading to a misdirection in its learning process. The primary aim of this paper is to systematically evaluate the robustness of selective reincarnation in MARL systems against the subtle yet potentially debilitating effects of observation poisoning attacks. Through assessing how manipulated observation data influences MARL agents, we seek to highlight potential vulnerabilities and inform the development of more resilient MARL systems. Our experimental testbed was the widely used HalfCheetah environment, utilizing the Independent Deep Deterministic Policy Gradient algorithm within a cooperative MARL setting. We introduced a series of triggers, namely Gaussian noise addition, observation reversal, random shuffling, and scaling, into the teacher dataset of the MARL system provided to the reincarnating agents of HalfCheetah. Here, the “teacher dataset” refers to the stored experiences from previous training sessions used to accelerate the learning of reincarnating agents in MARL. This approach enabled the observation of these triggers’ significant impact on reincarnation decisions. Specifically, the reversal technique showed the most pronounced negative effect for maximum returns, with an average decrease of 38.08% in Kendall’s tau values across all the agent combinations. With random shuffling, Kendall’s tau values decreased by 17.66%. On the other hand, noise addition and scaling aligned with the original ranking by only 21.42% and 32.66%, respectively. The results, quantified by Kendall’s tau metric, indicate the fragility of the selective reincarnation process under adversarial observation poisoning. Our findings also reveal that vulnerability to observation poisoning varies significantly among different agent combinations, with some exhibiting markedly higher susceptibility than others. This investigation elucidates our understanding of selective reincarnation’s robustness against observation poisoning attacks, which is crucial for developing more secure MARL systems and also for making informed decisions about agent reincarnation.},
  archive      = {J_NPL},
  author       = {Putla, Harsha and Patibandla, Chanakya and Singh, Krishna Pratap and Nagabhushan, P},
  doi          = {10.1007/s11063-024-11625-w},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {A pilot study of observation poisoning on selective reincarnation in multi-agent reinforcement learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DynamicAug: Enhancing transfer learning through dynamic data
augmentation strategies based on model state. <em>NPL</em>,
<em>56</em>(3), 1–27. (<a
href="https://doi.org/10.1007/s11063-024-11626-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning has made significant advancements, however, the issue of overfitting continues to pose a major challenge. Data augmentation has emerged as a highly promising technique to counteract this challenge. Current data augmentation methods are fixed in nature, requiring manual determination of the appropriate intensity prior to the training process. However, this entails substantial computational costs. Additionally, as the model approaches convergence, static data augmentation strategies can become suboptimal. In this paper, we introduce the concept of Dynamic Data Augmentation (DynamicAug), a method that autonomously adjusts the intensity of data augmentation, taking into account the convergence state of the model. During each iteration of the model’s forward pass, we utilize a Gaussian distribution based sampler to stochastically sample the current intensity of data augmentation. To ensure that the sampled intensity is aligned with the convergence state of the model, we introduce a learnable expectation to the sampler and update the expectation iteratively. In order to assess the convergence status of the model, we introduce a novel loss function called the convergence loss. Through extensive experiments conducted over 27 vision datasets, we have demonstrated that DynamicAug can significantly enhance the performance of existing transfer learning methods.},
  archive      = {J_NPL},
  author       = {Yu, Xinyi and Zhao, Haodong and Zhang, Mingyang and Wei, Yan and Zhou, Libo and Ou, Linlin},
  doi          = {10.1007/s11063-024-11626-9},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-27},
  shortjournal = {Neural Process. Lett.},
  title        = {DynamicAug: Enhancing transfer learning through dynamic data augmentation strategies based on model state},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual classifier adaptation: Source-free UDA via adaptive
pseudo-labels learning. <em>NPL</em>, <em>56</em>(3), 1–21. (<a
href="https://doi.org/10.1007/s11063-024-11627-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different from Unsupervised Domain Adaptation (UDA), Source-Free Unsupervised Domain Adaptation (SFUDA) transfers source knowledge to target domain without accessing the source data, using only the source model, has attracted much attention recently. One mainstream SFUDA method fine-tunes the source model by self-training to generate pseudo-labels of the target data. However, due to the significant differences between different domains, these target pseudo-labels often contain some noise, and it will inevitably degenerates the target performance. For this purpose, we propose an innovative SFUDA method with adaptive pseudo-labels learning named Dual Classifier Adaptation (DCA). In DCA, a dual classifier structure is introduced to adaptively learn target pseudo-labels by cooperation between source and target classifiers. Simultaneously, the minimax entropy is introduced for target learning, in order to adapt target data to source model, while capture the intrinsic cluster structure in target domain as well. After compared our proposed method DCA with a range of UDA and SFUDA methods, DCA achieves far ahead performance on several benchmark datasets.},
  archive      = {J_NPL},
  author       = {Wang, Yunyun and Li, Qinghao and Hua, Ziyi},
  doi          = {10.1007/s11063-024-11627-8},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Dual classifier adaptation: Source-free UDA via adaptive pseudo-labels learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sample-adaptive classification inference network.
<em>NPL</em>, <em>56</em>(3), 1–15. (<a
href="https://doi.org/10.1007/s11063-024-11629-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing pre-trained models have yielded promising results in terms of computational time reduction. However, these models only focus on pruning simple sentences or less salient words, while neglecting the treatment of relatively complex sentences. It is frequently these sentences that cause the loss of model accuracy. This shows that the adaptation of the existing models is one-sided. To address this issue, in this paper, we propose a sample-adaptive training and inference model. Specifically, complex samples are extracted from the training datasets and a dedicated data augmentation module is trained to extract global and local semantic information of complex samples. During inference, simple samples can exit the model via the Sample Adaptive Exit Mechanism, Normal samples pass through the whole backbone model before inference, while complex samples are processed by the Characteristic Enhancement Module after passing through the backbone model. In this way, all samples are processed adaptively. Our extensive experiments on classification tasks datasets in the field of Natural Language Processing demonstrate that our method enhances model accuracy and reduces model inference time for multiple datasets. Moreover, our method is transferable and can be applied to multiple pre-trained models.},
  archive      = {J_NPL},
  author       = {Yang, Juan and Zhou, Guanghong and Wang, Ronggui and Xue, Lixia},
  doi          = {10.1007/s11063-024-11629-6},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-15},
  shortjournal = {Neural Process. Lett.},
  title        = {Sample-adaptive classification inference network},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pinning group consensus of multi-agent systems under DoS
attacks. <em>NPL</em>, <em>56</em>(3), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11630-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, group consensus is investigated for a class of nonlinear multi-agent systems suffered from the DoS attacks. Firstly, a first-order nonlinear multi-agent system is constructed, which is divided into M subsystems and each subsystem has an unique leader. Then a protocol is proposed and a Lyapunov function candidate is chosen. By means of the stability theory, a sufficient criterion, which involves the duration of DoS attacks, coupling strength and control gain, is obtained for achieving group consensus in first-order system. That is, the nodes in each subsystem can track the leader of that group. Furthermore, the result is extended to nonlinear second-order multi-agent systems and the controller is also improved to obtain sufficient conditions for group consensus. Additionally, the lower bounds of the coupling strength and average interval of DoS attacks can be determined from the obtained sufficient conditions. Finally, several numerical simulations are presented to explain the effectiveness of the proposed controllers and the derived theoretical results.},
  archive      = {J_NPL},
  author       = {Lang, Qian and Xu, Jing and Zhang, Huiwen and Wang, Zhengxin},
  doi          = {10.1007/s11063-024-11630-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Pinning group consensus of multi-agent systems under DoS attacks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LCTCS: Low-cost and two-channel sparse network for
hyperspectral image classification. <em>NPL</em>, <em>56</em>(3), 1–31.
(<a href="https://doi.org/10.1007/s11063-024-11631-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using convolutional neural networks (CNNs) in classifying hyperspectral images (HSIs) has achieved quite good results in recent years. It is widely used in agricultural remote sensing, geological exploration, environmental monitoring, and marine remote sensing. Unfortunately, the complexity of network structures used for hyperspectral image classification challenges the efficient delivery of HSI data extremely, and existing methods suffer from a large amount of redundancy in the network weight parameters during training, as they either require huge computational resources or make inefficient use of storage space when designing the network structure, and many of the parameters that waste computational resources contribute less to the rich spectral and spatial information transfer in HSI. So we introduce LCTCS, a better low-memory and less-parametric network approach. LCTCS aims to improve the efficiency of computational resource utilization with advanced classification performance and lower levels of computational resources. Unlike the conventional 2D and 3D convolution used previously, we use simple and efficient 3D grouped convolution as a vehicle to convey the semantic features of HSIs. More specifically, we design a novel two-channel sparse network to classify HSIs since grouped 3D convolution conveys the properties of hyperspectral data well in the time and space domains.We have compared LCTCS with eight widely used network methods on four publicly available hyperspectral datasets for learning HSI information. A series of experiments shows that the model architecture designed has $$65.89 \%$$ less storage space than the DBDA method, consumes $$67.36 \%$$ fewer computational resources than the SSRN method on the IP dataset, and accomplishes a highly accurate classification task with the number of parameters accounting for only $$1.99 \%$$ that of the DBMA method.},
  archive      = {J_NPL},
  author       = {Sun, Jie and Yang, Jing and Chen, Wang and Ding, Sujie and li, Shaobo and Hu, Jianjun},
  doi          = {10.1007/s11063-024-11631-y},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-31},
  shortjournal = {Neural Process. Lett.},
  title        = {LCTCS: Low-cost and two-channel sparse network for hyperspectral image classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical reinforcement learning from demonstration via
reachability-based reward shaping. <em>NPL</em>, <em>56</em>(3), 1–18.
(<a href="https://doi.org/10.1007/s11063-024-11632-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical reinforcement learning (HRL) has achieved remarkable success and significant progress in complex and long-term decision-making problems. However, HRL training typically entails substantial computational costs and an enormous number of samples. One effective approach to tackle this challenge is hierarchical reinforcement learning from demonstrations (HRLfD), which leverages demonstrations to expedite the training process of HRL. The effectiveness of HRLfD is contingent upon the quality of the demonstrations; hence, suboptimal demonstrations may impede efficient learning. To address this issue, this paper proposes a reachability-based reward shaping (RbRS) method to alleviate the negative interference of suboptimal demonstrations for the HRL agent. The novel HRLfD algorithm based on RbRS is named HRLfD-RbRS, which incorporates the RbRS method to enhance the learning efficiency of HRLfD. Moreover, with the help of this method, the learning agent can explore better policies under the guidance of the suboptimal demonstration. We evaluate the proposed HRLfD-RbRS algorithm on various complex robotic tasks, and the experimental results demonstrate that our method outperforms current state-of-the-art HRLfD algorithms.},
  archive      = {J_NPL},
  author       = {Gao, Xiaozhu and Liu, Jinhui and Wan, Bo and An, Lingling},
  doi          = {10.1007/s11063-024-11632-x},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {Hierarchical reinforcement learning from demonstration via reachability-based reward shaping},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing document information selection through
multi-granularity responses for dialogue generation. <em>NPL</em>,
<em>56</em>(3), 1–23. (<a
href="https://doi.org/10.1007/s11063-024-11633-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document information selection is an essential part of document-grounded dialogue tasks, and more accurate information selection results can provide more appropriate dialogue responses. Existing works have achieved excellent results by employing multi-granularity of dialogue history information, indicating the effectiveness of multi-level historical information. However, these works often focus on exploring the hierarchical information of dialogue history, while neglecting the multi-granularity utilization in response, important information that holds an impact on the decoding process. Therefore, this paper proposes a model for document information selection based on multi-granularity responses. By integrating the document selection results at the response word level and semantic unit level, the model enhances its capability in knowledge selection and produces better responses. For the division at the semantic unit level of the response, we propose two semantic unit division methods, static and dynamic. Experiments on two public datasets show that our models combining static or dynamic semantic unit levels significantly outperform baseline models.},
  archive      = {J_NPL},
  author       = {Wang, Meiqi and Qiao, Kangyu and Xing, Shuyue and Yuan, Caixia and Wang, Xiaojie},
  doi          = {10.1007/s11063-024-11633-w},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {Enhancing document information selection through multi-granularity responses for dialogue generation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-channel autoencoder with key region feature enhancement
for video anomalous event detection. <em>NPL</em>, <em>56</em>(3), 1–18.
(<a href="https://doi.org/10.1007/s11063-024-11634-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly event detection is crucial for analyzing surveillance videos. Existing methods have limitations: frame-level detection fails to remove background interference, and object-level methods overlook object-environment interaction. To address these issues, this paper proposes a novel video anomaly event detection algorithm based on a dual-channel autoencoder with key region feature enhancement. The goal is to preserve valuable information in the global context while focusing on regions with a high anomaly occurrence. Firstly, a key region extraction network is proposed to perform foreground segmentation on video frames, eliminating background redundancy. Secondly, a dual-channel autoencoder is designed to enhance the features of key regions, enabling the model to extract more representative features. Finally, channel attention modules are inserted between each deconvolution layer of the decoder to enhance the model’s perception and discrimination of valuable information. Compared to existing methods, our approach accurately locates and focuses on regions with a high anomaly occurrence, improving the accuracy of anomaly event detection. Extensive experiments are conducted on the UCSD ped2, CUHK Avenue, and SHTech Campus datasets, and the results validate the effectiveness of the proposed method.},
  archive      = {J_NPL},
  author       = {Ye, Qing and Song, Zihan and Zhao, Yuqi and Zhang, Yongmei},
  doi          = {10.1007/s11063-024-11634-9},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {Dual-channel autoencoder with key region feature enhancement for video anomalous event detection},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Speeding up the training of neural networks with the
one-step procedure. <em>NPL</em>, <em>56</em>(3), 1–13. (<a
href="https://doi.org/10.1007/s11063-024-11637-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, research and corporate have shown a dramatically growing interest in the field of machine learning, mostly due to the performances of deep neural networks. These increasingly complex architectures solved a wide range of problems. However, training these sophisticated architectures require many computation on advanced hardware. With this paper, we introduce a new approach based on the One-Step procedure that may fasten their training. In this procedure, an initial guess estimator is computed on a subsample that is then improved with only one step of the Newton gradient descent on the whole dataset. To show the efficiency of this framework, we consider regression and classification tasks using simulated and real datasets. We consider classic architectures, namely multi-layer perceptrons and show, on our examples, that the One-Step procedure is often halving the computation time to train the neural networks while preserving the performances.},
  archive      = {J_NPL},
  author       = {Meskini, Wajd and Brouste, Alexandre and Dugué, Nicolas},
  doi          = {10.1007/s11063-024-11637-6},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-13},
  shortjournal = {Neural Process. Lett.},
  title        = {Speeding up the training of neural networks with the one-step procedure},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural circuit policies for virtual character control.
<em>NPL</em>, <em>56</em>(3), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11640-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of high-stakes decision-making neural agents that interact with complex environments, such as video games, is an important aspect of AI research with numerous potential applications. Reinforcement learning combined with deep learning architectures (DRL) has shown remarkable success in various genres of games. The performance of DRL is heavily dependent upon the neural networks resides within them. Although these algorithms perform well in offline testing but the performance deteriorates in noisy and sub-optimal conditions, creating safety and security issues. To address these, we propose a hybrid deep learning architecture that combines a traditional convolutional neural network with worm brain-inspired neural circuit policies. This allows the agent to learn key coherent features from the environment and interpret its dynamics. The obtained DRL agent was not only able to achieve an optimal policy quickly, but it was also the most noise-resilient with the highest success rate. Our research indicates that only 20 control neurons (12 inter-neurons and 8 command neurons) are sufficient to achieve competitive results. We implemented and analyzed the agent in the popular video game Doom, demonstrating its effectiveness in practical applications.},
  archive      = {J_NPL},
  author       = {Razzaq, Waleed and Raza, Kashif},
  doi          = {10.1007/s11063-024-11640-x},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Neural circuit policies for virtual character control},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multichannel multimodal emotion analysis of cross-modal
feedback interactions based on knowledge graph. <em>NPL</em>,
<em>56</em>(3), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11641-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis is a downstream branch task of sentiment analysis with high attention at present. Previous work in multimodal sentiment analysis have focused on the representation and fusion of modalities, capturing the underlying semantic relationships between modalities by considering contextual information. While this approach is feasible for simple contextual comments, more complex comments require the integration of external knowledge to obtain more accurate sentiment information. However, incorporating external knowledge into sentiment analysis to enhance information complementarity has not been thoroughly investigated. To address this, we propose a multichannel cross-modal feedback interaction model that incorporates the knowledge graph into multimodal sentiment analysis. Our proposed model consists of two main components: the cross-modal feedback recurrent interaction module and the external knowledge module for capturing latent information. The cross-modal interaction employs a self-feedback mechanism during network training, extracting feature representations of each modality and using these representations to mask sensory inputs, allowing the model to perform feedback-based feature masking. The external knowledge graph captures potential semantic information representations in the textual data through knowledge graph embedding. Finally, a global feature fusion module is employed for multichannel multimodal information integration. On two publicly available datasets, our method demonstrates good performance in terms of accuracy and F1 scores, compared to state-of-the-art models and several baselines.},
  archive      = {J_NPL},
  author       = {Dong, Shaohua and Fan, Xiaochao and Ma, Xinchun},
  doi          = {10.1007/s11063-024-11641-w},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Multichannel multimodal emotion analysis of cross-modal feedback interactions based on knowledge graph},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Add-vit: CNN-transformer hybrid architecture for small data
paradigm processing. <em>NPL</em>, <em>56</em>(3), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11643-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vision transformer(ViT), pre-trained on large datasets, outperforms convolutional neural networks (CNN) in computer vision(CV). However, if not pre-trained, the transformer architecture doesn’t work well on small datasets and is surpassed by CNN. Through analysis, we found that:(1) the division and processing of tokens in the ViT discard the marginalized information between token. (2) the isolated multi-head self-attention (MSA) lacks prior knowledge. (3) the local inductive bias capability of stacked transformer block is much inferior to that of CNN. We propose a novel architecture for small data paradigms without pre-training, named Add-Vit, which uses progressive tokenization with feature supplementation in patch embedding. The model’s representational ability is enhanced by using a convolutional prediction module shortcut to connect MSA and capture local features as additional representations of the token. Without the need for pre-training on large datasets, our best model achieved 81.25 $$\%$$ accuracy when trained from scratch on the CIFAR-100.},
  archive      = {J_NPL},
  author       = {Chen, Jinhui and Wu, Peng and Zhang, Xiaoming and Xu, Renjie and Liang, Jia},
  doi          = {10.1007/s11063-024-11643-8},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Add-vit: CNN-transformer hybrid architecture for small data paradigm processing},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GPINN with neural tangent kernel technique for nonlinear two
point boundary value problems. <em>NPL</em>, <em>56</em>(3), 1–23. (<a
href="https://doi.org/10.1007/s11063-024-11644-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks as differential equation solvers are a good choice of numerical technique because of their fast solutions and their nature in tackling some classical problems which traditional numerical solvers faced. In this article, we look at the famous gradient descent optimization technique, which trains the network by updating parameters which minimizes the loss function. We look at the theoretical part of gradient descent to understand why the network works great for some terms of the loss function and not so much for other terms. The loss function considered here is built in such a way that it incorporates the differential equation as well as the derivative of the differential equation. The fully connected feed-forward network is designed in such a way that, without training at boundary points, it automatically satisfies the boundary conditions. The neural tangent kernel for gradient enhanced physics informed neural networks is examined in this work, and we demonstrate how it may be used to generate a closed-form expression for the kernel function. We also provide numerical experiments demonstrating the effectiveness of the new approach for several two point boundary value problems. Our results suggest that the neural tangent kernel based approach can significantly improve the computational accuracy of the gradient enhanced physics informed neural network while reducing the computational cost of training these models.},
  archive      = {J_NPL},
  author       = {Jha, Navnit and Mallik, Ekansh},
  doi          = {10.1007/s11063-024-11644-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {GPINN with neural tangent kernel technique for nonlinear two point boundary value problems},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge distillation based on narrow-deep networks.
<em>NPL</em>, <em>56</em>(3), 1–16. (<a
href="https://doi.org/10.1007/s11063-024-11646-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks perform better than shallow neural networks, but the former tends to be deeper or wider, introducing large numbers of parameters and computations. We know that networks that are too wide have a high risk of overfitting and networks that are too deep require a large amount of computation. This paper proposed a narrow-deep ResNet, increasing the depth of the network while avoiding other issues caused by making the network too wide, and used the strategy of knowledge distillation, where we set up a trained teacher model to train an unmodified, wide, and narrow-deep ResNet that allows students to learn the teacher’s output. To validate the effectiveness of this method, it is tested on Cifar-100 and Pascal VOC datasets. The method proposed in this paper allows a small model to have about the same accuracy rate as a large model, while dramatically shrinking the response time and computational effort.},
  archive      = {J_NPL},
  author       = {Zhou, Yan and Wang, Zhiqiang and Li, Jianxun},
  doi          = {10.1007/s11063-024-11646-5},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Knowledge distillation based on narrow-deep networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An observer-based topology identification and
synchronization in finite time for fractional singularly perturbed
complex networks via dynamic event-triggered control. <em>NPL</em>,
<em>56</em>(3), 1–24. (<a
href="https://doi.org/10.1007/s11063-024-11648-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the topology identification and synchronization in finite time for fractional singularly perturbed complex networks (FSPCNs). Firstly, a convergence principle is developed for continuously differential functions. Secondly, a dynamic event-triggered mechanism (DETM) is designed to achieve the network synchronization, and a topology observer is developed to identify the network topology. Thirdly, under the designed DETM, by constructing a Lyapunov functional and applying the inequality analysis technique, the topology identification and synchronization condition in finite time is established in the forms of the matrix inequality. In addition, it is proved that the Zeno behavior can be effectively excluded. Finally, the effectiveness of the main results is verified by an application example.},
  archive      = {J_NPL},
  author       = {Wang, Lingyan and Wu, Huaiqin and Cao, Jinde},
  doi          = {10.1007/s11063-024-11648-3},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-24},
  shortjournal = {Neural Process. Lett.},
  title        = {An observer-based topology identification and synchronization in finite time for fractional singularly perturbed complex networks via dynamic event-triggered control},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantized iterative learning bipartite containment tracking
control for unknown nonlinear multi-agent systems. <em>NPL</em>,
<em>56</em>(3), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11649-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a quantized model-free adaptive iterative learning control (MFAILC) algorithm to solve the bipartite containment tracking problem of unknown nonlinear multi-agent systems, where the interactions between agents include cooperation and antagonistic interactions. To design the controller, the agent’s dynamics is transformed into the linear data model based on the dynamic linearization method, and then a quantized MFAILC algorithm is established based on the quantized values of the relative output measurements. The designed controller only depends on the input and output data of the agent. We prove that under the quantized MFAILC algorithm, the multi-agent systems can achieve the bipartite containment, that is, the output trajectories of followers converge to the convex hull formed by the leaders’ trajectories and the leaders’ symmetric trajectories. Finally, we provide simulations to illustrate the effectiveness of our theoretical results.},
  archive      = {J_NPL},
  author       = {Zhang, Ruikun and Sang, Shangyu and Zhang, Jingyuan and Lin, Xue},
  doi          = {10.1007/s11063-024-11649-2},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Quantized iterative learning bipartite containment tracking control for unknown nonlinear multi-agent systems},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Capsule network based on double-layer attention mechanism
and multi-scale feature extraction for remaining life prediction.
<em>NPL</em>, <em>56</em>(3), 1–26. (<a
href="https://doi.org/10.1007/s11063-024-11651-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The era of big data provides a platform for high-precision RUL prediction, but the existing RUL prediction methods, which effectively extract key degradation information, remain a challenge. Existing methods ignore the influence of sensor and degradation moment variability, and instead assign weights to them equally, which affects the final prediction accuracy. In addition, convolutional networks lose key information due to downsampling operations and also suffer from the drawback of insufficient feature extraction capability. To address these issues, the two-layer attention mechanism and the Inception module are embedded in the capsule structure (mai-capsule model) for lifetime prediction. The first layer of the channel attention mechanism (CAM) evaluates the influence of various sensor information on the forecast; the second layer adds a time-step attention (TSAM) mechanism to the LSTM network to weigh the contribution of different moments of the engine&#39;s whole life cycle to the prediction, while weakening the influence of environmental noise on the prediction. The Inception module is introduced to perform multi-scale feature extraction on the weighted data to capture the degradation information to the maximum extent. Lastly, we are inspired to employ the capsule network to capture important position information of high and low-dimensional features, given its capacity to facilitate a more effective rendition of the overall features of the time-series data. The efficacy of the suggested model is assessed against other approaches and verified using the publicly accessible C-MPASS dataset. The end findings demonstrate the excellent prediction precision of the suggested approach.},
  archive      = {J_NPL},
  author       = {Shang, Zhiwu and Feng, Zehua and Li, Wanxiang and Wu, Zhihua and Cheng, Hongchuan},
  doi          = {10.1007/s11063-024-11651-8},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-26},
  shortjournal = {Neural Process. Lett.},
  title        = {Capsule network based on double-layer attention mechanism and multi-scale feature extraction for remaining life prediction},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal diversity-aware micro-video recommendation with
long- and short-term interests modeling. <em>NPL</em>, <em>56</em>(3),
1–21. (<a href="https://doi.org/10.1007/s11063-024-11652-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have become indispensable for addressing information overload for micro-video services. They are used to characterize users’ preferences from their historical interactions and recommend micro-videos accordingly. Existing works largely leverage the multi-modal contents of micro-videos to enhance recommendation performance. However, limited efforts have been made to understand users’ complex behavior patterns, including their long- and short-term interests, as well as their temporal diversity preferences. In micro-video recommendation scenarios, users tend to have both stable long-term interests and dynamic short-term interests, and may feel tired after incessantly receiving numerous similar recommendations. In this paper, we propose a Temporal Diversity-aware micro-video recommender (TD-VideoRec) for user behavior modeling, simultaneously capturing users’ long- and short-term preferences. Specifically, we first adopt a user-centric attention mechanism to cope with long-term interests. Then, we utilize an attention network on top of a long-short term memory network to obtain users’ short-term interests. Finally, a temporal diversity coefficient is introduced to characterize the temporal diversity preferences of users’ click behaviors. The value of the coefficient depends on the distinction between users’ long- and short-term interests extracted by vector orthogonal projection. Extensive experiments on two real-world datasets demonstrate that TD-VideoRec outperforms state-of-the-art methods.},
  archive      = {J_NPL},
  author       = {Gu, Pan and Hu, Haiyang and Wang, Dongjing and Yu, Dongjin and Xu, Guandong},
  doi          = {10.1007/s11063-024-11652-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Temporal diversity-aware micro-video recommendation with long- and short-term interests modeling},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SpanEffiDet: Span-scale and span-path feature fusion for
object detection. <em>NPL</em>, <em>56</em>(3), 1–32. (<a
href="https://doi.org/10.1007/s11063-024-11653-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lower versions of EfficientDet (such as D0, D1) have smaller network structures and parameter sizes, but lower detection accuracy. Higher versions exhibit higher accuracy, but the increase in network complexity poses challenges for real-time processing and hardware requirements. To meet the higher accuracy requirements under limited computational resources, this paper introduces SpanEffiDet based on the channel adaptive frequency filter (CAFF) and the Span-Path Bidirectional Feature Pyramid structure. Firstly, the CAFF module proposed in this paper realizes the frequency domain transformation of channel information through Fourier transform and effectively extracts the key features through semantic adaptive frequency filtering, thus, eliminating channel redundant information of EfficientNet. Simultaneously, the module has the ability to compute the weights across the channels and at fine granularity, and capture the detailed information of element features. Secondly, a two-way characteristic pyramid network multi-level cross-BIFPN, which can achieve multi-layer and multi-nodes, is proposed to build cross-level information transmission to incorporate both semantic and positional information of the target. This design enables the network to more effectively detect objects with significant size differences in complex environments. Finally, by introducing generalized focal Loss V2, reliable localization quality estimation scores are predicted from the distribution statistics of bounding boxes, thereby improving localization accuracy. The experimental results indicate that on the MS COCO dataset, SpanEffiDet-D0 achieved an AP improvement of 3.3% compared to the original EfficientDet series algorithms. Similarly, on the PASCAL VOC2007 and 2012 datasets, the mAP of SpanEffiDet-D0 is respectively 1.66 and 2.65% higher than that of EfficientDet-D0.},
  archive      = {J_NPL},
  author       = {Liu, Qunpo and Zhao, Yi and Gao, Ruxin and Bu, Xuhui and Hanajima, Naohiko},
  doi          = {10.1007/s11063-024-11653-6},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-32},
  shortjournal = {Neural Process. Lett.},
  title        = {SpanEffiDet: Span-scale and span-path feature fusion for object detection},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nested entity recognition method based on multidimensional
features and fuzzy localization. <em>NPL</em>, <em>56</em>(3), 1–21. (<a
href="https://doi.org/10.1007/s11063-024-11657-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nested named entity recognition (NNER) aims to identify potentially overlapping named entities. Sequence labeling method and span-based method are two commonly used methods in nested named entity recognition. However, the linear structure of sequence labeling method results in relatively poor performance, and span-based method requires traversing all spans, which brings very high time complexity. All of them fail to effectively leverage the positional dependencies between internal and external entities. In order to improve these issues, this paper proposed a nested entity recognition method based on Multidimensional Features and Fuzzy Localization (MFFL). Firstly, this method adopted the shared encoding that fused three features of characters, words, and parts of speech to obtain a multidimensional feature vector representation of the text and obtained rich semantic information in the text. Secondly, we proposed to use the fuzzy localization to assist the model in pinpointing the potential locations of entities. Finally, in the entity classification, it used a window to expand the sub-sequence and enumerate possible candidate entities and predicted the classification labels of these candidate entities. In order to alleviate the problem of error propagation and effectively learn the correlation between fuzzy localization and classification labels, we adopted multi-task learning strategy. This paper conducted several experiments on two public datasets. The experimental results showed that the proposed method achieves ideal results in both nested entity recognition and non-nested entity recognition tasks, and significantly reduced the time complexity of nested entity recognition.},
  archive      = {J_NPL},
  author       = {Zhao, Hua and Bai, Xueyang and Zeng, Qingtian and Zhou, Heng and Bai, Xuemei},
  doi          = {10.1007/s11063-024-11657-2},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Nested entity recognition method based on multidimensional features and fuzzy localization},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causality-driven intra-class non-equilibrium label-specific
features learning. <em>NPL</em>, <em>56</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s11063-024-11439-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label learning, label-specific feature learning can effectively avoid some ineffectual features that interfere with the classification performance of the model. However, most of the existing label-specific feature learning algorithms improve the performance of the model for classification by constraining the solution space through label correlation. The non-equilibrium of the label distribution not only leads to some spurious correlations mixed in with the calculated label correlations but also diminishes the performance of the classification model. Causal learning can improve the classification performance and robustness of the model by capturing real causal relationships from limited data. Based on this, this paper proposes a causality-driven intra-class non-equilibrium label-specific features learning, named CNSF. Firstly, the causal relationship between the labels is learned by the Peter-Clark algorithm. Secondly, the label density of all instances is calculated by the intra-class non-equilibrium method, which is used to relieve the non-equilibrium distribution of original labels. Then, the correlation of the density matrix is calculated using cosine similarity and combined with causality to construct the causal density correlation matrix, to solve the problem of spurious correlation mixed in the label correlation obtained by traditional methods. Finally, the causal density correlation matrix is used to induce label-specific feature learning. Compared with eight state-of-the-art multi-label algorithms on thirteen datasets, the experimental results prove the reasonability and effectiveness of the algorithms in this paper.},
  archive      = {J_NPL},
  author       = {Ge, Wenxin and Wang, Yibin and Xu, Yuting and Cheng, Yusheng},
  doi          = {10.1007/s11063-024-11439-w},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {Causality-driven intra-class non-equilibrium label-specific features learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection of image tampering using deep learning, error
levels and noise residuals. <em>NPL</em>, <em>56</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s11063-024-11448-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images once were considered a reliable source of information. However, when photo-editing software started to get noticed it gave rise to illegal activities which is called image tampering. These days we can come across innumerable tampered images across the internet. Software such as Photoshop, GNU Image Manipulation Program, etc. are applied to form tampered images from real ones in just a few minutes. To discover hidden signs of tampering in an image deep learning models are an effective tool than any other methods. Models used in deep learning are capable of extracting intricate features from an image automatically. Here we proposed a combination of traditional handcrafted features along with a deep learning model to differentiate between authentic and tampered images. We have presented a dual-branch Convolutional Neural Network in conjunction with Error Level Analysis and noise residuals from Spatial Rich Model. For our experiment, we utilized the freely accessible CASIA dataset. After training the dual-branch network for 16 epochs, it generated an accuracy of 98.55%. We have also provided a comparative analysis with other previously proposed work in the field of image forgery detection. This hybrid approach proves that deep learning models along with some well-known traditional approaches can provide better results for detecting tampered images.},
  archive      = {J_NPL},
  author       = {Chakraborty, Sunen and Chatterjee, Kingshuk and Dey, Paramita},
  doi          = {10.1007/s11063-024-11448-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Detection of image tampering using deep learning, error levels and noise residuals},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reconstruction-aware kernelized fuzzy clustering framework
incorporating local information for image segmentation. <em>NPL</em>,
<em>56</em>(2), 1–55. (<a
href="https://doi.org/10.1007/s11063-024-11450-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernelized fuzzy C-means clustering with weighted local information is an extensively applied robust segmentation algorithm for noisy image. However, it is difficult to effectively solve the problem of segmenting image polluted by strong noise. To address this issue, a reconstruction-aware kernel fuzzy C-mean clustering with rich local information is proposed in this paper. Firstly, the optimization modeling of guided bilateral filtering is given for noisy image; Secondly, this filtering model is embedded into kernelized fuzzy C-means clustering with local information, and a novel reconstruction-filtering information driven fuzzy clustering model for noise-corrupted image segmentation is presented; Finally, a tri-level alternative and iterative algorithm is derived from optimizing model using optimization theory and its convergence is strictly analyzed. Many Experimental results on noisy synthetic images and actual images indicate that compared with the latest advanced fuzzy clustering-related algorithms, the algorithm presented in this paper has better segmentation performance and stronger robustness to noise, and its PSNR and ACC values increase by about 0.16–3.28 and 0.01–0.08 respectively.},
  archive      = {J_NPL},
  author       = {Wu, Chengmao and Qi, Xiao},
  doi          = {10.1007/s11063-024-11450-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-55},
  shortjournal = {Neural Process. Lett.},
  title        = {Reconstruction-aware kernelized fuzzy clustering framework incorporating local information for image segmentation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep convolutional neural network compression method: Tensor
ring decomposition with variational bayesian approach. <em>NPL</em>,
<em>56</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11465-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to deep neural networks (DNNs) a large number of parameters, DNNs increase the demand for computing and storage during training, reasoning and deployment, especially when DNNs stack deeper and wider. Tensor decomposition can not only compress DNN models but also reduce parameters and storage requirements while maintaining high accuracy and performance. About tensor ring (TR) decomposition of tensor decomposition, there are two problems: (1) The practice of setting the TR rank to be equal in TR decomposition results in an unreasonable rank configuration. (2) The training time of selecting rank through iterative processes is time-consuming. To address the two problems, a TR network compression method by Variational Bayesian (TR-VB) is proposed based on the Global Analytic Solution of Empirical Variational Bayesian Matrix Factorization (GAS of EVBMF). The method consists of three steps: (1) rank selection, (2) TR decomposition, and (3) fine-tuning to recover accumulated loss of accuracy. Experimental results show that, for a given network, TR-VB gives the best results in terms of Top-1 accuracy, parameters, and training time under different compression levels. Furthermore, TR-VB validated on CIFAR-10/100 public benchmarks achieves state-of-the-art performance.},
  archive      = {J_NPL},
  author       = {Liu, Weirong and Zhang, Min and Shi, Changhong and Zhang, Ning and Liu, Jie},
  doi          = {10.1007/s11063-024-11465-8},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep convolutional neural network compression method: Tensor ring decomposition with variational bayesian approach},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced coalescence backdoor attack against DNN based on
pixel gradient. <em>NPL</em>, <em>56</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s11063-024-11469-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been widely used in many applications such as face recognition, autonomous driving, etc. However, deep learning models are vulnerable to various adversarial attacks, among which backdoor attack is emerging recently. Most of the existing backdoor attacks use the same trigger or the same trigger generation approach to generate the poisoned samples in the training and testing sets, which is also commonly adopted by many backdoor defense strategies. In this paper, we develop an enhanced backdoor attack (EBA) that aims to reveal the potential flaws of existing backdoor defense methods. We use a low-intensity trigger to embed the backdoor, while a high-intensity trigger to activate it. Furthermore, we propose an enhanced coalescence backdoor attack (ECBA) where multiple low-intensity incipient triggers are designed to train the backdoor model, and then, all incipient triggers are gathered on one sample and enhanced to launch the attack. Experiment results on three popular datasets show that our proposed attacks can achieve high attack success rates while maintaining the model classification accuracy of benign samples. Meanwhile, by hiding the incipient poisoned samples and preventing them from activating the backdoor, the proposed attack exhibits significant stealth and the ability to evade mainstream defense methods during the model training phase.},
  archive      = {J_NPL},
  author       = {Yin, Jianyao and Chen, Honglong and Li, Junjian and Gao, Yudong},
  doi          = {10.1007/s11063-024-11469-4},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Enhanced coalescence backdoor attack against DNN based on pixel gradient},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intuitionistic fuzzy extreme learning machine with the
truncated pinball loss. <em>NPL</em>, <em>56</em>(2), 1–61. (<a
href="https://doi.org/10.1007/s11063-024-11492-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy extreme learning machine (FELM) is an effective algorithm for dealing with classification problems with noises, which uses a membership function to effectively suppress noise in data. However, FELM has the following drawbacks: (a) The membership degree of samples in FELM is constructed by considering only the distance between the samples and the class center, not the local information of samples. It is easy to mistake some boundary samples for noises. (b) FELM uses the least squares loss function, which leads to sensitivity to feature noise and instability to re-sampling. To address the above drawbacks, we propose an intuitionistic fuzzy extreme learning machine with the truncated pinball loss (TPin-IFELM). Firstly, we use the K-nearest neighbor (KNN) method to obtain local information of the samples and then construct membership and non-membership degrees for each sample in the random mapping feature space based on valuable local information. Secondly, we calculate the score value of samples based on the membership and non-membership degrees, which can effectively identify whether the boundary samples are noises or not. Thirdly, in order to maintain the sparsity and robustness of the model, and enhance the stability of the resampling of the model, we introduce the truncated pinball loss function into the model. Finally, in order to solve more efficiently, we employ the concave-convex procedure (CCCP) to solve TPin-IFELM. Extensive comparative experiments are conducted on the benchmark datasets to verify the superior performance of TPin-IFELM.},
  archive      = {J_NPL},
  author       = {Gao, Qingyun and Ai, Qing and Wang, Wenhui},
  doi          = {10.1007/s11063-024-11492-5},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-61},
  shortjournal = {Neural Process. Lett.},
  title        = {Intuitionistic fuzzy extreme learning machine with the truncated pinball loss},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Power optimization in wireless sensor network using VLSI
technique on FPGA platform. <em>NPL</em>, <em>56</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11495-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the demand for high-performance wireless sensor networks (WSN) is increasing, and its power requirement has threatened the survival of WSN. The routing methods cannot optimize power consumption. To improve the power consumption, VLSI based power optimization technology is proposed in this article. Different elements in WSN, such as sensor nodes, modulation schemes, and package data transmission, influence energy usage. Following a WSN power study, it was discovered that lowering the energy usage of sensor networks is critical in WSN. In this manuscript, a power optimization model for wireless sensor networks (POM-WSN) is proposed. The proposed system shows how to build and execute a power-saving strategy for WSNs using a customized collaborative unit with parallel processing capabilities on FPGA (Field Programmable Gate Array) and a smart power component. The customizable cooperation unit focuses on applying specialized hardware to customize Operating System speed and transfer it to a soft intel core. This device decreases the OS (Operating System) central processing unit (CPU) overhead associated with installing processor-based IoT (Internet of Things) devices. The smart power unit controls the soft CPU’s clock and physical peripherals, putting them in the right state depending on the hardware requirements of the program (tasks) being executed. Furthermore, by taking the command signal from a collaborative custom unit, it is necessary to adjust the amplitude and current. The efficiency and energy usage of the FPGA-based energy saver approach for sensor nodes are compared to the energy usage of processor-based WSN nodes implementations. Using FPGA programmable architecture, the research seeks to build effective power-saving approaches for WSNs.},
  archive      = {J_NPL},
  author       = {Leelakrishnan, Saranya and Chakrapani, Arvind},
  doi          = {10.1007/s11063-024-11495-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {Power optimization in wireless sensor network using VLSI technique on FPGA platform},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-back-propagation algorithm for signal neural network
decomposition. <em>NPL</em>, <em>56</em>(2), 1–27. (<a
href="https://doi.org/10.1007/s11063-024-11518-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel back-propagation error technique is presented. This neural network structure allows for two fundamental basic modes: (1) To decompose the neurones by transforming their variables, weights, and scalar functions into vectors. This conveys for the decomposition of the transfer function of every neurone (where the output variables are the components of the decomposition) and, consequently, to be written as the invariant sum of orthogonal functions, with the safeguard of preserving information This orthogonality is proven using Fourier theory. (2) In a second mode, a tuned neural network that occupies one of the channels of the neural network can see the weights of its supplementary channels adjusted to retain additional information. Only the decomposition algorithm of the network is presented here—Multi-back-propagation algorithm. The adopted methodology is validated step-by-step with some representative examples. Namely, to assess the performance of the splitting method, two different examples have been constructed from scratch: (1) a 2D classification problem and (2) a 3D surface. In both problems, the signal and transfer functions of the neural network are successfully decomposed without information losses. Therefore, since the main contribution of this work is to allow for the organisation of the information stored in neural network structure, through a split process, this promising method shows potential use in various areas—e.g. classification and/or pattern recognition problems, data analysis, modelling and so on. In the future, we expect to work further in the method computational aspects to render it more efficient, versatile and robust.},
  archive      = {J_NPL},
  author       = {Salgado, Paulo and Perdicoúlis, T.-P. Azevedo},
  doi          = {10.1007/s11063-024-11518-y},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-27},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-back-propagation algorithm for signal neural network decomposition},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Central attention with multi-graphs for image annotation.
<em>NPL</em>, <em>56</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s11063-024-11525-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, the development of multimedia and computer vision has sparked significant interest among researchers in the field of automatic image annotation. However, much of the research has primarily focused on using a single graph for annotating images in semi-supervised learning. Conversely, numerous approaches have explored the integration of multi-view or image segmentation techniques to create multiple graph structures. Yet, relying solely on a single graph proves to be challenging, as it struggles to capture the complete manifold of structural information. Furthermore, the computational complexity of building multiple graph structures based on multi-view or image segmentation is substantial and time-consuming. To address these issues, we propose a novel method called &quot;Central Attention with Multi-graphs for Image Annotation.&quot; Our approach emphasizes the critical role of the central image region in the annotation process. Remarkably, we demonstrate that impressive performance can be achieved by leveraging just two graph structures, composed of central and overall features, in semi-supervised learning. To validate the effectiveness of our proposed method, we conducted a series of experiments on benchmark datasets, including Corel5K, ESPGame, and IAPRTC12. These experiments provide empirical evidence of our method’s capabilities.},
  archive      = {J_NPL},
  author       = {Liu, Baodi and Liu, Yan and Shao, Qianqian and Liu, Weifeng},
  doi          = {10.1007/s11063-024-11525-z},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Neural Process. Lett.},
  title        = {Central attention with multi-graphs for image annotation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-enhanced attention for image captioning. <em>NPL</em>,
<em>56</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s11063-024-11527-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning, which involves automatically generating textual descriptions based on the content of images, has garnered increasing attention from researchers. Recently, Transformers have emerged as the preferred choice for the language model in image captioning models. Transformers leverage self-attention mechanisms to address gradient accumulation issues and eliminate the risk of gradient explosion commonly associated with RNN networks. However, a challenge arises when the input features of the self-attention mechanism belong to different categories, as it may result in ineffective highlighting of important features. To address this issue, our paper proposes a novel attention mechanism called Self-Enhanced Attention (SEA), which replaces the self-attention mechanism in the decoder part of the Transformer model. In our proposed SEA, after generating the attention weight matrix, it further adjusts the matrix based on its own distribution to effectively highlight important features. To evaluate the effectiveness of SEA, we conducted experiments on the COCO dataset, comparing the results with different visual models and training strategies. The experimental results demonstrate that when using SEA, the CIDEr score is significantly higher compared to the scores obtained without using SEA. This indicates the successful addressing of the challenge of effectively highlighting important features with our proposed mechanism.},
  archive      = {J_NPL},
  author       = {Sun, Qingyu and Zhang, Juan and Fang, Zhijun and Gao, Yongbin},
  doi          = {10.1007/s11063-024-11527-x},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {Self-enhanced attention for image captioning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CNN-based methods for offline arabic handwriting
recognition: A review. <em>NPL</em>, <em>56</em>(2), 1–38. (<a
href="https://doi.org/10.1007/s11063-024-11544-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arabic Handwriting Recognition (AHR) is a complex task involving the transformation of handwritten Arabic text from image format into machine-readable data, holding immense potential across various applications. Despite its significance, AHR encounters formidable challenges due to the intricate nature of Arabic script and the diverse array of handwriting styles. In recent years, Convolutional Neural Networks (CNNs) have emerged as a pivotal and promising solution to address these challenges, demonstrating remarkable performance and offering distinct advantages. However, the dominance of CNNs in AHR lacks a dedicated comprehensive review in the existing literature. This review article aims to bridge the existing gap by providing a comprehensive analysis of CNN-based methods in AHR. It covers both segmentation and recognition tasks, delving into advancements in network architectures, databases, training strategies, and employed methods. The article offers an in-depth comparison of these methods, considering their respective strengths and limitations. The findings of this review not only contribute to the current understanding of CNN applications in AHR but also pave the way for future research directions and improved practices, thereby enriching and advancing this critical domain. The review also aims to uncover genuine challenges in the domain, providing valuable insights for researchers and practitioners.},
  archive      = {J_NPL},
  author       = {El Khayati, Mohsine and Kich, Ismail and Taouil, Youssef},
  doi          = {10.1007/s11063-024-11544-w},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-38},
  shortjournal = {Neural Process. Lett.},
  title        = {CNN-based methods for offline arabic handwriting recognition: A review},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A feature selection method based on feature-label
correlation information and self-adaptive MOPSO. <em>NPL</em>,
<em>56</em>(2), 1–33. (<a
href="https://doi.org/10.1007/s11063-024-11553-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection can be seen as a multi-objective task, where the goal is to select a subset of features that exhibit minimal correlation among themselves while maximizing their correlation with the target label. Multi-objective particle swarm optimization algorithm (MOPSO) has been extensively utilized for feature selection and has achieved good performance. However, most MOPSO-based feature selection methods are random and lack knowledge guidance in the initialization process, ignoring certain valuable prior information in the feature data, which may lead to the generated initial population being far from the true Pareto front (PF) and influence the population’s rate of convergence. Additionally, MOPSO has a propensity to become stuck in local optima during the later iterations. In this paper, a novel feature selection method (fMOPSO-FS) is proposed. Firstly, with the aim of improving the initial solution quality and fostering the interpretability of the selected features, a novel initialization strategy that incorporates prior information during the initialization process of the particle swarm is proposed. Furthermore, an adaptive hybrid mutation strategy is proposed to avoid the particle swarm from getting stuck in local optima and to further leverage prior information. The experimental results demonstrate the superior performance of the proposed algorithm compared to the comparison algorithms. It yields a superior feature subset on nine UCI benchmark datasets and six gene expression profile datasets.},
  archive      = {J_NPL},
  author       = {Han, Fei and Li, Fanyu and Ling, Qinghua and Han, Henry and Lu, Tianyi and Jiao, Zijian and Zhang, Haonan},
  doi          = {10.1007/s11063-024-11553-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-33},
  shortjournal = {Neural Process. Lett.},
  title        = {A feature selection method based on feature-label correlation information and self-adaptive MOPSO},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human gait recognition based on frontal-view walking
sequences using multi-modal feature representations and learning.
<em>NPL</em>, <em>56</em>(2), 1–23. (<a
href="https://doi.org/10.1007/s11063-024-11554-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite that much progress has been reported in gait recognition, most of these existing works adopt lateral-view parameters as gait features, which requires large area of data collection environment and limits the applications of gait recognition in real-world practice. In this paper, we adopt frontal-view walking sequences rather than lateral-view sequences and propose a new gait recognition method based on multi-modal feature representations and learning. Specifically, we characterize walking sequences with two different kinds of frontal-view gait features representations, including holistic silhouette and dense optical flow. Pedestrian regions extraction is achieved by an improved YOLOv7 algorithm called Gait-YOLO algorithm to eliminate the effects of background interference. Multi-modal fusion module (MFM) is proposed to explore the intrinsic connections between silhouette and dense optical flow features by using squeeze and excitation operations at the channel and spatial levels. Gait feature encoder is further used to extract global walking characteristics, enabling efficient multi-modal information fusion. To validate the efficacy of the proposed method, we conduct experiments on CASIA-B and OUMVLP gait databases and compare performance of our proposed method with other existing state-of-the-art gait recognition methods.},
  archive      = {J_NPL},
  author       = {Deng, Muqing and Zhong, Zebang and Zou, Yi and Wang, Yanjiao and Wang, Kaiwei and Liao, Junrong},
  doi          = {10.1007/s11063-024-11554-8},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {Human gait recognition based on frontal-view walking sequences using multi-modal feature representations and learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SGNNRec: A scalable double-layer attention-based graph
neural network recommendation model. <em>NPL</em>, <em>56</em>(2), 1–21.
(<a href="https://doi.org/10.1007/s11063-024-11555-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the information from the multi-relationship graphs is difficult to aggregate, the graph neural network recommendation model focuses on single-relational graphs (e.g., the user-item rating bipartite graph and user-user social relationship graphs). However, existing graph neural network recommendation models have insufficient flexibility. The recommendation accuracy instead decreases when low-quality auxiliary information is aggregated in the recommendation model. This paper proposes a scalable graph neural network recommendation model named SGNNRec. SGNNRec fuse a variety of auxiliary information (e.g., user social information, item tag information and user-item interaction information) beside user-item rating as supplements to solve the problem of data sparsity. A tag cluster-based item-semantic graph method and an apriori algorithm-based user-item interaction graph method are proposed to realize the construction of graph relations. Furthermore, a double-layer attention network is designed to learn the influence of latent factors. Thus, the latent factors are to be optimized to obtain the best recommendation results. Empirical results on real-world datasets verify the effectiveness of our model. SGNNRec can reduce the influence of poor auxiliary information; moreover, with increasing the number of auxiliary information, the model accuracy improves.},
  archive      = {J_NPL},
  author       = {He, Jing and Tang, Le and Tang, Dan and Wang, Ping and Cai, Li},
  doi          = {10.1007/s11063-024-11555-7},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {SGNNRec: A scalable double-layer attention-based graph neural network recommendation model},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Co-GZSL: Feature contrastive optimization for generalized
zero-shot learning. <em>NPL</em>, <em>56</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s11063-024-11557-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized Zero-Shot Learning (GZSL) learns from only labeled seen classes during training but discriminates both seen and unseen classes during testing. In GZSL tasks, most of the existing methods commonly utilize visual and semantic features for training. Due to the lack of visual features for unseen classes, recent works generate real-like visual features by using semantic features. However, the synthesized features in the original feature space lack discriminative information. It is important that the synthesized visual features should be similar to the ones in the same class, but different from the other classes. One way to solve this problem is to introduce the embedding space after generating visual features. Following this situation, the embedded features from the embedding space can be inconsistent with the original semantic features. For another way, some recent methods constrain the representation by reconstructing the semantic features using the original visual features and the synthesized visual features. In this paper, we propose a hybrid GZSL model, named feature Contrastive optimization for GZSL (Co-GZSL), to reconstruct the semantic features from the embedded features, which ensures that the embedded features are close to the original semantic features indirectly by comparing reconstructed semantic features with original semantic features. In addition, to settle the problem that the synthesized features lack discrimination and semantic consistency, we introduce a Feature Contrastive Optimization Module (FCOM) and jointly utilize contrastive and semantic cycle-consistency losses in the FCOM to strengthen the intra-class compactness and the inter-class separability and to encourage the model to generate semantically consistent and discriminative visual features. By combining the generative module, the embedding module, and the FCOM, we achieve Co-GZSL. We evaluate the proposed Co-GZSL model on four benchmarks, and the experimental results indicate that our model is superior over current methods. Code is available at: https://github.com/zhanzhuxi/Co-GZSL .},
  archive      = {J_NPL},
  author       = {Li, Qun and Zhan, Zhuxi and Shen, Yaying and Bhanu, Bir},
  doi          = {10.1007/s11063-024-11557-5},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Co-GZSL: Feature contrastive optimization for generalized zero-shot learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-separation method-based global stability criteria for
takagi–sugeno fuzzy quaternion-valued BAM delayed neural networks using
quaternion-valued auxiliary function-based integral inequality.
<em>NPL</em>, <em>56</em>(2), 1–32. (<a
href="https://doi.org/10.1007/s11063-024-11559-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the global asymptotic stability (GAS) problem for Takagi–Sugeno (T-S) fuzzy quaternion-valued bidirectional associative memory neural networks (QVBAMNNs) with discrete, distributed and leakage delays by using non-separation method. By applying T-S fuzzy model, we first consider a general form of T-S fuzzy QVBAMNNs with time delays. Then, by constructing appropriate Lyapunov–Krasovskii functionals and employing quaternion-valued integral inequalities and homeomorphism theory, several delay-dependent sufficient conditions are obtained to guarantee the existence and GAS of the considered neural networks (NNs). In addition, these theoretical results are presented in the form of quaternion-valued linear matrix inequalities (LMIs), which can be verified numerically using the effective YALMIP toolbox in MATLAB. Finally, two numerical illustrations are presented along with their simulations to demonstrate the validity of the theoretical analysis.},
  archive      = {J_NPL},
  author       = {Ramalingam, Sriraman and Kwon, Oh-Min},
  doi          = {10.1007/s11063-024-11559-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-32},
  shortjournal = {Neural Process. Lett.},
  title        = {Non-separation method-based global stability criteria for Takagi–Sugeno fuzzy quaternion-valued BAM delayed neural networks using quaternion-valued auxiliary function-based integral inequality},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global asymptotic stability of anti-periodic solutions of
time-delayed fractional bam neural networks. <em>NPL</em>,
<em>56</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s11063-024-11561-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, bidirectional fractional-order BAM neural networks with time-varying delays are examined. Time delay is an important phenomenon in the implementation of a signal or effect passing through neural network. Signal transmission in neural networks can generally be described as an anti-periodic process. Our aim is to show global asymptotic stability and the uniqueness of the equilibrium point for such neural networks in the problem with antiperiodic solution.For this purpose, the proof was made using differential inequality theory, basic analysis information, and the Lyapunov functional method. In addition, a numerical example is presented to verify the theoretical results.},
  archive      = {J_NPL},
  author       = {Tuz, Münevver},
  doi          = {10.1007/s11063-024-11561-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Global asymptotic stability of anti-periodic solutions of time-delayed fractional bam neural networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved lightweight head detection based on GhostNet-SSD.
<em>NPL</em>, <em>56</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s11063-024-11563-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This abstract proposes an algorithm for human head detection in elevator cabins that addresses the challenges of improving detection accuracy, reducing detection speed, and decreasing the number of parameters. The algorithm is based on GhostNet-SSD and includes several improvements, such as an efficient coordinate attention mechanism to replace the Squeeze-and-Excitation attention mechanism, optimization of auxiliary convolutional layer with large parameter weight, and adjustment of anchor ratio based on the statistical results of human head labeling frame. In addition, data normalization and convolutional fusion methods are used for inference acceleration. The algorithm was tested on JETSON XAVIER NX development board and achieved a new state-of-the-art 97.91% AP at 61FPS, outperforming other detectors with similar inference speed. The effectiveness of each component was validated through careful experimentation.},
  archive      = {J_NPL},
  author       = {Hou, Hongtao and Guo, Mingzhen and Wang, Wei and Liu, Kuan and Luo, Zijiang},
  doi          = {10.1007/s11063-024-11563-7},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {Improved lightweight head detection based on GhostNet-SSD},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modal domain adaptation method based on parameter
fusion and two-step alignment. <em>NPL</em>, <em>56</em>(2), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11567-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the well-known domain shift problem, directly deploying a trained multi-modal classifier to a new environment usually leads to poor performance. The existing multi-modal domain adaption methods not only lack the fine-grained information of cross-modal data distribution, but also lack the cross-modal correlation research. Therefore, this paper proposes a multi-modal domain adaption method based on parameter fusion and two-step alignment (PFTS) to solve the related problems. The consistency of network parameters is used to enhance the correlation among modalities, and a higher-order moment measurement is introduced to improve the alignment of data distribution at the fine-grained level. In addition, the weighting of each modality is further carried out to achieve focused transfer. Comprehensive experiments based on multi-modal datasets with different domain adaption settings have been conducted, the results show that the precision of PFTS is 5.38% higher than state-of-the-art multi-modal domain adaption methods.},
  archive      = {J_NPL},
  author       = {Wu, Lan and Wang, Han and Gong, Lishuang and Yao, Yuan and Guo, Xin and Li, Binquan},
  doi          = {10.1007/s11063-024-11567-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-modal domain adaptation method based on parameter fusion and two-step alignment},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dissipativity of stochastic competitive neural networks with
multiple time delays. <em>NPL</em>, <em>56</em>(2), 1–23. (<a
href="https://doi.org/10.1007/s11063-024-11569-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The $$(Q,R,S)-\gamma -$$ dissipative of stochastic competitive neural networks (SCNNs) with leakage delays and discrete delay is studied. Firstly, Lyapunov–Krasovskii functional is constructed, which studies the relationship between various types of time delays. Secondly, by using integral inequality technique, the linear matrix inequality (LMI) criterion of $$(Q,R,S)-\gamma -$$ dissipative in the mean square sense of SCNNs is obtained. Furthermore, the obtained LMI criterion is extended to the passivity in the mean square sense, stability in the mean square sense, $$(Q,R,S)-\gamma -$$ dissipative and passivity. Finally, the effectiveness of the obtained results are verified by numerical simulation.},
  archive      = {J_NPL},
  author       = {Tang, Dandan and Wang, Baoxian and Hao, Caiqing},
  doi          = {10.1007/s11063-024-11569-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {Dissipativity of stochastic competitive neural networks with multiple time delays},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive learning rate deep learning optimizer using long
and short-term gradients based on g–l fractional-order derivative.
<em>NPL</em>, <em>56</em>(2), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11571-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning model is a multi-layered network structure, and the network parameters that evaluate the final performance of the model must be trained by a deep learning optimizer. In comparison to the mainstream optimizers that utilize integer-order derivatives reflecting only local information, fractional-order derivatives optimizers, which can capture global information, are gradually gaining attention. However, relying solely on the long-term estimated gradients computed from fractional-order derivatives while disregarding the influence of recent gradients on the optimization process can sometimes lead to issues such as local optima and slower optimization speeds. In this paper, we design an adaptive learning rate optimizer called AdaGL based on the Grünwald–Letnikov (G–L) fractional-order derivative. It changes the direction and step size of parameter updating dynamically according to the long-term and short-term gradients information, addressing the problem of falling into local minima or saddle points. To be specific, by utilizing the global memory of fractional-order calculus, we replace the gradient of parameter update with G–L fractional-order approximated gradient, making better use of the long-term curvature information in the past. Furthermore, considering that the recent gradient information often impacts the optimization phase significantly, we propose a step size control coefficient to adjust the learning rate in real-time. To compare the performance of the proposed AdaGL with the current advanced optimizers, we conduct several different deep learning tasks, including image classification on CNNs, node classification and graph classification on GNNs, image generation on GANs, and language modeling on LSTM. Extensive experimental results demonstrate that AdaGL achieves stable and fast convergence, excellent accuracy, and good generalization performance.},
  archive      = {J_NPL},
  author       = {Chen, Shuang and Zhang, Changlun and Mu, Haibing},
  doi          = {10.1007/s11063-024-11571-7},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {An adaptive learning rate deep learning optimizer using long and short-term gradients based on G–L fractional-order derivative},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural data augmentation for legal overruling task: Small
deep learning models vs. Large language models. <em>NPL</em>,
<em>56</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s11063-024-11574-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models produce impressive results in any natural language processing applications when given a better learning strategy and trained with large labeled datasets. However, the annotation of massive training data is far too expensive, especially in the legal domain, due to the need for trained legal professionals. Data augmentation solves the problem of learning without labeled big data. In this paper, we employ pre-trained language models and prompt engineering to generate large-scale pseudo-labeled data for the legal overruling task using 100 data samples. We train small recurrent and convolutional deep-learning models using this data and fine-tune a few other transformer models. We then evaluate the effectiveness of the models, both with and without data augmentation, using the benchmark dataset and analyze the results. We also test the performance of these models with the state-of-the-art GPT-3 model under few-shot setting. Our experimental findings demonstrate that data augmentation results in better model performance in the legal overruling task than models trained without augmentation. Furthermore, our best-performing deep learning model trained on augmented data outperforms the few-shot GPT-3 by 18% in the F1-score. Additionally, our results highlight that the small neural networks trained with augmented data achieve outcomes comparable to those of other large language models.},
  archive      = {J_NPL},
  author       = {Sheik, Reshma and Siva Sundara, K. P. and Nirmala, S. Jaya},
  doi          = {10.1007/s11063-024-11574-4},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Neural data augmentation for legal overruling task: Small deep learning models vs. large language models},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PEB-TAXO: Projecting entities as boxes for taxonomy
expansion. <em>NPL</em>, <em>56</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s11063-024-11575-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As domain knowledge evolves, new concepts (entities) continuously emerge, leading to a decrease in the coverage of existing taxonomies with hierarchical structures, thus necessitating the continual expansion of these taxonomies to include new concepts. Due to the relationships (“contain”, “disjoint”, and “intersect”) between the boxes, which can effectively represent asymmetric hierarchies, box embeddings have been successfully applied in taxonomy expansion. However, existing models that use box embeddings for taxonomy expansion have the following shortcomings: (1) the size of the boxes is not restricted, and the model produces meaningless boxes; (2) the model does not fully utilize the geometric information of the boxes. To address the above shortcomings, this paper proposes a taxonomy expansion model based on projecting entities as boxes: PEB-TAXO. Firstly, PEB-TAXO employs modified L1 regularization to constrain the box sizes in all dimensions, pushing the box sizes towards the preset minimum, thereby avoiding the generation of meaningless boxes by the model. Secondly, the model utilizes a box inclusion inference method: it infers the relationship between two entities through the relationship between two boxes in geometric space, thus fully exploiting the geometric information of the boxes for more accurate inferences. Finally, we conducted extensive experiments on two public datasets and verified that PEB-TAXO greatly improves performance over mainstream taxonomy expansion methods.},
  archive      = {J_NPL},
  author       = {Zhang, Yuhang and Qin, Jiwei and Feng, Chongren},
  doi          = {10.1007/s11063-024-11575-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {PEB-TAXO: Projecting entities as boxes for taxonomy expansion},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CLSTM-SNP: Convolutional neural network to enhance spiking
neural p systems for named entity recognition based on long short-term
memory network. <em>NPL</em>, <em>56</em>(2), 1–40. (<a
href="https://doi.org/10.1007/s11063-024-11576-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Membrane computing is a type of parallel computing system (generally called P system) abstracted from information exchange mechanisms in biological cells, tissues, or neurons, which can process data in a distributed and interpretable manner. LSTM-SNP, the first model of long short-term memory networks based on parameterized nonlinear Spiking neural P systems, was proposed recently. However, a systematic understanding and leveraging of the LSTM-SNP model to address named entity recognition (NER) and other natural language processing (NLP) tasks are still lacking. The bottleneck of the NER task lies in the scarcity of data and the vague definition of entity edges. Most approaches center on dataset handling, and there have been few attempts to address the issue in Spiking neural P (SNP) systems. This paper proposes a model named CLSTM-SNP based on the LSTM-SNP, aiming to tackle the NER problem in the field of SNP systems for the first time. First, this study employs a CNN layer to obtain character-level characteristics. Second, GloVe word vectors are utilized as word representations. Third, the research employs the LSTM-SNP to analyze textual features. We subsequently studied CLSTM-SNP’s effectiveness in addressing NER problems on CoNLL-2003 and OntoNotes 5.0 datasets and compared it to the results of five other baseline methods. Our model CLSTM-SNP achieved a macro F1-score of 89.2 $$\%$$ on CoNLL-2003 and 75.5 $$\%$$ on OntoNotes 5.0, respectively. The performance of CLSTM-SNP and LSTM-SNP indicates a great potential for handling named entity recognition or other sequential tasks in NLP.},
  archive      = {J_NPL},
  author       = {Deng, Qin and Chen, Xiaoliang and Yang, Zaiyan and Li, Xianyong and Du, Yajun},
  doi          = {10.1007/s11063-024-11576-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-40},
  shortjournal = {Neural Process. Lett.},
  title        = {CLSTM-SNP: Convolutional neural network to enhance spiking neural p systems for named entity recognition based on long short-term memory network},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel distributed process monitoring framework of
VAE-enhanced with deep neural network. <em>NPL</em>, <em>56</em>(2),
1–31. (<a href="https://doi.org/10.1007/s11063-024-11577-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent manufacturing process needs to adopt distributed monitoring scenario due to its massive, high-dimensional and complex data. Distributed process monitoring has been introduced into global monitoring and local monitoring to analyze the characteristic relationship between process data. However, the existing framework methods ignore or suppress the fault information and thus cannot effectively identify the local faults and the time sequence characteristics between units in the batch production system. This paper proposes a novel distributed process monitoring framework based on Girvan-Newman algorithm modular subunit partitioning and probabilistic learning model with deep neural networks. First, Girvan-Newman algorithm is used to divide the complex manufacturing system modularized to reduce the latitude of data processing. Second, variational autoencoder (VAE) is adopted to ensure the stability of local analysis, and long short-term memory is adopted to improve the VAE model to detect global multi-time scale anomalies. Finally, distributed process fault detection is carried out for each subunit in a separate and integrated manner, and the performance of the framework in distributed process monitoring is analyzed through two fault detection indicators T2 and SPE statistics. A case study of the Tennessee Eastman Process is used to demonstrate the performance and applicability of the proposed framework. Results show that the proposed VAE enhancement framework based on the DNN could accurately identify faults in distributed process monitoring and locate the specific sub-units where the fault occurs. Compared with VAE-DNN method and traditional process monitoring methods, the framework proposed in this paper has higher fault detection rate and lower false alarm rate, and the detection rate of some faults can reach 100%.},
  archive      = {J_NPL},
  author       = {Yin, Ming and Tian, Jiayi and Wang, Yibo and Jiang, Jijiao},
  doi          = {10.1007/s11063-024-11577-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-31},
  shortjournal = {Neural Process. Lett.},
  title        = {A novel distributed process monitoring framework of VAE-enhanced with deep neural network},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new optimization model for MLP hyperparameter tuning:
Modeling and resolution by real-coded genetic algorithm. <em>NPL</em>,
<em>56</em>(2), 1–31. (<a
href="https://doi.org/10.1007/s11063-024-11578-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an efficient real-coded genetic algorithm (RCGA) evolved for constrained real-parameter optimization. This novel RCGA incorporates three specially crafted evolutionary operators: Tournament Selection (RS) with elitism, Simulated Binary Crossover (SBX), and Polynomial Mutation (PM). The application of this RCGA is directed toward optimizing the MLPRGA+5 model. This model is designed to configure Multilayer Perceptron neural networks by optimizing both their architecture and associated hyperparameters, including learning rates, activation functions, and regularization hyperparameters. The objective function employed is the widely recognized learning loss function, commonly used for training neural networks. The integration of this objective function is supported by the introduction of new variables representing MLP hyperparameter values. Additionally, a set of constraints is thoughtfully designed to align with the structure of the Multilayer Perceptron (MLP) and its corresponding hyperparameters. The practicality and effectiveness of the MLPRGA+5 approach are demonstrated through extensive experimentation applied to four datasets from the UCI machine learning repository. The results highlight the remarkable performance of MLPRGA+5, characterized by both complexity reduction and accuracy improvement.},
  archive      = {J_NPL},
  author       = {El-Hassani, Fatima Zahrae and Amri, Meryem and Joudar, Nour-Eddine and Haddouch, Khalid},
  doi          = {10.1007/s11063-024-11578-0},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-31},
  shortjournal = {Neural Process. Lett.},
  title        = {A new optimization model for MLP hyperparameter tuning: Modeling and resolution by real-coded genetic algorithm},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boundedness and convergence of mini-batch gradient method
with cyclic dropconnect and penalty. <em>NPL</em>, <em>56</em>(2), 1–16.
(<a href="https://doi.org/10.1007/s11063-024-11581-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dropout is perhaps the most popular regularization method for deep learning. Due to the stochastic nature of the Dropout mechanism, the convergence analysis of Dropout learning is challenging and the existing convergence results are mainly of probability nature. In this paper, we investigate the deterministic convergence of the mini-batch gradient learning method with Dropconnect and penalty. By drawing and presenting a set of samples of the mask matrix of Dropconnect regularization into the learning process in a cyclic manner, we establish an upper bound of the norm of the weight vector sequence and prove that the gradient of the cost function, the cost function itself, and the weight vector sequence deterministically converge to zero, a constant, and a fixed point respectively. Considering Dropout is mathematically a specific realization of Dropconnect, the established theoretical results in this paper are also valid for Dropout learning. Illustrative simulations on the MNIST dataset are provided to verify the theoretical analysis.},
  archive      = {J_NPL},
  author       = {Jing, Junling and Jinhang, Cai and Zhang, Huisheng and Zhang, Wenxia},
  doi          = {10.1007/s11063-024-11581-5},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Boundedness and convergence of mini-batch gradient method with cyclic dropconnect and penalty},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep reinforcement learning model for stock portfolio
management based on data fusion. <em>NPL</em>, <em>56</em>(2), 1–24. (<a
href="https://doi.org/10.1007/s11063-024-11582-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) can be used to extract deep features that can be incorporated into reinforcement learning systems to enable improved decision-making; DRL can therefore also be used for managing stock portfolios. Traditional methods cannot fully exploit the advantages of DRL because they are generally based on real-time stock quotes, which do not have sufficient features for making comprehensive decisions. In this study, in addition to stock quotes, we introduced stock financial indices as additional stock features. Moreover, we used Markowitz mean-variance theory for determining stock correlation. A three-agent deep reinforcement learning model called Collaborative Multi-agent reinforcement learning-based stock Portfolio management System (CMPS) was designed and trained based on fused data. In CMPS, each agent was implemented with a deep Q-network to obtain the features of time-series stock data, and a self-attention network was used to combine the output of each agent. We added a risk-free asset strategy to CMPS to prevent risks and referred to this model as CMPS-Risk Free (CMPS-RF). We conducted experiments under different market conditions using the stock data of China Shanghai Stock Exchange 50 and compared our model with the state-of-the-art models. The results showed that CMPS could obtain better profits than the compared benchmark models, and CMPS-RF was able to accurately recognize the market risk and achieved the best Sharpe and Calmar ratios. The study findings are expected to aid in the development of an efficient investment-trading strategy.},
  archive      = {J_NPL},
  author       = {Li, Haifeng and Hai, Mo},
  doi          = {10.1007/s11063-024-11582-4},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-24},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep reinforcement learning model for stock portfolio management based on data fusion},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extended dissipative criteria for delayed semi-discretized
competitive neural networks. <em>NPL</em>, <em>56</em>(2), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11583-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This brief investigates the extended dissipativity performance of semi-discretized competitive neural networks (CNNs) with time-varying delays. Inspired by the computational efficiency and feasibility of implementing the networks, we formulate a discrete counterpart to the continuous-time CNNs. By employing an appropriate Lyapunov–Krasovskii functional (LKF) and a relaxed summation inequality, sufficient conditions ensure the extended dissipative criteria of discretized CNNs are obtained in the linear matrix inequality framework. Finally, to refine our prediction, two numerical examples are provided to demonstrate the sustainability and merits of the theoretical results.},
  archive      = {J_NPL},
  author       = {Adhira, B. and Nagamani, G.},
  doi          = {10.1007/s11063-024-11583-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Extended dissipative criteria for delayed semi-discretized competitive neural networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyperspectral image classification based on 3D–2D hybrid
convolution and graph attention mechanism. <em>NPL</em>, <em>56</em>(2),
1–21. (<a href="https://doi.org/10.1007/s11063-024-11584-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks and graph convolutional neural networks are two classical deep learning models that have been widely used in hyperspectral image classification tasks with remarkable achievements. However, hyperspectral image classification models based on graph convolutional neural networks using only shallow spectral or spatial features are insufficient to provide reliable similarity measures for constructing graph structures, limiting their classification performance. To address this problem, we propose a new end-to-end hyperspectral image classification model combining 3D–2D hybrid convolution and a graph attention mechanism (3D–2D-GAT). The model utilizes the collaborative work of hybrid convolutional feature extraction module and GAT module to improve classification accuracy. First, a 3D–2D hybrid convolutional network is constructed and used to quickly extract the discriminant deep spatial-spectral features of various ground objects in hyperspectral image. Then, the graph is built based on deep spatial-spectral features to enhance the feature representation ability. Finally, a network of graph attention mechanism is adopted to learn long-range spatial relationship and distinguish the intra-class variation and inter-class similarity among different samples. The experimental results on three datasets, Indian Pine, the University of Pavia and Salinas Valley show that the proposed method can achieve higher classification accuracy compared with other advanced methods.},
  archive      = {J_NPL},
  author       = {Zhang, Hui and Tu, Kaiping and Lv, Huanhuan and Wang, Ruiqin},
  doi          = {10.1007/s11063-024-11584-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Hyperspectral image classification based on 3D–2D hybrid convolution and graph attention mechanism},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stabilization of semi-markovian jumping uncertain
complex-valued networks with time-varying delay: A sliding-mode control
approach. <em>NPL</em>, <em>56</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11585-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper pays close attention to the stabilization issue for delayed uncertain semi-Markovian jumping complex-valued networks via sliding mode control. The concerned corresponding transition rates depend on a positive constant, i.e., sojourn-time, which is not required to obey the general exponential distribution. Combine the generalized Dynkin’s formula with Lyapunov stability theory as well as the characteristics of cumulative distribution functions, a few sufficient criteria are proposed to ascertain the stochastic stability of the obtained sliding mode dynamical system. In addition, design a novel sliding mode controller to ensure all state trajectories of the potential closed-loop system can reach the synthesized sliding mode switching surface in a finite time and maintain there in the subsequent time. In the end of paper, one simple example is presented to verify superiority and feasibility of the provided controller design scheme.},
  archive      = {J_NPL},
  author       = {Li, Qiang and Wei, Hanqing and Hua, Dingli and Wang, Jinling and Yang, Junxian},
  doi          = {10.1007/s11063-024-11585-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {Stabilization of semi-markovian jumping uncertain complex-valued networks with time-varying delay: A sliding-mode control approach},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep embedding clustering based on residual autoencoder.
<em>NPL</em>, <em>56</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s11063-024-11586-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering algorithm is one of the most widely used and influential analysis techniques. With the advent of deep learning, deep embedding clustering algorithms have rapidly evolved and yield promising results. Much of the success of these algorithms depends on the potential expression captured by the autoencoder network. Therefore, the quality of the potential expression directly determines the algorithm’s performance. In view of this, researchers have proposed many improvements. Although the performance has been slightly improved, they all have one shortcoming, that is, too much emphasis is placed on the original data reconstruction ability during the process of feature expression, which greatly limits the further expression of potential features according to specific clustering tasks. Moreover, there is a large amount of noise in the original data, so blindly emphasizing reconstruction will only backfire. Hence, we innovatively propose a deep embedding clustering algorithm based on residual autoencoder (DECRA) after in-depth research. Specifically, a novel autoencoder network with residual structure is proposed and introduced into deep embedded clustering tasks. The network introduces an adaptive weight layer in feature representation z, which can make it have good robustness, generalization for specific tasks, and adaptive learning of better feature embeddings according to category classification. In this paper, the reasons for the validity of this structure are explained theoretically, and comprehensive experiments on six benchmark datasets including various types show that the clustering performance of the DECRA is very competitive and significantly superior to the most advanced methods.},
  archive      = {J_NPL},
  author       = {Li, Mengli and Cao, Chao and Li, Chungui and Yang, Shuhong},
  doi          = {10.1007/s11063-024-11586-0},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep embedding clustering based on residual autoencoder},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robustness analysis of exponential stability of fuzzy
inertial neural networks through the estimation of upper limits of
perturbations. <em>NPL</em>, <em>56</em>(2), 1–25. (<a
href="https://doi.org/10.1007/s11063-024-11587-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper characterizes the robustness of exponential stability of fuzzy inertial neural network which contains time delays or stochastic disturbance through the estimation of upper limits of perturbations. By utilizing Gronwall-Bellman lemma, stochastic analysis, Cauchy inequality, the mean value theorem of integrals, as well as the properties of integrations, the limits of both time delays and stochastic disturbances are derived in this paper which can make the disturbed system keep exponential stability. The constraints between the two types of disturbances are provided in this paper. Examples are offered to validate our results.},
  archive      = {J_NPL},
  author       = {Fang, Wenxiang and Xie, Tao},
  doi          = {10.1007/s11063-024-11587-z},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-25},
  shortjournal = {Neural Process. Lett.},
  title        = {Robustness analysis of exponential stability of fuzzy inertial neural networks through the estimation of upper limits of perturbations},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new adaptive robust modularized semi-supervised community
detection method based on non-negative matrix factorization.
<em>NPL</em>, <em>56</em>(2), 1–30. (<a
href="https://doi.org/10.1007/s11063-024-11588-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most extensively used tools for categorizing complicated networks are community detection methods. One of the most common methods for unsupervised and semi-supervised clustering is community detection based on Non-negative Matrix Factorization (NMF). Nonetheless, this approach encounters multiple challenges, including the lack of specificity for the data type and the decreased efficiency when errors occur in each cluster’s knowledge priority. As modularity is the basic and thorough criterion for evaluating and validating performance of community detection methods, this paper proposes a new approach for modularity-based community detection which is similar to symmetric NMF. The provided approach is a semi-supervised adaptive robust community detection model referred to as modularized robust semi-supervised adaptive symmetric NMF (MRASNMF). In this model, the modularity criterion has been successfully combined with the NMF model via a novel multi-view clustering method. Also, the tuning parameter is adjusted iteratively via an adaptive method. MRASNMF makes use of knowledge priority, modularity criterion, reinforcement of non-negative matrix factorization, and has iterative solution, as well. In this regard, the MRASNMF model was evaluated and validated using five real-world networks in comparison to existing semi-supervised community detection approaches. According to the findings of this study, the proposed strategy is most effective for all types of networks.},
  archive      = {J_NPL},
  author       = {Ghadirian, Mohammad and Bigdeli, Nooshin},
  doi          = {10.1007/s11063-024-11588-y},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-30},
  shortjournal = {Neural Process. Lett.},
  title        = {A new adaptive robust modularized semi-supervised community detection method based on non-negative matrix factorization},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consensus affinity graph learning via structure graph fusion
and block diagonal representation for multiview clustering.
<em>NPL</em>, <em>56</em>(2), 1–28. (<a
href="https://doi.org/10.1007/s11063-024-11589-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a robust affinity graph is fundamental to graph-based clustering methods. However, some existing affinity graph learning methods have encountered the following problems. First, the constructed affinity graphs cannot capture the intrinsic structure of data well. Second, when fusing all view-specific affinity graphs, most of them obtain a fusion graph by simply taking the average of multiple views, or directly learning a common graph from multiple views, without considering the discriminative property among diverse views. Third, the fusion graph does not maintain an explicit cluster structure. To alleviate these problems, the adaptive neighbor graph learning approach and the data self-expression approach are first integrated into a structure graph fusion framework to obtain a view-specific structure affinity graph to capture the local and global structures of data. Then, all the structural affinity graphs are weighted dynamically into a consensus affinity graph, which not only effectively incorporates the complementary affinity structure of important views but also has the capability of preserving the consensus affinity structure that is shared by all views. Finally, a k–block diagonal regularizer is introduced for the consensus affinity graph to encourage it to have an explicit cluster structure. An efficient optimization algorithm is developed to tackle the resultant optimization problem. Extensive experiments on benchmark datasets validate the superiority of the proposed method.},
  archive      = {J_NPL},
  author       = {Gui, Zhongyan and Yang, Jing and Xie, Zhiqiang and Ye, Cuicui},
  doi          = {10.1007/s11063-024-11589-x},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-28},
  shortjournal = {Neural Process. Lett.},
  title        = {Consensus affinity graph learning via structure graph fusion and block diagonal representation for multiview clustering},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection and classification of brain tumor using
convolution extreme gradient boosting model and an enhanced salp swarm
optimization. <em>NPL</em>, <em>56</em>(2), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11590-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some types of tumors in people with brain cancer grow so rapidly that their average size doubles in twenty-five days. Precisely determining the type of tumor enables physicians to conduct clinical planning and estimate dosage. However, accurate classification remains a challenging task due to the variable shape, size, and location of the tumors.The major objective of this paper is to detect and classify brain tumors. This paper introduces an effective Convolution Extreme Gradient Boosting model based on enhanced Salp Swarm Optimization (CEXGB-ESSO) for detecting brain tumors, and their types. Initially, the MRI image is fed to bilateral filtering for the purpose of noise removal. Then, the de-noised image is fed to the CEXGB model, where Extreme Gradient Boosting (EXGB) is used, replacing a fully connected layer of CNN to detect and classify brain tumors. It consists of numerous stacked convolutional neural networks (CNN) for efficient automatic learning of features, which avoids overfitting and time-consuming processes. Then, the tumor type is predicted using the EXGB in the last layer, where there is no need to bring the weight values from the fully connected layer. Enhanced Salp Swarm Optimization (ESSO) is utilized to find the optimal hyperparameters of EXGB, which enhance convergence speed and accuracy. Our proposed CEXGB-ESSO model gives high performance in terms of accuracy (99), sensitivity (97.52), precision (98.2), and specificity (97.7).Also, the convergence analysis reveals the efficient optimization process of ESSO, obtaining optimal hyperparameter values around iteration 25. Furthermore, the classification results showcase the CEXGB-ESSO model’s capability to accurately detect and classify brain tumors.},
  archive      = {J_NPL},
  author       = {Jebastine, J.},
  doi          = {10.1007/s11063-024-11590-4},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Detection and classification of brain tumor using convolution extreme gradient boosting model and an enhanced salp swarm optimization},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multipath attention and adaptive gating network for video
action recognition. <em>NPL</em>, <em>56</em>(2), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11591-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D CNN networks can model existing large action recognition datasets well in temporal modeling and have made extremely great progress in the field of RGB-based video action recognition. However, the previous 3D CNN models also face many troubles. For video feature extraction convolutional kernels are often designed and fixed in each layer of the network, which may not be suitable for the diversity of data in action recognition tasks. In this paper, a new model called Multipath Attention and Adaptive Gating Network (MAAGN) is proposed. The core idea of MAAGN is to use the spatial difference module (SDM) and the multi-angle temporal attention module (MTAM) in parallel at each layer of the multipath network to obtain spatial and temporal features, respectively, and then dynamically fuses the spatial-temporal features by the adaptive gating module (AGM). SDM explores the action video spatial domain using difference operators based on the attention mechanism, while MTAM tends to explore the action video temporal domain in terms of both global timing and local timing. AGM is built on an adaptive gate unit, the value of which is determined by the input of each layer, and it is unique in each layer, dynamically fusing the spatial and temporal features in the paths of each layer in the multipath network. We construct the temporal network MAAGN, which has a competitive or better performance than state-of-the-art methods in video action recognition, and we provide exhaustive experiments on several large datasets to demonstrate the effectiveness of our approach.},
  archive      = {J_NPL},
  author       = {Zhang, Haiping and Hu, Zepeng and Yu, Dongjin and Guan, Liming and Liu, Xu and Ma, Conghao},
  doi          = {10.1007/s11063-024-11591-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Multipath attention and adaptive gating network for video action recognition},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-model UNet: An adversarial defense mechanism for
robust visual tracking. <em>NPL</em>, <em>56</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s11063-024-11592-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, state-of-the-art object-tracking algorithms are facing a severe threat from adversarial attacks, which can significantly undermine their performance. In this research, we introduce MUNet, a novel defensive model designed for visual tracking. This model is capable of generating defensive images that can effectively counter attacks while maintaining a low computational overhead. To achieve this, we experiment with various configurations of MUNet models, finding that even a minimal three-layer setup significantly improves tracking robustness when the target tracker is under attack. Each model undergoes end-to-end training on randomly paired images, which include both clean and adversarial noise images. This training separately utilizes pixel-wise denoiser and feature-wise defender. Our proposed models significantly enhance tracking performance even when the target tracker is attacked or the target frame is clean. Additionally, MUNet can simultaneously share its parameters on both template and search regions. In experimental results, the proposed models successfully defend against top attackers on six benchmark datasets, including OTB100, LaSOT, UAV123, VOT2018, VOT2019, and GOT-10k. Performance results on all datasets show a significant improvement over all attackers, with a decline of less than 4.6% for every benchmark metric compared to the original tracker. Notably, our model demonstrates the ability to enhance tracking robustness in other blackbox trackers.},
  archive      = {J_NPL},
  author       = {Suttapak, Wattanapong and Zhang, Jianfu and Zhao, Haohuo and Zhang, Liqing},
  doi          = {10.1007/s11063-024-11592-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-model UNet: An adversarial defense mechanism for robust visual tracking},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient bayesian CNN model compression using bayes by
backprop and l1-norm regularization. <em>NPL</em>, <em>56</em>(2), 1–19.
(<a href="https://doi.org/10.1007/s11063-024-11593-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swift advancement of convolutional neural networks (CNNs) in numerous real-world utilizations urges an elevation in computational cost along with the size of the model. In this context, many researchers steered their focus to eradicate these specific issues by compressing the original CNN models by pruning weights and filters, respectively. As filter pruning has an upper hand over the weight pruning method because filter pruning methods don’t impact sparse connectivity patterns. In this work, we suggested a Bayesian Convolutional Neural Network (BayesCNN) with Variational Inference, which prefaces probability distribution over weights. For the pruning task of Bayesian CNN, we utilized a combined version of L1-norm with capped L1-norm to help epitomize the amount of information that can be extracted through filter and control regularization. In this formation, we pruned unimportant filters directly without any test accuracy loss and achieved a slimmer model with comparative accuracy. The whole process of pruning is iterative and to validate the performance of our proposed work, we utilized several different CNN architectures on the standard classification dataset available. We have compared our results with non-Bayesian CNN models particularly, datasets such as CIFAR-10 on VGG-16, and pruned 75.8% parameters with float-point-operations (FLOPs) reduction of 51.3% without loss of accuracy and has achieved advancement in state-of-art.},
  archive      = {J_NPL},
  author       = {Shaikh, Ali Muhammad and Zhao, Yun-bo and Kumar, Aakash and Ali, Munawar and Kang, Yu},
  doi          = {10.1007/s11063-024-11593-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {Efficient bayesian CNN model compression using bayes by backprop and l1-norm regularization},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical patch aggregation transformer for motion
deblurring. <em>NPL</em>, <em>56</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11594-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The encoder-decoder framework based on Transformer components has become a paradigm in the field of image deblurring architecture design. In this paper, we critically revisit this approach and find that many current architectures severely focus on limited local regions during the feature extraction stage. These designs compromise the feature richness and diversity of the encoder-decoder framework, leading to bottlenecks in performance improvement. To address these deficiencies, a novel Hierarchical Patch Aggregation Transformer architecture (HPAT) is proposed. In the initial feature extraction stage, HPAT combines Axis-Selective Transformer Blocks with linear complexity and is supplemented by an adaptive hierarchical attention fusion mechanism. These mechanisms enable the model to effectively capture the spatial relationships between features and integrate features from different hierarchical levels. Then, we redesign the feedforward network of the Transformer block in the encoder-decoder structure and propose the Fused Feedforward Network. This effective aggregation enhances the ability to capture and retain local detailed features. We evaluate HPAT through extensive experiments and compare its performance with baseline methods on public datasets. Experimental results show that the proposed HPAT model achieves state-of-the-art performance in image deblurring tasks.},
  archive      = {J_NPL},
  author       = {Wu, Yujie and Liang, Lei and Ling, Siyao and Gao, Zhisheng},
  doi          = {10.1007/s11063-024-11594-0},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {Hierarchical patch aggregation transformer for motion deblurring},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DialGNN: Heterogeneous graph neural networks for dialogue
classification. <em>NPL</em>, <em>56</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s11063-024-11595-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue systems have attracted growing research interests due to its widespread applications in various domains. However, most research work focus on sentence-level intent recognition to interpret user utterances in dialogue systems, while the comprehension of the whole documents has not attracted sufficient attention. In this paper, we propose DialGNN, a heterogeneous graph neural network framework tailored for the problem of dialogue classification which takes the entire dialogue as input. Specifically, a heterogeneous graph is constructed with nodes in different levels of semantic granularity. The graph framework allows flexible integration of various pre-trained language representation models, such as BERT and its variants, which endows DialGNN with powerful text representational capabilities. DialGNN outperforms on CM and ECS datasets, which demonstrates robustness and the effectiveness. Specifically, our model achieves a notable enhancement in performance, optimizing the classification of document-level dialogue text. The implementation of DialGNN and related data are shared through https://github.com/821code/DialGNN .},
  archive      = {J_NPL},
  author       = {Yan, Yan and Zhang, Bo-Wen and Min, Peng-hao and Ding, Guan-wen and Liu, Jun-yuan},
  doi          = {10.1007/s11063-024-11595-z},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {DialGNN: Heterogeneous graph neural networks for dialogue classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep self-supervised attributed graph clustering for social
network analysis. <em>NPL</em>, <em>56</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s11063-024-11596-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep graph clustering is an unsupervised learning task that divides nodes in a graph into disjoint regions with the help of graph auto-encoders. Currently, such methods have several problems, as follows. (1) The deep graph clustering method does not effectively utilize the generated pseudo-labels, resulting in sub-optimal model training results. (2) Each cluster has a different confidence level, which affects the reliability of the pseudo-label. To address these problems, we propose a Deep Self-supervised Attribute Graph Clustering model (DSAGC) to fully leverage the information of the data itself. We divide the proposed model into two parts: an upstream model and a downstream model. In the upstream model, we use the pseudo-label information generated by spectral clustering to form a new high-confidence distribution with which to optimize the model for a higher performance. We also propose a new reliable sample selection mechanism to obtain more reliable samples for downstream tasks. In the downstream model, we only use the reliable samples and the pseudo-label for the semi-supervised classification task without the true label. We compare the proposed method with 17 related methods on four publicly available citation network datasets, and the proposed method generally outperforms most existing methods in three performance metrics. By conducting a large number of ablative experiments, we validate the effectiveness of the proposed method.},
  archive      = {J_NPL},
  author       = {Lu, Hu and Hong, Haotian and Geng, Xia},
  doi          = {10.1007/s11063-024-11596-y},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep self-supervised attributed graph clustering for social network analysis},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic spectral clustering with contrastive learning and
neighbor mining. <em>NPL</em>, <em>56</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s11063-024-11597-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep spectral clustering techniques are considered one of the most efficient clustering algorithms in data mining field. The similarity between instances and the disparity among classes are two critical factors in clustering fields. However, most current deep spectral clustering approaches do not sufficiently take them both into consideration. To tackle the above issue, we propose Semantic Spectral clustering with Contrastive learning and Neighbor mining (SSCN) framework, which performs instance-level pulling and cluster-level pushing cooperatively. Specifically, we obtain the semantic feature embedding using an unsupervised contrastive learning model. Next, we obtain the nearest neighbors partially and globally, and the neighbors along with data augmentation information enhance their effectiveness collaboratively on the instance level as well as the cluster level. The spectral constraint is applied by orthogonal layers to satisfy conventional spectral clustering. Extensive experiments demonstrate the superiority of our proposed frame of spectral clustering.},
  archive      = {J_NPL},
  author       = {Wang, Nongxiao and Ye, Xulun and Zhao, Jieyu and Wang, Qing},
  doi          = {10.1007/s11063-024-11597-x},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {Semantic spectral clustering with contrastive learning and neighbor mining},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning reliable dense pseudo-labels for point-level
weakly-supervised action localization. <em>NPL</em>, <em>56</em>(2),
1–15. (<a href="https://doi.org/10.1007/s11063-024-11598-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point-level weakly-supervised temporal action localization aims to accurately recognize and localize action segments in untrimmed videos, using only point-level annotations during training. Current methods primarily focus on mining sparse pseudo-labels and generating dense pseudo-labels. However, due to the sparsity of point-level labels and the impact of scene information on action representations, the reliability of dense pseudo-label methods still remains an issue. In this paper, we propose a point-level weakly-supervised temporal action localization method based on local representation enhancement and global temporal optimization. This method comprises two modules that enhance the representation capacity of action features and improve the reliability of class activation sequence classification, thereby enhancing the reliability of dense pseudo-labels and strengthening the model’s capability for completeness learning. Specifically, we first generate representative features of actions using pseudo-label feature and calculate weights based on the feature similarity between representative features of actions and segments features to adjust class activation sequence. Additionally, we maintain the fixed-length queues for annotated segments and design a action contrastive learning framework between videos. The experimental results demonstrate that our modules indeed enhance the model’s capability for comprehensive learning, particularly achieving state-of-the-art results at high IoU thresholds.},
  archive      = {J_NPL},
  author       = {Dang, Yuanjie and Zheng, Guozhu and Chen, Peng and Gao, Nan and Huan, Ruohong and Zhao, Dongdong and Liang, Ronghua},
  doi          = {10.1007/s11063-024-11598-w},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Neural Process. Lett.},
  title        = {Learning reliable dense pseudo-labels for point-level weakly-supervised action localization},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel GCN model using dense connection and attention
mechanism for text classification. <em>NPL</em>, <em>56</em>(2), 1–17.
(<a href="https://doi.org/10.1007/s11063-024-11599-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Network (CNN) or Recurrent Neural Network (RNN) based text classification algorithms currently in use can successfully extract local textual features but disregard global data. Due to its ability to understand complex text structures and maintain global information, Graph Neural Network (GNN) has demonstrated considerable promise in text classification. However, most of the GNN text classification models in use presently are typically shallow, unable to capture long-distance node information and reflect the various scale features of the text (such as words, phrases, etc.). All of which will negatively impact the performance of the final classification. A novel Graph Convolutional Neural Network (GCN) with dense connections and an attention mechanism for text classification is proposed to address these constraints. By increasing the depth of GCN, the densely connected graph convolutional network (DC-GCN) gathers information about distant nodes. The DC-GCN multiplexes the small-scale features of shallow layers and produces different scale features through dense connections. To combine features and determine their relative importance, an attention mechanism is finally added. Experiment results on four benchmark datasets demonstrate that our model’s classification accuracy greatly outpaces that of the conventional deep learning text classification model. Our model performs exceptionally well when compared to other text categorization GCN algorithms.},
  archive      = {J_NPL},
  author       = {Peng, Yinbin and Wu, Wei and Ren, Jiansi and Yu, Xiang},
  doi          = {10.1007/s11063-024-11599-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Novel GCN model using dense connection and attention mechanism for text classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Brain tumor segmentation using deep
learning and fuzzy k-means clustering for magnetic resonance images.
<em>NPL</em>, <em>56</em>(2), 1–2. (<a
href="https://doi.org/10.1007/s11063-024-11601-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Pitchai, R. and Supraja, P. and Victoria, A. Helen and Madhavi, M.},
  doi          = {10.1007/s11063-024-11601-4},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-2},
  shortjournal = {Neural Process. Lett.},
  title        = {Retraction note: Brain tumor segmentation using deep learning and fuzzy K-means clustering for magnetic resonance images},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Intelligent crime prevention and control
big data analysis system based on imaging and capsule network model.
<em>NPL</em>, <em>56</em>(2), 1. (<a
href="https://doi.org/10.1007/s11063-024-11602-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Cai, Yijun and Li, Dian and Wang, Yuyue},
  doi          = {10.1007/s11063-024-11602-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1},
  shortjournal = {Neural Process. Lett.},
  title        = {Retraction note: Intelligent crime prevention and control big data analysis system based on imaging and capsule network model},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A city monitoring system based on real-time
communication interaction module and intelligent visual information
collection system. <em>NPL</em>, <em>56</em>(2), 1–2. (<a
href="https://doi.org/10.1007/s11063-024-11603-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Li, Daming and Qin, Bin and Liu, Wenjian and Deng, Lianbing},
  doi          = {10.1007/s11063-024-11603-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-2},
  shortjournal = {Neural Process. Lett.},
  title        = {Retraction note: A city monitoring system based on real-time communication interaction module and intelligent visual information collection system},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Burn image recognition of medical images
based on deep learning: From CNNs to advanced networks. <em>NPL</em>,
<em>56</em>(2), 1–2. (<a
href="https://doi.org/10.1007/s11063-024-11604-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Wu, Xianjun and Chen, Heming and Wu, Xiaoli and Wu, Shunjun and Huang, Jinbo},
  doi          = {10.1007/s11063-024-11604-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-2},
  shortjournal = {Neural Process. Lett.},
  title        = {Retraction note: burn image recognition of medical images based on deep learning: from CNNs to advanced networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Application of meta-learning framework
based on multiple-capsule intelligent neural systems in image
classification. <em>NPL</em>, <em>56</em>(2), 1. (<a
href="https://doi.org/10.1007/s11063-024-11608-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Wang, Qingjun and Wang, Gang and Kou, Guangjie and Zang, Mujun and Wang, Harry},
  doi          = {10.1007/s11063-024-11608-x},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1},
  shortjournal = {Neural Process. Lett.},
  title        = {Retraction note: Application of meta-learning framework based on multiple-capsule intelligent neural systems in image classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LeCaSiM: Learning causal structure via inverse of m-matrices
with adjustable coefficients. <em>NPL</em>, <em>56</em>(1), 1–26. (<a
href="https://doi.org/10.1007/s11063-024-11436-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of causal discovery is to uncover the causal relationships among natural phenomena or human behaviors, thus establishing the basis for subsequent prediction and inference. Traditional ways to reveal the causal structure between variables, such as interventions or random trials, are often deemed costly or impractical. With the diversity of means of data acquisition and abundant data, approaches that directly learn causal structure from observational data are attracting more interest in academia. Unfortunately, learning a directed acyclic graph (DAG) from samples of multiple variables has been proven to be a challenging problem. Recent proposals leverage the continuous optimization method to discover the structure of the target DAG from observational data using an acyclic constraint function. Although it has an elegant mathematical form, its optimization process is prone to numerical explosion or the disappearance of high-order gradients of constraint conditions, making the convergence conditions unstable and the result deviating from the true structure. To tackle these issues, we first combine the existing work to give a series of algebraic equivalent conditions for a DAG and its corresponding brief proofs, then leverage the properties of the M-matrix to derive a new acyclic constraint function. Based on the utilization of this function and linear structural equation models, we propose a novel causal discovery algorithm called LeCaSiM, which employs continuous optimization. Our algorithm exploits the spectral radius of the adjacency matrix to dynamically adjust the coefficients of the matrix polynomial, effectively solving the above problems. We conduct extensive experiments on both synthetic and real-world datasets, the results show our algorithm outperforms the existing algorithms on both computation time and accuracy under the same settings.},
  archive      = {J_NPL},
  author       = {Cai, Qingsong and Zhang, Yongchang},
  doi          = {10.1007/s11063-024-11436-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Neural Process. Lett.},
  title        = {LeCaSiM: Learning causal structure via inverse of M-matrices with adjustable coefficients},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robust sequential recommendation model based on multiple
feedback behavior denoising and trusted neighbors. <em>NPL</em>,
<em>56</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11438-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, most of the personalized sequential recommendations utilize users’ implicit positive feedback (such as clicks) to predict user behavior, ignoring the impact of implicit negative feedback and explicit feedback on the accuracy of recommendation results prediction. In this paper, we propose a robust sequence recommendation model based on multi feedback behavior denoising and trusted neighbors, which utilizes multiple feedback behavior data for feature denoising and considers trusted nearest neighbor information to improve model performance. Firstly, by learning the feature representations and interactions of various types of feedback, explicit feedback is used to map and purify implicit feedback with the same and different attributes, resulting in unbiased user performance. Then, we design a filter attention network to identify highly trusted neighbor information. Finally, we integrate pure user interest representations and trusted nearest neighbor representations to improve the accuracy and robustness of the model. The experimental results on two publicly available datasets show that the proposed sequential recommendation model can achieve superior results to baseline methods in both AUC and RelaImpr.},
  archive      = {J_NPL},
  author       = {Cai, Hongyun and Meng, Jie and Yuan, Shilin and Ren, Jichao},
  doi          = {10.1007/s11063-024-11438-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {A robust sequential recommendation model based on multiple feedback behavior denoising and trusted neighbors},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced extreme learning machine based on square-root
lasso method. <em>NPL</em>, <em>56</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11443-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme learning machine (ELM) is one of the most notable machine learning algorithms with many advantages, especially its training speed. However, ELM has some drawbacks such as instability, poor generalizability and overfitting in the case of multicollinearity in the linear model. This paper introduces square-root lasso ELM (SQRTL-ELM) as a novel regularized ELM algorithm to deal with these drawbacks of ELM. A modified version of the alternating minimization algorithm is used to obtain the estimates of the proposed method. Various techniques are presented to determine the tuning parameter of SQRTL-ELM. The method is compared with the basic ELM, RIDGE-ELM, LASSO-ELM and ENET-ELM on six benchmark data sets. Performance evaluation results show that the SQRTL-ELM exhibits satisfactory performance in terms of testing root mean squared error in benchmark data sets for the sake of slightly extra computation time. The superiority level of the method depends on the tuning parameter selection technique. As a result, the proposed method can be considered a powerful alternative to avoid performance loss in regression problems .},
  archive      = {J_NPL},
  author       = {Genç, Murat},
  doi          = {10.1007/s11063-024-11443-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {An enhanced extreme learning machine based on square-root lasso method},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large-scale clustering on 100 m-scale datasets using a
single t4 GPU via recall KNN and subgraph segmentation. <em>NPL</em>,
<em>56</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s11063-024-11444-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the promising progress that has been made, large-scale clustering tasks still face various challenges: (i) high time and space complexity in K-nearest neighbors (KNN), which is often overlooked by most methods, and (ii) low recall rate caused by simply splitting the dataset. In this paper, we propose a novel framework for large-scale clustering tasks named large-scale clustering via recall KNN and subgraph segmentation (LS-RKSS) to perform faster clustering with guaranteed clustering performance, which embraces the ability of handling large-scale data up to 100 million using a single T4 GPU with less than 10% of the running time. We propose recall KNN (RKNN) and subgraph segmentation (SS) to effectively address the primary challenges in large-scale clustering tasks. Firstly, the recall KNN is proposed to perform efficient similarity search among dense vectors with lower time and space complexity compared to traditional exact search methods of KNN. Then, the subgraph segmentation is proposed to split the whole dataset into multiple subgraphs based on the recall KNN. Given the recall rate of RKNN based on traditional exact search methods, it is theoretically proved that dividing the dataset into multiple subgraphs using recall KNN and subgraph segmentation is a more reasonable and effective approach. Finally, clusters are generated independently on each subgraph, and the final clustering result is obtained by combining the results of all subgraphs. Extensive experiments demonstrate that LS-RKSS outperforms previous large-scale clustering methods in both effectiveness and efficiency.},
  archive      = {J_NPL},
  author       = {Liu, Junjie and Jiang, Rongxin and Liu, Xuesong and Zhou, Fan and Chen, Yaowu and Shen, Chen},
  doi          = {10.1007/s11063-024-11444-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {Large-scale clustering on 100 M-scale datasets using a single t4 GPU via recall KNN and subgraph segmentation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Merging of neural networks. <em>NPL</em>, <em>56</em>(1),
1–13. (<a href="https://doi.org/10.1007/s11063-024-11445-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a simple scheme for merging two neural networks trained with different starting initialization into a single one with the same size as the original ones. We do this by carefully selecting channels from each input network. Our procedure might be used as a finalization step after one tries multiple starting seeds to avoid an unlucky one. We also show that training two networks and merging them leads to better performance than training a single network for an extended period of time.},
  archive      = {J_NPL},
  author       = {Pašen, Martin and Boža, Vladimír},
  doi          = {10.1007/s11063-024-11445-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Neural Process. Lett.},
  title        = {Merging of neural networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid prompt recommendation explanation generation combined
with graph encoder. <em>NPL</em>, <em>56</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s11063-024-11446-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems have been effectively utilized in various fields, but their internal decision-making methods are still largely unknown. This opaque decision-making method can greatly affect users’ trust in the recommendation system. Therefore, finding a way to explain the reasons for model decisions has become an urgent task. Previous studies often used LSTM and other models to generate recommendation explanations and explain the reasons for recommendations in text form. However, traditional methods cannot effectively use the ID information of users and items, and the text generated is highly repetitive. To solve this problem, this paper uses the method of prompt learning combined with a graph encoder to design a recommendation explanation generation model. In order to narrow the semantic gap between the ID information of users and items and natural language and capture high-level interaction information, this paper designs a graph encoder based on user similarity to learn the interactive semantic information of user and item IDs, and to construct a continuous prompt. Then, the discrete prompt composed of discrete features of users and items is combined with the continuous prompt to construct a hybrid prompt to input into the pre-trained model to generate the recommended explanation. This paper experiments on three publicly available datasets and compares them with several state-of-the-art methods to demonstrate the personalization and text quality of the generated explanations.},
  archive      = {J_NPL},
  author       = {Wang, Tianhao and Wu, Sheng and Yi, Fen and Kuang, Lidan and Wang, You and Zhang, Jin},
  doi          = {10.1007/s11063-024-11446-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Neural Process. Lett.},
  title        = {Hybrid prompt recommendation explanation generation combined with graph encoder},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving 3D object detection with context-aware and
dimensional interaction attention. <em>NPL</em>, <em>56</em>(1), 1–24.
(<a href="https://doi.org/10.1007/s11063-024-11447-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, 3D object detection technology based on point clouds has developed rapidly. However, too few points of distant and occluded objects are scanned by the sensor, and thus these objects suffer from too insufficient features to be detected. This case damages the detection accuracy. Therefore, we constitute a novel 3D object detection with Context-aware and dimensional Interaction Attention Network (CIANet) to explore vital geometric cues for enriching the feature representation of the object, thus boosting the overall detection performance. Specifically, in the first stage, we employ the 3D sparse convolution to extract voxel features, and then construct a Channel-Spatial Hybrid Attention (CSHA) module and a Contextual Self-Attention (CSA) module to enhance voxel features for generating proposals. The CSHA module aims to enhance the key information of the channel and spatial domains of 2D Bird’s Eye View (BEV) features, and the CSA module is applied to supplement contextual information to the enhanced BEV features, thus generating accurate proposals. In the second stage, we construct a Dimensional Interaction Attention (DIA) module to refine Region of Interest (RoI) features within the proposals. It enhances the interactions among the channel and spatial dimensions of RoI features to learn accurate boundaries of objects for proposal refinement. Extensive experiments on the KITTI and Waymo benchmarks show the superior detection performance of CIANet compared to recent methods, especially for objects such as pedestrians and cyclists.},
  archive      = {J_NPL},
  author       = {Zhou, Jing and Gong, Zixin and Zhang, Junchi},
  doi          = {10.1007/s11063-024-11447-w},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Neural Process. Lett.},
  title        = {Improving 3D object detection with context-aware and dimensional interaction attention},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simplified multi-head mechanism for few-shot remote sensing
image classification. <em>NPL</em>, <em>56</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s11063-024-11451-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of few-shot remote sensing image classification has received significant attention. Although meta-learning-based algorithms have been the primary focus of recent examination, feature fusion methods stress feature extraction and representation. Nonetheless, current feature fusion methods, like the multi-head mechanism, are restricted by their complicated network structure and challenging training process. This manuscript presents a simplified multi-head mechanism for obtaining multiple feature representations from a single sample. Furthermore, we perform specific fundamental transformations on remote-sensing images to obtain more suitable features for information representation. Specifically, we reduce multiple feature extractors of the multi-head mechanism to a single one and add an image transformation module before the feature extractor. After transforming the image, the features are extracted resulting in multiple features for each sample. The feature fusion stage is integrated with the classification prediction stage, and multiple linear classifiers are combined for multi-decision fusion to complete feature fusion and classification. By combining image transformation with feature decision fusion, we compare our results with other methods through validation tests and demonstrate that our algorithm simplifies the multi-head mechanism while maintaining or improving classification performance.},
  archive      = {J_NPL},
  author       = {Qiao, Xujian and Xing, Lei and Han, Anxun and Liu, Weifeng and Liu, Baodi},
  doi          = {10.1007/s11063-024-11451-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Neural Process. Lett.},
  title        = {Simplified multi-head mechanism for few-shot remote sensing image classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SR-MACL: Session-based recommendation with multi-layer
aggregation augmentation in contrastive learning. <em>NPL</em>,
<em>56</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11452-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation (SBR) aims to predict the next item of interest in chronological order based on a given sequence of short-term behaviour of anonymous users. Due to the limited data available for short-term user interactions, its performance is more susceptible to data sparsity problems than traditional recommendation methods. Contrastive learning is often used to solve the data sparsity problem due to its ability to extract general features from the raw data. Existing session-based recommendation methods based on graph contrastive learning typically build graph contrastive learning by using information from other sessions to generate augmented views. While this avoids the problem that the use of dropout in traditional contrast learning methods can cause damage to the session context, it inevitably introduces irrelevant item information, which interferes with accurately modelling user interests and leads to sub-optimal model performance. To address these issues, we propose a new session recommendation method based on multi-layer aggregation augmentation contrastive learning, namely SR-MACL. In SR-MACL we construct a contrastive view by adding noise to the embedding representation and forming a contrastive embedding representation by multi-layer aggregation, which not only effectively solves the problem that traditional graph enhancement methods can destroy the context of the whole session, but also avoids the interference of irrelevant items. Experimental results on three real datasets have shown that SR-MACL can improve the accuracy of recommendation results and predict the user&#39;s next interaction more effectively.},
  archive      = {J_NPL},
  author       = {Gao, Shiwei and Zeng, Yufeng and Dang, Xiaochao and Dong, Xiaohui},
  doi          = {10.1007/s11063-024-11452-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {SR-MACL: Session-based recommendation with multi-layer aggregation augmentation in contrastive learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep convolutional encoder–decoder–restorer architecture
for image deblurring. <em>NPL</em>, <em>56</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11455-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of many computer vision tasks is reduced by blurred images, so deblur is important. More details of the image can be captured by a common multi-stage network, but the computational complexity of this method is higher compared with a single-stage network. However, a single-stage network cannot capture multi-scale information well. To tackle the problem, a novel convolutional encoder–decoder–restorer architecture is proposed. In this architecture, a multi-scale input structure is used in the encoder. Improved supervised attention module is inserted into the encoder for enhanced feature acquisition. In decoder, information supplement block is proposed to fuse multi-scale features. Finally, the fused features are used for image recovery in the restorer. In order to optimise the model in multiple domains, the loss function is calculated separately in the spatial and frequency domains. Our method is compared with existing methods on the GOPRO dataset. In addition, to verify the applications of our proposed method, we conduct experiments on the Real image dataset, the VOC2007 dataset and the LFW dataset. Experimental results show that our proposed method outperforms state-of-the-art deblurring methods and improves the accuracy of different vision tasks.},
  archive      = {J_NPL},
  author       = {Fan, Yiqing and Hong, Chaoqun and Zeng, Guanghui and Liu, Lijuan},
  doi          = {10.1007/s11063-024-11455-w},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {A deep convolutional Encoder–Decoder–Restorer architecture for image deblurring},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Information-minimizing generative adversarial network for
fair generation and classification. <em>NPL</em>, <em>56</em>(1), 1–24.
(<a href="https://doi.org/10.1007/s11063-024-11457-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies show that machine learning models trained from biased data can discriminate against groups with certain sensitive attributes. This problem can be mitigated by cleaning the original data or learning fair representations. However, collecting real data in real-life is extremely time and resource-consuming, whereas generative models (e.g., GANs) can create new data that enable more application scenarios. Therefore, utilizing fair data generated by generative models can benefit various downstream tasks. In this paper, we propose a information-minimizing generative adversarial network to improve the fairness of machine learning by generating fair data. An ANOVA-based latent factor is constructed in the input for reducing the accuracy loss, and the joint adversarial training between the generator and classifier can better solve the indirect discrimination and achieve fair classification. Extensive experiments on various environments show the effectiveness of the proposed method.},
  archive      = {J_NPL},
  author       = {Chen, Qiuling and Ye, Ayong and Zhang, Yuexin and Chen, Jianwei and Huang, Chuan},
  doi          = {10.1007/s11063-024-11457-8},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Neural Process. Lett.},
  title        = {Information-minimizing generative adversarial network for fair generation and classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing semi supervised semantic segmentation through
cycle-consistent label propagation in video. <em>NPL</em>,
<em>56</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s11063-024-11459-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To perform semantic image segmentation using deep learning models, a significant quantity of data and meticulous manual annotation is necessary (Mani in: Research anthology on improving medical imaging techniques for analysis and intervention. IGI Global, pp. 107–125, 2023), and the process consumes a lot of resources, including time and money. To resolve such issues, we introduce a unique label propagation method (Qin et al. in IEEE/CAA J Autom Sinica 10(5):1192–1208, 2023) that utilizes cycle consistency across time to propagate labels over longer time horizons with higher accuracy. Additionally, we acknowledge that dense pixel annotation is a noisy process (Das et al. in: Proceedings of the IEEE/CVF winter conference on applications of computer vision, pp. 5978–5987, 2023), whether performed manually or automatically. To address this, we present a principled approach that accounts for label uncertainty when training with labels from multiple noisy labeling processes. We introduce two new approaches; Warp-Refine Propagation and Uncertainty-Aware Training, for improving label propagation and handling noisy labels, respectively, and support the process with quantitative and qualitative evaluations and theoretical justification. Our contributions are validated on the Cityscapes and ApolloScape datasets, where we achieve encouraging results. In later endeavors, the aim should be to expand such approaches to include other noisy augmentation processes like image-based rendering methods (Laraqui et al. in Int J Comput Aid Eng Technol 18(5):141–151, 2023), thanks to the noisy label learning approach.},
  archive      = {J_NPL},
  author       = {Addanki, Veerababu and Yerramreddy, Dhanvanth Reddy and Durgapu, Sathvik and Boddu, Sasi Sai Nadh and Durgapu, Vyshnav},
  doi          = {10.1007/s11063-024-11459-6},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Enhancing semi supervised semantic segmentation through cycle-consistent label propagation in video},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TLC-XML: Transformer with label correlation for extreme
multi-label text classification. <em>NPL</em>, <em>56</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s11063-024-11460-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme multi-label text classification (XMTC) annotates related labels for unknown text from large-scale label sets. Transformer-based methods have become the dominant approach for solving the XMTC task due to their effective text representation capabilities. However, the existing Transformer-based methods fail to effectively exploit the correlation between labels in the XMTC task. To address this shortcoming, we propose a novel model called TLC-XML, i.e., a Transformer with label correlation for extreme multi-label text classification. TLC-XML comprises three modules: Partition, Matcher and Ranker. In the Partition module, we exploit the semantic and co-occurrence information of labels to construct the label correlation graph, and further partition the strongly correlated labels into the same cluster. In the Matcher module, we propose cluster correlation learning, which uses the graph convolutional network (GCN) to extract the correlation between clusters. We then introduce these valuable correlations into the classifier to match related clusters. In the Ranker module, we propose label interaction learning, which aggregates the raw label prediction with the information of the neighboring labels. The experimental results on benchmark datasets show that TLC-XML significantly outperforms state-of-the-art XMTC methods.},
  archive      = {J_NPL},
  author       = {Zhao, Fei and Ai, Qing and Li, Xiangna and Wang, Wenhui and Gao, Qingyun and Liu, Yichun},
  doi          = {10.1007/s11063-024-11460-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {TLC-XML: Transformer with label correlation for extreme multi-label text classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-strategy enhanced arithmetic optimization algorithm
and its application in path planning of mobile robots. <em>NPL</em>,
<em>56</em>(1), 1–51. (<a
href="https://doi.org/10.1007/s11063-024-11467-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-strategy enhanced arithmetic optimization algorithm called MSEAOA is proposed to address the issues of low population diversity, imbalanced exploration and exploitation capabilities, and low accuracy of optimal solution in the Arithmetic Optimization Algorithm. Firstly, using the good point set strategy for population initialization to improve population diversity and thus accelerate convergence speed. Secondly, we integrate the exploration and exploition capabilities of differential self-learning strategy, best example learning strategy, and second-order differential perturbation strategy balancing algorithm. Finally, the introduction of somersault foraging strategy improves the accuracy of the optimal solution. We select 14 classical benchmark test functions and the CEC2019 function test set to test the optimization ability of MSEAOA, and apply MSEAOA to the path planning problem of mobile robots. MSEAOA is compared with other meta-heuristic optimization algorithms, and the experimental results are statistically analyzed by the Wilcoxon rank-sum test. The simulation experimental results show that MSEAOA performs the best among 14 benchmark functions, but for 10 CEC2019 functions, MSEAOA has the best optimization performance among 5 of them (50%). In the path optimization problem of mobile robots, the path obtained by MSEAOA is also the best among all algorithms, its path shortening rate exceeds 8.8% in 83% of environments. The results indicate that MSEAOA is a reliable algorithm suitable for function optimization and practical optimization problems.},
  archive      = {J_NPL},
  author       = {Deng, Xuzhen and He, Dengxu and Qu, Liangdong},
  doi          = {10.1007/s11063-024-11467-6},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-51},
  shortjournal = {Neural Process. Lett.},
  title        = {A multi-strategy enhanced arithmetic optimization algorithm and its application in path planning of mobile robots},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predefined-time stability-based zeroing neural networks and
their application in solving the lyapunov equation. <em>NPL</em>,
<em>56</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s11063-024-11470-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lyapunov equation is extensively applied in engineering areas, and zeroing neural networks (ZNN) are very effective in solving this kind of equation. In this paper, two predefined-time stability theorems are used to devise new activation functions. Then, we obtain two new ZNN models, which are applied in solving the Lyapunov equation. This type of model is called the predefined-time stability-based zeroing neural network model. Compared with the ZNN models which have existed, the proposed model retains the noise-tolerant virtue and gains a new advantage: predefined-time convergence. Lastly, we verify that the model developed in this paper is superior to the known models in solving the time-variant Lyapunov equation via numerical simulations.},
  archive      = {J_NPL},
  author       = {Yue, Yuanda and Mi, Ling and Chen, Chuan and Yang, Yanqing},
  doi          = {10.1007/s11063-024-11470-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Neural Process. Lett.},
  title        = {Predefined-time stability-based zeroing neural networks and their application in solving the lyapunov equation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A vision enhancement and feature fusion multiscale detection
network. <em>NPL</em>, <em>56</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s11063-024-11471-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of object detection, there is often a high level of occlusion in real scenes, which can very easily interfere with the accuracy of the detector. Currently, most detectors use a convolutional neural network (CNN) as a backbone network, but the robustness of CNNs for detection under cover is poor, and the absence of object pixels makes conventional convolution ineffective in extracting features, leading to a decrease in detection accuracy. To address these two problems, we propose VFN (A Vision Enhancement and Feature Fusion Multiscale Detection Network), which first builds a multiscale backbone network using different stages of the Swin Transformer, and then utilizes a vision enhancement module using dilated convolution to enhance the vision of feature points at different scales and address the problem of missing pixels. Finally, the feature guidance module enables features at each scale to be enhanced by fusing with each other. The total accuracy demonstrated by VFN on both the PASCAL VOC dataset and the CrowdHuman dataset is better than that of other methods, and its ability to find occluded objects is also better, demonstrating the effectiveness of our method.The code is available at https://github.com/qcw666/vfn .},
  archive      = {J_NPL},
  author       = {Qian, Chengwu and Qian, Jiangbo and Wang, Chong and Ye, Xulun and Zhong, Caiming},
  doi          = {10.1007/s11063-024-11471-w},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {A vision enhancement and feature fusion multiscale detection network},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Besicovitch almost anti-periodic solution of octonion-valued
cohen–grossberg neural networks with delays on time scales.
<em>NPL</em>, <em>56</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11472-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we put forward a concept of Besicovitch almost anti-periodic functions on time scales, which is new even when time scale $$\mathbb {T}=\mathbb {R}$$ or $$\mathbb {Z}$$ . Based on this, we use the fixed point theorem and analytical techniques to obtain the existence, uniqueness and global exponential stability of Besicovitch almost anti-periodic solutions for a class of octonion-valued Cohen–Grossberg neural networks with time delays on time scales. Finally, the validity of the results is verified by a numerical example.},
  archive      = {J_NPL},
  author       = {Li, Yongkun and Qi, Weiwei},
  doi          = {10.1007/s11063-024-11472-9},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Besicovitch almost anti-periodic solution of octonion-valued Cohen–Grossberg neural networks with delays on time scales},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time series prediction of ESN based on chebyshev mapping and
strongly connected topology. <em>NPL</em>, <em>56</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11474-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel approach called Chebyshev mapping and strongly connected topology for optimization of echo state network (ESN). To enhance the predictive performance of ESNs for time series data, Chebyshev mapping is employed to optimize the irregular input weight matrix. And the reservoir of the ESN is also replaced using an adjacency matrix derived from a digital chaotic system, resulting in a reservoir with strong connectivity properties. Numerical experiments are conducted on various time series datasets, including the Mackey–Glass time series, Lorenz time series and solar sunspot numbers, validating the effectiveness of the proposed optimization methods. Compared with the traditional ESNs, the optimization method proposed in this paper has higher predictive performance, and effectively reduce the reservoir’s size and model complexity.},
  archive      = {J_NPL},
  author       = {Xie, Minzhi and Wang, Qianxue and Yu, Simin},
  doi          = {10.1007/s11063-024-11474-7},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {Time series prediction of ESN based on chebyshev mapping and strongly connected topology},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BIKAGCN: Knowledge-aware recommendations under bi-layer
graph convolutional networks. <em>NPL</em>, <em>56</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s11063-024-11475-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are a popular solution for the problem of information overload, offering personalized recommendations to users. Recent years, research has aimed to enhance recommender systems by employing knowledge graphs in conjunction with Graph convolutional network (GCN) to extract user and item features. Although GCN possess a great potential, they are still far from reaching their full capability in recommender systems. This paper introduces a novel approach—knowledge-aware recommendations under bi-layer graph convolutional networks (BIKAGCN) that combines attention and bi-layer GCNs to improve performance. The first layer of the BIKAGCN model trains embedding representations of users and items based on user-item interaction graphs. The second layer introduces a novel knowledge-aware layer of attention and graph convolutional network (KAGCN) layer that leverages both the first layer’s user-item embeddings and item knowledge graph embeddings. Experimental results on three publicly available datasets (MovieLens-20M, Last-FM, and Book-Crossing) demonstrate that BIKAGCN leads to significant performance improvements in recall@20 metric (14.41%, 8.86%, and 20.90%, respectively) compared to currently available state-of-the-art approaches. Moreover, the model maintains satisfactory performance in cold-start cases.The research provides some guidance for the direction of subsequent research on recommender systems.},
  archive      = {J_NPL},
  author       = {Li, Guoshu and Yang, Li and Bai, Sichang and Song, Xinyu and Ren, Yijun and Liu, Shanqiang},
  doi          = {10.1007/s11063-024-11475-6},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {BIKAGCN: Knowledge-aware recommendations under bi-layer graph convolutional networks},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gated fusion adaptive graph neural network for urban road
traffic flow prediction. <em>NPL</em>, <em>56</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s11063-024-11479-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of traffic flow plays an important role in maintaining traffic order and traffic safety, which is a key task in the application of intelligent transportation systems (ITS). However, the urban road network has complex dynamic spatial correlation and nonlinear temporal correlation, and achieving accurate traffic flow prediction is a highly challenging task. Traditional methods use sensors deployed on roads to construct the spatial structure of the road network and capture spatial information by graph convolution. However, they ignore that the spatial correlation between nodes is dynamically changing, and using a fixed adjacency matrix cannot reflect the real road spatial structure. To overcome these limitations, this paper proposes a new spatial-temporal deep learning model: gated fusion adaptive graph neural network (GFAGNN). GFAGNN first extracts long-term dependencies on raw data through stacking expansion causal convolution, Then the spatial features of the dynamics are learned by adaptive graph attention network and adaptive graph convolutional network respectively, Finally the fused information is passed through a lightweight channel attention to extract temporal features. The experimental results on two public data sets show that our model can effectively capture the spatiotemporal correlation in traffic flow prediction. Compared with GWNET-conv model on METR-LA dataset, the three indexes in the 60-minute task prediction improved by 2.27%,2.06% and 2.13%, respectively.},
  archive      = {J_NPL},
  author       = {Xiong, Liyan and Yuan, Xinhua and Hu, Zhuyi and Huang, Xiaohui and Huang, Peng},
  doi          = {10.1007/s11063-024-11479-2},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {Gated fusion adaptive graph neural network for urban road traffic flow prediction},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge graph embedding via triplet component
interactions. <em>NPL</em>, <em>56</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11481-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In knowledge graph embedding, multidimensional representations of entities and relations are learned in vector space. Although distance-based graph embedding methods have shown promise in link prediction, they neglect context information among the triplet components, i.e., the head_entity, relation, and tail_entity, limiting their ability to describe multivariate relation patterns and mapping properties. Such context information denotes the entity structural association inside the same triplet and implies the correlation between entities that are not directly connected. In this work, we propose a novel knowledge graph embedding model that explicitly considers context information in graph embedding via triplet component interactions (TCIE). To build connections between components and incorporate contextual information, entities and relations are represented as vectors comprised of two specialized parts, enabling comprehensive interaction. By simultaneously interacting with one-hop related head and tail entities, TCIE strengthens the connections between distant entities and enables contextual information to be transmitted across the knowledge graph. Mathematical proofs and experiments are performed to analyse the modelling ability of TCIE in knowledge graph embedding. TCIE shows a strong capacity for modelling four relation patterns (i.e., symmetry, antisymmetry, inverse, and composition) and four mapping properties (i.e., one-to-one, one-to-many, many-to-one, and many-to-many). The experimental evaluation of ogbl-wikikg2, ogbl-biokg, FB15k, and FB15k-237 shows that TCIE achieves state-of-the-art results in link prediction.},
  archive      = {J_NPL},
  author       = {Wang, Tao and Shen, Bo and Zhang, Jinglin and Zhong, Yu},
  doi          = {10.1007/s11063-024-11481-8},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {Knowledge graph embedding via triplet component interactions},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spectro temporal fusion with CLSTM-autoencoder based
approach for anomalous sound detection. <em>NPL</em>, <em>56</em>(1),
1–11. (<a href="https://doi.org/10.1007/s11063-024-11485-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are proved efficient for complex learning tasks. Anomalous sound detection is one such complex task for which self-supervised deep architectures are emerging in recent days. Self-supervised deep models efficiently capture the underlying structure of data. Self-supervised anomalous sound detection attempts to distinguish between normal sounds and unidentified anomalous sounds. With the use of appropriate autoencoders, reconstruction error based decision making is effective for anomaly detection in domains such as computer vision. Auditory image (Spectrogram) based representation of sound signals are commonly used in sound event detection. We propose convolutional long short-term memory (CLSTM) Auto Encoder based approach for anomalous sound detection. In this approach, we explore fusion of spectral and temporal features to model characteristics of normal sounds with noises. The proposed approach is evaluated using MIMII dataset and the DCASE Challenge (2020) Task 2—Anomalous sound detection dataset. Experiments on proposed approach reveal significant improvement over the state-of-the-art approaches.},
  archive      = {J_NPL},
  author       = {Chandrakala, S. and Pidikiti, Akhilandeswari and Sai Mahathi, P. V. N.},
  doi          = {10.1007/s11063-024-11485-4},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Neural Process. Lett.},
  title        = {Spectro temporal fusion with CLSTM-autoencoder based approach for anomalous sound detection},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image contour detection based on visual pathway information
transfer mechanism. <em>NPL</em>, <em>56</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s11063-024-11486-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the coding mechanism and interactive features of visual information in the visual pathway, a new method of image contour detection is proposed. Firstly, simulating the visual adaptation characteristics of retinal ganglion cells, an adaptation &amp; sensitization regulation model (ASR) based on the adaptation-sensitization characteristics is proposed, which introduces a sinusoidal function curve modulated by amplitude, frequency and initial phase to dynamically adjusted color channel response information and enhance the response of color edges. Secondly, the color antagonism characteristic is introduced to process the color edge responses, and the obtained primary contour responses is fed forward to the dorsal pathway across regions. Then, the coding characteristics of the “angle” information in the V2 region are simulated, and a double receptive fields model (DRFM) is constructed to compensate for the missing detailed contours in the generation of primary contour responses. Finally, a new double stream information fusion model (DSIF) is proposed, which simulates the dorsal overall contour information flow by the across-region response weighted fusion mechanism, and introduces the multi-directional fretting to simulate the fine-tuning characteristics of ventral detail features simultaneously, extracting the significant contours by weighted fusion of dorsal and ventral information streams. In this paper, the natural images in BSDS500 and NYUD datasets are used as experimental data, and the average optimal F-score of the proposed method is 0.72 and 0.69, respectively. The results show that the proposed method has better results in texture suppression and significant contour extraction than the comparison method.},
  archive      = {J_NPL},
  author       = {Cai, Pingping and Cai, Zhefei and Fan, Yingle and Wu, Wei},
  doi          = {10.1007/s11063-024-11486-3},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Neural Process. Lett.},
  title        = {Image contour detection based on visual pathway information transfer mechanism},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on solving flexible job shop scheduling problem
based on improved GWO algorithm SS-GWO. <em>NPL</em>, <em>56</em>(1),
1–26. (<a href="https://doi.org/10.1007/s11063-024-11488-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important branch of production scheduling, the flexible job shop scheduling problem (FJSP) is a typical NP-hard problem. Researchers have adopted many intelligent algorithms to solve the FJSP problem, nonetheless, the task of dynamically adapting its essential parameters during the computational process is a significant challenge, resulting in the solution efficiency and quality failing to meet the production requirements. To this end, this paper proposes an adaptive gray wolf fast optimization algorithm (SS-GWO), which adopts the gray wolf algorithm (GWO) as the basic optimization method, and the algorithm adaptively selects the global search or local search according to the degree of agglomeration of individuals. Firstly, a non-linear convergence factor strategy is employed to control the global exploration and local exploitation capabilities of the algorithm at different stages. This enhances optimization precision and accelerates convergence speed, achieving a dynamic balance between the two. Secondly, the spiral search mechanism of Whale Optimization Algorithm is used in GWO to improve the exploration capability of Gray Wolf Optimization Algorithm. Finally, the effectiveness of SS-GWO model is verified by comparison experiments. The comparison demonstrates the superiority of SS-GWO over the other five state-of-the-art algorithms in solving the 22 classical benchmark test functions. SS-GWO is applied to solve FJSP by means of the standard test function bandimarte calculus. The optimal solution and performance of SS-GWO for solving FJSP are compared with other algorithms. The experimental results show that the SS-GWO algorithm has good optimization performance, and the maximum completion time is reduced by 19% and 37% compared with that of IGWO and GWO, respectively, and the proposed SS-GWO algorithm achieves a better solution effect on flexible job shop scheduling instances, which can satisfy the actual production scheduling needs.},
  archive      = {J_NPL},
  author       = {Zhou, Kai and Tan, Chuanhe and Zhao, Yi and Yu, Junyuan and Zhang, Zhilong and Wu, Yanqiang},
  doi          = {10.1007/s11063-024-11488-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Neural Process. Lett.},
  title        = {Research on solving flexible job shop scheduling problem based on improved GWO algorithm SS-GWO},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On <span class="math display"><em>H</em><sub>∞</sub></span>
finite-time boundedness and finite-time stability for discrete-time
neural networks with leakage time-varying delay. <em>NPL</em>,
<em>56</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s11063-024-11489-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problems of $$H_\infty $$ finite-time boundedness (FTB) and finite-time stability (FTS) for discrete-time neural networks (NNs) with both leakage delay and discrete delay, as well as different generalized activation functions. To this end, we construct suitable Lyapunov–Krasovskii (L–K) functionals and apply the extended reciprocally convex approach to derive delay-dependent criteria for the addressed problems. The obtained conditions are expressed as linear matrix inequalities (LMIs), which can be efficiently solved by the LMI Toolbox in Matlab. The paper also admits of two numerical examples to point up the advantages and reliability of the proposed method.},
  archive      = {J_NPL},
  author       = {Tuan, Le A.},
  doi          = {10.1007/s11063-024-11489-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {On $${H}_\infty $$ finite-time boundedness and finite-time stability for discrete-time neural networks with leakage time-varying delay},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GraphSAGE++: Weighted multi-scale GNN for graph
representation learning. <em>NPL</em>, <em>56</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s11063-024-11496-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have emerged as a powerful tool in graph representation learning. However, they are increasingly challenged by over-smoothing as network depth grows, compromising their ability to capture and represent complex graph structures. Additionally, some popular GNN variants only consider local neighbor information during node updating, ignoring the global structural information and leading to inadequate learning and differentiation of graph structures. To address these challenges, we introduce a novel graph neural network framework, GraphSAGE++. Our model extracts the representation of the target node at each layer and then concatenates all layer weighted representations to obtain the final result. In addition, the strategies combining double aggregations with weighted concatenation are proposed, which significantly enhance the model’s discernment and preservation of structural information. Empirical results on various datasets demonstrate that GraphSAGE++ excels in vertex classification, link prediction, and visualization tasks, surpassing existing methods in effectiveness.},
  archive      = {J_NPL},
  author       = {Jiawei, E. and Zhang, Yinglong and Yang, Shangying and Wang, Hong and Xia, Xuewen and Xu, Xing},
  doi          = {10.1007/s11063-024-11496-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Neural Process. Lett.},
  title        = {GraphSAGE++: Weighted multi-scale GNN for graph representation learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RII-GAN: Multi-scaled aligning-based reversed image
interaction network for text-to-image synthesis. <em>NPL</em>,
<em>56</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s11063-024-11503-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The text-to-image (T2I) model based on a single-stage generative adversarial network (GAN) has significantly succeeded in recent years. However, the generation model based on GAN has two disadvantages: the generator does not introduce any image feature manifold structure, which makes it challenging to align the image and text features. Another is the image’s diversity; the text’s abstraction will prevent the model from learning the actual image distribution. This paper proposes a reversed image interaction generative adversarial network (RII-GAN), which consists of four components: text encoder, reversed image interaction network (RIIN), adaptive affine-based generator, and dual-channel feature alignment discriminator (DFAD). RIIN indirectly introduces the actual image distribution into the generation network, thus overcoming the problem that the network lacks the learning of the actual image feature manifold structure and generating the distribution of text-matching images. Each adaptive affine block (AAB) in the proposed affine-based generator can adaptively enhance text information, establishing an updated relation between original independent fusion blocks and the image feature. Moreover, this study designs a DFAD to capture important feature information of images and text in two channels. Such a dual-channel backbone improves semantic consistency by utilizing a particular synchronized bi-modal information extraction structure. We have performed experiments on publicly available datasets to prove the effectiveness of our model.},
  archive      = {J_NPL},
  author       = {Yuan, Haofei and Zhu, Hongqing and Yang, Suyi and Wang, Ziying and Wang, Nan},
  doi          = {10.1007/s11063-024-11503-5},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Neural Process. Lett.},
  title        = {RII-GAN: Multi-scaled aligning-based reversed image interaction network for text-to-image synthesis},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DCLGM: Fusion recommendation model based on LightGBM and
deep learning. <em>NPL</em>, <em>56</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11504-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recommendation system can mine valuable information according to user preferences, so it is widely used in various industries. However, the performance of recommendation systems is generally affected by the problem of data sparsity, and LightGBM can alleviate the impact caused by data sparsity to a certain extent. To this end, this paper proposes a fusion recommendation model based on the LightGBM and deep learning—CLGM model. The model is composed of LighGBM, cross network and deep neural network. First, the features in the dataset are fused and extracted through LightGBM, and the feature with the highest classification accuracy is selected as the input of the neural network layer; Then, using the cross network and the deep neural network, the linear cross combination feature relationship and nonlinear correlation relationship between high-order features are respectively obtained; finally, the results obtained by the pre-order network are linearly weighted and combined to obtain the final recommendation result. In this paper, AUC and Logloss are used as evaluation indicators to verify the model on the public dataset Criteo and dataset Avazu. The simulation experiment results show that, compared with the four typical recommendation models, the recommendation effect of this model is better.},
  archive      = {J_NPL},
  author       = {Zhao, Bin and Li, Bin and Zhang, Jiqun and Cao, Wei and Gao, Yilong},
  doi          = {10.1007/s11063-024-11504-4},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {DCLGM: Fusion recommendation model based on LightGBM and deep learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse embedded convolution based dual feature aggregation
3D object detection network. <em>NPL</em>, <em>56</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s11063-024-11506-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The algorithm design of compatible detection speed and accuracy based on LiDAR point clouds is a challenging issue in various practical applications of 3D object detection, including the field of autonomous driving. This paper designs a single-stage object detection algorithm that is lightweight and compatible with detection speed and accuracy for the above issue. To achieve these objectives, we propose a framework for a 3D object detection algorithm using a single-stage detection network as the backbone network. Firstly, we design a dual feature extraction module to reduce the occurrence of vehicle miss and error detection problems. Then, we use a multi-scale feature fusion scheme to fuse feature information with different scales. Furthermore, we design a data enhancement scheme suitable for this network architecture. Experimental results in the KITTI dataset show that the proposed method achieves improvement ratios of 38.5% for the detection speed and 2.88% $$\sim $$ 13.65% in terms of the average precision of vehicle detection compared to the existing algorithm based on single-stage object detection (SECOND).},
  archive      = {J_NPL},
  author       = {Li, Hai-Sheng and Lu, Yan-Ling},
  doi          = {10.1007/s11063-024-11506-2},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Sparse embedded convolution based dual feature aggregation 3D object detection network},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-triggered finite-time dissipative control for
fractional-order neural networks with uncertainties. <em>NPL</em>,
<em>56</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s11063-024-11510-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the focus is on addressing the problems of designing an event-triggered finite-time dissipative control strategy for fractional-order neural networks (FONNs) with uncertainties. Firstly, the Zeno behavior of the fractional-order neural networks model is discussed. Utilizing inequality techniques, we calculate a positive lower bound for inter-execution intervals, which serves to resolve issues related to infinite triggering and sampling. Secondly, we formulate an event-triggered control scheme to solve the finite-time dissipative control problems. Through the application of finite-time boundedness theory, fractional-order calculus properties, and linear matrix inequality techniques, we derive sufficient conditions for the existence of such an event-triggered finite-time dissipative state-feedback control for the considered systems. Finally, a numerical example is given to demonstrate the effectiveness of the proposed methodology.},
  archive      = {J_NPL},
  author       = {Huyen, Nguyen Thi Thanh and Tuan, Tran Ngoc and Thuan, Mai Viet and Thanh, Nguyen Truong},
  doi          = {10.1007/s11063-024-11510-6},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {Event-triggered finite-time dissipative control for fractional-order neural networks with uncertainties},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on feature selection with grasshopper
optimization algorithm. <em>NPL</em>, <em>56</em>(1), 1–54. (<a
href="https://doi.org/10.1007/s11063-024-11514-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent growth in data dimensions presents challenges to data mining and machine learning. A high-dimensional dataset consists of several features. Data may include irrelevant or additional features. By removing these redundant and unwanted features, the dimensions of the data can be reduced. The feature selection process eliminates a small set of relevant and important features from a large data set, reducing the size of the dataset. Multiple optimization problems can be solved using metaheuristic algorithms. Recently, the Grasshopper Optimization Algorithm (GOA) has attracted the attention of researchers as a swarm intelligence algorithm based on metaheuristics. An extensive review of papers on GOA-based feature selection algorithms in the years 2018–2023 is presented based on extensive research in the area of feature selection and GOA. A comparison of GOA-based feature selection methods is presented, along with evaluation strategies and simulation environments in this paper. Furthermore, this study summarizes and classifies GOA in several areas. Although many researchers have introduced their novelty in the feature selection problem, many open challenges and enhancements remain. The survey concludes with a discussion about some open research challenges and problems that require further attention.},
  archive      = {J_NPL},
  author       = {Alirezapour, Hanie and Mansouri, Najme and Mohammad Hasani Zade, Behnam},
  doi          = {10.1007/s11063-024-11514-2},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-54},
  shortjournal = {Neural Process. Lett.},
  title        = {A comprehensive survey on feature selection with grasshopper optimization algorithm},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-channels prototype contrastive learning with condition
adversarial attacks for few-shot event detection. <em>NPL</em>,
<em>56</em>(1), 1–34. (<a
href="https://doi.org/10.1007/s11063-024-11515-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot Event Detection (FSED) is a sub-task of Event Detection that aims to accurately identify event types with limited training instances and enable smooth transfer to newly-emerged event types. Recently, the dominant works have used the prototypical network to accomplish this task and employ contrastive learning to alleviate the issue of semantically-close categories. Nevertheless, these methods still suffer from two serious problems: (1) inadequate learning of prototype representations resulting from limited training data; (2) hard-easy sample imbalance and categories imbalance caused by the large number of non-trigger word(&quot;O&quot; tags) in the token-level classification task. To address the problems, this paper proposes the Multi-channels Prototype and Contrastive learning method with Conditional Adversarial attack, which introduces the improved multi-channels prototype and contrastive networks to alleviate the categories and hard-easy samples imbalance. Moreover, we devise a constrained adversarial attack to improve the problem of limited training data. Extensive experimental results show that our model performs better than other FSED methods. All the code and data will be available for online public access.},
  archive      = {J_NPL},
  author       = {Zhang, Fangchen and Tian, Shengwei and Yu, Long and Yang, Qimeng},
  doi          = {10.1007/s11063-024-11515-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-channels prototype contrastive learning with condition adversarial attacks for few-shot event detection},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural generalization of multiple kernel learning.
<em>NPL</em>, <em>56</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s11063-024-11516-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple Kernel Learning (MKL) is a conventional way to learn the kernel function in kernel-based methods. MKL algorithms enhance the performance of kernel methods. However, these methods have a lower complexity compared to deep models and are inferior to them regarding recognition accuracy. Deep learning models can learn complex functions by applying nonlinear transformations to data through several layers. In this paper, we show that a typical MKL algorithm can be interpreted as a one-layer neural network with linear activation functions. By this interpretation, we propose a Neural Generalization of Multiple Kernel Learning (NGMKL), which extends the conventional MKL framework to a multi-layer neural network with nonlinear activation functions. Our experiments show that the proposed method, which has a higher complexity than traditional MKL methods, leads to higher recognition accuracy on several benchmarks.},
  archive      = {J_NPL},
  author       = {Ghanizadeh, Ahmad Navid and Ghiasi-Shirazi, Kamaledin and Monsefi, Reza and Qaraei, Mohammadreza},
  doi          = {10.1007/s11063-024-11516-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Neural Process. Lett.},
  title        = {Neural generalization of multiple kernel learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exponential stability of stochastic time-delay neural
networks with random delayed impulses. <em>NPL</em>, <em>56</em>(1),
1–25. (<a href="https://doi.org/10.1007/s11063-024-11521-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mean square exponential stability of stochastic time-delay neural networks (STDNNs) with random delayed impulses (RDIs) is addressed in this paper. Focusing on the variable delays in impulses, the notion of average random delay is adopted to consider these delays as a whole, and the stability criterion of STDNNs with RDIs is developed by using stochastic analysis idea and the Lyapunov method. Taking into account the impulsive effect, interference function and stabilization function of delayed impulses are explored independently. The results demonstrate that delayed impulses with random properties take a crucial role in dynamics of STDNNs, not only making stable STDNNs unstable, but also stabilizing unstable STDNNs. Our conclusions, specifically, allow for delays in both impulsive dynamics and continuous subsystems that surpass length of impulsive interval, which alleviates certain severe limitations, such as presence of upper bound for impulsive delays or requirement that impulsive delays can only exist between two impulsive events. Finally, feasibility of the theoretical results is verified through three simulation examples.},
  archive      = {J_NPL},
  author       = {Huang, Yueli and Wu, Ailong and Zhang, Jin-E},
  doi          = {10.1007/s11063-024-11521-3},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Neural Process. Lett.},
  title        = {Exponential stability of stochastic time-delay neural networks with random delayed impulses},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synthetic hard negative samples for contrastive learning.
<em>NPL</em>, <em>56</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s11063-024-11522-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has emerged as an essential approach in self-supervised visual representation learning. Its main goal is to maximize the similarities between augmented versions of the same image (positive pairs), while minimizing the similarities between different images (negative pairs). Recent studies have demonstrated that harder negative samples, i.e., those that are more challenging to differentiate from the anchor sample perform a more crucial function in contrastive learning. However, many existing contrastive learning methods ignore the role of hard negative samples. In order to provide harder negative samples for the network model more efficiently. This paper proposes a novel feature-level sample sampling method, namely sampling synthetic hard negative samples for contrastive learning (SSCL). Specifically, we generate more and harder negative samples by mixing them through linear combination and ensure their reliability by debiasing. Finally, we execute weighted sampling of these negative samples. Compared to state-of-the-art methods, our method can provide more high-quality negative samples. Experiments show that SSCL improves the classification performance on different image datasets and can be readily integrated into existing methods.},
  archive      = {J_NPL},
  author       = {Dong, Hengkui and Long, Xianzhong and Li, Yun},
  doi          = {10.1007/s11063-024-11522-2},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {Synthetic hard negative samples for contrastive learning},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Projective synchronization of inertial quaternion-valued
neural networks via non-reduced order approach. <em>NPL</em>,
<em>56</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s11063-024-11523-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the issue on projective synchronization of delayed inertial quaternion-valued neural networks (IQVNNs) is investigated. Different from most existing literature, we adopt the non-reduced order approach to deal with IQVNNs described by second order differential equations. By introducing a novel Lyapunov functional, several sufficient criteria are presented in component form to ensure the projective synchronization between master–slave systems. A numerical experiment demonstrates the feasibility of control strategy as well as the correctness of theoretical results.},
  archive      = {J_NPL},
  author       = {Huang, Qun and Yu, Yue and Cao, Jinde},
  doi          = {10.1007/s11063-024-11523-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Neural Process. Lett.},
  title        = {Projective synchronization of inertial quaternion-valued neural networks via non-reduced order approach},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TSCF: An improved deep forest model for time series
classification. <em>NPL</em>, <em>56</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s11063-024-11531-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep forest presents a novel approach that yields competitive performance when compared to deep neural networks. Nevertheless, there are limited studies on the application of deep forest to time series classification (TSC) tasks, and the direct use of deep forest cannot effectively capture the relevant characteristics of time series. For that, this paper proposes time series cascade forest (TSCF), a model specifically designed for TSC tasks. TSCF relies on four base classifiers, i.e., random forest, completely random forest, random shapelet forest, and diverse representation canonical interval forest, allowing for feature learning on the original data from three granularities: point, subsequence, and summary statistics calculated based on intervals. The major contribution of this work, is to define an ensemble and deep classifier that significantly outperforms the individual classifiers and the original deep forest. Experimental results show that TSCF outperforms other forest-based algorithms for solving TSC problems.},
  archive      = {J_NPL},
  author       = {Dai, Mingxin and Yuan, Jidong and Liu, Haiyang and Wang, Jinfeng},
  doi          = {10.1007/s11063-024-11531-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {TSCF: An improved deep forest model for time series classification},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A graph contrastive learning model based on structural and
semantic view for HIN recommendation. <em>NPL</em>, <em>56</em>(1),
1–23. (<a href="https://doi.org/10.1007/s11063-024-11534-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of information in the Internet era, people are in great need of recommendation methods to filter information. At present, recommendation methods which based on heterogeneous information network (HIN) have attracted wide attention. Recently, HIN-based recommendation methods need to be modeled from two aspects: node structural association and semantic association. To this end, we propose a graph contrastive learning model based on structural and semantic view for HIN recommendation (GCL-SS). GCL-SS utilizes U-I interactive view to obtain node structural embeddings, and utilizes U-I semantic view to obtain node semantic embeddings. Based on these two kinds of embeddings, we establish a self-supervised contrastive learning mechanism to effectively integrate structural information and semantic information of user (item) nodes in HIN, and finally learn a more discriminative user (item) embedding. In addition, in order to strengthen the semantic association between nodes, we innovatively utilize time sequence encoder (TSE), such as LSTM, to encode semantic homogeneous network decomposed by HIN in U-I semantic view. At last, based on the user and item embeddings, we adopt bilinear decoder to model the potential association between user and item, so as to realize rating prediction of user to item. The experimental results on three real datasets confirm that our GCL-SS model performs better than state-of-the-art recommendation methods in rating prediction task. In addition, the results of four ablation experiments indicate that our GCL-SS model can effectively improve the performance of rating prediction in recommendation.},
  archive      = {J_NPL},
  author       = {Yu, Ruowang and Xin, Yu and Dong, Yihong and Qian, Jiangbo},
  doi          = {10.1007/s11063-024-11534-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {A graph contrastive learning model based on structural and semantic view for HIN recommendation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A YOLOX object detection algorithm based on bidirectional
cross-scale path aggregation. <em>NPL</em>, <em>56</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s11063-024-11536-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the problem of insufficient feature fusion between the deep and shallow feature layers of the original YOLOX algorithm, which resulting in a loss of object semantic information, this paper proposes a YOLOX object detection algorithm based on attention and bidirectional cross-scale path aggregation. First, an efficient channel attention module is embedded in the YOLOX backbone network to reinforce the key features in the object region by distinguishing between the importance of the different channels in the feature layer, thus enhancing the detection accuracy of the network. Second, a bidirectional cross-scale path aggregation network is designed to change the information fusion circulation path while increasing the cross-scale connections. Weighted feature fusion is used to learn the importance of the different path input features for differentiated fusion, thereby improving the feature information fusion capability between the deep and shallow layers. Finally, the SIOU loss function is introduced to improve the detection performance of the network. The experimental results show that on the PASCAL VOC2007 and MS COCO2017 datasets, the algorithm in this paper improves mAP by 2.32% and 1.53% compared with the original YOLOX algorithm, and has comprehensive performance advantages compared with other algorithms. The mAP reaches 99.44% on the self-built iron ore metal foreign matter dataset, with a recognition speed of 56.90 frames/s.},
  archive      = {J_NPL},
  author       = {Liu, Qunpo and Zhang, Jingwen and Zhao, Yi and Bu, Xuhui and Hanajima, Naohiko},
  doi          = {10.1007/s11063-024-11536-w},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {A YOLOX object detection algorithm based on bidirectional cross-scale path aggregation},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-KG link prediction by learning substructural
semantics. <em>NPL</em>, <em>56</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11537-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction across different knowledge graphs (i.e. Cross-KG link prediction) plays an important role in discovering new triples and fusing multi-source knowledge. Existing cross-KG link prediction methods mainly rely on entity and relation alignment, and are challenged by the problems of KG incompleteness, semantic implicitness and ambiguosness. To deal with these challenges, we propose a learning framework that incorporates both node-level and substructure-level context for cross-KG link prediction. The proposed method mainly consists of a neural-based tensor-completion module and a graph-convolutional-network module, which respectively captures the node-level and substructure-level semantics to enhance the performance of cross-KG link prediction. Extensive experiments are conducted on three benchmark datasets. The results show that our method significantly outperforms the state-of-the-art baselines and some interesting analysis on real cases are also provided in this paper.},
  archive      = {J_NPL},
  author       = {Wen, Wen and Wu, Shiyuan and Cai, Ruichu and Hao, Zhifeng},
  doi          = {10.1007/s11063-024-11537-9},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Cross-KG link prediction by learning substructural semantics},
  volume       = {56},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
